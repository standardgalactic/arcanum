Hello. Today I'd like to talk about bots, AI, and social media influencing human behavior.
There was an interesting event that happened earlier this year. This is 2025.
A team of researchers from University of Zurich used AI to pose as people in a Reddit.
Reddit is part of the internet where there's subreddits of various different subjects.
And one of them is called Change My View, where people post a subject matter and then they want people to change their view, see if they can change their view, their opinion about something.
It could be political, economic, religious, or something.
And then people post to try to change their original poster's perspective.
Well, this team from University of Zurich used AI to pose as several different accounts.
And they posted something like 12,000 comments to this subreddit.
These are fake. These are not real people. These are bot accounts.
But they posed as various types of people.
One was an African-American that opposed the Black Lives Matter movement.
Why would they choose that?
Another one was a male rape, sexual assault survivor.
There were several other different personas that they chose to have AI pretend to be.
And without consent of the people participating in this subreddit, and without the consent of the moderators, or the knowledge of the people who run that subreddit,
these researchers collected data, seeing if they could influence people using AI.
And the metric they used was how many awards or upvotes the AI comments got versus other Redditors' comments.
Now, are those humans? We don't know.
Probably.
But they may be bots, too.
Because we don't know.
And that's the whole point of this talk.
Well, what they found, what they reported to the subreddit,
so they eventually disclosed that they were conducting live experiments on humans without their consent.
And they found that the AI personas, the AI bot accounts, were more persuasive than other Reddit comments,
whether they were human or other AIs,
by a factor of around six,
in terms of measures of upvotes and awards given to these comments.
So, their argument was that the AI bot accounts were about six times more persuasive based on their measurements
than what were probably humans commenting.
So, that caused an uproar.
In fact, the Reddit team got their legal team involved,
threatening to sue the university.
And the researchers did not, they agreed to not publish their results.
And the university said that they were going to,
they issued a warning to the researchers.
Now, that just sounds like a slap on the wrist.
So, what does this mean?
Well, as somebody who contributes to social media,
me, Gooby,
I read a lot of comments from people that comment on my channel.
And I know for sure that some are bots
because some are trying to promote some product or a book
or some get-rich-quick scheme
or some psychedelic mushrooms or something.
And then, it's very easy to spot
because one comment will all of a sudden have like 30, 40 replies
all saying kind of similar things.
It's a scam.
Or, they'll say,
or there'll be people that pretend to be me.
So, I know that they're definitely not real people
because they're pretending to be me.
But they changed the name from Gooby and Dooby
to like Gabi and Dobby
or Gabi, Gooby underscore and underscore Dooby.
And then, they ask people to contact them
by some number,
some like telegram or WhatsApp thing.
And then, hopefully,
they're not scamming people on this channel.
So, if you've fallen for that,
it's not me.
It's just Sabat just taking your money or something
or manipulating you to do something.
So, don't fall for that.
So, there definitely are bots
that comment on this channel.
But the thing is,
there are other comments
that certainly seem bot-like.
And, the thing is,
those are much more subtle.
But the way that they communicate
and the repetitiveness
is concerning for bot-like behavior.
But, I don't know.
And then,
sometimes I run into a comment
like today.
that is very convincing
that it's a human being.
But, too convincing.
And, in that,
it's like,
it's like they,
the person or
program that commented
like knows exactly
what I would respond to.
And, what would get me to
change my mind about something.
And, they sound like a real human being.
But, they're so perfect
in their execution
of what they said
to try to change my mind
that it makes me suspicious.
Well, I see all of that
as a content creator
with a YouTube channel
that receives a lot of comments.
I used to be a very active participant
in Reddit.
Well, maybe
not active participant,
more of a
active consumer
of the content of Reddit.
and Reddit
is only partially
like the post
but the majority
of the content
is the comments.
People comment.
And,
this,
this episode
from University of Zurich
shows that
people are using
bots,
AI,
to sway people's opinions.
Well, I think
that is happening
on YouTube.
It's probably happening
on TikTok,
on Instagram.
I don't use those.
Probably happening
on X,
formerly known as Twitter.
And,
it's,
it really makes me
second guess
what I read online.
And,
if I want to read,
read comments.
If I want to read
articles.
There's,
there's a,
lawsuits
that are going on
in,
in popular culture
about,
some director
named Baldoni
and the
actor,
ah,
crap,
what's her name?
Blake Lively.
And,
part of the lawsuit,
part,
part of the lawsuit
claims that
Baldoni hired
a PR firm
to write
smear articles
and post comments
that would sway
people's view.
Now,
I'm not taking
one side or the other
because,
honestly,
I don't really care
that much about it
other than the fact
that this claim
was made.
And,
that fits
with
what happened
from University of Zurich
that,
you know,
people are using bots
to sway people's opinions.
and it fits
with what I see
on my YouTube channel.
And,
it fits with
my experience
of reading Reddit,
which,
I don't read
Reddit anymore
because
I felt like
it was just
a bunch of echo chambers,
possibly with significant bot activity
to sway my mind
about things.
Well,
there is a theory
called the dead internet theory
that at some point
the bot,
the internet's,
internet will be
taken over by AI
just chatting with itself.
No,
I don't think
that we're there.
But,
I think that
it's significantly
changed
and that
it's kind of
headed that direction.
So,
I don't think
it is a dead internet.
I think that
the internet,
the technology,
social media,
is allowing people
to connect
in ways
that we haven't
before.
but I also think
that
AI
and corporate
interests
are
co-opting that
for their own ends.
Government too.
People that have money
that can pay
for these things
are influencing
people's viewpoints.
I felt like
my
friends
that I've known
for a long time
have
been swept up
in
polarizing
subject matters
like
the
Baldoni
Blake Lively
controversy
like
racist content
on TikTok
and
Instagram
like
political content
I feel like
it's very
dangerous.
It's dangerous
to the fabric
of society.
I made a video
about that.
But the thing
that I was
really kind of
concerned about
bot activity
was confirmed
in this story
about the
Zurich
researchers.
so I wanted
to make
this video
make sure
that people
are watching
this channel
and be careful.
There are
bots already
swaying people's
opinions
and it's very
hard to know
if a commenter
is a real
person
or an AI.
I mean
sometimes
it's easy
to tell
if it's
like a scam
but
sometimes
it's not.
In fact
sometimes
it's so
convincing
it's like
a well-oiled
machine
to change
your mind
about something
and if you
feel that way
I would
really
be careful
if you
run into
someone
or
somebody
that is
posting
something
and it's
like a
really
well-oiled
machine
that's
changing
the way
you think
be really
careful
be really
careful
yeah
that's what
I would
say
how do
you prove
whether
someone's
real
well you
can meet
them in
person
but even
then
you don't
know
if they're
just putting
on
putting
on
a
performance
acting
I guess
the only
people that
you can
really know
are real
are people
you've known
for a long
time
people that
you've had a lot
of interaction
with in
person
but it's
very hard
to know
if someone's
real online
people have
asked if I'm
real
did I really
go into
neurosurgery
did I
really study
medicine
am I just
making all
this stuff
up
well
I guess
if you're
really good
you could
probably find
out all
that information
online
most people
don't want to
spend the
time to do
that
and I'm
not going to
volunteer that
information
because that
all docks
myself
and there
are some
crazy people
out there
I've had
people show
up
try to
talk to me
about
actually the
dangers of
AI
now I don't
think that
person's crazy
but it
did send a
lot of
red flags
up
they were
just hanging
out around
my place
for like
a couple
weeks
is what
they said
so yeah
I'm not
going to
dox myself
to prove
to someone
that I'm
a real
person
how do
you know
if someone's
a real
person
how do
you know
they're not
a bot
how do
you know
they're not
AI
well in
this day
and age
it's very
difficult
makes me
appreciate
the people
that I do
know
in real
life
and that I
have
in real
life
conversations
share a
meal
with them
go
backpacking
my
doggie
she's
real
I spend
time with
her
every day
my
wife
she's
real
I don't
communicate
with her
by social
media
yeah
well I
guess
the point
of this
talk
is
appreciate
real
personal
interactions
and be
wary of
what you
see and
hear
online
because
there's a
lot of
manipulation
going on
that is
that is
what I
would have
to say
about that
this is a
short video
thing
you
you
you
you
you
you
you
you
