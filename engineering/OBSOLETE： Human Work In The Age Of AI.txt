Tyler Perry was building an $800 million studio and he paused the construction as soon as he saw
what is it called Sora? Sora. If you haven't heard about OpenAI's Sora it's about to blow your mind
and maybe even your eyes. In an instant we've gone from Will Smith eating pasta to this.
Honestly if I saw this on Twitter I'd be like oh nice drone shot dude and that
has all sorts of implications for the drone pilot that no longer needs to be hired for all the
photographers and videographers whose footage no longer needs to be licensed to show up in that ad
that's being made. The implications are so massive that it's it's tough to try to wrap your head around.
This is cool Brian I mean yeah it could mean a millions of people though could be out of work.
Well how long till I can take my favorite book or novel and just feed it into the computer
and have the computer make it a movie or a Netflix series?
It's a very big computer in the cloud about two years.
The era of Hollywood is basically over. You're going to be able to just make a movie yourself by
typing in a few problems. We're f***ed. We're f***ed. We're f***ed. Because there will be no more jobs.
What does that do to the industry? I think it erases it. I don't think the industry changes. I think it
goes away. When you got an idea you want to move on. You might not have the money. You might not have
the education. You might not have the support or the resources you need. What is that something
that can keep us going that will enable us to act on our dream? Here's what I want you to repeat after
be pleased with power and conviction. Say it's possible. It's possible. This is Les Brown one of
the world's leading motivational speakers. Two years ago when I started a motivational videos
channel on YouTube and was looking for materials he stood out. It was the beginning of 2023. I just
became aware of chat GPT. I gradually felt conflicted. Here I was editing videos which are supposed to uplift
people. Make them believe in themselves and in the power they have to face any crisis and make their
lives better. But chat GPT seemed to signal that the world where you could redeem yourself through hard
work and determination might come to an end. With the presentation of AI tools that are built in order
to eventually outperform humans in any task possible. How could you redeem yourself in a world where job
opportunities have become obsolete? In a world like that would Les Brown's uplifting speeches be relevant at all?
The AI space is on a roll right now. I mean the game does not stop. In just 18 months over a billion
people have used large language models. We are in the fastest and most consequential wave ever. The
developments in AI are moving so fast every day it unlocks something new and fundamental for economic and
national security. It feels like things are changing incredibly fast like this generation is undergoing a
more rapid change of their technological environment than ever before. Is it really or does every
generation feel that way? Every generation thinks like that but this time it's real. At some point we
will be able to use our models to say all right like let's do amazing things with a robot. If the hardware
guys who've done a good job on legs actually get the arms hands fingers piece and then we couple it
and it's not ridiculously expensive that could change the job market for a lot of the blue collar type
work pretty rapidly. This robot is learning the behaviors through the use of neural networks and
it's improving on them trial and error step by step by itself automagically. What we want our humanoids
to do is to do physical work and we want them to be a generalizable replacement for human labor.
They're already having them work as kitchen assistants where they talk to you in your kitchen.
I go to studio where you used to go in those places and see like 12 cameramen is one producer
and all the cameras are robotic. We hear from people who are excited. We hear from people who are
concerned. I am very worried about it being a job destroyer because that's the low road and what we
are seeing from the Hollywood studios what we're seeing from BuzzFeed what we're seeing from the ad
industry and what we're seeing from many office jobs is that that's going to be the most natural
tendency. That's going to steamroll through society. That is just going to mow people over.
The layoffs and technology just keep coming. What if Google's Leia they're just the beginning of an
entirely new trend rather than playing catch up or correcting post pandemic. This is actually Google
getting into position for an AI platform shift that will require a different kind of workforce. The move by
Paytm highlights a strategic shift one that leans towards leveraging AI for greater efficiency. Just today I
saw this use case where they replaced 700 workers with a bot and saved 38 million dollars and drove
customer service calls from 10 minutes to two minutes. So everyone won except the 700 people
that used to work there. OpenAI will roll out an update that obliterates the jobs of illustrators
from one day to the next obliterates the jobs of translators from one day to the next. If you're in the
Philippines what's happening to your entire poor sector industry when you have a 24 7 AI that beats perfect
English. There are jobs where your tasks what you actually do minute to minute are pretty much the
tasks that AI is doing faster cheaper and higher quality. If AI does everything and then what AI
doesn't do the robots do then where do I fit in as a person as someone who's on this planet for a
certain period of time. Perhaps the biggest nightmare is the looming new industrial revolution the displacement
of millions of workers. We're looking down the line at AI automation and you're going are we not just
going to make millions of jobs obsolete. And now pretty much everybody in tech thinks that generative
AI is the next big platform shift. However that's about the only thing that we really think is clear
after that all the questions are wide open in fact we're still trying to work out what the questions are.
So the big question is when will AI change our lives? I think that's a much harder question than
will AI change our lives? Any prediction that you make with a timeline is guaranteed to be wrong so
I'll try to give myself at least a little bit of buffer and I know that everything I'm saying
probably directionally correct timeline probably way off. But in two years or five years from now
would you need to rethink your thesis or redo your calculations? I should have prefaced this by saying
there's a huge amount of uncertainty in any forecast about AI and apologies that I didn't do that.
It is incredibly hard to predict the future right now even for those of us in the middle
of it. So all sorts of kind of science questions as to how good this will get where the answer is I
don't know but neither does anybody else. Do you think it's an AI bubble? You said bubble so I'm gonna
ask is this a bubble? So there's this suspicion growing that AI is nothing but marketing hype that
it's the same as crypto. Like I was saying it's FTX. It's a safe and easy way to get into crypto.
Yeah I don't think so. A web 3 and the metaverse just a new way for these tech companies to prop up
their stock prices because they don't have any other real ideas. Do you have an example of something that
humans are doing that you think AIs are potentially super far away from? Well almost everything that
humans do in the economy AI is pretty far away from that. I don't need some special example I can just
pick a random job. Do you think that we are in some sort of hype cycle? Do you think that actually
this market is as big as many are factoring in? Well first of all we are definitely in a hype cycle.
There's going to be multiple. One day you read in the papers LLMs can do anything and the next day
you read they've hit a limit. Ignore all that stuff. We're just starting this. There's going to be massive
aspirations. In December 2023 the International Monetary Fund
published an article by economist Anton Koronek highlighting three scenarios for AI's economic
impact. 1. Business as usual. AI improves productivity and creates new job opportunities for displaced workers.
2. Baseline. AGI in 20 years. AGI automates all human tasks within two decades devaluing labor.
3. Aggressive. AGI in five years similar to the baseline but faster. The IMF's recognition of AI's uncertain
economic effects emphasizes the issue's urgency. In order to say something about the future of work and
economy in light of AI progress we have to navigate a minefield of open questions. But we need to at
least outline some kind of approximate trajectory. I think now when we are approaching what I think
will be this transition to a machine intelligence era we maybe need to give some deeper thought to
what ultimately it is that we would be hoping to achieve if we avoid all the pitfalls and the dangers
like what is the actual destination that we are staring towards. Before we dive into the
possible future problems caused by fast AI-fueled automation let's hear what some of the AI
proponents are thinking about a positive future enabled by it. We think we can have like significant
economical value if we can basically have robots doing real work every single day. Once you have
general-purpose humanoid robots and autonomous vehicles you can build anything. Whether it's cleaning
your house or manufacturing cars or making a beautiful garden. We're going to go to a post-scarcity
type economy. In a benign AI scenario we will really have an age of abundance. You'll be able to have
any products and services you want. I think over a long enough period of time everybody will own a
humanoid just to do work for them. Labor will be optional and you'll choose to do work or not. Bad day at
the office. Yeah those three hour work days are killing me. We as a human race are then liberated from
having to do routine work so we can do things that we enjoy or we're good at. This is one version of
optimism which basically claims automation will bring an age of abundance where humans will not have to
work at all. It turns out when you look through human history when there's a major automation of
something the instant reaction is oh my god we're gonna have millions of people out of work. What
actually happens is we create a ton more work that needs to get done okay. Another version of optimism
claims that we'll enjoy an unprecedented prosperity which will create endless job opportunities. What happens
is the introduction of technology into production process causes prices to fall. As prices fall consumers have
more spending power. As consumers have more spending power they create new demand. That new demand then
causes capital and labor to form into new enterprises to satisfy new wants and needs and the result is
more jobs and higher wages. To me the future is not necessarily unemployment it's actually corporations
maybe being 80% AIs 20% humans but we have way more corporations and we're far more ambitious with what
we do right. So it is sort of a happy story that labor demand and firms desire to increase their
scale are sufficient forces to translate some of the technological improvements into benefits for
workers and we question that. What about the worker? The workers work for companies and so companies when
they become more productive earnings increase. I've never seen one company that had earnings increase and
not hire more people. But if you're doing automation imagine amazing factory that has no workers that produces a lot of output
well why should that make employers want to hire more laborers? There are some jobs that are going to
become obsolete. Customer service representative automated. Receptionists automated. Accountants and
bookkeepers automated. Salespeople automated. Research and analysis automated. Warehouse work automated.
Insurance underwriting automated. Retail automated. Well let me offer it this way. I believe that you still
want human in the loop because we have good judgment because there are circumstances that the machine's just not going to
understand. There will be many other jobs that will be very hard to predict as history would tell us
every technological revolution has eventually provided more jobs than it decimated. There'll be creators
who will create for AI models or something like that and get paid for it. You know people have asked me
is AI going to take your job and I always say AI will not take your job. AI used by somebody else will take your job.
Who would have thought that there will be a prompt engineer right? Right. Prompt engineer. I think
you mean types question guy. And by the way if there's any job that can be easily replaced by AI
it's types question guy. Many people say it'll create more jobs. For this particular thing I'm not
convinced of that. In the industrial revolution we made human strength irrelevant. Now we're making human
intelligence irrelevant. What's different this time is this is a machine of the mind. It shapes
cognitive work. I have a suspicion that AI is coming for the cognitive class. You know it used to
be your labor. Okay we can get past the labor we got tractors and things and you go up up up up up
and we're up to the point in our minds where anything related to mental processing the computer can
probably do better. Everyone's getting brainwashed and thinking okay you have to be adaptable you have to
be like an efficient market actor and if you can just do that then you're going to be okay. No.
What if you're like you're a janitor you're you're like a freaking plumber or you're going to just
change your like how how's that supposed to work? At some point in the future there will come a time
when the cost of hiring a human to do a job will become equal to the cost of renting a robot to do that
same job. When that point comes we won't really need humans to work. Human labor is going to become
economically irrelevant. Let me say that again the economic value of human labor is going to be zero
before too long. This concern has played out for literally centuries and you know this is the story
of the Luddites. The overwhelming evidence is that the net gain here is wildly positive and most people
like overwhelmingly come out the other side being huge beneficiaries of this. There isn't even any
question or debate that we today are beneficiaries of the process that started in the 18th century. The
industrial revolution the application of industrial technology and then later scientific methods we
are much more comfortable much much much healthier and much much more prosperous. So you might think
that is exhibit number one for techno-optimism. Well not quite that process wasn't automatic either and in
fact the first 80 90 years of the British industrial revolution did not bring much comfort or improvements to
the working people. But then in the end it became better so yes so in my view there will be a lot of
disruption like these other like the industrial revolution also you know 90 years it took 90 years
I don't think that's what we want to put up with. That interim period can be very very messy because
it's a zero-sum game with people scrabbling over that. You need to think about how do you manage that
transition because there's vested interests and others when the whole world gets flipped and currencies start
shifting because a lot of the anchors are broken. Each technological revolution has gotten faster
and this will be the fastest by far and that's the part that I find potentially a little scary is
just the speed with which society is going to have to adapt and the labor market will change. The worry
is that the creation of new wants and needs at a rapid rate will mean there's a lot of turnover in
jobs so people will lose jobs just the actual experience of losing a job and having to learn new things
and new skills is painful. The transition period is the danger. I mean some jobs disappear, some jobs
appear, people have to transition. Just remember that Hitler rose to power in Germany because of three
years of 25 percent unemployment. Look the transition is going to have pain. There's going to be challenges
and reordering and sort of disruption because this is an industrial AI revolution done incredibly quickly
with multiple things from self-driving to autonomous agents to intelligence all coming at the same time.
At least those other disruptions took place over a century or decades. AI is going to be ready to
take over by Thursday. And once that happens, what the is there left for the rest of us to do?
So the conditions of the working classes did not improve, not at all, until the second half of the 19th
century. So was that an automatic process? No. That was a result of a redirection of technological change
towards things that increased labor productivity and through a process of institutional change,
democratization, much better bureaucratic control of pollution, public infrastructure, public sanitation
and trade unions became legal and started for asking better conditions, higher wages,
also having a say in how factories were run. Why did the labor movement succeed after the industrial
revolution? Because it was needed. The companies still needed to have workers and that's why strikes had
power and so on. If we get to the point where most humans aren't needed anymore, I think it's quite
naive to think that they're going to still be treated well. I am of the opinion that AI can already do
all of the jobs that we as humans do. It's just a question of how we apply it and use it. The only
question is, can we create new jobs to make up for that? And that's difficult. Do you think we can?
I doubt we can, to be honest.
Geoffrey Hinton, do you think that this increase in productivity, essentially, that will come with
automation and so on and so forth, is a good thing for society? Well, it ought to be, right? I mean,
it's crazy. We're talking about having a huge increase in productivity. So there's going to be
more goods and services for everybody. So everybody ought to be better off. But actually, it's going to
be the other way around. And it's because we live in a capitalist society. And so what's going to happen
is this huge increase in productivity is going to make much more money for the big companies and the
rich. And it's going to increase the gap between the rich and the people who lose their jobs.
That technology provides those who control it, the power to improve things, but also the power
to dominate others, gain all of the advantage, create more inequality. I worry about economics
and the concentration of power. I worry about how do we make sure that that fair world reaches
everyone. When things have gone wrong for humans, they've often gone wrong because humans mistreat other
humans. How do we make sure that it's not like a handful of people in San Francisco making decisions
and reaping all the benefits? The social inequality we have today is nothing compared to what we could
have if we don't address it, because AI will just be such a powerful lever. I think we have an opportunity
that comes along only every couple of centuries to redo the socioeconomic contract. And how we include
everybody in that, make everybody a winner, and how we don't destroy ourselves in the process is a huge
question. You list in the list of what we must do as rethink our economic models. One of the biggest
challenges is that our historic economic models aren't viable. They don't make sense anymore with
what's coming given AI and humanoid robotics. So how do you think about rethinking our economic models? Where
do you imagine it going? That's a nice, simple question, Peter.
You just lost your capitalist model. You have a model with two inputs called K and L that's taught
in every university that subscribes to neoclassical economics. What's AI? Is it L? Is it labor? Is
it capital? What the heck is it? There is no distinction between capital and labor once you can automate
pretty much everything. This is a profound challenge to capitalism, and I think we need to be honest about
it. Well, no kidding. This is going to break capital. It's entirely clear that it's going to break
capitalism. And the old structures can't answer those questions. So we need completely new models
and new structures, new value systems, new monetary systems, et cetera, to deal with these structures.
That creates massive dysfunctions in a bunch of ways. So for instance, if you have workers who don't have
cash capital to buy goods and services, which are made more productively than ever before because
you have so much automation, then you have a crisis of what's called price of demand or under-consumption,
which is you don't have people who can buy all the goods and services being made.
While automation promises unprecedented productive efficiency, it simultaneously
threatens to eliminate human labor income. Without wages, where does consumer purchasing power come
from? Society and politicians need to recognize that this is not something that's going to change
in 10 years. The implications for society are going to come in the coming years, and it's time to think
a little bit proactively about what measures could be taken as a consequence. I still find it mind-blowing
that people don't seem to be fully grasping the trajectory that we're on. I mean, we are going
to produce a replacement to cognitive management in the next couple of years. That's going to have a
massively, massively fundamental shift to the labor market. If structural disemployment goes up by one or
two percent, the financial cost of managing that transition is phenomenal. The impact on populism and
the political process is phenomenal. So I just feel like, you know, that's the conversation that we
should all be having. The companies do not have a plan for the hundreds of millions to billion jobs
that they are about to displace. That's sort of what we've been wondering is when this shows up in
the macroeconomic conversations and is the Fed paying it? I mean, we know the Fed's paying attention,
but there's a lot of research to be done. I've been asking heads of IMF because if it's going to have
profound effects on productivity and economic growth and labor market, it's something we have to
understand. It needs to be viewed really as an emergency situation in which there's a good work,
good plan worked out for how to deal with that effectively. All hell's about to break loose.
And my question is, are you trying to figure out which way the wave is going to break and get your
surfboard in the water? Are you trying to figure out how to anticipate this? No. In general,
we sit around worrying about it in the most inert way possible. There really is no plan. That's the
single biggest thing that you get hit over the head with over and over, whether it's talking to
the people who are in charge of the labor transition, their whole thing is like, yeah, universal basic
income, and then question mark, and then smiley face. That's basically the three steps that they
envision. It's the same when you look internationally, like, okay, tomorrow you build an AGI that's like
incredibly powerful, potentially dangerous thing. What is the plan? Like, how are you going to,
like, I don't know, you're going to secure it, share it? Figure it out as we go along, man.
Yeah. That's the freaking message. Like, that is the entire plan.
If we live in this world of infinite abundance with billions of robots and trillions of agents,
what is money? We need to rethink how our economic flows go and the rights around that as well,
and that's difficult and it's hard. That's why I think every nation needs their own AI experts,
AI teams. We need to get the smartest economists in the world to think about this and think outside the
boat. This is the moment. Why are we not holding a conference on after capitalism and communism?
What is the next economic system? Do you imagine that Adam Smith and Karl Marx would just be sitting
on their hands? No, they'd be smart enough to say, okay, we now need a new model. We're going to have
an opportunity to push the reset button and think about the world we want, and I think universal basic
income is one part of that.
So, universal basic income, this is what this is all about. My initial knee-jerk reaction was,
get out of here. Like universal basic income, just going to give people money. They're just going
to be lazy. Nothing's ever going to get done. That's a terrible idea. And then I started paying
attention to the rise of AI and automation and how many jobs are going to get taken away. And then
once you see the actual numbers, it's pretty staggering. The idea is as AI and robotics start
to disrupt them job markets and people lose their job to technology, we need to do a few things,
potentially, at least in the interim, is give them reliable income, a universal basic income
that allows them to put food on the table, get insurance, perhaps get a better education,
perhaps invest in whatever tech they need to start a small business. And it's about human dignity to a
large degree and getting rid of fear. There's going to be a lot of fear as AI steps in in a bigger way
in the next few years. UBI, universal basic income, seems to be the main solution many propose for a
world where human jobs have become obsolete. But there are many problems with the concept of UBI,
as far as I can see. Over the years, several UBI experiments have been conducted, including one
concluded in mid-2024, backed by OpenAI CEO Sam Altman, where low-income individuals received
$1,000 per month. However, it's important to note that these experiments evaluated UBI's impact on
individuals within our current economy, where most people work and UBI supplements their income.
They did not examine a future scenario where jobs became obsolete, and most people would have to
rely solely on their monthly UBI allowance. In my view, this makes these experiments largely
irrelevant to the UBI envisioned for a post-labor society. UBI is basically like just getting an
allowance from your parents, and that's not good. I mean, it's a start, you know, it's better than
nothing, but that is no way to live. I think technology does a great deal to lift the world
to more abundance, to greater heights, to better prosperity, whatever you want to call it. You
can see lots of ways. It doesn't take much imagination that AI does more to help the poorest
people than the richest people, and we really believe that. We're enthusiastic about it.
AI advocates often claim that the immense wealth AI will generate could help third-world countries
close the gap with the West. But is this realistic? So James, let me ask you then,
if you think technology, AI could help Africa develop. But Africa has not been benefiting from
all this technology. But could it, I'm saying? It could. But to do that, many things have to change.
Institutions have to change. Politics has to change. And then the even bigger issue is one of space.
The disappearance of jobs and the new jobs will be created in different parts of the world. So we
might see a situation when there is immense demand for more jobs in California or Texas or China,
whereas entire countries lose their economic basis. So we look industry by industry. First you stop
offshoring, then you stop graduate hiring, and then it impacts the workers. The only prospect for
rebuilding U.S. manufacturing is to climb the tech stack and build new kinds of factories that are fully
robotic and fully AI-enabled, where they're extremely advanced, sophisticated systems that run in a very
different model than a manual laborer system. You pour as much technology into them as you possibly
can. And the reason for that is just very straightforward, which is the big thing that
caused U.S. manufacturing to move offshore was the cost of people. It was just flat out cheaper to hire
people in, you know, Korea or Vietnam or China or India or Mexico. Consider Vietnam with its massive
manufacturing sector, which accounts for about 25 percent of its GDP and includes many foreign companies
that have relocated production there. Or take the Philippines, where a significant portion of GDP
comes from customer service, IT support and financial services provided to Western companies
and customers. All these sectors are at risk of being disrupted by AI. I think anything that's outsourced
right now, that has to be in danger. The winners of the AI race will most likely be American companies,
and possibly some Chinese ones. The U.S. and China might be able to tax these companies to fund
universal basic income, UBI, for their citizens. But what about the rest of the world?
Let's talk about DeepSeq because it is mind-blowing and it is shaking this entire industry to its core.
In the wake of the Chinese open source large language model DeepSeq R1, there has been a lot of talk
about the need to make LLMs open source. I think if you want regulations, the most important
regulation would be to not open source big models. It's crazy to open source these big models because
bad actors can then fine tune them for all sorts of bad things. I might be wrong here, but as Hinton
has noted regarding security concerns, if we want to survive, these models likely cannot be open source
in the future. This raises an important question. How would other countries generate enough wealth
to fund UBI? I think there will be immense new wealth created by these technologies. I'm less sure
that the governments will be able to redistribute this wealth in a fair way on a global level.
I just don't see the U.S. government raising taxes on corporations in California and sending the
money to help unemployed textile workers in Pakistan or Guatemala. Take a European country like Finland,
for example, with its substantial IT and manufacturing sectors. If we assume that AI will not be open source,
there is a significant likelihood that AI products from the U.S. and China could dominate the market and
disrupt large portions of Finland's economy. In that case, how could Finland afford UBI?
So a lot of people are thinking, oh, if the robots take all the jobs, we'll just have our government
hand out a UBI and then everybody will be okay. See, the problem with that is you're counting on this
new robot economy being in your jurisdiction so you can tax it to pay for the UBI. But this new robot
economy doesn't have to be equally spread around the world. It doesn't have to be showing up in your
jurisdiction so you can tax it. It might be showing up only in a few other places. And beyond this,
there is another major problem with UBI. I certainly believe in universal basic income.
I don't think that's enough, though, because a lot of people get their self-respect from the job
they do. And if you put everybody on universal basic income, that solves the problem of them
starving and not being able to pay the rent. But it doesn't solve the self-respect problem.
Universal basic income, too, is still the best thing we can do. People used to always ask you,
well, what about the meaning that work provides? And you're like, yeah, that's a tough one. Like,
I don't want to tell you about that. Look, I'm someone who believes very deeply that people need
structure, purpose, fulfillment, community, and that we work for a multitude of reasons,
not just to pay the bills. Jobs bring dignity, and they bring an identity, and they bring structure.
We have also idea for iRisk, Ikigai risks, where we lost our meaning. The systems can be more creative,
they can do all the jobs. It's not obvious what you have to contribute to a world where superintelligence exists.
What would you do if you didn't have to do anything? Because robots keep everything better than you.
I get a lot of excitement that, hey, I'm good at working on malaria, and malaria eradication,
and getting smart people, and applying resources to that. When the machine says to me,
Bill, go play pickleball. I've got malaria eradication. You're just a slow thinker.
It is a philosophically confusing thing, and how you organize society. Yes, we're going to improve
education, but education to do what? Well, you've got to wonder what happens to the general population.
People, their life is going to be taken over by automation, and how susceptible those people are
going to be. They're not going to have any agency. They're going to be relying on a check,
and this idea of going out and doing something. You're going to have a giant swath of the population
that has no purpose.
If you can build safe AGI, if you can build superintelligence, basically all the limitations
that cause harm today can be completely eliminated. It's a wonderful possibility,
and this is not sci-fi. This is something which is clearly possible according to laws of physics,
but unfortunately, that'll only happen if we steer in that direction. That's absolutely not the
default outcome. That's why income inequality keeps going up. That's why the life expectancy in the US
has been going down now. I think it's four years in a row. At the present moment, 2024, we still have
control of the direction that AI is developing, but I don't know for how many more years.
And we can still choose the future that we want, but we have to actually see the risk clearly,
so we know the kinds of choices that we need to make to get to that future.
Well, I think if we never lift our eyes from the ground and gaze towards the horizon, we have no way
of telling whether we are on the right track or not. Like, we might be making a lot of progress,
but unless we consider where we are ultimately headed, like we might be making progress in the
wrong direction. I'm very worried about the existential risk of AI, but I made this film
specifically because I feel we urgently need to also address the economic and social implications of AI.
In the current trajectory we're on with AI and robotics, it's quite obvious to me that if we survive
artificial superintelligence, which is not trivial at all, we're heading towards a default outcome,
which entails a loss of human value, extreme inequality and mass poverty for most human beings,
we need to decide now if that's the future we want, and if not, what we're going to do about it.
I want a world where we have agency over our lives, where we can be secure while having
opportunities to improve our situation and realize our potential as individuals.
A world where Les Brown's message about our endless possibilities still rings true.
And it's possible that I can bring my greatness out here in the universe,
that I can do what I want to do. It's possible I can write my own book. I can have my own business. I,
I can take the trip and travel around the world. It's possible. I can bounce back from adversity and
reinvent my life. It's possible. Regardless of where I am, the things can get better for me. It's possible.
