What is the probability that any organism has ever been shaped
to see any aspect of objective reality truly as it is?
What if our entire understanding of reality is just an illusion shaped by evolution?
Could the universe be a sophisticated virtual reality created by our own minds
or evolution itself for our own good? And does free will even exist?
The math is just the math. It doesn't tell you how you have to interpret it.
But it's sort of tempting to interpret it as a notion of free will.
After talking just this year alone to Sam Harris, Robert Sapolsky, and Daniel Dennett,
three prominent philosophers on the subject of free will, two of whom would deny the existence
of free will, I'm thrilled to converse with Donald Hoffman, who offers a completely different,
highly mathematical and grounded perspective.
I'm delighted that different people are taking different points of view.
Hoffman is a renowned philosopher and a colleague of mine in the University of California.
He's the author of the provocative breakout bestseller, The Case Against Reality.
This is his third time on the show because we simply never run out of topics.
And it's always refreshing to hear his brilliant thoughts on these issues and more.
So buckle up. This is going to be the deepest dive
into the fabric of reality that you've ever been on. Let's go.
Both Sam Harris and Robert Sapolsky have recently been guests on the Into the Impossible podcast,
and their perspective on consciousness is quite different from yours.
How do you view their perspectives in contrast to your own, Don?
One of the things that they focus on is that they don't think that there's free will. At least Sam
doesn't think that there's free will. And the theory of conscious agents that I'm working on does seem
to have what we call a decision kernel in it. So a Markovian kernel that sort of models the decisions that
a conscious agent takes. Of course, the math is just the math. It doesn't tell you how you have to
interpret it. But it's sort of tempting to interpret it as a notion of free will, but a very interesting
notion of free will because agents aren't in a vacuum. They're in a milieu of other agents. It's a
social network of interacting conscious agents. And as we'll discuss, they can combine. So agents can
interact and if they are compatible, they can combine. And in that process, what you see is that
there's this, it's not just a social network of agents, but the agents themselves are combining and
or dividing. And so the decision kernel of each agent is not the only decision kernel that's going
on. There's lots of these decision kernels interacting. But the fact that you can combine
means that in some sense, my decisions are part and parcel of perhaps a bigger agent of which I'm a
part. And so if there is a notion of free will and the notion of conscious agents, I would say that
it's a notion that's unusual. That in some sense, my free choices are entirely aligned with the higher
agents of which I'm a part. And yet my actual, if you look at the details of my choices, they're unique
to me. So I have my own unique, you know, Markovian kernel for my own choices, but is compatible with
all the other choices. So that's one interesting direction. So our work on consciousness provides
an interesting framework for thinking about free will in a perhaps more less philosophical, more
mathematical kind of way. But then there's another aspect where we may differ on consciousness.
Although, you know, people's views evolve, I take consciousness as fundamental. Most neuroscientists,
and I think Sam, at least in some of the things I've heard of him, heard him say, wants to
talk about the neural underpinnings of consciousness. Now, you know, maybe that's no longer the case.
I won't pin that on Sam. I won't say that that's what he's saying. But suppose if he is,
then, and that's sort of the standard view, is that in some sense, there is a physical substrate
to consciousness. So consciousness, in that sense, isn't fundamental. It's the neurons,
the neural circuits, for example, that are fundamental in their activity. Or if it's an AI,
maybe the circuits of an AI, or the software in an AI that's fundamental, and it's the substrate that
gives rise to consciousness. So my attitude is that, of course, that's a natural thing to look at.
It fits in with the normal framework of science of, you know, of productionism and so forth. But
it hasn't worked out yet. There's not a single specific conscious experience that we've been
able to reduce to a neural substrate, for example, or any of the current physicalist theories. So
we're batting zero on that. So those are two areas where I won't claim that we're fundamentally
disagreeing, but where one could imagine there's disagreement.
And when I think about those two individuals, they both, you're right, kind of deny the essence
of the question of whether or not we have free will. In one case, it seems to be strictly determined,
in Sam Harris's case, I should say, and Sapolsky's case, you know, where I kind of diverge from him,
or at least I give him intellectual honesty points, because he says, I act as if I have free will.
And I believe in my heart, and to my shame, he said to me, that people should be punished for their
action. I find that very odd, you know, if I go up to Stanford and, you know, occupy his office,
and, you know, and so forth. And then, or worse, I steal his manuscript in LaTeX form from his,
from his desktop, not his virtual mental and evolutionary desktop that you have pioneered,
but the real desktop on his computer. I assume he'd be pursuing me in a court of law if I steal his
next book, you know, really determined or, you know, super determined, as he probably is one.
So how do you come down on people that, that say that they don't really put their money where their
amounts are, you know, and I'm glad that they don't, because nobody acts as if they have no
free will. I mean, even people that believe, like Sam Harris acts as if he has free will,
even though he believes everything is effectively determined. How do you, what do you make of such
people? I mean, are they, you know, do you respect their honesty, but you kind of deny their
legitimacy? Where do you come down on the case of, you know, for example, crime and punishment,
you know, cause and effect? How would you adjudicate such issues?
These are difficult issues, and they have a long philosophical history. And,
and I'm, I'm delighted that different people are taking different points of view, and we're having
a debate. So when I read Sam's stuff, for example, it's challenging, and it forces me to think out of
the box and so forth. And when you see the, the neural evidence that we can predict from neural
activity in certain parts of the motor cortex, what you're going to do, you, you know, several
seconds before you know what you're going to do, there's a prima facie case that can be made,
that the neural activity is, in fact, the cause of your behavior and not your, what you thought was
your free choice. It's an obvious prima facie case that can be made. Now, I think that it doesn't
go beyond prima facie. I think it didn't, you know, when you push on it, I think it dissolves. But I
certainly would not in any way charge them with intellectual dishonesty or anything like that.
Absolutely not. I think I'm delighted to have intellects of that stature taking points of view
that I disagree with, so that it gives me something challenging to have to push back on and so forth.
So I think it's, it's all good. And, you know, reductionism has been a very powerful framework for
a long, long time. I think it's no longer going to work going forward. But it, you know, there's good
reason to try it given the long history of, of, of some major successes. So you gave a wonderful talk
in the science of consciousness, which is put on by our mutual friend and many time guests,
Stuart Hameroff and others at the University of Arizona. It's been going on 30 plus years,
I believe. I spoke at it about 10 years ago, was never invited back. Um, no, I, I, but I've had on all
the, all the wonderful luminaries like your, uh, fellow colleagues, but you gave, uh, just a
spectacular talk and you've been gracious enough to agree that you'll present, uh, we'll present
your slides here and we'll walk through it and maybe I'll ask some questions as a interested lay
person. You know, I'm always frustrated when I talk to, not, not to you, but to others, you know,
just seems to be so little progress that the, the progress in string theory seems to be like
meteoric, you know, compared to consciousness. And that's saying a lot, as you know, my feelings
about string theory, but, um, let's walk through your slides and then we'll show them on the screen
as you go through it. And, uh, I'll try not to interrupt, but, uh, but it's, uh, such a fascinating
talk. I couldn't let the opportunity to share this with my audience pass me by.
Scientific advances are often frightening as well as exciting. An example of this is Elon Musk's new
Neuralink, a brain computer interface designed to assist paralyzed patients
in controlling technology with their thoughts. While this technology holds immense promise
for restoring movement and communication, ethical concerns linger around safety, privacy,
and the potential long-term effects. Despite the controversy, Neuralink is planning upcoming trials
in more and more patients aiming for high single digits by the end of the year. If successful,
this could mark a significant step towards revolutionizing human computer interaction.
I love staying up to date on news, especially related to science, technology, and artificial
intelligence. And with the rapid speed of today's news cycle, it's crucial to stay informed and trust
where you're getting your information. I'm excited I found this story about Neuralink on Ground News.
Ground News is a website and app that I use every day. It gathers articles from around 50,000 news
sources all over the world in an unbiased way that can help you read between the lines of the standard
mainstream media bias. It helps you break free of algorithms and echo chambers and filter bubbles.
You can check them out at ground.news slash drbryan. Let me show you why I love Ground News.
Right away in the Neuralink story, you can see that 47 news outlets have reported on the story.
Of these 47 outlets, 35% of them lean to the left politically, 35% come from the center, and only 31% lean
right. You can see the reliability of the outlets covering the story. This is unique. It also shows
who owns the outlets reporting on the story. The majority, 32%, are from independent news outlets.
Ground News also makes it easy to compare headlines to see how bias might influence the framing and
shape our understanding of the issues. I found it hugely fascinating that the left tends to focus on
the detailed technical issues and improvements, highlighting the long-term goals, while the center
emphasizes Musk's intentions to give people superpowers. Surprisingly, the right-leaning media
coverage underscores assurances made that the implant doesn't harm the brain and focuses more
on the technology's potential benefits. You can't get this type of news analysis anywhere else. The news
isn't going to report on itself, but Ground News does. With Ground News, you get a deeper understanding
of the complexity and nuance of different issues by seeing it from all different sides and identifying
media narratives. To get this, go to ground.news.drbryant to stay fully informed on breaking news
and see-through media bias. You'll become a smarter news consumer and subscribe to my link for 40% off
unlimited access with their Vantage plan, the same plan I use, by subscribing. They're directly
supporting an independent platform for news and supporting the show as well.
So the title of my talk is Positive Geometries of Consciousness.
I first start off and talk about the fact that we have lots of conscious experiences. We can experience
estimates are thousands of flavors or millions of colors. And I was surprised to find out that
the field of smell now thinks that we could be experiencing trillions of smells.
And then we have all sorts of experiences of sounds and bodily feelings.
And so, all in all, we have trillions of specific conscious experiences that we enjoy or don't
enjoy as human beings. And so, you would think that, you know, there's been a lot of work now
in cognitive neuroscience and AI and so forth, trying to get theories of consciousness, you know,
to try to understand and explain these specific conscious experiences. And most of these theories
assume, of course, that space and time are fundamental. And particles, elementary particles
and space and time are sort of the fundamental building blocks. And when you get, you know,
a large enough group of these particles interacting the right way, you get macroscopic objects like neurons
and brains, and neurons and brains with the right properties give rise to consciousness or to the
illusion of consciousness. Some physicalists think that consciousness isn't real, it's just an illusion
that's made, say, by our nervous system. And then there are panpsychists of various stripes, but the ones
I'm interested in are panpsychists who also take space-time as fundamental and certain physical objects
in space-time, like elementary particles as fundamental objects, but that in addition to
their physical properties, they have some kind of property of consciousness, some unit of consciousness,
say an electron has physical properties, but also has some kind of qualia experiences associated with it.
So there are a number of theories, there are, you know, higher order theories, there are
integrated information theory, neuronal monotubule, quantum states collapse, orchestrated collapse,
global workspace theory, there's a number of theories. And recently, you know, there's been
some adversarial collaborations that have been funded, where a couple of these theories can go head
to head and make predictions, say, about the neural correlates of consciousness that they have,
and so forth. So it looks like you might think, well, okay, well, it's a good field, we have lots
of theories out there and a good background. So, you know, where are we? And, you know,
there's trillions of experiences out there that, you know, for these theories to explain. So it must be,
you know, you think it would be like, you know, shooting fish in a burrow, you know, with, you know,
just pick, there's trillions, so pick one, and you use your physical theory to explain it.
Well, and so how are we doing? How are, you know, how are, how many experiences have these
theories explained? And the remarkable fact is, is that they're zero. There's, there's no
physicalist theory right now that can explain, for example, the taste of mint, you know, what,
what orchestrated collapse of quantum states of neuronal microtruples must be the taste of mint
and couldn't be the smell of garlic or something like that.
And so we're, we're batting zero. And it's quite remarkable. When you look at all these theories,
and then some of the theories will tell you exactly what you need to do. For example,
an integrated information theory, to have a substrate for, for a conscious experience, you,
you need, you need to have the right causal structure of the substrate. And that causal structure
can be specified by a Markovian kernel. So the natural question is, okay, great. So give me a
Markovian kernel for the taste of mint. You know, how big a Markovian kernel does it have to be? You
know, what does it have, you know, a thousand rows and a thousand columns and therefore like a million
entries? And if so, why that number of rows and columns and what are the specific numbers in the
entries that it must be, that it must have, or the class of entries that it must have to be the taste of
mint and could, and couldn't be the taste of chocolate. And there's nothing, nothing's been
done. So they, some of these theories tell you what they would have to do to have a theory. But,
but in fact, when it comes right down to it, where's the beef? Where's, where, where is your matrix?
Or where's your precise orchestrated collapse of quantum states and microtubules that must be the
taste of vanilla? Or what's the global workspace architecture and contents of the, of the shared memory
that, you know, must be that, you know, the, the taste of chocolate. So, and, and part of the problem
is that as soon as you say, okay, well, here's the matrix that must be, you know, this is the causal
matrix that must be the taste of mint. The obvious question is, give me a break. Why in the world must
this thousand by thousand matrix and those particular entries be the taste of mint, please, you know,
give me an explanation. And you can, you can say, well, you can see where there's going to be some
problems here doing that, or what orchestrated collapse of quantum states. And this is not,
by the way, a new problem. Leibniz saw this way back 300 years ago in his monodology. He, he,
he actually gave a physicalist theory short shrift. He gave them one paragraph. He said, yeah,
obviously can't be done. You can't boot up consciousness from unconscious mechanical,
physical ingredients. He, he spent a paragraph on it and figured, you know, you know, intelligent
readers can move on. They could have cited him, you know, he'd have a good H index. It'd be good
for his career runner. These are some of the conscious experiences that you might want them
to try to explain the taste of chocolate, smell of a rose and so forth, or, or, you know,
the experience of space, you know, um, if you have a theory of space, you know, the, the experience of
space, uh, why was my, must this, for example, pattern of integrated information be the experience
of visual space? And why could it not be the experience of haptic space or auditory space?
Um, and, and similarly for, for, for time. So, so again, no, no answers to this kind of thing.
For example, an integrated information theory and experience quality is identical to maximally
irreducible intrinsic cause effect structure of a mechanism in a state. And, and the cause effect
structure can be, you know, written as a transition probability matrix. And so the,
the question then is, so what, what, what is the probability matrix that, that must be,
uh, you know, the taste of mint and why, why those specific, uh, entries in, in the Markovian kernel.
Hey there, students of the impossible. I'm sure you're enjoying this conversation with my good
friend, Don Hoffman. And I want to make sure that you help me help you get even more great guests on
the Into the Impossible podcast. It's been a wild ride this year alone. I've had Sam Harris,
Dan Dennett, Robert Sapolsky, and soon you'll hear from Richard Dawkins, two special episodes,
but I want you to help me help you, which is to make sure you're subscribed and following the
podcast on audio and video formats. It really helps out. And if you don't mind extra credit
homework assignments from a professor, please make sure you leave a comment or leave a review of the
podcast on Spotify or on the Apple podcast app. You're able to do that. It will really help me out
so much. So now back to the episode with Don. What do these matrices operate on? What's the
vector analog here? I think they're not so much viewing them as, as operators here, as, as representing
a, a, a causal structure. It could be viewed as maybe a flow of information through a particular,
you know, circuit or something like that. So yeah. So why should, you know, if you have a theory that you,
you're claiming as a theory of the experience of space, what is the matrix for visual versus
auditory versus haptic? And why must it be that matrix and so forth? So, and again, this is just
asking them to do what their own theories say that they need to do for, right? So orchestrated collapse
of neural microtubules, it would be okay. So what does give me the precise pattern of orchestrated
collapse of neural microtubules that must be the taste of mint? And why, why must it be that?
And so, so we're batting zero on that. This is a little striking because if I came to you and said,
I'm, I've got a theory of particle interactions and you said, oh, wonderful. So, you know, what,
what particular particle interactions can you, can you model in your, in your theory? I say, well,
you know, you might say, well, can you do like electron photon interactions like this one or
a fork and glue on interactions? And if I said to you, well, oh, I can't do any specific
particle interactions. I can't actually, you know, predict any specific ones. I just have
a general theory of particle interactions. You might wonder what in the world I'm talking about.
What does it mean to have a theory of particle interactions that doesn't explain any particle
interactions? And so the same thing is here. What does it mean to have a theory of conscious
experiences or of consciousness where that doesn't account for any specific conscious experiences?
It's important to understand that, you know, what a scientific theory is. Every scientific
theory makes certain assumptions and it says, if you grant me these assumptions,
then I can explain some other wonderful stuff. As a result, because every theory has assumptions,
there is no theory of everything. The theory has a scope and it has some limits. Newton's theory,
Newtonian physics has incredible scope. A lot of mathematics in the theory to explore the
power of that scope. But it has a hard limit. When we came to look at chemistry, we realized that
basically Newton can't do chemistry. No way that Newtonian physics is going to do. We need to do
quantum theory. So every scientific theory has its own scope and limits. We sometimes talk about the
hard problem of consciousness. But, you know, there are also certain theories that are just going to be
the wrong problem for them. So chemistry is the wrong problem for Newton. It's the right problem,
perhaps, for quantum mechanics. Every good theory gives you mathematical tools to explore its scope.
Great theory gives you the mathematical tools to actually find their limits. And that's an important
aspect of science. We have certain concepts like Einstein, for example, had a concept of space-time
being fundamental and the speed of light being universal for all the observers, at least inertial
observers. So he turned his concepts into a mathematically precise framework, special and general
relativity. And then later on, that combined with quantum theory and quantum field theory led to
the discovery that space-time is not fundamental. The space-time falls apart at the Planck scale.
So every theory has its own scope and limits. And a great theory, actually, you can use the mathematics
of the theory to show the fundamental limits of the basic concepts of that theory. For example,
in Einstein's case, space-time itself, which is what he's modeling, turns out to have a limited
range of applicability. It has no operational meaning beyond 10 to the minus 33 centimeters.
So I want to propose, in part because space-time is not fundamental, that physicalism cannot do
consciousness. So it's not just that consciousness is a hard problem for physicalist approaches,
neural reductionist approaches, or AI reductionist approaches, or whatever it might be, or integrated
information, identifying it with certain causal structures in a physical substrate. That class
of theories assumes that space-time is fundamental and assumes the whole reductionist paradigm. And
I'm saying that that whole paradigm is just the wrong paradigm. And consciousness is the wrong
problem, not a hard problem, but an impossible problem for any physicalist reductionist approach.
So that's sort of one of the main points that I want to make here.
So, and it's not, of course, it's one thing for cognitive scientists to say, but it's the high
energy theoretical physicists who are saying this. So, Neymar, Connie, Hamed, and others. So,
Nathan Seiberg, for example, says, I'm almost certain that space and time are illusions. These
are primitive notions that will be replaced by something more sophisticated. Andrew Strominger at
Harvard says, the notion of space-time is something, clearly something we're going to have to give up.
David Gross, who won the Nobel Prize for his work on the strong force, says,
I believe that space for sure, and presumably time as well, will be emergent. And then I think Neymar
says, the very notion of space-time is not a fundamental one. Space-time is doomed. There's
no such thing as space-time fundamentally in the laws of physics. David Gross then explains why.
He explains that there's no operational meaning to distances smaller than the Planck scale. You know,
if you're trying to measure smaller and smaller objects, you need to have more and more powerful
microscope. And for that, effectively, you're using light or some kind of radiation with smaller and
smaller wavelengths, so you can resolve the details of the object that you're trying to look at.
Quantum theory allows that. I mean, you can make as small a wavelength as you wish. It requires more
energy. You know, the E equals H nu. So, as the frequency goes up, the wavelength is smaller than the
energy is going up. But when you combine that with Einstein's theory of space-time, and especially the fact that,
you know, energy and matter are the same thing, and matter energy curves space-time, you get a
problem at 10 to the minus 33 centimeters that with the wavelengths at 10 to the minus 33 centimeters,
you have so much energy in such a small region of space that you actually create a black hole,
and you destroy the very thing that you're looking at. And so, what this means is that space-time is a
fairly shallow data structure. It falls apart at 10 to the minus 33 centimeters, not 10 to the minus 33
trillion centimeters, just 10 to the minus 33 centimeters. That sounds impressive to us now,
because we don't have the technologies to probe it. But once we get the technologies to probe it,
10 to the minus 33 centimeters, then, you know, it's going to be a hard limit to what we can do inside
space-time. So, space-time is doomed. We thought it was fundamental, but it's not. I also talk about,
you know, evolution by natural selection. And it also agrees with the physicists, the high energy
theoretical physicists, that space-time is doomed. You can use Darwin's theory in mathematical form,
in evolutionary game theory, to ask a technical question, which is, you know, what is the
probability that any organism has ever been shaped to see any aspect of objective reality
truly as it is? So, you can ask that as a technical question. Do we see the truth? What's the
probability that our senses show us the truth about objective reality, right? We see what appears to us,
in our senses, are there space and time and physical objects inside space and time. So,
the question I'm asking, does evolution entail that those are going to be true,
true perceptions of the objective nature of reality, or not? And it turns out,
so we can ask the question, does natural selection favor veridical perceptions?
And the answer on the next slide is, no. Vertical perceptions go extinct. In fact,
the probability is zero that any sensory system of any organism has ever been shaped by
natural selection to see any structural aspect of objective reality correctly.
So, what we find is the two main pillars of modern science, which is high energy theoretical physics,
you know, quantum field theory, for example, and also evolution of natural selection, both agreeing
that space-time isn't fundamental, and objects in space-time aren't fundamental, and therefore the
whole physicalist reductionist paradigm will be called into question. So, what is it that we are seeing
from an evolutionary point of view? We get a hint that evolution shapes our sensory systems to guide
adaptive behavior. That's right. We are shaped by evolution to have sensory systems that guide
adaptive behavior, period. We thought that seeing the truth was going to help you have more adaptive
behavior, and that's just a wrong intuition. When you actually look at evolution, what's really going on
is in some sense evolution isn't showing you a window on reality. Evolution gives you a user interface,
like the desktop interface, or gives you a VR headset, if you will, to play the game of life.
If you're playing a virtual reality game like Grand Theft Auto, what you're really doing in this
analogy is you're toggling millions of voltages in a precise sequence in some computer, some powerful
computer somewhere. But if you had to do that to try to win the game, good luck. It would be very,
very difficult to toggle those voltages and win the game. Someone who has a little virtual reality
headset and they see a steering wheel and a dashboard and gas pedal and so forth is going to beat you.
They don't need to see the truth. They need to control the truth, but they don't need to know
what the truth is even. You don't have to know about diodes and resistors and voltages to win the game
if you are given the right interface. And so, that's sort of the idea of what
Darwin's theory tells us is that evolution shaped us with a headset that lets us play the game of
life and it hides the truth. So, that means that reductionism is doomed. If space-time is doomed,
then the idea of reductionism, which I think is on the next slide, that fundamentally the laws of
physics are given by some laws at the ultra-most microscopic scale. And we just have to go to the
smaller scale to see what's ultimately going on. And physicists are telling us that that reductionist
paradigm is wrong. As we go to smaller and smaller scales, at some point, you just stop. You can't go
any smaller, 10 to the minus 33. And actually, if you try to go smaller, you start actually going the
other direction. You actually get black holes that get bigger and bigger and bigger. So, you get more
macroscopic. So, the reductionist paradigm is a problem and it's been the foundation for a lot of
science. We used to think that the foundation was like earth, air, fire, and water, the four basic
elements. And then we went to the periodic table of elements. We thought that was fundamental. And now,
we have the standard model of physics with the bosons, leptons, and quarks. And that's our current
fundamental reductionist approach. But we know that space-time is doomed, so that even the bosons,
leptons, and quarks aren't going to be the final answer in terms of what's the nature of the basic
elements of objective reality. So, the idea that has guided a lot of consciousness research is,
again, a reductionist one, which is that, you know, we start with fundamental particles like the bosons,
leptons, and quarks. And when they have the right combinations, we get more larger objects,
like these pyramidal neurons. And if you go in larger, you get objects like the brain. And then
the brain with the right properties, right, the right causal or other kinds of properties,
somehow gives rise to conscious experiences. That's the theory in global workspace, and illusionism,
and panpsychism, and so forth. But there's a problem with all this. And Steven Pinker points
it out quite nicely in his 2018 book, Enlightenment Now, what I'll call the stipulation problem of
consciousness. And what Pinker says is, but the last dollop in the theory, and he was talking about
the global workspace theory, which is the theory that Pinker seems to like in that book. But the
last dollop in the global workspace theory, that it subjectively feels like something to be such
circuitry, the global workspace circuitry, may have to be stipulated as a fact about reality where
explanation stops. What Steve is saying is that, you know, we have the global workspace theory and all
of its architecture, and is trying to explain conscious experiences when you get right down to it,
like, you know, tasting the smell of a rose or the taste of chocolate, it doesn't give it to you.
You have, you're assuming the global workspace architecture, and then you're having to also
stipulate the conscious experience of the rose or the chocolate of the cake. So you're stipulating
the physical system, you're also stipulating the experience. There's no explanation here,
it's all stipulation. It's tautological, yeah. Yeah, and it's not very satisfying science when
the thing you're trying to explain has to be stipulated. At the very last step, you know,
you say, you know, you have to stipulate. So that's a big problem. These reductionist approaches
are failing, and I think it's for principled reasons, because reductionism is doomed.
And that's what the high-energy theoretical physicists are telling us. Space-time is doomed,
therefore reductionism is doomed. And therefore, our field, the field of consciousness studies, needs to
get a cue from the experts on space-time, namely the high-energy theoretical physicists,
that it's over for space-time and reductionism. And we can't, if we want to start there with our
theory of consciousness, you know, we're starting with the wrong foundation. And not only is it space-time
not the right foundation, but also quantum mechanics. So again, these theorists are pointing out
that quantum theory is not fundamental either. As Nima puts it, so there's some other structure that
we're looking for, and some way of thinking about interpreting the structure beyond space-time,
that will let us see space-time and quantum mechanics emerge simultaneously and joined at the
hip. One reason why they're saying that, you know, space-time is doomed and quantum theory is doomed,
is that they've, you know, when they're trying to understand the probabilities or the amplitudes for
particles interacting, like two gluons smashing into each other and six gluons spraying out,
when you do the computation inside space-time, it's a mess. It's hundreds of pages of algebra for a single
event, hundreds of thousands, millions of terms. But they've discovered recently these new structures
outside of space-time, yeah, like the amplituhedron and cosmological polytopes and the sociahedron.
So they found these new structures, this is all fairly new, last 10 or 11 years, that allow them
to compute scattering amplitudes much more cleanly, much, much more simply. Millions of terms can turn
into four or five terms that you can compute by hand. And you see new symmetries,
something called the infinite Yang-Yin symmetry, for example, in certain interactions that you can't
see inside space-time. What we're finding, and then they're finding these structures called
decorated permutations that help classify, allow them to classify these new geometric structures.
And so there's this whole new field called the field of positive geometries that's coming out now.
We used to think space-time is fundamental, but it's not. Beyond space-time, there are positive
geometries like the amplituhedron, and then beyond them are these combinatorial objects,
like decorated permutations, which allow us to classify these objects. So this is a brand new
frontier. We've stepped outside of space-time for the first time as a species in the last 10,
10 or 11 years. We're outside of space-time and we're finding stuff.
Hey there, it's me again with a great offer for you, which is free and you can cancel at any time,
but I hope you won't. It's to join my Monday Magic mailing list. And for one lucky listener each month,
I select you to win a real fragment of a 4.3 billion year old segment of our solar system,
a meteorite, which fell to Earth in Argentina some few thousand years ago. I'll send you information
about meteorites and all sorts of cool things and how you can observe and maybe find some yourself.
But I'll also send you every week the latest and greatest information from around the world of STEM,
science, technology, engineering, and math, and many, many other thoughts that I develop and go
through. And every week, people really seem to enjoy it. Recommendations, tips, tricks,
hacks, and all sorts of cool things from around the world of academia and beyond.
So if you have a .edu email address, the offer is even sweeter. You're guaranteed to win one of
these beauties if you live in the United States. For those of you with a .edu email address,
go to briankeating.com slash edu and send your details there. Now back to the episode with Don.
Yeah. And this is right up our alley as physicists, but it might not be abundantly clear to the audience,
you know, how does it come back to the brain? I mean, is it, is it that there's a, it's a no-go
theorem because we, you know, we currently don't understand and we need physics beyond the standard
model to understand physical reality and the ultimate building blocks are, you know, particles,
but we, we, we don't actually know if there are strings that go even below that or matrices or loop
quantum gravity is correct. Is that the relevance of the, I mean, it's fascinating to me as a physicist,
but what is the relevance to the brain and the mind and consciousness? Well, well, the relevance
is if we're trying to find a fundamental framework from which to boot up consciousness, the question
is, is space-time itself a deep enough structure for us to try to boot up consciousness from it? And my
take on what's, what's happening in high energy theoretical physics is they're saying, no, space-time
and quantum theory themselves are merely projections of much deeper structures and much more interesting
structures. Space-time has four dimensions, maybe 11 or 12, depending on what, what other theory you
might have. The, the, the, the amplituhedron could have billions of dimensions. These are, these are
different. So these are not little things curled up inside space-time. These are brand new structures.
And so we're, we're very much taken off the headset. We're looking outside of space-time and what we're
finding are obelisks. We're finding these, these geometric objects outside of, of space-time. And
I think about it as like the scene in 2001, A Space Odyssey, where the, there's the, the obelisk and all
the, the apes are, you know, hooting and hollering, pounding, and they, they know it's really important
and it's very significant, but they don't know what it means. And I think that's where we are,
because we, we've only been outside of space-time for the last 10 or 11 years. We're finding these
positive geometries, but the question is who ordered that and why, and what does this mean?
And in space-time is, is, is clearly not fundamental. What is fundamental? So we're at this big, you know,
this big new Vista has opened up in science that says reductionism inside space-time is not where it's
at. And there's something new that's really important. It's positive geometries, but we don't
know what it means yet. For example, we have no dynamics. Well, what is that a dynamics outside of
space-time that gives rise to these positive geometries and these decorated permutations
that they found? This is all brand new, but what it says to me is, to my field of consciousness studies,
if, if we're trying to build our theory of consciousness on space-time physics, that's an
old horse now. We don't want to hop on that old horse. We, we need to get, get on something that's
more fundamental. And, and by the way, there's a, just in February, there was a, um, a big workshop in
Germany, bringing together a hundred PhDs in physics and in, in, in high energy theoretical
physics, um, in what's called the universe plus project that's been funded by the European
research council, the ERC. That's a 10 million euro grant international study, uh, effort to, to, uh,
understand these positive geometries and the deck, you know, the combinatorial objects like the
decorated permutations. So this is where, you know, the high energy theoretical physics is headed right now.
And consciousness studies will ignore this to their own peril. We'll, we'll effectively be in,
in the same place as someone trying to do chemistry and, and, and believing that Newton is the way to
do it. So I'm going to stick with Newton. I don't care what this newfangled quantum stuff is. I'm
sticking with Newton for my theory of chemistry. Well, good luck. And that's where we are right now
in our consciousness studies. We're going to, we're going to stick with space-time, even though that
horse is not the horse that the, the, the, the physicists themselves are riding in, you know,
at the very high energy level. So what I want to propose then with, again, with a number of
collaborators, including, you know, Chaitan Prakash, Robert Prentner, um, um, Manish Singh, and, and a
number of other Schwabon, Chattopatye and others, um, a theory of what we call conscious agents, a network
of interacting conscious agents as the fundamental nature of reality. And this is going to be conscious
agents not emerging from space-time, but prior to space-time. And the idea will be that these
conscious agents are in fact, prior to the positive geometries that, that high energy physics is finding
outside of space-time. So, you know, we'll, I'll talk about that in a moment. So there's a whole laundry
list of things that a theory of consciousness must explain. I've got, you know, learning, memory,
problem solving, attention, memory, the self, intelligence, semantics. There's lots of things that you would like a
theory to do. But, you know, following Occam's razor, I want to keep my assumptions to a minimum.
So we're going to only pick a couple, but we're going to use, um, qualia. So conscious experiences
exist and actions, that there are probabilistic relationships among conscious experiences.
That's all we're going to have in our, in our theory. And then, um, we put this in a mathematical
formalism, which I'll only talk about briefly. We have these things called conscious agents and the
agent has, uh, a set of experiences based on the experiences. It then decides, um, what action is
going to take. And once it does that decision that it acts on, on the network, the big social network
of other conscious agents, which then, um, acts back on the conscious agent that we're, that we're sort
of focusing on here. So we get this loop of perception, decision, action loop. Um, and we
modeled this with Markovian kernels. So probability spaces for the, for the set of possible experiences
and so forth. And then Markovian kernels for the arrows. It turns out that that's the set of conscious
agents is computationally universal. So it's easy to prove that anything that you can do with a neural
network. You can, you can, you can also use a conscious agent network to build. So there is a
learning memory problem solving and so forth can be. And it's Markovian in that the current state,
you know, provides input for the future state, but no further kind of memory, uh, you know,
hysteresis or, uh, effects linger, or is there some other, um, implementation of Markovian processes?
We're going to implement it as, uh, as Markov literal Markov kernels in the, where those arrows
are. So we'll literally have Markovian kernels, but what you pointed out is, is correct. A Markovian
dynamics is one in which the current state is all the information that governs the transition to the
next state. So it's a finite memory. I would point out that you can make that state as complex as you
want. So it's what it really means is you can have an arbitrary, but finite amount of memory in, in
your decision. So it's very much like in Turing machines where we say you have a, you have a
tape. It's, it's, it's, it's a finite tape, but there's as much tape as you want. You, you, you'll
never run out of tape when you're doing your computation. And that's sort of the way it is
with the, with the Markovian kernel states. It's going to be finite, but as, as big a state as you
want, we can give you that and we can turn it into Markovian. So, so it's not much of a limitation,
actually. Then, then I went through some, you know, fairly technical stuff here. Um, there's a,
it turns out that we discovered, um, an order. So we, we can actually model individual
conscious agents with what we call a qualia kernel. We can take the perception, decision,
action kernels that I talked about in that loop and combine them together into a single kernel
that we call the qualia kernel. So now we have a much simpler thing and we can actually then
look at a single Markovian kernel, which describes if I'm a conscious agent, I have the experience of red.
Um, now what's the probability that I'll experience green next or blue next or, or whatever. So,
so it gives us what we call a quality kernel. What we've shown is that there's actually a logic
on the set of these Markovian kernels. So this is apparently a new contribution to the mathematics
of Markov chains. Um, and we'll be publishing that in, in the paper that we're writing right now.
We discovered that there's, um, what's called a partial order on the set of Markov, Markovian kernels.
And this gives a, a logic. You can take the, the and and the or, the meet and the join. Um,
and, and, and, and so complements in certain, certain cases and so forth. We give it a non-bullying
logic of Markovian kernels, which then turns into a non-bullying logic of conscious agents.
So we can actually talk about agents, uh, consciousness is combining or, or disassociating,
decombining. And we can talk about, um, also a notion of observation, you know, one conscious
agent, um, if it's sort of what's called a trace chain of a bigger, um, agent, then it observes the,
the bigger agent. Um, then there's a whole logic that we, that we have on that. So then our, our big
idea then is that we have this network, this social network, like the Twitterverse of conscious agents,
and it's beyond space-time. And it's actually beyond the, the geometries and permutations that
the physicists have found outside of space-time. But our proposal is that we can project the
dynamics of conscious agents onto the decorated permutations. And from there, um, the physicists
tell us how to, you know, project into the positive geometries and into space-time. So we've actually,
in a, in a paper last year, we actually got a projection onto decorated permutations from Markovian
kernels. And when we did that, we first just went, literally, we assumed that it had already been done.
Just how, how do you represent Markovian kernels and, you know, classify them with, with decorated
permutations? And it turned out it hadn't been done. So last year we, we did it and we, we actually
contributed, as far as I can tell, something new to the mathematics of Markov, Markov chains. We actually
showed how they can be classified by decorated permutations. So now what we're, what we're
doing is we're, um, we're looking at, at how to now project. We've got the projection of the dynamics
of conscious agents onto decorated permutations. Now we want to get all the way into space-time,
right? We want to make, you know, what does the mass, what, what are particles in space-time? How do,
what, what do they correspond to in the Markovian dynamics and so forth? What does mass, momentum,
spin, um, distance and so forth? Uh, and I, I can just say at top level in the paper we're writing
right now, we're, we're, we're going to publish, um, the, the idea that the mass of particles inside
space-time is a projection of the so-called entropy rate of communicating classes of these Markovian
kernels of conscious agents. So an entropy rate is, um, is an interesting thing. It's very important in
communication theory. Uh, if, if you're, if you have a source, a communication source that, um,
has an entropy rate that's greater than the channel capacity, then you're going to get distortion.
You won't get the message through clearly. And also entropy rate has, is related to a minimum
description for, for a signal, minimum description link. So the entropy rate is an intro, and if people
want, I can go into detail about the mathematical definition of entropy rate, but, but we make a
proposal that the entropy rate, um, it is what projects to, to mass. And that makes a real clean
prediction because if the entropy rate is zero, then we're going to be dealing with massless particles,
right? And therefore we have to make the prediction that this is going to be a spin one particle plus or
minus one. And we have to make the prediction that this thing is going at the speed of light,
there's a maximum speed and this thing is going. So in other words, we don't just get to say, oh,
entropy rate is mass. There are, there are consequences for saying that. And, and, and it
turns out that they work in the, in the Marconian dynamics. When you actually have an entropy rate
of zero, you get a kernel, looks like the P kernel down here on the, on the bottom right, where it's
all zeros and ones. Those are the, the entropy rates are zero. And those in fact have spin or
determinant plus or minus one. So they, if, if we say the spin is a projection of the determinant,
then we get that. And then they also have the fastest commuting times. So commuting time between
two states is the expected number of steps it takes you to get from that state to the, the second
state and then back again. So it's the round trip time. And it turns out that, that when you have the
zero entropy rate, then you are effectively, the commuting times are the fastest you can possibly have.
And so there is a maximum speed limit and it happens precisely when you're massless in this theory. And
when the determinant is, is plus or minus one. So, so internally consistent, it's, it's internally
consistent. You know, it doesn't mean we're right, but it means that the, the, the first, the first
little test is, is passing the first sniff test. Well, we'll see if it, if it goes all the way. So,
yeah. So what's nice is that, um, Einstein assumed that the, um, speed of light is, this is the maximum
speed and it's the same for all observers. But this theory, if this, if this pans out,
will actually explain why there's a maximum speed because there is a maximum commuting time. And it
happens to be for those, um, systems that have zero entropy, right? And, and therefore are massless and
have spin one things that are, are assumptions and Einstein's theory will be things that we can explain
from deeper assumptions in, in the theory of consciousness. So how do we test all this?
There's a number of ways to try to test it. Um, you mean, you might say, well, why don't you go
after neural correlates of consciousness? I mean, that's clearly the thing you want to test. And,
and eventually we do, but I'm more interested in, in, um, doing something simpler. Not, not that it's
simple, but, but, you know, I'm looking in this little example here. I want to look at the inside of a
proton. And the, the many physicists have spent decades studying particle collisions that, that
are, you know, inelastic collisions. They destroy the proton to let you look inside, you know, at the
quarks and gluons and so forth inside. And so this is just sort of a high level picture of, you know,
where quarks and gluons and protons fit in the whole scheme of matter. I have to point out that,
that nucleus in the atom is not, uh, charge neutral. There's something going on with that. It
only has two protons. It should be helium, but it's helium five or something.
Oh, okay. Oh, interesting. So when you look inside of a proton, um, what at the top level,
what the, what decades of experiments have shown is that at the, at the lowest resolution,
what they call Bjork and X and Q squared, um, inside of a proton, you find it's dominated by, um,
three valence quarks, two up quarks and a down quark. As you increase the resolution in space and time,
you get what they call a quark C. You start to get quark, anti-quark pairs appearing,
and, and you also get a bunch of gluons. Then when you get to the highest resolution,
um, highest Bjork and X and Q squared, then you get just a vast gluon C. So what you, what you see
inside the proton depends on essentially the scale, the, the, the temporal and spatial scales at which
you're, you're looking. And so we want to show that we can model all of this. We can get all of these
momentum distributions at the different scales of, of resolution in space and time and actually
get this, the exact momentum distribution. So that's going to be one of the acid tests we want
to give, give our theory. And in fact, there's a team, um, of researchers from Caltech and elsewhere
that, that are just working with us on this right now. They're, they're going to be trying to build
these simulations. So these are some of the momentum distributions that we'll try to, to match.
And for those who are interested, um, in some of the, the published details on, on this,
we have a paper called fusions of consciousness, which is free online. You can, you can read about
the, the mapping to, of, of Markov chains to decorated permutations and so forth.
That's excellent. No, that was, uh, really fun. So I've got a bunch of questions of my own,
and then, uh, I've got a lot of questions from my audience as well. Can I ask, you know, since we
talked in, uh, your, for about your first book, the case or the most recent book, the case against
reality, um, have there been updates to your, you know, sort of, uh, evolution in, in this realm
with, uh, respect to the, you know, interface theory of perception? Have, have there been
new developments since 2021 when we talked last on the podcast, uh, live about that book? Any,
any new developments either from you or criticisms or, or, or, you know, kind of joint, uh, research?
Yeah, there's been, um, some, some criticisms that, um, from, from philosophers that have
been quite sharp and, and, um, published. So they've, it's not just been verbal, but they've
actually published articles. And the, and the argument is, goes like this, that we, we use
evolutionary game theory to show that physical objects like organisms and, um, and resources in
space and time are not fundamental, that, that they're, they're just a user interface illusion.
Several philosophers have said, um, that is logically shooting yourself in the foot.
You're a cognitive scientist. You don't know philosophy. You don't know about logic
well enough to know that you've actually, you've committed some basic fundamental self-refutation
going on here. So, so the argument is this. You're using, Hoffman, you're using evolutionary
game theory, which is a mathematician, mathematization of Darwin's ideas. You're using
evolutionary game theory to prove that physical objects like organisms and resources are, are not
fundamental. They're, they're not part of the fundamental furniture of reality. They're just
user illusions, so to speak. Now, so their argument goes like, goes not good. Now, either
the mathematics of evolutionary game theory faithfully represents Darwin's ideas,
or it doesn't. If it doesn't, you couldn't use it for the purpose that you you've used for. And if,
if evolutionary game theory does faithfully represent Darwin's ideas, then it couldn't possibly
refute those ideas. It couldn't possibly end up saying those ideas cannot be fundamental. So either way,
you're in what the, they've actually in print said an unfortunate dialectical situation.
Okay. In other words, I shot myself in the foot. And, and, and so my, my reply is that argument
completely misunderstands the very foundations of how science works. First, there are two critical things
to know about science. First, every scientific theory makes assumptions. Very, very simple thing to note.
As a result, there is no theory of everything. Because you don't explain your assumptions,
you assume your assumptions. Your assumptions of your theory are miracles for, for that theory,
the flat out miracles, because you don't explain them. And if, of course, you can give me a deeper
theory that explains those assumptions, but your new theory will have its own miracles, its own
assumptions. And this goes on ad infinitum. So there is no theory. So that means that every scientific
theory has a scope, if it's a good theory, maybe there's a bad theory that we don't care about.
But if it's a good theory, it has a scope and it gives you the mathematical tools to explore
the power of its scope. But it will have a limit. And if it's a great theory, the theory will give you
the tools to discover the limits. And in case of Einstein's theory of space-time, he gave us essential
tools to discover the limits of his very central concepts of space and time, namely 10 to the minus
33 centimeters and 10 to the minus 43 seconds. It's over for space-time. So it's not that we
wouldn't want to say, oh, well, Einstein is, you know, Einstein's mathematics is review. Poor Einstein,
he got himself caught in a logical bind. He shot himself in the foot. He had these ideas about space
and time curving and so forth. But then, you know, he came up with this mathematics and the
mathematics came back and showed, well, that idea of space-time falls apart at 10 to the minus 30.
Oh, well, Einstein, you dork. You dummy. You bloot. Well, no, that's not our attitude. It's like,
no, it's a great theory because Einstein gave us the tools to find out not only the scope,
but the limits of these very fundamental concepts. These were professional philosophers,
publishing, in some cases, in professional philosophical journals. So the misunderstanding
of science is profound in that. So that's the fun, interesting thing that's happened in the last...
I've got a paper coming, a couple of papers in reply to these. Another question that a lot of my
audience has had, and I've had it too, is, you know, this trope that the map is not the territory,
you know, that you're explaining a modality to explain something, but now it's not clear where
these matrices end and, like, real reality would begin. What do you say in those cases? What do you
make of that as a criticism, that describing something as a Markov process is inherently,
which is inherently the byproduct of the human brain, someone called Markov, you know, originally,
but, you know, where does it end? Is it important to truly have, you know, some base layer where you
say, this is where we start from, and these are axioms, and then even if you could do that,
sorry to ask a double-barreled question, but if you could do that, you know, what would Gertl say?
You know, how can it be complete, given that? So the map is not the territory. How do you answer
that? And then maybe Gertl's objection? I couldn't agree more with the first
objection. And so when I say that there is no scientific theory of everything, that includes
Hoffman's theory. And that's the predicament of science, is that, well, it's, you know,
this predicament, if you wanted a theory of everything, then this is a bitter pill to swallow,
right? But there is no theory of everything. If you want job security, this is great. So for job
security for science, this is really great. And my own view about scientific theories is
that whatever reality is, a scientific theory is merely a description of a particular perspective.
At best, at best, it's a description of a particular perspective on reality. And my guess is that there's
an infinite number of perspectives that one could take, not just one or two, an infinite number of
different perspectives that one can take. And in some sense, the perspective that we're taking is
what we call space-time. That's our little headset. That's the little headset that we use to get our
little, you know, projection of whatever this reality is. And again, when I say that, of course,
I'm already using terms of my own theory. And so at this point now, I can always say is,
those terms are used as pointers. There is a reality, and we're just pointing to a description
of a projection of that reality. But it turns out most of our theories are not even good at that.
So most of the stuff that we come up with is not even good as a description of a projection of reality,
right? But every once in a while, we get something that is a good description of a projection of reality,
reality. And then we can build technology with it. So there is something useful to be done here.
I don't think we're getting closer to the truth. If you ask me, what is the truth? My own guess is,
you are the truth. But to know that truth, you have to let go of any concept of who you are.
You have to let go of all concepts and just be with yourself. Then you're knowing,
it's a non-conceptual knowing of who you are as the truth. So now that gets to the Gdel question,
right? So I take scientific theories as mathematically precise systems, right? And they
have at least the power of arithmetic, which is something that Gdel was looking at. So they will,
in general, have the power of arithmetic. And so, therefore, there will be statements
using Gdel's approach that are true, but cannot be proven within whatever axiom system
you've chosen for your scientific theory. So I think that that Gdel incompleteness thing
is another reason why I'm saying pretty emphatically, there is no scientific theory of everything.
And in fact, we don't even get close, right? In some sense, the reality, whatever it is,
infinitely transcends any scientific theory, including my own, infinitely transcends. But
it's not all, hope is not all loss, because I'm suggesting that what you are is that truth,
that reality, just looking at itself through a particular avatar. In this case, right, there's a,
you know, a Brian and a Don avatar, but it's the one, there's this one reality
looking at itself through different avatars, in a particularly simple headset,
and only a four-dimensional headset. So it's a fairly trivial, and I can imagine that there's
an infinity of other headsets, for example, with maybe billions of dimensions, trillions of dimensions,
who knows? And we're probably, you know, the more dumb one.
Hey, there's a good chance you might be a scientist or an engineer aspiring to be,
maybe going to school, graduate school, or after school, or maybe you're a professor like me.
If you're wanting to learn the greatest tips and ways to become your best scientist,
you might want to get my book, Into the Impossible, Think Like a Nobel Prize Winner,
with a forward by my friend, Nobel laureate, Barry Barish. In it, we describe an incredible series of tips
on how to collaborate better, unlock your creative genius, and get over common pitfalls,
like the imposter syndrome. I hope you'll take a deep dive into it, and I know you'll enjoy it.
You can read a free chapter at my website, briankeating.com slash books, and you can buy
it at amazon.com in ebook, audiobook, or in physical hard copy, or paperback form. Thanks a lot.
Okay, some questions from my audience. Abe Chung asks, Dr. Hoffman, I'd love to hear more
about the interface for reality in the context of linguistics, particularly text linguistics.
I am a translator by trade for 20 years, and studying this field constantly reminds me of
the lectures you have given. My studies are not enough to capture anything at the level that you
do, but I have a gut feeling you've seen more down there. Can you say something about linguistics
and applications of the interface for reality in that context? The language that we use
represents, in some sense, a worldview, in part. And the way we learn language, how do you actually
learn the words of a language when you're teaching a kid, for example, at 18 months of age or something
like that, and you have Johnny there, and there's a rabbit on a rug in your living room, and when the
time is right, you're there with Johnny, and you point your finger to the rabbit, and you say,
rabbit. And if Johnny's old enough and attentive, he gets it. Actually, that's what we call
ostensive definition. So, in this case, almost every term that we learn in a language is by ostensive
definition. And notice that there's an infinite ambiguity. If I point and say rabbit,
rabbit, what in the world am I referring to? It could be the color of the rabbit. It's white.
Or it's fur, the furry texture. Or it could be the left ear and the right front paw. Or it could be the
tail and the carpet. So, an object composed of the tail of the rabbit and the carpet that it's sitting on.
So, what does the word rabbit refer to? And yet, somehow, there's something called the level at which
you're doing it, the basic level. So, when you point, you're going to say rabbit, you're not going
to say, oh, biped or quadruped. You won't say, oh, Johnny, quadruped. It is a quadruped, but you know that
you'd be messing up your kid. If the first thing you said was not rabbit, but quadruped. Or even if
you tried to say the color first, you learn that you have to say the shape first, and then the color
and higher things. So, what's really interesting is, Johnny has to share this perceptual interface
with mom and dad. And whoever it is, right, you have to have the same evolutionary interface. So,
this whole interface, so now I'm tying in the interface theory of perception with this linguistic
thing. And for Johnny to even pick up what you're talking about, he has to have the same kinds of
entities in his interface. Otherwise, I mean, if you tried to do that with, you know, a rabbit,
if you take a rabbit and point and say rabbit, it's not going to get it. It's got a different
interface. So, yeah, there's a really big connection. And in some sense, everything that
you know, all the words that refer to objects and properties in a language, you only learn by
extensive definition. That means you assume a shared headset. So, there's, of course,
you can see a huge, the language depends hugely on an assumption of some shared properties of headsets.
And maybe the last question I have from a listener is, his name is Los Angdonio,
which I considered for one of my children's names. He says like this, suppose the argument
for only conscious agents existing depends on an evolutionary argument. In that case, it seems like
the biological entities and their systems involved in perception are somehow outside of or more
fundamental than perceptions of a conscious agent. Yet they, our brains, eyes, etc., must also be
merely products of evolution and predictive modeling and not real entities. Does this lead to
an internal contradiction in your theory of conscious agents? Well, if you approach it that way, you might
get it a contradiction, but I approach it in a different way. So, the way I approach it is the
following. We can write down a Markovian dynamics of conscious agents that is called stationary. And
that means that the entropy at each step is the same. So, there's no entropic error of time in this
dynamics. But it's a theorem, a very, very simple theorem to prove that if you take a projection of
that stationary dynamics, say, by conditional probability, you'll get a new dynamics, a Markovian
dynamics. That's a projection. But the projected dynamics will have increasing entropy. So, it will
have an entropic error of time. So, my take on this is, I think that the conscious agent dynamics
of consciousness is stationary. So, when we get an arrow of time in our headset, that's entirely an artifact
of the projection. So, time is not fundamental. The entropic error of time is not fundamental. Now, this now
ties into the evolution question. What is the most fundamental limited resource in evolution? It's
time. If I don't breathe in time, I die. If I don't eat in time, I die. If I don't mate in time,
I don't reproduce. Time is the most fundamental limited resource. So, what I'm saying is, I love
Darwin's theory. I've studied it. I think it's incredible. If you're going to talk inside of our
space-time headset about biological evolution, use Darwin. That's the right theory inside of our
headset. Having said all those nice things about Darwin, I'll now say, every aspect of that theory,
organisms competing for resources, limited time, nature read in tooth and claw, every aspect of
Darwin's theory is not an insight into a deeper reality. Every aspect is entirely an artifact of loss
of information in the projection into this headset. So, the theory of conscious agents need have no
limited resources, no competition, no nature read in tooth and claw, cooperation and love, possibly,
right? It could be all that. But in the projection, when you lose information, it will look like
there's an arrow of time, nature read in tooth and claw, predictive processing, Markov blankets,
the whole, all that whole thing of me versus the separation between entities will all appear there.
So, you can see how I'm reframing the entire question. I'm not trying to do, I don't take
evolution. What I did with evolution was I said, that's our current theory. I'm trying to find the
scope and limits of our current theories, right? So, I used evolution to show that organisms in space
and time can't be the fundamental reality, right? That's what, that's what, it's the inside game that
you play in science. You use your own theory to show its own limits. That's what we did. So, given
that, great. So, now I have to make a leap. I make a leap entirely beyond space-time. Evolution doesn't
tell me what leap to take. I'm just making a leap. I'm proposing, there are these positive geometries,
there's decorative permutations, and beyond them, a theory, you know, a network of conscious agents.
Now, of course, my, what I have to do is what I just sketched. If I start with the theory of conscious
agents outside of space-time, how do I get evolution inside space-time? Answer, as an artifact
of loss of information in the projection. Then it looks like nature read in truth and claw,
fighting for resources in limited time. But that's not true of the deeper picture. But,
but the deeper picture shows how this limited headset picture arises as a loss of information
in a special case. And that's the way science works. I want to ask one last question with my
host prerogative. And that's just, I noticed that you are now listed as emeritus professor at UC Irvine,
just up the road as an anteater. I want to ask you just quick reflections on a career in academia,
but with a particular eye towards the future of academia for, you know, slightly younger,
though not much younger, but folks like me, and even a new professor. Will academia look the same
in 20 years when I'm, you know, emeritus or when a new assistant professor today that we just hired,
and she's going to be emeritus in 40 years? What will academia look like? And what will, in particular,
the field of artificial intelligence, obviously very closely related, a lot of your wonderful images
came from AI-generated art, which I love. How will AI change our profession? Or how will other forces
protest and disruptions and encampments? What do you see as a future of academia with the benefit of this
story, legendary career that you've had? My best guess is that AI is going to have a profound
impact. In fact, when you're asking the question, that was the first thing that came to mind is that
AI, right now, AI is my closest collaborator, right? Because I mean, on mathematical things,
I always ask Chaitan, but sometimes my mathematician friend Chaitan that I've worked with and love for
35 or 40 years, right? But you know, he's a person, he's got a life, and he can't be at my beck and
call every time I, Chaitan, what, you know, tell me about this, man. So it's not a grad student
anymore. That's right. So I just go and ask the AI to explain this stuff to me and it does,
it does a good job. So already, just in the last year, my whole style of research
has really actually accelerated because I don't have to wait. And I can actually ask a series of
questions and I can get a pretty, I mean, you have to tell when the AI, sometimes the AI gets
it wrong. So you have to, you have to be careful. Well, I think that students, you know, ultimately,
I'm not sure we're going to need us to teach, frankly, this won't happen right away. I mean,
but I, you know, if you're looking 20 years down the line, I don't see too many people being able to
compete with AIs 20 years down the line, in terms of didactic skills and so forth.
And right now, it's the worst AI is going to be, right? I mean, it's only going to get better.
And imagine my, you know, kids, a 10-year-old and, you know, he or she has had AI, you know,
reading over their emails and let's say it's benevolent, you know, who knows about Google.
But, you know, everything will be on Google. You know, I wasn't on Google when I was 10. It didn't
exist for them, you know, it took 20 more years, but almost before it existed. So imagine everything,
every single thing, every thought, every email to collaborator.
And again, it could be malevolent, but let's just assume it's benevolent.
Imagine, you know, it's truly a second, third, fourth, fifth brain and just the capability of
that. But, you know, I wonder, I had some conversations last week with David Berlinski,
who you probably know. He's a wonderful thinker and raconteur. And he was talking about a conversation
he had in 1965 with Noam Chomsky and B.F. Skinner and all these incredible minds that are heroes,
right, to many people. And the question that came up of, you know, will computers ever really be able
to reason. And he asked this of Chomsky and Chomsky said, you know, the probability of,
you know, in the stochastic system of the next word being selected is zero. You know, basically,
there's an infinite number of words. And then you add in context, layer, grammar, syntax,
lexicon, vocab, all these. So the probability, and yet I'm speaking to you right now.
And I'm not even thinking about what I'm saying. It's probably obvious to you. But the point being,
you know, that Chomsky, even the great Chomsky thought that these LLMs were impossible, you know,
as recently as, you know, 30 years, 40 years ago, even, maybe even more recent than that. So,
and yet, I pushed back on David, who's sort of even suggesting that AI will come up with these laws
of physics. I mean, I don't have to remind you, but, you know, Einstein here, you know, he said his
happiest thought was that if he was in free fall, he'd experienced no gravitational field. And that
led to the Einstein equivalence principle, which then overlaid onto it, you know, Riemannian geometry
and everything. To what extent, you know, can ChatGPT produce an amplituhedron, you know, or an
Einstein equivalence principle? Is it just a matter of tokens? Because I'm very optimistic about the need
for humans. Although I agree, our days, at least as we do it, are numbered. But I'm no Einstein.
And the question of, you know, creativity at the level of, you know, I made a joke the other day on
X, I said, you know, is it I assume I stipulate that computers will always be better at humans than
chess, but I don't believe a computer will ever invent a game like chess. So where is the magic? You
know, where is where's the room for physicists for cognitive scientists? Is it in creativity? Are there
things that LLMs certainly cannot replicate just based on their architecture? Earlier, I said that
I think that you are the truth, you are the reality. And then there's this one infinite reality that
transcends any concepts that's talking to itself through a Don and Brian avatars and so forth. And
that's relevant to this question. Because if we look at an LLM or a future AI, it's going to be some
kind of computational system. And computational systems have their limits, right? We have good
limits at a minimum. I'm betting that you and I are avatars of an infinite intelligence that's the
true source of all creativity, and that Einstein and any scientist taps into when they come up with
their truly original ideas. The first step will be to say, if it's just a computational device,
then it doesn't transcend, it doesn't transcend and doesn't get to this true originality. But then
there's a deeper level to trying to address your question. Because in some sense, okay, well, what is
this thing we call Don and Brian? Well, these are just avatars in a particular headset, right?
So why can't we create a new avatar in our headset that looks like a computer that is actually an
avatar of the deep intelligence, right? If we're going to only stick with a computational thing,
then I think there's a problem. But somehow the Brian avatar is a portal into
the infinite consciousness. And the Don avatar is a portal into it. And we know one way of creating new
portals into this infinite consciousness, and that is having kids. So that's one technology
that allows us to do it. So could we, once we understand space-time as a headset,
and we understand the headset and at least some layers of its relationship to the infinite reality,
that's a source of true insight and true originality and creativity,
could we figure out new ways to open up genuine new portals? And might that look like AI?
There I'll have to say, the jury's out. But so the first one, I would say,
if it's just an LLM kind of, or just a computation device, no, then there's a level of creativity that
is going to miss. But is it possible that we could actually open new portals into the consciousness
behind? Then it's a different game. Excellent. Well, Don, this is a wonderful,
I could talk to you forever. Maybe I'll come up to Irvine next time. We'll do it in person.
Oh, it would be a pleasure. Absolutely. Great pleasure, Brian. Yeah.
Don, you're such a fan favorite, my favorite. I love talking to you. And hopefully we'll do it
again, like I said, in person sometime. I would love to do that, Brian. Great to talk.
Okay. Stay well. Bye, Don. Congratulations. You made it all the way to the end in this wonderful
conversation with Don. I know you're going to love my episode with Sam Harris. And click here
for my greatest episodes in the theory of consciousness and the mind. See you next week on
Into the Impossible.
