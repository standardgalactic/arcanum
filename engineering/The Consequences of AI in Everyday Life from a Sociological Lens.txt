Hi friends, I'm Ash. I'm a social scientist and sometimes I make videos about sociological
topics and sometimes I make vlogs. Today, we are talking about the consequences of AI,
artificial intelligence, and everyday life from a sociological lens. So let's get into the video.
And yes, I am wearing the same outfit from either the past video or the next video because I am
trying to batch content a bit better, especially because we're going to New Zealand for a couple
of weeks in November and I just want to get a bit more into the groove of making content and try and
do better. And with that being said, I am also trying to get to a thousand subscribers before
the end of the year. That is one of my 2024 goals. So if you enjoy my content, I would love it if you
subscribe to the channel. Anyway, as always, I've written a blog post about this and I'm just all
about repurposing content right now. So, uh, I'll link the blog post down below so you can read that
as well if you like. I'm not like perfect at always looking at the camera. I am practicing and getting
better and getting more confident. So thank you to those who are supporting me on this journey.
But yeah, uh, let's talk about the consequences of AI in everyday life.
But first, what is AI? So according to Wikipedia, AI in its broadest sense is intelligent exhibited by
machines, particularly computer systems. It is a field of research and computer science that develops
and studies methods and software that enable machines to perceive their environment and uses
learning and intelligence to take actions that maximize their chances of achieving defined goals.
And if there's an updated definition in Wikipedia, I'll put it on the screen here for you.
But let's break it down for us like simple-minded folk because AI obviously isn't my area of
expertise, but, uh, one of the things that I want to do in life or before I turn 30, which is very soon,
um, is learn a lot more about AI. I'm just kind of curious. So IBM describes AI as technology that
enables computers and machines to simulate human intelligence and problem solving capabilities.
So to me, that means AI is a type of computer software that is kind of replicating what we
do as humans. So we don't have to think as much. Um, and I keep seeing lots of memes about people
wanting AI to do their mundane tasks, like the dishes and washing and whatnot, uh, so they can write and
make art, but what AI is doing is doing their writing and making art. Not very good art. Um,
it's a bit of like plagiarism basically. So some examples of AI that we have in everyday life and
we've had for a while, uh, chat bots. So chat GPT, um, digital assistant. So Siri, okay, Google,
I don't want to go too much into detail about what these are because obviously most of us, that's common
knowledge navigation. So Google maps, Apple map, Apple max, Apple maps, um, use AI to direct it
or direct where we're going. Never really thought about maps as AI until now, which is interesting.
And according to MDPI, uh, navigation is a science and technology of accurately determining the position
and velocity of an airborne land or Marine vehicle relative to a known reference, wherein the planning
and execution of the maneuvers necessary to move between desired locations that analyzed smarticle
robotics. That's a example of AI, like making robots. Some examples of that, uh, before I talk about the
examples is that I think robotics and AI are very two different disciplines. Um, that's not to say
they don't overlap, but, um, robotics is a branch of engineering and computer science where people
build machines like little robots who can operate without human intervention or will not too much.
And the reason these robots are built is so that they can carry out the tasks that humans would get
fatigued by. And obviously I've already defined AI. So I won't bore you with that.
AI in robotics is currently a minority, but there are some examples. So, uh, the household product,
Amazon's Astro bot, uh, I'll put in like pictures or links. Uh, so you know what I'm talking about.
So robots and manufacturing, and there's even robots in healthcare. Uh, one robot is known as,
or not one robot, but there's robots known as Waldo surgeons and they help with surgery.
And the name is actually inspired from a sci-fi short story called Waldo from Robert A. Heinlein,
who was a very, uh, famous, uh, sci-fi writer or author. Um, I don't know if he is still alive,
so let's have a look. No, he's, he's definitely not alive anymore. Born on 1907 and died in 1988.
But yeah, very, very, very good sci-fi writer. If you like sci-fi, I recommend checking him out.
Anyway, healthcare, uh, facial recognition, autonomous vehicles, like a self-driving car
and even search engines. So those are the examples of like AI and everyday life.
Now that we have a bit more context to what AI is, let's take a bit of a deeper dive into the
consequences or implications or whatever you want to call it of AI and everyday life from a
sociological lens. And I feel like I have to apologize because sometimes I talk with my hands
and sometimes I don't. And yeah, I think my personality is just a little bit all over the
place, a little bit rustic and a little bit awkward and a little bit anxious.
Okay. The first consequence or implication, I don't know what to say. Implication,
maybe implication is better. So labor markets and employment. And I feel like this has both
pros and cons about it. So AI could increase labor productivity by automating mundane and routine tasks,
which frees up time for workers to develop other skills. And this could in turn increase the value
of the workers, but it could also decrease employment opportunities. So that's like the pro and the con
there. And what kind of jobs will AI create? So according to the world economic forum, some jobs that
could be created by AI are AI trainers. So people who develop AI explainers, people who help explain what
AI is to the general public and sustainers, people who use AI and make sure to continue using it in the best
ways possible. And a little side note here, this article also talks about creative destruction. And that
makes my sociological brain very happy because they are exactly right. AI is literally creative
destruction. And we could have a whole discussion on that. So what about the jobs that AI might
destroy or replace? So according to Marianne, 2024 roles that require repetitive tasks like data entry,
legal admin, and mathematical careers may be replaced with AI or enhanced depending on how you look at it.
And healthcare may be impacted as well as we already saw with Waldo surgeons. And with such innovation,
it means that new skill requirements will need to be met. So are we going to lose more or learn more?
I don't have a specific subsection for AI in healthcare, but I do want to say a few things
here if you don't mind. So according to Shahan 2021, there are many applications of AI in healthcare,
such as AI for drug discovery, meaning that AI has helped pharmaceutical companies fast track their
drug discovery process. So Pfizer, I don't know, how does that case that? Pfizer is using machine
learning to help discover immunoecology treatments, get vaccinated everyone. AI is being used in clinical
trials to help automate and speed up the process. And AI is being used for patient care to analyze
people's quality of life. So I feel like it's doing some good things in healthcare.
Moving on to social relationships and interactions. And I am getting distracted because I feel like I
haven't set the camera up where I usually do or the lighting's just a bit off because it's darker.
Usually I film early in the day, but it's like, because we had the gardeners come today,
all there has been is like noises of mowing lawns. And I just haven't been able to like film while
that's going on because it's frustrating me and like, it's just annoying, right? And I feel like the
mic would pick up on a little bit. Anyway, social relationships and interactions. So I personally
feel like AI is going to influence our social relationships and interactions. So for example,
we already see the use of filters in social media apps, such as Snapchat and Instagram.
I am sure there are others, but I can't think of them right now. And I use filters sometimes not
usually to enhance my face, but sometimes I like to play with the silly ones on Snapchat,
but a lot of filters are about changing the way we look often to enhance our beauty or shape our face
to fit with what's training at the time. So there's a whole debate there, but I do want to say,
as I said before, there are a range of like really silly or stupid filters that like make us look
ugly or not our best selves. And I think that's important to point out because it's not,
no one ever talks about that. They only ever talk about the beauty enhancing side of things.
And I feel like there are always multiple sides to things. And I personally think that people do
actually just talk about negative things when it comes to social media.
Like where are the people talking about the positive things about social media? Because
there are both talking about social media. A lot of platforms have integrated AI into their own
algorithms. Even my blog, um, hosting site uses AI insider to help make the users have a better
experience. Um, social media platforms use AI to enable personalized content recommendations,
real time content analysis and automated content generation. And with this comes enhancement for
the user experience on social media. It could also lead lead. It could also lead to the spread of
misinformation, filter bubbles, and echo chambers. And this was written a while ago, but since then,
the AI on like Instagram and Facebook is really annoying, like, like, I'm just trying to search
for someone so I can message them. And then it's like telling me this whole story about horses or
whatever. Uh, yeah, it's, and I find it funny how now Facebook has AI that is just like
summarizing a comment section of a post. Anyway, AI is also seen in things like customer relations,
where companies will use AI similar to the way they would use a customer service agent. And by doing
this, it saves them money, but also helps with time and location barriers. So it doesn't matter what time
a person is calling or, um, chatting with the company, the AI agent can help them because they don't have
a legal right to go home at a certain time. It also means that companies can unfortunately be located
in cheaper areas, uh, which might lead to more exploitation. If they do employ AI agents instead of
people, I mean, it might mean that such companies can generate higher revenue. Yay, capitalism! That's sarcasm!
Um, and turnovers each year. Uh, whether or not the user experience is as good as talking to a human
is a different story. Personally, I don't like talking on the phone at all, but I've also struggled
with chatbots too, because sometimes they just have no idea what you're talking about. So I feel like I'm
on the fence, but that might just be because I'm a bit of an introvert. And if you're like me, you've
probably watched a lot of sci-fi or read a lot of sci-fi content and I love it, but it does scare me to
some degree, especially when it does come to things like robots. And I've talked about this in previous
videos, Westworld, such a good show. Uh, but it did scare me a lot. And I really feel like we got ripped
off with not another season because I just wanted more of that. But apparently you had like,
it just costs too much money to make and they weren't making any money, but yeah, it was really
good. Anyway, we are going off topic a little bit. Um, but the reason I brought up sci-fi is
because it makes me think of AI and companionship. Can AI really replace human companionship?
Personally, I don't think so. I don't think there's a very extra special feeling when you create
a connection with an AI. Like when you create a connection with a human, it's very like special,
whether it's a friendship or relationship, uh, like lover or whatever, those connections are very
like special to me. And this could just be my opinion, but I don't think I could have that with
a robot. But yeah, that reminds me, there is the movie Her, which is very interesting, very long too.
And in saying this, it's not to say that some people won't be able to have that connection
or like some people won't be affected because there definitely will be people affected by AI
companionship tools. I wrote here that I personally think some people may become addicted to them,
which is terrifying to think about. So if we replace human interaction with AI,
we are likely to get less equality and less satisfaction. It's not just the same. It's not,
no, it's just not the same. Quantified 2024 suggests that, and this is a quote,
that human to human communication is vital to humanity, social life, and it should be nurtured
and enhanced in any way possible. And that data and artificial intelligence provide a powerful
opportunity, enhanced personal human to human interaction and have more winning conversation.
And they also go on to say that the human fear of AI is based on the concept that AI will make humans
obsolete, which definitely won't be the case. Like that won't happen, but I do understand where the fear
comes from. Well, this is going to be a long video, long to edit, but moving on now to surveillance,
surveillance, and privacy. Is AI the new eyes of surveillance? Well, one would assume,
so considering the way it can collect, interpret, and analyze data and do so at rapid speeds.
With this comes concerns of safety, privacy, and data collection. Remember Cambridge Analytica.
Thanks Zuckerberg. According to Faye 2024 in a Forbes article,
it's widely understood that AI tools allow people to create content, texts, images, videos,
and much more can be quickly created with AI, but these tools can also be used to track and profile
individuals. AI allows for more detailed profiling and tracking of individuals' activities, movements,
and behaviors than was ever possible before. AI-based surveillance technology can, for instance,
be used for marketing purposes and targeted advertising. And to me, this quote is very,
very scary, as the use of AI in such a way can lead to an invasion of privacy, and it may make people
feel very uncomfortable and uneasy. Just think about how many cameras you walk past on a daily basis,
or how many things are actually tracking out every move. Are our phones listening to us? I wouldn't go to
say as far as our phones have our bugs, have a bug in it, but the way algorithms and things like that
work is on prediction. They know what we want before we know we want it, if that makes sense.
But what is our data being used for? Facial recognition technology is widely used in public
spaces like train stations and airports, probably a lot of other spaces too. And I remember watching a
Gruen episode, which is an Australian panel show hosted by comedian Will Anderson. And there's a
couple of advertising experts, I can't remember their names, and then they get new ones every week.
And they analyze Australian ads and say whether they think it's going to work. And basically they do
a sociological analysis of the ads, and it's really good. And one episode, it's quite old now, but said
that there were shopping centers in Australia that were tracking your like movement. And obviously
there's cameras in shopping centers for safety, but apparently they were trying to work out what
your mood was so that they could like put ads in like areas close to you. And so you'd go shop at that
place. Yeah, that kind of freaked me out. Like why do they need to know your mood anyway? And
facial recognition technology being used in such spaces leads to a lot of ethical concerns about
the constant monitoring of people? Are we in a real life 1984? Is the show, person of interest,
going to become a reality? You tell me. Okay, the next implication we're going to talk about or factor,
sociological factor, is ethics. Ethics is an interesting topic. I don't really know how people
can decide what's ethical and not like you have a gut feeling, but there are so many experiments
from the past, especially if you've done psychology or looked into that, uh, where just things are so
unethical. And you're just like, how did that happen? How did they allow that to happen?
And I know there are ethics committees and they decide what you can do and what you can't do.
But I feel like it's just so interesting how far we've come. Like what the if was the CIA doing with
MKUltra? Like how did they get away with that? That was like literal brainwashing. So they took a substance,
it must've been LSD and, um, drugged people without their knowledge. And then they wanted to see if they
could like control them. That's another topic in itself. Is AI ready to make unsupervised decisions,
like moral decision making? So simply put, no. Have you seen some of the images that it generates?
Like people have like seven fingers. However, it can help with decision making in general. We want AI
to enhance our lives, not to take over and make humans obsolete. According to McTendrick and Tori,
I don't know if I'm pronouncing that right. 2022 AI makes the right decisions for the most part.
What AI might struggle with is specific moral decision making. They go on to discuss the trolley
problem where someone has to make a decision to sacrifice one person to save a larger number of
people. Will AI be able to make a split second decision? Will it make the right one? What's even
scarier is the idea that if AI can answer the trolley problem, it's able to think independently.
Would AI make the same ethical and moral decisions that us people would? Is there AI era like there is
human era? So the trolley problem is kind of like, uh, how do I explain it? So it's a thought experiment
in ethics and psychology, uh, involving ethical dilemmas of whether to sacrifice one person or
save, uh, millions of people. So you would be like, if this person, uh, passes away, then all these
people are saved. If this person is saved, millions of people are going to pass away. So logically,
most people would go with one person passing away rather than millions. Anyway, back to what I was talking
about, would AI be able to have empathy for others or even sympathy? I know these are just more questions
than answers, but I feel like right now we still don't really know where AI stands. Like it's kind
of like still developing. And there's also the issue of bias and fairness that comes up. For example,
the idea of AI as a recruitment tool. Let's look at this example from Amazon, where they used AI,
where they used an AI based tool to essentially out recruit other big tech companies. You might
be shocked to learn what actually happened. The recruitment tool did not like women. And yes,
as a feminist and a woman myself, this is a big, big problem. The data that this AI tool used was
tainted because it was only really looking at men. It was designed to fit applications by observing patterns
and resumes submitted to the company over a 10 year period. And most of these came from men. A reflection
of male dominance across the tech industry. And you can unpack that a bit because a lot of the time
women won't apply for jobs because they don't think they're qualified for enough. And there have been
studies done on like men applying for jobs that they're definitely not qualified for and they get them.
So yeah, women should just be applying for more jobs is the takeaway from that. So this AI tool taught
itself that men were preferable to hire. As Amazon were unable to make the problem gender neutral,
the AI tool development was scrapped. And I feel like if AI was able to teach itself this,
we have to talk about hegemonic masculinity. So this is the practice which reinforces male dominance in
society. So how do we get away from that if AI is just going to have gender biases? Why is it that
men are still in charge? Aren't countries with a woman as their leader better off as a whole? Well,
that's just my opinion. It'll be very interesting to see what happens in the November election in America.
I'm very interested. And lastly, what about accountability? If AI does the wrong thing,
who takes accountability for that? Will AI be able to apologize or rectify a mistake?
We just don't know. Next, we're going to talk about economic inequality. So I feel like something
that always has to be discussed in sociology is economics. If you've ever taken a first year
sociology course, you'll know all about the social, political, cultural, and economic factors,
all of those. They all work together and can play an important role in impacting something. And often
each factor is correlated to each other. So what about AI and economic inequality? Well, we all know
that we live in this crazy capitalist world where the rich get richer and the poor get poorer. Thank you,
Karl Marx. But there's this question that's always stuck with me from my university days. And one of my
supervisors always used to say it, but who has access? And in hindsight, this is a really important
question. Who has access to the technology of AI? Well, firstly, we need an internet connection
because not everyone has that. We need to know how to use a computer and we need to be tech savvy enough
to be able to use a tool like chat GPT. And those with access might lose out. And with all that being
said, I also think AI will allow those who may have not had access before to education, finally get
access to education. We also might see the rise of personalized learning. So learning tailored to the
way we want to learn or how we might learn best. There is the idea that with the rise of AI,
income inequality will worsen. I don't have a better way of paraphrasing this, but this is from Bell
and Koronek 2023. And as a quote, we argue that this poses a grave threat to democracy that is separate
from more traditional AI risks to democracy, to democracy, such as deepfakes and misinformation.
High inequality corrodes democratic institutions through increased ELI influence, corruption,
populism, and greater public discontent. At the same time, weakened democracy loses power to rein
in an inequality through progressive policies. This may create a vicious feedback loop of eroding
democracy and rising inequality, which may accelerate rapidly following an economic shock like large
scale displacement of workers by AI. The result could be a new society wide equilibrium with starkly
increased income disparities and a weakened voice for ordinary citizens. That was a mouthful.
And if this does come into play, wealth distribution will be impacted and we will see a rise in economic
inequality. And to minimize the likelihood of this policy should be put in place, such as not allowing AI to
automate or work, empower workers, reform tax policies and make sure there are no excessive power gains from
the implementation of AI. Okay, we are at the last factor and this is social norms. And this is my favorite
one, I think. So social norms are the shared standard of behaviors that are acceptable in certain places,
which can often be different in different scenarios. So for example, there's a social norm of not talking to
other people in a lift or elevator. And if someone breaks a social norm, it can get quite uncomfortable.
So someone might face the wrong way in an elevator or lift, and it could be seen as a social norm.
Another social norm in New Zealand compared to Melbourne is when you're on the escalator steer things
in a shopping center in New Zealand, no one walks up them. Everyone's pretty lazy and just stands on them,
and you don't really need to get out of the way. But in Melbourne, because people are like always
busy, busy and trying to get to other places, you need to stand on the lift so that if anyone needs to
get up really fast, they can. Yeah, I just thought that was interesting. Anyway, what about social norms
and AI? I personally think that AI is going to fundamentally, fundamentally change our social norms,
especially in the Western world. So Baranchelli 2024 says,
an outlook on how AI could influence the formation of future social norms emphasizes the importance for
open societies to anchor their formal deliberation process in an open, inclusive and transparent
public discourse. So in my own interpretation of this quote,
new social norms are likely to emerge from the use of AI, but we don't yet know what they are going
to be. It also just makes me think of things like uncanny valley. I don't know why. Are we going to lose
agency with the rise of AI? How much of the world is actually going to take over? Do we really need to
be scared? And what's going to happen to our work-life balance? Are the days of the nine to five over,
or are we still going to be overworked and underpaid? What happens to agency? Does AI have agency?
Social norms and AI and our society is becoming increasingly digitalized. Things like social cues
that we'd have with a person to person interaction will not be seen in the same way when interacting
with an AI chatbot. They may not be able to pick up on subtle hints or cues like humans would.
They go on to say that we may even see a decline in authenticity. So this is all wreck and different
bitch who I am referencing here. Um, so we might see a decline in authenticity online when we see
avatars, which I think is already happening with like AI influences. And I don't understand why they
have so many followers. If a person is acting as an avatar or something like that on the metaverse,
does there mean there are different social norms and expectations for that avatar? What happens if
that avatar commits a crime? Is it treated the same way as a crime in real life? What happens to trolls?
Will we still be able to block them? So many thought provoking questions. And I feel like I have
more questions about social norms and answers to do with AI, and I apologize for that. But that brings me
to the end. So to summarize, we have discussed the consequences or implications of AI on everyday
life from a sociological lens. We have explored examples of AI, the effects of AI on labor markets
and employment, AI and social relationships, AI and surveillance society, AI and ethics, AI and economic
inequality, AI and social norms. We can see that AI is another form of creative destruction,
but with the rise of AI comes way more questions than answers. So stay tuned.
Anyway, thank you so much for watching. As I said at the start of this video, I am trying to get to a
thousand subscribers before the end of this year. So if you could go ahead and give this video a big
thumbs up if you enjoyed it and subscribe to my channel. If you have not already, I believe there's
about 70% of people who are watching my videos, but aren't subscribed. And I will link all the sources
and my blog posts down below. So you can go and read those as well. I'll see you next one. Bye.
