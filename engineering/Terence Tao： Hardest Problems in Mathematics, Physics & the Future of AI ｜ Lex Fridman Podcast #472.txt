The following is a conversation with Terence Tao, widely considered to be one of the greatest
mathematicians in history, often referred to as the Mozart of math. He won the Fields Medal
and the Breakthrough Prize in Mathematics, and has contributed groundbreaking work to a truly
astonishing range of fields in mathematics and physics. This was a huge honor for me,
for many reasons, including the humility and kindness that Terry showed to me
throughout all our interactions. It means the world. This is the Lex Friedman Podcast. To support
it, please check out our sponsors in the description or at lexfreedman.com slash sponsors.
And now, dear friends, here's Terence Tao. What was the first really difficult research-level
math problem that you encountered? One that gave you pause, maybe?
Well, I mean, in your undergraduate education, you learn about the really hard, impossible problems,
like the Riemann hypothesis, the Trin-Primes conjecture. You can make problems arbitrarily
difficult. That's not really a problem. In fact, there's even problems that we know to be
unsolvable. What's really interesting are the problems just on the boundary between what we
can do easily and what are hopeless. But what are problems where existing techniques can do
like 90% of the job and then you just need that remaining 10%. I think as a PhD student,
the Kikeya problem certainly caught my eye. And it just got solved, actually. It's a problem I've
worked on a lot in my early research. Historically, it came from a little puzzle by the Japanese
mathematician, Suji Kikeya, in like 1918 or so. So the puzzle is that you have a needle
on the plane. Think of driving on a road or something. And you want to execute a U-turn.
You want to turn the needle around. But you want to do it in as little space as possible.
So you want to use this little area in order to turn it around. But the needle is infinitely
maneuverable. So you can imagine just spinning it around. It's a unit needle. You can spin it around
its center. And I think that gives you a disk of area, I think, pi over 4. Or you can do a three-point
U-turn, which is what we teach people in their driving schools to do. And that actually takes
area pi over 8. So it's a little bit more efficient than a rotation. And so for a while, people thought
that was the most efficient way to turn things around. But Vesikovic showed that, in fact, you could
actually turn the needle around using as little area as you wanted. So 0.001, there was some really
fancy multi-back-and-forth U-turn thing that you could do, that you could turn the needle
around. And in so doing, it would pass through every intermediate direction.
Is this in the two-dimensional plane?
This is in the two-dimensional plane. Yeah. So we understand everything in two dimensions.
So the next question is what happens in three dimensions? So suppose like the Hubble Space
Telescope is tube in space. And you want to observe every single star in the universe. So you want to
rotate the telescope to reach every single direction. And here's the unrealistic part. Suppose that
space is at a premium, which totally is not. You want to occupy as little volume as possible
in order to rotate your needle around in order to see every single star in the sky.
How small a volume do you need to do that? And so you can modify Vesikovic's construction.
And so if your telescope has zero thickness, then you can use as little volume as you need.
That's a simple modification of the two-dimensional construction. But the question is that if your
telescope is not zero thickness, but just very, very thin, some thickness delta, what is the
minimum volume needed to be able to see every single direction as a function of delta? So
as delta gets smaller, as your needle gets thinner, the volume should go down. But how fast does it go
down? And the conjecture was that it goes down very, very slowly, like logarithically,
roughly speaking. And that was proved after a lot of work.
So this seems like a puzzle. Why is it interesting? So it turns out to be surprisingly
connected to a lot of problems in partial differential equations, in number theory,
in geometry, combinatorics. For example, in wave propagation, you splash some water around,
you create water waves and they travel in various directions. But waves exhibit both particle and
wave type behavior. So you can have what's called a wave packet, which is like a very localized wave
that is localized in space and moving a certain direction in time.
And so if you plot it into both space and time, it occupies a region which looks like a tube.
And so what can happen is that you can have a wave which initially is very dispersed,
but it all focuses at a single point later in time. Like you can imagine dropping a pebble
into a pond and ripples spread out. But then if you time reverse that scenario, and the equations
of wave motion are time reversible, you can imagine ripples that are converging to a single point and then
a big splash occurs, maybe even a singularity.
And so it's possible to do that. And geometrically, what's going on is that there's always light rays.
So like if this wave represents light, for example, you can imagine this wave as the superposition of
photons all traveling at the speed of light. They all travel on these light rays and they're all
focusing at this one point. So you can have a very dispersed wave focus into a very concentrated wave
at one point in space and time, but then it defocuses again and it separates. But potentially,
if the pinjacule had a negative solution, so what that meant is that there's a very efficient way to pack
tubes pointing different directions into a very, very narrow region of a very narrow volume,
then you would also be able to create waves that start out, there'll be some arrangement of waves
that start out very, very dispersed, but they would concentrate not just at a single point, but
there'll be a large, there'll be a lot of concentrations in space and time. And you could
create what's called a blow up, where these waves, their amplitude becomes so great that the laws of
physics that they're governed by are no longer wave equations, but something more complicated and
non-linear. And so in mathematical physics, we care a lot about whether certain equations
and wave equations are stable or not, whether they can create these singularities. There's a famous
unsolved problem called the Navier-Stokes regularity problem. So the Navier-Stokes equations
are the equations that govern the fluid flow or incompressible fluids like water. The question asks,
if you start with a smooth velocity field of water, can it ever concentrate so much that the
velocity becomes infinite at some point? That's called a singularity. We don't see that
in real life. If you splash around water on the bathtub, it won't explode on you,
or have water leaving at the speed of light. But potentially, it is possible.
And in fact, in recent years, the consensus has drifted towards the belief that, in fact, for certain
very special initial configurations of water, that singularities can form. But people have not yet
been able to actually establish this. The Clay Foundation has these seven-millennium prize problems,
has a million-dollar prize for solving one of these problems. This is one of them. Of these seven,
only one of them has been solved at the Poincar√© conjecture.
Mike Perlman. So the Cacare conjecture is not directly, directly related to the Navier-Stokes problem,
but understanding it would help us understand some aspects of things like wave concentration,
which would indirectly probably help us understand the Navier-Stokes problem better.
Can you speak to the Navier-Stokes? So the existence and smoothness, like you said,
millennial prize problem. Right.
You've made a lot of progress on this one. In 2016, you published a paper, Finite Time Blow-Up,
for an averaged three-dimensional Navier-Stokes equation. Right.
So we're trying to figure out if this thing usually doesn't blow up, but can we say for sure it never
blows up? Right. Yeah. So yeah, that is literally the million-dollar question. So this is what
distinguishes mathematicians from pretty much everybody else. If something holds 99.99% of the
time, that's good enough for most things. But mathematicians are one of the few people who really
care about whether every, like 100%, really 100% of all situations are covered by, yeah. So
most fluid, most of the time, water does not blow up, but could you design a very special initial
state that does this? And maybe we should say that this is a set of equations that govern
in the field of fluid dynamics, trying to understand how fluid behaves. And it actually turns out to be
a really complicated, you know, fluid is extremely complicated thing to try to model.
Yeah. So it has practical importance. So this clay price problem concerns what's called the
incompressible Navier-Stokes, which governs things like water. There's something called
the compressible Navier-Stokes, which governs things like air. And that's particularly important
for weather prediction. Weather prediction, it has a lot of computational fluid dynamics. A lot
of it is actually just trying to solve the Navier-Stokes equations as best they can.
Also gathering a lot of data so that they can get, they can initialize the equation. There's a lot
of moving parts. So it's very important problem practically.
Why is it difficult to prove general things about the set of equations like it not blowing up?
The short answer is Maxwell's Demon. So Maxwell's Demon is a concept in thermodynamics. Like if you
have a box of two gases, you know, oxygen and nitrogen, and maybe you start with all the oxygen
on one side and nitrogen on the other side, but there's no barrier between them, right? Then they will mix.
And they should stay mixed, right? There's no reason why they should unmix. But in principle,
because of all the collisions between them, there could be some sort of weird conspiracy.
Like maybe there's a microscopic demon called Maxwell's Demon that will, every time an oxygen
and nitrogen atom collide, they will bounce off in such a way that the oxygen sort of drifts onto one
side and the nitrogen goes to the other. And you could have an extremely improbable configuration emerge,
which we never see. And statistically, it's extremely unlikely. But mathematically, it's possible that
this can happen and we can't rule it out. And this is a situation that shows up a lot in mathematics.
A basic example is the digits of pi, 3.14159 and so forth. The digits look like they have no pattern,
and we believe they have no pattern. On the long term, you should see as many ones and twos and threes
as fours and fives and sixes. There should be no preference in the digits of pi to favour, let's say,
seven over eight. But maybe there's some demon in the digits of pi that every time you compute
more and more digits, it biases one digit to another. And this is a conspiracy that should
not happen. There's no reason it should happen, but there's no way to prove it with our current
technology. Okay, so getting back to Navier-Stokes, a fluid has a certain amount of energy. And because
the fluid is in motion, the energy gets transported around. And water is also viscous. So if the energy is
spread out over many different locations, the natural viscosity of the fluid will just damp
out the energy and it will go to zero. And this is what happens when we actually experiment with
water. You splash around, there's some turbulence and waves and so forth, but eventually it settles
down. And the lower the amplitude, the smaller the velocity, the more calm it gets. But potentially,
there is some sort of demon that keeps pushing the energy of the fluid into a smaller and smaller
scale. And it will move faster and faster. And at faster speeds, the effect of viscosity is relatively
less. And so it could happen that it creates some sort of what's called a self-similar blob scenario,
where the energy of the fluid starts off at some large scale, and then it all sort of transfers
energy into a smaller region of the fluid, which then at a much faster rate moves into an even smaller
region and so forth. And each time it does this, it takes maybe half as long as the previous one.
And then you could actually converge to all the energy concentrating in one point in a finite amount
of time. And that scenario is called a finite amount of blow-up. So in practice, this doesn't
happen. So water is what's called turbulent. So it is true that if you have a big eddy of water,
it will tend to break up into smaller eddies, but it won't transfer all the energy from one big eddy
into one smaller eddy. It will transfer into maybe three or four. And then those ones split up into maybe
three or four small eddies of their own. And so the energy gets dispersed to the point where the
viscosity can then keep everything under control. But if it can somehow concentrate all the energy,
keep it all together, and do it fast enough that the viscous effects don't have enough time to calm
everything down, then this blow-up can occur. So there were papers who had claimed that, oh,
you just need to take into account conservation of energy and just carefully use the viscosity and you
can keep everything under control for not just Navier-Stokes, but for many, many types of equations like this.
And so in the past, there have been many attempts to try to obtain what's called global regularity
for Navier-Stokes, which is the opposite of final time blow-up, that velocity stays smooth.
And it all failed. There was always some sign error or some subtle mistake and it couldn't be salvaged.
So what I was interested in doing was trying to explain why we were not able to disprove
final time blow-up. I couldn't do it for the actual equations of fluids, which were too complicated.
But if I could average the equations of motion of Navier-Stokes, basically if I could turn off
certain types of ways in which water interacts and only keep the ones that I want.
So in particular, if there's a fluid and it could transfer this energy from a large eddy into this
small eddy or this other small eddy, I would turn off the energy channel that would transfer energy to
this one and direct it only into this smaller eddy while still preserving the law of concentration of energy.
So you're trying to make a blow-up?
Yeah. Yeah. So I basically engineer a blow-up by changing the laws of physics,
which is one thing that mathematicians are allowed to do. We can change the equation.
How does that help you get closer to the proof of something?
Right. So it provides what's called an obstruction in mathematics. So what I did was that basically,
if I turned off certain parts of the equation, which usually when you turn off certain interactions,
make it less non-linear, it makes it more regular and less likely to blow up. But I found that by
turning off a very well-designed set of interactions, I could force all the energy to blow up in finite time.
So what that means is that if you wanted to prove global regularity for Navier-Stokes for the actual
equation, you must use some feature of the true equation, which my artificial equation does not
satisfy. So it rules out certain approaches. So the thing about math is it's not just about
taking a technique that is going to work and applying it, but you need to not take the techniques that
don't work. And for the problems that are really hard, often there are dozens of ways that you might
think might apply to solve the problem, but it's only after a lot of experience that you realize there's
no way that these methods are going to work. So having these counter examples for nearby problems
kind of rules out. It saves you a lot of time because you're not wasting energy on things that you
now know cannot possibly ever work. How deeply connected is it to that specific
problem of fluid dynamics or just some more general intuition you build up about mathematics?
Right. Yeah. So the key phenomenon that my technique exploits is what's called supercriticality.
So in partial differential equations, often these equations are like a tug of war between different
forces. So in Navier-Stokes, there's the dissipation force coming from viscosity and it's very well
understood. It's linear. It calms things down. If viscosity was all there was, then nothing bad
would ever happen. But there's also transport. That energy in one location of space can get
transported because the fluid is in motion to other locations. And that's a non-linear effect
and that causes all the problems. So there are these two competing terms in the Navier-Stokes equation,
the dissipation term and the transport term. If the dissipation term dominates, if it's large,
then basically you get regularity. And if the transport term dominates, then we don't know
what's going on. It's a very non-linear situation. It's unpredictable. It's turbulent. So sometimes
these forces are in balance at small scales, but not in balance at large scales or vice versa.
So Navier-Stokes is what's called supercritical. So at smaller and smaller scales, the transport
terms are much stronger than the viscosity terms. So the viscosity terms are things that calm things down.
And so this is why the problem is hard. In two dimensions, so the Soviet Methodician Ladishinskaya,
she in the 60s shows in two dimensions, there was no blow up. And in two dimensions, the Navier-Stokes
equations is what's called critical. The effect of transport and the effect of viscosity are about
the same strength, even at very, very small scales. And we have a lot of technology to handle critical and
also subcritical equations and prove regularity. But for supercritical equations, it was not clear
what was going on. And I did a lot of work and then there's been a lot of follow-up showing that
for many other types of supercritical equations, you can create all kinds of blow up examples. Once
the non-linear effects dominate the linear effects at small scales, you can have all kinds of bad things
happen. So this is sort of one of the main insights of this line of work is that supercriticality
versus criticality and subcriticality, this makes a big difference. I mean, that's a key qualitative
feature that distinguishes some equations for being sort of nice and predictable, like planetary
motion. I mean, there are certain equations that you can predict for millions of years, or thousands
at least. Again, it's not really a problem, but there's a reason why we can't predict the weather
past two weeks into the future, because it's a supercritical equation. Lots of really strange things
are going on at very fine scales. So whenever there's some huge source of non-linearity,
that can create a huge problem for predicting what's going to happen.
Yeah. And if non-linearity is somehow more and more featured and interesting at small scales.
I mean, there's many equations that are non-linear, but in many equations, you can approximate things by
the bulk. So for example, planetary motion, if you wanted to understand the orbit of the Moon or Mars
or something, you don't really need the microstructure of like the seismology of the Moon or
like exactly how the Mars is distributed. You just basically, you can almost approximate these
planets by point masses. And just the aggregate behavior is important. But if you want to model
a fluid, like the weather, you can't just say in Los Angeles, the temperature is this,
the wind speed is this. For supercritical equations, the fine scale information is really important.
If we can just linger on the Navier-Stokes equations a little bit. So you've suggested,
maybe you can describe it, that one of the ways to solve it or to negatively resolve it would be to
sort of to construct a liquid, a kind of liquid computer, and then show that the halting problem
from computation theory has consequences for fluid dynamics. So show it in that way. Can you describe
this idea? Right. Yeah. So this came out of this work of constructing this average equation that blew
up. So as part of how I had to do this, there's sort of this naive way to do it. You just keep
pushing. Every time you get energy at one scale, you push it immediately to the next scale as fast
as possible. This is sort of the naive way to force blow up. It turns out in five and higher dimensions,
this works. But in three dimensions, there was this funny phenomenon that I discovered
that if you change the laws of physics, you just always keep trying to push
the energy into smaller and smaller scales. What happens is that the energy starts getting
spread out into many scales at once. So you have energy at one scale, you're pushing it
into the next scale. And then as soon as it enters that scale, you also push it to the next scale,
but there's still some energy left over from the previous scale. You're trying to do everything at
once. And this spreads out the energy too much. And then it turns out that it makes it vulnerable
for viscosity to come in and actually just damp out everything. So it turns out this directive
motion doesn't actually work. There's a separate paper by some other authors that actually showed this
in three dimensions. So what I needed was to program a delay. So kind of like airlocks. So I needed an
equation which would start with a fluid doing something at one scale, it would push its energy
into the next scale, but it would stay there until all the energy from the larger scale got transferred.
And only after you pushed all the energy in, then you sort of open the next gate and then you push
that in as well. So by doing that, the energy inches forward scale by scale in such a way that it's
always localized at one scale at a time. And then it can resist the effects of viscosity because it's
not dispersed. So in order to make that happen, I had to construct a rather complicated non-linearity.
And it was basically like, it was constructed like an electronic circuit. So I actually thank my wife
for this because she was trained as an electrical engineer. And she talked about, she had to design circuits
and so forth. And if you want a circuit that does a certain thing, like maybe have a light that
flashes on and then turns off and then on and then off, you can build it from more primitive components,
you know, capacitors and resistors and so forth. And you have to build a diagram. And these diagrams,
you can sort of follow with your eyeballs and say, oh yeah, the current will build up here and it will
stop and then it will do that. So I knew how to build the analog of basic electronic components,
you know, like resistors and capacitors and so forth. And I would stack them together
in such a way that I would create something that would open one gate and then there would be a
clock. And then once the clock hits a certain threshold, it would close it. It would become
a Rube Goldberg type machine, but described mathematically. And this ended up working.
So what I realized is that if you could pull the same thing off for the actual equations,
so if the equations of water support a computation, so like if you can imagine kind of a steampunk,
but it's really water punk type of thing where, you know, so modern computers are electronic,
you know, they're powered by electrons passing through very tiny wires and interacting with
other electrons and so forth. But instead of electrons, you can imagine these pulses
of water moving at a certain velocity. And maybe there are two different configurations corresponding to
a bit being up or down. Probably if you had two of these moving bodies of water collide,
they would come out with some new configuration, which would be something like an AND gate or OR gate.
You know, the output would depend in a very predictable way on the inputs. And like,
you could chain these together and maybe create a Turing machine. And then you have computers,
which are made completely out of water. And if you have computers, then maybe you can do robotics,
you know, hydraulics and so forth. And so you could create some machine, which is basically a fluid
analog of what's called a von Neumann machine. So von Neumann proposed, if you want to colonize Mars,
the sheer cost of transporting people and machines to Mars is just ridiculous. But if you could
transport one machine to Mars, and this machine had the ability to mine the planet, create some more
materials, smelt them, and build more copies of the same machine, then you could colonize the whole planet
over time. So if you could build a fluid machine, which, yeah, so it's a fluid robot. And what it
would do, its purpose in life, it's programmed so that it would create a smaller version of itself
in some sort of cold state. It wouldn't start just yet. Once it's ready, the big robot,
the water would transfer all its energy into the smaller configuration and then power down. And then
it clean itself up. And then what's left is this newer state, which would then turn on and do the
same thing, but smaller and faster. And then the equation has a certain scaling symmetry. Once you
do that, it can just keep iterating. So this in principle would create a blow up for the actual
Navier-Stokes. And this is what I managed to accomplish for this average Navier-Stokes.
So it provided this sort of roadmap to solve the problem. Now, this is a pipe dream because
there are so many things that are missing for this to actually be a reality.
So I can't create these basic logic gates. I don't have these special configurations of water.
I mean, there's candidates that include vortex rings that might possibly work. But also, you know,
analog computing is really nasty compared to digital computing. I mean, because there's always errors.
You have to do a lot of error correction along the way. I don't know how to completely power down
the big machine so that it doesn't interview the writing of a smaller machine. But everything
in principle can happen. It doesn't contradict any of the laws of physics. So it's sort of evidence
that this thing is possible. There are other groups who are now pursuing ways to make Navier-Stokes blow
up, which are nowhere near as ridiculously complicated as this. They actually are pursuing much closer to
the direct self-similar model. It doesn't quite work as is, but there could be some simpler scheme
than what I just described to make this work.
There is a real leap of genius here to go from Navier-Stokes to this Turing machine. So it goes
from what the self-similar blob scenario that you're trying to get the smaller and smaller blob
to now having a liquid Turing machine gets smaller and smaller and smaller and somehow seeing how that
could be used to say something about a blow up. I mean, that's a big leap.
So there's precedent. I mean, so the thing about mathematics is that it's really good at
spotting connections between what you might think of as completely different
problems. But if the mathematical form is the same, you can draw a connection.
So there's a lot of work previously on what I call cellular automata, the most famous of which is
Conway's Game of Life. There's this infinite discrete grid, and at any given time, the grid is either
occupied by a cell or it's empty. And there's a very simple rule that tells you how these cells
evolve. So sometimes cells live and sometimes they die. When I was a student, it was a very popular
screensaver to actually just have these animations going on. And they look very chaotic. In fact,
they look a little bit like turbulent flow sometimes. But at some point, people discovered
more and more interesting structures within this game of life. So for example, they discovered this
thing called a glider. So a glider is a very tiny configuration of like four or five cells, which
evolves and it just moves in a certain direction. And that's like this vortex rings.
So this is an analogy. The Game of Life is kind of like a discrete equation, and the fluid Navier-Stokes
is a continuous equation. But mathematically, they have some similar features.
And so over time, people discovered more and more interesting things that you could build within
the Game of Life. The Game of Life is a very simple system. It only has like three or four rules
to do it. But you can design all kinds of interesting configurations inside it. There's something called
a glider gun that does nothing to spit out gliders one at a time. And then after a lot of effort,
people managed to create AND gates and OR gates for gliders. There's this massive ridiculous structure,
which if you have a stream of gliders coming in here and a stream of gliders coming in here,
then you may produce extreme gliders coming out. So maybe if both of the streams have gliders,
then there'll be an output stream. But if only one of them does, then nothing comes out. So they could
build something like that. And once you could build these basic gates, then just from software engineering,
you can build almost anything. You can build a Turing machine. I mean, it's like an enormous
steampunk type things. They look ridiculous. But then people also generated self-replicating objects
in the Game of Life. A massive machine upon a machine, which over a huge period of time,
and it always looked like glider guns inside doing these very steampunk calculations, it would create
another version of itself, which could replicate. That's so incredible. A lot of this was like
community crowdsourced by amateur mathematicians, actually. So I knew about that work. And so
that is part of what inspired me to propose the same thing with Navier-Stokes.
As I said, analog is much worse than digital. You can't just directly take the constructions from
the Game of Life and plunk them in. But again, it shows it's possible.
You know, there's a kind of emergence that happens with these cellular automata. Local rules,
maybe it's similar to fluids, I don't know. But local rules operating at scale can create these
incredibly complex dynamic structures. Do you think any of that is amenable to mathematical analysis?
Do we have the tools to say something profound about that?
The thing is, you can get these emergent, very complicated structures, but only with very
carefully prepared initial conditions. So these glider guns, and gates, and software machines,
if you just plunk down randomly some cells, you will not see any of these.
And that's the analogous situation of Navier-Stokes again, that with typical initial conditions,
you will not have any of this weird computation going on. But basically through engineering,
you know, by specially designing things in a very special way, you can pick clever constructions.
I wonder if it's possible to prove the sort of the negative of like,
basically prove that only through engineering can you ever create something interesting.
This is a recurring challenge in mathematics that I call the dichotomy between structure
and randomness. That most objects that you can generate in mathematics are random.
They look like the digits of pi. Well, we believe is a good example. But there's a very small number
of things that have patterns. But now you can prove something as a pattern by just constructing,
you know, like if something has a simple pattern and you have a proof that it does something like
repeated itself every so often, you can do that. And you can prove that, for example, you can prove
that most sequences of digits have no pattern. So like if you just pick digits randomly, there's something
called the low-large numbers. It tells you you're going to get as many ones as twos in the long run.
But we have a lot fewer tools to, if I give you a specific pattern like the digits of pi,
how can I show that this doesn't have some weird pattern to it? Some other work that I spend a lot
of time on is to prove what are called structure theorems or inverse theorems that give tests for when
something is very structured. So some functions are what's called additive. Like if you have a function
that makes the natural numbers of the natural numbers. So maybe, you know, two maps to four,
three maps to six and so forth. Some functions are what's called additive, which means that if you add
if you add two inputs together, the output gets added as well. For example, I multiply by a constant.
If you multiply a number by 10, if you multiply a plus b by 10, that's the same as multiplying a by 10
and b by 10 and then adding them together. So some functions are additive. Some functions are kind of additive,
but not completely additive. So for example, if I take a number
n, I multiply by the square root of 2 and I take the integer part of that. So 10 by square root of
2 is like 14 point something. So 10 up to 14. 20 up to 28. So in that case, additivity is true then.
So 10 plus 10 is 20 and 14 plus 14 is 28. But because of this rounding, sometimes there's round off errors.
And sometimes when you add a plus b, this function doesn't quite give you the sum of the two
individual outputs, but the sum plus minus one. So it's almost additive, but not quite additive.
So there's a lot of useful results in mathematics. And I've worked a lot in developing things like
this to the effect that if a function exhibits some structure like this, then it's basically,
there's a reason for why it's true. And the reason is because there's some other nearby
function, which is actually completely structured, which is explaining this sort of partial pattern
that you have. And so if you have these inverse theorems, it creates this dichotomy that either
the objects that you study have no structure at all, or they are somehow related to something that is
structured. And in either case, you can make progress. A good example of this is that there's this
old theorem in mathematics called Zemuretti's theorem, proven in the 1970s. It concerns trying
to find a certain type of pattern in a set of numbers. The pattern is arithmetic progression,
things like 3, 5, and 7, or 10, 15, and 20. And Zemuretti proved that any set of numbers that
are sufficiently big, what's called positive density, has arithmetic progressions in it of any length you
wish. So for example, the odd numbers have a set of density one half, and they contain arithmetic
progressions of any length. So in that case, it's obvious because the odd numbers are really, really
structured. I can just take 11, 13, 15, 17, I can easily find arithmetic progressions in that set.
But Zemuretti's theorem also applies to random sets. If I take the set of all numbers and I flip a coin
for each number, and I only keep the numbers for which I got a heads. So I just flip coins,
I just randomly take out half the numbers, I keep one half. So that's a set that has no patterns at
all. But just from random fluctuations, you will still get a lot of arithmetic progressions in that
set. Can you prove that there's arithmetic progressions of arbitrary length within a random...
Yes. Have you heard of the infinite monkey theorem? Usually, mathematicians give boring
names to theorems, but occasionally they give colourful names. The popular version of the
infinite monkey theorem is that if you have an infinite number of monkeys in a room with each
with a typewriter, they type out text randomly. Almost surely, one of them is going to generate
the entire script of Hamlet or any other finite string of text. It will just take some time,
quite a lot of time actually. But if you have an infinite number, then it happens.
Basically, the theorem says that if you take an infinite string of digits or whatever,
eventually any finite pattern you wish will emerge. It may take a long time, but it will
eventually happen. In particular, the arithmetic progressions of any length will eventually happen,
but you need an extremely long random sequence for this to happen.
I suppose that's intuitive. It's just infinity.
Yeah. Infinity absorbs a lot of sins.
Yeah. How are we humans supposed to deal with infinity?
Well, you can think of infinity as an abstraction of a finite number for which you do not have a
bound for. Nothing in real life is truly infinite, but you can ask yourself questions like,
what if I had as much money as I wanted? What if I could go as fast as I wanted? A way in which
mathematicians formalize that is mathematics has found a formalism to idealize, instead of something
being extremely large or extremely small, to actually be exactly infinite or zero. Often,
the mathematics becomes a lot cleaner when you do that. In physics, we joke about assuming spherical
cows. Real-world problems have got all kinds of real-world effects, but you can idealize
send certain things to infinity, send certain things to zero. The mathematics becomes a lot simpler
to work with there. I wonder how often using infinity
forces us to deviate from the physics of reality.
Yeah. There's a lot of pitfalls. We spend a lot of time in undergraduate math classes teaching
analysis. Analysis is often about how to take limits. For example, A plus B is always B plus A.
When you have a finite number of terms and you add them, you can swap them and there's no problem.
But when you have an infinite number of terms, there are these sort of show games you can play,
where you can have a series which converges to one value, but you rearrange it and it suddenly
converges to another value. You can make mistakes. You have to know what you're doing when you allow
infinity. You have to introduce these epsilons and deltas, and there's a certain type of way of
reasoning that helps you avoid mistakes. In more recent years, people have started taking results
that are true in infinite limits and what's called finiteizing them. You know that something's true
eventually, but you don't know when, now give me a rate. If I don't have an infinite number of
monkeys, but a large finite number of monkeys, how long do I have to wait for Hamlet to come out?
That's a more quantitative question. This is something that you can attack by purely finite
methods and you can use your finite intuition. In this case, it turns out to be exponential
in the length of the text that you're trying to generate. This is why you never see the monkeys
create Hamlet. You can maybe see them create a four-letter word, but nothing that big. I personally
find once you finalize an infinite statement, it does become much more intuitive and it's no longer
so weird. So even if you're working with infinity, it's good to finalize so that you can
have some intuition. Yeah. The downside is that the finalized
proofs are just much, much messier. So the infinite ones are found first, usually like decades earlier,
and then later on people finalize them. So since we mentioned a lot of math and a lot of physics,
what is the difference between mathematics and physics as disciplines, as ways of understanding,
of seeing the world? Maybe we can throw an engineering in there. You mentioned your wife
is an engineer and give it a new perspective on circuits. So there's a different way of looking
at the world, given that you've done mathematical physics, so you've worn all the hats.
Right. So I think science in general is interaction between three things. There's the real world,
the real world, our observations, and then our mental models as to how we think the world works.
So we can't directly access reality. All we have are the observations, which are incomplete and they
have errors. And there are many, many cases where we want to know, for example, what is the weather
like tomorrow? And we don't yet have the observation and we'd like to predict. And then we have these
simplified models, sometimes making unrealistic assumptions, you know, spherical cow type things.
Those are the mathematical models. Mathematics is concerned with the models. Science collects
the observations and it proposes the models that might explain these observations. What mathematics
does, we stay within the model and ask what are the consequences of that model? What observations,
what predictions would the model make of the future observations or past observations? Does it fit
observed data? So there's definitely a symbiosis. I guess mathematics is unusual among other disciplines
is that we start from hypotheses like the axioms of a model and ask what conclusions come out from that
model. In almost any other discipline, you start with the conclusions, you know, I want to do this.
I want to build a bridge. You know, I want to make money. I want to do this. Okay. And then you find the
paths to get there. There's a lot less sort of speculation about, suppose I did this, what would
happen? You know, planning and modeling. Speculative fiction maybe is one other place, but that's about
it actually. Most of the things we do in life is conclusions driven, including physics and science.
I mean, they want to know, you know, where is this asteroid going to go? You know, what is the
weather going to be tomorrow? But mathematics also has this other direction of going from the axioms.
What do you think? There is this tension in physics between theory and experiment.
What do you think is the more powerful way of discovering truly novel ideas about reality?
Well, you need both top down and bottom up. Yeah, it's a really interaction between all these things.
So over time, the observations and the theory and the modeling should both get closer to reality.
But initially, I mean, this is always the case, you know, they're always far apart to begin with.
But you need one to figure out where to push the other, you know. So if your model is predicting
anomalies that are not picked up by experiment, that tells experimenters where to look to find
more data, to refine the models. So it goes back and forth. Within mathematics itself, there's also
a theory and experimental component. It's just that until very recently, theory has dominated almost
completely. Like 99% of mathematics is theoretical mathematics. And there's a very tiny amount of
experimental mathematics. I mean, people do do it, you know, like if they want to study prime numbers
or whatever, they can just generate large data sets. So once we had computers, we began to do
it a little bit. Although even before, well, like Gauss, for example, he discovered, he conjectured the
most basic theorem in number theory, which is called the prime number theorem, which predicts how many
primes that are up to a million, up to a trillion. It's not an obvious question. And basically what he did
was that he computed, I mean, mostly by himself, but also hired human computers, people whose
professional job it was to do arithmetic, to compute the first hundred thousand primes or something,
and made tables and made a prediction. That was an early example of experimental mathematics.
But until very recently, theoretical mathematics was just much more successful. I mean, because doing
complicated mathematical computations, this was just not feasible until very recently.
And even nowadays, you know, even though we have powerful computers, only some mathematical things
can be explored numerically. There's something called the combinatorial explosion. If you want
us to study, for example, you want to study all possible subsets of numbers one to a thousand,
there's only one thousand numbers, how bad could it be? It turns out the number of different subsets
of one to a thousand is two to the power of one thousand, which is way bigger than any computer
can currently enumerate. There are certain math problems that very quickly become intractable to
attack by direct brute force computation. Chess is another famous example. The number of chess positions,
we can't get a computer to fully explore. But now we have AI, we have tools to explore this space,
not with 100% guarantees of success, but with experiment. We can empirically solve chess now.
For example, we have very, very good AIs that don't explore every single position in the game
tree, but they have found some very good approximation. And people are using actually
these chess engines to do experimental chess. They're revisiting old chess theories about,
oh, this type of opening, this is a good type of move, this is not. And they can use these chess
engines to actually refine, and in some cases overturn, um, um, conventional wisdom about chess.
And I do hope that, uh, that mathematics will have a larger experimental component in the future,
perhaps powered by AI. We'll of course talk about that, but in the case of chess, and there's a similar
thing in mathematics that I don't believe it's providing a kind of formal explanation of the
different positions. It's just saying which position is better or not that you can intuit as a human
being. And then from that, we humans can construct a theory of the matter. You've mentioned the Plato's
cave allegory. So in case people don't know, it's where people are observing shadows of reality,
not reality itself. And they believe what they're observing to be reality. Is that in some sense
what mathematicians and maybe all humans are doing is, um, looking at shadows of reality?
Is it possible for us to truly access reality?
Well, there are these three ontological things. There's actual reality, there's our observations,
and our, our models. Um, and technically they are distinct, and I think they will always be distinct.
Um, right. But they can get closer, um, over time. Um, you know, so, um, and the process of getting
closer often means that you're, you have to discard your initial intuitions. Um, so, um, astronomy provides
great examples, you know, like, you know, like an initial model of the world is flat because it
looks flat, you know, and, um, and that it's, and it's big, you know, and the rest of the universe,
the skies is not, you know, like the sun, for example, looks really tiny. Um, and so you start
off with a model, which is actually really far from reality. Um, but it fits kind of the observations
that you have. Um, you know, so, you know, so things look good, you know, but over time, as you make
more and more observations, bringing it closer to, to reality, um, the model gets dragged along with it,
you know, and so over time, we had to realize that the earth was round, that it spins,
it goes around the solar system, solar system goes on the galaxy, and so on and so forth,
and the sky's part of the universe is expanding. Um, expansions are self-expanding,
accelerating. And in fact, very recently in this year, I saw this, uh, even the acceleration of
the universe itself is, uh, this evidence that it's non-constant. And, uh, the explanation behind
why that is... It's catching up. Um, it's catching up. I mean, it's still, you know, the dark matter,
dark energy is this, this kind of thing. Yes. We have, we have a model that sort of
explains that fits the data really well. It just has a few parameters that, um, uh, you have to
specify. Um, but so, you know, people say, oh, that's fudge factors, you know, with,
with enough fudge factors, you can explain anything. Um, yeah, but, uh, the mathematical point
of the model is that, um, you want to have fewer parameters in your model than data points in your
observational set. So if you have a model with 10 parameters that explains 10 observations,
that is a completely useless model. It's what's called overfitted. But like, if you have a model
with, you know, two parameters and it explains a trillion observations, which is basically, uh,
so, uh, yeah, the, the dark matter model, I think it has like 14 parameters and it explains petabytes of
data, um, that, that, that the astronomers have. Um, you can think of a theory, uh, like one way to
think about, um, uh, physical mathematical theory, uh, theory is it's, it's a compression of the universe,
um, and, uh, data compression. So, you know, you have these petabytes of observations,
you'd like to compress it to a model, which you can describe in five pages and specify a certain
number of parameters. And if it can fit to reasonable accuracy, you know, almost all of
your observations, I mean, the more compression that you make, the better your theory.
In fact, one of the great surprises of our universe and of everything in it is that it's
compressible at all. That's the unreasonable effectiveness of mathematics.
Yeah. Einstein had a quote like that, the, the most incomprehensible thing about
the universe is that it is comprehensible. Right. And not just comprehensible,
you can do an equation like E equals MC squared. There is actually some mathematical possible
explanation for that. Um, so there's this phenomenon in mathematics called universality.
So many complex systems at the macro scale are coming out of lots of tiny interactions at the
macro scale. And normally because of the common form of explosion, you would think that, uh, the
macro scale equations must be like infinitely exponentially more complicated than, than the, uh, the
micro scale ones. And they are, if you want to solve them completely exactly. Like if you want to model,
um, all the atoms in a box of, of air, uh, that's like Avogadro's number is humongous, right? There's
a huge number of particles. If you actually have to track each one, it would be ridiculous. But certain
laws emerge at the microscopic scale that almost don't depend on what's going on at the macro scale,
or only depend on a very similar number of parameters. So if you want to model a gas, um,
of, you know, quintillion particles in a box, you just need to know its temperature and pressure and
volume and a few parameters, like five or six. And it models almost everything you need to know about
these 10 to 23 or whatever particles. Um, so we, we have, um, we, we don't understand universality
anywhere near as we would like mathematically, but there are much simpler toy models where we do, um,
have a good understanding of why universality occurs. Um, um, most basic one is, is the central
limit theorem that explains why the bell curve shows up everywhere in nature, that so many things
are distributed by what's called a Gaussian distribution, famous bell curve. Uh, there's
not even a meme with this curve. And even the meme applies broadly, the universality to the meme.
Yeah. Yes, you can go meta, uh, if you like, but there are many, many processes. For example,
you can take lots and lots of independent, um, random variables and average them together,
um, uh, in, in various ways. You can take a simple average or more complicated average,
and we can prove in various cases that, that these, these bell curves, these gaussians emerge. And
it is a satisfying, satisfying explanation. Um, sometimes they don't. Um, so, so if you have many
different inputs and they all correlated in some systemic way, then you can get something very
far from a bell curve show up. Uh, and this is also important to know when the situation fails.
So universality is not a 100% reliable thing to rely on at that, um, um,
that the global financial crisis was a famous example of this. Uh, people thought that, uh, um,
mortgage defaults, um, um, had this sort of, um, Gaussian type behavior that, that if you, if you
ask if a population of, of, uh, you know, a hundred thousand Americans with mortgages,
ask what, what proportion would default in the mortgages? Um, if everything was
decorrelated, it would be a nice bell curve. And like, you can, you can, you can manage risk
with options and derivatives and so forth. And, um, and it is a very beautiful theory. Um,
but if there are systemic shocks in the economy, uh, that can push everybody to default at the same
time, uh, that's very non-gassing behavior. Um, and, uh, this wasn't fully accounted for
in, uh, 2008. Um, now I think there's some more awareness that this is a systemic risk is actually a
much bigger issue. And, uh, just because the model is pretty, uh, and nice, uh, it may not match
reality. And so, so the mathematics of working out what models do is really important. Um, but, um,
also the, the science of validating when the models fit reality and when they don't, um, I mean that you
need both. Um, and, but mathematics can help because it can, for example, these central limit
theorems, it tells you that if you have certain axioms, like, like, like, uh, non-correlation,
that if all the inputs were not correlated to each other, um, then you have this Gaussian
behavior, so things are fine. It tells you where to look for weaknesses in the model. So
if you have a mathematical understanding of central limit theorem and someone proposes
to use these Gaussian copulas or whatever to model, um, default risk, um, if you're mathematically
trained, you would say, okay, but what are the systemic correlation between all your inputs?
And so then that, then you can ask the economists, you know, how, how, how much risk is that? Um,
and then you can, you can, you can go look for that. So there's always this, this, this synergy
between science and mathematics. A little bit on the topic of universality.
You're known and celebrated for working across an incredible breadth of mathematics, reminiscent of
Hilbert a century ago. In fact, the great fields medal winning mathematician Tim Gowers has said that
you are the closest thing we get to Hilbert, uh, he's a colleague of yours, um, but anyway, so you are
known for this ability to go both deep and broad in mathematics. So you're the perfect person to ask,
do you think there are threads that connect all the disparate areas of mathematics? Is there a kind of
deep underlying structure, uh, to all of mathematics? There's certainly a lot of connecting threads, um,
and a lot of the progress of mathematics has, can be represented by taking by stories of two fields of
mathematics that were previously not connected and finding connections. Um, an ancient example is, um,
geometry and number theory. You know, so, so in the times of the ancient Greeks, these were considered
different subjects. Um, I mean, mathematicians worked on both, you know, Euclid, uh, work both
on geometry most famously, but also on numbers. Um, but they were not really considered related.
Um, I mean, a little bit like, you know, you could say that this length was five times this length
because you could take five copies of this length and so forth, but it wasn't until Descartes who really
realized that, uh, to develop analytical analytical geometry that you can, you can parameterize the plane,
a geometric object by, um, by two real numbers. Every point can be, and so geometric problems can
be turned into, into problems about numbers. Um, and today this feels almost trivial. Like,
there's like, there's, there's, there's no content to this. Like, of course, uh, you, you know, um,
a plane is X, X, and Y, and of course, that's what we teach and it's internalized. Um, but it was an
important development that these, these two fields are, uh, were unified. Um, and this process has
just, it's just gone on throughout mathematics over and over again. Algebra and geometry were
separated and now we have this through algebraic geometry that connects them and over and over
again. And that's certainly the type of mathematics that I enjoy the most. So I think there's sort of
different styles to being a mathematician. I think hedgehogs and fox, a fox knows many things a little
bit, but a hedgehog knows one thing very, very well. Um, and in mathematics, there's definitely both
hedgehogs and foxes. Um, and then there's people who are kind of, uh, who can play both roles.
Um, and I think ideal collaboration between mathematicians involves very, you need some
diversity, like, um, a fox working with many hedgehogs or vice versa. So, yeah, but I identify
mostly as a fox. Uh, certainly I, I, I like, uh, arbitrage somehow, you know, like, like, um,
learning how one field works, learning the tricks of that wheel, and then going to another field,
which people don't think is related, but I can, I can adapt the tricks.
So see the connections between the fields.
Yeah. Yeah. So there are other mathematicians who are far deeper than I am. Like, they're
really hedgehogs. They know everything about one field and they're much faster and, and, and more
effective in that field, but I can, I can give them these extra tools.
I mean, you've said that you can be both a hedgehog and, and the fox, depending on the context,
depending on the collaboration. So what can you, if it's at all possible, speak to the difference
between those two ways of thinking about a problem, say you're encountering a new problem,
you know, searching for the connections versus like very singular focus.
I'm much more comfortable with, with the, uh, the, uh, the fox paradigm. Yeah. So, um,
yeah, I, I like looking for analogies, narratives. Um, I, I spend a lot of time. If there's a result,
I see it in one field and I like the result, it's a cool result, but I don't like the proof.
Like it uses types of mathematics that I'm not super familiar with. Um, I often try to reprove
it myself using the tools that I favor. Um, of my proof is worse. Um, but, um, by the exercise of
doing so, um, I can say, oh, now I can see what the other proof was trying to do. Um, and from that,
I can get some understanding of, of the tools that are used in, in that field. So it's very exploratory,
very doing crazy things in crazy fields and like reinventing the wheel a lot. Yeah. Whereas
some of the hedgehog style is, uh, I think much more scholarly, you know, you, you, you're very
knowledge-based you, you, you, you stay up to speed on like all the developments in this field. You,
you know, all the history, um, you have a very good understanding of, of exactly the strengths and
weaknesses of, of each particular technique. Um, yeah, uh, I think you, you'd rely a lot more on sort
of calculation than sort of trying to find narratives. Um, so yeah, I mean, I could do
that too, but, uh, there are other people who are extremely good at that. Let's step back and, uh,
maybe look at the, the, a bit of a romanticized version of mathematics. So, uh, I think you've
said that early on in your life, uh, math was more like a puzzle solving activity when you were,
uh, young, when did you first encounter a problem or proof where you realize math can
have a kind of elegance and beauty to it?
That's a good question. Um, when I came to graduate school, uh, in Princeton, um, so John Conway was there
at the time he passed away a few years ago, but, uh, I remember one of the very first research talks
I went to was a talk by Conway on what he called extreme proof. So Conway had just had this amazing
way of thinking about all kinds of things in a, in a way that you wouldn't normally think of. So,
um, he thought of proofs themselves as occupying some sort of space, you know, so, so, um, if you want
to prove something, let's say that there's infinitely many primes, okay, there will be different proofs,
but you could, you could rank them in different axes. Like some proofs are elegant, some proofs are long,
some proofs are, um, are elementary and so forth. Um, and so this is cloud. So the space of all proofs
itself has some sort of shape. Um, and so he was interested in, in extreme points of this shape,
like out of all, all these proofs, what is one of those, the shortest at the expense of everything,
everything else, or, or the most elementary or, or whatever. Um, and so he gave some examples of
well-known root theorems, and then he would give what he thought was, was the extreme proof, um, in
these different aspects. Um, um, I, I just found that really eye-opening, um, that, that, um, you
know, it's, it's not just getting a proof for a result was interesting, but, but once you have
that proof, you know, trying to, to, uh, to optimize it in various ways, um, that, that proof, um, uh,
proofing itself had some craftsmanship to it. Um, it's something for my writing style, um, that,
you know, like when you do your, your math assignments and as your undergraduate, your
homework and so forth, you, you're sort of encouraged to just write down any proof that
works. Okay. And they hand it in and get a, get, as long as it gets a tick mark, you, you move on.
Um, but if you want your, your, your results to actually be influential and be read by people,
um, it can't just be correct. It should also, um, be a pleasure to read, you know, um, motivated, um,
be adaptable to, to generalize to other things. Um, it's the same in many other disciplines,
like, like coding, isn't it? There's a, uh, there's a lot of analogies between math and coding.
I like analogies if you haven't noticed. Um, but, um, you know, like you can code something
spaghettico that works for a certain task and it's quick and dirty and it works, but, uh, there's lots
of good principles for, for, um, writing, uh, code well so that other people can use it, build upon it
and so on and then has fewer bugs and whatever. Um, and there's similar things with mathematics.
So, yeah, the, first of all, there's so many beautiful things there and
college, one of the great minds, uh, in mathematics ever and computer science,
uh, just even considering the space of proofs and saying, okay, what does this space look like?
And what are the extremes? Uh, like you mentioned, coding is an analogy is interesting
because there's also this activity called the code golf. Oh yeah, yeah, yeah.
Which I also find beautiful and fun, uh, where people use different programming languages to try
to write the shortest possible program that accomplishes a particular task. Yeah.
And I believe there's even competitions on this. Yeah, yeah, yeah.
And, uh, it's also a nice way to stress test, not just the sort of the programs or in this case,
the proofs, but also the different languages. Maybe that's a different notation or whatever
to use to accomplish a different task. Yeah.
You learn a lot. I mean, it may seem like a frivolous exercise, but it can generate all
these insights, which if you didn't have this artificial, um, objective to, to pursue, you,
you might not see. What do you use the most beautiful or elegant equation in mathematics?
I mean, one of the things that people often look to in beauty is the simplicity. So if you look at E
equals MC squared, so when, when a few concepts come together, that's why the Euler identity is often
considered, uh, the most beautiful equation in mathematics. Do you, do you find beauty in that
one in the oil identity? Yeah. Well, as I said, I mean, what I find most appealing is, is connections
between different things that you, um, so the, if you, uh, E to pi i equals minus one. Um, so yeah,
people will always use all the fundamental constants. Okay. That, that's, I mean, that's cute. Um,
but, but to me, so the exponential function was interested by Euler to measure exponential growth,
you know, so the compound interest or decay, you know, anything which is continuously growing,
continuously decreasing growth and decay or dilation or contraction is modeled by the exponential
function. Um, whereas pi, uh, comes around from circles and rotation, right? If you want to rotate
a needle, for example, 100 degrees, uh, you need to rotate by pi radians. And i, complex numbers,
represents the swapping between you and imaginary axes, so a 90 degree rotation, so a change in
direction. So the exponential function represents growth and decay in the direction that you already
are. Um, when you stick an eye in the exponential, it, it, it, it, now it's, it's, instead of motion
in the same direction as your current position, it's the motion as a right angle as your current position,
so rotation. Um, and then, so E to pi i equals minus one tells you that if you rotate for time pi,
you end up at the other direction. So it unifies geometry through dilation and exponential growth,
or dynamics, through this act of, of complexification, rotation by, by, by i. So it, it connects together
all these sorts of mathematics, you know, yeah, dynamics, geometry, and complex, and complex, and, um,
the complex numbers, they're all considered almost, yeah, they're all next door neighbors in
mathematics because of this identity. Do you, do you think the thing you mentioned is cute, the, the,
the collision of notations from these disparate fields, um, is just a frivolous
side effect, or do you think there is legitimate, like, value in when the notation, all the, our old
friends come together, right? Well, it's, it's, it's confirmation that you have the right concepts.
Um, so when you first study anything, um, you, you have to measure things and give them names. Um,
and initially sometimes you're, because your, your model is getting too far off from reality,
you give the wrong things, the best names, and you only find out later what's, what's really important.
Physicists can do this sometimes. I mean, but it turns out, okay.
So actually with physics, so E equals mc squared, okay. So, uh, one of the, the big things was the E,
right? So when, when Aristotle first came up with his thoughts of, of motion, and then, and then, um,
Galileo and Newton and so forth, you know, they saw the things they could, they could measure.
They could measure mass and acceleration and force and so forth. And so, Newtonian mechanics,
for example, I think it was MA was the famous, uh, Newton's second law of motion. So those were the,
the primary objects. So they gave them the central billing in the theory.
It was only later after people started analyzing these equations that there always seemed to be
these quantities that were conserved. Um, so in particular momentum and energy, um, uh,
and it's not obvious that things happen in energy. Like it's not something you can directly measure
the same way you can measure mass and, and, and velocity and so forth. But over time,
people realized that this was actually a really fundamental concept. Hamilton eventually in 19th
century reformulated Newton's laws of physics into what's called Hamiltonian mechanics,
where the energy, which is now called the Hamiltonian was the dominant object. Once
you know how to measure the Hamiltonian of any system, you can describe completely the dynamics,
like what, what happens to, to, to all the states. Like it's, um, it, it really was a central
actor, which was not obvious initially. Um, and this, uh, helped actually, uh, this change of perspective
really helped when quantum mechanics came along, uh, because, um, um, the early physicists who
studied quantum mechanics, they had a lot of trouble trying to adapt their Newtonian thinking
because, you know, everything was a particle and so forth to, to, to quantum mechanics, you know,
because I think because it was a wave, it just looked really, really weird. Um, like you ask,
what is the quantum vision if it was MA? And it's really, really hard to, to give an answer to that.
Um, but it turns out that the Hamiltonian, which was so, um, secretly behind the scenes in classical
mechanics also is the key, uh, object in, um, um, in quantum mechanics, that there's, there's also
an object called Hamiltonian. It's a different type of object. It's what's called an operator rather than,
than a function. But, um, and, um, but again, once you specify it, you specify the entire dynamics.
So there's something called Schrodinger's equation that tells you exactly how quantum systems evolve
once you have the Hamiltonian. So side by side, they look completely different objects, you know,
like one involves particles, one involves waves and so forth. But with this centrality, you could
start actually transferring a lot of intuition and facts from classical mechanics to quantum mechanics.
So, for example, in classical mechanics, there's this thing called Noether's theorem. Every time
there's a symmetry in a physical system, there was a conservation law. So the laws of physics are
translation invariant. Like if I move 10 steps to the left, I experience the same laws of physics as
if I was here. And that corresponds to conservation momentum. Um, if I turn around by some angle,
again, I experience the same laws of physics. Uh, this corresponds to the conservation angle of
momentum. If I wait for 10 minutes, um, I still have the same laws of physics. Um, so this time
transition invariance, this corresponds to the law of conservation of energy. Um, so there's this
fundamental connection between symmetry and conservation. Um, and that's also true in quantum mechanics,
even though the equations are completely different, but because they're both coming from the
Hamiltonian, Hamiltonian controls everything. Um, every time the Hamiltonian has a symmetry,
the equations will have a conservation law. Um, so it's, it's, it's, it's, it's, once you have the
right language, it actually makes things, um, a lot, a lot cleaner. One of the points is why we can't
unify quantum mechanics and general relativity yet. We haven't figured out what the fundamental
objects are. Like, for example, we have to give up the notion of space and time being these almost
Euclidean type spaces and it has to be, um, you know, and, you know, we kind of know that at very
tiny scales, uh, um, there's going to be quantum fluctuations, there's a space, space-time foam,
um, and trying to, to use Cartesian coordinates X, Y, Z is going to be, it's, it's just, it's, it's a non-starter,
but we don't know how to, what to replace it with. Um, we don't actually have the mathematical,
um, um, concepts, you know, the analog or the Hamiltonian that sort of organized everything.
Does your gut say that there is a theory of everything? So this is even possible to unify,
to find this language that unifies general relativity and quantum mechanics?
I believe so. I mean, the history of physics has been out of unification,
much like mathematics, um, over the years, you know, electricity and magnetism were separate
theories and then Maxwell unified them. You know, Newton unified the motions of the heavens for the
motions of objects on the earth and so forth. So it should happen. Uh, it's just that the, um,
uh, again, to go back to this model of the observations and theory, part of our problem
is that physics is a victim of its own success. That our two big theories of, of, of physics,
general relativity and quantum mechanics are so, are so good now. So together they cover 99.9% of
sort of all the observations we can make. Um, and you have to like either go to extremely insane
particle accelerations or, or the early universe or, or things that are really hard to measure,
um, in order to get any deviation from either of these two theories to the point where you can
actually figure out how to, how to combine them together. Um, but I have faith that we, you know,
we've, we've, we've been doing this for centuries and we've made progress before and there's no reason
why we should stop. Do you think you will be a mathematician that develops a theory of everything?
What often happens is that when the physicists need, uh, um, some theory of mathematics, there's
often some precursor that the mathematicians, um, worked out earlier. So when Einstein started
realizing that space was curved, he went to some mathematician and asked, you know, is there,
is there some theory of curved space that the mathematicians already came up with that could be
useful? And he said, oh yeah, there's a, I think Riemann came up with something. Um, and so, yeah,
Riemann had developed Riemann geometry, um, which is precisely, um, you know, a, a theory of
spaces that are curved in, in various general ways, which turned out to be almost exactly what was
needed, um, for Einstein's theory. This is going back to Wiggins' unreasonable effectiveness on
mathematics. I think the theories that work well to explain the universe tend to also involve the same
mathematical objects that work well to solve mathematical problems. Ultimately, they're just sort of
both ways of organizing data, um, in, in useful ways. It just feels like you might need to go some
weird land that's very hard to, to intuit. Like, you know, you have like string theory.
Yeah. That, that's, that was, that was a leading candidate for many decades. I think it's slowly
pulling out of fashion because it's, it's not matching experiment.
So one of the big challenges, of course, like you said,
is experiment is very tough because of the, how effective both theories are. But the other is like,
just, you know, you're talking about, you're not just deviating from space time. You're going into
like some crazy number of dimensions. You're doing all kinds of weird stuff that to us,
we've gone so far from this flat earth that we started at, like you mentioned.
Yeah. Yeah. Yeah. Yeah.
Now we're just, it's, it's very hard to use our limited
eight descendants of, uh, uh, cognition to intuit what that reality really is like.
This is why analogies are so important. You know, I mean, so yeah, the round earth is not intuitive
because we're stuck on it. Um, but you know, but you, you, you know, but round objects in general,
we have pretty good intuition over, uh, and we have interest about light works and so forth. And
like, it's, it's actually a good exercise to actually work out how eclipses and phases of the
sun and the moon and so forth can be really easily explained by, by, by, by round earth and round moon,
you know, um, and models. Um, and, and you can just take, you know, a basketball and a golf ball
and a, and, and a light source and actually do these things yourself. Um, so the intuition is
there. Um, but yeah, you have to transfer it. That is a big leap intellectual for us to go
to from flat to round earth because, you know, our life is mostly lived in flat land.
Yeah. To load that information. And we're all like, take it for granted. We take so many things
for granted because science has established a lot of evidence for this kind of thing, but
you know, we're in a round rock flying through space. Yeah. Yeah. That's a big leap. And you
have to take a chain of those leaps, the more and more and more we progress. Right. Yeah. So
modern science is maybe again, a victim of its own success is that, you know, in order to be more
accurate, it has to, to move further and further away from your initial intuition. And so, um, for
someone who hasn't gone through the whole process of science education, it looks more and more suspicious
because of that. So, you know, we, we, we need, we need more grounding. I mean, I think, um, I mean,
you know, there are, there are scientists who do excellent outreach. Um, but there's, there's,
there's, there's, there's, there's, there's lots of science things that you can do at home. There's
lots of YouTube videos. I did a YouTube video recently with Grant Sanderson. We talked about this
earlier that, uh, you know, how the ancient Greeks were able to measure things like the distance of the
moon, distance of the earth, and, you know, using techniques that you could also replicate yourself. Um, it doesn't all
have to be like fancy space telescopes and, and really intimidating mathematics.
Yeah, that's, uh, I highly recommend that. I believe you give a lecture and you also
did an incredible video with Grant. It's a beautiful experience to try to put yourself in the mind of a
person from that time shrouded in mystery. Right. You know, you're like on this planet, you don't know
the shape of it, the size of it. You see some stars, you see some, you see some things and you try to
like localize yourself in this world and try to make some kind of general statements about distance
to places. Change of perspective is really important. You see, travel burdens the mind.
This is intellectual travel, you know, put yourself in the mind of the ancient Greeks or, or some other
person, some other time period, make hypotheses, spherical cows, whatever, you know, speculate.
Um, and you know, this is, this is what mathematicians do and some sort of artists do actually.
It's just incredible that given the extreme constraints, you could still say
very powerful things. That's why it's inspiring looking back in history, how much can be figured
out when you don't have much to figure out stuff with. If you propose axioms, then the mathematics
lets you follow those axioms to their conclusions. And sometimes you can get quite a lot, quite a long
way from, you know, initial hypotheses. If we stay in the land of the weird,
you mentioned general relativity. You've, uh, you've contributed, uh, to the mathematical
understanding of Einstein's field equations. Can you explain this work? And, uh, from a sort of
mathematical standpoint, uh, what aspects of general relativity are intriguing to you, challenging to
you? I have worked on some equations. There's something called the wave maps equation, or the
sigma field model, which is not quite the equation of space-time gravity itself, but of certain fields that
might exist on top of space-time. Um, so Einstein's equations of relativity just describes space and
time itself. Um, but then there's other fields that live on top of that. Uh, there's the electromagnetic
field, um, there's things called Yang-Mills fields, and there's this whole hierarchy of different
equations of which Einstein is considered one of the most non-linear and difficult, but relatively low
on the hierarchy was this thing called the wave maps equation. So it's a wave which at any given
point, uh, is fixed to be like on a sphere. Um, so, uh, I can think of a bunch of arrows in space and
time, and, and, and, and yeah, so it's pointing in, in different directions. Um, but they propagate like
waves. If you, if you wiggle an arrow, it will propagate and create and make all the arrows move kind
of like, uh, sheaves of wheat in the wheat field. And I was interested in the global regularity problem
again for this question. Like, is it possible for, for all the energy here to collect at a point?
So the equation I considered was actually what's called a critical equation where it's actually
the behavior at all scales is roughly the same. Um, and I was able barely to show that, um,
that you couldn't actually force a scenario where all the energy concentrated at one point,
that the energy had to disperse a little bit, and the moment it disperse a little bit, it would,
it would, it would stay regular. Yeah, this was back in 2000. That was part of why I got interested
in Nary Soaks afterwards, actually. Yeah, so I developed some techniques to, um, to solve that problem.
So part of it, it was, um, this problem is really non-linear, uh, because of the curvature of the
sphere. Um, there's, there was a certain non-linear effect, which was a non-perturbative effect. It was,
when you sort of looked at it normally, it looked larger than the linear effects of the wave equation.
Um, and so it was hard to, to keep things under control, even when the energy was small.
But I developed what's called a gauge transformation. So the equation is kind of like an
evolution of, of, of heaves of wheat and they're all bending back and forth. And so there's a lot of
motion. Um, but like, if you imagine like stabilizing the flow by attaching little cameras
at different points in space, which are trying to move in a way that captures most of the motion
and under this sort of stabilized flow, the flow becomes a lot more linear. I discovered a way to
transform the equation to reduce the amount of non-linear effects. Um, and then I was able to, to,
to, to solve the equation. I found this transformation while visiting my aunt in
Australia and I was trying to understand the dynamics of all these fields. And I, I couldn't
do it with pen and paper. Um, and I had not enough facility of computers to do any computer simulations.
So I ended up closing my eyes on the floor and just imagining myself to actually be
the spectre field and rolling around to try to, to see how to change coordinates in such a way that
somehow things in all directions would behave in a reasonably linear fashion. And, uh, yeah,
my aunt walked in on me while I was doing that. And she was asking, what am I doing, doing this?
It's complicated. Yeah. Yeah. And okay, fine. You know, you're a young man. I don't ask questions.
I, I, I have to ask about the, you know, um, how do you approach solving difficult problems? What,
if it's possible to go inside your mind when you're thinking, are you visualizing
in your mind, the mathematical objects, symbols, maybe what are you visualizing in your mind?
Usually when you're thinking a lot of pen and paper, one thing you pick up as a mathematician
is sort of, uh, I call it cheating strategically. Um, so, uh, the, the, the beauty of mathematics is
that, is that you get to change the rule, change the problem and change the rules as you wish.
Uh, like this, you don't get to do this for any other field. Like, you know, if, if you're an engineer
and someone says, build a bridge over this, this river, you can't say, I want to build this
over here instead, or I want to put it out of paper instead of steel. Um, but a mathematician,
you can, you can do whatever you want. Um, it's, it's like trying to solve a computer game where you
can get this unlimited cheat codes available. Uh, and so, you know, you can, you can set this,
there's a dimension that's too large. I'll set it to one. I'd solve the one-dimensional problem
first. So there's a main term and an error term. I'm going to make a spherical car assumption.
I'll assume the error term is zero. And so the way you should solve these problems is,
is not in sort of this iron man mode where you make things maximally difficult. Um,
but actually the way you should, you should approach, um, uh, any reasonable math problem is that you,
if there are 10 things that are making it difficult, find a version of the problem that turns off nine
of the difficulties, but only keeps one of them. Um, and so that, um, and then that just figures. So
you, you, you, you install nine cheats. Okay. If you saw 10 cheats, then, then the game is trivial.
If you saw nine cheats, you solve one problem that, that, that, that, that teaches you how to
deal with that particular difficulty. And then you turn that one off and you turn someone else,
something else on, and then you solve that one. And after you, you know how to solve the 10 problems,
10 difficulties separately, then you have to start merging them a few at a time. Um, I, I, as a kid,
I watched a lot of these Hong Kong action movies, um, from a culture. Um, and, uh, one thing is that
every time it's a fight scene, you know, so maybe the hero gets swarmed by a hundred bad guy goons
or whatever, but it will always be choreographed. So that you'd always be only fighting one person at
a time and then it would defeat that person and move on. And, and because of that, they could,
they could defeat all of them. Right. But whereas if they had fought a bit more intelligently and
just swarmed the guy at once, uh, it would make for much, uh, much worse choreo, uh, cinema, but,
uh, but they would win. Are you usually, uh, pen and paper? Are you working, uh, with computer
and LaTeX? I'm mostly pen and paper actually. So in my office, I have four giant blackboards. Um,
and sometimes I just have to write everything I know about the problem on the four blackboards
and then sit my couch and just sort of see the whole thing. Is it all symbols like notation or is
there some drawings? Oh, there's a lot of drawing and a lot of bespoke doodles that,
uh, only make sense to me. Um, I mean, and, and that's the beauty of blackboards you raise and
it's very organic thing. Um, I'm beginning to use more and more computers, um, partly because
AI makes it much easier to do simple coding things that, you know, if I wanted to plot a function
before, which is moderately complicated as some iteration or something, you know, I'd have to, to
remember how to set up a Python program and, and, and, and, and how does a for loop work and, and, and
debug it and it would take in two hours and so forth. And, and now I can do it in 10, 15 minutes
as much. Um, yeah, I'm, I'm using more and more, uh, computers to do simple explorations.
Let's talk about AI a little bit if we could. So, um, maybe a good entry point is just talking about
computer assisted proofs in general. Can you describe the lean formal proof programming language and
how it can help as a proof assistant and maybe how you started using it and how, uh, it has helped
you. So, um, lean is a computer language, um, much like sort of standard languages like Python and C
and so forth, except that in most languages, the focus is on producing executable code lines of code
do things, you know, they, they flip bits or they make a robot move or, or they, they deliver you text
on the internet or something. Um, so lean is a language that can also do that. Uh, it can also
be run as a standard, uh, traditional language, but it can also produce certificates. So a software
language like Python might do a computation and give you the answer is seven. Okay. Then it does the sum
of three plus four is equal to seven, but, uh, lean can produce not just the answer, but, but a proof
that, uh, how it got the, the answer of seven as three plus four, uh, and all the steps involved in,
in, in, in, in, um, so it's, it creates these more complicated objects, not just statements,
but statements with proofs attached to them. Um, and, um, every line of code is just a way of
piecing together previous statements to, to create new ones. So the idea is not new. These things are
called proof assistants. And so they provide languages for which you can create quite
complicated, um, intricate mathematical proofs. And, um, they produce these certificates that give a
100 percent, um, guarantee that your arguments are correct if you trust the compiler of lean,
but they made the compiler really small and you can, there are several different compilers available
for the same. For, um, can you give people some intuition about the, the difference between writing
on pen and paper versus using lean programming language? How hard is it to formalize statement?
So lean, a lot of mathematicians were involved in the design of lean. So it's, it's designed so that
um, individual lines of code resemble individual lines of ethical argument. Like you might want
to introduce a variable. You want to want to prove a contradiction. You, you know, um, um,
there are various standard things that you can do and, and it's, it's written. So ideally it should
like a one-to-one correspondence in practice. It isn't because lean is like explaining a proof to
extremely pedantic colleague who will, will point out, okay, did you really mean this? Like what,
what happens if this is zero? Okay. Um, did you, how do you justify this? Um,
so lean has a lot of automation in it, um, to try to, to, uh, to be less annoying. Um,
so for example, um, every mathematical object has to come with a type. Like if I, if I talk about x,
is x a real number or, um, a natural number or, or a function or something? Um, if you write things
informally, um, it's often in some context. You say, you know, um, clearly x is equal to, uh, let x be the sum of
y and z and y and z were every real number. So x should also be a real number. Um, so lean can do
a lot of that. Um, but every so often it says, wait a minute, uh, can you tell me more about what
this object is? Uh, what, what type of object it is? You have to think more, um, at a philosophical
level, not just sort of computations that you're doing, but sort of what each object actually, um,
is in some sense. Is he using something like LLMs to do, uh, the type inference or, like,
you match with a real number? It's, it's using much more traditional, what's called good old
fashioned AI. You can represent all these things as trees and there's always algorithm to match
one tree to another tree. So it's actually doable to figure out if something is a, a real number
or a natural number. Yeah. Every object sort of comes with a history of where it came from
and you can, you can kind of trace. Oh, I see. Um, yeah. So it's, it's, it's designed for reliability.
So, uh, modern AIs are not used in, it's a disjoint technology. People are beginning to use
AIs on top of Lean. So when a mathematician tries to program, um, improvement in Lean,
um, often there's a step, okay, now I want to use, um, the fundamental calculus, say, okay,
to do the next step. So the Lean developers have built this, this massive project called
Metholib, a collection of tens of thousands of useful facts about methodical objects. And
somewhere in there is the fundamental calculus, but you need to find it. So a lot, the bottleneck
now is actually lemma search. You know, there's a tool that, that you know is in there somewhere
and you need to find it. Um, and so you can, there are various search engines specialized for
Metholib that you can do. Um, but there's now these large language models that you can say,
um, I need the fundamental calculus at this point. And it was like, okay, um, uh, for example,
when I code, I have GitHub Copilot installed as a plugin to my IDE and it scans my text and it sees
what I need says, you know, I might even type it. Okay. Now I need to use the fundamental calculus.
Okay. And then it might suggest, okay, try this. And like maybe 25% of the time it works exactly.
And then another 10, 50% of the time, it doesn't quite work, but it's close enough that I can say,
oh yeah, if I just change it here and here, it will work. And then like half the time,
it gives me complete rubbish. Um, so, but people are beginning to use AIs a little bit on top. Um,
mostly on the level of basically fancy autocomplete, um, that, uh, you can type half of one
line of a proof and it will find, it will tell you. Yeah. But, but a fancy, especially fancy with
the sort of capital letter F is, uh, uh, remove some of the friction. Yeah. Mathematician might
feel when they move from pen and paper to formalizing. Yes. Yeah. So right now I estimate
that the effort, time and effort taken to formalize a proof is about 10 times the amount taken to write
it out. Yeah. So it's doable, but, uh, you don't, it's, it's annoying, but doesn't it like kill the
whole vibe of being a mathematician? Yeah. So, I mean, having a pedantic coworker,
right? Yeah. If, if that was the only aspect of it. Okay. But, um, okay. So there's some,
there's some cases where it's actually more pleasant to do things formally. So there was,
there was a theorem that formalized and there was a certain constant 12, um, that, that came out at,
um, in, in the final statement. And so this 12 had to be carried all through the proof. Um,
and like everything had to be checked that it goes, all the, all these other numbers that had to be
consistent with this final number 12. And then, so we wrote a paper through this theorem with this
number 12. And then a few weeks later, someone said, oh, we can actually improve this 12 to an
11 by reworking some of these steps. And when this happens with pen and paper, um, like every time you
change a parameter, you have to check line by line that every single line of your proof still works.
And there can be subtle things that you didn't quite realize some properties of the number 12 that
you didn't even realize that you were taking advantage of. So a proof can break down at a subtle
place. Um, so we had formalized the proof with this constant 12. And then when this, this new
paper came out, uh, we said, oh, let's, uh, so that took like three weeks to formalize and like 20
people to formalize this, this, this original proof. I said, oh, but now let's, let's, um, uh,
let's update the 12 to 11. And what you can do with lean. So you just, in your headline theorem,
you change your 12 to 11, you run the compiler and like off the thousands of lines of code you have,
90% of them still work. And there's a couple that are lined in red. Now I can't justify these steps,
but it immediately isolates which steps you need to change, but you can skip over everything,
which, which works just fine. Um, and if you program things correctly, um, with good programming
practices, most of your lines will not be read. Um, and there'll just be a few places where you,
I mean, if you don't hard code your constants, but you sort of, uh, um, um, you use smart tactics
and so forth, uh, you can, you can localize, um, the things you need to change to, to a very small,
um, period of time. So it's like within a day or two, we had updated our proof because this is
very quick process. You, um, you make a change. There are 10 things now that don't work for each
one. You make a change and now there's five more things that don't work, but, but the process converges
much more smoothly than with pen and paper. So that's for writing. Are you able to read it?
Like if somebody else has a proof, are you able to like, how, what's, what's the, uh, versus paper?
And yeah, so the proofs are longer, but each individual piece is easier to read. So, um,
if you take a math paper and you jump to page 27 and you look at paragraph six and you have a line
of, of, of text or math, I often can't read it immediately because it assumes various definitions,
which I have to go back and, and maybe on 10 pages earlier, this was defined. And this, um,
the proof is scattered all over the place and you basically are forced to read fairly sequentially.
Um, it's, it's not like say a novel where like, you know, in theory, you could open up a novel
halfway through and start reading. There's a lot of context, but when a proof and lean,
if you put your cursor on a line of code, every single object there, you can hover over it and
it would say what it is, where it came from, where the stuff is justified. You can trace things back
much easier than sort of flipping through a math paper. So one thing that lean really enables is
actually collaborating on proofs at a really atomic scale that you really couldn't do in the past.
So traditionally a pen and paper, um, when you want to collaborate with another mathematician,
um, either you do it at a blackboard where you, um, you can really interact,
but if you're doing it sort of by email or something, um, basically, yeah, you have to segment it.
So I'm going to, I'm going to finish section three, you do section four, but, uh, you can't really sort
of work on the same thing, uh, collaborative at the same time. But with lean, you can be trying to
formalize some portion of proof and say, Oh, I got stuck at line 67 here. I need to prove this thing,
but it doesn't quite work. Here's the, like the three lines of code I'm having trouble with. Um,
but because all the context is there, someone else can say, Oh, okay, I recognize what you need
to do. You need to apply this trick or this tool, and you can do extremely atomic level conversations.
So because of lean, I can collaborate, you know, with dozens of people across the world,
most of whom I don't have never met in person. Um, and I may not know actually even whether they're,
um, how reliable they are in, in, in their, um, um, in, in the proof they give me, but lean gives me a
certificate of, of, of trust. Um, so I can do, I can do trustless mathematics.
So there's so many interesting questions. There's one, you're, you're known for being a great collaborator.
So what is the right way to approach solving a difficult problem in mathematics when you're
collaborating? Are you doing a divide and conquer type of thing, or are you brains,
are you focused on a particular part and you're brainstorming?
David There's always a brainstorming process first. Yeah. So math research projects sort of
by their nature, when you start, you don't really know how to do the problem. Um, it's not like an
engineering project where somehow the theory has been established for decades and it's,
it's implementation is the main difficulty. You have to figure out even what is the right path.
Right. So, so this is what I said about, about cheating first, you know, um, it's like, um,
to go back to the bridge building analogy, you know, so first assume you have an infinite budget
and like unlimited amounts of, of, of workforce and so forth. Now, can you, can you build this bridge?
Okay. Okay. Now have an infinite budget, but only finite workforce, right? Now can you do that?
And so what, um, so, uh, I mean, of course, no, no engineer can actually do this because they have
fixed requirements. Yes. There's this sort of jam sessions always at the beginning where
you try all kinds of crazy things and you, you make all these assumptions that are unrealistic,
but you plan to fix later. Um, and you try to see if there's even some skeleton of an approach that
might work. Um, and then hopefully that breaks up the problem into smaller sub problems, which
you don't know how to do, but then you, uh, you focus on, on, on the sub ones. Uh, and sometimes
different collaborators are better at, at working on certain things. Um, so one of my themes I'm
known for is the theme of Ben Green, which is now called the Green Tau theorem. Um, it's a statement
that the primes contain authentic progressions of any event. So it was a modification of this
theorem already. And the way we collaborated was that Ben had already proven a similar
result for progressions of length three. Um, he showed that sets like the primes contain
lots and lots of progressions of length three, um, even, and even, um, subsets of the prime,
certain subsets do. Um, but his techniques only worked for, um, for length three
progressions. They didn't work for longer progressions. Um, but I had these techniques
coming from a gothic theory, which is something that I had been playing with and, and, uh, I knew
better than Ben at the time. Um, and so, um, if I could justify certain randomness properties of
some set relating to the primes, like there's, there's a certain technical condition, which if
I could have it, if Ben could supply me this fact, I could give, I could conclude the theorem.
But I, what I asked was a really difficult question in number theory, which, um, he said,
there's no way we can prove this. Can you, so he said, can you prove your part of the theorem
using a weaker hypothesis that I have a chance to prove it? And he proposed something which he could
prove, but it was too weak for me. Uh, I can't use this. Um, so there's this, there was this conversation
going back and forth. Um, different cheats too. Yeah. Yeah. Yeah. I want to cheat more.
He wants to cheat less. Yeah. Uh, but eventually we found a, a, a, a, a, a property, which A,
he could prove, uh, and B I could use. Um, and then we, we could prove our view. Uh, and, um, yeah,
so there's, there's, there's all kinds of dynamics, you know? I mean, it's, it's, it's every,
every, um, collaboration has a, has a, has some story. It's no two are the same.
And then on the flip side of that, like you mentioned with lean programming,
now that's almost like a different story because you can do, you can create, I think you've
mentioned a kind of a blueprint for a problem. And then you can really do a divide and conquer
with lean where you're working on separate parts and they're using the computer system
proof checker essentially to make sure that everything is correct along the way.
Yeah. So it makes everything compatible and, uh, yeah. And trustable. Um, yeah. So currently only a
few mathematical projects can be cut up in this way. At the current state of the art,
most of the lean activity is on formalizing proofs that have already been proven by humans.
A math paper basically is a boop, a blueprint in a sense. It is taking a difficult statement,
like big theorem and breaking up into a hundred little numbers. Um, but often not all written
with enough detail that each one can be sort of directly formalized. A blueprint is like a really
pedantically written version of a paper where every step is explained as much detail as possible.
And to try to make each step kind of self-contained, um, and, or depending on only a very specific
number of previous statements that have been proven so that each node of this blueprint graph that gets
generated can be tackled independently of all the others. And you don't even need to know how the
whole thing works. Um, so it's like a modern supply chain, you know, like if you want to create an
iPhone or some other complicated object, um, no one person can, can build a single object,
but you can have specialists who just, if they're given some widgets from some other company,
they can combine them together to form a slightly bigger widget.
I think that's a really exciting possibility because you can have,
if you can find problems that could be broken down this way, then you can have, you know,
thousands of contributors, right?
Yes, yes, yes.
So I told you before about the split between theoretical and experimental mathematics. And right now,
most mathematics is theoretical and only a tiny bit is experimental. I think the platform that lean
and other software tools, uh, so, um, GitHub and things like that, um, um, allow, uh, they will
allow experimental mathematics to be, to scale up, um, to a much greater degree than we can do now.
So right now, if you want to, um, um, do any mathematical exploration, uh, of some mathematical
pattern or something, you need some code to write out the pattern. And I mean, sometimes there are some
computer algebra packages that help, but often it's just one mathematician coding lots and lots of
Python or whatever. And because coding is such an error prone activity, it's not practical to allow
other people to collaborate with you on writing modules for your code. Because if one of the modules
has a bug in it, the whole thing is unreliable. Um, so it's, these are, uh, so you get these bespoke,
uh, spaghetti code written by non professional programmers, mathematicians, you know, and they're
clunky and, and, and slow. Um, and so because of that, it's, it's hard to, to really mass produce
experimental results. Um, but, um, yeah, but I think with lean, I mean, so I'm already starting
some projects where we are not just experimenting with data, but experimenting with proofs. So I have
this project called the Equational Theories Project. Basically we generated about 22 million little
problems in abstract algebra. Maybe I should back up and tell you what, what the project is. Okay.
So abstract algebra studies operations like multiplication and addition and their abstract
properties. Okay. So multiplication, for example, is commutative. X times Y is always Y times X,
at least for numbers. Um, and it's also associative. X times Y times Z is the same as X times Y times Z.
Um, so, um, these operations obey some laws that don't obey others. For example, X times X is not
always equal to X. So that law is not always true. So given any, any operation, it obeys some laws and
not others. Um, and so we generated about 4,000 of these possible laws of algebra that certain
operations can satisfy. And our question is, which laws imply which other ones? Um, so for example,
does commutativity imply associativity? And the answer is no, because it turns out you can describe
an operation which obeys the commutative law, but doesn't obey the associative law.
So by producing an example, you can, you can show that commutativity does not imply associativity,
but some other laws do imply other laws by substitution and so forth. Uh, and you can write
down some, some algebraic proof. So we look at all the pairs between these 4,000 laws, and there's
about 22, 22 million of these pairs. And for each pair, we ask, does this law imply this, um, law? If so,
give a, give, uh, give a proof. If not, give a counterexample. Um, so 22 million problems,
each one of which you could give to like an undergraduate algebra student, and they had
a decent chance of solving the problem. Although there are a few, at least 22 million, there are
like a hundred or so that are really quite hard. Okay. But a lot are easy. And the project was just
to, to work out, to determine the entire graph, like, like which ones imply which other ones.
That's an incredible project, by the way, such a good idea, such a good test of the very thing we've
been talking about on a scale that's remarkable.
Yeah. So it would not have been feasible. You know, I mean, the state of the art in the literature
was like, you know, 15 equations and sort of highly implied, that's sort of at the limit of what a
human with pen and paper can do. So you need to scale it up. So you need to crowdsource,
but you also need to trust all the, um, you know, I, I mean, no one person can check 22 million of
these groups. Okay. You need to be computerized. And so it only became possible with, with lean. Um,
we were hoping to use a lot of AI as well. Um, so the project is almost complete. Um, so all these
20 million, all but two had been settled. Um, and, uh, well, actually, and of those two,
uh, we have a pen and paper proof of the two, uh, and we were formalizing it. In fact, I was,
this morning I was working on finishing it. Um, so we're almost done on this. Um, it's incredible.
Yeah. How many people were able to get, uh, 50, um, which in mathematics is considered a huge number.
It's a huge number. That's crazy.
Yeah. So we're gonna have a paper of 50 authors, uh, and a big appendix of who contributed to what,
here's an interesting question, not to maybe speak even more generally about it.
When you have this pool of people, is there a way to, uh, organize the contributions by level of
expertise of the people or the contributors now? Okay. Uh, I'm asking a lot of pothead questions here,
but I am imagining a bunch of humans and maybe in the future, some AIs, can there be like an ELO
rating type of situation where like a gamification of this?
The beauty of, of these lean projects is that automatically you get all this data,
you know? So like, like everything's uploaded to this GitHub and GitHub tracks who contributed what.
Um, so you could generate statistics from, at any, at any later point in time, you could say,
oh, this person contributed, this made this many lines of code or whatever. I mean,
these are very crude metrics. Um, I would, I would definitely not want this to become like,
you know, part of your tenure review or something. Uh, um, but, um, I mean, I think already in, in,
in enterprise computing, right, people do use some of these metrics as part of, of the assessment of,
of, uh, performance of, of an employee. Um, again, this is the direction which is a bit scary for
academics to go down. We, we, we don't like metrics so much.
And yet academics use metrics. They just use old ones, number of papers.
Yeah. Yeah. Yeah. It's true. It's true that, yeah. I mean, um, it feels like this is a metric
while flawed is, is going in the more in the right direction, right? Yeah. It's interesting.
I mean, at least it's a very interesting metric. Yeah. I think it's interesting to study. I mean,
I think you can do studies of whether these are better predictors. Um, there's this problem called
Goodhart's law. If a statistic is actually used to incentivize performance, it becomes gamed. Um,
and then it is no longer a useful measure. Oh, humans always. Yeah. Yeah. No,
I mean, it's, it's rational. So what we've done for this project is, is self-report. So, um, there
are actually standard categories, um, from the sciences of what types of contributions people give.
So there's, there's a concept and validation and resources and, and, and, and coding and so forth.
Um, so we, we, we, there's a standard list of 12 or so categories. Um, and we just ask each
contributor to this big matrix of all the, of all the authors and all the categories just to tick the
boxes where they think that they contributed. Um, and just give a rough idea, you know, like,
oh, so you did some coding and, and, uh, and you provided some compute, but you didn't do any of the
pen and paper verification or whatever. And I think that that works out. Traditionally,
mathematicians just order alphabetically by surname. So we don't have this tradition as in the sciences of,
you know, lead author and second author and so forth, which we're proud of. You know,
we make all the authors equal status, but it doesn't quite scale to this size.
So a decade ago, I was involved in these things called polymath projects.
It was the crowdsourcing mathematics, but without the lean component. So it was limited by,
you needed a human moderator to actually check that all the contributions coming in were actually
valid. And this was a huge bottleneck actually. Um, but still we had projects that were, you know,
10 authors or so, but we had decided at the time, um, not to try to decide who did what, um,
but to have a single pseudonym. Um, so we created this fictional character called
DHJ polymath in the spirit of Bobaki. Bobaki is the pseudonym for a famous group of mathematicians
in the 20th century. But, um, and so the paper was also authored on the pseudonym. So none of us
got the author credit. Um, this actually turned out to be not so great for a couple of reasons.
So, so one is that if you actually wanted to be considered for tenure or whatever,
you could not use this paper in your, uh, uh, as you submitted as one of your publications,
because it was, you didn't have the formal author credit. Um, um, but the other thing that we've
recognized much later is that when people referred to these projects, they naturally refer to the most
famous person who was involved in the project. Oh, so this was Tim Gower's project. This was Terence
Tao's project and not mentioned the other 19 or whatever people that were involved.
Oh yeah. So we're trying something different this time around where we have, everyone's an author.
Um, but we will have an appendix with this matrix and we'll see how that works.
I mean, uh, so both projects are incredible. Just the fact that you're involved in such huge
collaborations, but I think I saw a talk from Kevin Buzzard about, uh, the lean programming languages
a few years ago. And you're saying that, uh, this might be the future of mathematics. And so it's
also exciting that you're embracing, uh, one of the greatest mathematicians, uh, in the world,
embracing this, what seems like the paving of the future of mathematics. Um, so I have to ask you
here about the integration of AI into this whole process. So DeepMind's alpha proof was trained
using reinforcement learning on both failed and successful formal lean proofs of IMO problems.
So this is sort of high level, high school. Oh, very high level. Yes.
Very high level, high school level mathematics problems. What do you think about the system?
And maybe what is the gap between this system that is able to prove the high school level
problems versus gradual level, uh, problems? Yeah. The difficulty increases exponentially with the,
the number of steps involved in the proof is a commentorial explosion, right? So the thing of
large language models is, is that they make mistakes. And so if your proof has got 20 steps
and your large language board has a 10% failure rate, um, at each step, um, of going in the wrong
direction, like, uh, it's just extremely unlikely to actually, uh, reach the end. Actually, uh, just to
take a small tangent here is how hard is the problem of mapping from natural language to the formal
program? Oh yeah. It's extremely hard. Actually. Um, natural language, you know, it's very fault
tolerant. Um, like you can make a few minor grammatical errors and a speaker in the second
language can get some idea of what you're saying. Um, yeah, but, but formal language. Yeah. You
know, if you get one little thing wrong, um, I think that the whole thing is, is, is nonsense. Um,
even formal to formal is, is, is very hard. There are different incompatible, um, uh, proof
of system languages. Uh, there's lean, but also cock and Isabel and so forth. And actually even converting from
a formal action, formal language, um, it's, uh, it's an unsolved, it's an unsolved problem.
That is fascinating. Okay. So, uh, but once you have an informal language, they're using,
um, their RL train model. So something, something akin to alpha zero that they used to go
to then try to come up with tools. They also have a model. I believe it's a separate model for
geometric problems. So what impresses you about the system and, um, what do you think is the gap?
Yeah. We talked earlier about things that are amazing over time become kind of normalized.
Um, so yeah, now somehow it's, oh, of course, geometry is a silver book problem.
Right. That's true. That's true. I mean, it's still beautiful.
Yeah, yeah, no, it's, it's, it's, it's a great work that shows what's possible. I mean, um, it's,
it, um, the approach doesn't scale currently. Yeah. Three days of Google's server is,
server time to sort of one, uh, high school math formula. This, this is not a scalable, uh,
prospect, um, especially with the exponential increase in, um, as, as the complexity, um,
increases, which mentioned that they got a silver medal performance, the equivalent of,
I mean, yeah, I mean, so first of all, they took way more time than was, uh, allotted. Um,
and they had this assistance where the, where the humans started helped by, by formalizing. Um,
but, uh, also they're giving us those full marks for the solution, which I guess is formally verified.
So I guess that that's, that's fair. Um, uh, um, there, there are efforts. There was,
there will be a proposal of at some point to actually have an, an AI math Olympiad,
where at the same time as the human contestants gets the, the actual Olympiad, um, problems,
the AIs will also be given the same problems, the same time period. Um, and the outputs will have
to be graded by the same judges. Um, um, and which means that will have to be written in natural language
rather than formal language. Oh, I hope that happens. I hope that this IMO happens. I hope,
I hope next one. It won't happen this IMO, the performance is not good enough in, in, in the time
period. And, and, uh, um, but there are smaller competitions, uh, you know, there are competitions
where the, the answer is a, is a number rather than a long form proof. Um, and that's, that's, um,
AI is actually a lot better at, um, problems where there's a specific numerical answer. Um,
cause it's, it's, it's easy to, to, to, uh, to reinforce, to reinforce some learning on it.
Yeah. You've got the right answer. You've got the wrong answer. Uh, it is, it's, it's a very clear
signal, but a long form proof either has to be formal and then the lean can give it thumbs up,
thumbs down or it's informal. Um, but then you need a human to create it to tell. Uh, and if you're
trying to do billions of, of reinforcement learning, um, you know, um, um, runs, you're not, you can't
hire enough humans to, uh, to grade those. Um, maybe it's already hard enough for, for the last
language was to do reinforcement learning on, on just the regular text that, that people get.
But now if you actually hire people, not just give thumbs up, thumbs down, but actually check
the output mathematically. Yeah. Uh, that's too expensive.
So if we, uh, just explore this possible future,
what, what, what is the thing that humans do that's most special in, um, in mathematics? So
that you could see AI, uh, not cracking for a while. So inventing new theories. So
coming up with new conjectures versus, uh, proving the conjectures, building new abstractions,
new representations, maybe, uh, an AI turner style with, uh, seeing new connections between
disparate fields. That's a good question. Um, I think the nature of what mathematicians do
over time has changed a lot. Um, you know, um, so a thousand years ago, mathematicians had to
compute the date of Easter, uh, and those really complicated, uh, calculations, you know, but it's
all automated, automated centuries. Uh, we don't need that anymore. You know, they used to navigate
to do spherical navigation, spherical trigonometry to navigate how to get from, from, um, the old
world to the new or something, uh, very complicated calculations. Again, we'd been automated. Um,
um, you know, even a lot of undergraduate mathematics, even before AI, um, like Wolfram
Alpha, for example, uh, it's, it's not a language model, but it can solve a lot of undergraduate
level math tasks. So on the computational side, verifying routine things, like having a problem
and, um, and say, here's a problem in partial differential equations. Could you solve it using
any of the 20 standard techniques? Um, and they say, yes, I've tried all 20. I hear that 100 different
permutations and, and here's my results. Um, and that type of thing, I think it will work very well.
Um, type of scaling to once you solve one problem to, to make the AI attack a hundred adjacent
problems. Um, the things that humans do still, so, so where the AI really struggles right now,
um, is knowing when it's made a wrong turn. Um, and it can say, oh, I'm going to solve this problem.
I'm going to split up this one into, um, into these two cases. I'm going to try this technique.
And, um, sometimes if you're lucky and it's a simple problem, it's the right technique and you solve
the problem. And sometimes it will get, it will have a problem. It would propose an approach
which is just complete nonsense. Um, and, but like, it looks like a proof. Um, so this is one
annoying thing about LLM-generated mathematics. So, um, yeah, we, we, we've had human-generated
mathematics that's very low quality. Um, uh, like, you know, submissions for people who don't have the
formal training and so forth. But if a human proof is bad, you can tell it's bad pretty quickly. It makes
really basic mistakes, but the AI-generated proofs, they can look superficially flawless.
Uh, and it's partly because that's what the reinforcement learning has actually trained
them to do, uh, to, to make things, to, to produce text that looks like, um, uh, what is correct,
which for many applications is good enough. Um, uh, so the errors often really subtle. And then when
you spot them, they're really stupid. Um, like, you know, like no human would have actually made that
mistake. Yeah. It's actually really frustrating in the programming context. Cause I, I program a lot and
yeah, when a human makes when a low quality code, there's something called code smell,
right? You can, you can tell, you can tell immediately, like there's signs, but with,
with AI-generate code and then you're right. Eventually you find an obvious dumb thing that
just looks like good code. Yeah. So, um, it's very tricky to, and frustrating for some reason to
have to work. Yeah. So the sense of smell, this is, this is one thing that humans have.
Um, and there's a metaphorical mathematical smell that, uh, this is not clear how to get the AI to
duplicate that. Eventually, um, I mean, so the, the way, um, alpha zero and so forth, they make
progress on go and, and chess and so forth. This is in some sense, they have developed a sense of
smell for go and chess positions, you know, that, that this position is good for white. That's good
for black. Um, they can't enunciate why, um, but just having that, that sense of smell lets them
strategize. So if AI's gained that ability to sort of assess a viability of certain proof strategies,
it says, so because I'm going to try to, to break up this problem into two small sub-tasks
and they can say, Oh, this looks good. The two tasks look like they're simpler tasks than, than your main
task. And they still got a good chance of being true. Um, so this is good to try or no, you've, you've
made the problem worse because each of the two sub-problems is actually harder than your original
problem, which is actually what normally happens if you try a random, uh, thing to try. You normally
actually, it's very easy to transform a problem into an even harder problem. Very rarely do you
transport a simpler problem. Um, yeah, so if they can pick up a sense of smell, then they could maybe
start competing with, uh, uh, human level mathematicians. So, so this is a hard question,
but not competing, but collaborating. Yeah. If, okay. Hypothetical. If I gave you an oracle
that was able to do some aspect of what you do and you could just collaborate with it. Yeah. Yeah.
Yeah. What would that oracle, what would you like that oracle to be able to do? Would you like it to,
uh, maybe be a verifier, like check do the codes, like you're yes. Uh, a professor towel. This is the
correct. This is a good, this is a promising fruitful direction. Yeah. Yeah. Yeah. Or, or would you like
it to, uh, generate possible proofs and then you see which one is the right one? Um, or would you like
it to maybe generate different representation, different, totally different ways of seeing
this problem? Yeah. I think all of the above, um, a lot of it is, we don't know how to use these tools
because it's, it's a paradigm that it's not, um, yeah, we have not had in the past assistants that
are competent enough to understand complex instructions, um, that can work at massive
scale, but are also unreliable. Uh, like it's, it's an interesting, uh, a bit unreliable in subtle ways
whilst we, whilst providing sufficiently good output. Um, it's an interesting combination. Um, you know,
I mean, you have, you have like graduate students that you work with who are kind of like this,
but not at scale. Um, you know, and, and, and we had previous software tools that, um, can work at
scale, but, but very narrow. Um, so we have to figure out how to, how to use, um, I mean, um, so Tim
Coward actually, you mentioned he actually foresaw like in 2000, he was envisioning what mathematics
would look like in, in actually two and a half decades. That's funny. Yeah. He, he wrote in his, in his,
his article, like a, a hypothetical conversation between a mathematical assistant of the future,
um, and himself, you know, trying to solve a problem and they would have to have a conversation.
Sometimes the human would propose an idea and the AI would, would evaluate it. And sometimes the AI
would propose an idea. Um, and, uh, and sometimes a competition was required and the AI would just go
and say, okay, I've, I've checked the 100 cases needed here. Or, um, uh, the first, uh, uh, you,
you said this is true for all N, I've checked the N up to 100, um, and it looks good so far,
or hang on, there's a problem at N equals 46. And so just a free form conversation where you
don't know in advance where things are going to go, but just based on, on, I think ideas could
be proposed on both sides, calculations could be proposed on both sides. I've had conversations
with AI where I say, okay, let's, we're going to collaborate to solve this math problem. And it's
a problem that I already know the solution to. So I try to prompt it. Okay. So here's the problem.
I suggest using this tool and it'll find this lovely argument using a completely different tool,
which eventually goes into the weeds and say, no, no, no, try using this. Okay. And
it might start using this and then it'll go back to the tool that I wanted to do before. Um,
and like you have to keep railroading it, um, onto the path you want. And I could eventually force it
to give the proof I wanted. Um, but it was like herding cats. Um, like, and the amount of personal
effort I had to take to not just sort of prompt it, but also check its output because it, a lot of what it
looks like it's going to work. I know there's a problem on nine 17 and basically arguing with it.
Um, like it was more exhausting than doing it, uh, unassisted. So like it, but that's the current
state of the art. I wonder if there's, there's a phase shift that happens to where it's no longer
feels like herding cats and maybe it'll surprise us how quickly that comes.
I believe so. Um, so in formalization, I mentioned before that it takes 10 times longer
to formalize a proof than to write it by hand with these modern AI tools. And also just better tooling.
The lean, um, um, developers are doing a great job adding more and more features and making it
user friendly. It's going on from nine to eight to seven. Okay. No big deal. But one day it will drop
below one. Um, and that's the phase shift because suddenly, um, it makes sense when you write a paper
to, to write it in lean first, uh, or through a conversation with AI, which is generally, um,
on the fly with you. And it becomes natural for journals to accept, uh, you know, maybe they'll
offer an expedite refereeing, you know, that if, if a paper has already been formalized in lean, um,
they'll just ask the referee to comment on, on the significance of the results and how it
connects to literature and not worry so much about the correctness. Um, because that's been certified.
Um, papers are getting longer and longer in mathematics and like it's harder and harder
to get good refereeing for, um, the really long ones, unless they're really important.
Uh, it is actually an, an issue which, and the formalization is coming in just the right time
for this to be. And the easier and easier it gets because of the tooling and all the other factors,
then you're going to see much more like math label grow potentially exponentially. It's a, it's a,
it's a, it's a virtuous, uh, cycle. Okay. I mean, one phase shift of this type that happened in the
past was, uh, the adoption of LaTeX. So, so LaTeX is this typesetting language that all
Massachusetts use now. So in the past, people use all kinds of word processors and typewriters and
whatever, but at some point LaTeX became easier to use than all other competitors. And that people
would just switch, you know, within a few years, like it was just a dramatic, um, phase shift.
Yeah. It's a wild out there question, but what, what year, how far away are we from
a, uh, AI system being a collaborator on a proof that wins the Fields Medal? So that level.
Okay. Um, well, it depends on the level of collaboration.
I mean, no, like it deserves to be, to get the Fields Medal. Like, so half and half.
Yeah. Already, like I could imagine if it was a metal winning paper, having some AI systems in
writing it, you know, uh, just, you know, like the autocomplete alone is already, I use it. Like
it speeds up my, my own writing. Um, um, like, you know, you, you, you can have a theorem and you
have a proof and the proof has three cases. And I, I write down the proof of the first case and the
autocomplete just suggests that now here's how the proof of the second case could work. And like,
it was exactly correct. That was great. Saved me like five, 10 minutes of, uh, of, of typing.
But in that case, the AI system doesn't get the Fields Medal.
No. Uh, are we talking 20 years, 50 years, a hundred years? What do you think?
Okay. Uh, so I, I, I gave a prediction in print, but so by 2026, which is now next year, um, there will
be math collaborations, you know, with AI. So not Fields Medal winning, but, but like actual research
level math. Like published ideas that are in part generated by AI.
Um, maybe not the ideas, but at least, uh, some of the computations, um, um, the
verifications. Yeah. I mean, that. Has that already happened?
That's already happened. Yeah. There are, there are problems that were solved, uh, by a complicated
process, conversing with AI to propose things and the human goes and tries it and it, and
the contract doesn't work. Um, but it was a different idea. Um, it it's, it's hard to disentangle exactly.
Um, there are certainly math results, which could only have been accomplished because there was a
math, math, human mathematician and an AI involved. Um, but it's hard to sort of disentangle credit.
Um, I mean, these tools, they, they do not, uh, replicate all the skills needed to do mathematics,
but they can replicate sort of some non-trivial percentage of them, you know, 30, 40%. So they can
fill in gaps. Um, you know, so, uh, coding is, is, is a, is a good example, you know? So I, I, um, um,
it's annoying for me to, to code in Python. I'm not, I'm not a native, um, no professional, um,
programmer. Um, but, um, the, with AI that the, the, the friction cost of, of doing it is, is much reduced.
Uh, so it, it fills in that gap for me. Um, AI is getting quite good at literature review. Um, I mean,
there's still a problem with, um, hallucinating, you know, the references that don't exist.
Um, but this I think is a silverware problem. Uh, if you train in the right way and so forth,
you can, you can, and, um, and verify, um, you know, using the internet, um, you, you know,
um, you, um, you should in a few years get the point where you, you have a, a lemma that you need
and, uh, say, has anyone proven this lemma before? And we will do basically a fancy web search,
AI-assisted and say, yeah, yeah, there are these six papers where something similar has happened.
Uh, and I mean, you can ask me right now and we'll give you six papers of which maybe one
is legitimate and relevant. One exists, but it's not relevant and four are hallucinated. Um,
it has a non-zero success rate right now, but, uh, it's, there's so much garbage, uh, so much,
the signal noise ratio is so poor that it's, it's, um, it's most helpful when you already somewhat know
the literature. Um, and you just need to be prompted to be reminded of a paper that was
already subconsciously in your memory.
Versus helping you discover new, you were not even aware of, but is the correct citation.
Yeah, that's, yeah, that it can sometimes do, but, but when it does, it's, it's buried in,
in a list of options towards the other.
That are bad.
Yeah.
I mean, being able to automatically generate a related work section that is correct.
Yeah.
That's actually a beautiful thing that might be another phase shift because it assigns credit
correctly.
Yeah.
It does. It breaks you out of the silos of.
Yeah, yeah, yeah. No, I mean, yeah, no, there's a big hump to overcome right now.
I mean, it's, it's like self-driving cars, you know, the safety margin has to be really high
for it to be, um, uh, to be feasible. So yeah, so there's a last mile problem, um, with a lot of AI
applications, um, that, uh, you know, they can develop tools that work 20%, 80% of the time,
but it's still not good enough. Um, and in fact, even worse than good in some ways.
I mean, another way of asking the feels metal question is what year do you think
you'll wake up and be like real surprised? You read the headline, the news or something happened
that AI did like, you know, real breakthrough something. It doesn't, you know, like feels metal,
even hypothesis. It could be like really just this alpha zero moment would go that kind of thing.
Right. Um, yeah, this, this decade, I can, I can see it like making a conjecture between
two unrelated, two, two things that people thought was unrelated.
Oh, interesting. Generating a conjecture. That's a beautiful conjecture.
Yeah. And, and actually has a real chance of being correct and, and, and meaningful.
And, um, because that's actually kind of doable, I suppose, but the word of the data is,
yeah, yeah, no, that would be truly amazing.
Um, the current models struggle a lot. I mean, so, um, a version of this
is, um, I mean, the physicists have a dream of getting the AIs to discover new laws of physics.
Um, uh, you know, the, the dream is you just feed it all this data. Okay. Uh, and, and this is a,
here is a new patent that we didn't see before, but it actually even struggled. The current state
of the art even struggles to discover old laws of physics, um, from the data. I mean, uh, or if it does,
uh, there's a big concern of contamination that it did it only because like somewhere in this
training data, it is somehow new, um, you know, Boyle's law or whatever law you're trying to,
to, to reconstruct. Um, part of it is that we don't have the right type of training data for this.
Um, yeah. So for the laws of physics, like we, we don't have like a million different
universes with a million different laws of nature. Um, and, um, like a lot of what we're missing in
math is actually the negative space of, so we have published things of things that people have been
able to prove, um, and conjectures that ended up being verified, um, or maybe counterexamples
produced, but, um, we don't have data on, on things that were proposed and they're kind of a good thing
to try, but then people quickly realized that it was the wrong conjecture. And then they, they said,
oh, but we should actually change, um, our claim to modify it in this way to actually make it more
plausible. Um, there's this, there's a trial and error process, which is a real integral part of
human mathematical discovery, which we don't record because it's embarrassing.
Uh, we make mistakes and, and we only like to publish our, our wins. Um, and, uh, the AI has
no access to this data to train on. Um, I sometimes joke that basically, you know, AI has to go through,
um, a grad school and actually, you know, go to grad courses, do the assignments, go to office hours,
make mistakes, um, get advice on how to correct the mistakes and learn from that.
Let me, uh, ask you if I may about, uh, Grigori Perlman.
Mm-hmm.
You mentioned that you try to be careful in your work and not let a problem completely consume you.
Just, you've really fallen in love with the problem and really cannot rest until you solve it.
But you also hasted to add that sometimes this approach actually can be very successful.
An example you gave is Grigori Perlman who proved the Poincare conjecture and did so by working alone
for seven years with basically little contact with the outside world. Can you explain this one
millennial prize problem that's been solved, Poincare conjecture, and maybe speak to the journey that
Grigori Perlman's been on?
All right. So it's, it's a question about curved spaces. Earth is a good example. So Earth can
think it was a 2D surface. And just to be round, it could maybe be a torus with a hole in it or kind
of many holes. And there are many different topologies, a priori, that, that a surface could
have. Um, even if you assume that it's, it's bounded and, and, uh, and smooth and so forth.
So we've, we have figured out how to classify surfaces. As a first approximation, uh, everything
is determined by something called the genus, how many holes it has. So a sphere has genus zero,
a donut has genus one and so forth. And one way you can tell these surfaces apart, probably the
sphere has, which is called simply connected. If you take any closed loop on the sphere, like a big
closed loop of rope, you can contract it to a point and while staying on the surface. And the sphere has
this property, but a torus doesn't. And if you're on a torus and you take a rope that goes around,
say the, the outer diameter torus, there's no way it can't get through the hole. There's no way to
contract it to a point. So it turns out that the, this, the sphere is the only surface with this
property of contractibility, I mean, up to like continuous deformations of the sphere. So, um,
so things that are what I call topologically, um, equivalent of the sphere. So Poincare asked the
same question in higher dimensions. Um, so this, it becomes hard to visualize, uh, because, um, surface
you can think of as embedded in three dimensions, but as a curved free space, we don't have good intuition
of four D space to, to, to limit it. And then there are also three D spaces that can't even
fit into four dimensions. You need five or six or, or higher. But anyway, uh, mathematically,
you can still pose this question that if you have a bounded three dimensional space now,
which is also has this simply connected property that every loop can be contracted. Can you turn it
into a three dimensional version of the sphere? And so this is the Poincare conjecture. Weirdly,
in higher dimensions, four and five, it was actually easier. So, uh, it was solved first in higher
dimensions. There's somehow more room to do the deformation. It's easier to,
to, to move things around to your sphere, but three was really hard. So people tried many
approaches. There's sort of commentary approaches where you chop up the, the surface into little
triangles or tetrahedra, and you, you just try to argue based on how the faces interact with each
other. Um, there were, um, algebraic approaches. Uh, there's, there's various algebraic objects,
uh, like things called the fundamental group that you can attach to these homology and cohomology and,
and, and, and all these very fancy tools. Um, they also didn't quite work. Um, but
Richard Hamilton's proposed a, um, partial differential equations approach. So you take,
um, you take, so the problem is that you're, so you have this object, which is sort of secretly a
sphere, but it's given to you in a, in a, in a, in a weird way. So it's like, I think of a ball
that's been kind of crumpled up and twisted, and it's not obvious that it's a ball. Um, but, um, like,
if you, if you, if you have some sort of surface, which is, which is a deformed sphere, you could,
um, uh, you could, for example, think of it as the surface of a balloon. You could try to inflate it.
You blow it up. Um, and naturally, as you fill it with air, um, the, the wrinkles will sort of smooth
out and it will turn into, um, um, a nice round sphere. Um, uh, unless of course it was a torus or
something in which case it would get stuck at some point. Like if you inflate a torus, there would,
there'd be a point in the middle. When the inner ring shrinks to zero, you get, you get a singularity,
and you can't blow up any further. Uh, you can't flow any further. So he created this flow,
which is now called Ritchie flow, which is a way of taking an arbitrary surface or space
and smoothing it out to make it rounder and rounder, to make it look like a sphere. And
he wanted to show that, that either, uh, this process would give you a sphere or it would create
a singularity. Um, I can very much like how PDs, either they have global regularity or finite and blow up.
I can basically, it's almost exactly exactly the same thing. It's all connected. Um,
and so, and, and he showed that for two dimensions, two dimensional surfaces,
um, uh, if you started something connected, no singularity is ever formed. Um, you, you never
ran into trouble and you could flow and it will give you a sphere. And it, so he, he got a new
proof of the two dimensional result. But by the way, that's a beautiful explanation
of Ritchie flow and its application in this context. How difficult is the mathematics here?
Like for the 2D case, is it? Yeah. These are quite sophisticated equations on par with the
Einstein equations that are slightly simpler, but, um, um, yeah, but, but they were considered
hard nonlinear equations to solve. Um, and there's lots of special tricks in 2D that, that, that helped.
But in 3D, the problem was that, uh, this equation was actually super critical. It has the same
problem as Navier-Stokes. As you blow up, um, maybe the curvature could get concentrated in
finer and smaller, smaller regions. And it, um, it looked more and more nonlinear and things just
look worse and worse. And there could be all kinds of singularities that showed up. Um, some
singularities, um, like if, uh, there's these things called neck pinches where, where the, uh,
the surface sort of behaves like a, like a, like a barbell and it, it, it pinches at a point. Some,
some singularities are simple enough that you can sort of see what to do next. You just make a snip
and then you can turn one surface into two and you build them separately. But there's, there was a,
the, the prospect that there's some really nasty, like knotted singularities showed up that you,
you couldn't see how to, um, resolve in any way, uh, that you couldn't do any surgery to.
Um, so you need to classify all the singularities, like what are all the possible ways that things
can go wrong. Um, so what Perlman did was, first of all, he, he made the problem, he turned the
problem from a supercritical problem to a critical problem. Um, I said before about how, um, the
invention of the, of, of energy, the Hamiltonian, like really clarified, um, Newtonian mechanics.
Um, uh, so he introduced, uh, something which is now called Perlman's reduced volume and Perlman's
entropy. Um, he introduced new quantities, kind of like energy that looked the same at every single
scale and turned the problem into a critical one where the nonlinearities actually suddenly
looked a lot less scary than they did before. Um, and then he had to solve, he still had to analyze
the singularities of this critical problem. Uh, and that itself was a problem similar to this
wave map thing I worked on actually. Um, so on the, on the level of difficulty of that,
so he managed to classify all the singularities of this problem and show how to apply surgery to
each of these. And through that was able to, to resolve the Poincare conjecture. So, um,
quite, uh, like a lot of really ambitious steps. Um, and like, like nothing that a large language
model today, for example, could, I mean, um, at best, uh, I could imagine a model proposing this
idea as one of hundreds of different things to try. Um, but the other 99 would be complete dead
ends, but you'd only find out after months of work. He must've had some sense that this was
the right track to pursue because it takes years to get them from A to B.
So you've done, like you said, actually, you see, even strictly mathematically, but
more broadly in terms of the process, you've done similarly difficult things. What, what can you infer
from the process he was going through? Cause he was doing it alone. What are some low points in a
process like that? When you start to like, you've mentioned hardship, like, uh, AI doesn't know
when it's failing. What happens to you? You're sitting in your office when you realize the thing
you did for the last few days, maybe weeks is a failure. Well, for me, I switched to different
problems. Uh, so, uh, I'm, I'm, I'm, I'm a fox. I'm not a hedgehog, but you'll do it. That is a
break that you can take is to step away and look at a different problem. Yeah. You can modify the
problem too. Um, I mean, um, yeah, you can ask them if, if there's a specific thing that's blocking
you at that, that just, um, some bad case keeps showing up that, that, that for which your tool
doesn't work, you can just assume by fiat, this, this bad case doesn't occur. So you, you do some
magical thinking, um, for the, but, but strategically, okay. For the point to see if the rest of the
argument goes through, um, if there's multiple problems, uh, with, with, with your approach,
then maybe you just give up. Okay. But if this is the only problem that, you know, then everything
else checks out, then it's still worth fighting. Um, so yeah, you have to do some, some sort of
forward reconnaissance sometimes to, uh, you know, and that is sometimes productive to assume like,
okay, we'll figure it out. Oh yeah. Yeah. Eventually. Um, sometimes actually it's even
productive to make mistakes. So, um, one of the, I mean, um, there was a project which actually,
uh, we won some prizes for it, uh, I mean, uh, before other people, um, we worked on this PD
problem again, actually this blow off regularity type problem. Um, and it was considered very hard.
Um, Jean Bougain, um, uh, who was another fields methodist who worked on a special case of this,
but he could not solve the general case. Um, and we worked on this problem for two months
and we found, we thought we solved it. We, we had this, this cute argument that if everything
fit and we were excited, uh, we were planning celebration, um, to all get together and have
champagne or something. Um, and we started writing it up. Um, and one of us, not me actually, but
another co-author said, oh, um, in this, in this lemma here, we, um, we have to estimate these 13
terms that show up in this expansion. And we estimated 12 of them, but in our notes, I can't
find the estimation of the 13th, can you? Can someone supply that? And I said, sure, I'll look at
this. And actually, yeah, we didn't cover that. We completely omitted this term. And this term
turned out to be worse than the other 12 terms put together. Um, in fact, we could not estimate this term.
Um, and we tried for a few more months, uh, and all different permutations. And there was always
this one thing, one term that we could not control. Um, and so like, um, this was very frustrating.
Um, but because we had already invested months and months of evidence already, um, we stuck at this.
We tried increasingly desperate things and crazy things. Um, and after two years, we found that
approach was somewhat different, but quite a bit from our initial, um, strategy, which did actually
didn't generate these problematic terms and, and actually solve the problem. So we solved the problem
after two years, but if we hadn't had that initial full storm of nearly solving a problem, we would
have given up by month two or something and, and worked on an easier problem. Um, yeah, if we had
known it would take two years, not sure we would have started the project. Yeah. Sometimes actually
having the incorrect, you know, it's like Columbus traveling to New World, they had an incorrect
version of measurement of the size of the earth. Um, he thought he was going to find a new trade
route to India, uh, or at least that was how he sold it in his prospectus. I mean, it could be that
he actually secretly knew, but just on a psychological element, do you have like emotional or
like self doubt that just overwhelms you moments like that, you know, cause this stuff, it feels like
math is, it's so engrossing that like it can break you when you like invest so much yourself in the
problem and then it turns out wrong. You could start to similar way chess has broken some people.
Yeah. Um, I, I think different mathematicians have different levels of emotional investment
in what they do. I mean, I think for some people it's just a job, you know, you, you have a problem
and if it doesn't work out, you, you go on the next one. Um, yeah. So the fact that you can always
move on to another problem, um, it reduces the emotional connection. I mean, there are cases,
you know, so there are certain problems that are what are called mathematical diseases where, where,
where just latch onto that one problem and they spend years and years thinking about nothing but that
one problem. And, um, you know, maybe their career suffers and so forth. They say, oh,
but I'll get this big win. This will, you know, once I, once I finish this problem, I will make up for
all the years of, of, of lost opportunity. And that's, that's, I mean, occasionally, occasionally
it works, but I, I, um, I really don't recommend it for people without the right fortitude. Yeah. So I,
I've never been super invested in any one problem. Um, one thing that helps is that we don't need to call
our problems in advance. Uh, um, well, uh, when we do grant proposals, uh, we sort of say we will,
we will study this set of problems, but even though we don't promise definitely by five years,
I will supply a proof of all these things, you know, um, you promise to make some progress or
discover some interesting phenomena, uh, and maybe you don't solve the problem, but you find some
related problem that you can say something new about. Uh, and that's, that's a much more feasible task.
But I'm sure for you, there's problems like this. You have, you have, um, made so much progress
towards the hardest problems in the history of mathematics. So is there, is there a problem
that just haunts you? It sits there in the dark corners, you know, twin prime conjecture,
Riemann hypothesis, global conjecture. Twin prime, that sounds, well, again, so, I mean,
the problem is like Riemann hypothesis. Those are so far out of reach. I, I, I, I, I, I,
do you think so? Yeah. There's no even viable strategy. Like, even if I activate all my,
all the cheats that I know of in this problem, like it, there's just still no way to give me
to be, um, like it's, it's, um, I think it needs a breakthrough in another area of mathematics to
happen first and for someone to recognize that that would be a useful thing to transport into this
problem. So we, we should maybe step back for a little bit and just talk about prime numbers.
Okay. So they're often referred to as the atoms of mathematics. Can you just speak to the structure
that these, uh, atoms provide? So the natural numbers have two basic operations attached to
some addition and multiplication. Um, so if you want to generate the natural numbers,
you can do one of two things to start with one and add one to itself over and over again. And that
generates you the natural numbers. So additively, they're very easy to generate one, two, three,
four, five, or you can take the prime number. If you want to generate multiplicatively,
you can take all the prime numbers, two, three, five, seven, and multiply them all together.
Um, and together that gives you all the, the natural numbers, except maybe for one.
So there are these two separate ways of thinking about the natural numbers from an added point of
view and a multiplicative point of view. Um, and separately, they're not so bad. Um, so like any
question about natural numbers that only involves addition is relatively easy to solve. And any question
that only involves multiplication is relatively easy to solve. Um, but what has been frustrating is that you
combine the two together, um, and suddenly you get an extremely rich, I mean, we know that there are
statements in number theory that are actually as undecidable. There are certain polynomials in some
number of variables. Is there a solution in the natural numbers? And the answer depends on, on an
undecidable statement, um, like, like whether, um, the axioms of mathematics are consistent or not.
Um, but, um, yeah, but even the, the simplest problems that combine something more applicative,
such as the primes with something additive, such as shifting by two, uh, separately, we understand
both from, well, but if you ask, when you shift the prime by two, do you, can you get up? How often
can you get another prime? We, it's been amazingly hard to relate the two. And we should say that the
twin prime conjecture is just that it posits that there are infinitely many pairs of prime numbers
that differ by two. Now, the interesting thing is that you have been very successful at pushing
forward the field and answering these complicated questions, uh, of this variety. Like you mentioned,
the green tile theorem, it proves that prime numbers contain arithmetic progressions of any length.
Right.
Which is mind blowing that you could prove something like that.
Right. Yeah. So what we've realized because of this, this type of research is that this different
patterns have different levels of, uh, interstructibility. Um, so, so what makes the
twin prime conjecture hard is that if you take all the primes in the world, you know, three, five,
seven, eleven, and so forth, there are some twins in there. Eleven and thirteen is a twin prime,
pair of twin primes and so forth, but you could easily, if you wanted to, um, redact the primes to
get rid of, to get rid of the, um, these twins. Like the twins, they show up and there are infinitely many
of them, but they're actually reasonably sparse. Um, not, there's, there's not, I mean, initially
there's quite a few, but once you got to the millions and trillions, they become rarer and
rarer. And you could actually just, you know, if, if someone was given access to the database of
primes, you just edit out a few primes here and there, they could make the twin prime conjecture
false by just removing like 0.01% of the primes or something. Um, just well chosen to, to, um, to do this.
And so you could present a censored database of the primes, which passes all of the statistical
tests of the primes, you know, that it obeys things like the prime number theorem and other
things about the primes, but it doesn't contain any twin primes anymore. Um, and this is a real
obstacle for the twin prime conjecture. It means that any proof strategy to actually find twin primes
in the actual primes must fail when applied to these slightly, um, edited primes. And so it must use
you some very, um, subtle, delicate feature of the primes that you can't just get from like,
like aggregate statistical analysis. Okay. So that's out. Yeah. On the other hand,
athletic progressions has turned out to be much more robust. Um, like you can take the primes and
you can eliminate 99% of the primes actually, you know, and you can take, take any 99% you want.
And, uh, it turns out, and another thing we proved is that you still get athletic progressions.
Um, athletic progressions are much, you know, they're like cockroaches.
Of arbitrary length though. Yes. Yes.
That's crazy. I mean, so, so this, uh, for, for people who don't know,
athletic progressions is a sequence of numbers that differ by some fixed amount.
Yeah. But it's again, like it's, it's an infinite monkey type phenomenon. For any fixed length of
your set, you don't get arbitrary lengths of progressions. You only get quite short progressions.
But you're saying twin primes is not an infinite monkey of phenomena. I mean,
it's a very subtle, it's still an infinite monkey phenomenon.
Right. Yeah. If the primes were really genuinely random, if the primes were generated by monkeys,
um, then yes, in fact, the infinite monkey theorem would.
Oh, but you're saying that twin prime is, it doesn't, you can't use the same tools.
Like the, it doesn't appear random almost.
Well, we don't know. Uh, yeah. We, we, we, we believe the primes behave like a random set.
And so the reason why we care about the Trimham conjecture is it's, it's a test case
for whether we can genuinely confidently say with, with 0% chance of error that the primes behave
like a random set. Okay. Random, yeah. Random versions of the primes we know contain twins.
Um, at least with, with, with 100% probability, uh, or probably tending to 100% as you go out
further and further. Um, yeah. So the prime is we believe that they're random. Um, the reason why
ethnic progressions are indestructible is that regardless of whether you're saying it looks
random or looks, um, structured, like periodic, in both cases, um, ethnic progressions appear,
but for different reasons. Um, and this is basically all the ways in which the thing,
there are many proofs of, of these sort of ethnic progression epithereums, and they're all proven by
some sort of dichotomy where your set is either structured or random. And in both cases,
you can say something and then you put the two together. Um, but in twin primes, if, if the primes
are random, then you're happy, you win. But if your primes are structured, they can be structured in,
in a specific way that eliminates the, the twins. Uh, and we can't rule out that one conspiracy.
And yet you were able to make a, as I understand, progress on the k-tuple version.
Right. Yeah. So, um, the, the one funny thing about conspiracies is that any one conspiracy theory
is really hard to disprove. Uh, that, you know, if you believe the world is run by, by lizards,
you say, here's some evidence that, that it, it, not run by lizards, but that, that evidence was
planted by lizards. Yeah. Right. Um, you may have encountered, uh, uh, this kind of phenomenon.
Yeah. So like, like, um, a pure, like there's, there's almost no way to,
um, definitively rule out a conspiracy. And the same is true in mathematics,
that a conspiracy that is solely devoted, devoted to eliminating twin primes, you know,
like you would, you would have to also infiltrate other areas of mathematics to sort of, but, but,
like you, it could be made consistent, at least as far as we know. But there's a weird phenomenon
that you can make one, um, uh, one conspiracy rule out other conspiracies. So, you know, if the,
if the world is run by lizards, they can't also be run by aliens. Right. Right.
So one unreasonable thing is, is, is, is, is hard to disprove, but, but more than one,
there are, there are tools. Um, so yeah, so for example, we, we know there's infinitely many primes
that are, um, uh, no two, which are, um, so the infinite pairs of primes which differ by at most,
uh, um, 246 actually is, is, is, is, is the code. So there's like a bound.
Yes. Right. So like there's twin primes, there's things called cousin primes that differ by, by four.
Um, there's things called sexy primes that differ by six. Uh, what are sexy primes?
Primes that differ by six. The name, the name is much less, it costs as much less exciting than
the name suggests. Got it.
Um, so you can make a conspiracy rule out one of these, but like, once you have like 50 of them,
it turns out that you can't rule out all of them at once. It just, it requires too much energy
somehow in this conspiracy space. How do you do the bound part? How do you,
how do you develop a bound for the difference between the primes that there's an infinite number
of? So it's ultimately based on, uh, what's called the pigeonhole principle. Um,
so the pigeonhole principle, uh, it's the statement that if you have a number of pigeons
and they all have to go into pigeonholes and you have more pigeons than pigeonholes,
then one of the pigeonholes has to have at least two pigeons in it. So there has to be two pigeons
that are close together. So for instance, if you have a hundred numbers and they all range from one
to a thousand, um, two of them have to be at most 10 apart because you can divide up the numbers from
one to a hundred into one hundred pigeonholes. Let's, let's say they have a hundred, if you have
101 numbers, 101 numbers, then two of them have to be, uh, distance less than 10 apart because two
of them have to belong to the same pigeonhole. So it's a basic, um, basic feature of, uh, a basic
principle in mathematics. Um, so it doesn't quite work with the primes already because the primes get
sparser and sparser as you go out, that fewer and fewer numbers are prime. But it turns out that
there's a way to assign weights to the, to, to numbers. Like, um, so there are numbers that are
kind of almost prime, uh, but they're not, they, they don't have no factors at all other than
themselves in one, but they have very few factors. Um, and it turns out that we understand almost
primes a lot better than we understand primes. Um, and so, for example, it was known for a long
time that there were twin almost primes, uh, this has been worked out. So almost primes are
something we can't understand. So you can actually restrict attention to a suitable set of almost primes
and, um, whereas the primes are very sparse overall, uh, relative to the almost primes,
they actually are much less sparse. They may, um, you can set up a set of almost primes where the
primes have density like say 1%. Um, and that gives you a shot at proving by applying some sort of
original principle that, that there's pairs of primes that are just only 100 apart. But in order to
prove the twin prime conjecture, you need to get the density of primes inside the almost primes up to,
up to a threshold of 50%. Um, once you get up to 50%, you will get twin primes.
But, uh, unfortunately there are barriers. Um, we know that, that no matter what kind of
good set of almost primes you pick, the density of primes can never get above 50%.
It's called the parity barrier. Um, and I would love to find, yeah, so one of my long-term
dreams is to find a way to breach that barrier. Because it would open up not only the twin
pump conjecture, the go back conjecture, and many other problems in number theory are currently
blocked because our current techniques would require improve, going beyond this theoretical,
parity barrier. It's like, it's like pulling past the speed of light.
Yeah. So we should say a twin prime conjecture, one of the biggest problems in the history of
mathematics, go back conjecture also. Um, they feel like next door neighbors. Uh,
is there been days when you felt you saw the path?
Oh yeah. Um, um, yeah. Uh, sometimes you try something and it works super well. Um, you, you,
again, again, the sense of mathematical smell, uh, we talked about earlier, uh, you learn from
experience when things are going too well, because there are certain difficulties that
you sort of have to encounter. Um, um, I think the way a colleague might put it is that, um,
you know, like if, if you are on the streets of New York and you put in a blindfold and you put
in a car and, and, uh, after some hours, um, you, the Bible is off and then you're in Beijing.
Um, you know, I mean, that was too easy somehow. Like, like there was no ocean being crossed.
Even if you don't know exactly what, how, what, what was done, uh, you're suspecting that
there's something that wasn't right. But is that still in the back of your head to,
do you return to these, to the prime, do you return to the prime numbers every once in a while to see?
Yeah. When I have nothing better to do, which is less and less than I have,
which is I get busy with so many things these days, but yeah, when I have free time and I'm not,
and I'm too frustrated to, to work on my sort of real research projects, and I also don't want to
do my administrative support. I don't want to do some errands with my family. Um, I can play with these,
these things, um, for fun. Uh, and usually you get nowhere. Yeah. Yeah. You have to learn to just
say, okay, fine. Once again, nothing happened. I will, I will move on. Um, yeah. Very occasionally,
one of these problems I actually solved, uh, or sometimes as you say, you think you solved it and
then you, you throw it for, uh, maybe 15 minutes and then you think I should check this because this
is too easy to be true. And it usually is. What's your gut say about when these problems would be,
uh, solved when prime and go back prime, I think we'll keep getting, keep getting more partial results.
Um, it doesn't need at least one, this parity barrier is, is the biggest remaining obstacle.
Um, there are simpler versions of conjecture where we are getting really close. Um, so I think we will,
in 10 years, we will have many more, much closer results. We may not have the whole thing.
Um, yeah. So turn primes is somewhat close. Yeah. Riemann hypothesis, I have no, I mean,
it has to happen by accident. I think, uh, so the Riemann hypothesis is a kind of more general
conjecture about the distribution of prime numbers, right? Right. Yeah. It's, it's, it's,
it's sort of viewed multiplicatively, like for, for questions only involving multiplication, no addition,
the primes really do behave as randomly as, as you could hope. So there's a phenomenon in
probability called square root cancellation that, um, you know, like if you want to poll,
say America upon some, some issue, um, and you, you ask one or two voters and you may have sampled
a bad sample and then you get, you get a really imprecise, um, measurement of the offer for average.
But if you sample more and more people, the accuracy gets better and better. And it actually
improves like the square root of the number of, of people you, uh, you sample. So yeah,
if you sample, um, a thousand people, you can get like a two, three percent margin error.
So in the same sense, if you measure the primes in a certain multiplicative sense,
there's a certain type of statistic you can measure. It's called the Riemann's data function
and it fluctuates up and down. But in some sense, um, as you keep averaging more and more,
if you sample more and more, the fluctuations should go down as if they were random.
And there's a very precise way to quantify that. And the Riemann hypothesis is a very elegant
way that captures this. But, um, as with many other ways in mathematics, we have very few tools to
show that something really genuinely behaves like really random. And this is actually not just a little
bit random, but it's, it's asking that it behaves as random as it actually random set. This, this,
this square root cancellation. And we know because of things related to the parity problem, actually,
that most of us, usual techniques cannot hope to settle this question. Um, the proof has to come out
of left field. Um, yeah, but, uh, what that is, yeah, no one has any serious proposal. Um, yeah, and there's,
there's various ways to sort of, as I said, you can modify the primes a little bit and you can destroy
the Riemann hypothesis. Um, so like it has to be very delicate. You can't apply something that has
huge margins of error. It has to just barely work. Um, and like, um, there's like all these pits,
pitfalls that you like dodge very adeptly.
Yeah. The prime numbers is just fascinating. Yeah. Yeah. Yeah. What, what to you is, um,
most mysterious about the prime numbers?
That's a good question. So like conjecturally, we have a good model of them. I mean, like, as I said,
I mean, they have certain patterns, like the primes are usually odd, for instance, but apart from these
obvious patterns, they behave very randomly and just assuming that they behave. So there's something
called the Kramer random model of the primes that, that, that after a certain point primes just behave
like a random set. Um, and there's various slight modifications to this model, but this has been a
very good model. It matches the numerics. It tells us what to predict. Like I can tell you with complete
certainty, the Trimprine conjecture is true. Uh, the random model gives overwhelming odds it is true.
I just can't prove it. Most of our mathematics is optimized for solving things with patterns in them.
Um, and the primes have this anti-pattern, um, as do almost everything really, but we can't prove that.
Yeah. I guess it's not mysterious at the primes being random. It's kind of random because there's
sort of no reason for them to be, um, uh, to have any kind of secret pattern, but what is mysterious
is what is the mechanism that really forces the randomness to happen. Uh, and this is just absent.
Another incredibly surprisingly difficult problem is the Collat's conjecture.
Oh yes. Simple to state, beautiful to visualize in its simplicity and yet extremely, uh, difficult
to solve. And yet you have been able to make progress. Uh, uh, Paul Urdar said about the
Collat's conjecture that mathematics may not be ready for such problems. Others have stated that it is an
extraordinarily difficult problem completely out of reach. This is in 2010 out of reach of present
day mathematics. And yet you have made some progress. Why is it so difficult to make?
Can you actually even explain what it is? Oh yeah. So it's, it's a, it's a problem that you can
explain. Um, yeah, it, um, it helps with some, um, visual aids, but yeah. So you take any natural
number, like say 13 and you apply the following procedure to it. So if it's even, you divide it by
two and if it's odd, you multiply it by three and add one. So even numbers get smaller, odd numbers get
bigger. So 13 will become 40 because 13 times three is 39. Add one to get 40. So it's a simple
process for odd numbers and even numbers. They're both very easy operations. And then you put it
together. It's still reasonably simple. Um, but then you ask what happens when you iterate it.
You take the output that you just got and feed it back in. So 13 becomes 40, 40 is now even divided by
two is 20, 20 is still even divided by two, 10, five, and then five times three plus one is 16. And then
eight, four, two, one. So, uh, and then from one, it goes one, four, two, one, four, two, one,
it cycles forever. So the sequence I just described, um, yeah, 13, 40, 20, 10, so both, uh, these are
also called hailstone sequences because there's an oversimplified model of, of hailstone formation,
which is not actually quite correct, but it's somehow taught to high school students as a first
approximation is that, um, like a little nugget of ice gets, gets a nice crystal forms and clouded.
It goes up and down because of the wind. And sometimes when it's cold, it requires a bit more
mass and maybe it melts a little bit. And this process of going up and down creates this sort of
partially melted ice, which eventually causes hailstone. And eventually it falls down to the
earth. So the conjecture is that no matter how high you start up, like you take a number,
which is in the millions or billions, this process that goes up, if you're odd and down,
if you're even, it eventually goes down to earth all the time.
No matter where you start with this very simple algorithm, you end up at one.
Right.
And you might climb for a while.
Right. Yeah. So it's, yeah, if you plot it, um, these sequences, they look like Brownian motion.
Um, they look like the stock market, you know, they just go up and down in a, in a seemingly random
pattern. And in fact, usually that's what happens that, that if you plug in a random number, you can
actually prove that at least initially that it would look like, um, a random walk. Um, and that's
actually a random walk with a downward drift. Um, it's like, if you're always gambling on a roulette
at, at the casino with odds slightly weighted against you. So sometimes you, you win, sometimes
you lose, but over in the long run, you lose a bit more than you win. Um, and so normally your wallet
will hit, will go to zero. Um, if you just keep playing over and over again.
So statistically it makes sense.
Yes. Yeah. So, so the result that I, I proved roughly speaking asserts that, that statistically
like 90% of all inputs would, would drift down to maybe not all the way to one, but to be much,
much smaller than what you started. So it's, it's like, if I told you that if you go to a casino,
most of the time you end up, if you keep playing it for long enough, you end up with a smaller
amount in your wallet than when you started. Um, that's kind of like the, what, the result that I
proved. So why is that result? Like, can you continue down that thread to prove the full
conjecture? Well, the, the problem is that, um, my, I used arguments from probability theory.
Um, and there's always this exceptional event. So, you know, so in probability, we have this,
this low, large numbers, um, which tells you things like if you play a casino with a, um,
a game at a casino with a losing, um, expectation over time, you are guaranteed or almost surely
with probably, probably as close to 100% as you wish, you're guaranteed to lose money.
But there's always this exceptional outlier. Like it is mathematically possible that even in the game
is, is the odds are not in your favor. You could just keep winning slightly more often than you lose.
Very much like how in Navier Stokes, there could be, you know, um, most of the time, um,
your waves can disperse. There could be just one outlier choice of initial conditions that would
lead you to blow up. And there could be one outlier choice of, um, um, a special number that you,
they stick in that shoots off infinity while all other numbers crash to earth, uh, crash to one.
Um, in fact, um, there's some mathematicians, um, who've, uh, Alex Kontorovich, for instance,
who've proposed that, um, that actually, um, these collapse, uh, iterations are like these cellular
automator. Um, uh, yeah, actually, if you look at what happened in binary, they do actually look a
little bit like, like these game of life type patterns. Um, and in an analogy to how the game
of life can create these, these massive like self-applicating objects and so forth, possibly
you could create some sort of heavier than air flying machine, a number, which is actually encoding
this machine, which is just whose job it is to encode is to create a version of itself, which is larger.
Yeah. Heavier than air machine encoded in a number. Yeah. That flies forever. Yeah. So Conway,
in fact, worked on, worked on this problem as well. Oh wow. So Conway, um, so similar, in fact,
uh, that was one of my inspirations for the Navi, Navi Stokes project, uh, Conway studied generalizations
of the collapse problem, where instead of multiplying by three and adding one or dividing by two, you have
more complicated branching wheels, but, but instead of having two cases, maybe you have 17 cases and then you
go up and down. And he showed that once your innovation gets complicated enough, you can
actually encode Turing machines and you can actually make these problems undecidable and do things like
this. In fact, he invented a programming language for, uh, these kind of fractional linear transformations.
He called a fact-trat as a play on Fortran. Uh, and he showed that, that you couldn't, um, you can
program this with Turing complete. You could, you could, you could, uh, um, you could make a program that if,
if your number you inserted in was encoded as a prime, it would sink to zero, it would go down.
Otherwise it would go up, uh, and things like that. Um, so the general class of problems is, is really,
uh, as complicated as all the mathematics. Some of the mystery of the cellular automata that we
talked about, uh, having a mathematical framework to say anything about cellular automata, maybe the
same kind of framework is required. Yeah. Yeah. Yeah. If you want to do it, not statistically,
but you really want 100, 100% of all inputs to, to, to for the earth. Yeah. So what might be feasible
is, is, is yeah, statistically 99%, you know, go to one, but like everything, you know, uh, that
looks hard. What would you say is out of these within reach famous problems is the hardest problem
we have today? Is it Riemann hypothesis? Riemann is up there. Um, Pico's MPs is a good one because like,
uh, that's, that's, that's a meta problem. Like if you solve that in the, um, in the positive sense
that you can find a Pico's MP algorithm, then potentially this solves a lot of other problems
as well. And we should mention some of the conjectures we've been talking about, you know,
a lot of stuff is built on top of them though. There's ripple effects. Pico's MP has more ripple
effects than basically any other. Right. If the Riemann hypothesis is disproven, um,
um, that'd be a big mental shock to the number theorists, uh, but it would have follow on effects
for, um, cryptography. Um, because a lot of cryptography uses number theory, um, uses number
theory constructions involving primes and so forth. And, um, it relies very much on the intuition
that number of those are built over many, many years of what operations involving primes behave
randomly and what ones don't. Um, and in particular encryption, um, methods are designed to turn
text with information on it into text, which is indistinguishable from, um, from random noise.
So, um, and hence we believe to be almost impossible to crack, um, at least mathematically.
Um, but, uh, if something as core to our beliefs as the Riemann hypothesis is wrong, it means that there
are actual patterns of the primes that we are not aware of. And if there's one, there's probably going
more, um, and suddenly a lot of our crypto systems are in doubt.
Yeah. But then how do you then say stuff about the primes?
Yeah.
Like you're going towards the collect conjecture again. Um, because if I, I, I, you, you want it
to be random, right? You want it to be random.
Yeah.
Yeah. So more broadly, I'm just looking for more tools, more ways to show that, that,
that things are random.
How do you prove a conspiracy doesn't happen, right?
Yeah.
Is there any chance to you that P equals NP? Is there some, can you imagine a possible universe?
It is possible. I mean, there's various, uh, scenarios. I mean, there's one where
it is technically possible, but in fact, it's never actually implementable. The evidence is
sort of slightly pushing in favor of, no, that we probably P is not equal to NP.
I mean, it seems like it's one of those cases seem more similar to Riemann hypothesis. I think
the evidence is leaning pretty heavily on the no.
It's certainly more on the no than on the yes. The funny thing about P equals NP is that we have
also a lot more obstructions than we do for almost any other problem. Um, so while there's evidence,
we also have a lot of results ruling out many, many types of approaches to the problem. Uh, this is
the one thing that the computer scientists have actually been very good at. It's actually saying that
certain approaches cannot work. No go theorems. It could be undecidable. We don't, yeah, we don't
know. There's a funny story. I read that when you won the fields metal, somebody from the internet
wrote you and asked, uh, you know, what are you going to do now that you won this prestigious award?
And then you just quickly, very humbly said that, you know, this, a shiny metal is not going to solve
any of the problems I'm currently working on. So I'm just, I'm going to keep working on them. It's just,
first of all, it's funny to me that you would answer an email in that context. And second of all,
it, um, it just shows your humility, but anyway, uh, maybe you could speak to the fields metal, but
it's another way for me to ask, uh, uh, about, uh, Gregorio Perlman. What do you think about
him famously declining the fields metal and the millennial prize, which came with a $1 million
of prize money? He stated that I'm not interested in money or fame.
The prize is completely irrelevant for me. If the proof is correct, then no other recognition is
needed. Yeah. No, he's, he's somewhat of an outlier, um, even among mathematicians who tend to, uh,
to have, uh, somewhat idealistic views. Um, I've never met him. I think I'd be interested to meet
him one day, but I never had the chance. I know people who met him, but he's always had strong
views about certain things. Um, I mean, it's not like he was completely isolated from the math community.
I mean, he would, he would give talks and write papers and so forth. Um, but at some point he
just decided not to engage with the rest of the community. He was, he was disillusioned
or something. Um, I don't know. Um, and he decided to, to, uh, uh, to peace out, uh, and, you know,
collect mushrooms in St. Petersburg or something. And that's, that's fine. You know, and you can,
you can do that. Um, I mean, that's another sort of flip side. I mean, we are not a lot of problems
that we solve, you know, but some of them do have practical application and that's, that's great.
But, uh, like if you stop thinking about a problem, you know, so he's, he hasn't published
since in this field, but that's fine. There's many, many other people who've done so as well.
Um, yeah. So I guess one thing I didn't realize initially with the Fields Medal is that it, it sort
of makes you part of the establishment. Um, you know, so, you know, most mathematicians here,
there's, uh, just career mathematicians, you know, you just focus on publishing your next paper,
maybe getting one, just to promote one, one rank, you know, and, and starting a few projects,
maybe taking some students or something. Yeah. But then suddenly people want your opinion on things
and, uh, you have to think a little bit about, uh, you know, things that you might just so foolishly
say because you know, no one's going to listen to you. Uh, it's more important now.
Is it constraining to you? Are you able to still have fun and be a rebel and try crazy stuff and
play with ideas? I have a lot less free time than I had previously.
Um, I mean, mostly by choice. I mean, I, I, I can always see I have the option to sort of,
uh, decline. I, so I declined a lot of things. I, I did, I could decline even more. Um,
or I could acquire a reputation of things so unreliable that people don't even ask anymore.
Uh, this is, I love the different algorithms here. This is great.
This is, it's always an option. Um, but you know, um, there are things that are like,
I mean, sort of, I mean, I, I, I don't spend as much time as I do as a postdoc, you know,
just, just working on one problem at a time or, um, fooling around. I still do that a little bit,
but yeah, as you're advancing your career, some of the more soft skills, so math somehow
front loads all the technical skills to the early stages of your career. So, um, yeah,
so it's, uh, as a postdoc is published or perish, you're, you're, you're incentivized to basically
focus on, on proving very technical things. So prove yourself, um, as well as proof of theorems.
Um, but then as, as you get more senior, you have to start, you know, mentoring and, and, and,
and giving interviews, uh, and, uh, and trying to shape, um, direction of the field, both research
wise and, and, and, you know, uh, sometimes you have to, uh, uh, you know, do various administrative
things and it's kind of the right social contract because you, you need to, to work in the trenches
to see what can help mathematicians.
The other side of the establishment sort of the, the, the really positive thing is that,
um, you get to be a light that's an inspiration to a lot of young mathematicians or young people
that are just interested in mathematics. It's like, it's just how the human mind works. This
is where I would probably, uh, say that I like the Fields Medal, that it does inspire a lot of
young people somehow. I don't, this is just how human brains work.
Yeah.
At the same time, I also want to give sort of respect to somebody like Gregorio Perlman, who
is critical of awards in his mind. Those are his principles and any human that's able for their
principles to like, do the thing that most humans would not be able to do. It's beautiful to see.
Some recognition is, is necessarily important. Uh, but yeah, it's,
it's also important to not let these things take over your life.
Yeah. Um, and like only be concerned about, uh, getting the next big award or whatever. Um,
I mean, yeah, but yeah, so again, you see these people try to only solve like a really big math
problems and, and not work on, on, on things that are less, uh, sexy if you wish, but, but, but
actually still interesting and instructive. As you say, like the way the human mind works, it's, um,
we understand things better when they're attached to humans. Um, and also, uh, if they're attached to a
small number of humans, like the way our human mind is wired, we can comprehend the
relationships between 10 or 20 people, you know, but once you get beyond like a hundred people,
there's, there's a, there's a limit. I figured there's a name for it. Um, beyond which, uh,
it just becomes the other. Um, and, uh, so we have, you have to simplify the pole mass of,
you know, 99.9% of humanity becomes the other. Um, and, uh, and often these models are, are incorrect,
and this causes all kinds of problems, but, um, so, yeah, so to humanize a subject, you know,
if you identify a small number of people and say, you know, these are representative people
of the subject, you know, role models, for example, um, that has some role, um, but it can also be, um,
uh, yeah, too much of it can be harmful because it's, I'll be the first to say that my own career
path is not that of a typical mathematician. Um, I, the very accelerated education, I skipped a lot of
classes. Um, I think I was, had very fortunate mentoring opportunities, um, and I think I was
at the right place at the right time. Just because someone does, doesn't have my, um, trajectory,
you know, doesn't mean that they can't be good mathematicians. I mean, they, they, they, they,
they, they, they, they just in, in a very different style, uh, and we need people with a different
style. Um, and, you know, even if, and sometimes too much focus is given on the, on the person who
does the last step to complete, um, a project in mathematics or elsewhere, that's, that's really
taken, you know, centuries or decades with lots and lots of putting on lots of previous work. Um,
but that's a story that's difficult to tell, um, if you're not an expert, because, you know,
it's easier to just say one person did this one thing, you know, it makes for a much simpler history.
I think on the whole, it, um, is a hugely positive thing to, to talk about Steve Jobs
as a representative of Apple, when I personally know, and of course, everybody knows the incredible
design, the incredible engineering teams, just the individual humans on those teams. They're not
a team, they're individual humans on a team. And there's a lot of brilliance there,
but it's just a nice shorthand, like a very, like pie. Yeah. Steve jobs. Yeah. Yeah.
As a, as a starting point, you see, you know, as a first approximation, that's how you,
and then read some biographies and then look into much deeper.
First approximation. Yeah, that's right. Uh, so you mentioned you were a person to,
um, Andrew Wiles at that time. Oh yeah. He's a professor there. It's a funny moment,
how history is just all interconnected. And at that time, he announced that he proved the Fermat
last theorem. What did you think, maybe looking back now with more context about that moment
in math history? Yeah. So I was a graduate student at the time. I mean, I, I vaguely remember,
you know, there was press attention and, uh, um, we all had the same, um, uh, we had pigeonholes
in the same mail room, you know, so we would pick up mail and like suddenly Andrew Wiles's
mailbox exploded to be overflowing. That's a good, that's a good metric.
Yeah. Um, you know, so yeah, we, we all talked about it at, at tea and so forth. I mean, we,
we didn't understand most of us sort of understand the proof. Um, we understand sort of high level
details. Um, like there's an ongoing project to formalize it in lean, right? Kevin Buzzard is like,
you know, can, can we take that small tangent? Is it, is it, how difficult is that? Cause as,
as I understand the Fermat's last, the, the proof for, uh, Fermat's last theorem has like super
complicated objects. Yeah. It's really difficult to formalize though. Yeah. I guess, yeah, you're
right. The objects that they use, um, you can define them. Uh, so they've been defined in lean.
Okay. So, so just defining what they are can be done. Uh, that's really not trivial, but it's been done.
But there's a lot of really basic facts about, um, these objects that have taken decades to prove
and that they're, they're in all these different math papers. And so lots of these have to be
formalized as well. Um, Kevin's, uh, Kevin Buzzard's goal, actually, he has a five-year grant
to formalize Fermat's last theorem. And his aim is that he doesn't think he will be able to get all
the way down to the basic axioms, but he wants to formalize it to the point where the only things that
he needs to rely on is black boxes are things that were known by 1980 to, um, to number theorists
at the time. Um, and then some other person or some other work would have he done to, to, to get
from there. Um, so it's, it's a different area of mathematics than, um, the type of mathematics I'm
used to. Um, um, in analysis, which is kind of my area, um, the objects we study are kind of much
closer to the ground. We study, I study things like prime numbers and, and, and functions and, and things
that are within scope of a high school, um, uh, math education to at least, uh, define. Um, yeah,
but then there's this very advanced algebraic side of number theory where people have been building
structures upon structures for, for quite a while. Um, and it's, it's a very sturdy structure.
There's, it's, it's, it's been, it's been very, um, at the base at least it's extremely well-developed
with textbooks and so forth. But, um, um, it does get to the point where, um, if you're, if you haven't
taken these years of study and you want to ask about what, what is going on at, um, like level
six of the, of this tower, you have to spend quite a bit of time before they can even get to the point
where you can see, you see something you recognize. What inspires you about his journey that was
similar as we talked about seven years, mostly working in secret. Yeah. Uh, yes, that is a romantic,
uh, yeah. So it kind of fits with the sort of the, the romantic image that I think people have
of mathematicians to the extent that they think of them at all as these kind of eccentric, uh,
you know, wizards or something. Um, so that certainly kind of, uh, uh, accentuated that
perspective. You know, I mean, it's, it is a great achievement. His style of solving problems
is so different from my own. Um, but which is great. I mean, we, we need people like that.
Can you speak to it? Like what, uh, in, in terms of like, uh, you like the collaborative.
I like moving on from a problem if it's giving too much difficulty. Um,
got it. But you need the people who have the tenacity and the, the fearlessness. Um,
you know, I, I, I've collaborated with, with people like that where I want to give up, uh,
because the first approach that we tried didn't work in the second one didn't approach, but they're
convinced and they have the third, fourth, and the fifth of what works. Um, and I have to
eat my words. Okay. I didn't think this was going to work, but yes, you were right all along.
And we should say for people who don't know, not only are you known for the brilliance of your work,
but the incredible productivity, just the number of papers, which are all of very high quality.
So there's something to be said about being able to jump from topic to topic.
Yeah. It works for me. Yeah. I mean, there are also people who are very productive and they,
they focus very deeply on. Yeah. I think everyone has to find their own workflow. Um, like one thing
which is a shame in mathematics is that we have mathematics, there's sort of a one-size-fits-all approach.
to teaching, teaching mathematics. Um, and you know, so we have a certain curriculum and so forth.
I mean, you know, maybe like if you do math competitions or something, you get a slightly
different experience, but, um, I think many people, um, they don't find their, their native
math language, uh, until very late, uh, or usually too late. So they, they, they stopped doing
mathematics and they have a bad experience with a teacher who's trying to teach them one way to do
mathematics that they don't like it. Um, my theory is that, um, humans don't come, evolution has not
given us a math center of our brain directly. We have a vision center and a language center and some
other centers, um, which have evolution as honed, but we, it doesn't, we don't have innate sense of
mathematics. Um, but our other centers are sophisticated enough that different people,
we, we, we can repurpose other areas of our brain to do mathematics. So some people have figured out
how to use the visual center to do mathematics. And so they think, think very visually when they
do mathematics. Some people have repurposed their, their language center and they think very symbolically.
Um, you know, um, some people like if, if they are very competitive and they feel like gaming,
there's a type of, there's a part of your brain that's very good at, at, at, uh, at solving puzzles
and games and, and, and, and that can be repurposed. But like when I talk to other mathematicians,
you know, they don't quite think that I can tell that they're using some of different styles of, of
thinking than I am. I mean, not, not disjoint, but they, they may prefer visual. Like I, I, I, I don't
actually prefer visual so much. I need lots of visual aids myself. Um, you know, mathematics provides
a common language so we can still talk to each other, even if we are thinking in, in different ways.
But you can tell there's a different set of subsystems being used in the thinking process.
Yeah. Like they, they take different paths. They're very quick at things that I struggle with
and vice versa. Um, and yet they still get to the same goal. Um, and yeah, but I mean,
the way we educate, unless you have like a personalized tutor or something, I mean,
education sort of just by nature of scale has to be mass produced. You know, you have to teach the 30
kids, you know, they have 30 different styles. You can't, you can't teach 30 different ways.
On that topic, what advice would you give to students, uh, young students who are struggling with
math and, but are interested in it and would like to get better? Is there something in this?
Yeah. Um, in this complicated educational context, what, what would you?
Yeah. It's a tricky problem. One nice thing is that there are now lots of sources for
my faculty enrichment outside the classroom. Um, so in, in, in my day, they're already,
there are math competitions. Um, and you know, they're also like popular math books in the library.
Um, yeah, but, but now you have, you know, YouTube, uh, there are forums just devoted to solving,
you know, math puzzles and, um, and math shows up in, in other places, you know, like, um,
for example, there, there are hobbyists who play poker, uh, for fun. Uh, and, um, they, they,
you know, they, for very specific reasons, are interested in very specific probability questions.
Um, and, and they actually, you know, there's a community of amateur probabilists in, in, in poker,
um, in chess and baseball. I mean, there's, there's, there's, uh, yeah, um,
there's math all over the place. Um, and I'm, I'm, I'm hoping actually with, uh, with these new sort
of tools for lean and so forth, that actually we can incorporate the broader public into math
research projects. Um, like this is almost, it doesn't happen at all currently. So in the sciences,
there's some scope for citizen science, like astronomers, uh, they're amateurs who discover
comets and there's biologists, they're people who could identify butterflies and so forth.
Um, and in method, um, there are a small number of activities where, um, amateur mathematicians
can like discover new primes and so forth. But, but previously, because we have to verify every
single contribution, um, like most mathematical research projects, it would not help to have
input from the general public. In fact, it would, it would just be, be time consuming because just
error checking and everything. Um, but you know, one thing about these formalization projects is that
they are bringing together more, bringing in more people. So I'm sure the high school students
who've already contributed to some of these formalizing projects, who contributed to MathLib.
Um, you know, you don't need to be a PhD holder to just work on one atomic thing.
There's something about the formalization here that also,
as a very first step, opens it up to the programming community too.
Yes.
The people who are already comfortable with programming. It seems like programming is somehow
maybe just the feeling, but it feels more accessible to folks than math.
Math is seen as this like extreme, especially modern mathematics, seen as this extremely difficult
to enter area and programming is not. So that could be just an entry point.
You can execute code and you can get results. You know, you can print a whole world pretty quickly.
Um, you know, like if, uh, if programming was taught as an almost entirely theoretical subject
where you just taught the computer science, the theory of functions and, and, and, and routines
and so forth, and, and outside of some, some very specialized homework assignments, you're not
actually programmed like on the weekend for fun. Yeah.
Or yeah, that would be as considered as hard as math. Um, yeah, so as I said, you know, there are
communities of non-mathematicians where they're deploying math for some very specific purpose,
you know, like, like optimizing their poker game and, and for them, then that becomes fun for them.
Uh, what advice would you give in general to young people, how to pick a career,
how to find themselves? That's a tough, tough, tough question. Yeah. So, um, there's a lot of
certainty now in the world, you know, I mean, there was this period after the war where, uh, at least in
the West, you know, if you came from a good demographic, you, uh, you know, like you, there was a very
stable path to it, to a good career. You go to college, you get an education, you pick one
profession and, and you stick to it. It's becoming much more thing of the past. So I think you just
have to be adaptable and flexible. I think people will have to get skills that are transferable,
you know, like, like learning one specific programming language or one specific subject
of mathematics or something. It's, it's, it's, that itself is not a super transferable skill, but sort of
knowing how to, um, reason with, with abstract concepts or how to problem solve and things
go wrong. So anyway, these are things which I think we will still need, even as our tools get, get
better and, you know, you'll, you'll be working with AI sports and so forth.
But actually you're an interesting case study. I mean, you're like a, one of the great living
mathematicians, right? And then you had a way of doing things and then all of a sudden you start
learning. I mean, first of all, you kept learning new fields, but you learn lean. That's not,
that's a non-trivial thing to learn. Like that's a, that's a, for a lot of people, that's an extremely
uncomfortable leap to take, right? Yeah. A lot of mathematicians.
First of all, I've always been interested in new ways to do mathematics. I, I, I feel like
a lot of the ways we do things right now are inefficient. Um, I, I, I spent, like me and my
colleagues who spent a lot of time doing very routine computations or doing things that other
mathematicians would instantly know how to do, and we don't know how to do them. Uh, and why can't
we search and get a quick response and so on? So that's why I've always been interested in exploring
new workflows. About four or five years ago, I was on a committee where we had to ask for ideas for
interesting workshops to run at a math institute. And at the time, Peter Schultzer had just, uh,
formalized one of his, his, um, new theorems. And, um, there's some other developments in computer
assisted proof that look quite interesting. And I said, oh, we should, we should, uh, um,
we should run a workshop on this. This would be a good idea. Um, and then I, I was a bit too
enthusiastic about this idea. So I, I got voluntold to actually run it. Um, so I did with a bunch of
other people, Kevin Buzzard and Jordan Ellenberg and a bunch of other people. Um, and it was, it was a,
uh, a, a nice success. We brought together a bunch of mathematicians and computer scientists
and other people, and, and we got up to speed on the state of the art. Um, and it was really
interesting, um, developments that, that most mathematicians didn't know what was going on. Um,
that lots of nice proofs of concept, you know, just sort of hints of, of what was going to happen.
This was just before ChatGBT, but there was even then there was one talk about language models and
the potential, um, capability of, of those in the future. So that got me excited about the subject.
So I started giving talks, um, about this is something we should, more of us should start
looking at. Um, now that I, I arranged at the runner's conference and then ChatGBT came out
and like suddenly AI was everywhere. And so, uh, I got interviewed a lot, um, about, about this topic.
Um, and in particular, um, the interaction between AI and formal proof assistants. And I said, yeah,
they should be combined. This, this is, this is, um, this perfect synergy to happen here. And at some
point I realized that I have to actually do not just talk the talk, but walk the walk, you know,
like, you know, I don't work in machine learning. I, and I don't work in proof formalization. And
there's a limit to how much I can just rely on authority and saying, you know, I, I, I'm a,
I'm a, I'm a mathematician. Just trust me. You know, when I say that this is going to change
mathematics and I'm not doing it any, and I don't do any of it myself. So I felt like I had to actually,
uh, uh, justify it. Yeah. A lot of what I get into actually, um, I don't quite see an advice as how
much time I'm going to spend on it. And it's only after I'm sort of waist deep in, in, in, in a project
that I, I realized by that point I'm committed. Well, that's deeply admirable that you're willing
to go into the fray, be in some small way, beginner, right. Or have some of the sort of
challenges that a beginner would, right. So new concepts, new ways of thinking also, you know, sucking
at a thing that others, I think, I think in that talk, you know, you could be a field metal winning
mathematician and an undergrad knows something better than you. Yeah. Um, I think mathematics
inherently, I mean, mathematics is so huge these days that nobody knows all of modern mathematics.
Um, and inevitably we make mistakes and, um, you know, uh, you can't cover up your mistakes with just
sort of bravado. And, and, uh, I mean, because people will ask for your proofs and if you don't have
the proofs, you don't have the proofs. Um, I don't love math. Yeah. So it does keep us honest.
I mean, not, not, I mean, you can still, uh, it's not a perfect, uh, panacea, but I think, uh,
we do have more of a culture of admitting error then because we're forced to all the time.
Big, ridiculous question. I'm sorry for it. Once again, who is the greatest mathematician
of all time? Maybe one who's no longer with us. Uh, who are the candidates? Euler,
Gauss, Newton, Ramanujan, Hilbert. So first of all, as I mentioned before,
like there's a, there's some time dependence on the day. Yeah. Like if you, if you, if you,
if you pop cumulatively over time, for example, Euclid like, like sort of like this is one of the
contenders. Um, and then maybe some unnamed anonymous mathematicians before that, um, you know,
whoever came up with the concept of numbers, you know, um, do mathematicians today still feel the
impact of Hilbert just directly of what everything that's happened in the 20th century.
Yeah. Yeah. Hilbert spaces. We have lots of things that are named after him, uh, of course,
just the arrangement of mathematics and just the introduction of certain concepts. I mean,
23 problems have been extremely influential. There's some strange power to the declaring which
problems are hard to solve, the statement of the open problems. Yeah. I mean, you know,
there's this bystander effect in everywhere, right? Like if, if no one says you should do X,
everyone just mills around waiting for somebody else to, to, uh, to do something and, and like,
nothing gets done. Um, so, and, and like, like it's the point, one thing that actually, uh, you have
to teach undergraduates in mathematics is that you should always try something. So, um, you see
a lot of paralysis, um, in an undergraduate trying a math problem. If they recognize that there's a
certain technique that, that can be applied, they will try it, but there are problems for which they
see none of their standard techniques obviously applies. And the common reaction is then just
paralysis. I don't know what to do. Uh, oh, um, I think there's a quote from the Simpsons. I've
tried nothing and I'm all out of ideas. Um, so, you know, like the next step then is to try anything,
like no matter how stupid, um, and in fact, almost the stupid of the better, um, which, you know,
I think we're just almost guaranteed to fail, but the way it fails is going to be instructive.
Um, like it fails because you, you, you're not at all taking into account this hypothesis. Oh,
this hypothesis must be useful. That's a clue. I think you also suggested somewhere this,
this fascinating approach, which really stuck with me as they're using it. It really works.
I think you said it's called structured procrastination. No, yes.
It's when you really don't want to do a thing. They imagine a thing you don't want to do more.
Yes. That's worse than that. And then in that way, you procrastinate by not doing the thing
that's worse. Yeah. Yeah. That's a nice, it's a nice hack. It actually works.
Yeah. Yeah. Um, I mean, with anything that I, you know, I mean, like you've, um,
psychology is really important. Like you, you, you, you, you talk to athletes like marathon runners
and so forth and, you know, and they talk about what's the most important thing is that the
training regimen or the diet and so forth. So much of it is like your psychology. Um,
you know, just tricking yourself to, to think that the problem is feasible, um, so that you're
motivated to do it. Is there something our human mind will never be able to comprehend?
Well, I sort of, I guess a mathematician, I mean, you know, it's my induction,
it's a very, there must be some, it's a very large number that you can't understand.
That was the first thing that came to mind. So that, but even broadly, is there,
are we, is there something about our mind that's, we're going to be limited
even with the help of mathematics?
Well, okay. I mean, it's like, how much augmentation are you willing? Like, for example,
if I didn't even have pen and paper, um, like if I had no technology whatsoever, okay,
so I'm not allowed blackboard, pen and paper.
Right. You're already much more limited than you would be.
Incredibly limited. Even language, the English language is a technology.
Uh, it's, uh, it's one that's been very internalized.
So you're right. They're really, the, the, the formulation of the problem is incorrect,
because there really is no longer a, just a solo human. We're already
augmented in extremely complicated, intricate ways, right?
Yeah. Yeah.
So we're already like a collective intelligence.
Yes. Yeah. I guess. So humanity, plural, has much more intelligence, in principle,
on his good days than the individual humans put together. Uh, it can all have less. Okay. But,
uh, um, yeah, so yeah, the mathematical community, plural, is, is, is an incredibly super intelligent,
uh, entity, um, that, uh, no single human mathematician can, can come close to, to replicating.
You see it a little bit on these, like, question analysis sites. Um, uh, so this math overflow,
which is the math version of stack overflow. And like, sometimes you get like this very quick responses
to very difficult questions from the community. Um, and it is, it is, it's a pleasure to watch,
actually, as an expert. I'm a fan spectator of that, uh, of that site, just seeing the brilliance of
the different people there, um, the depth of knowledge that some people have, and the willingness
to engage in the, in the rigor and the nuance of the particular question. It's pretty cool to watch.
It's fun. It's almost like just fun to watch. Uh, what gives you hope about this whole thing we
have going on, human civilization? I think, uh, yeah, um, the younger generation is always like,
like really creative and enthusiastic and, and inventive. Um, uh, it's a pleasure working with,
with, uh, with, uh, with, uh, with young students. Um, you know, the, uh, the progress of science
tells us that the problems that used to be really difficult can become extremely, you know,
can become like trivial to solve, you know? And I mean, like, it was like navigation,
you know, just, just knowing where you were on the planet was this horrendous problem before people
died, um, you know, uh, or lost fortunes because they couldn't navigate, you know? And we have devices
in our pockets that do this automatically for us, like it's a completely solved problem, you know?
So things that are seem unfeasible for us now could be maybe just sort of homework exercises for
things. Yeah. One of the things I find really sad about the finiteness of life is that I won't get
to see all the cool things we create as a civilization, you know, that, because in the
next hundred years, 200 years, just imagine showing, showing up in 200 years. Yeah. Well,
already plenty has happened, you know, like if, if you could go back in time and talk to your, your
teenage self or something, you know what I mean? Yeah. And just the internet and, and now AI, I mean,
it's like, again, they've been, they're beginning to be internalized and say, yeah, of course, uh,
and AI can understand our voice and, and give reasonable, you know, slightly incorrect answers
to, to any question, but you know, I, this was mind blowing even two years ago. And in the moment,
it's hilarious to watch on the internet and so on the, the drama, uh, people take everything for
granted very quickly. And then they, we humans seem to entertain ourselves with drama. Well, out of anything
that's created, somebody needs to take one opinion, another person needs to take an opposite opinion
and argue with each other about it. But when you look at the arc of things, I mean, it's just even
in progress of robotics, just to take a step back and be like, wow, this is beautiful that we humans
are able to create this. Yeah. When the infrastructure and the culture is, is healthy, you know,
the community of humans can be so much more intelligent and mature and, and rational than the
individuals within it. Well, one place I can always count on rationality is the comment section of
your blog, which I'm a big fan of. There's a lot of really smart people there. And thank you, uh,
of course, for, uh, for putting those ideas out on the blog. And it's, I can't tell you how, uh,
honored I am that you would spend your time with me today. I was looking forward to this for a long
time. Terry, I'm a huge fan. Um, you inspire me, you inspire millions of people. Thank you so much for
time. Thank you. It was a pleasure. Thanks for listening to this conversation with Terrence
Tao. To support this podcast, please check out our sponsors in the description or at lexfriedman.com
sponsors. And now let me leave you with some words from Galileo Galilei.
Mathematics is the language with which God has written the universe. Thank you for listening
and hope to see you next time.
Thank you.
