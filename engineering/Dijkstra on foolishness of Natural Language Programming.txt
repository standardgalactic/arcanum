Alright, Dykstra on the foolishness of natural language programming.
This feels like it could be relevant today, considering where we're kind of at with the whole world,
and Dykstra always has some scorchers, so let's see what he has to say today.
On the foolishness of natural language programming, since the early days of automatic computing,
we have had people that have felt it as a shortcoming that programming required the care and accuracy
that is characteristic for the use of any formal symbolism.
They blame the mechanical slave for its strict obedience, with which it carried out its given instructions,
even if a moment's thought would have revealed that those instructions contained an obvious mistake.
But a moment is a long time, and thought is a painful process.
A.E. Hussmann
They eagerly hope and waited for more sensible machinery that would refuse to embark on such nonsensical activities
as trivial clerical error evoked at the time.
Is this some sort of, like, punch against COBOL? What's going on here?
Because this must have been a while ago, but there is something that's also very true about this,
which is that I think about this all the time, and I've actually had this happen to me multiple times on chat
with, like, either vibe coding with cursor or chat jippeting, is you say something,
and it interprets it not how you meant to say it.
Just because English is just so imprecise.
You know, the crazier part is that I foresee a moment in the future where there's going to be a programming language
that's developed for LLMs.
You're going to get something like pseudolang.
I think people have already tried this.
I think pseudolang, if I'm not mistaken, there you go.
A powerful pseudopro, yeah, pseudolang.
A powerful pseudocode programming language for LLMs.
And so I know this is, people are trying to make fetch happen, and given the amount of VC money in it,
fetch is going to happen.
But this is one of those moments in life where I have to think men will do anything to avoid learning programming,
including learning programming just in a higher level language that's more inconvenient.
Like, that's how I look at these things, is just like, these feel very inconvenient when you start looking at these,
these commands and all this.
It's just like, it's almost a programming language, but, I know, we're going to Ouroboros ourselves, exactly.
Machine code, with its absence of almost any form of redundancy,
was soon identified as a needlessly risky interface between men and machine.
Agreed.
I mean, that seems reasonable.
Partly in response to this recognition, so-called high-level programming languages were developed.
And, as time went by, we learned to a certain extent how to enhance the protection against silly mistakes.
It was a significant improvement that now many a silly mistake did result in an error message instead of an erroneous answer.
And even this improvement wasn't universally appreciated.
Some people found error messages they couldn't ignore more annoying than wrong results.
And, when judging relative merits of programming languages,
some still seem to equate the ease of programming with the ease of making undetected mistakes.
Is this, like, the neckbeards of old, real programmers don't eat quiche?
Is that, is that, is that what we're talking about here?
For those that don't know, the real, real programmers don't eat quiche was, like, a satire article written against,
I think it was, like, real men don't eat quiche, which was some New York Times article or something along those lines.
And it had to do with people who wanted to be able to write their own instructions so that they could, like, time drum memory
instead of using something like Fortran, because it just wasn't as optimal.
It's like, oh, that's not as optimal.
I can time memory reads with the speed of the drum, with the, with the, the speed of the drum RPM.
Therefore, I should be the real, because I'm the real programmer.
You guys don't know even about drum speed.
Anyways, let's see.
The abstract machine corresponding to a programming language remained, however, a faithful slave,
i.e., the nonsensical automaton perfectly capable of carrying out nonsensical instructions.
Programming remained the use of a formal symbolism and, as such, continued to require the care and accuracy required before.
I feel like, dude, Dykstra, I know he died in, what, 2002, early 2000s?
Man, this guy, I can already feel the foresight slowly setting in.
It's just slowly coming in decades later.
In order to make machines significantly easier to use, it has been proposed or tried to design machines that we could instruct in our native tongues.
This would admittedly make the machines more complicated, but, it was argued, by letting the machines carry a larger share of the burden, life would become easier for us.
It sounds sensible, provided you blame the obligation to use a formal symbolism as the source of your difficulties.
But is the argument valid?
I doubt.
I wonder, like, I do wonder what Dykstra would say with today's world.
Would he still say, I doubt?
Or would he, you know, because this was almost, like, this was at least a quarter century or more ago that he wrote this.
Would he still say today that, I doubt?
Or would he say, I know?
Or would he say, nah, bro, AI's the future.
Let's native tongue, let's native tongue up our programming.
Unfortunately, we can't make any sort of objective, like, guesses into this.
But I think, in some sense, he does make a really reasonable point right here, which is, let's see, it sounds sensible, provided you blame the obligation to use a formal symbolism as the source of your difficulties.
There's something that's, like, really awesome about that statement.
That is incredible.
We know, in the meantime, that the choice of an interface is not just a division of a fixed amount of labor, because the work involved in cooperating and communicating across interface has to be added.
We know, in the meantime, from sobering experience, I may add that a change of interface can easily increase at both sides of the fence the amount of work to be done, even drastically so.
Hence, the increased preference for what are now called narrow interfaces.
Therefore, although changing to communication between machine and man conducted in the latter's native tongue would greatly increase the machine's burden, we have to challenge the assumption that this would simplify man's life.
Okay, I think I see what he's trying to say.
What he's trying to say here is that often when we add some level of abstraction, we add an equal difficulty on both sides.
And so, by adding difficulty on both sides, is the use of a native tongue, which greatly increases the machine's burden, which is true.
Like, he is, by the way, this is, like, such a spot-on observation he's made right here, that it is true, using a native tongue has increased the machine's burden, because, A, a lot more redundant stuff.
B, I mean, we have an entire, we have, we have, we have entire nuclear power plants, nuclear, nuclear, nuclear power plants dedicated to just powering these machines, and it's all in the hope that it would simplify man's life.
10,000 gallons of water, big and, true.
Computer language can't begin to fathom the stupidity of human input, is his breakdown.
That's kind of what I'm, that's kind of what I'm gathering here.
A short look at the history of mathematics shows how justified this challenge is.
Greek mathematicians got stuck because it remained a verbal, pictorial activity.
Muslim algebra, after a timid attempt at symbolism, died when it returned to their rhetoric style, and the modern, civilized world could only emerge.
For better or for worse, when Western Europe could free itself from the fetters of medieval scholasticism, a vain attempt at verbal precision,
thanks to the carefully, or at least consciously designed formal symbolism that we owe to people like Vieta, Descartes, Leibniz, and later, Buhl.
Buhl. George Buhl.
To be honest, I'm not really sure what his argument is here, other than people always tried to make things more verbal and pictorial activity for math,
but other people fought against it and went into some sort of formal symbolism for mathematics.
A vain attempt at verbal precision describes prime reading skills.
I know, true.
My reading skills today, by the way, I just want to let you know, my reading skills today, feeling like an absolute minimum right now.
I don't know what's going on, but I'm hurting.
Maybe it's just like how fancy this Dykstra man speaks, or maybe I'm just like, I just woke up on the wrong side of dyslexia this morning.
Just today? Yes, today is particularly bad.
You know it's true.
Don't even come at me with that.
The virtue of formal texts is that their manipulations in order to be legitimate need to satisfy only a few simple rules.
They are, when you come to think of it, an amazingly effective tool for ruling out all sorts of nonsense that,
when we use our native tongues, are almost impossible to avoid.
Yeah, you can say, you can say weird things, right?
The green dream sings is technically like a valid, is like a valid sentence structurally,
but it's like, it just doesn't make any sense.
Like, what the hell does that even mean?
Right? Like, okay, you got all the words in there, but what the hell is the thing?
You got an adjective, you got a noun, you got a verb, but it just makes no sense.
Right? It literally makes no sense.
Instead of regarding the obligation to use formal symbolism or symbols as a burden,
we should regard the convenience of using them as a privilege.
Thanks to them, schoolchildren can learn to do what in early days only genius could achieve.
This was evidently not understood by the author that wrote in 1977 in the preface of a technical report
that even the standard symbols used for logical connectives have been avoided for the sake of clarity.
The occurrence of that sentence suggests that the author's misunderstanding is not confined to him alone.
Just wrecked.
Okay, so this must be even older.
This must be something that is, this article must be a half decade old at this point.
Dude, that's awesome.
Okay.
I mean, I think he makes, I think this is a really great argument, by the way.
Simple symbols following a simple rule, though complex to learn, become easier to read.
And I think we can all understand this, even just with programming.
Because programming is just literally a series of symbols that, you know, do what you tell them.
And at first it's really hard, but then as time goes on, it gets easier.
When all is said and told, the naturalness with which we use our native tongues boils down to the ease with which we can use them for making statements,
that nonsense of which is not obvious.
It may be illuminating to try to imagine what would have happened if, right from the start,
our native tongue would have been the only vehicle for the input into and output from our information processing equipment.
My considered guess is that history would, in a sense, have repeated itself.
And that computer science would consist mainly of the indeed black art how to bootstrap from there to sufficiently well-defined formal system.
We would need all the intellect in the world to get the interface narrow enough to be usable.
And in the view of history of mankind, it may not be overly pessimistic to guess that to do the job well enough would require, again, a few thousand years.
I can't tell if LLMs are in shambles or not from this statement.
I find that I just, I generally agree with this statement in the sense that I just, I think formal symbolism makes life easy, right?
Definite action based on definite rules makes life easy.
In short, it's the monkey paw.
Maybe.
A thousand years.
I thought I could become a programmer in six months.
Good luck, not C++ rookie.
Okay, remark.
As a result of the educational trend away from intellectual discipline, the last decades have shown in the Western world a sharp decline of people's mastery of their own language.
Many people that, by the standards of a previous generation, should know better are no longer able to use their native tongue effectively, even for purposes for which it is pretty adequate.
You have only to look at the indeed alarming amount of on-close reading meaningless verbiage in scientific articles, technical reports, government publications, etc., or my reading skills.
This phenomenon, known as the new illiteracy, should discourage those believers in natural language programming that lack the technical insight indeed or needed to predict its failure.
End of remark.
Interesting.
I mean, I think that's generally true.
When you talk, you know, like when I talk to, I feel like when I talk to older people, they use more, generally, more words to describe what they're thinking, and they use less like contextual or slang items, but more definite items.
I'm not saying slang is good or bad, but it also, the problem with slang is that it has many meanings to many people.
He specified American, ha, ha, ha, ha, ha.
No, he specified Western world.
Dummy.
Dude, you like, you like literally fell into his trap.
The guy's like, people are having a hard time reading and understanding things, and you're like, yeah, he said that about America, dummy.
That was pretty good.
That was pretty hilarious.
I'm just saying, to ever have anybody prove a point, oh my gosh, this was so good.
All right, for one gut feeling, I derive much consolation.
I suspect that machines to be programmed in our native tongue, be it Dutch, English, American, nice, American.
It's funny that he uses American as a language.
If this is what you're referring to, then that's pretty awesome, but if not, it's pretty awesome that you did it up here.
But we do have, I mean, we have a lot more slang, and we're growing slang by the day.
Okay, French, and I'm not sure if that's an American thing anymore, or if that's going to become like an internet online thing that's just English as a medium transfer.
It is weird to say American, though.
I'm having a hard time understanding why American is separated from English.
French, German, or Swahili are as damned difficult to make as they would to use.
I think that's just because you guys spell color with a U.
It's like not my fault that you like spell color wrong.
That's the way to spell color.
Yeah, if you're bad at spelling.
And theater.
Where's my R-E at the end?
Oh, it's actually, it's a theater.
T-re.
T-re.
There is no color without you.
Oh, that's kind of sweet.
Thanks, baby.
I really did like this article quite a bit, because I think it just makes a really good argument.
He obviously did not see LLMs coming.
Obviously, there's no LLMs in here that could make sense.
Like, he did not have this in his mind.
He probably had something else in his mind, is my assumption.
He probably didn't have this idea that there are now algorithms or giant matrices set in place in which,
if you give it a bunch of English words, can produce mostly code coming out the other side.
Probably quite the bizarre, you know, idea for him.
I think what he was thinking is more that it's just literally English to execution.
Anyways, people are asking me about American.
Xscape.
Okay, so that's just, you know, some people say it with an X because we're stupid.
Anyways, weren't the first AI attempts in the 70s?
They're in the 60s as well.
70s.
I mean, AI has been saying there has been a winter of AI going since the 60s.
Like, the amount of articles that were written about how the future is now, old man.
You can see it in Looney Tunes, in fact.
Looney Tunes would always have these things where someone would press a button on a machine
and the machine would go and clean their house and do all their chores and everything.
Like, this is a very old concept that everything you're doing is going to be done by robots very, very soon.
It's just right on the horizon.
It's just right around the corner.
The Jetsons was a bit different.
Maybe.
I don't know if I can call the Jetsons as quite the same style, but maybe.
I think the TLDR is.
The simpler you make the mundane, the harder you make the exceptional.
Programmers aren't going anywhere anytime soon.
Yeah, that's also very, very true.
It's really easy to produce a React to-do app.
And as somebody who just got done doing seven days of Vibe coding and regular coding,
anything worth any level of complexity, you can evidently see within the code why it falls apart
when you use something else to steer other than your really smart brain.
And I think sometimes, like, hard disagree.
I'm curious what you mean by hard disagree.
I think a lot of times people make the mistake of thinking the exceptional is just something that feels complicated to you.
There are some people that think quicksort is hard.
It's not hard.
There are people that think a lot of things are hard that aren't hard.
They're trivial to someone with expertise.
And when someone with expertise looks at it, they go, oh, that's completely wrong.
There's actually this old – there's this thing that – I can't remember the exact name.
I forget – you know how there's, like, the list of laws?
One of the laws goes like this.
If you're an expert and you read an article, you will find all the reasons in which why it's wrong.
But if you're a layman and you read an article from the same outlet, say, I don't know, the New York Times, right?
And it has – one day it has an article on JavaScript.
And the next day it has an article on horses.
You're going to look at the JavaScript article and be like, ah, they're wrong here.
They're wrong here.
No, this isn't quite correct.
Oh, we can argue on all these things.
The next day the horses article comes out.
And what do you do?
You're like, oh, wow.
Horses do what?
They do what?
Wow.
Look at all this information.
And that's because when you don't have the expertise, anything that appears to be an expert makes you think that it's really smart.
It's like the classic – oh, gentleman amnesia.
That's the word I'm looking for.
Gentleman amnesia.
No, this is gentleman amnesia.
Right?
Where you – anything – like, I think LLMs apply to gentleman's amnesia.
You look at something that feels complicated.
And then what do you do?
You go, oh, that must be correct.
But anybody that's been doing it for a while goes, oh, that's not – that's actually – no.
Here's the reasons why it's broken down.
Right?
And we had Casey Moratori, an expert game developer, go through code of a first-person shooter developed purely by LLMs.
And what happened?
He's just – he – like, I mean, he – like, every single function was like, this, though looks like game programming, is in fact not game programming.
And here's why.
Right?
It ran.
Correct.
But it wasn't – it wasn't good.
Even in – in all senses, both architecturally from the top down and in individual functions.
So it wasn't even a granular or a – it wasn't like a terse problem.
Even the specifics were oddly incorrect.
It just worked, which is a very unusual thing to see.
Anyways, there you go.
I love this article.
This is a great article.
The name.
The name.
Yo, King.
Yo, baby.
How you doing?
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
A gen.
