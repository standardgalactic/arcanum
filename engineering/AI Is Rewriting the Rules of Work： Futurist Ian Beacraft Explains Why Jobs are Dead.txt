Hey everyone, today I'm super excited to be talking to Ian Becraft. He's the founder and
chief futurist at Signal and Cypher and he is an absolute thought leader when it comes to the
intersection of AI and enterprises that we all work for. He has so many deep amazing insights.
I had the chance to watch a number of his keynotes at South by Southwest recently and it just never
ceases to amaze me how much new thought leadership he brings to the table here. So I'm really excited
to pick his brain to understand how much of this new technology is really being limited by us and
our own boundaries and how we can break through that. It should be an amazing conversation.
I've been a big fan of your keynotes. I've been binging them in the last couple of days. One of
the quotes that I wrote down, I don't remember if it was from South by Southwest this year or last
year, but as I was binging, one of the quotes I wrote down was, poor leadership, adherence to old
systems and technology first mindsets are a bigger risk than AI to organizations. What is going on
out there and can you kind of dissect that quote? Yeah, absolutely. So to me, when we go through
times of change, we need to galvanize behind something and that happens both productively
and disruptively. We tend to find something to create opposition towards. And for a lot of people,
they see AI as the main threat because it is the easiest thing to point to and say, that's a threat
to my job. I look at that and I see very clearly it's automating pieces of what I do and that becomes
extractive. It's taking something that basically I provided value through that thing before and I no
longer do. And because of that, I as an individual are less valuable to that organization. Now, if I'm
continuing as a leader to just say, my goal is to create efficiency and scale within the system that
we have today, the typical lever we're going to pull is efficiency, which is code for layoffs.
Right. And that is essentially how our system has operated for the last 150 years. And it's been
able to grow. We've been able to create prosperity in a number of different ways, but that system's
changing now. The era of unending exponential growth in existing paradigm is starting to fray at the
seams. And when we think about the future through the lens of the past, what we do is we apply old
metrics, old ways of thinking, old processes to new technologies, new ways of working and new
challenges. And those things come together and they don't work. But when leaders are so fixed in
how they want to approach these things, they're not thinking about how this is different and how they
have to take a different paradigm or different approach to this new type of challenge and new
type of circumstances. And that's what leads to the demise of the organization, not just that employee
or that department. Right. So I want to, I want to zoom in on two different phrases you used there
that I think are really important. You talked about, shoot, now I'm going to screw it up, but you talked
about, you know, growth and the ability for us to have these, you know, productivity improvements and be
thinking about what we're doing differently. And you also said efficiency and efficiency has become a
really popular word these days. You know, efficiency is something, you know, across the public sector,
across the commercial sector, you know, a very hot word. To what degree is efficiency the right thing
to be looking at right now or a distraction from what's actually going to help us?
Yeah. I think there's a balance here. There's a recognition that organizations have a duty to their
stakeholders and their stockholders. And that means you have to look for efficiencies. And if you're
not, that's a dereliction of that obligation. Understandable. Right. So they should be looking
at efficiency and they should be looking at increasing productivity, but to do so with the
same fervor we have over the past several decades, since the beginning of the digital revolution,
I think is absolutely incredibly short-sighted because what this does is this doesn't just scale
an individual's efficiency and effectiveness. This changes the fundamental boundaries of what
jobs and tasks are. We're really, we're re-engineering or completely changing what the
atomic unit of work looks like. So for example, we take a look at organizations as built from people,
which are defined for jobs, very specific slotted roles that are well-defined. And if I look at an org
chart of any organization, I have these mental shortcuts that I can use to understand who does what,
where, and how. All of that's starting to change though, because AI makes it so that I don't actually
have to stick within the boundaries of a specific role and say, that's all you do. If you're accountant
number two, you know, in the finance department, which whatever that designation might mean to a
specific organization, you have the very specific set of roles, responsibilities, KPIs, and remits that
you are responsible for. What happens with AI though, is it makes it so that the skill sets that might
sit adjacent to my existing skill sets or responsibilities are now accessible to me.
So it starts to put pressure on these boundaries that we keep people in with their roles. So if
you're just a copywriter or just an AD, if you're staying within those boundaries now with the access
to AI and generative AI and other tool sets, it's also almost a abdication of responsibility to say,
I'm just going to stay in my lane. And all of a sudden we have this chaos that comes with people
saying, I have access to new skill sets. I have access to new capabilities, but the system around
me has not adapted to really make that possible fluid and part of the system where I'm not stepping
on other people's toes. I'm not doing things without permission. I'm not doing things without
support and an apparatus or feedback loop. So what's happening is we have this new technology that allows
all sorts of new behaviors within the organization, but the organization has no idea how to pull those
behaviors and structures and processes together. Right. It's too rigid to actually take advantage
of what this technology could unlock. Absolutely.
So what do we do with that? Like as leaders, where do we start? How can we start to rethink
these systems and processes in a way that's more dynamic or at least can help us harness these
possibilities? Absolutely. Well, what I would say is the first place you should look is not just
about how do I do more with less? You can, I'm not saying don't think about that, but that shouldn't
be the primary goal of the value you're trying to get out of AI, because that's a race to the bottom.
Like we're all going to get that benefit. And if that's your focus, then you're playing a Walmart game
for a premium enterprise type of environment. That's not going to help anybody. It might give short term
impact. So a quarter to quarter thinking of a Western or American style way of doing business,
you'll see immediate impact. And I think that when you take a look at what's happening on the balance
sheets at Meta and several other organizations, people see, oh, less staff, higher margins,
more productivity. That's the way of it. They're missing a lot of what's actually going on behind
the scenes. So a lot of these companies that are in the space of building the models and kind of
changing the way they work have seen this coming around the bend and they're already restructuring
the way that they operate for leaders that are trying to figure out what this means for them.
I would say, first of all, you need some sort of experiential learning,
like just understanding this stuff, theoretically might've worked for the past 25 years,
because you have a lot of understanding of how the digital paradigm works. This is not new digital,
you know, connected networks, all that stuff. We've known that since the eighties and nineties,
this is a fundamentally different paradigm, different way of working, different way of
thinking about growth, different way of connecting software and systems. I mean,
we're literally working with quote unquote software that now replicates and imitates
cognitive processes, completely different paradigm for people. So having some sort of education or
experience that gets you into that head space where you can start to grapple with what those changes
are is absolutely necessary. Just reading articles, doing a couple of things in chat GPT is not going
to be enough because if you're going to competently lead an AI transformation, you as a leader also need
to have spent that time immersed in that space. I'm not saying, you know, hundreds of hours, but at least
dozens in that space to understand it with the proper guidance, what it's going to do for your team,
your business. How does it help you answer the questions about what kind of value are we providing
as a company? How do we structure our teams? How do we grow effectively in this market where
everyone else is starting to go into these adjacent spaces as well? So there's a lot of
new questions that I have to answer from that.
Yeah. When you talk about that experiential learning, Ian, do you have a sense of like
what leaders are doing? What does that mean? What tools are they using? What does that look like?
Yeah. So the most effective programs that we've seen are ones that are built to be used with the
same types of tools that they are already using their environment. So everyone uses Microsoft Teams,
Slack, have access to chat GPT or something like that. 90% of what you need to do can be done with
those environments, but just using the vanilla version of it is not going to cut it. Being able
to learn with these tools by also building the documentation, the vision, the information you need
to move forward is really where we've seen the most value. So to give you an example of a module that we
run, we'll work with leaders in an environment where they're working with the AI to build their vision
for what AI looks like in their organization, to create a maturity assessment. So where do we stand and
where's the alignment amongst the CXOs? And it's not just about the education of in AI, it's about
alignment. And there's a strong difference between agreement and alignment. What happens oftentimes at
the leadership level is we agree AI is important. We agree that we're all implementing it, but they're
not aligned as to how that happens or where they even are on a maturity index. So having them come
together to do that together while using the tools to facilitate it brings a couple of those
objectives together. And all of a sudden they start to see, okay, here's how the tools can
facilitate this work. It doesn't need to take six weeks. It can literally take an afternoon.
So you've taken something that might've been a six month consulting engagement and said,
we're walking out in two and a half hours with a much clearer understanding of what we're doing,
how we're doing it, who's responsible and what that roadmap looks like. So that's one of the big
paradigm shifts we're seeing. So it's more, if I understand you correctly, there's more value
in like one condensed facilitated session of having the right people in the room and asking the right
questions than like a protracted engagement on like, here's a bunch of recommendations of like
potential use cases and what you could be doing. Is that fair?
I think that the potential use case model is kind of outdated at this point. So I do think that the
idea of the, the thousand page decks and the, the long consulting engagements need to change.
I won't proclaim that consulting companies are, are dead on arrival. I think that's a,
there's a little hyperbole there. They're like advertising agencies. Like they survive this kind
of stuff. The consulting company of the future looks wildly different than it does today. But one
of the things that they're often kind of admonished for is this idea of the thousand page deck.
And I do think that the idea of learning being separate from doing, so having that thousand
page deck, a bunch of seminars, and then finally being responsible to do on your own is outdated.
We now have the tools. We have the apparatus to learn and do at the same time, while also building
some of the most essential infrastructure, as well as documentation and strategy amongst executives.
So when you walk out of a session, you should have a clear revision. You should have an understanding of
how this impacts you, what your maturity assessment looks like and what your roadmap looks like.
So what we've come to see is that we can take things that should take six weeks or even three
months and condense that into one afternoon or a full day session.
Right. Which is, which is really exciting. And you know, I think helps us get a lot more,
like just accelerate our, our time to value or our time to results. Ian, there's a, there's a phrase I
want to talk about, um, that you've said quite a lot and I want to, I want to put some parameters
around it, which is the tools, right? Talking about AI and quote the tools, because you know,
in my mind, when we talk about AI and when we talk about the tools, it's everything from, you know,
just go to chat GPT or Google and write in your question to, you know, this world I'm finding we
live in increasingly where like every software vendor and their brother is promising you that,
oh, there's AI in this now. It's an AI PC that like, like any crevice we can hide AI in,
we're telling you there's AI in it. What tools do people need to be thinking about? How should we be
bringing tool wise AI into our organizations? Yeah. We're, we're at the very beginning of
the development of very robust ecosystem. So most people are seeing things like chat GPT,
Claude, co-pilot, et cetera. And that's kind of when people say tools, they think of that and that's fine.
Sure. But what we're seeing at the enterprise level is a weaving of that into the basic
infrastructure across the board. So for a lot of people, they're pulling in co-pilot,
others they're pulling in, you know, open AI's API into the work that they do. And stage one is just
to get people exposed to tools. So that's access to the chat bots. It's a one-to-one relationship.
You put in an input, you get an output. That is barely, that's not even alpha products for an
enterprise at this point in time. Like you're just getting your, your socks on before you put
your shoes on to get out the door. And what we're seeing with organizations that are more successful
is they're leading with use cases that everyone can understand. And then they're building that
into the infrastructure of their organization. Not just saying, can you go learn how to use chat GPT?
That's basic and necessary because people can't start to identify what the use cases are going to be
unless they have experienced the technology. And I'm a big fan of pushing that down and out.
You should have people at the edges coming up with the use cases, not just the people at the top,
because the people who are dealing with the challenges, who are the ones actually doing the
work, have a much more nuanced understanding of how it should be done and what success looks like for
those types of tasks and activities. To get there has to go way beyond just access to chat GPT.
Um, what we've found for so many organizations is they'll often call us like, Hey, we, we invested
half a million dollars in chat GPT licenses and people loved it in the beginning. And then like,
nobody uses it. It goes like it crests. And then it crashes as far as usage. And the big part of it is
you just gave them a new tool. You gave them barely any training, barely any context. And you said,
amongst all the things you're doing, you're overstretched, under resourced, your expectations are just
getting higher. Now you have to go learn a new way of doing things. There's no surprise people
are not using the tools, right? So it has to be very clear from the beginning, how this applies to
them, why it's relevant, why it's going to change their life, not the organization, like really put
it in, into terms they can understand and grapple with. And then over time, as the knowledge starts
to diffuse across the organization, the infrastructure also becomes more robust. It's almost the opposite in
many ways of previous transformation. So let's take a SAP ERP implementation. That's a three to five
year process, IT command and control. We install it. Everyone else has to adapt to it. What's
happening with AI is we're kind of reversing that in a, in a way. Yes, IT is provisioning licensing,
but this is not just an IT issue anymore. This is an HR issue. This is a strategy issue. This is
a finance issue. And if you don't have your C CFO, your CHRO and your CEO all in lockstep on how this
is being distributed, you're not going to come up with an effective way of distributing the technology,
the knowledge and the application across your organization. So that, that changes the dynamic
of the tool enormously. And over time, it then becomes part of the fabric of the organization,
just like we have with all of our other productivity tools. So I'm, lots to process there.
One of the things you've said, Ian, is we talked a little bit about it already, but this,
there's a fear of people losing their jobs and like disintermediating like jobs from tasks and
augmenting what we're doing. You had said previously, we're not going to lose jobs. We're going to lose
job descriptions. What does that mean? And what does that look like with these,
with AI and with these modern tools and approaches? Absolutely. So I said that probably two or three
years ago in one of my South by Southwest speeches, I said, we won't lose our jobs, we'll lose our job
descriptions. And I've, I've had several people say, well, that aged horribly. And I'm like, actually,
yes and no. Like I will willingly say there are jobs that are going to be lost to this. There's no
question about that. But the, the image that conjures for a lot of people is like, well,
you're going to be on a bread line for the rest of your life. You'll never be allowed to work again
because you're completely irrelevant. That's not how this works. There will be some fracturing of the
system that we work within, and that's not going to be easy. And that's going to cause some,
some pain for some organizations and a lot of people. But what does happen is it also changes the
nature of the jobs we hold. So what I see happening, and this is related to the concept of creative
generalists that I've been talking about for a while now, and I can define that as well, but
a creative generalist is essentially, I'll, I'll pull this back because it's related to the way
we're educated and we build our careers. So we grew up in a system that said, go to school, get a job,
build expertise within that job that becomes defensible. And that's what gets you promoted over
time. Over time, you start to manage the functions that you're an expert in, you become management and
leadership and up you go. That vertical, vertical way of working has been the way that we've promoted
people and told people to go after their careers for decades. What AI does, as I mentioned earlier,
is it essentially abstracts the years and decades of expertise, influence, opportunity, exposure
that you need to build expertise in a specific subject. And it allows you to perform proficiently in
skillsets that are adjacent to your own, or even some that you never had access to before. I said
proficiently, I did not say in any means an elite level, but what we often have to confront in our
organizations is in many cases, good enough is good enough. You don't need somebody with 25 years of
experience to do junior level work. And if I am outside or adjacent to that role and I can get that
junior level work done, why do I have to wait or rely on specialized expertise and resources to get
that work done? So that changes this dynamic and the nature of how I relate to my peers, their roles,
my roles, and it expands the capacity and responsibility in the remit of individual roles.
We're moving away from role-based relationships to jobs, to skill-based and task-based relationships to jobs.
And that's where I feel like the idea of jobs are not going away. I even say in that same speech,
jobs are dead, long live work. And one thing that I think we're so stuck on and say, we need good
jobs. We need, you know, you'll hear every politician say, we need to bring good jobs back to America.
And it's not the jobs, it's the work that we need. If we're so focused on jobs, we're already narrowly
defining ourselves and oftentimes attaching ourselves to things that are not coming back.
Like we're, we're not really going to be bringing back the coal sector, the way everybody's talking
about it in many ways. That's kind of a train that's moved along no matter what we do. And other
jobs are the same way. But when we talk about the work as it relates to the tasks and roles and things
like that, that need to be put together for the future of work, that's where we can actually make
some traction. And that's why I do believe like we're not getting rid of jobs. We're getting rid
of the definition of the artificial boundaries that keep you in a specific space in your organization.
And that's how I see organizations evolving significantly over the next decade.
So if that, if that is the case, there's like tons of wild implications. And I, by the way,
I think that probably is the case. But there's like tons of wild implications from the education system
to our careers, to organizations. But in terms of impacts, Ian, and maybe feel free to tell me this
entire paradigm is wrong, but where is there more risk? Is there more risk for, you know, junior
employees right now who, you know, their general skillset and their baseline level of knowledge can be
replaced by AI? Or is there more risk for people who are 20 years into their career and they have a
deep skillset that maybe now is almost commoditized because you can ask, you know, AI how to, you know,
I'll pick on data scientists, you know, just for example, because, you know, these are, you know,
historically high paid roles that have a lot of schooling behind them. And if you can start to get some of these
answers, some of this validation and information commoditized by AI, what does that mean for people
in these careers? So where, where is the risk greater or is the entire paradigm just, you know,
misplaced? It's so they're both under an enormous amount of strain right now. The one that's most
present that we're seeing happen with more frequency is those who are at the beginning of their careers
are at highest risk to this exposure because you can replace a lot of the things that they would do.
We're kind of, there was this unspoken contract that when you leave school, you would continue
your training almost like a vocation in whatever place you would go and learn. And there's an
enormous amount of teaching mentoring that goes on with that. And when I can just consult chat GPT
and get it done and not have to mentor it, I'm going to do that. Like there's just no question that
that's going to happen in mass. So junior roles are already starting to disappear. The capacity and
capability that juniors have are starting to disappear. And the challenge that just adding
the technology to and giving juniors access to that doesn't help a lot because they don't have
the experience and the frameworks to understand, you know, when I'm doing some exploratory research
on this, what matters, what are the things I should be looking at and honing in on. And they just,
they get overwhelmed by the sheer volume of things they should be looking at without being able to find
the right signals to hone in on. Now, the other part that's true is that middle management is also
getting hit really hard with this stuff, because if your role is focused more on creating alignment,
checking in on organizations or checking in on your employees, doing a little bit of mentoring here
and there, but more so the things that are around productivity and efficiency of a team. So not the
leadership level, not the visioning, but just like the operations of the company that is directly in
the line of fire of AI. And what that changes is it the stuff of being a boss is also starting to go
away. What that makes space for is for people to step into actual roles of leadership. So we're seeing
this layer of middle management that is directly in the line of fire, but also collapses the organization
a bit where the line between junior or more junior people and leadership is also starting to become
thinner and thinner and thinner, but it means more direct contact with people who can spend time
in the space of being leaders versus bosses. Can you just unpack that a little bit for me?
I'm actually a little bit surprised to hear that, that some of the team management piece
is something that AI can do. What are the tasks that you see as being now doable to AI? What does
that look like? Absolutely. So a lot of what happens at the management level is facilitation
and alignment and things like facilitation are easily done by AI. When we actually work within
Signal and Cypher, the projects that we're working on are known not only to us, but also our AI and our
project management system. So I don't have to check in with my co-founder be like,
where are you on this? It knows, therefore I know. So that the amount of meetings that I'm having
around alignments and approval have dropped like 70%. So these big parts where we call it corporate waste,
these items where you're waiting on specialized resources, they come available to do the work
or to have a moment of someone's time to say, do you approve of this? Or having those CYA moments of
does legal approve of this? Those are actually starting to disappear as well because the systems
can check on these things. Now, none of these things are bulletproof or faultless yet. So in the
beginning, they actually create more work in an apparatus. So there's more work for bosses and middle
management to work on. There's more work for implementation. And we see that almost in every
transformation, it actually productivity dips and effort and investment go up during that transitory phase.
But when you get past that and start to see some of those benefits, it changes dramatically how you
operate. So we'll go into organizations, we'll see 25 people sitting at a table for an hour long
meeting. And the first thing I think of is like, three of you need to be here. And this is so
expensive. Like you're raising so much more. And for us, it's gotten to a point where we say that the
small team is the ultimate flex. It means that if you've got a small team that can really run
effectively and you're using your tools and your infrastructure appropriately, then you can move so
fast. You can make decisions confidently without having to consult everybody. And most of those
meetings are really about CYA. It's about, can I distribute the liability of this decision across
a group of people? So it's not just my fault. Right. So with that in mind, you've talked before
about this notion of augmented teams and being able to use some of this technology to get more out of
an existing team or even restructure an existing team. What does that look like in practice?
Yeah. So there's a couple of things that we lean into to help augment teams. The first level is just
learning to use the tools. Like just by doing that, you're already moving 10 to 20% faster,
more effectively, better thought partnership with AI. But the next level is starting to actually encode your
own knowledge. So that can happen at a team level or an individual level. What I mean by including it
is taking things that you've written, whether that's briefs, emails, contents, and starting to
turn that into something that the large language model can work with and understand. It's a bit like
training a Laura on your own assets. And that becomes a bit of a digital twin. And we do this at the team
level, the individual level and the organizational level. What most people aren't seeing right now,
we're seeing a lot of that happen at the organizational level, but when we augment an
individual and say, okay, I've taken everything you've written at a, not everything, but the highest
signal, highest quality stuff that you've written, um, content about who you are, what you've done,
et cetera, and turn that into a document that sits on top of the large language model. And that becomes
the filter through which you prompt is to filter both going in and going out. So it's going to augment
what you're actually prompting against. It's also going to filter the responses that the LLM gives
you. So everything you do is going to be in your style, in your tone of voice, with your strategic
understanding of the business. And that can really expand your capabilities in a number of different
directions. Uh, the same thing happens with the organization, um, which helps enormously with things
like brain drain or bringing people up to speed. One of our goals is as an organization, if I bring
someone in off the street, I want to be able to get them to the same level as everybody else within
less than a month. And on day one, they should be able to write an email in the tone of voice of the
company. They should be able to manage their social media presence, all that kind of stuff, because we
built a layer on top of the large language model that already has all of that encoded rather than
having to teach someone to do that from day one. So it's doing two things. It's augmenting the
individual's capability and capacity. And it's also removing a lot of friction of having to become
up to speed on how your organization right works. Right. So, I mean, I, it's such an interesting
approach and I can, you know, immediately see like huge transformational organizational benefits,
you know, from an efficiency and effectiveness perspective by doing something like that.
Are you finding that there's resistance at an individual level to that? Like my concern would be
that people say like, oh, you're trying to like download my brain into AI and then get rid of
me. Like I can imagine a world where there's angst. Is that the case? And if so, how do you overcome
that? That's the very first response most people give is like, hey, this, this is my value. Like,
this is why you hired me to do this. And that becomes a conversation between the organization,
the individual and a contract of this is yours, not ours. So the goal with the data is for the
organization and the team level data that is owned by the organization. The individual level data must
stay with the individual. And this is a, this is a personal philosophy of mine. I honestly don't
believe that we can move towards a future paradigm where this is a part of the way we do our work
if that agreement doesn't stay into place. So it's like when you move from organization to organization,
you take your experience with you, but you're not taking the files you worked on at, at the office.
If I'm going to encode you and your thoughts, it's just like saying as an actor or a voice actor,
I've encoded your voice and no longer have to give you credit for what I extracted from you.
That by definition creates an antagonistic relationship between the organization and
the individual. I firmly believe we should own our data. So that's what we have encouraged and
facilitated. But yes, that is typically the way people look at it when they first start. It's like,
okay, the company's going to own everything about me. And sometimes the company are like,
oh yeah, that's, that's, we could really do a lot more with a lot fewer people. Like, no,
that will absolutely one, destroy morale and two, no one will want to come work with you.
Right. So are we, it's such an interesting idea. And I really, I hadn't heard that before,
to be honest. And I talk to people in this space all day, every day.
Okay. Um, so the idea of having this, like this individual, um, you know, digital twin
or AI-ified, uh, you know, likeness or, or, or, you know, data model of you right now,
I have to imagine if most organizations propose that to a staff member, that'll be like the first
they've heard of it. And they're like, whoa, you know, what is this? Are we heading toward a world
in the next few years where this is going to become the norm and, you know, everyone will
start to be literate around this and, you know, expecting this conversation almost?
I don't know. Uh, and the reason I say that is not because the technology is not ready for it,
not because it's not possible. It's that the, the limitations of how our organizations grow
are not just technological. There's so many different other constraints as to why organizations
change the way they do and why technological adoption is so slow. Um, there's a concept
that I love called Martex law, and it's, it's about the difference between technology moving
exponentially and people in organizations develop logarithmically. And what this does is creates
this ever increasing gap between what is possible with the technology and what the companies and
individuals are actually capable of. So we're looking at potential versus practical reality.
And the thing that's pushing this curve so much lower than this is infrastructure, technology,
culture, decision, debt, technological debt. There are all these constraints in an organization
that dictate how high that logarithmic curve can go and how far you can push that up. So the technology
can move as fast as you possibly could imagine. We are not going to be able to integrate and adapt it
as fast as it changes. We're already seeing that right now where you'll see some people
who are just, you know, they've hundred acts themselves, um, with what they can do, what
they're possible, uh, what they're capable of doing. And then everyone else is looking at them
like they're an alien. And that's because they, as an individual have leaned into it and are already
adapted a lot of this stuff. They've already had the experience to help them do that. Usually, you know,
really good engineers and developers can lean in in a way that can do that. But if you're a account
person who doesn't have that expertise, you look at that and say, there's all these limitations
preventing me from doing that. Organizations work the same way. Some organizations like ours are
small. We're built for this. We're native AI. Whereas a lot of the organizations we're working
with that are Fortune 500 don't have any of those things, any of those qualities that allow them to
say, we're going to be AI native tomorrow. Right. So, you know, this brings me to another
central question that I was excited to ask you about, Ian, which is who do you see as being the winners
and losers of this disruption? And I'm, I'm deliberately asking that in kind of the broadest
possible sense. Yeah. It's an interesting question for which I'm still forming an answer myself
because the initial thinking is like, okay, if we don't need big teams, then we obviously don't
need organizations that are 200, 300, 400,000 people. And all these startups are going to come and
take their lunch. And it's a lot more complicated than that. There are other structures besides just
size, keeping the, the current winners entrenched in their space. So let's take like a chemical
manufacturer for, for instance, like there's a lot of the corporate work that can be taken away by AI
and made more efficient. And you can use smaller teams for that, but there's physical apparatus,
there's mechanical apparatus, all that needs to be done. There's distribution, there's geopolitical
elements to how these companies grow. And again, that gets back to the practical limitations that
shape the growth and change of these organizations in new paradigms. So I don't think it's just as
simple as, okay, you need smaller teams, fewer people, companies will shrink and startups will come
in and eat lunch of those who don't move fast enough. Speed is one variable. It's a very important
variable, but it's just one. What I do think though, is companies will get smaller. But I also think
there'll be more startups and more businesses formed than ever before. If we just look at the
trajectory of the statistics, even since COVID, we've had a massive increase in the number of S
corps and LLCs formed more than any time in history. And that's likely to get even easier
as time goes on because the ability to form a company, again, gets easier with AI. The ability
to form a team gets easier with AI. So I think freelancing is going to explode even more than
our ES. So an acceleration of the existing trend, the ability to open businesses, the things that keep
people away from opening businesses is going to almost evaporate. And I think that the opportunity to
start creating these entities for even short time periods of times for more specialized use cases is
going to become a thing too. So I could easily see the number of businesses built in the next 10
years, a hundred X-ing, not just multiplying on that because we're also using agents for that too.
We're not using agents for employees, but we're using agents to build the business. So if you think
about how you can scale that, I'm still wrapping my head around what that looks like as far as what does
the economy look like? How do we align that in terms of geopolitics and how that becomes the way
organizations shape as well? It's a lot of things that still have not shaped themselves yet. So I
don't think it's just a small organizations, more business, but that's the closest thing I could find
so far. Right. And I'm glad you had that level of clarity because it's easy to just end up in the
mindset of smaller organizations, eating your lunch, you're done, good luck.
The, when I think about the implications of what I think we broadly agree upon, which is it's going
to be way easier to start a business. There's already more businesses happening. That's really
good for consumers, I would imagine. And it does mean more competition for incumbents. And I like,
I really like your point about, well, it's not just, they're going to eat your lunch because there's more
to it than, you know, just the speed or the efficiency there. You've talked before about
the need for transformational change versus just strictly optimizing what incumbents are doing.
How transformational do we need to be thinking? And what's the best way to get into that mindset?
Is it creating like an innovation incubator in your organization? Is it trying to start your own,
you know, kind of funded startups? Are there any kind of tactics you recommend with organizations?
Absolutely. So I think I would encourage organizations to be radical with their thinking
and practical with their approach. So there are too many people who say you kind of need to
break, burn it all to the ground and start fresh. There's no enterprise that says we're profitable.
We're doing just fine. We want to disrupt that. Nobody says that. But what I do think is,
unless you are radical with your thinking, you will not be ready for the disruptions that are
going to come. So these technological transformations that happen at GPT level,
so general purpose technology, start at the infrastructure level. So we've seen disruption
with technology and the technology that we use. So electricity did the same thing
and OpenAI did the same thing with GPT. So now we're all using it. But over time, those disruptions
move up a level from infrastructure to application to industry. So if you're not,
okay, I guess it is explosive. But if you're not thinking radically about the transformation that can
happen at each one of those levels, and also the transformation that can happen to your industry,
and you're just focused on the data of what you have now, you're missing one of the critical shifts of
transformation in the business. And there's a theme that's becoming more popular right now is moving
from insight to foresight. And when everything is changing around you, insights valuable. It's how
you create structure around a business that you can take to market. Foresight is about how you avoid
getting disrupted. If we're not looking forward, and we're still letting yesterday's mental models collide
with tomorrow's technologies, that is how we lose. But if we are being radical with the way we think,
with the ability to test different business models, put things to market faster when we might not
previously get that data and that feedback loop as fast as possible, we're going to learn more about
that unexplored terrain way faster. So I wouldn't say go and disrupt your $1 billion revenue line,
but you absolutely should be incubating things that will, because there are hundreds and eventually
thousands of other startups that are doing exactly that. And you will have no defense against that if
you're not thinking in that way. So think radically, approach practically. So that next step goes,
okay, so what do we do to implement this? Is it tiger teams? Is it small skunk works?
All of those are viable. I do believe that having in its transformation, you need to find people who
are leaning in and already self-selecting as the people who are like, I'm all about this. I want to do
this. Don't try and convince a bunch of people who might not be invested in this to be the first ones
through the door. They will be unenthusiastic about it. They don't have the willpower to get
through the challenges. It's going to be hard and they're going to fail a million times before they
get it right. If they're not already passionate about this, they're going to stop at the first
sign of trouble. Those people can be followers of the people who lead the way. It's not that they're
irrelevant. You need to find the people who are like, I want to be the person who kicks the door
down. I want the first person in the room. And those are the ones you want to build your teams
around to think about these things and build different ideas and find the tinkerers, find the
people who may not be the developers or the engineers who are already tinkering with this stuff.
There are so many people who are using AI and building their own agents or creating side
businesses on the weekends who could also be resources for this. And that's the culture that
will create new opportunities, new business models. And they're going to learn what these new
paradigms look like by doing the work in that space that then can be diffused across the organization.
And that's the second most important part. Once you have the knowledge, do you have the
infrastructure set up to diffuse that knowledge as fast as possible and as thoroughly as possible
across the organization? Otherwise it just stays compartmentalized and it dies on the vine.
Right. And I'm glad, Ian, you used the word culture because I'm curious. We talked about
Martech's law. We talked about the need to, I don't know if we use these words, but bend the curve
upward to try to keep pace with technology, to try to compete. You know, to what degree does culture
play a role there? Is it the most important thing? Is it in the top five? And if it's not the most
important, what is the most important? I do think it's the most important thing
because if you don't have a culture or can't create a culture that is willing to lean in and say,
Hey, things are going to look so different in the next couple of years that we won't even recognize
it. It's up to us to make that change. You're not going to get there. If everyone is waiting for the
vision to be given to them, to take action, it's already too late. And that's one of the biggest
challenges is a lot of organizations. We built this expectation that when the CEO gives the vision,
then people act and people start to live near it. If people aren't leaning in and saying,
I'm in R and D too. Like I I'm actively in research and development of what my own role looks
like in my organization, my own profession looks like, because you're going to encounter this no
matter what role you have or what company you work at, you go work somewhere else, it's still going to
find you. So we, as individuals have to take ownership over this. If we want to maintain relevance
in this space, this is not an us versus them up versus down organization versus individual issue.
It's a collective one, right? So if that's recognized in a healthy way within an organization,
that creates a camaraderie, a collectivism that can move an organization forward.
Right. If everybody's kind of, sorry, I'm going to use the silly, like, you know,
this, the silly idiom about rowing in the same direction, right? But having that purpose and
everybody kind of banding together to move the organization forward.
But it's so true. And so, so spot on. Yeah.
I want to, you know, with that, I want to come back to, you know, another kind of quote you had,
which is moving from insight to foresight, which, which I love, by the way,
where does foresight come from? And, and can it come from AI? Because my sense is with like a lot
of these tools, they can summarize what's already known, right? Like they aren't necessarily taking
you forward. They're just telling you the sum of what we know up into this point. Where does foresight
come from? Right. So I would actually disagree with that a little bit. My perspective is that
large language models are commodifying. Like they, if you just use the large language models,
there's a period of probably two more years where you can have an advantage over many of your, your
colleagues. But over time, it's just going to be like, I use email, big whoop. So does everybody
else. It's literally a commodity. And the difference is going to be, how do you use it? And then how have
you encoded your knowledge into doing that? But specifically on the foresight piece, it's,
it's about searching for signals and how you combine things as the user. This is a place where we're
still very much in control. I don't think this is the kind of thing you want to automate.
What you can automate is searching for signals of change. So foresight is really about finding those,
those data points that are outside of the normal distribution that say, this is different. Like
you should, you should pay attention over here and validate whether or not this is something that you
should be investing your time in or concerned about. And in foresight, if you talk about formal
foresight, there's probable, plausible, impossible futures. There's a whole bunch of structure around
it to create really good thinking about what's to come. But I think that can overwhelm and over
complicate people. We all have a responsibility to think about foresight. What does my role look like
in a world where I actually don't have to go to six meetings a day? Oh my gosh, sounds amazing.
But what's my new responsibility? Cause there's more on me now. And like not thinking that through
puts you on your back foot and it makes you subservient to the vision of whatever else is
happening around you. So when it comes to foresight, we should be thinking about, well,
what if this happened, how would I react? And it's not about fortune telling or predicting the future.
It's about seeing the signals and patterns that are starting to arrive and understanding the scenarios
of how might that affect me? How might I react? So that when something does actually come your way,
you can say, ah, you know, I've seen something that looks like this before, or this rhymes with
something else we've already thought through and you're adapting versus reacting. You're proactive
versus reactive. And I think the best organizations in the world do an enormous amount of that.
The ones that don't are the ones that really do get caught by surprise. And we'd see a lot of
enterprises in that space right now. But I do think that the foresight is where we need to lean,
because it's also where we can have a lot more of our human agency using the models and the AI and
the tools to bring the data into us, to help us identify what's different and say, what does it
actually mean to me and using AI as a thought partner in getting to clarity. Right. So on the
note of what it means to me and to be honest, Ian, I'm surprised and very intrigued to hear you say that
more of the foresight can be done by these tools than maybe we imagined before. And I'm curious,
and this is sort of a self-serving question for both of us, but what role does an organization like
Signal and Cypher play in this world, right? Is this something that, oh, well, the tools can do it.
AI can do it. You know, we don't need partners to help us with this. Where does an organization
like yours come into play to help actually accelerate traditional enterprises?
Absolutely. So to create a little more clarity around that, I don't believe that the AI tools
can do this on their own. But I think that they can facilitate our own work in coming to an
understanding of what possible and plausible futures could look like. So a lot of the research
that one would do to do future scanning and signal scanning, to find these opportunities we should
be looking into, can be massively accelerated, scaled and assisted using large language models.
It's still up to us to say, how does this fit with my strategy? How does this fit with
the market dynamics that I'm seeing play out? So it expands and augments our capability to do it.
And it makes it so people who are unfamiliar with this can dive in even faster. So it's less
intimidating to get into that space. There will be more and more automation of that as time goes on.
And who knows, maybe in five, seven years, we could actually say, okay, just go run and create,
you know, do a Monte Carlo simulation times a thousand for me and pull these all together
and then give me that data and tell me what my future looks like. I don't think it'll be that
simple, but there could be a world that that looks like. But for the work that we're doing,
our focus is on helping organizations get that to become part of their culture. So it comes from
training that comes from building that data layer that goes on top of the large language model and
coding their knowledge so that they can understand how the signals that come in from the outside world
are going to impact them. How might they respond to that? And also scaling the internal workings of
the organization. So they can be more efficient and effective things we talked about at the very
beginning. We're not eliminating that, but what we're doing is expanding the capacity and ability for
them to operate in spaces they never could have before. So where that changes is organizations might
say, well, okay, I can use this. And now I only need a three person marketing team instead of a 25
person marketing team. Company A might do that. Company B might say, Hey, for the last three years,
we probably had, if we go back and look at our backlog, three or 400 products or projects that we would
have loved to pursue, tested and gotten data on that. There's no way we'd have a team of 500 that we would need,
but you know what? Now we could do that with 25 and all of a sudden running simulations, putting
products together, testing things, getting that data becomes possible at an enterprise scale from
a small team and you're exploring new opportunities in unknown territories. So you have this expansive
mindset versus a contracted mindset. One works very well with industrialist capitalist mindset. One works
very well in a time of transition where new markets, economies, and form factors are starting to
develop, but we don't know what they look like yet. So that's what we encourage companies to do is say,
rather than saying, you're going to lay off 50% of your workforce and do more with less,
do more with the same. Expand our skill sets, expand capacity, expand possibility.
And that is really where we see the most value.
I want to talk. I love the, I love the dual approach there and it makes, it makes complete sense to me.
I'm curious with the second scenario you talked about where it's 25 people,
500 new products or tests or what have you. One of the things I've found, and I'm curious if you've
seen it too, or you've seen something different is in this emerging world where technology isn't the
limiting factor anymore. And it's like, if you can dream it, you can build it, you can test it.
At some point, the bottleneck becomes the market or it becomes your staff, or in some sense,
it's people's ability to actually try and digest new things. And my sense is you have to still get
back to prioritization in some capacity, because even if the technology can give you 500 new things,
you're going to be limited somewhere. Do you buy that? And what are the implications?
I absolutely do. I think that what that does is it shows another weakness in the current paradigm
for the future that we're trying to create. We go through these phases of oftentimes 150,
200, 300 years where the economic paradigm also shifts. So the one that we're currently in
is identical to the one where we built the steam engine and connected geographically disparate places.
The metrics that we use are still the same ones that we used with some modifications
when the steam engine was a cutting edge technology. So what that does, it shows that
the paradigm that we're in is kind of the ultimate bias. A paradigm shows you what's important. What
do you measure? What questions are worth asking? And all of those are still very much directed towards
the capitalist system that we have now. And I'm not saying this to capitalism versus socialism
versus Marxism type of argument. It's what does capitalism 8.0 look like in order to start to
expand its environment. So these new types of businesses could become possible. So there will
be fully autonomous organizations that have zero humans evolved. And what does that look like?
It's not a full replacement for humans. That would be like saying the digital office replaced paper.
It obviously did not. That digital killed analog. Analog is still is absolutely decreasing,
but it's not zero and it won't ever be zero in my opinion, but it creates this fragmentation
of what we saw as like the dominant paradigm. And it creates space for coexistence of all these new
models, mental models, operational models, and economic models. We don't know what those look
like just yet because we haven't seen many of them succeed. We're seeing some signals when we look at
companies that are, let's say on the lean AI leaderboard, which is a reference I love.
You know, average 3.3 million average revenue per employee. You know, time to scale is absolutely
insane. And we look at these organizations that are AI native. They're starting to show what some
of those paradigms could look like. If you extrapolate that from, you know, 10 people, 50 million ARR
and say, what would it look like with one person, 150 million ARR, what apparatus and infrastructure would
you need? What would it look like to operate as that individual? And that can give you some of those
signals I was talking about earlier of what possible probable and plausible futures could look like.
But I do think that how we look at capitalism today is going to change dramatically. And it's
not just a technological question. It's a social question. It's an economic question, geopolitical
question. And that's why AI is all of those as well. So these things are all coming together at the
same time. And that's another reason people kind of feel like they're being thrown off balance in every
direction because everything is changing all at once. Right.
So throughout this conversation, I feel like I've started to be able to put together a mosaic of
like your view of the future through, you know, a series of different lenses and also some spaces
where you say, you know what, there's still too much uncertainty here. Is there anything you can tell
me about like your predictions for the next five to 10 years that we haven't covered that
like you're pretty confident we're going to see? Yeah. I would say that the paradigm around
training skill sets and education is going to change dramatically. And that has profound
implications for the work that we do and how we go about that. One of the things I talk about is skill
flux. And it's this concept that we go from this paradigm of, you know, 30 years ago, you could have
a skill set that lasted you 30 years before shelf life was obsolete. Now, you know, someone like me,
I had a skill set that was, you know, 10 years, it was valuable. I started off as a mobile strategist
for an agency. You don't hire those anymore. It just doesn't happen. Right. You might at an
enterprise level if you're like Cisco and doing software, but not in that environment. And the
skill sets that are valuable are shortening on their shelf life. And for more technical skill sets,
those are arising and disappearing faster than ever. So now we're at like two and a half years for a
technical skill set. And I could see that shrinking more and more and more is the point where many of
them are arising very quickly and gone the next day, six months. To give you an example, I think
coding and prompt engineering are two versions of that. So prompt engineering became something that was
relevant about two years ago. I would give that maybe a five year shelf life max before it's no
longer relevant at all. And we're already seeing agents being able to take on a lot of that work.
Um, but there will also be a new skill set that you'll have to learn in order to operate in a new
paradigm with new technology and new objectives. So we're going to see this exponential increase in
importance and value and a chat GPT moment that comes in and says, that's not valuable anymore.
That's gone. Right. And that's going to have this almost like whiplash for us as we go along.
That changes how we educate ourselves is if we're front-loading education for the first quarter of our
lives, we're out of date by the time we walk out of university. And this is not a new discussion at
all, but it becomes exacerbated by that. So the idea of lifelong learning, you know, very cliche,
but micro-credentialing, uh, we call it surge skilling, where it's like, you're actually having
to get very deep into something very, very quickly to create competitive advantage. And then you just
know that this is going to be less valuable in a certain period of time. But what is valuable is being
that first mover and creating value with it as fast as possible before, before it comes obsolete.
So that's where I see education changing, where I see people shifting their focus for competitive
advantage and the culture of organization changing too, because you're going to have to keep learning
on the job and the tools and the AI's you're using will have to teach you how to work with it as they
change. So I'm, I'm really glad Ian, that that was your answer. Cause that was on my list of things
that I wanted to talk to you about that we hadn't gotten to yet. Um, with that in mind,
these, the, the shortening time horizon of skills, you mentioned, you know, it's going to have massive
implication on education. What do you see as being the risks and the opportunities for the traditional
education system? Um, and also what does it mean for like the hiring process of organizations?
Absolutely. So it completely disrupts the one to many broadcast model. Like the idea of a teacher
you're standing in front of a room and speaking for an hour and a half to three hours is gone.
Um, the, which is great for people like me, I was a terrible student, um, super neurodivergent.
I can't sit in a class and listen for more than five minutes. I have to be engaged.
So what this is going to do, it will disrupt the current model, but it will make it amenable to a
much larger group of people who are not built for the more industrial ask, um, manufacturing, like
education model, the challenge though. And, and I don't say that with, with any, um, malice towards
teachers and educators, they are some of the most under-resourced over tax and over expected people
in the world. And then you take a look at the dynamic in the U S and how hostile it is. I have
so much empathy for people who choose to go into a life of service for the next generation. We need to
be spending a lot more time and money in that space. And I make a comment in my keynote where I say,
the L and D budget should be as big as your technology budget. And that kind of like people
would bug eyed at me like what, like what we're spending. So we're spending trillions of dollars
on technology. I love that. I love that. Yeah. But if we don't like the technology is moving faster
than any other sector, faster than the economy, faster than society is moving faster and education
is moving. And if we truly want to understand where humans play in that picture, the fact that we're
investing everything we have in technology has already indicated our preference for technology
over humans. So that math has to balance out a bit. We have to figure out how do we invest so much more
into education, not so much less. And until we do that, we are going to be behind the eight ball.
We are going to have a target on our back in many ways, because if the paradigms don't change,
the technology gets better. We're going to suffer the consequences. But if we put ourselves front
and center of that equation, we have the chance and the opportunity to figure that out.
Right. It's wow. Yeah. As you said, this is not an incremental shift. This is like
a complete disruption of the model from end to end.
Without a doubt. And even for people who live and breathe it, it's overwhelming for me.
I do this 24-7. I love it. I'm passionate about it. I'm excited about where we're going.
And net-net, I'm optimistic about the long-term future. But we are all pioneers right now,
whether we want to be or not. And we've kind of bastardized the term pioneer. We've made it seem
like, oh, it's Richard Branson on the cover of Entrepreneur Magazine with his billions of dollars
of success. He was a pioneer at one point in time, but pioneers do really hard shit. And they go to
places where there's no infrastructure. They suffer the consequences of decisions that they didn't know
they'd have to make. They are attacked by the environment that they're in. Nature tries to kill them
in a number of different ways. And as a super resilient species, we still make a way forward.
We construct the environment after we figure it out. We might show up in Hawaii with snowshoes on
and realize, oh crap, I'm not properly equipped for this. And then we figure a way out. That time to go
from not knowing to knowing can be really hard, painful, and challenging. But the way we thrive once we
do is absolutely amazing. So I would say that we are going to have amazing things happen,
but we're also going to have to encounter some really tough growing pains individually and
collectively to get there. So if anyone's saying otherwise, it's absolutely smoke and mirrors.
Right. Right. Wow. Exciting times ahead. There's one more question, Ian, that I wanted to ask you that
I haven't had a chance to yet, which is I wanted to ask you the inverse of what I just asked you,
which is, you know, aside from like what is going to happen and what's going to disrupt us.
Is there anything you're hearing right now, hype wise, technology wise, trend wise that you're like,
that's BS. Like that's not actually going to come to pass. We're being sold a bill of goods.
Yeah, actually, I think the agents conversation is way over height. I think they are transformative.
I don't know a single organization that is going to say, I'm going to let an autonomous series of
agents run my enterprise that I've spent decades building without the oversight necessary. Like
we've, we've been working with agents for years and we've been building setups where agents will
work with other agents and giving them autonomy and creating virtual environments to see what happens.
And every time we let them run amok, it's frightening. Like it is absolutely like jaw dropping. Oh my gosh,
I can't believe that would have happened. So glad I didn't get them freedom to access real live data.
Yeah. And that, that infrastructure needs to be built. The, there are actions that agents can
do that are absolutely mind blowing, but they're, they're narrow, they're specific, they're structured.
And they have strong guardrails. The idea that we can kind of have this almost reinforcement learning,
you know, give it a million different examples, let it kind of like bang around and figure its way
through approach to unleashing it in the organization does not work. Um, because the
infrastructure is just not there yet. It hasn't caught up with the promise of the technology.
So I think we're very much at the top of the hike cycle of agents. We're going to have this
crash into the trough of disillusionment, which in my opinion is the best place for a nascent
technology to be. Um, a lot of people say less bad, but what it means is the people who are making
promises who don't know what they're talking about. And let's face it. There's an enormous amount of people
who are rushing to find the gold that have no business being here and making promises.
They disappear because it's now it's getting hard. You actually have to deliver.
And in the trough of disillusionment, it pulls all the pundits out. And now the people who are
committed to doing the work, who are there for the right reasons, they get to work and they build
that infrastructure that's necessary to deliver on all of those promises we were making back here.
So it takes time. And I, I'm just kind of waiting for that to kind of implode on itself and for people
to say like, Oh yeah, these are very, very powerful. This is absolutely the paradigm of the future,
but that future is still the future, not the present. We need to get there first.
Right. I love that answer. And, um, I think it's so appropriate right now, given where we are in
that height, hype cycle. So, uh, thank you for taking some of the air out of that one. That's awesome.
One of the things that maybe I can put a finer point on is the metrics piece, and that is the
expansive versus contractive. So what I was talking about earlier, as I was mentioning,
a lot of teams are going to say, let's, let's do more with less. Let's pull back the number of
resources that we have and get along and have higher efficiencies, greater margins and best,
better stockholder returns. And the challenge that we have is we're moving into a paradigm that is
going to shape what matters and what matters and what's valued in the work that we do is going to be
different, but when what matters changes, but the metrics do not. And the incentives do not.
Yeah. Yeah. That means you run right into a paradigm that is going to push back on you and
potentially hurt you as an organization. So we encourage organizations in time of change
to also understand how is this going to change the incentives and the metrics that I use to measure
that change as it's happening. So we're thinking more about growth metrics, metrics of innovation,
metrics that are about charting the unknown versus optimizing the known. We've come from a paradigm of
optimizing the known for the last 150 years. We're really good at it. The problem is how much is known
about the next five years. So if we're doing 95% of our metrics on optimizing the known 5% on exploring
the unknown, that means you're already out of date. If we're starting to push more of that towards
exploring and charting this unknown territory, this makes us more prepared for what's going to be coming.
This gives us the opportunity to think about innovation quotient, knowledge diffusion across
the organization, building the structures that will make you resilient in this future paradigm.
Because right now, optimization to scale by definition requires some calcification of the
organization. It needs to be rigid in some ways in order to be efficient and rigidness against an
oncoming wave is a recipe for disaster. So that's one of the things we encourage organizations to think
of too. And we get very deep into what is that metric? What matters for you? How is it specific
to your context? What are the things that you measure? How do you actually do that work?
And when that clarity is there, all of a sudden it goes from, well, we don't know what the future
brings to, oh, well, at least we know how to move in that direction.
Right. And with respect to the fact that I'm sure there's lots of different metrics for different
organizations, is the answer to just move to a new set of hard metrics or get more comfortable
with the notion that we need to be flexible and measure things with a little bit more flexibility
than we have in the past? Absolutely. That's typically the first step. You never want to shift
entirely because you want to leave what's working, working. So we don't say you've measured this way,
don't do that anymore, but at least a portion of the work that's being done needs to be done in this
forward-facing way. And that type of work needs to be measured differently. Because if you're measuring,
for example, a lot of teams, a lot of tiger teams, a lot of innovation teams are measured by ROI on their
first run, which is mind-boggling to me. Okay. Right. You're going to have impact on margin
the first time you touch chat GPT. No, that doesn't, that doesn't happen. No chance. And I think
that's almost a bad example because that's just ludicrous on all levels. But if you're thinking
about scale efficiency, margin impact on things that are by definition going to require investment
and time, you're already impeding the work that is going to help you explore unknown territory.
Yeah. No, it's, it's super interesting. And yeah, I'm sure we could talk for another hour just on,
just on that. With that in mind though, Ian, I did want to say a big thank you for joining me today.
This has been super, super interesting and it's honestly been a real treat. I talked to a lot
of people in this space and I'm just continuously blown away by the breadth and the depth of insights
that you have in this space. So I wanted to say a big thank you. Thanks, Jeff. It's been an honor
to join you. I really enjoyed it.
