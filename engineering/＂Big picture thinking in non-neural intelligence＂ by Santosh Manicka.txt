Right. Thank you so much, Gautam and Leo, for inviting me and giving me the opportunity
to talk to all of you. So today, I'll be talking about some of the research that we have been
doing in our lab, which is a regenerative and developmental biology lab. We have a small
computational group and different people are working on different kinds of projects, ranging
from detailed biophysical models and machine learning projects. And I've been working on
this theme of cognition in non-neural systems, and I've been exploring this idea using minimal
modeling. So I want to start with this idea of intelligence, because intelligence is a
very vast topic, and there are many different schools of thought, as you may know. But
for the purpose of this talk today, I want to focus on this unique distinguishing character
of intelligence, which is big picture thinking. So as you know, many scientists come up with
some original ideas with the help of some sort of intuition, you know, typically takes the
form of some sort of big picture idea that then boils down into some details.
You know, one great example of the many hundreds of examples is the quicksort algorithm. It was
invented by a computer scientist named Tony Hoare in the 1950s. So he was grappling with the problem of
sorting arrays of objects, and it could be numbers or anything that has a smaller or larger relation.
And so the big picture idea that he came up with was this divide and conquer strategy. So you have an array of numbers, you partially sort the entire array, and then you divide the array into two, and then you partially sort each of them, and so on and so forth. You keep doing this until you end up with small bits of arrays, you put them together, you get a fully sorted array. So,
So, so that, of course, there are details in this algorithm that will make it work. But I will take this perspective that the intelligence behind this algorithm was this big picture idea of divide and conquer.
So, of course, of course, of course, of course, of course, it was a human and there's a human brain behind it. And so he was able to use this top down idea of starting with the big picture, and then working out all the details.
So, in today's world, we have these big machines and neural networks and large language models that are kind of flipped the other way around. So they start bottom up, right? And come up with complex ways to solve very difficult problems.
So, for example, we have this neural network that can detect faces. So you input images of faces, and then it will output whether it will tell you what kind of face it is, like does it belong to a human or does it belong to a dog, and stuff like that.
So if you look at this neural network, it has thousands of parts, right? You know, hundreds of weights and thousands of connections, there's biases and so on and so forth. That's what we give the machine, right? We don't give any high level instructions as to how to solve this problem, but still the machine comes up with some sort of algorithm.
Typically, typically, we don't know what the algorithm these machines adopt, but we do have some idea. In fact, there is this whole branch of science, which is a hard area of science and research these days known as interpretability.
So they try to analyze these complex machines from neural nets or large language models, and try to shift the high level strategies they try to follow, right? So in the case of these neural nets, we know that the high level strategy that they follow is basically assemble small primitive images into more and more complex images.
So it is literally sort of building a big picture in this case. And there is this example of Google's cloud, large language model. So when you ask it to complete a sentence, it starts with something like the capital of the state containing Dallas is what?
So if you look at it. So if you look at the internal details, it actually does a lot of linear algebra to give the answer that is Austin. But in a recent paper, it just recently came out, they call it the biology of large language model.
They did some analysis of how these algorithms work, and they found that they follow a two-step reasoning, very similar to what a human would do to answer this question.
In the first step, it figures that the state that contains Dallas is Texas, and in the next step, it tells you that the capital of Texas is Austin, right?
So in both of these cases, we have either a full-fledged brain at work or something or some, excuse me, or some sort of machine that is inspired by the brain architecture, right?
So by brain architecture, I mean networks that have, that might have long-range connections, you know, axons are much longer than the size of the neurotic cells,
or some typically some sort of feed-forward architecture that is inspired by the architecture of the visual cortex in the brain.
So the question that we are interested in our lab is, what about non-numeral systems like, say, an embryo or some sort of somatic system, right?
Do they also follow some sort of high-level algorithm or some sort of high-level strategy that is hidden in plain sight, right?
That's the kind of question that we ask about neural networks these days.
And like the example that I showed before, we do get, sometimes we do get answers, like, you know, this complicated-looking neural network follows a simple two-step reasoning.
So the question that we are interested in is, say, for example, might embryos, which starts from a single cell and develops into this full-fledged, beautiful, complex pattern,
like, do they also follow some sort of, you know, high-level strategies that result in this complex pattern formation?
You might think that this is not an example of intelligence, but I think, and some of us in the lab,
we think that maybe it can be characterized or cast in the form in terms of intelligence and cognition,
because it's not an easy task to turn something very simple, a single egg, to something very complex, like these patterns over here.
So what we, and also there is this more interesting question of whether evolution may be looking for these sort of organisms,
or is it trying to design organisms that have this high-level strategies, but it's not evident to us.
It's not, it's kind of hidden in plain sight.
So this, that's the thesis that Mike Levin, who is the director of our lab, he posted in his recent paper,
where he proposed that maybe evolution is searching in the lower-dimensional space of these high-level strategies,
because these strategies are, by design, simpler than the higher-dimensional space of lower-level hardware,
such as gene networks or physiological networks, and so on and so forth.
So this is the kind of motivation for a lot of research that we have done here.
And so I will be walking you through a few examples that make this idea concrete,
and those examples involve minimal models that are tractable, and that's why we are able to analyze these models
and sift out the big-picture algorithms or strategies that they may be following.
And those minimal models recapitulate some sort of biological phenomena, such as development,
such as pattern generation or pattern detection or some sort of bioelectric regulation of morphogenesis and so on.
But before I get to that, I want to start with a pedagogical example.
And maybe I might have to do this at the expense of some research, action research examples later,
because I thought that for this audience, maybe starting with a very simple, concrete example,
make things very clear as to what we mean by these high-level strategies and how do we identify them.
Because we can do this even on very, very simple models.
So this is the first example, the pedagogical example that I want to start with is this notion of action at a distance signaling.
So let's say we have a chain of cells. You can imagine this as some form of tissue.
And let's say we want one of the cells to send a signal to another cell, but without the intervening cells knowing.
So in a way you don't want, you only want one receiver cell to be able to read your message and you want the other cells to just relay the message.
So you can imagine that this would require some sort of, you know, intelligent behavior, right?
Because somehow you want to hide the message from the other cells and you want only one cell to be able to read the message.
So something like, you know, you have a chain of cells that are all in the black state and you flip one of the cells at the end of the chain.
And you want the signal to propagate through the chain to the other end and you want the contralateral cell at the other end of the chain to also activate.
But you don't want any of these intervening cells to activate, right?
So computationally, you can imagine that this being equivalent to something like exclusive R, which is a nonlinear problem in computer science.
And that sort of stumbled neural network research for many years, believe it or not, during the 1960s and 70s.
So here you want this chain system to self-organize itself and be able to categorize the cells at the end of the chain into one group and the cells in the middle into another group.
So it's a nonlinear problem, but still it's kind of simple, right?
So there is a way to solve this problem.
So before I get to the model, I want to sort of do a quick refresher on some dynamical systems concepts known as stability and bifurcation,
because I'm not sure how many of you are familiar with these concepts, but I'll try to keep it simple.
So dynamical system is basically a description of how things change over time.
And so here is an example of a dynamical system in one variable.
It's a one dimensional dynamical system.
And the dx by dt tells you how x, the variable x changes over time.
And it's a simple cubic equation, so it's a function of x and another parameter d.
Just two things that can determine how x changes.
And you can graph this equation like this, where the horizontal axis is x and the vertical axis is the rate of change of x.
And it is a third degree polynomial, so it's a, you'll see, when you graph it, you'll see a line that has two points of inflection that looks like this.
And where this curve meets the zero line, that is the line where the rate of change is zero.
Or exactly where the solutions of the system lie, you know.
Those are the points where x stops changing and it will just stay there.
And depending on how this curve meets the zero line, you can determine whether the system has stable solutions or unstable solutions of a mixture of both.
So for example, when d is equal to minus two, you have this curve meeting at the zero line at three points.
One over here, the other over here, and over here.
But these two solutions, the black and the white, are known as stable solutions.
Because if your system, if your x is at this value, and if you move x a little bit to its left, it will come back to it.
And if you move it a little bit to the right, it will come back to it.
Likewise, the white unstable equilibrium, if you move it a little to the left or to its right, it will come back to it.
But the gray is known as unstable equilibrium.
Because if you move it to the left, it will go to the black state.
And if you move to the right, it will go to the white state.
So white and the black states are stable equilibria, and the gray state is unstable.
Now, so this is if you fix the parameter d at this certain value of minus two.
But if you increase d, you'll basically lift the curve above the zero line.
And suddenly, you will end up with just one solution, one stable solution, which is the white circle over here.
So what the d parameter does is basically shift the system from being bi-stable, like over here,
to being monostable.
Here, there's only one solution.
Here, there are two stable solutions.
So that's what the parameter d does.
And somewhere in between, we have this systems lying at the edge of bifurcation.
And this is often referred to as tipping points in the system.
So we will leverage this idea to design a system that will self-organize such that it will place the cells at the end of the chain,
to lie at the edge of bifurcations, and the cells in the middle of the chain to lie far away from bifurcation.
So this way, when you perturb the cell over here, it will lift the curve a little bit.
So this will switch the bi-stable system to a monostable system.
So the black state will head to the white state in the form of a flash, and it will send the signal down the length of the chain.
But so meaning that the curves of these black cells would also be lifted, but it won't be enough to cause a bifurcation.
But when the signal reaches the end of the chain, it will cause a bifurcation over here.
So the cell at this end of the chain will also switch from black to white, but all of these cells in the middle will not change states.
So this is a very simple sort of trivial way to design the system of secret message passing, if you will.
Now, you can write down systems.
So that's sort of the intuition.
So I actually designed a system that makes it work using two molecules, if you will,
a signaling molecule that follows a reaction diffusion, a very simple reaction diffusion system,
which often non-neural systems like skin or things like that, somatic systems, even embryos might follow.
And there is this readout signal, a readout molecule, which does not follow any diffusion.
So it's just a readout and is determined by the signal, but it has its own reaction system to follow.
So I optimized the system.
Basically, the parameters in the red are optimized and using machine learning.
Let's not go into the details, but I just want to point out that this is a very simple system, and I'll just show it in action.
So this is a nine cell chain.
So I will run it now.
So what you will find is they all start from a homogenous initial condition.
And after a while, they will settle into some state.
And at the middle of the simulation, I will introduce a sine wave at one end of the chain.
And what it will do is it will flip this cell from black to white.
And then after a while, you will see that this cell over here will also flip from black to white.
But none of these cells in the middle, they will just retain their states.
Yeah, so this is like a 40 second simulation.
And about so right now, all the cells have settled to some equilibrium state.
You can already see that these cells at the end, ends of the chain have slightly different values.
That's because those they are teetering at the edge of bifurcation.
So now we introduce the perturbation over here.
So this cell changed from black to white.
And towards the end of the simulation, you will see that the cell at the other end of the chain will also switch its state to white state.
But nothing happened here.
But still the message was passed down the chain, right?
So I guess the point here is that this is a very sort of simple problem, you know, but still it requires some sort of minimal or primitive intelligence to solve this problem.
And the intelligence, quote unquote, is basically a cell at one end of the chain being able to trigger a cell at the other end of the chain, but not disturbing anything in between.
So what we have been doing in my research is make this intuition more concrete and visualize these high level strategies that these systems are following by constructing so-called causal networks.
So basically it's the system I showed you before is basically a differentiable system.
So you can compute derivatives of how the readout molecule changes over time as a response to small changes introduced in the signal and or any given point in time.
So different timescales and you can visualize these derivatives in the form of networks.
So when we do that, what happens is at short timescales, these causal edges are all locally contained, you know, it's because our model itself is kind of, they have short range connections.
But over longer timescales, you will see that these, you know, long distance causal connections emerge.
And at the longest time scale, you will see that all of these causal edges point either to one cell at the end or to the other cell at the end.
There are no causal arrows that point to any of these cells in between.
So basically this sort of high level strategy of one cell being able to trigger causally the cell at the other end of the chain is visualized in this form of causal networks.
So this high level strategy is made concrete in the form of causal networks.
And we see that that has enabled these cells at the end of the chain belong to one category and the cells in intervening cells fall into another category.
So this is, this is the kind of approach that we have been using to analyze how models work and to think about what intelligence is or what their high level
characterized, intelligence characterized as high level strategies is and visualize them as causal networks.
Okay, how am I doing all the time?
Okay.
And by the way, please feel free to stop me at any point in time and ask me questions.
I have like three other examples.
If time, if there is no time and just do two examples, and I think that should be enough.
But you please ask me questions at any point in time.
So before I go into the models that we use in the research, I just wanted to give you an idea of what sort of modeling approach we have been using.
So if you think about modeling approaches, there are this phenomenological models, something like Ising models on the one hand, which, which are pretty generic, and they have been used to understand a whole variety of phenomena.
And on the other end, there are this highly detailed biophysical models, such as CELSIM, and that is something called BEPSI in our lab, which is used to investigate bioelectric phenomena.
And what I've been doing in my research is a modeling approach that combines the minimal simple features of phenomenological models and also biological constraints.
So this is what I mean when I say I've been using this minimal modeling approach.
So I've been walking through three different examples that recapitulate three different phenomena, biological phenomena.
But one thing I want to notice in these models is you can see that all the connections are local because that's how non-neutral systems are typically constructed.
Of course, there are these tunneling nanotubes and microtubules and stuff like that that do facilitate long-range connectivity, but they are not as conspicuous or not as widely studied as, say, axons in the brain.
So we typically characterize these non-neutral systems as those with short-range connectivity.
But what I hope to show is that when we analyze them using this causal network framework, we can throw away these local connections, and you can see that these long-range connections emerge,
and they form these sort of patterns that will help you understand exactly how these complex-looking systems are solving the problems that they were designed to model.
And so that will tell us the intelligence mechanisms or strategies that these models adopt to solve the problems that they have been.
Yeah.
Santo, can I quickly ask you something about this?
Yeah.
Just to clarify.
Yeah.
Because you just mentioned also like long-distance connectivity, for example, and that are normal tissues that are non-neural, that you normally don't have these long-range connectivity connections, right?
So what you're saying is that you observe emergent phenomena that are completely based on local interactions that are similar to the long-range connectivity networks, but simply take more time.
Is that what you're saying?
Exactly.
Yeah, exactly.
Okay, perfect.
Yeah.
Yeah.
So that's the idea of timescales, right, in the causal networks.
If you're just looking at short timescales, you would think that all these connections stay local.
But if you look at longer timescales, then longer, like more complex patterns emerge, and that will tell you how exactly those models break the symmetry sometimes,
and develop those long-range connections to solve the specific problems that, you know, that they're designed to set them on.
Yeah.
So that's what these red dashed arrows indicate.
Right.
Right.
So, yeah.
So, yeah.
Sorry, I apologize.
Just one very quick clarification question.
When you say genetic network, are you talking sort of gene expression there, or is that correct?
Gene regulatory networks.
Fantastic.
Thank you.
Yeah.
Yeah.
In principle, they are equivalent to neural networks that we've been using, because they also sort of follow the sigmoid functions.
But to me, they are all just dynamical systems.
But yeah, gene regulatory networks is what I refer to you.
Okay.
All right.
So let me start with the first example, which is the simplest of the three, in my view.
So biological systems, embryos, it's almost like universal phenomenon that a featureless set of cells that typically look like some sort of blobs that have many symmetries, develop some sort of axial gradient, some sort of axis that has a gradient.
And so the process of embryogenesis breaks many of those symmetries that those blobs have during the early phase of embryogenesis, and then it forms some sort of axis, you know, that has fewer symmetries.
For example, if you look at a tadpole, it has an anterior pole and a posterior pole that did not exist before when it was almost featureless.
So the question is, how might these axial gradients develop over time?
Of course, there is a lot of work in embryogenesis.
It's a wide area of research and people have done a lot of work.
But for us, we wanted to understand the phenomenology of this phenomenon using very, using simple models.
So as I told you before, that's the modeling approach that we have been using.
So for this purpose, we designed a simple one-dimensional model that has two layers.
The first layer is a physiological network.
It's just a cell with a scalar physiological state.
And then there is a genetic layer where every cell has a genetic network, a gene regulatory network that just looks like a neural network, to be honest.
And it's the same GRN, so I would call these GRNs, in each cell, right?
And they all interact locally.
They have short-range connections.
So this is how the model looks like in detail.
I don't want to go into the details of this model because that's not the point of this lecture.
I just want to convey some sort of high-level intuitions here.
But so the main point, main thing that I want to point out here is that all the connections are local.
You know, if you look at these inter-cellular connections, inter-GRN connections, they're all just local.
So what we wanted the model to do is start from a homogenous condition where the states are all the same and design the network in such a way or optimize the parameters of the network in such a way that it will form this simple axial gradient.
You know, that looks like a ramp. That's all.
So using machine learning, we optimize the parameters of the network, and this is how it works.
So the black line is the spatial state of the system.
So the horizontal axis is the cells.
So it's a small system consisting of just 12 cells.
And the vertical axis indicates the activity levels of the cell.
So when we run this optimized system, we saw this black line, which started with almost a flat line.
And slowly, I mean, right now it has this jagged pattern, but slowly what they will do is
it just turns this jagged line into this ramp-like gradient.
So the red line is the target that we use to train the system.
And even though it does not fall exactly the red line, it almost forms a...
Even though the axial gradient is not perfect, it does form to some extent.
The model does other things too, but I don't want to get into that.
But what I want to focus on is to understand how this works, how this model works.
Because I showed you a complicated looking system, right?
It has these local connections and many different parameters.
But when we do this causal network analysis, where we keep track of how the activity S of a cell of K changes at some point in time,
given the state of gene G in some cell at some point in the past, then again, it's a first-order causal influence, right?
It's the causal influence between the gene and the cell activity, the physiological state.
We compute this and we plot it.
We keep, say, the strongest possible, the strongest influences.
And we plot these in the form of causal networks, like I showed you before.
Then we see patterns emerging.
So again, I plotted these networks across different timescales.
We start at the smallest timescale.
You see that all the causal influences are local.
But as the timescale increases, you see these positive and negative interactions indicated by the blue and red edges emerge.
And initially, they are all mixed.
But if you consider the longest possible timescale, which covers the entirety of the simulation, you see that the positive influences, the blue edges, segregate in the anterior half of the embryo.
And the red edges are all directed to the posterior half of the embryo.
So if it's chumate, I see a tractor.
Basically, it looks like this.
The anterior half positively influences itself.
And this half negatively influences the posterior half.
Now you can begin to understand, right?
Like, why is it that the ramp, the axial gradient, forms from a flat, homogenous condition?
Because basically, this entire complicated-looking line of cells reduces to this two-cell system where one cell activates itself and it represses the other.
So it's almost like a Turing-like mechanism, right?
So that's what we learned by doing this causal network analysis.
So yeah, so here, if you look at this phenomenon of developing this axial gradient as a form of intelligence, because basically, you are turning a non-pattern, which is flat-lined, into a pattern.
So that requires some sort of primitive intelligence.
And if you assume that, then you can ask exactly how it is solving this problem.
What is its intelligent strategy?
Then we can say that this is the strategy.
This is the high-level strategy, you know.
Reduce the entire system into a two-cell system, a two-cell activation repression system.
And that's what it uses to develop the simple axial gradient pattern.
Santosh, another question about this.
So that's really interesting.
But my impression is that all of these cells, basically, you have a hidden dimension to which you don't have access.
And then you have the phenomenon that is your readout, right?
And then basically, a lot of this readout is based on some nonlinear transformation, some thresholding function.
Is that right?
Yeah, in this case, there is no readout, per se, because everything is recurrent.
So every physiological state also acts back on the GRN states, and GRN states act on the physiological.
So everything is recurrent here.
So you can still consider the physiological state as a readout because the axial gradient is basically a pattern of the physiological state.
So that's what you're interested in.
So in a sense, there is a sort of hidden state here.
The genetic states may be considered as hidden because that's the sort of scaffold that enables the formation of the patterns.
But these causal patterns actually keep track of how they influence the physiological state.
So that's the G over here, right?
So we have to incorporate them into the analysis in order to decipher these high level patterns, even though they are sort of hidden, if that makes sense.
Absolutely, absolutely.
So you have your physiological state, and this one can also feed back into your gene regulatory network.
But your physiological state is predominantly determined by the gene regulatory network.
But also, if you look at this model, you see these bidirectional connections here.
So the physiological state act on themselves as well.
So there is this higher level layer.
For example, they might represent gap junctions where, you know, molecules can pass through.
So yeah, so there are many levels of recurrence here.
That's because we wanted to, we wanted the model to be constrained by actual biological features as much as possible, but still keep it simple as much as possible.
So the idea is that even though we have this so many complicated recurrent features, if you look at the macro scale causal network, it's very simple.
Yeah, yeah.
And we can use this to understand how the model forms these patterns.
Brilliant.
Thank you.
Yeah.
Okay.
All right.
So the second example is one of our most recent works, and this paper is in the review.
Here we looked at how, if and how electric fields might mediate or facilitate morphogenetic pattern formation.
So the motivation for the work comes from this work that was done in our lab.
I wasn't even there in the lab because way back in 2011.
So what they found was that frog embryos formed these bioelectric pre patterns before they actually formed the phenotypic patterns.
So I will run this video here.
What you will see is bio.
So this is just a map of the voltage of cells.
So this is a frog embryo developing through time.
And you can see that, you can see facial features form, right?
But these are not phenotypic features.
This is not a phenotypic feature.
This is a bioelectric feature.
It's a pre pattern that emerges before the phenotypic features actually emerge.
But one of the intriguing things about these patterns is that unlike typical diffusion based patterns, where you will see some sort of seed pattern that is spread through space, and then you will see features crystallize.
What you see here is slightly different.
You will see that, you know, for example, if you look at the eye here, it suddenly just pops into existence.
It is possible that we have, you know, we didn't keep track of other diffusing molecules.
But it is also possible that maybe something like the electric field is at work in the electric field by virtue of its long range interactions may be enabling this sort of non diffusive like pattern formation.
So that was, that was the idea that motivated this particular work.
And so to investigate that, we designed a simple, a minimal bioelectric network.
So now, again, it's a two dimensional tissue network of cells, but now the cells do not have any gene regulatory networks inside them.
They only have the simple bioelectric circuitry that's represented by a simple pair of ion channels, a polarizing channel and a depolarizing channel.
The polarizing channel will push the cell to assume a more negative voltage, and the depolarizing channel will push the cell in the opposite direction.
And by virtue of these voltages, which means that the cells would have some sort of charge content, they would naturally have some sort of electric field, right?
That's Coulomb's law.
And so we assumed that that is true in this model, and that's represented by this little red lines over here.
And so it's a simple, minimal, it's a minimal model that has the bioelectric layer and also an electric field layer, but there is no regulatory networks or any physiological networks.
And of course, in reality, real embryos do have, or vastly more complicated, they have the gene regulatory networks, they have biomolecular networks and all sorts of things.
But we wanted to understand if we set aside all of those things and just assume a simple bioelectric circuitry to get the electric field, what can it do?
Can it give rise to some interesting patterns?
And what sort of patterns might we see?
So again, I don't want to go into the details of the model, but I just want to point out that we assumed a negative feedback interaction between the electric field that the cell is surrounded by and its voltage.
And in general, we know that patterning requires some sort of negative interactions.
And so the literature also supports that to some extent.
And so that's what we assume.
And what we did with this model was train the model or optimize the parameters of the model in such a way that when we stimulate the electric field that surrounds the boundary of the tissue, can we just, through transient stimulation, get the tissue to develop complex patterns that look like a face, for example.
And we optimize the system to do just that.
So for example, what we did was we identified a set of stimulation parameters using machine learning, and we applied that stimulation for 10% of the stimulation, you know, just for 100 steps.
And then we just let it go.
So we removed all the stimulation.
And so that left the model in this end of like a vague state.
But what happened was, when we let it go, it just sculpted itself into this phase-like pattern, right?
And that's just by, through interactions between the electric field and the voltages of the cells.
So I will show that in action over here.
So this is the stimulation, and then we let it go.
And the red arrows represent electric field, force field vectors around the cells.
And you see that there is this, the tissue basically sculpts itself into a phase pattern.
You know, this shows the eyes and the nose and the mouth.
Of course, it's not perfect, but you can sort of see the phase pattern that emerged from this.
And interestingly, it's somehow the sequence of this pattern, right?
And then you saw how there was a sequence of steps, you know.
Some cells on the boundary turn black, and there is a specific sequence.
And these seem to trigger some cells over here, and then they seem to trigger some cells on the boundary,
and there is some sort of back and forth between the bulk and the boundary.
And in reality, we see a similar sequence.
And somehow the model was able to recapitulate qualitatively to some extent.
And so that was like an interesting observation.
But as I mentioned before, the model seemed to follow some sort of bulk boundary exchanges in a stigmatic fashion.
And so I just run this pattern again.
You see this boundary cells activating, and then you see the cells in the bulk, and then you see some sort of exchange.
So you might suspect that there is some kind of boundary interactions.
And so to confirm that, what I did was I turned off these cells in the boundary, meaning I just depolarized all of them.
And I saw what would happen.
So at this point, I forced all the cells in the boundary to depolarize.
So they are all yellow.
And now what happens is that you can see that the pattern has changed.
It's not the same as the original pattern, but you didn't see any sort of signals propagated from the boundary into the bulk.
It just seemed to happen in sort of secret kind of exchange.
That's because the electric field has this long range interactions.
So in this model, the intelligence, so to speak, is basically this self-organized bulk boundary interactions.
And again, when we do this causal network analysis, you will see some patterns emerge.
So at a short time scale, you will see these causal patterns limited to local regions.
But then in longer time scales, you see some new patterns emerge.
For example, the eye features over here are controlled by cells in the boundary.
And interestingly, the eyes on the left are influenced by these boundary cells on the right of the midline axis.
And the other facial features are controlled by other boundary cells.
So basically, spatially segregated or separated cells on the boundary seem to sculpt spatially separated features in the bulk.
So that seems to be the intelligence high level strategy that this model seems to be following.
And that became evident by doing this sort of causal influence analysis.
And this is the schematized view of this whole process.
That initially looked like this, something that looked short range and complicated.
But when you look at the big picture, you see this new pattern image.
Okay, I see that we have only 10 more minutes to eight o'clock.
And I have one more example.
But I want to pause here if you want to, if you want some time for discussion.
So what do you suggest, Leo?
Do you want me to keep going and go with the other example or?
I think like keep going and then we can go through another example or like through the rest of your, of your talk.
And then we're going to have a discussion section at the end, if you don't mind.
Okay.
Okay.
Yeah, I can do that.
All right to you?
Yeah, absolutely.
Yeah.
Perfect.
All right.
So the last example I want to show is, it's a kind of, so the previous two examples are examples of pattern generation, right?
And we did another piece of work that is an example of pattern detection in some sense.
And it is this phenomenon of bioelectric regulation of morphogenesis.
So what happens during frog development is, of course, it's, it's a process of embryogenesis.
It goes through various phases of embryo formation, embryo development.
And during one of the earlier stages of embryogenesis, we see this tissue called neural plate that looks like a, like a plate that over time folds up and turns into a tube.
And this tube elongates to form the spinal cord and then various brain regions and so on and so forth.
What Pi in our lab found back in 2018 was that this neural plate has a characteristic bioelectric pattern.
So the pattern looks like this.
The flanking regions of the tissue are apparently more depolarized.
Now they have OT just closer to zero compared to the central regions of the tissue, which is more hyperpolarized.
And turns out if you disturb this pattern, then you will see developmental defects.
So for example, if you expose the embryo to nicotine, it will basically flatten this entire pattern and it will make all the cells to assume a depolarized state.
And that will lead to aberrant brain morphologies.
But you can rescue this using some sort of ion channel expressors like HCN2 and things like that, that will basically restore the original pattern.
And you will get a normal brain development following this.
So that's what, that's the biology work that they did.
But what we wanted to understand was how is it that the embryo is able to recognize the changes in pattern?
Because it is a spatial expression, right?
It's not localized to one cell.
It's spread across a wide range of cells, spread across the entire tissue.
And the embryo is somehow able to, using a decentralized information processing mechanism, able to recognize which pattern is right and which pattern is not.
So how does, how does the embryo do that?
So to do that, we, to understand it, we designed a minimal model that has a bioelectric network as before, but this time the cells do have gene regulatory networks inside the cells.
But as before, since this model is supposed to represent embryonic tissue, all of the connections are short range and they are symmetrical, meaning they are bi-directional as, as before.
So what we wanted the model to do was when we, when we initiate this model with an endogenous bioelectric pattern where the flanking columns are all hyperpolarized or depolarized and the, the cells in the middle are hyperpolarized then, which is the endogenous pattern.
We wanted the model to express all the genes in all the cells, meaning that the, the development should be, should be normal.
But when we initiated it with a, uh, incorrect pattern, meaning all the cells are depolarized or all the cells are hyperpolarized, then we wanted all the genes to basically deactivate.
Um, so we trained the model again by training, I mean, uh, optimizing the parameters of the model using machine learning that does that.
And we did find a model which recapitulates a phenomenon and that's what you're looking at here.
Uh, so this is basically a time course of, uh, gene series, the average gene, the model.
So when we show the endogenous pattern over here, then we see that after a certain point in time, they activate.
That if you show it a depolarized or hyperpolarized pattern, the incorrect patterns, then the genes all deactivate.
Uh, so we know that this model can recapitulates the phenomenon, but the question again, as before is how does it work?
How, how is it that a two dimensional tissue of cells, network of cells, uh, process or collect information across space and then decide whether it's the right pattern or not?
Uh, so to do that, um, uh, I want to, I don't want to go into the history of it, but we found that we had to compute the second order derivative here.
So basically what it, what it, what this derivative represents is, uh, it keeps track of how gene expressions change over time in response to voltages of pairs of cells.
It's not a single send anymore, source is a pair of cells. That's why we have a second order derivative.
And when we visualize this, um, second order causal influences in the form of networks as before, then we see patterns emerge.
So this is a little difficult for me to unpack, but I will try anyway.
Uh, so what we did here was, uh, we, so there is a, uh, a gene that is the target and the source is, is voltage, right?
And so due to the four fold symmetry of, of the model, we considered only the genes in the top left quadrant of the tissue.
And then, uh, each edge over here shown in purple or brown represents the, uh, the pairs of cells that's shown in the derivative here, okay?
So when we construct this network, uh, over different timescales, we see certain patterns emerge.
So as expected, uh, at a very short timescale, these influences tend to stay local.
So the genes in these cells are influenced by pairs of cells that are within the vicinity, right?
But in a longer timescale, you see that the influences are also long range and they kind of spread to other regions of the tissue.
So at this timescale, you see influences emerging from over here, which is the other end of the tissue.
And then it swings back to the bottom portion and then it swings back to this.
And so there is this sort of oscillatory fashion.
And if it schematizes this, this is kind of what it looks like, right?
Uh, so the genes over here are influenced by groups of cells there, by which I mean their voltages, uh, over here.
And then it slowly swings back over here and then back here and then back here.
So it, it looks like the, the, the causal influence, uh, occurs in a sort of, uh, oscillatory fashion.
And this kind of makes intuitive sense, right?
Because you want to know, um, uh, the patterns that's, that spread all over the space.
So you want to collect pieces of information and then integrate them into your system before you make a decision.
I think that's what is happening here.
In the paper, we didn't go any further than this, but the intuition is that probably this is what is happening.
And probably this is why you see this, uh, spatial information from far away in the tissue.
Uh, uh, now reach over here and it's kind of swept for the space.
So, so we see this as an information processing mechanism that's maybe required to make a decision as to what is the right pattern and what is not the right pattern.
So, uh, to summarize, um, uh, I, the big picture point, uh, no pun intended that I want to convey here is that intelligence can be characterized as this sort of macroscopic causal patterns, uh, that may be hidden in plain sight.
And if you do the right kind of analysis, like what we did here, or there may be other kinds of analysis that you can do, you will see these patterns emerge.
And that will help you to understand how complex looking systems actually solve the problems, uh, that they, that they solve.
Um, but, uh, the big challenge is, um, like, you know, the, the theme of the seminar series is adaptive behavior.
Right.
And if you notice, uh, we designed all of these models to do something concrete, something specific.
It's not obviously adaptive.
So the question is, uh, the challenge is, can we make this adaptive?
Can we design the system, uh, in such a way that it can learn on the fly?
So maybe as a hover, uh, problem for, maybe for some of you for interested in this sort of thing, if you go back to the pedagogical model, uh, that I talked about earlier, where we design the system, where we train, this is a model where the cells, the end of the chain can stimulate each other.
But do you think it's possible where you design just one system, one model, that you can get any contralateral pair of cells to signal to each other, but not others.
So that's, I think it's sort of the, uh, uh, uh, an example of adaptive behavior that maybe you can explore in a very simple system like this.
I don't have an answer to this.
Uh, but, uh, if you guys, if any of you are interested, maybe you can let me know if you find anything.
So, but that's where I will, uh, conclude.
And, um, and thanks to, to Mike Clevin, who's my boss and who's the director for lab, for, uh, helping me, uh, for letting me work on these very interesting projects.
And, uh, PI who collaborated with me on the neural plate model.
And interestingly, some of the predictions that were made by our even minimal model were actually verified.
And that's what PI did this work.
And so, yeah, that's all I had to say.
Thank you.
I hope to say thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
