Hello and welcome to the Future of Being Human Unplugged. My name's Andrew Maynard. I'm a
professor of advanced technology transitions at Arizona State University, and I'm also the
director of ASU's Future of Being Human initiative. Today it is my great pleasure to be joined by the
pioneering biologist, Professor Michael Levin. So I first became aware of Mike's work some time ago
when one of my grad students asked if I'd seen it and what I thought of it. So here I should say I'm
not a biologist, so Mike hadn't actually been on my radar, but there were enough hints from my student
that there was something profoundly transformative going on in his lab that I thought I should
probably check it out. And I'm very glad I did. So Mike is part of a new wave of thinkers and
researchers who are challenging received wisdom about the world we live in and opening up radical
new possibilities for how we transform it, including ourselves. And here I suspect that that phrase
profoundly transformative is an understatement. Through his work on why cells do what they do,
why organisms look and behave as they do, and why our genome doesn't seem to be that great of an
indicator of much of that, it's clear that Mike and his collaborators are upending a lot of our
assumptions about how biology works and what that implies about everything from intelligence, including
AI to what it means to be human. So Mike, it is great to have you here for this conversation.
Thanks so much, Andrew. So happy.
Yeah, and it's one that I've actually been looking forward to for a long time. And I'm expecting that
we're actually going to cover a lot of ground. And as always with this Unplugged format, serendipity is
the name of the game. So I have no idea where this conversation is going to go. But I did want to start
with the biology and the science. And I want to start off with a question that I suspect some people
will consider to be very naive. And I'm allowed to because, as I said, I'm a physicist. And it's
something that actually has been bothering me for years. So the question is, you take a cell on the end
of my nose, how does it know that it's on the end of my nose? How does it know what the shape of my
nose is and what its place is in my body? Because that cell, if you look at the genome, there's no way
it should know where it is in space and time. How on earth does this work?
Yeah, great question. And like you, I entered this field from a different area. I was a computer
scientist and likewise asking similar questions. As far as we know now, the individual cell does not
know where it is. It doesn't know anything about a nose. It doesn't know anything about you. But the
cellular collective does. So cells merge into networks. And these networks have computational
properties that we're only beginning to understand. And it's those networks that implement the kind of
collective intelligence that solves a number of problems. One of those problems it solves is storing
a rough representation of what it's supposed to be building, and then minimizing error slash stress
in order to reduce the delta between what it thinks it should be building and what it thinks the
current state is. So what we ask in this lab all the time is, what does the group know? Sometimes
what does the cell know, but mostly what does the group know?
Right. And I've got to ask, where does that idea of what the group should be knowing come from?
Presumably, at some point, that is coded within the genome.
Well, one way to think about this, and I know people are not enamored of computer analogies in
biology, and in many ways they're bad, but this one I think is a good one. The genome, what the
genome encodes is the hardware. The genome tells every cell what kind of microscopic hardware it has
to play with. Those are the proteins that it has. Everything that happens after that, in an important
sense, is software. That hardware is reprogrammable. It does representation. It does a number of interesting
things that hardware does. But you have to treat the genome as that. The genome does not directly
specify your shape. It doesn't specify the content of the memories of your body networks. What it gives
you is some amazing hardware that does some stuff by default, sort of out of the box, and also is
highly reprogrammable.
Yeah, yeah. So just to sort of follow on with that, so this idea of out of the box. So I'm assuming if
you're looking at humans, for instance, and we're going to start really complex and we'll probably get
more simple from here, but the out of the box default is a rough human shape. But what you're saying, it
seems to be, is that that doesn't have to be the endpoint. We can begin to sort of tweak the out of the
box sort of default of the genome. Correct. I mean, if you think about the task that is set in front of
biological creatures, and I can give you some examples of some amazing things that they do, the
kind of architecture that we use in computer science where the hardware is extremely reliable and
information is meant to be kept and we make sure that it doesn't get altered and we keep the noise
down and then the higher levels are sort of insulated from the lower levels. That doesn't work in biology.
Because the hardware is fundamentally unreliable. Everything that is in the cell is going to be
damaged, turned over. The noise is huge. And during evolution, guaranteed, the hardware is going to
change. So there's going to be mutations. There are going to be the environment will change. Your own
parts will change. Everything is going to change. So sticking with this idea that what you're going to
try to do is create a solution to a specific problem the way that our current, let's say, genetic
algorithms do, I think is not what biology does at all. What I think what biology does is create
problem-solving agents that operate. And we could talk about some of the ways that this happens. They
operate in various problem spaces like anatomical space. And if all things being equal, they take the
same journey through anatomical morphospace and you go from being a single cell oocyte to a human shape. But
they're perfectly willing to take other journeys if the situation requires them. For example, if you
cut an early embryo into pieces, you don't get half bodies, you get monozygotic twins, triplets, whatever.
So they can make up for all kinds of weird perturbations, some really strange ones in certain
species of amazing examples. And then you can also get these cells to do other things. So we've shown
examples of that, of planaria making flatworms, making bodies with the heads of different species
and things like that. There's a lot of variety.
Yeah. So why don't we sort of go to the flatworm work? Because I think that actually sort of shows
some really interesting stuff where you can effectively, I'm not sure that reprogramming is the
right term, but you can actually get the form and structure of flatworms to change depending on the
how you actually program these collectives of cells.
Yeah. And I guess the first thing I wanted to just mention is that this idea, the plasticity of
the hardware is so hard for us to see because development is normally very reliable. So most of
the time it does exactly the right thing. And so we get lulled into this false sense of security that we
know what these genomes do and they produce a certain shape and that's that. There are other bioengine-
and I'm going to, I'll address the planaria point in a second, but there are other bioengineers besides
the human ones that show us how limited that view is. And one of the things that I show sometimes in
my talks are these galls. So imagine you have a flat green leaf that belongs to an oak and you kind of
know, you say, well, the oak genome makes this flat green thing, you know, 100% of the time,
that's what it makes. Well, along comes a wasp, a parasite that's a non-human bioengineer.
And it prompts the leaf cells with some chemicals, not really known exactly how it works. And they go
on to make this crazy, beautiful red spiky thing that looks absolutely nothing like the leaf. So we would
have zero clue that those cells are capable of doing that. And you can bet that the wasp is not
sitting there micromanaging where the cells go. It's not micromanaging the gene expression. It's not
doing genetic editing. It is communicating to the cellular collective some prompts that take advantage
of their morphogenetic capacity. So nature is already doing this, but evolution is making these plastic things
that can respond in interesting ways. And so in planaria, we took advantage of that. And the thing about planaria
is that it's these flatworms. They've got a head and a tail and true brain, lots of different organs. You can chop
them into pieces. The record is, I don't know, 275, I think, or something like that. And each piece will reliably
regenerate an entire worm. So it's really interesting to ask, how does every piece know what a correct worm is supposed to look like?
And so we were studying this. And long story short, we discovered that there's a bioelectric circuit.
And this is one thing my lab does is it studies this really interesting electrical interface to the collective
intelligence of these cells. That interface is kind of like an API that cells use to hack each other's behavior.
And there's a circuit that has a particular voltage pattern that basically encodes the fact that you should have one head.
And we learned to rewrite that pattern to change that into saying two heads instead of one.
And those animals, if you then cut them, they will make two headed animals.
And so a couple of things interesting there. One is that we can actually see the bioelectrical pattern.
So we now have the ability to directly visualize the memories in the mind of this collective intelligence.
You can see them the way that neuroscientists try to read brains.
That's A. B, we can at least begin to decode them so that now you can rewrite them.
C, these two headed worms are permanently two headed, meaning that if you keep cutting them in plain water with no more manipulation of any kind,
they will continue to be two headed forever with no genetic change.
Right, right. So you look at that. Actually, I love the analogy of an API between cells, by the way.
But you also use this term memory. So effectively, by manipulating these bioelectrical networks,
you're embedding effectively a new collective memory within these these planaria.
How analogous is that to sort of the memory we think of in our brains? Is there a continuum there?
Well, a couple of things. So mechanistically, actually, no one really knows how memories are stored in our brain.
There's a there's a sort of a conventional story having to do with something about synaptic structures.
That story has a lot of cracks in it. There are some folks that have been challenging that in a strong way.
It really isn't clear. The biggest thing about memory is not just the storage medium, but the interpretation,
because there have been all kinds of experiments on moving memories from one animal to another.
And in fact, across radically different architectures.
So let's say from caterpillar to butterfly, memories persist. They have to be remapped.
You know, the straight up memories of a caterpillar don't don't are useless to a butterfly.
Everything is different.
And so so so we don't know how it's handled in brains.
I mean, I have suspicions, but but we don't know.
But but the thing that the thing that is homologous here is a couple of things.
First of all, a lot of the machinery is the same.
So ion channels, neurotransmitters, electrical synapses, all of that stuff is there and being used much like in brains.
And the idea that that that two headed memory that we that we first incept into these animals is a counterfactual memory, meaning that it isn't true right now.
So you can put in a to a, you know, kind of a bipolar memory pattern into a anatomically normal worm.
And that pattern is not what the worm is right now.
So I think of it as the beginnings of that kind of mental time travel that we have, meaning the ability to conceive of and remember things that are not true right now, but might be true at some later time.
Right. Right.
That pattern is what the animal is going to do if it gets injured in some future time.
OK, OK, so so this actually takes us into weird territory and I'm going to push on this.
I'm not sure how comfortable you are going there, but it's the way that you're actually challenging sort of our concepts of memory all the way through sort of memories from collective collectives of cells all the way up to what we understand about sort of the memory in our heads.
It seems like you're implying that in principle, we can actually sort of shift memories around.
We can actually sort of put new memories.
Maybe it's just memories of sort of physical form, but we can put memories into actually I'm going to move away from humans, but but into the brain of an organism.
But you can also transfer those memories either between generations of organisms or beyond that.
How am I going outside the bounds of reality here?
No, I don't think you are. I mean, it's it's been done.
People there are lots of papers on moving memories from from one body to another.
So so some of the best modern work is David Glantzman at UCLA who injects RNA ground up from trained aplysia into the brains of naive hosts and the information transfers.
There's a long history of that work in planaria.
And, you know, this was discovered in the 60s, but we actually confirmed it ourselves in 2013.
If you train the worm, chop off their heads and wait for the tail to regenerate a brand new head with a brand new brain, they still show recall of the information, which means that not only was it partially stored in the tail, but also somehow imprinted onto the new brain as the new brain develops.
So this idea of behavioral memories moving through tissue, moving across tissues, being transferred in molecular, you know, molecular media.
I yeah, I think that's I think all of them exists.
And if you could talk a little bit more about the caterpillar butterfly example, because that work of yours just blew my mind in terms of the progression from the caterpillar to the butterfly with retained memories.
So so I want to be really clear, that isn't my work. So we weren't. Thank you.
So so there was there was old work that that did it in various kind of larvae and beetles and things like that.
And then the classic caterpillar butterfly stuff was done by Douglas Blackiston, who's a staff scientist in my lab.
That's kind of a coincidence. I hired him, you know, a long time ago.
And, you know, I didn't realize at first that he had done that amazing work.
But but anyway, the the the results basically go like this.
You train a caterpillar to eat food, which for the caterpillars leaves on a particular color disc.
The caterpillar undergoes metamorphosis because what it needs to do is shift from a soft bodied kind of creature, which requires a particular controller.
You know, in the soft body, there's nothing you can push on. Right.
So so then it becomes a butterfly that has to that has to live in a three dimensional world now.
And and so because of that, the brain is largely dissolved.
A lot of many of the connections are broken. Most of the most of the cells are killed off.
There's some there's some debate now as to, you know, whether everything is killed off or whether some things remain.
But the interesting thing is not just the persistence of the memory.
The interesting to me, the more interesting thing is this.
If you learn as a caterpillar to crawl in a particular way to receive leaves, which is your food, that memory is completely useless to the butterfly.
The butterfly doesn't crawl. It lives in a three dimensional space.
It has to fly and it doesn't eat leaves. It drinks nectar.
So so so that memory is is useless.
So what has to happen is an interesting kind of remapping, which we still really don't understand very well, although I have some some thoughts about what's going on.
But what's happening is that it first has to generalize the idea of from from leaves into a generic category of food.
So generalizing from specifics to to general categories is a kind of intelligence.
So first it has to generalize and then it has to remap that relationship, the the the association between the color and the and the food concept onto a completely new body, which is driven by a completely different set of effector signals.
So that that to me is the more interesting part is this remapping of information.
And I think that that is just just the beginning.
I think I think once you start looking for it, that remapping is everywhere.
It's there in evolution. It's there in, you know, human cognitive science.
It's it's all over the place.
Yeah. And that I think is is where this this strand of work becomes particularly interesting when we begin to look at how it begins to sort of apply and have relevance and resonance across so many different areas.
And I I actually want to sort of come back to this in a in a moment looking at how we extend it.
But just sticking with this and the idea of these endogenous biological networks.
So if I'm getting this right, if you're looking at sort of these notions of memory, they're embedded in this idea of these these networks, which are remembered by these clusters of cells.
But then moving away from memory, this this seems to be profoundly important that we can actually or biology is effectively determined to a certain degree by these these networks and we can begin to engineer these networks.
So then where does this this knowledge take us in terms of understanding biology and how we can actually utilize biology?
OK, there's a there's a short kind of a short term version and a bigger picture here.
The short term version is basically that now that we understand how to re-specify at least a little, you know, we're beginning to understand how to re-specify these pattern memories.
It means that we have applications and in my group, we've been we've been going after some of these applications in birth defects, in inducing regeneration and normalizing tumors.
We can we can control morphology at a at a at a much higher level.
And what I mean by that is, look, imagine let's just let's just take it into behavior for a second.
Imagine you had a rat and you wanted this rat to do a circus trick, you know, sit on a little bicycle or something.
One thing you could do if you if you took the bottom up approach, that's that's basically what all of molecular medicine these days is about.
If you were, you know, wanted to micromanage all of this from the hardware end, you could try to figure out exactly what the muscle motions need to be to get the rat to sit on this thing and then try to work it up to see upwards to see which neurons would have to fire and trace that into the brain.
All the circuits figure out what would have to happen there and then figure out what pixels on the rats retina you would have to activate with light signals in order to get it to do the behavior.
If you if you do that, you'll be here till the sun burns.
Right. And that feels very much like deterministic sort of science that we do at the moment.
In fact, it feels like an awful lot of computer science.
How do you build stuff out from scratch?
Yeah, yeah, exactly. But but, you know, the good news is that computer science kind of has shown us the way.
The reason that we you don't get out your soldering iron when it's time to switch from Photoshop to Microsoft Word is that we now understand that that the hardware is only a part of the story.
And then you can if your hardware is good enough, you can communicate to it with signals, with reprogrammability, all that fun stuff.
So so the thing with the rat is that instead of that, what you can do is you can just train the rat because the rat offers you this amazing interface that does all the hard work of translating your goals to the rat's goals.
You're getting the buy in of the of the agent, the organism, and it does all the hard work of organizing its downward component parts into a set of activities that are going to get your joint goals met.
So we've been taking exactly that approach in biomedicine to say that I don't want to control all the cells.
I don't want to talk to stem cells. I don't want to control gene expression.
I want the cells to be motivated to take a journey in anatomical space that goes from a wound to a limb being regenerated versus a scar tissue.
And this is exactly what we've done, for example, in the frog where we can show that adult frogs, which normally don't regenerate their legs, 24 hours of stimulation with a with a particular treatment that we came up with gives you a year and a half of leg growth.
After that, we don't touch it at all during that time. The idea is not to micromanage the process.
The idea is to convince the cells that this is what they want to do and they have all the competencies about how to do it.
And of course, this brings in this idea of agental systems, which I actually find quite compelling.
The understanding that of multiple layers within biology, you have systems with agency and you're basically creating the environment where that agency leads to what you want.
Yeah, the amazing thing about biology is that your whole body, every every level seems to be deforming the the energy landscape for the level below it to take advantage of their competencies in navigating that landscape, but to get it to go where you want it to go.
You know, and and and this is this is exactly what what we can take advantage of, not because we're we're so smart, but but because that's what the the hardware is already primed to do.
You know, every every level is already primed to do all these interesting things if you can get the incentives right.
Right, right. So when you look at this, I this feels like it's it's really powerful in terms of rethinking biology.
So, you know, you've already hinted at this, that that's so much of what we do is trying to engineer biology from the ground up, whether it's the the individual proteins or the genome upwards.
But if I know I'm paraphrasing here, but if we can persuade biology to do what we want at a higher level, from what my understanding is, you're cascading down.
So you sort of set the top level parameters and each level within the biological system will then try and optimize within those parameters.
Yeah, I think I think that's right. I think I think all of these levels are made of sub agents that solve problems in various spaces, anatomical space, physiological space, whatever.
And they have different competencies and different agendas of doing it.
And each layer is taking advantage of this is I call it an agential material because you have to engineer it very differently than you would, you know, and engineer the passive or even active matter.
And and it goes it goes even below cells. I mean, we've been studying the learning capacities of molecular networks.
So never mind whole cells, even the molecular networks have probably at least six different kinds of learning capacity.
Yeah. And I know you've used the term intelligence with these these systems.
Talk a little bit about how you define intelligence, because it feels a little weird to talk about sort of molecular systems having intelligence.
Yeah. OK, two two two important things there.
One is that we need to have some kind of way of talking about molecular systems having intelligence because we have to be able to tell a story of scaling.
We all start life as a as a as an unfertilized OSA, a little blob of chemistry and physics.
And if you if you don't want to tell any kind of story about intelligence with that system, you're going to owe a some kind of a claim on when during embryonic development, this intelligence shows up.
And there is no magic light lightning bolt that at some point says, OK, you were physics, but now you're a real mind, you know, so that that doesn't happen.
So so we need we know already given given our origin as a collection of cells and then the single cell before that, we know we we have to come up with some kind of a scaling paradigm for how intelligence scales from simpler forms.
Now, the kind of intelligence that I'm talking about is the kind that William James defined as same goal by different means.
So it's really a navigational intelligence. It's it's it's a publicly observable, perfectly sort of empirically testable problem solving capacity.
So this is not I am not talking about consciousness. I am not talking about self-aware meta intelligence where you know how intelligent you are.
I'm not talking about any of that. I'm talking about the ability to navigate a problem space and get your goals met despite various new things that are going to happen.
Like how much competency do you have at that? And so with the framework that I'm developing, it's called TAME Technological Approach to Mind Everywhere.
This this framework, the most basic thing about it says the any kind of intelligence claim to two things about intelligence claims.
First of all, it isn't a philosophical claim. It is an empirical testable experimental claim.
So if you think some kind of system has some kind of intelligence, what you're going to do is make a hypothesis about a problem space, about the goal that it has, about the competencies you think it has.
And then you're going to do perturbative experiments to see if the the type and amount of intelligence you've you've ascribed it helps you have a more efficient relationship with that system.
So it's it's not anything goes and we don't just paint hopes and dreams on rocks.
We we have very specific hypotheses about problem solving capacities.
And and that means that, you know, you can't just sort of imagine a spirit under every rock.
But at the same time, you can't just assume that cells don't have it.
You have to do experiments. And when we do experiments, we find, you know, we find amazing things.
The other the other unexpected, we get surprised, which is what you want from a scientific theory.
The other right, the other piece of that is when you make a claim about the intelligence of some system, you're basically taking an IQ test yourself.
Because what you're saying is, as an observer, as an external observer, here is what I have noticed this system can do.
And that doesn't mean you didn't miss a whole bunch of other things that you didn't notice just because you don't see it doing things doesn't mean that that it definitely doesn't do them.
Right, right. But even just talking about that, you're you're taking an approach where you say at some point in the system, there is enough awareness to be aware of yourself and what other systems are doing.
So that must be a transition. I'm assuming that we're not looking at intelligence in a way where cells have got a concept of what molecules do.
It's just that they have a specific type of agency. So is there a differentiator?
I mean, and I know we're getting into consciousness here, which we don't really want to go down that path.
But it feels as you begin to talk about humans sort of having that intelligence to understand what's happening further down the hierarchy, that there needs to be some degree of self awareness.
Or is that just an emergent property, which actually isn't that important?
Well, I'm certainly not going to say self awareness isn't important. I'm sure it's important. Look, the thing the thing is that you can you can definitely have bona fide intelligence without without self awareness.
Right. You can have interesting learning capacities. You can be able to use the tools that you have in novel and creative ways.
You can have delayed gratification, the capability of a context or sensitive attention.
You can have all of these things without having that kind of metacognitive self awareness.
And I think and I think it's perfectly good intelligence. I think self awareness is a slightly different thing.
But I also think that we have to have a continuous notion of all of these things.
In other words, I don't believe there's a binary way that you can say yes, self awareness, no self awareness, because we're inevitably going to get to questions of when and how during embryogenesis and during evolution that supposed self awareness shows up.
All of these processes are extremely slow. They they go step by step.
There are no you know, people talk about phase transitions, but I have yet to hear other than certain quantum events.
I have yet to hear an actual phase transition that's really sharp when you sort of zoom in to the to the key parameter.
I don't believe any of these things are sharp phase transitions.
Yeah. And I want to take a quick foray into artificial intelligence on that point before coming back to the biology, because this seems to be really important with conversations and discussions around the nature of intelligence with machines.
Simply because what you've just described seems to make it very easy to talk in practical terms about the nature of intelligence with machines.
If you forget about consciousness and self awareness, that ability to solve problems along multiple pathways seems to be actually what we're developing with a lot of machine learning at the moment.
And to me, it seems to simplify those questions around what is intelligence versus not when it comes to AI.
Does that make sense?
Yeah, it makes it. It makes perfect sense.
I don't think there's any way. I mean, we can have some arguments about consciousness and so on, but I don't think there's any way to argue that we do not have machines that have that that have a considerable, in some cases, human level degree of operational intelligence.
And so it is a problem solving. I think what's what's new nowadays is that in the past, that level of intelligence always went along with a very long evolutionary journey and and, you know, certain other properties that are certain are the cognitive properties.
And now we've managed to dissociate them because I think current architectures actually don't have a lot of the key properties, but but I absolutely think they have the problem problem solving intelligence and whatever.
I mean, I think it's important to know that whatever the differences between us and some kind of AI architecture, whether it be the current one or some some future one, the answer is not going to be what people often say is that's just so here are some bad answers.
That's just a machine. That's just a machine. It operates on the laws of physics and chemistry.
Well, guess what? So so do you. Right. That's you know, and and I know what it is because I built it and it's just linear algebra.
You know, I hear I hear that sometimes, too. You know, a couple couple of a couple of key key things here, which is that, you know, we we find learning and memory in systems as simple as a few genes that turn each other on and off.
That's it. A network of differential equations that represent genes turning each other on and off, never mind a whole cell, never mind, you know, the genome that already can do Pavlovian conditioning.
That's it. This stuff starts very early on. And we found unexpected problem solving capacities and behaviors in something as dumb as a sorting algorithm.
You know, as we're talking bubble sort selection. So if you look at them the right way, you and these things are deterministic six lines of code.
There's there's nowhere to hide. There's no magic. There's nothing there. People, people, you know, people have been studying these for many decades.
And if you look at them the right way, you find things that you did not know they could do and you find things that are literally not in the algorithm.
So that tells me that we need to have a lot of humility about saying that we know what something does or what something is capable of just because we know the parts or just because we made it.
If a stupid bubble sort can do things we didn't see coming, you know, what are these other things going to do that?
And it seems that that actually completely changes the framing around how we think about machine learning and AI from a very deterministic perspective where we say, as you say, we're building the things that we know to the nth degree what it does to understanding we're building systems which have got inbuilt agency that it's not that easy to predict the outcomes of.
But it also strikes me and I correct me if I'm wrong here because I knew you hinted at this earlier that quite often when it comes to building machines or computer science, we try and predict everything to the nth degree.
We try and create the perfect system. And from everything you're saying, it seems like that is totally the wrong approach.
And I think we're beginning to move away from there. But if we approach these systems as hierarchical systems of a gentle sort of algorithms or whatever, how far along are we in terms of saying create a system where we create the parameters that persuade the subsystems to do what we want?
Or is that something we really need to focus more on?
Yeah. I think that if we were if we I'm not sure we I'm not sure we need to or want to do that.
The problem is, well, two things. Number one is we may get it without without even trying because while we know, I mean, people have been studying complexity and emergence for a really long time.
It's very, you know, or perverse instantiation, these kinds of things. It's very easy to make systems that follow simple rules and then generate a bunch of complexity.
That's not what I'm talking about. I'm not talking about unexpected complexity or side effects or any of that.
I'm talking about emergent agency, the emergent goal directedness.
Now, I will say that the architectures that we have today, at least the ones of which I'm aware, do not maximize the kinds of the kinds of dynamics that would lead to that.
But but there are unexpected ways of getting it that I think we need to be really careful about.
And the bigger picture for me is that I think we have to be really careful about this in the sense that like like I started a few months ago, I started writing a paper to lay out very clearly.
What are the half a dozen things about biology that are really critical for making a true agents that matter in a moral sense?
And what's different? You know, here's what biology is doing that none of our computer architectures are doing.
And and I stopped and I'm not going to write that paper because I think that well, not that it'll help because somebody else will do it eventually.
But but right. So somebody will catch on to the stuff. But but but but I don't want to be responsible for it.
The thing is that to whatever extent I'm right in in having found some of the key features that I think make for true sentient beings that we're going to need to take care of.
And to that extent, I don't want to be responsible for creating, you know, trillions of them and and having no control over how they're right.
So but but interesting that that's your thinking. It's not that this isn't something that's possible.
It's that this is something that's possible.
And we've got to be really careful about what we do in that space.
I think it's absolutely possible because the idea that what is special about minds can only be produced by a blind, you know, a tinkering agent that makes mutations and selects for certain things.
I don't see why that process would have a monopoly on creating real minds.
I think that and I know there are there are people that I respect a lot who would disagree with that.
You know, Richard Watson, I think, is one. But to me, I think that there are many roads to doing this.
And at some point we are going to figure out and I think we already have a good basis for figuring out what are the actual policies and components that are that are necessary.
And they have nothing to do with being made of protoplasm or any of the things that we assume, you know, are tied to the biology.
So so I absolutely think they can be reinstantiated in other media.
And that resonates with with conversations I've had with other people where you're looking at almost substrate agnostic systems.
It's it's the agency within the systems, which is important.
So on that, we've only got a few minutes left, but I wanted to sort of build on that and extend out into much broader territory.
And I've no idea sort of how you'll respond to this, but it's something that fascinates me at the moment.
I looking at your work and looking at work in other disciplines, it feels very much as if we're on the age of a on the edge of a scientific renaissance.
I'm beginning to see people challenging established notions of how the world works in many, many different areas.
And I don't know whether that's just me seeing things through my narrow perspective or whether it really is the case that we're at a point in human history
where we're beginning to rethink a lot of what we've assumed is constant and true.
How am I off totally off base here?
I would love to agree with you.
And my personal experience is that as well.
But but I have to correct for the fact that I mostly hang around with, you know, with people who like to think in these big directions.
I mean, I think purely statistically, you know, when I give talks about this stuff to a to a generic random audience in conventional fields,
most of this is things they've either never heard of or that sound completely wrong to them from a philosophical level.
So I'm not sure how where we are in that transition from this is impossible to this is completely obvious.
I'm sure that I think that's the journey we're on.
I'm not sure where we are there.
But but I agree with you that that is that is where we're going.
This is assuming we we all live long enough.
This is going to overturn everything.
And it should because right, our future.
And I one of the reasons I say that is I come across the same sorts of conversations in multiple different disciplines.
So if you're looking at neuroscience, if you're looking at psychology, if you're looking at physics, even conversations where I'll talk to respective physicists will say, you know,
I'm not sure the second law of thermodynamics is actually sort of holding true.
And it just feels like there are cracks in the reality that we've built over the last sort of several sort of decades or centuries.
And you'll work as part of that.
And there's definitely a sense that something is shifting.
It may take a while before sort of broader audiences actually see it.
But it does feel as if we're at one of those really interesting points in history where we're rewriting what we know about the world and how it works.
I think that's true.
And the part of it that I'm the most excited about, in addition to the practical implications of, you know, for biomedicine and things, which I think are huge, is I think we have to start climbing out of what some people have called a crisis of meaning.
So this is work that I'm doing with a number of collaborators, but, you know, you can sort of see this parabolic shape where neuroscience has told us some things that we thought about what we are and how free will works that are wrong.
Evolutionary theory has told us about this sort of every man for himself kind of fundamental idea.
Physics is telling us about determinism and things like that.
And so this progressively the loss of these important ways of thinking about the world has taken us down into a situation where a lot of people are actually very disturbed by it.
And we scientists and philosophers need to now climb out.
We need to provide provide the other side of that problem, which I think does exist for recovering the things in a better in a better way.
Not in the, you know, sort of incorrect way that we've been thinking about them, but in a better, more scientifically defensible way.
Yeah. So final question before we finish then just on that.
From your very speculative perspective, what does all this mean to the future of being human?
Okay.
60 seconds.
60 seconds.
60 seconds.
60 seconds.
The, the, the future, the future is a freedom of embodiment.
And the future that I see are children who are told stories of the past where they say, you've got to be kidding me.
You mean, you mean somebody was born and just because of the vagaries of some cosmic ray that hit some DNA, they had to stay in the body that they were born with.
Maybe they wanted, you know, maybe their goals required more, more IQ or longer lifespan, but no, they got lower back pain and astigmatism.
And then they, you know, they died at 70.
That, that can't be right.
Like nobody can live like that.
That, that's the future.
I see that where that, that, that where we are now, that becomes ridiculous and it should be, it is ridiculous.
I, I, I love that.
Perfect place to end and a beautiful challenge.
And I'm very, very aware we, we need to, to wrap up.
Um, there are so many other areas we, we could have touched on, um, that the whole regenerative medicine area, um, that not being constrained by what we think our bodies can do.
Um, we're going to have to have you back at some stage, but we just looking at the time we should wrap up.
So, uh, Mike, thank you so much for this.
Thank you so much.
This has been an incredible conversation.
Thank you.
And to those of you watching, that's it for this episode of the future of being human unplugged, obviously.
Um, thank you so much again for Mike for joining us and challenging our thinking and what I think are some quite profound and unexpected ways.
Um, if you want to know more about Mike's work, I should check out the, the links in the, the blurb to this video or simply Google him and you'll get a wealth of information.
And finally, if you're interested in joining us for future conversations, um, please do sign up for updates from ASU's Future of Being Human initiative at futureofbeinghuman.asu.edu.
That's futureofbeinghuman, all one word, .asu.edu.
And with that, thank you again for joining us and have a great day.
Good day.
you
