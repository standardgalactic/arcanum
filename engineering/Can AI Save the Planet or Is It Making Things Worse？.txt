When Musk said, give me a plan to solve world hunger, I'll give you six billion.
Did he give that six billion? These billionaires are playing with us.
It is of the utmost importance that we know how AI systems work
and not to subscribe to these ideas that it's only Elon Musk who knows how technology works.
Welcome back to The Tea, the show where we dive into the story behind the stories.
I'm your host, Miriam Froswer.
Before we get into this episode, I just want to take a tiny moment to ask you to do one thing for me
and that is to hit that subscribe button now.
We're a small independent team, no big networks here, no corporate backing,
just a handful of people who care deeply about having honest conversations
and shining a light on what often goes unseen or unheard.
So if our work does resonate with you too, then subscribe now on YouTube and join us on Patreon, link in our bio.
This year is set to see governments around the world making huge investments in AI.
The UK has just announced a 14 billion pound AI action plan and the US has allocated 1.8 billion for AI research.
And behind the scenes, big tech is racing to build massive data centers to keep up with demand.
Tools like ChatGPT are highly resource intensive.
In fact, each prompt uses nearly 10 times more electricity than a Google search.
And meanwhile, our planet is burning with global temperatures already above 1.5 degrees for 12 months straight.
With tech visionaries more focused on blasting celebrities into space and colonizing Mars
than addressing this existential threat and billions being poured into AI and climate tech,
can AI technology really be part of the solution or is it just making the problem worse?
To help us unpack this, we are joined by award-winning environmental justice researcher and educator,
Joycelyn Longdon, one of the most powerful voices working at the intersection of tech, climate and justice.
A PhD researcher at Cambridge University, she is the founder of the educational platform Climate in Colour
and she has advised institutions from the UN to Greenpeace.
She was also featured in British Folk's Forces for Change in 2023.
Her book, Natural Connection, looks at what Indigenous knowledge and marginalized communities can teach us
about meaningful environmental action.
Welcome to the Tea, Joycelyn. Thank you so much for being here.
Thanks for having me. It's really great to be here.
Thank you. So, first off, obviously wanted to ask you, you're born and raised in London,
which isn't particularly known for its greenery.
What sparked your interest in environmentalism?
Yeah, I was really lucky to grow up in a council flat that backed on to like a brook and it had fields.
I grew up in zone five, so not central, central London.
And I was lucky enough to have these like little snippets of green space.
My primary school had, you know, this like conservation area that we'd go to weekly.
And so I think like subliminally, like I had no idea what environmentalism was or anything like that.
But subliminally, I'd had these experiences of being outside, especially as a sporty kid,
like doing cross-country, things like that.
I was connected to the natural world, maybe not in ways that like you'd usually think of,
but in my own London-y ways.
And I think I remember going on this trip to Ireland for like one of my uncle's weddings.
And I was like, oh my God, this country is so beautiful.
And we went to these ancient forests and I just found myself becoming so in love with the natural world.
And I think it was just something innate in me.
You know, I'd watch like Escape to the Country and be like, you know, I'd love to be in the countryside.
And so I think it was these like tiny little early experiences of being in the natural world
and just having that innate connection as a child without this kind of knowledge of what environmentalism was
or the political dimensions that set off that love that I think has stayed with me as I've kind of grown up.
And I think for me, things clicked when I realized how my identity as a black person
was deeply intertwined with the outcomes of the environmental crisis,
which happened a lot later for me kind of as a teenager.
So it took that love and politicized it, which is kind of what drives my work now.
That's so interesting.
So I actually was going to ask you about that because, of course, the climate and environmentalism space
does have a little bit of a bad rep for being the whole white Birkenstocks, granola, let's save the whales movement.
And it hasn't always been a space that people of color have always felt welcome in.
And so I wanted to ask you, you know, how did you end up in that movement and what was your experience of it?
And have things changed?
You know, maybe that's an outdated vision.
I don't know.
Yeah, it's really interesting.
So when I was a teenager and in my first year of uni, I was doing a lot of racial justice journalism.
I was engaging with survivors of Grenfell.
I was engaging a lot in racial justice activism and also working with creatives, black and brown Londoners,
who were speaking about and communicating racial justice.
And I felt that was my space, right?
I had this background love for the environment and for nature.
But as you said, my kind of understanding of what environmentalism was, was tree huggers,
white Californians, Birkenstocks, people that did not necessarily connect with me.
And I did go to one of my first climate marches when I was 15.
And that was like an experience that put me off joining the environmental movement
because I really noticed my like isolation as a person of color.
And I guess it was such a stark difference to the racial justice spaces that I'd been in.
And it wasn't until I started to become cognizant of the impacts of the climate crisis on black communities in London.
I'm from Ghana also, which experiences the effects of climate change and learning more about how people from where I'm from
are impacted by the climate crisis.
That kind of clicked for me because I was like, this racial justice work that I'm doing is not disconnected at all
from my love for the natural world or from environmentalism.
And I think for me, it's so important that people of color, black people, brown people, indigenous people,
we connect to the histories that our ancestors have of environmentalism because they're there,
but they're just not necessarily in the mainstream of kind of the British media or what we're taught environmentalism looks like.
And I think that's kind of a key part of my work is reconnecting us to those stories because they're there.
They're just unamplified.
Well, I definitely want to ask you about some of those actually shortly.
But in 2020, you created the platform Climate in Color, which began posting accessible and diverse resources on climate justice.
Presumably, you created that platform because you felt that the wider environmental movement just was not tackling this through the right avenues.
And I wanted to ask you, as someone who's immersed in it now, why does the movement have this reputation for being so white?
And what do we mean when we say that?
Yeah, I think the environmental movement oftentimes when it's coming from like a white perspective is built on different worldviews than necessarily like a black perspective or a perspective of people of color.
And I think it may be this myth that the environmental movement is only made from made up of white people.
I think it's just who is getting platformed and who is getting amplified.
And the majority of people on the front lines of the environmental crisis, the people who are having to create solutions out of necessity, not outside of, you know, this distance that we have, say, in the global north, are black, brown, indigenous communities.
And I think that it's wrapped up in our racism, colonialism, that kind of devalues those perspectives and focuses more on this idea of solutionism and saviourism, which has dominated the environmental story and environmental movement, at least in a global north perspective for decades.
You asked kind of, is it changing?
I think there is much more understanding that white environmentalism is not a good representation of what environmentalism is.
And I think people have got the language now to start talking about that, to be talking about justice.
I think we're getting the theory part and it's the practice of actually amplifying, listening to and changing the way that we approach environmentalism from the perspective of marginalized communities that we're still in that process.
We're in that process of holding people accountable and of shifting values and worldviews.
And that's kind of what I try to do through my work.
And so is it the case that kind of the wider balance of power that we see in society where it kind of white people in general get more visibility, more kind of credibility for the same kinds of work is then reflected within the environmental movement?
Is that what the situation is?
There are added dimensions to why it's perceived in this way as being sort of particularly white.
You know what I mean?
Of all the different movements, it's like, why is this one, why is this one seen as so white?
Yeah, I think it's really interesting.
There was a study that was done in Bristol, which was timing the amount of time in climate conversations, like in decision-making spheres, right?
In government, in policy, how much time each person got to talk and what demographics those people were from.
And I can't remember exactly, but I think it was in an hour or more of conversation, people of colour, especially black women, got around two minutes of time actually talking.
And so it's this ingrained superiority of white people in the environmental space that they have all of the solutions.
We have the science, we've got the knowledge, and that's not something that we associate with black and brown people, right?
And so, yeah, I think it is really interesting.
And I think it is connected to the systems of oppression that we already are within.
And that's what our environmental justice perspective focuses on, right?
That it's not just about environmentalism.
It's not just about carbon.
It's not just about, you know, saving the trees.
All of that sits within the context of wider systems of oppression, like capitalism, colonialism, racism, discrimination.
And so we can't kind of effectively take environmental action without considering all of those together.
And I think there's this idea also from a kind of Western perspective of this, like, duality of nature and humans, right?
That if we're taking environmental action, it's because we are separate from nature and we are better than nature and it's our job to save nature.
And I think that's a very white perspective towards environmentalism that doesn't take into consideration other worldviews or other ways of connecting to the living world.
And which is why our conversations are dominated in this country by white people.
And I think it's also influenced by Britain's very specific lack of engagement with its history.
There's this resistance to acknowledging the colonial history of Britain, which is really confusing considering that so many Brits, you know, on the right want us to get back to our history.
And it's like, there is a deep history that we have in this country of disconnection through colonialism from the natural world.
And so I think it's partly influenced by that kind of Western intellectual approach to environmentalism that sees us as separate from the living world.
And also that sees black and indigenous people as closer to fauna and flora than as humans.
So, yeah, there's a lot.
There's a lot there.
There is a lot there.
And I was going to ask you about that duality, which I think so many of us have sort of just internalized as natural, right?
It's like nature on one side, humans on the other.
But we don't realize that that is a product of a particular mode of thinking that is specific to, in many ways, on the scale of human history.
You know, Europe at a specific point in time.
And then obviously we export it through colonialism and other forms of sort of imperial knowledge domination.
But is that duality kind of, to your mind, also part of why we've ended up in the crisis that we're in right now?
A hundred percent.
A hundred percent.
Because if we cannot see ourselves as part of nature, not above it or outside it, then the ways in which we interact, that distance is so dangerous.
Because we fail to see how our actions resonate and provide these ripples to the rest of the world.
And I would say not just to natural ecosystems, but to our social, our wider social interactions.
If we're distanced from the people who are mining the materials to build our phones, that's both a social and an ecological distance that we have that sees us disconnected from our connections, right?
To the land and to the people that labour on the land in order to provide our tools and technologies.
And so I think that part of solving the climate crisis, outside of this white environmentalist, like, well, we'll just, you know, cut carbon emissions and we'll do carbon capture and storages.
Part of this problem is rooted in the fact that we approach our connection to the living world from a distance.
And that we are rooted still in a kind of green capitalism, right?
That fails to understand that we are part of nature and that all of this, everything around us, comes from the earth first.
Nothing doesn't come from the earth.
And I think, you know, I talk to people about perceptions of nature that we think it's out there, right?
You have to, like, travel halfway across the world to get to a forest and then you're really experiencing nature.
But this is nature. This was mind from the earth. This has come from the earth.
Everything that we touch and interact with every day has come from the earth.
And I think building that ability to observe and understand our connections to the living world day to day, not just in these special moments when we're out in a national park or going abroad to a forest,
is kind of part of rewiring our brain to understand ourselves as part of the natural world.
And so alongside your environmentalism, you're also a tech, a woman in tech, right?
A woman who works on AI and environmentalism and the kind of intersection of the two.
And so we were just talking there about kind of the philosophy that we could think of as being this philosophy of dualism,
which is you identified as sort of being at the root of part of the problem that we find ourselves in today,
the idea of this disconnection between us and nature.
As someone who works in the sort of AI and tech world, do you find that there is anything within the kind of underlying philosophies of that world,
which is either conducive to the solution or part of the problem?
Yeah, working in the tech space is very interesting.
It's very complex and I'm someone that doesn't subscribe to binaries and that's a big kind of myth or thing within the tech space is like either it's going to save the world or it's going to like wipe us all out, right?
And I think the reality is much more complex than that.
Technology, as with colonialism and capitalism, is rooted, well, let me be specific, a Western technology is rooted in systems of oppression, of colonialism and capitalism.
And I think my work is trying to make people aware that this short period of time or these kind of technologies that we now associate with the word technology are not, that's not the expansiveness of technology.
Technology is much more than chat GPT and an iPhone or what we now know as AI, right?
AI has for decades gone through these summers and winters, right?
There's times where no one's thinking about AI.
It's not the interesting thing.
There's no money going into it.
And then suddenly, boom.
And this has been happening over decades and decades.
And we're now in one of these AI summers where everything and everyone is AI focused.
And I think that, yeah, the current paradigm of AI right now is one that is the public one, the big tech chat GPT generative AI space is rooted in extraction and is influencing a kind of data colonialism,
is influencing harm through capitalist ideals where tech is mainly seen as something to maximise profit rather than something that is supposed to benefit and contribute to human life.
And you mentioned that we're in this AI summer, AI everywhere.
We talk about it in every space.
Why is that that we're in this AI summer?
Like why is so much money being pumped into AI in every sector that we can think of pretty much?
Capitalism.
I think that there's, I think it's interesting as we move into more tricky social, cultural and ecological situations.
We're faced right now by such large and complex problems.
And I think technology comes in as this kind of band aid, right?
For the governments and the corporations who don't want to engage in these deeper conversations of why are we in the messes that we're in?
Why are we in such extreme environmental collapse?
They don't want to talk about that because it's difficult, it's tricky, it's messy.
It also requires a huge amount of personal investment to build connections with people and understand the social kind of roots of our problems.
You can just pave that over with technology, right?
You can say, don't worry, climate crisis is not going to happen because technology is going to solve it.
I think it's a bit of a pacifier and we're faced with so much kind of social turmoil right now that it's very easy to go.
This thing's going to save us.
We're always looking for that thing outside to save us.
And so that's partly from an environmental perspective.
What I'm seeing is that we were getting to a place where we were kind of in 2020 and around those times talking a little bit more about environmental justice and how intersectional our environmentalism should be.
And I think people have kind of fatigued and are like, what are the solutions that's just going to make us the most money and make life the easiest for us?
Right.
From a short term perspective, not in the long term.
Is there, to your mind, a sort of mythology?
Because, you know, I think a lot about the mythology around science, for example, which I think in the Western context has come to replace God as a sort of, you know, the truth of the capital T that we should, you know, they don't trust in God.
We trust in maths or whatever it is or science.
And I think about that mythology when it comes to AI and the extent to which we are fed constantly, no doubt from very well-funded PR machines, the idea that the leaders of tech industries are these incredibly smart people, these visionaries.
And that the technology they're creating is so intelligent and that we should all really just follow, you know, the lead of these sublimely smart, almost God-like figures who understand things and have created technologies that could, you know, to the secular mind come to even replace God, you know, in the sense of the knowledge is so expansive.
It knows everything about everyone and everything in the world and as someone who's in that world, like, how much should we be buying into that mythology?
Not at all. Not at all. I think you've hit it on the head.
So much of science, if we look at the history of science, has been based on charismatic figures that kind of present themselves as wizards, you know, that there is a huge amount about mystique and mythology and magic that we see with science and that we see with technology.
And that myth is also to keep us distanced, right? Because if we feel that something is so far beyond our comprehension, that it can't be questioned, that it can't be challenged, then they can have the power and it keeps the power within those systems rather than within, you know, civil society.
And I think what's really important to understand is, one, AI and technology are physical. They're material. We talk about the cloud. It's not this immaterial thing. Technology, AI, is rooted in the earth. It comes from the earth. It takes from the earth. Also, it is human.
A lot of AI algorithms and models and companies that we see are built from human labor and often the labor of marginalized people.
And so I think we need to uncover, like lift the veil, a bit of a Wizard of Oz moment where we take off, pull back that curtain and actually see who is behind AI.
Because it's not just these charismatic wizards, but it's fleets and hundreds of thousands, millions of people around the world who are doing low paid jobs, work, labor to sustain AI algorithms and us, right?
Every time you do that little capture on Google, that's you training an AI model to understand, is this a bicycle? Is that a chair?
We are training AI models all the time. And so this idea that AI is this kind of mystical thing, I think we need to move away from because it's not, it's, it's physical and it's built by and maintained by people.
And we, we see this through the work of Kate Crawford and Ruha Benjamin, who talk about at every stage of the system, there's a human there and it is built on labor and that labor needs to come to the forefront because then we see that these technologies are not just these kind of like mind, you know, mind games from people like Elon Musk, but they're actually built by often Africans.
They're often built by people in the global South, they're often built by people in the global South, who are maintaining and building these algorithms.
Wow. I mean, I think that definitely is one of the mystiques that continues to resurface constantly.
And I wonder to what extent, as you sort of touched on there, we are ending up handing over power that we have when we start to believe in these systems as somehow smarter than ourselves and as having almost like these superpower qualities.
I remember there was a video that went viral a couple of months ago of this, um, uh, YouTuber who was like, you know, I, I asked chat GPT what it would do if it was God to divide humans and cause chaos on the planet.
And then it came back with like, you know, I would, so racial division, I would, uh, you know, I would, you know, play on all the fault lines around things like abortion.
And I was thinking, I was, you know, I was looking at the comments and all the comments where people were just like, oh my God, oh my God, oh my God.
And I just was like the lone voice in the comments, like, it's literally just regurgitating.
What we already do.
Right.
It's like, am I alone in this space?
To what extent are you concerned that many of us are buying into this idea that actually there's something bigger and more powerful and smarter than us that's coming to save us?
So we could just sit back.
I think this is my main concern around technology is apathy is this kind of release of power and agency and lack of education.
Um, the media needs to sell stories, right?
And if all we're engaging with is the inflammatory rage baiting media online about technology, we are feeding right in to the plans of those who are powerful and those who are making these technologies to dominate our lives.
Because we fail to engage with the ways that we have agency over the way, over, over tech and our tech use.
And I think that we're in this moment where rage is very profitable, right?
And where you say you're the only one in the comments actually questioning or bringing in a bit of critical knowledge.
We know that machine learning algorithms are trained on what already exists.
They're not, they're not thinking.
And I think this is a misconception that's brought in with the name artificial intelligence, because it has that intelligence aspect.
And the way that we talk about AI is often through metaphors that link it to human kind of processes.
And that's quite misleading because the AI is not thinking.
It is trained and is taking in information that already exists.
And so, of course, it's going to replicate the systems of oppression, the biases, the terrible framings of knowledge and worldviews that we already exhibit day to day.
And I think that, yeah, we're seeding and giving away our power by only kind of feeding into these, oh, my God, technology is going to end the world.
This is so awful. And it's like, we need both critique and imagination, right?
We can't move to better futures.
We can't move to better tech outcomes.
If all we're doing is responding to these prods and pokes from the media, we need to be building capacity separately so that we can take back our power from hegemony, basically.
And I mean, that's part of the work that you do on the ground, right?
So you work closely with marginalised communities in your research work in Ghana.
Can you tell us a little bit about the communities that you're involved with there and what type of challenges they are facing that AI is actually helping them address?
Yeah, so my work specifically focuses on conservation technologies.
And this is another space, as you said, AI is taking over everywhere and also conservation.
So this is how we're managing the biodiversity crisis, right?
Like, how do we protect the forests on this planet?
And AI is being kind of hailed as this is going to be the saviour, right?
If we just get as much data as possible on all the forests that exist in the world, we can use AI and it will help us better understand how we're losing biodiversity and make better decisions to protect it.
And I work with a specific technology called bioacoustics, which is how you use sound to monitor biodiversity.
So a really easy way to think about it is more complicated than this is Shazam for nature.
So how you just Shazam a song and that uses AI algorithms to let you know what song it is.
Similar concept, not as shallow as that, but that's how bioacoustics works.
The issue is that these technologies are being deployed all around the world in forests, coming back to the duality as if nobody lives there, right?
As if forests are just these sites of data production, right?
That they're only sites to be measured and that they're disconnected from humans.
And this links to the colonial history of conservation, which has been predicated on the disconnection of indigenous and local communities from areas of high biodiversity.
With this idea that nature can only flourish without humans.
Well, without brown and black humans or indigenous humans being there, right?
It's the white European that knows how to work with and save these environments.
And so we're seeing that replicated with the tech, right?
Where tech is being embedded into these ecosystems without an understanding of the political justice and human rights implications.
And so that's what my work challenges.
So I work with a forest community in Ghana and I take in these technologies and we've been kind of scheming and dreaming and critiquing and taking apart these technologies and trying to understand what are the risks, but also what are the opportunities?
Like how do communities want to appropriate these technologies?
The community I work with are facing the impacts of global capitalism through illegal gold mining and the forest I work in has been absolutely decimated by illegal gold mining, which is having a huge impact on the biodiversity, the safety, water pollution, food security of the communities that I work with.
And bioacoustics is just one technology that can help communities kind of monitor and track that and hopefully make decisions about how they want to conserve.
And this is a kind of tradition also within kind of community based monitoring is how can we use technologies to actually reinstate community agency and power over their lands?
So there's similar work by a researcher called Naomi Milner from Bristol who works with communities in Guatemala who are using drone technologies, which are a historically militaristic, historically colonial tool, but to reinforce their land rights in their forests.
So this work is complicated, right?
It's not that technology is always going to end up empowering communities or end up saving the planet, but there is this messy space in the middle where we are trying to develop solutions based on justice whilst living within this like colonialist capitalist construct.
And yeah, it's it's it's it's it's it's it's both about critiquing, but also imagining what the future looks like.
Um, yeah, and it's so interesting listening to you talk about these technologies and particularly AI being wielded in a way that replicates the sort of historical colonial myth about, you know, colonizers entering lands that are, you know, devoid of, devoid of anyone and what we meant historically by anyone was white people or us, you know, we were
there, so no one was there, which obviously is one of those great myths, but it's it's, I guess, worrying to hear that that continues to be the main, you know, a sort of very sustained paradigm through which we continue to build these new frameworks of technology.
And so I think it's very interesting to hear the ways in which you negotiate those spaces, because it does feel like there are so many inherent conflicts to it.
I mean, one of the ones I wanted to ask you about was, you know, obviously, it sounds like this, um, the use of these acoustic, uh, acoustic screenings with recorders.
Yes, so the use of these acoustic recordings, um, you know, with these AI models can be really helpful to these communities to conservation, but presumably they're also having to rely on these huge data centers.
And I was just reading that, you know, uh, obviously, uh, President Trump has, uh, recently just, um, allowed for the majority of forests in the U.S. to now be logged again.
I think it's 75% of them are now going to be open to logging.
Um, there's a renewed, um, return to fossil fuels, um, much of it being sold to us as necessary to fuel the growth of AI, which is coming to save us, obviously.
Um, and so I wanted to ask you as, as a scholar who works at the intersection of these worlds, how, how do you feel, like, how do you feel about it?
How do you, on one hand, get, you know, and I'm sure you must be, and I can see it in your work, so enthused about the capacity of these technologies to help, but also knowing the harm that they're causing simultaneously, how do you, how do you work through that?
Yeah, I think it's interesting, and I think we need to make a distinction, because AI, again, I think this is like part of the miseducation, is that we think all AI is generative AI.
Okay.
And actually, that's not what I work with.
Okay.
Um, I actually don't use chat GPT.
I might be, like, the only computer scientist that doesn't really engage with generative AI.
Um, but AI is much wider than, than generative AI, and, and kind of the technologies that I'm working with, I don't rely on a data center.
I, I do it on my, on my laptop and my computer.
And so I think there's a big difference between community-led tech and also kind of more low-tech approaches to conservation or to any kind of solutions, and there's very big Western industrialized tech.
And that's, like, a distinction that we have to make, because not all AI is made equal, um, but yes, for me, my work always starts from critique.
There's, um, there was a researcher, a computer scientist called Phil Agree, who in the 90s introduced this idea with a critical technical practice.
That is starting from a technical perspective, so as a computer scientist, always coming with a philosophical and a sociological edge.
So for me, I don't start with the hype. I start with, where do we need to critique? Because I don't believe from the offset, oh yeah, technology is 100% going to support marginalized communities, right?
I think that's a very Western, a very colonial perspective to have. It's like, these technologies exist. What are the harms? And how, if so, and if they want to, will communities take agency and appropriate that for themselves?
And so for me, I'm working in the tradition of, like, Afrofuturism, right? That black and brown people are always, usually the people most impacted negatively by emerging technologies.
And we have this tradition of, we're going to dream of different, uh, alternatives outside of this kind of main paradigm.
From an environmental perspective, the over-reliance on AI, mainly generative AI, is what is pushing this environmental destruction.
There was a report last week from Source Material in Guardian showing that, you know, the likes of Apple, Amazon, Google, are going to increase their data center development by 78% in the future.
Mainly in water-scarce regions, like Aragon in Spain, which, I mean, 75% of Spain is at risk of being desertified and you're going to put a data center, well, you know, dozens of data centers there, extracting water from the local ecosystem.
I think one of, um, these, it was, uh, recorded that some of these data centers will use, um, the amount of water that would, in a year, that would support 600 acres of farming, of agricultural land.
So, for me, there was no conflict there on large-scale, wide, capitalist expansion of AI.
That, for me, is not a conflict, right?
Like, we need to be developing outside of that idea that more data, bigger data centers, more AI investment is going to create better outcomes for us.
Because this is how they justify it.
Right.
There's this, like, techno-utopian ideal that, you know, we, in the West, we have all of the ideas, we have all of the technology, and we just have to make some sacrifices.
So, for the betterment of human society and human thriving in the future, we need to develop these data centers now, because they're going to, maybe in the future, AI is going to, like, you know, make the grid better, or we're going to get all of these benefits from AI.
Whilst that may be a possibility, I think we need to question who has the power to decide who makes sacrifices and who doesn't.
Who has the power to decide what is good for human benefit, and what is a kind of okay amount of destruction and extraction to get to that future.
And that, for me, is, yeah, something we need to critique and call out more widely.
And the we here is?
Well, we as society, right?
Specifically us as people working with the computer science industry.
And I think that's why it was so important for me to be in a computer science department and to work within computer science, because it's very easy for more sociological approaches to just be ignored.
And we need practices as scientists, as computer scientists, that are outside of this kind of Western colonial capitalist idea.
But also, we were talking before about giving away our power as citizens.
And so, I think, as citizens, not just as a researcher, we need to increase our education, our understanding, and then our critique of these systems.
Not kind of leading into this apathy and just inaction, but actually feeling like we have power here to take back.
And we're going to learn as much as possible as a society.
Come together, have cybersecurity parties, have AI critique parties, so that we can better understand what are the systems that are impacting our lives and how can we push back and resist them.
Cyber critique parties.
I look forward to the invite to that one.
Sounds lit.
The Tea is a fully independent, non-partisan production.
No corporate ties here, just a small, dedicated team working hard to bring you honest, impactful conversations.
If you believe in our work, please subscribe to our YouTube channel.
Just click on that subscribe button now and join us as a Patreon.
You'll find the link in our bio.
I want to ask you about a quote that I was reading in The Guardian from just in 2023.
Mohamedou Bawamia, the vice president of Ghana and head of the government's economic management team, said at the time that Africans have a gold mine at our fingertips.
A rapidly growing population of 1.4 billion people, 70 percent under the age of 30, combined with huge growth in AI investment, creates a potent recipe.
Would you agree with that?
I mean, this is tricky, right?
If we look at the history of, I mentioned Afrofuturism before, I don't subscribe to a non-technological future, right?
Because I have a different idea of what technology is and our communities, black communities, indigenous communities, we've been technological, right?
Maybe it doesn't look like the technologies of the West, but we have technology in our hearts.
We're innovators and we have always been in that sin, our ancestry.
And, you know, leaders like Kwame Nkrumah, who was president of Ghana before he was taken up by a military coup, always had this idea of a pan-African technological future, right?
Where technology lived in harmony with African flourishing based on an African-led approach to technological and science development.
I think I worry about kind of some of these comments because I think they often rely on this import and extraction from Western big tech, right?
And this is what we see that Google headquarters in AI in Ghana, in Accra, these big tech companies going in and kind of leeching African talent,
and African innovation for the purpose of Western profit and capitalist expansion, rather than approaching what Africans need and the solutions that Africans could be having on the ground.
And so, yeah, I think for me, it's actually really inspiring being in Ghana.
There is actually a huge kind of like underground community of especially young people working on climate tech solutions from like working with waste colonialism
and developing technologies to reduce waste colonialism, to transport and shipping, mobility, energy in Africa, built by Africans for African people.
There's an organization called Startup Discovery School who are investing in these solutions.
And I think for me, that's where I want to focus on is how do we build, whether it's in Africa, whether it's in India, whether it's in South America, how are communities in those areas leading and having agency in their technological futures,
which might be rejecting some technologies, which might be rejecting investment from outside influences, or which might be developing technologies that they feel kind of attend to the issues that they're having locally.
And so, whilst I believe there should be collaboration, for me, this idea that there's this untapped resource of skill, I don't know that that's the right space to be starting from,
because I think it opens us up to extraction and leaching rather than a generative kind of environment.
Well, it's interesting you say that because another poll that we were looking at suggests that the majority of people who are skeptical of how helpful AI can be globally are from the African continent.
Do you see that reflected in the teams that you're working with?
And is that connected to kind of historical relationships of extraction with the continent where, you know, this is just seen as another mode or another nexus for that exploitation?
Yeah, with the teams that I'm working with, I haven't experienced that particular perspective.
But I think that's because we don't engage with a capitalist or colonialist vision of technology, right?
And I think you've got it spot on.
There is resistance to this continued extraction and leaching of African talent and of African worldviews from the West.
It's like people have had enough because we have so much resource, physical, natural resource that are being extracted decade and decade after decade.
And yeah, technology poses another one of those threats or Western technology poses another one of these threats.
We're seeing this in Kenya, which has been called, you know, like the Silicon Savannah, where Kenyan people, the people behind AI algorithms, the people that spend eight hours a day circling and labeling all of this data that feeds into the algorithms for Google and for Amazon, who are being paid $2 a day, who are being overworked, who are being exposed to harmful images,
who are being exposed to substandard working conditions.
Technology is not a boon in that context, right?
It's another source of extraction and oppression.
And you mentioned sort of technologies not being recognized as being technologies.
And it's something you talk about in the book.
Can you expand on what you mean by this idea that there are African technologies that are not seen as African technologies or indigenous or marginalized communities technologies that are simply not seen as technologies but are?
Yeah, it's essential to our perspective about what technology is that we have neglected and that we have forgotten the stories of before, that we have forgotten the indigenous technologies of the past.
And we only see technology as something that's like post industrialist, right?
And that's only been created by people from the West.
There are so many different technologies that I can speak about.
We have technologies made from the earth, clay technologies, so wind catchers, they're called bad gears in Iran.
And in other communities as well have these kind of similar technologies for cooling, for cooling buildings that are as efficient, more efficient, less polluting, no carbon emissions than air conditioning, right?
These have existed for centuries.
And we have kind of new technologists coming in.
There's Ant Studios in India.
They're a Delhi based studio who are taking that kind of concept of clay based air conditioning.
And they've created these kind of air conditioning units for Indians who are going to be experiencing by 2030 the most heat stress.
And that's a challenge that how do we cool countries that are going to have huge amounts of heat stress without emitting tons more carbon, right?
And so Ant Studios are taking this indigenous knowledge of clay and water as a cooling system and making these zero carbon basically air conditioners from traditional practices, right?
That's just like one example of bringing the knowledge and the wisdom of the earth and of past indigenous practices into the modern day to solve our modern day problems.
And that is a technology.
Well, it's a technology and it's arguably the most efficient tech that we have because it doesn't contribute to the problem and yet doesn't get recognized.
So can we talk about that for a second?
Like why doesn't it get recognized?
Is this a patent issue?
Is this like in medicine where it's like if something is from nature, like if you could take a plant and just eat it, then it can't possibly work.
It has to be recognized and proven by one person.
There has to be a patent. I have to be able to patent it and limit the ability of other people to use it so I can make a lot of money, otherwise it doesn't work.
Exactly. And I think this is, that's, that is part of it, but I think it's partly racism, right?
Because we have this idea that people of color and the indigenous communities are anti-technological.
We don't associate those technologies with something that is like valid, right?
Even if it has the outcomes that we need and because of necessity, black indigenous and communities of color, we have technologies that support us in so many ways.
Like buckets, showering with a bucket, that's a technology that saves water and that is renewable, right?
And, and so I think it's partly racism, this mistrust in black and brown ideas, right?
That, you know, we have this kind of conversation a lot about like, oh, the Egyptians could have never built the pyramids, right?
Because like it couldn't have been black people that did that or it couldn't have been people of color that did that.
And I think it's just this like bias inside that technology is not something created from the global South.
It's only something created from the global North, which is just not true.
Right.
And so I think it's a racist perception, this kind of Western enlightenment idea of technology that limits us from kind of validating and acknowledging the technologies that exist in different realms.
And our, and our distance from the earth, right? This maybe doesn't look so much like the earth, but clay does look a little bit more like the earth.
So this can be more technological because it's smooth and it's shiny and it's made of metal.
Whereas something that's clay based, maybe it's a bit too woo woo for someone who has this hard idea of science.
Yeah.
Yeah.
This looks like science. The clay kind of cooling device looks like nature.
Yeah.
Can't possibly be worthy.
But nature is a technologist, right? Nature is a designer.
And I think that's what indigenous and African technologies are more connected to, right?
Is how does nature design and how can we be inspired by the ways that nature designs?
Because all of nature is technology.
So I'm personally very interested in this area because I, as a person of faith myself, I find that I see God and kind of the universal principles of, you know, the rules, whether it's like mathematical rules, scientific rules, principles, but also like extreme forms of high tech that we ourselves can't figure out.
Right. How does a bumblebee fly?
Right.
Right.
The tech behind it doesn't make any sense, but yet it does.
And there are so many examples like that. And so I think to myself, how much of where we are today is due to also that disconnect, right?
Yeah.
The sense that we don't see God reflected in the world around us.
Yeah.
And because we don't, we attribute the highest form of intelligence to humans.
Human made.
Yeah.
And that breeds both an arrogance vis-a-vis the natural world, but also like a lack of respect vis-a-vis that hierarchy, right?
Because if you understood that the natural world reflected the highest form of intelligence and that we are just kind of a few echelons down from that.
Yeah.
There'd be a humility vis-a-vis our relationship to the natural world, which is obviously completely absent.
You've hit it on top of the head and I write about this in the book as well, about the earth being a church and God being everywhere within that church.
And we, you know, whatever faith you subscribe to, it's not about religion per se, but it's about an understanding that we are surrounded constantly by the magic of a higher power of a higher intelligence.
I, this is actually one of the reasons my undergrad was in astrophysics and this was the reason why I wanted to do that degree because I would watch documentaries.
I remember watching a documentary talking about how birds know how to fly south and that partly it's to do with quantum physics.
And I was like 16 and I was like, no, I need to study this because I am so bowled over by the magnificence of this world.
And I think I had been asked before, like, how can you be spiritual and have, you know, and be a scientist?
And I'm like, have you seen the world? Like, are we watching, are we living in the same world?
Because it's incredible and we know so little about it. And I think that's why for me inquiry is so important.
And as citizens, it's so important to be curious and critical about the systems around us.
Because the more that we dive in, the more we realize that we know so little.
Yeah. And that there is so much intelligence around us.
There's a book called An Immense World and it talks about animal sensing and animal intelligence and just how insane animal intelligence is.
Like how in, I can't remember where it was. I think it was in the Amazon.
There's a bumblebee that each year knows it flies in the dark in order to collect nectar and to the specific branch every year lands on the same specific branch.
Like, I'm sorry, what is that apart? Like, how can that not be technology?
How can that not be intelligence? And we're surrounded by every day.
But we have this arrogance that we're the most intelligent species or that AI is going to be this more intelligent species without acknowledging.
We are surrounded by incredible intelligence, intelligence far superior to us every day.
And reflected in that natural technology that is all around us as well.
Speaking about debunking some myths, I wanted to put to you a few quotes by some of the, you know, AI thought leaders that we have around today just to hear your views on some of their reflections.
So we'll start, of course, with Mr. Elon Musk, who recently said, probably none of us will have a job.
He's talking about the future. If you want to do a job, that's kind of like a hobby.
You can do a job, but otherwise AI and the robots will provide any goods and services that you want. Is this the future?
I hate this perspective. I think that it's a very easy myth to say that technological development will always result in that like this technological productivity will always result in human flourishing.
And I think it's a nice idea. And I think there are other spaces and movements that deal with what this could look like, like solar punk movements that think about what does a world detach from capitalism, but that has technology look like where we can flourish.
That's not what Musk is talking about. And it's easy for him to say as someone who is developing technologies that will power that keep his power over other people. Right.
And it goes back to this understanding that technology is not void of humans. Technology is built on the labor of mainly marginalized people.
So I wonder who he is talking about. Who is he talking about that will have this sort of relaxed lifestyle and who will be laboring under that technology?
Important question. Jack Hiddory, the CEO of Sandbox AQ, says the mantra of AI or die is real. Certain companies and countries that do not engage will die.
I mean, this is just like so ridiculous and inflammatory. And it's kind of even it feels wrong to even engage in with these comments because I think we're so kind of used to
responding to inflammatory rage bait from these people who only have everything to gain from feeding us these kind of lies about what the future of technology looks like.
Do they want to create fear, do you think?
100%. Yeah. What's the function of it?
I think the function of fear is us releasing our agency. It's apathy. It's accepting that it's easier to accept the end of the world. Right. It's easier to say, God, we're all going to die because of technology, because that keeps us from challenging them.
That keeps us from building different things. That keeps us from appropriating technologies for our own use so that we don't have to subscribe to the processes or to the tools that they're forcing us or telling us that we have to use.
Right. It's in their interest to say, if you don't use not AI, my AI, if you don't use my technology, you will die, which feeds into their business.
And I think we need to be a bit more creative as citizens or as people who are outside of this billionaire tech class to challenge.
Really? Is that so? So yeah, they definitely have a lot to gain from from scaring us.
And that's not to say that there aren't things to be worried about. Yeah. But I think it's like, how do we engage with the things that there are to be worried about?
Because going on to social media or having these articles just constantly regurgitating the same things, they're still building it in the background. Right. And what are we doing?
Well, feeling disempowered, I guess. Right. Because I mean, even someone like Yuval Harari, who I think has often said a lot of very interesting things.
You know, I don't know if you saw recently in a podcast, you were saying, you know, we said a lot around AI and the kind of potential future mappings of what that could look like.
But one of them was like, never summon a power you can't control.
And, you know, obviously this conjures up this image of like, you know, Musk and all these other guys as you sort of like magicians conjuring up this dark power that none of us will eventually be able to control.
Yeah. Is that is that a representation of AI that you recognize or is that just fear mongering?
I think it's partly fear mongering. I think in part it's true because we have been disconnected from actually understanding and educating ourselves about AI.
There's a technologist from the States called Avril Epps and this is really the key of her work.
She's actually just brought out a book about AI bias for kids, for children, because she has children and she is of the opinion that like it is of the utmost importance that we know how AI systems work.
And not to subscribe to these ideas that it's only Elon Musk who knows how technology works and that he's the cleverest guy on the planet because the tools that he's making are built by thousands of people.
And so tools like AI bias cards, books aren't building our understanding and not accepting that we will just never know how to build AI systems.
And also those rogue activist developers who are building systems that are open source that can be used by anyone, low tech systems that we can take back and bring into our communities, right to repair all of these grassroots mechanisms that allow us to take back control over how we use tech and how we interact with tech.
Shut those people up because, you know, yes, that might be the case now.
But are we just going to accept that that's what the future is going to be?
I don't know. For me, that's that's not that's not how I'm going to move through life.
I don't want to accept.
You're not going down like that.
There's another book that I found really interesting called More Everything Ever by a guy called Adam Becker.
I don't know if you come across this. He's quite, quite critical of Silicon Valley visions of, you know, digital immortality and AI overlords and trillion person space colonies, which he calls not only implausible and immoral, but a distraction from the urgent issues that we're facing.
And I wanted to ask you that because we're speaking today in the same week as Bezos has blasted, you know, celebrities into space.
And, you know, the big the big questions are around, you know, can we colonize Mars?
And all the while, you know, I guess Becker's book says, you know, that's all well and good, but that's basically a show.
And in the meantime, you know, the planet is dying.
We have huge wealth inequality, growing wealth inequality, and none of that, you know, world hunger, you know, health care, none of that's being addressed.
But we can definitely shoot Katy Perry up into space for 10 minutes.
It is so embarrassing to me, and it's dangerous. It is a distraction.
And to, you know, it's been posed this flight, this Blue Origin flight has been posed as a sort of feminist victory.
Women and children are going to be the main, are mainly impacted by the climate crisis all around the world.
Women don't have access to reproductive care. Women are suffering under capitalism and patriarchy every day.
One of the auctioned seats on that, on that flight cost $28 million.
Oh my God.
What could we do with $28 million?
We could provide free health care.
Slow Factory brought the statistic out that we could have provided free reproductive health care for 140,000 women in the United States with that one seat.
Right.
So I think for me, this is the key to technology and why I subscribe to a more earth based idea about technology, because there is this colonial idea.
That we can just ruin everything on this planet and just go and escape.
And that's not the, that's not the reality for the majority of us.
And we have to understand that we're not just colonizers.
We are caretakers and we are connected to the earth.
And these ideas of sending away from the earth and using technology again for like the benefit of humanity or the like advancement of humanity.
Who has it advanced for six women to go up into space for 11 minutes at huge expense and a huge environmental impact.
Right.
And so these are distractions.
They're also distractions to make us angry because we're now focusing on space exploration rather than the issues that are, that we are facing right now.
And, you know, we saw this years ago when, when Musk said, give me a plan to solve world hunger.
I'll give you 6 billion.
Did he give that 6 billion?
No, these billionaires are playing with us.
Right.
They're, they want to, they're given every opportunity to support and to give back all that they have taken, all that they have extracted from this earth.
And time and time again, they show us that they will never kind of align with a global humanist socialist approach.
Obviously, like, when did we expect billionaires to be the people to come and save us?
Right.
So, yeah, I think.
Since Instagram told us so.
Since Instagram told us so.
Yeah.
And I think this is part of being critical, right?
Like, billionaires are not going to come and save us and they are part of the problem.
Even the more attention we give to their distractions, the less time and energy we're giving to the, to the issues that really matter.
Not just on a global scale, but in our own communities.
And I think this is how we build back our power.
We think, God, how are we going to solve all of these issues?
So global, it's, you know, at scale.
But there is so much that we can do from a local level, from our minds first, then to our communities and go out and out and out in ripples.
And I think for me and working in technology, that's the only way that I can do this work is to really, at some time, at some points, not be drawn in and engaged to all of this rage bait.
There's a quote, you know, that racism is distraction.
It's all a distraction and I wouldn't be able to do my work.
I wouldn't be able to build with the communities that I work with if I was constantly reacting to the kind of frivolous actions of the world's political elites.
My work is to challenge what they're doing and to build different futures.
And that's the thing.
I think you mentioned the word negotiation earlier.
And that's what this work is, right?
We're constantly negotiating dystopia and utopia.
There's not going to be one utopia.
There's not going to be one dystopia.
We're living utopias and dystopias all the time in parallel.
And so our work is to not think everything is lost because billionaires are going up in space.
I think everything is solved because a billionaire says, I've got this technology that's going to solve the climate crisis.
It's constantly being able to hold space for the fact that we're living through hell and through the most beautiful times at the same exact time.
Yeah, that's beautifully said.
I wanted to maybe end by asking you, you mentioned imagination and your work with these marginalized and indigenous communities.
Is there a story of hope that you can share from, you know, as you say, it's not either, you know, utopia or dystopia.
Something in the middle that shows us that there is space to retain hope for a balance between the natural world and the technological developments,
between the needs of all the residents of this unique planet.
Is there something that your research has shown you that you go back to as being the source of that hope and that allows you to continue doing the work that you do?
For sure.
I think for me, being grounded in a forest, in a particular place with a community, I've worked with the same community now for about four years.
I'm facing extraction, facing mineral extraction, facing destruction that I had never experienced before.
Right. As someone growing up in the global north, you had my friend Tori Joy on previously.
And, you know, she talks a lot about how we have this hopelessness, this eco anxiety in the global north when we're so kind of detached from the impacts of extraction, domination and climate crisis.
And for me, the hope is kept with the communities I work with who show up every day joyfully, actually, with grief, holding grief whilst also having imagination and thinking about the future.
And also of my ancestors. Every time I go back to Ghana, I go back to the slave castles.
I go back and walk through those cellars and those dungeons that my ancestors were held in.
I think it would be a huge disrespect to my ancestors who labored, who created music, who created art, who persevered, who lived through hell.
And the knowledge that we, our communities have seen the end of the world previously.
This is not the first end of the world and they have struggled and persisted.
And so I will struggle and persist. And that's my hope.
It's not a hope that, yeah, everything's going to be great and tech's going to save the world or climate crisis is going to save the world.
It's being, Rebecca Solnit talks about this, it's being heartbroken and still showing up anyway.
And that's what the communities that I work with teach me.
And that's what I hope to, you know, keep in my work as well.
And if there's anyone watching this who's saying, you know, I care deeply about the environment.
I really want to help, you know, combat the climate crisis that we're in.
But I also want to make sure that I stay a fae of the new technologies, right?
And, you know, I'll hold my hand up and be the first person to say, I care immensely about the climate crisis.
But do I also use generative AI on a regular basis when I know how much water it consumes?
I do, I do, you know, and it's like, we all live at the intersection of these tensions.
So if people are watching this and they're thinking like, what advice would you give to people on how to balance these concerns and how to move through these technologies
in a way that's like conscious and responsible, but also doesn't mean sort of trying to leave all the tech behind?
Yeah, I think that this is a key part of building our tolerance and our resilience to holding contradiction.
That we're all in this position where we're trying to live the best that we can in a system that is essentially falling apart.
And so I think first and foremost is critical engagement, right? Curiosity.
And it's also kind of taking back your power, like really super simple things like tomorrow.
Are you going to go outside and use your maps to try and navigate?
Or can you try and navigate your way through London without using your phone?
Like simple things like this that teach us out of a huge reliance on like these day to day technologies.
My friend Adele Walton's got a book called Logging Off coming out.
And, you know, that talks about how do we kind of come back into the real world?
How do we come back into ourselves?
And again, I use technology.
I don't use generative AI, but I work with technology.
And I think it's understanding that the world isn't made up of binaries.
It's not black and white, but to always have this curiosity and this critique to understand how are we connected to the world?
How are we connected to each other and be committed to those connections, right?
To not see ourselves as separate to the rest of the world, but to be interested and engaged citizens, right?
For me, that's just the biggest thing is rejecting apathy.
I want us to all reject apathy and to be active and engaged citizens because the systems of oppression rely on our apathy.
And I, for one, want to reject that.
So, yeah, holding tension, rejecting binaries and rejecting apathy in everything that we do.
Jocelyn, thank you so much for being our guest on The Tea today.
Appreciate your time.
Thank you so much for having me.
Thank you for joining us today.
We hope this conversation offered not just insights, but also raised questions that push us to think more critically about the systems shaping our world.
Now, at The Tea, we are committed to amplifying perspectives that often go unheard and to peeling back the layers on stories that deserve at least a second look.
If this episode resonated with you, consider subscribing, sharing it with someone in your circle or supporting us by becoming a patron.
To help keep these conversations alive, please head over to the comments section.
If you've made it this far, why not keep going and check out this episode?
You know, let me keep drawing them, Melissa.
Let's stop talking.
No!
