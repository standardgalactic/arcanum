Most people around the world are still not aware of what is happening on the AI front.
It can invent medicines and treatments we never thought about,
but it can also invent weapons that go beyond our imagination.
You're changing the basis of everything.
It's no wonder there is an earthquake in the structure that is built on top of it.
I got news for you people.
The rise of the machines is already upon us.
So what exactly do we need to understand about the rapid ascent of artificial intelligence?
What does this revolution augur for the future of the human species?
To gain clarity amidst the confusion, I'm joined today by Yuval Noah Harari,
a world-renowned historian and mega-best-selling author
whose landmark books on the history and future of humanity have sold an astonishing 45 million copies
and made him the public intellectual of our time.
This is the first time that we are basically about to enter a non-human culture.
The big question is whether we will force it to slow down
or it will force us to speed up until the moment we collapse and die.
His latest book and the terrain for today's conversation is Nexus,
an absolutely essential read that makes quite a compelling case
for why artificial intelligence will be the biggest disruption in the history of civilization.
AIs can make decisions.
They are not just tools in our hands.
They are agents creating new realities.
It's very difficult to appreciate the dangers
because the dangers, they are kind of alien.
In the Hollywood scenario, you have the killer robots shooting people.
In real life, it's the humans pulling the trigger, but the AI is choosing the targets.
Thank you for coming.
I appreciate you being here today.
I'm excited to unpack what I think is a really revelatory book,
a very important book that speaks to perhaps the most vital issue of our time.
And in reflecting upon it, I was thinking back on Homo Deus, which came out in 2015, 16.
16, yeah, 16.
And in that book, you address AI, but at that time,
it was as if you were sounding an alarm on a future story that had yet to be written, right?
And perhaps it came off a bit Cassandra, you know, in that moment.
And I'm curious, as we find ourselves now in 2024, eight, nine years later,
it's as if not only are we, you know, kind of on the cusp of this new revolution,
we're mired in it in a way that perhaps even is far more intense
than even you predicted at that time.
Yeah, I mean, things have been moving much, much faster than I think any of us predicted.
And, you know, in 2016, AI was like this tiny cloud on the horizon
that might arrive in decades or even centuries.
And here we are in 2024, and the storm is kind of upon us.
And I think maybe the most important thing is really to understand what AI is,
because now there is so much hype around AI
that it's becoming difficult for people to understand what is AI.
Now everything is AI, you know, especially in the markets,
in the investment world, they attach the tag AI to just about anything in order to sell it.
So, you know, your coffee machine is now a coffee machine,
it is an AI coffee machine, and your shoes are AI shoes.
And what is AI?
So, you know, the key thing to understand is that
AIs are able to learn and change by themselves
to make decisions by themselves,
to invent new ideas by themselves.
If a machine cannot do that, it's not really an AI.
So a coffee machine that just makes you coffee automatically,
but by a pre-programmed way, and it never learns anything new,
it's just an automatic machine.
It's not an AI.
It becomes an AI if, as you approach the coffee machine,
the machine, before you press any button,
addresses you and says to you,
I've been watching you for the last weeks or months,
and based on everything I've learned about you
and your facial expression and the time of day and so forth,
I predict you would like an espresso.
So I already took the liberty to make a cup for you.
It made the decision independently.
And it's really an AI if it then tells you,
actually, I've invented a new machine,
a new beverage, a new drink
that no human ever thought about before.
I call it Bespresso.
And I think it's better than espresso.
You would like it more.
And I took the liberty to prepare a cup for you.
Then it's really an AI,
something that can make decisions
and invent new ideas by itself.
And therefore, by definition,
something that we cannot predict
how it will develop and evolve.
And for good or for bad,
it can invent medicines and treatments
we never thought about,
but it can also invent weapons
and dangerous strategies
that go beyond our imagination.
You characterize AI not as artificial intelligence,
but as alien intelligence.
You give it a different term.
Can you explain the difference there
and why you've landed on that word?
Traditionally, the acronym AI
stood for artificial intelligence.
But with every passing year,
AI becomes less artificial and more alien.
Alien, not in the sense
that it's coming from outer space.
It's not.
We create it.
But alien in the sense
it analyzes information,
makes decisions,
invents new things
in a fundamentally different way
than human beings.
Again, artificial is from artifact.
It gives us the impression
that this is an artifact
that we control.
And this is misleading.
Because yes,
we designed the kind of baby AIs.
We gave them the ability
to learn and change by themselves.
And then we release them to the world.
And they do things
that are not under our control,
that are unpredictable.
And in this sense,
they are alien.
And again,
I mean,
humans are organic entities
like other animals.
We function organically.
For instance,
we function by cycles.
Day and night,
summer and winter,
we sometimes active,
sometimes we need to rest,
we need to sleep.
AIs are alien
in the sense
that they are not organic.
They function
in a completely different way,
not by cycles.
And they don't need to rest
and they don't need to sleep.
And now,
as they take over
more and more parts of reality,
parts of society,
there is a kind of tug of war
of who would be forced
to adapt to whom.
Would the inorganic AIs
be forced to adapt
to the organic cycles
of the human body,
of the human being?
Or would humans be pressured
into adopting
this kind of
inorganic lifestyle?
And starting with
the simplest thing
that AI are always on,
but people need time
to be off.
So if you think
even about something
like the financial markets,
traditionally,
if you look at Wall Street,
it's open only
Mondays to Fridays,
9.30 in the morning
to 4 o'clock
in the afternoon.
It's off for the night.
It's off for the weekends.
It takes vacations
on Christmas,
on Independence Day.
And now,
as algorithms
and AIs
are taking over
the markets,
they're always on.
And this puts pressure
on human bankers
and investments
and so forth.
You can't take
a minute off
because then
you're left behind.
So in this sense,
they are alien,
not in the sense
that they came for Mars.
To understand
artificial intelligence
and to understand
what is actually happening
and where we're heading,
the thesis
of this latest book
requires us
to understand
the nature
of information itself
and the formative ways
in which the evolution
of information networks
are inextricable
from the evolution
and progress
of humankind.
So I'm curious
about how you
discovered
that lens
into kind of
understanding
the nature
of artificial intelligence
and why it's important
to contextualize
what is occurring
right now
through that perspective.
It's actually something
I began exploring
in previous books.
The idea is that
information
is the most
fundamental
stratum,
most fundamental
basis
of human society
and of human reality
because the human
superpower
is the ability
to cooperate
in very large numbers.
If you compare us
to chimpanzees,
to elephants,
to hyenas,
individually,
there are some things
I can do
and the chimpanzee can't
and vice versa.
Our big advantage
is not on the individual level.
The really big advantage
is that chimpanzees
can cooperate
in, you know,
a few dozen chimpanzees,
like 50 chimpanzees
can cooperate,
maybe a hundred.
But with humans,
with Homo sapiens,
there is no limit.
We can cooperate
in thousands,
in millions,
in billions.
If you think about
the world trade network,
like the food we eat,
the shoes we wear,
everything we consume,
it sometimes comes
from the other side
of the world.
So if you have
eight billion people
cooperating,
and this is our big advantage
over the chimpanzees
and all the other animals,
what makes it possible
for us
to cooperate
with millions
and billions
of other human beings?
It's information.
Information is what holds
all these large-scale
systems together.
And to understand
human history
is to a large extent
to understand
the flow of information.
and I'll give an example
if you think,
for instance,
about the difference
between democracies
and dictatorships.
We tend to think
about it
as a difference
or as a conflict
between values,
between ethical systems.
Democracies believe
in freedom,
dictatorships believe
in hierarchies,
things like that.
And which is true
as far as it goes,
but on a deeper level,
information flows
differently
in democracies
and dictatorships.
It's a different shape,
a different kind
of an information network.
In a dictatorship,
all decisions
are made centrally.
Dictatorships
come from dictate.
One person
dictates everything.
Putin dictates
everything in Russia.
Kim Jong-un dictates
everything in North Korea.
So all the information
flows to a single hub
where all the decisions
are being made
and sent back as orders.
So it's a very centralized
information network.
A democracy,
on the other hand,
if you look at it
in terms of
you're in outer space
looking at the flow
of information
in the United States,
you will see
several centers
in the country.
Washington,
the political center,
New York,
the financial center,
Los Angeles,
the maybe autistic center.
But there is no single center
that dictates everything.
You have several centers
and you also have
lots and lots
of smaller hubs
and centers
where decisions
are constantly being made.
Private corporations,
private businesses,
voluntary associations,
individuals
making lots of decisions,
constantly exchanging information
without that information
ever having to pass
through the center,
through Washington,
or even through New York,
or even through Los Angeles.
So just looking,
you don't know anything
about the values
of the people.
You just imagine
you're in outer space
in some spaceship
or satellite
just observing
the flow of information
down below on the planet.
You will see
that North Korea
is very different
information flow
than the United States.
And this is crucial
to understand.
And when you look
at thousands of years
of history
and how history changes
and different regimes
rise and fall,
understanding what kind
of information technology
is available
is a key
to understanding
which political systems
or economic systems win.
For most of history,
a large-scale democracy
like the United States
was simply impossible.
If you think about
the ancient world,
the only examples
we know of democracy
are small city-states
like Republican Rome
or like ancient Athens
or even smaller tribes.
We don't have any example
of a large-scale democracy
of millions of people
spread over a vast territory
that functioned democratically.
Now, we know the stories,
for instance,
about the fall
of the Roman Republic
and the rise of the Caesars,
of the emperors,
of the autocrats.
But it's really not the fault
of Augustus Caesar
or Nero
or any of the other emperors
that Rome became
an autocratic empire.
Simply, there was no way
that the information technology
necessary
to maintain
a large-scale democracy
which is bigger
than just the city of Rome,
like the whole of Italy
or the whole of the Mediterranean.
Democracy is a conversation.
And how can millions of people
spread over thousands
of kilometers,
converse,
and decide
whether to go to war
with the Persian Empire,
what to do about
the immigration crisis
on the Danube
with all these Germans
trying to get in.
You can't have a conversation
because you don't have
the information technology.
And, you know,
if it was just the fault
of Caesar
that Rome became
an autocratic empire,
we should have seen
some other examples
of a large-scale democracy
in India,
in China,
somewhere,
but nowhere.
We only begin to see
large-scale democracies
in the late modern era
after the rise
of new information technologies
which were not available
to the Romans,
like the printed newspaper
and then the telegraph
and the radio
and television
and so forth.
Once you have
these technologies,
you begin to see
large-scale democracies
like the United States.
And one final point,
why is it so important
to understand this?
Once you understand
that democracy
is actually built
on top
of information technology,
you also begin
to understand
the current crisis
of democracy
because, you know,
now all over the world,
not just in the U.S.,
we have a crisis
of democracy
and to a large extent
this is because
there is a new
information technology,
social media,
algorithms,
AIs,
and it's like,
you know,
you're changing
the basis
of everything
so that it's no wonder
there is an earthquake
in the structure
that is built
on top of it.
So we have this idea
that the advent
or the improvement
of information systems
and information technology
is part and parcel
of the empowerment
of democratic systems
across the world.
But built into that
is this sort of indelible
misconstrual of information,
this assumption
or presumption
that more information
is better
and leads to truth
and knowledge
and wisdom.
and your book
kind of puts the lie
to that
and tells a very
different story
around not only
the definition
of information
but its purpose.
Yeah, I mean,
information isn't truth.
Information is connection.
It's something
that holds
a lot of people together.
And unfortunately,
what we see in history
that it's often
much easier
to connect people
to create
social order
with the help
of fiction
and fantasy
and propaganda
and lies
than with the truth.
So most information
is not true.
The truth
is a very
rare subset
of the information
in the world.
The problem of truth
is that the truth,
first of all,
is costly.
Whereas fiction
is very cheap.
If you want
to write
a truthful
history book
about the Roman Empire,
for instance,
you need to invest
a lot.
A lot of energy,
time, money.
You need to study Latin.
You probably need
to study Greek,
ancient Greek.
You need to do
archaeological excavations
and find
these ancient,
whether inscriptions
or pottery
or weapons
and analyze them.
Very costly
and difficult.
To write a fictional
story about
the Roman Empire,
very easy.
You just write
anything you want
and it's there
on the page
or on the internet.
The truth
is often also
very complicated
because reality
is complicated.
You want to give
a truthful explanation
for why the Roman Republic
fell
or why the Roman Empire
eventually fell.
Very complicated.
Whereas fiction
can be made
as easy
as simple as possible
and people tend
to prefer
simple explanations
over complicated ones.
And finally,
the truth
can be painful,
unattractive.
We often
don't want to know
the truth
about ourselves,
whether as individuals,
which is why
we go to therapy
for many years
to know the things
we don't want
to know about ourselves.
And also on the level
of entire nations.
You know,
each nation
has its own
dark episodes,
its own skeletons
or cemeteries
in the closet
that people don't
want to know about.
A politician
that, you know,
in an election campaign
would just tell people
the truth,
the whole truth
and nothing but the truth
is unlikely
to win many votes.
So in this competition
between the truth,
which is costly
and complicated
and sometimes painful
and fiction,
which is cheap
and simple
and you can make it
very attractive,
fiction tends to win.
And if you look
at, you know,
the large-scale systems,
networks in history,
they are often built
on fictions,
not on the truth.
Maybe I give
one example
if you think
about visual information
like portraits,
paintings,
photographs.
So what is
the most common
portrait in the world?
What is the most
famous face
in the history
of humanity?
It is the face
of Jesus.
I mean,
there are more
portraits of Jesus
than of any other
person in the history
of the world.
Billions and billions
produced over centuries
in cathedrals
and churches
and homes
and fully 100%
of them are fictional.
There is not a single
authentic,
truthful portrait
of Jesus anywhere.
We have no portrait
of him from his own
lifetime.
The Bible doesn't say
a single word
about how he looked like.
There is not a single
word in the Bible,
whether Jesus was
tall or short,
dark hair
or blonde
or bold,
nothing.
All the images,
and you know,
it's one of the most
famous faces in history.
It all comes from
the human imagination.
And it's still
very successful
in inspiring people
and uniting people.
Could be for good purposes,
you know,
charity
and building hospitals
and helping the poor,
but could also be
for bad purposes,
crusades,
persecutions,
inquisitions.
But either way,
the immense power
of a fictional image
to unite people.
And going,
looking at what's
happening today
in the world,
so you have these,
you know,
big tech companies
and social media companies
that they tell us
that our information
is always good.
So let's remove
all restrictions
on the flow of information
and flood the world
with more and more information.
And more information
would mean more truth,
more knowledge,
more wisdom.
And this is simply
not true.
Most information
is actually junk.
If you just flood
the world
with information,
the truth will sink
to the bottom.
It will not rise
to the top,
again,
because it's costly
and complicated.
And you look around,
we have this flood
of information,
we have the most
sophisticated information
technology in history,
and people are losing
the ability
to hold a conversation,
to talk
and listen to one another.
You know,
in the United States,
Republicans and Democrats
are barely able
to talk to each other.
And it's not
an American phenomenon.
You see the same thing
in Brazil,
in France,
in the Philippines,
all over the world.
Because,
again,
the basic misconception
is that more information
is always good for us.
It's like thinking
that more food
is always good for us.
the most information
is junk information.
Yeah.
And what's curious
to me about all of this
is that on some level
what you're saying is
there's nothing new
about this.
There is this idea
that suddenly
we've found ourselves
in a post-truth world.
And part of what you're saying
is it's kind of
always been that way.
But the qualitative difference
right now
is not by definition
these platforms
that allow us
to share information
as much as it is
the algorithms
that empower them
that make the decisions
about what we're seeing
and when we're seeing it.
Yeah.
I mean,
this is maybe
the first place
you see the power
of AIs
to make independent decisions
in a way
that reshapes the world.
When I said earlier
that, you know,
AIs can make decisions
and AIs,
they are not just tools
in our hands.
They are agents
creating new realities.
So you may think,
okay,
this is a prophecy
for the future.
A prediction
about the future,
but it's already
in the past
because even though
social media algorithms,
they are very,
very primitive AIs,
you know,
the first generation
of AIs,
they still reshaped
the world
with the decisions
they made.
In social media,
Facebook,
Twitter,
TikTok,
all that,
the ones that
make the decision
what you will see
at the top
of your news feed
or the next video
that you'll be recommended,
it's not a human being
sitting there
making these decisions.
It's an AI,
it's an algorithm.
And these algorithms
were given
a relatively simple
and seemingly
benign goal
by the corporations.
The goal was
increase user engagement,
which means
in simple English,
make people spend
more time
on the platform
because the more time
people spend
on TikTok
or Facebook
or Twitter
or whatever,
the company
makes more money.
It sells more advertisements,
it harvests
more data
that it can then
sell to third parties,
so more time
on the platform,
good for the company,
this is the goal
of the algorithm.
Now,
engagement
sounds like
a good thing,
who doesn't want
to be engaged?
But,
the algorithms
then experimented
on billions
of human guinea pigs
and discovered
something,
which was of course
discovered even earlier
by humans,
but now the algorithms
discovered it.
The algorithms
discovered
that the easiest way
to increase
user engagement,
the easiest way
to grab people's attention
and keep them glued
to the screen
is by pressing
the greed
or hate
or fear button
in our minds.
You show us
some hate-filled
conspiracy theory
and we become
very angry,
we want to see more,
we tell about it
to all our friends,
user engagement
goes up.
And this is what
they did
over the last
10 or 15 years.
They flooded the world
with hate
and greed
and fear,
which is why,
again,
the conversation
is breaking down.
Very hard to hold
the conversation
with all this
hate and fear.
Yeah,
it's a function
of unintended consequences
that on some level
is no different
than Nick Bostrom's,
you know,
alignment problem,
you know,
thought experiment
about paperclips.
like this is
the exact same thing
and I think
it speaks to
not only
human ignorance
but human hubris
around this
powerful technology.
I think,
you know,
you talk so much
about stories
and how indelible
they are in terms
of crafting
our reality,
but one of those
stories is
we know what
we're doing,
we can handle it,
we understand
the consequences,
we know
the downside here
and we're making
sure that
what we're putting
out in the world
is safe
and consumer-friendly
when,
you know,
on some level
they know it's not
but also
they have no idea,
you know,
what will become
of it as a result
and so we're just
in this frontier,
this unregulated frontier
where anything goes
at the moment.
Yeah,
and I think it's important
what you said
that these are
kind of unintended
consequences.
Like the people
who manage
the social media companies,
they are not evil,
they didn't set out
to destroy democracy
or to flood the world
with hate
and so forth.
They just really
didn't foresee
that when they give
the algorithm
the goal
of increasing
user engagement,
the algorithm
will start
to promote hate.
And one of the first
places that this happened...
But let me just interject
quickly on that,
though,
now that they know
that that's the case,
it's not as if
they're backtracking.
That's true.
I mean, now they know.
They're not exactly
regulation-friendly
at the moment.
No, absolutely not.
All right, sorry,
go ahead.
You're right.
Now they know
and they are not
doing nearly enough.
But initially,
when they started
this whole ball rolling,
they really didn't know.
And one of the places
you saw it
for the first time,
this was, you know,
eight years ago
when I published
Homo Deus,
this was happening.
I didn't pay attention
to it either.
In Myanmar,
Burma,
the country formerly
known as Burma,
Facebook was basically
the internet
and certainly
the biggest
social media platform.
And in the 2010s,
the algorithms
of Facebook
in Myanmar,
they deliberately
spread terrible
conspiracy theories
and fake news
about the Rohingya
minority in Myanmar,
which led
to an ethnic link
which, of course,
it was not the only reason.
There was deep-seated
hatred towards Rohingya
much before.
But this kind
of propaganda campaign
online on Facebook
contributed
to an ethnic
cleansing campaign
between 2016
and 2017,
2018,
in which thousands
of Rohingya
were killed,
tens of thousands
were raped,
and hundreds
of thousands
were expelled.
You now have
close to a million
Rohingya refugees
in Bangladesh
and elsewhere.
And this was fueled
to a large extent
by these conspiracy theories
and fake news
on Facebook.
And at the time,
the executive
of Facebook
had no...
I mean,
they didn't know
even the Rohingya existed.
It's not like
it was a conspiracy
of Facebook
against them.
For the whole
of Myanmar,
a country
where Facebook
had millions
and millions
of users,
they,
by 2018,
this is after
they got reports
of the ethnic
cleansing campaign,
they had just
a handful
of humans
trying to
kind of
regulate
the actions
of millions
of users
and the algorithms.
And they didn't
even speak Burmese.
Like,
when the algorithm
chose,
okay,
I'll show people
this hate-filled
conspiracy theory video,
in Burmese,
nobody in Facebook
headquarters
spoke Burmese.
They had no idea
what the algorithm
was promoting.
The key thing
is not to
absolve
the humans
from responsibility.
It's to understand
that even
very primitive
AIs,
and we were
talking about,
you know,
like eight years
ago,
not things
like ChatGPT.
Still,
the decisions
made by these
algorithms
to promote
certain content
had far-reaching
and terrible
consequences.
In Myanmar,
they were not
just producing
conspiracy theories,
they were producing
millions of users
producing,
you know,
cooking lessons
and biology lessons
and sermons
on compassion
from Buddhist monks
and conspiracy theories.
And the algorithms
made the decision
to promote
the conspiracy theories.
And this is just
kind of a warning
of look what happens
with even
very primitive
AIs.
And the AIs
of today,
which are far
more sophisticated
than in 2016,
they too
are still
just the very
early stages
of the AI
evolutionary process.
And we can think
about it like
the evolution
of animals.
Until you get
to humans,
you have
four billion years
of evolution.
You start
with microorganisms
like amoebas
and it took
billions of years
of evolution
to get to
dinosaurs
and mammals
and humans.
Now,
AIs are at present
at the beginning
of a parallel process
that ChatGPT
and so forth,
they are the amoebas
of the AI world.
But AI evolution
is not organic.
It's inorganic.
It's digital.
And it's millions
of times faster.
So where it took
billions of years
to get from amoebas
to dinosaurs,
it might take
just 10 or 20 years
to get from
the AI amoebas
of today
to AI T-Rex
in 2040
or 2050.
Maybe even less.
Maybe even less.
We're talking about,
I don't think
our brains
are organized
properly
to really comprehend
the accelerated speed
at which this is
self-learning
and iterating
and improving
upon itself.
Like,
it's a compounding
thing
that is astronomical.
Meanwhile,
trillions of dollars
are being spent
to build these
server farms
with these
NVIDIA chips
and there's
so much power
required to
keep these things
going.
They're talking
about nuclear power.
I mean,
this is like,
this is a whole
new world
and yet,
in talking about it,
it still feels
somewhat like
an academic exercise
because for myself
or somebody
who might be
watching or listening,
their experience
with AI
comes in the form
of ChatGPT
or some of these
helpful tools
like,
I like my algorithm.
It shows me
the kind of products
that I want to buy
without having
to search for it
and a simple example
would be
preparing for this podcast.
Like,
I listen to your book
on audiobook
and I'm doing
what I usually do,
pulling up a bunch
of tabs
and, you know,
like,
just collating
a bunch of information
on you
and the book
and the message
that you're putting out.
But I did something
I had never done before
which is
I got a PDF
of Nexus
and I uploaded it
to a tool
called Notebook LM
and that tool
then synopsized
the entire book
and created a chatbot
where I could ask it
questions about your book
and ask it to elaborate
on certain concepts
and it will even
create a podcast
conversation
between two people
about the subject matter
of the book.
So even this conversation
is at risk, right?
It's now irrelevant, yeah.
And I'm like,
wow,
that's kind of
a remarkably helpful tool
and it's easy
to, you know,
just not really
appreciate
or connect
with the downside
risk
and power
of these tools
and where they're
leading us.
So I think
what I'm saying is,
I guess the point
I'm trying to make
is consumers
like all of us,
we're being lured
into a trust
of something
so powerful
we can't comprehend
and are ill-equipped
to be able
to kind of
cast our gaze
into the future
and imagine
where this is leading us.
Absolutely.
I mean,
part of it
is that there is
enormous positive
potential in AI.
It's not like
it's all doom and gloom.
There is really
enormous positive potential
if you think about
the implications
for healthcare
that, you know,
AI doctors
available 24 hours a day
that know
our entire
medical history
and have read
every medical paper
that was ever published
and can tailor
their advice,
their treatment
to our specific
life history
and our blood pressure,
our genetics.
It can be
the biggest revolution
in healthcare ever.
If you think about
self-driving vehicles,
so every year
more than a million people
die all over the world
in car accidents
most of them
are caused
by human error
like people drinking
and then driving
or falling asleep
at the wheel
or whatever.
Self-driving vehicles
are likely to save
about a million lives
every year.
This is amazing.
You think about
climate change.
So yes,
developing the AIs
will consume
a lot of energy
but they could also
find new sources
of energy
and new ways
to harness energy
that could be
our best shot
at preventing
ecological collapse.
So there is
enormous positive potential.
we shouldn't deny
that we should
be aware of it
and on the other hand
it's very difficult
to appreciate
the dangers
because the dangers
they are kind of alien.
Like if you think
about nuclear energy,
yeah,
it also had
positive potential,
nuclear,
cheap nuclear energy
but people had
a very good grasp
of the danger,
nuclear war.
Anybody can understand
the danger of that.
With AI
it's much more complex
because the danger
is not straightforward.
The danger
is really,
I mean we've seen
the Hollywood
science fiction scenarios
of the big robot rebellion
that one day
a big computer
or the AI
decides to take over
the world
and kill us
or enslave us.
And this is extremely
unlikely to happen
anytime soon
because the AIs
are still a kind of
very narrow intelligence.
Like the AI
that can summarize a book
it doesn't know
how to act
in the physical world
outside.
You have AIs
that can fold proteins,
you have AIs
that can play chess
but we don't have
this kind of general AI
that can just
find its way
around the world
and build a robot army
and whatever.
So people,
it's hard on the center
what's so dangerous
about something
which is so kind of
narrow in its abilities.
And I would say
that the danger
doesn't come
from the big robot rebellion
it comes from
the AI bureaucracies.
Already today
and more and more
we will have
not one big AI
trying to take over
the world
we will have
millions and billions
of AIs
constantly making
decisions about us
everywhere.
You apply to a bank
to get a loan
it's an AI
deciding whether
to give you a loan.
You apply to get a job
it's an AI
deciding whether
to give you a job.
You're in court
or you're found guilty
of some crime
the AI will decide
whether you go
for six months
or three years
or whatever.
Even in armies
we already see now
in the war in Gaza
and with the war in Ukraine
AI make the decision
about what to bomb.
And in the Hollywood scenario
you have the killer robots
shooting people.
In real life
it's the humans
pulling the trigger
but the AI
is choosing the targets
is telling them
what to do.
This is much more complex
than the standard scenario.
Every point of connection
with bureaucracy
then becomes turned over
to an algorithm
that makes decisions
in a black box
without the opportunity
for rebuttal
or conversation.
Right?
So we're outsourcing
all of these decisions
and creating
like an autocratic
diaspora
of decision makers.
Right?
And that in turn
like you can imagine
over time
like what emerges
from that
is like a godhead
or a pantheon
of gods
where
there's an authoritarian
regime
that's dispersed
across this
in which we are
relenting our agency
over to these
machines
and trusting
that they're
making the right decisions
but not knowing
how those decisions
are being made
even the engineers
who are creating
the algorithms
don't know
and there's something
you know
kind of innately
terrifying about that.
Again it's not
authoritarian
in the sense
that there is
a single human being
that is pulling
all the levers
no it's the AI
it's like the bank
has this AI
that decides
who is qualified
to get a loan
and if they tell you
we decided not
to give you a loan
and you ask the bank
why not
and the bank says
we don't know
I mean computer says no
I mean the algorithm
says no
we don't understand
why the algorithm
says no
but we trust
the algorithm
and this is likely
to spread
to more and more
places.
The key thing
is it's not that
the bank is hiding
something from you
it's really that
the AIs make decisions
in a very different way
than human beings
on a basis
of a lot more data
so if the bank
really wanted
to explain to you
why they refuse
to give you a loan
like let's say
there is a law
the government
passes a law
of a right
to an explanation
if the bank
refused to give you
a loan
you can apply
they must give you
an explanation
so the explanation
well people fear
that it will be
kind of I don't know
racist bias
or homophobic bias
like in the old days
that the algorithm
saw that you're black
or you're Jewish
or you're gay
and this is why
they refuse to give you
a loan
it won't be like that
I mean the bank
will send you
an entire encyclopedia
millions of pages
saying this is why
the computer refused
to give you a loan
the computer
took into account
thousands and thousands
of data points
about you
each one based
on statistics
on millions
of previous cases
and now you can go
over these millions
of pages
if you like
and if you want
to challenge
okay
but it's not
the kind of
old style
racism
or whatever
sure
a new version
of the terms
and conditions
that we just click
on without reading
right
except extrapolated
a hundredfold
in addition to that
with all of these
data points
I can't help
but think that
that you know
these these machines
the veracity
of the information
that these machines
provide us
with
is only
as reliable
as
the data sets
that it
has been provided
with
and right now
we're tiptoeing
into a situation
where the internet
is being
rapidly degraded
because
it's being populated
more and more
by AI content
now when you go
to Google
and you search
the first thing
you see
is sort of
an AI
kind of
summary
of your query
as opposed
to links
and this in turn
is undermining
the business model
of legacy media
and all forms
of media
right
so as those
continue to die
on the vine
more and more
of the internet
will be
a result
of AI
generated content
and then it
becomes a recursive
thing
in which it's
feeding upon
its own inputs
to make decisions
and you know
with that
like you can imagine
a degradation
of the data set
upon which
it is making
those decisions
exactly
even if you think
about something
like music
so AI
that now creates
music
it basically
ate
the whole
of human music
like for thousands
of years
humans produced
music
or art
or theater
or whatever
within a year
the current
AI
just ate
the whole
of it
and digested
it
and start
now creating
new music
or new
texts
or new
images
and the first
kind of generation
of AI
texts
or music
this is based
on previous
human culture
but with each
passing year
the AIs
will be eating
their own
products
because as you know
the human share
in music production
or the human share
in text production
or image production
will go
lower and lower
most images
most music
will be produced
at least in part
by AI
and this will be
the new food
that the AI eats
and then you have
exactly what you described
this recursive pattern
and where it will lead us
we have no idea
I mean
another way to think about it
this is the first time
that we are basically
about to enter
a non-human culture
like humans
are our cultural entities
we live cocooned
inside culture
like all this
music
and art
and also finance
and also religion
this is all part of culture
and for tens of thousands
of years
the only entities
that produced culture
were other humans
so all the songs
you ever heard
were produced by humans
all the religious mythologies
you ever heard
came from the human imagination
now there is
an alien intelligence
a non-human intelligence
that will increasingly produce
songs and music
mythology
financial strategies
political ideas
even before we rush
to decide
is it good
is it bad
just stop and think
about the meaning
of living
in a non-human culture
or a culture
which is
I don't know
40%
or 70%
non-human
it's not like
going to China
and seeing a different
human culture
it's like
really alien culture
here on earth
yeah my human mind
bristles at that
I start thinking
about like this
this bias
I have
around the originality
of human thought
and emotion
and this
kind of assumption
that AI
will never be able
to fully mimic
the human experience
right
there's something
indelible about
what it means
to be human
that the machines
will never be able
to fully replicate
and when you talk
about
you know
information
the purpose of
information
being to create
connection
a big
piece there
is intimacy
like intimacy
between human beings
so information
is meant to create
connection
but now we have
so much information
and we're feeling
very disconnected
so there's something
broken in this system
and I think it's
driving this loneliness
epidemic
but on the other side
it's
it's making us
value
like intimacy
maybe a little bit
more than we
were previously
and so I'm curious
about where intimacy
kind of fits into
this you know
post-human world
in which culture
is being dictated
by machines
I mean human beings
are wired for that
kind of intimacy
and I think our radar
or our kind of
ability to
you know
identify it
when we see it
is part of what
makes us
human to begin with
maybe the most
important part
I think the key
distinction here
that is often lost
is the distinction
between intelligence
and consciousness
that intelligence
is the ability
to pursue goals
and to overcome
problems and obstacles
on the way
to the goal
the goal
could be a self-driving
vehicle
trying to get from
here to San Francisco
the goal
could be increasing
user engagement
and an intelligent
agent
knows how to
overcome the problems
on the way
to the goal
this is intelligence
and this is something
that AI
is definitely
acquiring
in at least
certain fields
AI is now
much more intelligent
than us
like in playing chess
much more intelligent
than human beings
but consciousness
is a different thing
than intelligence
consciousness
is the ability
to feel things
pain
pleasure
love
hate
when the AI
wins a game of chess
it's not joyful
if there is a tense
moment
in the game
it's not clear
who is going to win
the AI is not tense
it's only the human player
which is tense
or frightened
or anxious
the AI doesn't
feel anything
now there is a big
confusion
because in humans
and also in other mammals
in other animals
in dogs
and pigs
and horses
and whatever
intelligence
and consciousness
go together
we solve problems
based on our feelings
our feelings
are not something
that kind of evolution
it's decoration
it's the core system
through which
mammals make decisions
and solve problems
is based on our feelings
so we tend to think
that consciousness
and intelligence
must go together
and in all these
science fiction movies
you see that
as the computer
or robot
becomes more intelligent
then at some point
it also gains consciousness
it falls in love
with the human
or whatever
and we have no reason
to think like that
yeah consciousness
is not a mere
extrapolation of intelligence
absolutely not
it's a qualitatively
different thing
yeah and again
if you think
in terms of evolution
so yes
the evolution of mammals
took a certain path
a certain road
in which you develop
intelligence
based on consciousness
but so far
what we see
as computers
they took a different route
their road
develops intelligence
without consciousness
I mean computers
have been developing
you know
for 60-70 years now
they are not
very intelligent
at least in some fields
and still
zero consciousness
now this could continue
indefinitely
maybe they are just
on a different path
maybe eventually
they will be
far more intelligent
than us
in everything
and still
will have zero consciousness
will not feel pain
or pleasure
or love
or hate
you know
the same way
that if you think
about birds
and airplanes
so airplanes
did not become
like birds
airplanes don't fly
using feathers
and so forth
they fly
in a completely
different way
it's not like
that at a certain point
when the airplane
flies fast enough
suddenly the feathers
will appear
no
and it could be the same
with intelligence
and consciousness
that it will be
more and more intelligent
without feelings
ever appearing
now what adds
to the problem
is that there is
nevertheless
a very strong
commercial
and political incentive
to develop AIs
that mimic
feelings
to develop AIs
that can create
intimate relations
with human beings
that can
cause human beings
to be
emotionally attached
to the AIs
even if the AIs
have no feelings
of themselves
they could be trained
they are already trained
to make us
feel that they have feelings
and to start
developing relationships
with them
why is there
such an incentive?
because intimacy
is on the one hand
maybe the most
cherished
thing
that a human
can have
you know
just on the way
here we were listening
to Barbara Streisand
singing
people who need
people
are the luckiest
people
in the world
that intimacy
is not a liability
it's not something
bad
that oh
I need this
no it's the greatest
thing in the world
but it's also
potentially
the most powerful
weapons
weapon in the world
if you want to
convince somebody
to buy a product
if you want to
convince somebody
to vote for a certain
politician or party
intimacy is like
the ultimate weapon
I mean so far
in history
there was a big
battle for attention
how to grab
human attention
also we talked about
earlier in social media
how to get
human attention
and there were ways
like I don't know
in Nazi Germany
Hitler could force
everybody to listen
to his speech
on radio
so he had
command of attention
but not of intimacy
there was no
technology for
Hitler or Stalin
or anybody else
to mass produce
intimacy
now with AIs
it is possible
technically
to mass produce
intimacy
you can create
all these AIs
that will interact
with us
and they will
understand our feelings
because again
feelings are also
patterns
you can predict
a person's feelings
by watching them
for weeks and months
and learning
their patterns
and facial expression
and tone of voice
and so forth
and then
if it's in the wrong hands
it could be used
to manipulate us
like never before
sure it's our ultimate
vulnerability
this beautiful thing
that makes us human
becomes this
great weakness
that we have
because
as these AIs
continue to
self-iterate
their capacity
to mimic
consciousness
and human intimacy
will reach
such a degree
of fidelity
that it will be
indistinguishable
to the human brain
and then
humans become
like these
unbelievably
easy to hack
machines
who can be
directed
wherever the AI
chooses to
direct them
yeah
it's not a prophecy
we can take
actions
today
to prevent this
we can have
regulations about it
we can for instance
have a regulation
that AIs are welcome
to interact with humans
but on condition
that they disclose
that they are AIs
if you talk
with an AI doctor
that's good
but the AI
should not pretend
to be a human being
you know
I'm talking with an AI
I mean
it's not that
there is no possibility
that AI
will develop consciousness
we don't know
I mean
there could be
that AIs
will really develop
consciousness
it's mimicking it
to such a degree
of fidelity
does it even
in terms of like
how human beings
interact with it
does it matter
for the human beings
no
I mean
this is the problem
I mean
because
we don't know
if they really
have consciousness
or they're only
very very good
at mimicking consciousness
so the key question
is ultimately
political and ethical
if they have consciousness
if they can feel
pain
and pleasure
and love
and hate
this means
that they are
ethical
and political
subjects
they have
rights
that
you should
not inflict
pain
on an AI
the same way
you should not
inflict pain
on a human being
that what
they like
what they love
might be as
important as
what human beings
desire
so they should
also vote
in elections
and they could
be the majority
because you know
you can have
a country
100 million humans
and 500 million
AIs
so do they
choose the government
in this situation
now you know
in the United States
interestingly enough
there is actually
an open legal path
for AIs
to gain rights
it's one of the only
countries in the world
where this is the case
because in the United States
corporations are recognized
as legal persons
with rights
until today
this was a kind of
legal fiction
like according to US law
Google is a person
it's not just a corporate
it's a person
and as a person
it also has freedom of speech
this is the
Supreme Court ruling
for 2010
of Citizen United
now
until today
this was just legal fiction
because every decision
made by Google
was actually made
by some human being
an executive
a lawyer
an accountant
Google
could not make a decision
independent of the humans
but now you have AIs
so imagine the situation
when you incorporate
an AI
now this AI
is a corporation
and as a corporation
US law recognizes it
as a person
with certain rights
like freedom of speech
now it can earn money
it can go online
for instance
and offer it services
to people
and earn money
then it can open
a bank account
and invest its money
in the stock exchange
and if it's very smart
and very intelligent
it could become
the richest person
in the US
now imagine
the richest person
in the US
is not a human
it's an AI
and according to US law
one of the rights
of this person
is to make
political contributions
donations
this was the main reason
behind Citizen United
in 2010
so this AI
now makes
billions of dollars
of contributions
to politicians
in exchange
for expanding
AI rights
and the legal path
in the US
is completely open
you don't need
any new law
to make this happen
that's like
that's a plot
of a movie
yeah
when you know
we're in LA
yeah I mean
wow
that's so wild
to contemplate
what are the
differences
in the ways
in which
the advent
of this
powerful technology
is impacting
democratic systems
and authoritarian systems
so both systems
have a lot to gain
and have a lot to lose
again the AI
it's the most powerful
technology ever created
it's not a tool
it's an agent
so you have millions
and billions
of new agents
are very intelligent
very capable
that can be used
to create
the best healthcare system
in the world
but also
the most lethal
army in the world
or the worst
secret police
in the world
if you think
about authoritarian regimes
so throughout history
they always wanted
to monitor
their citizens
around the clock
but this was
technically impossible
even in the Soviet Union
you know
you have 200 million
Soviet citizens
you can't follow
them
all the time
because the KGB
didn't have
200 million agents
and even if the KGB
somehow got
200 million agents
that's not enough
because you know
in the Soviet Union
it's still basically
paper bureaucracy
the secret police
if a secret agent
followed you around
24 hours a day
at the end of the day
they write a paper report
about you
and send it to
KGB headquarters
in Moscow
so imagine
every day
KGB headquarters
is flooded
with 200 million
paper reports
now to be useful
for anything
somebody needs
to read and analyze them
they can't do it
they don't have
the analysts
therefore even
in the Soviet Union
some level of privacy
was still the default
for most people
for technical reasons
now for the first time
in history
it is technically possible
to annihilate privacy
a totalitarian regime
today doesn't need
millions of human agents
if he wants to follow
everybody around
you have the smartphones
and cameras
and drones
and microphones
everywhere
and you don't need
millions of human analysts
to analyze this ocean
of information
you have AI
and this is already
beginning to happen
this is not a future
prediction
in many places
around the world
you begin to see
the formation
of this totalitarian
surveillance regime
it's happening
in my country
in Israel
Israel is building
this kind of
surveillance regime
in the occupied
Palestinian territories
to follow everybody
around all the time
and also in our region
in Iran
since the Islamic revolution
in 1979
they had the hijab laws
which says that
every woman
when she goes out
walking
or even driving
in her private car
she must wear
the hijab
the headscarf
and until today
the regime
had difficulty
enforcing
the hijab laws
because they didn't have
you know
millions of police officers
that you can place
on every street
a police officer
if a woman drives
without a headscarf
immediately
she's arrested
and fine
or whatever
in the last few years
they switched
to relying
on an AI system
Iran is now
crisscrossed
by surveillance cameras
with facial recognition software
which recognizes
automatically
if in the car
that just passed
by the camera
the facial recognition software
can identify
that this is a woman
not a man
and she's not
wearing the hijab
and identify
her identity
find her phone number
and within half a second
they send her
an SMS message
saying
you broke the hijab law
your car is impounded
your car is confiscated
stop the car
by the side of the world
this is daily occurrence
today
in Tehran
and Isfahan
and other parts of Iran
and this is based on AI
and it's not like
there is a report
that goes to the court
and some human judge
goes over the data
and decides
what to do
the AI
like immediately
decides
okay
the car is confiscated
and this can happen
in more and more places
around the world
like even in the US
you know
for if you think about
all the debate
about abortion
without going into
the debate itself
the people who think
rightly or wrongly
but they think
that abortion
is murder
they have a very
strong incentive
to build
a similar
surveillance system
for American women
you know
to stop murder
like you can build
this surveillance system
that can identify
yesterday
yesterday you were pregnant
today you are not
what happened
in between
so it's not just
a problem
you know
for Iran
or for the Palestinians
or the Chinese
this can come
to the US as well
and to prevent them
from crossing
state lines
things like that
yeah
like okay
you went from
I don't know
Texas
to California
you were pregnant
you came back
you're not pregnant
what happened
in California
so it feels like
AI is this
incredible tool
to consolidate power
around authoritarian regimes
but it also has
its pitfalls too
like it's not the perfect tool
it also frightens
the autocrats
because the one thing
that human dictators
always feared most
was not a democratic revolution
the one thing
they feared most
is a powerful subordinate
that they can't control
and that might manipulate them
or take power from them
if you can look at
the Roman Empire
not a single Roman Emperor
was ever toppled
by a democratic revolution
never happened
but many of them
lost their life
or their power
to a subordinate
you know
a general
that rebelled against them
a provisional governor
their brother
their wife
that took power from them
this is the greatest fear
of every dictator
also today
and so
if you think about AI
so if you're a human dictator
and you now
give this immense power
to an AI system
where is the guarantee
that this system
will not turn against you
and either eliminate you
or just turn you
into a puppet
I mean
what we also know
about dictators
it's relatively easy
to manipulate these people
if you can whisper
in their ear
because they are very paranoid
and the easiest people
to manipulate
are the paranoid people
and we have our
AI corporation
in the United States
that can deploy
billions of dollars
towards bots
and whatever else
to you know
create that paranoia
or enhance it
you really just need
to hack one person
you know
for an AI
to take power
in the US
very complicated
it's such a distributed system
like okay
the AI can learn
to manipulate
the president
but it also needs
to manipulate
the senators
and the congress members
and the state governors
and the supreme court
like what would the AI
do with the senate filibuster
it's difficult
but if you want
to take power
in a dictatorship
you just need
to learn to manipulate
a single person
so the dictators
are not all happy
about the AIs
and we're already
beginning to see it
for instance
with chatbots
that they are
very concerned
because you know
you can design
a chatbot
which will be
completely loyal
to the regime
but once you release it
to the internet
to start interacting
with people
in real life
it changes
I mean remember
what we talked earlier
that AI
is defined
by the ability
to learn
and change
by itself
so even if
Putin creates
like the Putinist
chatbot
that always says
that Putin is great
and Putin is right
and Russia is great
and so forth
but then you release it
to the real world
it starts observing
things in the real world
for instance
it notices
that you know
in Russia
the invasion of Ukraine
is officially
not a war
it's called
a special military operation
and if you say
that it's a war
you go to prison
for up to I think
three years
or something like that
because it's not a war
it's a special military operation
now what do you do
if a very intelligent
chatbot
that you released
you know
connects the dots
and says
no
it's not a special
military operation
it's a war
would you send
a chatbot to prison
what can you do
and you know
democracies of course
also have a problem
with chatbot
saying things
we don't like
they can be racist
they can be homophobic
whatever
but the thing
about democracy
it has a relatively
wide margin
of tolerance
even for anti-democratic speech
dictatorships
have zero margin
for dissenting views
so they have a much
bigger problem
with how to control
these unpredictable
chatbots
but with the last decade
of hosting this podcast
my mission has been
to engage in
what I consider
to be
critically important
conversations
about the things
that matter
most in life
while I'm immensely
grateful
for the growth
of this show
I've also come
to realize
that my voice
alone is not enough
this mission
cannot be
a solitary endeavor
so I wanted to
find a way
to help amplify
other meaningful voices
and the result
is Voicing Change Media
this beautiful
consortium
of thinkers
storytellers
artists
and visionaries
all committed
to fostering
meaningful exchanges
intentionally curated
for those committed
to the path
of self-discovery
together
we're creating
a space of growth
a space of understanding
where every exchange
has the potential
to enrich our lives
and catalyze
profound
personal
and planetary change
visit
voicingchange.media
to learn more
and subscribe
how are you interpreting
the current moment
given that we're on the cusp
of an election here
in the United States
and you know
there's a lot of
discourse
around
the existential threat
to democracy
that we may be facing
what role
is AI playing
in this
what should we
understand
about the impact
of this technology
on us
as citizens
and voters
at present
I don't think
that AI
has
again
social media
has of course
a huge impact
on the political discourse
and thereby
on the results
of the elections
but
I don't see AI
really kind of changing
or manipulating
the elections
in November
it's too close
the big question
is
whoever wins
the elections
maybe
the most important
decisions
that person
has to make
will be
about AI
because of
the extremely
rapid pace
that this technology
is developing
you know
you look at
where chat GPT
was a year ago
you look at
what things
are now
in 2024
what will be
the state
of AI
in 2027
2028
so you know
I watched
the presidential debate
most people
their main takeaway
was about
the cats
and the dogs
it's the most
memorable thing
from the debate
I mean
you know
whoever wins
maybe will have
to make
some of the most
important decisions
in history
about the relations
if you're worried
about immigration
it's not the immigrants
that will you know
replace the taxi drivers
it's the immigrants
that will replace
the bankers
that you should be
worried about
and it's the AIs
not somebody coming
from south of
the border
and who do you trust
to make
these momentous decisions
now and if you
think specifically
about the threats
to democracy
so one thing
we learned
from history
is that
democracies
always
since again
ancient Athens
they always
had this
one single
big
problem
or weakness
that democracy
is basically
a kind of
a deal
that you
give power
to somebody
for a limited
time period
for four years
on condition
they give it back
and then you can
make a different
choice
like we tried this
it didn't work
let's try something else
this ability
to say
let's try something else
this is democracy
and it's based
on that
you give power
and you expect
to get it back
after four years
transfer
what happens
if you give power
to somebody
who then
doesn't give it back
they now have
the power
they have the power
to also stay in power
that was always
the biggest danger
in democracy
so for me
in the issue
in the US elections
it's you can discuss
the economic policies
the foreign policies
you like this
you like that
there is discussion
to be had
but you have
your one person
Donald Trump
and that has
you know
you have a record
for the previous time
that this person
doesn't want
to give power back
and he is willing
to go a long way
including
potentially inciting
violence
to avoid
giving power back
and you want
to give him
so much power
that doesn't sound
like a very
a very good idea
so for me
this is the kind of
the number one issue
in the elections
everything else
is
of marginal
importance
in comparison
yeah
I mean
I think it challenges
our
our predilections
around the stability
of democracy
and is forcing us
to really embrace
the fact that
it is a delicate
dynamic
that is
you know
informed by
collective action
by the people
and
in reflecting upon
you know
this technology
also
you know
the story of technology
is one in which
our ability
to legislate
around it
and regulate it
always falls
you know
way behind
the pace
of advancement
and now we're
in a situation
where the pace
of advancement
is like nothing
we've ever seen
before
which calls
into question
our ability
to not only
you know
kind of
put guardrails
around it
but to even
understand
what is actually
happening
the history
of information
systems
is one of
collective
human cooperation
and yet
we're in
a situation
right now
where
it feels
like
cooperation
is being
challenged
not only
nationally
here in the
United States
but
internationally
and so
as we
kind of
begin
to talk
about
how we're
going to
triage
this
or find
solutions
like
where do
you land
in terms
of
our
capacity
to
collectively
come
together
as a
global
community
to figure
out
solutions
and then
put them
into
motion
so that
we don't
tiptoe
into some
kind of
dystopia
so there
is a lot
to unpack
here
so first
of all
when we
think about
cooperation
as we
said earlier
this was
always our
biggest
advantage
as a
species
that we
cooperate
better than
anybody
else
we can
construct
these
even
global
networks
of trade
that no
other animal
even
understands
like if
you think
about
I don't
know
horses
so
horses
never
figured
out
money
they
were
bought
and
sold
but
they
never
understood
what
are
these
things
that
the
humans
are
exchanging
and
this
is
why
horses
could
never
unite
against
us
or
could
never
manipulate
us
because
they
never
figured
out
how
the
system
works
that
one
person
is
giving
me
to
another
person
in
exchange
for
a
few
shiny
metal
things
or
some
pieces
of
paper
AI
is
different
it
understands
money
better
than
most
people
like
most
people
don't
understand
how
the
financial
system
really
works
and
financial
AIs
in
fintech
they
already
surpass
most
human
beings
not
all
human
beings
but
most
human
beings
in
their
understanding
of
money
so
we
are
now
confronting
millions
of
new
agents
that
potentially
can
use
our
own
systems
against
us
that
computers
can
now
collaborate
using
for instance
the
financial
system
more
efficiently
than
humans
can
so
the
whole
issue
of
cooperation
is
changing
and
computers
also
learn
how
to
use
the
communication
systems
to
manipulate
us
like
in
social
media
so
they
are
cooperating
where
we
are
losing
the
ability
to
cooperate
and
that
should
raise
the
alarm
now
and
the
thing
is
it's
very
difficult
to
understand
what
is
happening
if
we
want
humans
around
the
world
to
cooperate
on
this
to
build
guardrails
to
regulate
the
development
of
AI
first
of
all
you
need
humans
to
understand
what
is
happening
secondly
you
need
the
humans
to
trust
each
other
and
most
people
around
the
world
are
still
not
aware
of
what
is
happening
on
the
AI
front
you
have
a
very
small
number
of
people
in
just
a
few
countries
mostly
the
US
and
China
and
a
few
others
who
understand
most
people
in
Brazil
in
Nigeria
in
India
they
don't
understand
and
this
is
very
dangerous
because
it
means
that
a
few
people
many
of
them
are
not
even
elected
by
the
US
citizen
they
are
just
private
companies
they
will
make
the
most
important
decisions
and
the
even
bigger
problem
is
that
even
if
people
start
to
understand
they
don't
trust
each
other
like
I
had
the
opportunity
to
talk
to
some
of
the
people
who
are
leading
the
AI
revolution
which
is
still
led
by
humans
it
is
still
humans
in
charge
I
don't
know
for
how
many
more
years
but
as
of
2024
it's
still
humans
in
charge
and
you
meet
with
these
you
know
entrepreneurs
and
business
tycoons
and
politicians
also
in
the
US
in
China
in
Europe
and
they
all
tell
you
the
same
thing
basically
they
all
say
we
know
that
this
thing
is
very
very
dangerous
but
we
can't
trust
the
other
humans
if
we
slow
down
how
do
we
know
that
our
competitors
will
also
slow
down
whether
our
business
competitors
let's
say
here
in
the
US
or
our
Chinese
competitors
across
the
ocean
and
you
go
and
talk
with
the
competitors
they
sell
the
same
thing
we
know
it's
dangerous
we
would
like
to
slow
down
to
give
us
more
time
to
understand
to
assess
the
dangers
to
debate
regulations
but
we
can't
we
have
to
rush
even
faster
because
we
can't
trust
the
other
corporation
the
other
country
and
if
they
get
it
before
we
get
it
it
will
be
a
disaster
and
so
you
have
this
kind
of
paradoxical
situation
where
the
humans
can't
trust
each
other
but
they
think
they
can
trust
the
AIs
because
when
you
talk
with
the
same
people
and
you
tell
them
okay
I
understand
you
can't
trust
the
Chinese
or
you
can't
trust
open
AI
so
you
need
to
move
faster
developing
this
super
AI
how
do
you
know
you
could
trust
the
AI
and
then
they
tell
you
oh
I
think
that
will
be
okay
I
think
we
figured
out
how
to
make
sure
that
the
AI
will
be
trustworthy
and
under
our
control
so
we
have
this
very
paradoxical
situation
when
we
can't
trust
our
fellow
humans
but
we
think
we
can
trust
and
layered
on top
of
that
is
an
incentive
structure
of
course
that
further
engenders
distrust
in this
arms race
right
like
the
prize
goes
to
the
breakthrough
developers
and
those
will be
rewarded
and
remunerated
in ways
that
are
you know
perhaps
unprecedented
right
so
absolutely
so
the
breakthroughs
and
what's
on the
other
side
of
that
is
is
so
enticing
that
any
discourse
around
regulation
that might
slow
it
down
becomes
not
only
a
national
security
threat
but
also
an
entrepreneurial
threat
right
so
everything
is
motivating
rapid
acceleration
at the
cost of
transparency
and regulation
and all
these other
things
all these
checks
and balances
that
we really
need
right now
and
I don't
know
like
you know
how you're
feeling
about this
but
it
leaves me
a little
cold
and
pessimistic
like
you're
a historian
like
the story
of human
kind
is
all
gas
no
brakes
you know
like
let's
just
we're
plowing
forward
and
we'll
deal
with
the
consequences
when
they
come
like
we're
not
wired
adequately
to
really
appreciate
the
long-term
consequences
of our
behavior
we're
kind
of
you
know
looking
right
in
front
of
us
and
making
decisions
based
on
how
it's
going
to
impact
us
in
the
immediate
future
and
and
very
little
else
yeah
I mean
throughout
history
they tend
to solve
the wrong
problems
like
they spend
very little
time
deciding
what
problem
we need
to solve
like
five percent
of the
effort
goes on
choosing
the
problem
then
95%
of the
effort
goes in
solving
the
problem
we
focus
on
and
then
we
realize
oh
we
actually
solved
the
wrong
problem
and
it
just
creates
new
problems
down
the
road
that
we
now
need
to
and
then
we
do
it
the
same
again
and
you
know
wisdom
often
comes
from
silence
from
taking
time
from
slowing
down
let's
really
understand
the
situation
before
we
rush
to
make
a
decision
and
you
know
it
starts
on
the
individual
level
that
so
many
people
for
instance
think
oh
my
main
problem
is
in
life
is
that
I
don't
have
enough
money
and
then
they
spend
the
next
50
years
making
lots
of
money
and
even
if
they
succeed
they
wake
up
at
certain
point
and
said
oops
I
think
I
chose
the
wrong
problem
I
think
it
wasn't
yeah
I
need
some
money
but
it
wasn't
my
main
problem
in
life
and
we
are
perhaps
doing
it
collectively
as a
species
the
same
thing
you
know
you
go
back
to
something
like
the
agriculture
revolution
so
people
thought
okay
we
don't
have
enough
food
let's
produce
more
food
with
agriculture
we'll
domesticate
wheat
and rice
and potatoes
we'll
have
lots
more
food
life
will
be
great
and
then
they
domesticate
these
plants
and also
some
animals
cows
chickens
pigs
whatever
and
they
have
lots
of
food
and
they
start
building
these
huge
agricultural
societies
with
towns
and
cities
and
then
they
discover
a
lot
of
new
problems
they
did
not
anticipate
for
instance
epidemics
hunter
gatherers
did
not
suffer
almost
any
infectious
diseases
because
most
infectious
diseases
came to
humans
from
domesticated
animals
and
they
spread
in
the
dense
towns
and
cities
now
if
you
live
in
a
hunter
gatherer
band
you
don't
hold
any
chickens
or
pigs
so
it's
very
unlikely
some
virus
will
jump
from
a
wild
chicken
to
you
and
even
if
you
got
some
new
virus
you
have
just
like
20
other
people
in
your
band
and
you
move
around
all
the
time
maybe
you
infect
five
others
and
like
three
die
and
that's
the
end
of
it
but
once
you
have
these
big
agricultural
cities
then
you
get
the
epidemics
people
thought
they
were
building
paradise
for
humans
turned
out
they
were
building
paradise
for
germs
and
human
life
expectancy
and
human
living
conditions
for
most
humans
actually
goes
down
if
you're
a
king
or
a
high
priest
it's
okay
but
for
the
average
person
it
was
actually
a
bad
move
and
the
same
thing
happens
again
and
again
throughout
history
and
it
can
happen
now
on a
very
very
big
scale
with
AI
in a
way
it
goes
back
to
this
issue
of
organic
and
inorganic
that
organic
systems
are
slow
they
need
time
and
this
AI
is
an
inorganic
system
which
accelerates
beyond
anything
we can
deal
with
and
the
big
question
is
whether
we
will
force
it
to
slow
down
or
it
will
force
us
to
speed
up
until
the
moment
we
collapse
and
die
I
mean
if
you
force
an
organic
entity
to
be
on
all
the
time
and
to
move
faster
and
faster
and
faster
eventually
it
collapses
and
dies
one
of
the
things
I
heard
you
say
that
really
struck
me
was
this
it's
a
quote
if
something
ultimately
destroys
us
it
will
be
our
own
delusions
so
can you
elaborate
on
that
a
little
bit
and
how
that
applies
to
what
we've
been
talking
about
yeah
I mean
the
AI
at least
of the
present
day
they
cannot
escape
our
control
and
they
cannot
destroy
us
unless
we
allow
them
or
unless
we
kind
of
order
them
to
do
that
we
are
still
in
control
but
because
of
our
you
know
political
and
mythological
delusions
we
cannot
trust
the
other
humans
and
we
think
we
need
to
develop
these
AIs
and
faster
and
faster
and
give
them
more
and
more
power
because
we
have
to
compete
with
the
other
humans
and
this
is
the
thing
that
could
really
destroy
us
and
you
know
it's
very
unfortunate
because
we
do
have
a
track
record
of
actually
being
quite
successful
of
building
trust
between
humans
it
just
takes
time
I
mean
if
you
think
about
the
long
arc
of
human
history
so
these
hunter
gatherer
bands
tens
of
thousands
of
years
ago
they
were
tiny
couple
of
dozen
individuals
and
even
though
the
next
steps
like
agriculture
they
had
their
downside
again
like
epidemics
people
did
learn
over
time
how
to
build
much
larger
societies
which
are
based
on
trust
if
you
now
live
in
the
United
States
or
some
other
country
you
are
part
of
a
system
of
hundreds
of
millions
of
people
who
trust
each
other
in
many
ways
which
were
really
unimaginable
in
the
Stone Age
like
you
don't
know
99.99%
of the
other
people
in
the
country
and
still
you
trust
them
with
so
much
I
mean
the
food
you
eat
mostly
you
did
not
go
to
the
forest
to
hunt
and
gather
it
by
yourself
you
rely
on
strangers
to
provide
the
food
for
you
most
of
the
tools
you
use
are
coming
from
strangers
your
security
you
rely
on
police
officers
on
soldiers
that
you
never
met
in
your
life
they
are
not
your
cousins
they
yes
if
you
now
go
to
the
global
level
okay
we
still
don't
know
how
to
trust
the
Chinese
and
the
Israelis
still
don't
know
how
to
trust
the
Iranians
and
vice
versa
but
it's
not
like
we
are
stuck
while
we
were
in
the
Stone
Age
we've
made
immense
progress
in
building
human
trust
and
we
are
rushing
to
throw
it
all
away
because
it
just
again
it
takes
time
it
will
not
happen
tomorrow
yeah
I
mean
I
think
it's
urgent
that
we
find
a way
back
to
repairing
some
institutional
trust
right
like
that
has
been
degraded
in
recent
times
and
I
think
without
that
we
stand
very
little
chance
as
a
democratic
republic
of
surviving
and
solving
these
kinds
of
problems
absolutely
if
you
ask
in
brief
what
is
the
key
to
building
trust
between
millions
of
strangers
the
key
is
institutions
because
you
can't
build
a
personal
intimate
relationship
with
millions
of
people
so
it's
only
institutions
whether
it's
courts
or
police
forces
or
newspapers
or
universities
or
healthcare
systems
that
build
trust
between
people
and
unfortunately
we now
see
this
again
another
epidemic
of
distrust
in
institutions
on
both
the
right
and
the
left
it
is
fueled
by
a
very
cynical
worldview
which
basically
says
that
the
only
reality
is
power
and
humans
only
want
power
and
all
human
interactions
are
power
struggles
so
whenever
somebody
tells
you
something
you
need
to
ask
whose
privileges
are
being
served
whose
interests
are
being
advanced
and
any
institution
is
just
an
elite
conspiracy
to
take
power
from
us
so
journalists
they're
not
really
interested
in
knowing
the
truth
about
anything
they
just
want
power
and
the
same
for
the
scientists
and
the
same
for
the
judges
and
if
this
goes
on
then
all
trust
in
institutions
collapses
and
then
society
collapses
and
the
only
thing
that
can
still
function
in
that
situation
is
a
dictatorship
because
dictatorships
don't
need
trust
they are
based
on
terror
so
people
who
attack
institutions
they
often
think
oh
we
are
liberating
the
people
from
these
authoritarian
institutions
they are
actually
paving
the way
for
a
dictatorship
and
the
thing
is
that
this
view
is
not
just
very
cynical
it's
also
wrong
humans
are
not
these
power
crazy
demons
all
of us
want
power
to
some
extent
that's
true
but
that's
not
the
whole
truth
about
us
humans
are
really
interested
in
knowing
the
truth
about
ourselves
about
our
lives
about
the
world
on a
very
deep
level
because
you
can
never
be
happy
if
you
don't
know
the
truth
about
your
life
because
you
will
not
know
what
are
the
sources
of
misery
again
you
will
focus
on
your
life
if
you
don't
know
the
truth
you
waste
all
your
life
trying
to
solve
the
wrong
problems
and
this
is
true
of
also
of
journalists
and
judges
and
scientists
yes
there
is
corruption
in
every
other
in
check
but
if
you
destroy
all
trust
in
institutions
what
you
get
is
either
anarchy
or
dictatorship
and
again
it's
a good
exercise
every
now
and
then
to
stop
and
think
about
how
every
day
we
are
protected
by
all
kinds
of
institutions
like
when
people
talk
with
me
about
the
deep
state
you
know
this
conspiracy
about
the
deep
state
I
immediately
think
about
the
sewage
system
the
sewage
system
is
the
deep
state
it's
a
deep
system
of
tunnels
and pipes
and pumps
which is
state
built
under
our
houses
and
streets
and
neighborhoods
and
saves
our
life
every
day
because
it
keeps
our
sewage
separate
from
our
drinking
water
you
know
you
go to
the
toilet
you
do
your
thing
it
goes
down
into
the
deep
state
which
keeps
it
separate
from
the
drinking
water
if
I
can
tell
one
historical
anecdote
where did
it
come
from
so
you
know
after
agricultural
revolution
you have
big cities
they are
paradise
for germs
hotbeds
for epidemics
this continues
really until
the 19th century
London
in the 19th century
was the biggest
city in the world
and one of the most
dirty and polluted
and a hotbed
for epidemics
and in the middle
of the 19th century
there is a cholera
epidemic
and people in London
are dying from
cholera
and then you have
this bureaucrat
medical bureaucrat
John Snow
not the guy
from games
of thrones
a real
John Snow
who did not
fight dragons
and zombies
but actually
did save
millions of
lives
because he
went around
London
with lists
and he
interviewed
all the
people who
got sick
or died
if somebody
died from
cholera
he would
interview
their family
tell me
where did
this person
get their
drinking water
from
and he
made these
long lists
of hundreds
and thousands
of people
and by
analysing
these lists
he pinpointed
a certain
well
on Broad Street
in Soho
in London
where
everybody
almost everybody
who got sick
on cholera
they had a zip
of water
from that well
at a certain
stage
and he
convinces
the municipality
to disable
the pump
of the well
and the epidemic
stops
and then
they investigate
they discover
that the well
was dug
about a meter
away
from a cesspit
and water
sewage water
from the cesspit
got into
the drinking water
and today
if you want
to dig
a well
or a cesspit
in London
or in Los Angeles
you have to fill
so many forms
and to get
all these
bureaucratic
permits
and it saves
our lives
and how does
that relate
to this idea
of the deep state
I'm trying to
tether those
two notions
together
again the people
who believe
the conspiracy
theories about
the deep state
they say
that all
these
state bureaucracies
they are
elite
conspiracies
against the
common people
trying to
take over
power
trying to
destroy us
and in
most cases
no the
people in
this you
know
to manage
a sewage
system
you need
plumbers
you also
need
bureaucrats
again you
need to
apply for
a license
to dig
a well
and it
is managed
by all
these kind
of state
bureaucrats
and it's
a very
good thing
because again
there is
corruption
in these
places
sometimes
this is
why we
keep
also
courts
you can
go to
court
this is
why we
keep
newspapers
so they
can expose
corruption
in the
cities
in the
municipalities
sewage
department
but most
of the
time
most of
these
people
are
honest
people
who are
working
very hard
every day
to keep
our sewage
separate from
our drinking
water
and to keep
us alive
and by
extrapolation
there are
all of
these
bureaucracies
that are
working
in our
interest
in
invisible
ways
that we
take
for
granted
you've
often said
clarity
is power
and I
think your
superpower is
your ability
to kind
of stand
at 10,000
feet
and look
down on
humanity
and the
planet
and identify
what's
most important
in these
macro trends
that help
us make
sense of
what's
happening
now
and I'd
like to
kind of
end this
with some
thoughts on
how you
cultivate
that clarity
through
meditation
and your
you know
very kind
of like
profound
practice of
mindfulness
and information
deprivation
I should say
right
information fast
yeah
starting maybe
with the idea
of an
information fast
so I think
this is
important today
for every
person to
go on an
information
diet
that this
idea that
more information
is always good
for us
is like
thinking that
more food
is always good
for us
it's not
true
and the
same way
that the
world is
full of
junk food
that we
better avoid
the world
is also
full of
junk
information
that we
have better
avoid
information
which is
artificially
filled
with greed
and hate
and fear
information
is the
food of
the mind
and we
should be
as mindful
as what
we put
into our
minds
as of
what we
put into
our mouths
but it's
not just
about limiting
consumption
it's also
about
digesting
it's also
about
detoxifying
like we
go throughout
our life
and we
take in
a lot of
junk
whether we
like it
or not
that fills
our mind
and I
meditate
two hours
every day
so I can
tell you
there is
a lot
of junk
in there
a lot
of hate
and fear
and greed
that I
picked up
over the
years
and it's
important
to take
time
to simply
digest
the information
and to
also detoxify
to kind
of let
go
of all
this
hatred
and anger
and fear
and greed
which is in
our minds
so I
began
when I was
doing my
PhD in
Oxford
a friend
recommended
that I
go on
a meditation
retreat
or a
Vipassana
meditation
and for
a year
he kind
of nagged
me to go
and I
said
no this
is kind
of
mystical
mumbo
jumbo
I don't
want
to
and eventually
I went
and it was
amazing
because it
was the
most remote
thing for
mysticism
that I
could imagine
because
it was a
10 days
retreat
and on
the very
first
evening
of the
retreat
the teacher
Esen Goenka
the only
instruction
he gave
he didn't
tell me
to kind
of visualize
some
goddess
or do
this
nothing
he just
said
what is
really
happening
right now
bring your
attention
to your
nostrils
to your
nose
and just
feel
whether the
breath is
going in
or whether
the breath
is going
out
that's the
only exercise
like a
pure
observation
of reality
what amazed
me was my
inability to
do it
like I
would bring
my attention
to the
nose
and try
to feel
is it
going in
is it
going out
and after
about five
seconds
some
thought
some
memory
some
fantasy
would arise
in the
mind
and would
just
hijack
my
attention
and for
the next
two or
three minutes
I would be
rolling
in this
fantasy
or memory
until I
realized
hey I
actually need
to observe
my breath
and I
would come
back to
the breath
again five
seconds
maybe ten
seconds
I will be
able oh
now it's
coming in
it's coming
in oh
now it's
going out
it's going
out and
again some
memory would
come and
hijack me
and I
realized first
that I've I
know almost
nothing about
my mind
I have no
control of
my mind
and my
mind is
just like
this factory
that constantly
produces
fantasies and
illusions and
delusions that
come between me
and reality
like if I
can't observe
the breath
going in and
out of my
nostrils
because some
fantasy comes
up what hope
do I have
of understanding
AI or
understanding the
conflict in the
Middle East
without some
mind made
illusion or
fantasy coming
between me
and reality
and for the
last 24 years
I have this
daily exercise
of I devote
two hours
every day to
just what is
really happening
right now
I sit with
closed eyes
and just try
and focus
let go of
all the
mind made
stories
and feel
what is
happening to
the breath
what is
happening to
my body
the reality
of the present
moment
I also go
for a long
meditation retreat
usually every
year of between
30 days and
60 days of
meditation
because again
one of the
things you
realize there
is so much
noise in the
mind that
just to calm
it down to
the level that
you can really
start meditating
seriously it
takes three or
four days of
continuous
meditation
just so much
noise so
long retreats
they enable
to have this
really
deep observation
of reality
which is
impossible
most of
life we
spend like
detached
from reality
two hours
a day
that's a
commitment
even in the
midst of
all the
book promotion
craziness
before I came
here I usually
do one in the
morning one in
the afternoon
or evening
what a
beautiful thing
and obviously
your ability
to think
clearly and
write so
articulately
about these
ideas is
very much
a product
of this
practice
absolutely
I mean
without the
practice I
would not be
able to
write such
books and
I would not
be able to
deal with
the kind
of all the
publicity and
all the
interviews and
you know this
roller coaster
of positive and
negative feedback
from the world
all the time
I would say
one one
important thing
this is not
necessarily for
everybody
because I
meditate and I
have meditator
friends and so
forth I mean
different things
work for
different people
there are
many people
that I
wouldn't
recommend to
meditate two
hours a day
or to go for
a 10 days
meditation retreat
because they
are different
their body
their minds
are different
for them
perhaps going
on a 10 days
hike in the
mountains would
be better
for them
perhaps devoting
two hours a
day to music
to say playing
or to creating
or going to
psychotherapy
would have
better results
humans are
really different
in many ways
from one
another
there is no
one size
fits all
so if you
never try
meditation
absolutely
try it out
and give it
a real chance
it's not like
you go for
like a few
hours and it
doesn't work
okay give it
up like give
it a real
chance
but keep in
mind that
again different
minds are
different
so find out
what really
works for you
and whatever
it is
that's the
important part
whatever it
is invest
in it
I have to
release you
back to your
life but
maybe we can
end this
with just
a concise
thought about
what it is
that you want
people to take
away from
from this
book like
what is most
vital and
crucial for
people to
understand about
what you're
trying to
communicate
but information
isn't truth
truth is a
it's a costly
a rare
and precious
thing
it is the
foundation
of knowledge
and wisdom
and of
benign
beneficial
societies
you can
build terrible
societies without
the truth
but if you
want to
build a
good society
and you
want to
build a
good
personal
life
you must
have a
strong
basis
in the
truth
and it's
difficult
again because
most information
is not the
truth
and invest
in it
it's
worthwhile
to have
a practice
whatever it
is
that gets
you connected
with reality
that gets
you connected
with the
truth
thank you
for coming
here today
I really
appreciate you
taking the
time to
share your
wisdom and
experience
I think
Nexus your
latest book
is as I said
at the outset
a crucial
vital book
that everybody
should read
we're entering
into a very
interesting time
and we are
well advised
to be as
best prepared
as we possibly
can and
I appreciate
the work that
you do
and thank you
again
thank you
I only
graced the
surface of
the outline
that I
created
so hopefully
you can
come back
because I
got a million
more questions
I could have
talked to you
for hours
next time
I'm in
LA
I'll be
happy to
thanks man
appreciate it
cheers
peace
that's it
for today
thank you
for listening
I truly
hope you
enjoyed the
conversation
to learn
more about
today's
guest
including
links
and resources
related to
everything
discussed
today
visit the
episode page
at richroll.com
where you can
find the
entire podcast
archive
my books
finding ultra
voicing change
in the plant power
way as well as
the plant power
meal planner
at meals
dot richroll.com
if you'd like
to support the
podcast the
easiest and
most impactful
thing you can
do is to
subscribe to
the show on
apple podcasts
on spotify
and on youtube
and leave a
review and or
comment this show
just wouldn't be
possible without
the help of our
amazing sponsors
who keep this
podcast running
wild and free
to check out
all their amazing
offers head to
richroll.com
slash sponsors
and sharing
the show or
your favorite
episode with
friends or on
social media is
of course awesome
and very helpful
and finally for
podcast updates
special offers on
books the meal
planner and other
subjects please
subscribe to our
newsletter which you
can find on the
footer of any page
at richroll.com
today's show was
produced and
engineered by
jason camiolo
the video edition
of the podcast was
created by blake
curtis with assistance
by our creative
director dan drake
portraits by davy
greenberg graphic
and social media
assets courtesy of
daniel solis and
thank you georgia
whaley for
copywriting and
website management
and of course our
theme music was
created by tyler
pyatt trapper pyatt
and harry mathis
appreciate the love
love the support
see you back here
soon peace
plants
namaste
namaste
you
you
you
you
you
You
