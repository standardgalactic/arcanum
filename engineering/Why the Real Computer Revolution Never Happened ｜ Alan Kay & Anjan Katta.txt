What we don't need is something that mimics fallible human beings magnified by the Industrial Revolution.
It's bad enough having fallible human beings putting out garbage and having the internet multiplying it.
Is it better to have a thousand times more fallible human beings if they're in the top 20% of intelligence?
I think the operative word is wisdom, not intelligence.
The first aspect of computing, where I approach it, is how do you help access the front of your brain, your prefrontal cortex, the higher version of yourself, versus falling into the lizard brain aspect of yourself?
We now have a second shot to start from scratch again with computing and build it up now with all the lessons we have and the wisdom.
Hey, I'm Mario, and this is the Generalist Podcast.
The future is already here, it's just not evenly distributed.
Each week, I sit down with the visionaries and builders who are living in that future to help you understand what's coming next and how you might prepare for it.
Today's episode is truly special.
A conversation with Alan Kay, the legendary computer scientist and polymath, and Anjan Kata, founder of Daylight Computer.
It's not an exaggeration to say that Alan helped invent the modern world.
At Xerox PARC in the 1970s, he and his team created the foundations of personal computing as we know it, the graphical user interface, object-oriented programming, and the conceptual framework for laptops and tablets.
Despite those achievements, Alan believes that the real computer revolution never actually happened.
Instead, what we got were commercialized inventions that missed the deeper vision entirely.
Anjan represents a new generation that's trying to course-correct.
His company, Daylight, has created what's arguably the most thoughtful computing device in quite some time.
It's a PC designed for reading, writing, and thinking, rather than consumption and distraction.
To do that, Anjan had to rethink computing from the ground up, spending years building novel hardware to ensure Daylight had the right foundations.
It is, in many ways, a return to computing's original, humanistic principles.
We recorded this on a sweltering summer day in Alan's London home, and the conversation ranges across centuries and disciplines.
We talk about Paleolithic caves, Marshall McLuhan's media theories, and modern AI.
It's part history lesson, part technology critique, and part philosophical meditation on what it means to be a human in an age of increasingly powerful machines.
To learn from one of the great polymaths of our era, alongside a supremely original founder, was a genuine privilege.
It sent me down a dozen rabbit holes and reframed how I think about humanity's relationship with computers.
This is a new podcast, so if you enjoy conversations like this, I'd love to have you subscribe and join the journey.
Now, here's my conversation with Alan Kay and Anjan Kata.
This episode is brought to you by Augment Code.
You're a professional software engineer.
Vibes won't cut it.
Augment Code is the only AI assistant built for real engineering teams.
It ingests your entire repo, millions of lines, tens of thousands of files, so every suggestion lands in context and keeps you in flub.
With Augment's new remote agent, queue up parallel tasks like bug fixes, features, and refactors, close your laptop, and return to ready-for-review pull requests.
Where other tools stall, Augment Code sprints.
Unlike Vibe Coding Tools, Augment Code never trains on or sells your code, so your team's intellectual property stays yours.
And you don't have to switch tooling.
Keep using VS Code, JetBrains, Android Studio, or even Vim.
Don't hire an AI for vibes.
Get the agent that knows you and your code base best.
Start your 14-day free trial at AugmentCode.com slash generalist.
This episode is brought to you by Brex.
Fred Adler, the influential venture capitalist of the 1970s, was known for displaying decorative pillows in his office that featured a signature business philosophy.
Corporate happiness is positive cash flow.
In today's post-SERP environment, Adler's wisdom feels particularly relevant, as founders need to make every dollar work harder.
That's exactly what Brex delivers.
Their modern finance platform was built specifically for startups like yours, and designed to help extend your runway when capital efficiency matters most.
With Brex, you get global corporate cards with up to 20x higher credit limits and no personal guarantee required.
Their banking solution has no minimums and no transaction fees, while letting you earn high yield from day one with same-day liquidity.
Best of all, Brex knows you were born to build, not juggle spreadsheets and finance tools.
Their AI-powered platform brings cards, banking, expense management, and travel all in one place.
It's simple, scalable, and designed to get you back to what you do best—building.
More than 30,000 companies, including one in three U.S. venture-backed startups, trust Brex to help make every dollar count toward their mission.
Join them at brex.com slash mario.
Alan, I was watching your lecture to OOPSLA in 1997, which has been titled—
Oh my goodness.
The computer revolution hasn't happened yet.
And so—
Yes, I've used that title a few—
A few times.
And I think Dan Ingalls, for that one, he said, Alan, go out and rattle their cage.
I think he did it.
28 years later, would you say the computer revolution has officially happened yet?
Well, a revolution has happened, but not the one we really wanted or needed.
There's no question.
And of course, that was the point back then also, because that was at the end of almost two decades
of commercialization of inventions of the earlier research groups that were interested in personal computing.
And so what we got commercially was different, and what we got socially 28 years after that lecture
is extremely different and mostly unfortunate.
When you sort of think about the aspects of the revolution that haven't happened yet that
you would have hoped to have happened, what does that look like exactly?
Many of us in the 60s who were working on these ideas were readers of McLuhan, Marshall McLuhan.
And so we were well aware that something large always happens when you make new media.
For one, it tends to absorb previous media in various ways.
For another, it changes what normal means to most people.
It can produce different psychological effects.
So one of the things that McLuhan predicted just from television, not from thinking about
computers and networks, was that the world would suddenly feel both small and large at the
same time.
He called it a global village.
He did not really want a global village, but he felt that the intimacy, the feeling of contact
over large areas was going to be a very large effect of what he called the electric world.
And so he made several predictions.
One of them, he said, most people will feel that they've lost their identity because they're
now in a small town, but nobody cares about them.
Yeah.
They have no true connection.
And they feel like they should.
And so one of his predictions was many people will spend the rest of their lives fighting,
sometimes violently, for their identity.
So there's an interesting one to think about.
And he made many other, like he predicted for television, that the content of television,
the shot length would come to resemble that of the television commercial.
Hmm.
Just shortening.
Yes.
Everything.
Because he said the actual thing that fits TV the best is the commercial.
Gosh, that was very prescient.
And no, he pointed out that the paintings by the great masters in the churches in Italy
were also commercials.
Commercials are always paid for by the people who have the most money.
They're meant to glorify what their beliefs are and so forth.
So he could see these things, which should be obvious to most people, but they are not.
Most people tend to take what's around them specifically rather than seeing it fit into
some period of history.
But McLuhan was a literary critic, actually.
And so he could see many of these.
Movements.
He could see these things.
Yeah.
Yeah.
And so he made some very prescient observations and predictions.
And many of us in the 60s were well aware of it.
When I look back, I spent a fair amount of time trying to deal, explain to the educational
establishments what was likely to happen.
Nicholas Negoponte and I spent a fair amount of time going around to publishers, explaining
what was going to happen to their businesses and stuff.
But in fact, looking back, if I had time to allocate back then, I would have allocated
at least a factor of 10 more time dealing with education.
Wow.
Interesting.
Because what we got was the most naive, most dangerous set of reactions in the public general
approach to things and what the public thinks of as normal and so forth, far beyond the dangers
that we thought we saw back then.
Anjan, I want to bring you in here because clearly you do what you do because you think
in some capacity the revolution hasn't happened yet.
Which parts of, particularly some of the educational aspects that Alan mentions, did you sort of
sense were clearly missing or clearly misaligned when you started to build?
I think what's interesting here is obviously my attraction to engaging deeply with Alan and his
work and a lot of this sort of visionary early computing work is this sort of, oh my God, that's
what it could be.
And that's definitely been a lot of the wind in my sails.
But actually I would say it's more of a bottom-up thing that sort of got me into like, computing
isn't actually what it should be and it could be.
And the bottom-up was just my personal experience, which is I've increasingly more RAM in my computer,
more powerful CPUs.
I have better and better software.
And I was just like not more productive, nor feeling better, nor remembering the things
I was reading.
I was just so often distracted or I'd be staying up way too late and I just feel not great using
a computer.
Yeah.
And so for me, I was like, what are they doing in these Apple commercials when they paint
all these glorious features?
And then what I actually see is this sort of, this caveman, Neanderthal, lizard brain behavior.
It doesn't, the possibility that this should be versus my actual experience of it is so
different.
So let me break in there for a second, because I just want all of us and our audience to be
aware that what we're doing right now could have been done in a Paleolithic cave 100,000
years ago.
We're sitting around having a conversation and it's being recorded by both audio and video.
Right.
And so the only technology that's actually involved here is one that is delaying
the account of it later on.
Yes, that's right.
And actually we're talking about technologies that could not have been invented without the
invention of writing.
And yet we are not writing about it because we do not assume the people who would need to
read the writing are going to read it.
We're making it into pictures and stuff because we're assuming the people who need to understand
what we're talking about are not basically readers and writers, but in fact, still oral
society types.
Right.
So that is something to really think about.
I bring it up in almost every talk I do.
I show a slide showing an old campfire and saying, hey, why are we having this conference?
Why aren't you reading something?
Because reading actually conveys much more of the kinds of detail that have to be comprehended
in order to understand where we are.
But we're having a conversation.
I'm not complaining here.
No, no.
It's a good point.
I honestly hadn't thought of that.
Yeah, people don't.
Yeah.
Even as a writer, I don't necessarily think of that.
Which...
Well, just for a second, if you know, for instance, in Plato's dialogue, The Phaedrus, he has his
mouthpiece, Socrates, complain bitterly about writing.
And you may know this, that Socrates complained, oh, writing is robbing us of the ability to
memorize.
Ah, wow.
Because we now have a prosthetic for memory.
And when somebody writes something, they can go off and die.
And we can't chase them down and talk them out of it.
There's a whole bunch of things there.
And however, the nice thing about being here in the UK is we're in a land that understands
irony.
And both Socrates and Plato were noted ironists.
So that was a winking...
Well, I think it was.
Yeah.
So, and what was he winking at?
Well, he was winking the way Shakespeare did when he had Puck say on the stage of the Globe
Theatre, what fools these mortals be, to an audience that not only were fools, wanted to
be fools, but paid to be fools.
That's irony.
And if, you know, if we don't give Shakespeare credit for that...
So what was Plato actually saying?
Well, the first one is, hey, the only reason you know about this is I wrote it down.
And by the way, I wrote it the way I wanted to.
We don't know whether Socrates actually said that or not.
So what point was I probably trying to make?
And I think the point was, no, the right thing to think about writing is because we have writing,
we have 10,000 more things that are worthwhile remembering.
The writing doesn't take away from our memory at all.
That's up to us.
That's like getting fat after the car was invented.
That's up to us.
And writing gives us this incredible benefit of allowing us to expand beyond our village culture.
And so memorization is much more important because it's too inefficient to have a zillion
books around and try to run from one to another.
You need it between your ears.
And so memorization is incredibly important now, much more important than it was in an
oral society where you only had to memorize a few thousand things.
So I think that's what Plato was actually saying there.
And I think we can apply some of those approaches to thinking about what we're talking about today.
Sorry to break in, but that was a perfect lead-in.
I think that captures a key part of this.
I forget who it was too, but they're like, you could have the most beautiful colonnade that you're in discussing, reading something.
But if there's a gnat beside your ear buzzing the entire time, good luck trying to remember that.
And so in so much as what we're talking about here is the positive capability, the computing revolution has never truly manifested.
I think also what I feel is we've got to also remove the negative strains, the gnat in your ear that comes in the way of even accessing the current capability, leave alone the positive capability that's here.
That's a very, that's a very good point.
And by the way, we have about a thousand gnats inside of our brain.
So getting the one in our ear out is relatively easy compared to the ones that our genetics give us.
That's something I think we have to, have to think about.
And when McLuhan was thinking about not just writing, but especially what printing did, one of the, one of the questions is why is writing associated with city building, which is the root of what the word civilization means.
It means people living in cities, and why is writing associated with up-level thoughts, and why did the printing press have such a large effect?
Because the Renaissance was already started by the time the printing press was revealed.
So it didn't start the Renaissance, but it looked, when you look at it from afar, there's a really great,
set of books by Elizabeth Eisenstein called The Printing Press as an Agent of Change.
So she looks at it as an incredible amplifier that happened to come along just, you know, about 40 or 50 years after thought had started shifting around.
Interesting.
What Kenneth Clark called the Great Thaw.
And along comes this first manifestation of the Industrial Revolution.
And I call it that because the Industrial Revolution is making a lot of things cheaply and being able to distribute them widely.
So the first things that were made that way were quickly made type, made from punches that Gutenberg and, he didn't invent printing.
Yes, you made this point in one of these lectures that I thought was so interesting, which was like most of the technology was already there in China.
China had the problem of, same problems the Middle Ages had when the printing in the Middle Ages was done by basically woodcuts.
The movable type that the Chinese had, had to be laboriously carved in order to be used.
Whereas Gutenberg was a gold.
Goldsmith.
Goldsmith.
And when you make a gold coin, you don't pour it.
You don't pour molten gold into a mold.
You just put a gold blank and you hit it with hard steel carved into what the coin is supposed to look like.
And the soft metal will flow from being struck.
And Gutenberg realized, oh, I could make the letter H into a punch.
And I could punch the letter H from my steel die.
I could punch it into brass.
Bing, bing, bing, bing, bing.
I can make a whole bunch of letter H sockets.
I can pour lead in there.
And all of a sudden, I've got a zillion letter H's.
And then suddenly everyone else can start printing books.
And so there are 20,000 presses in Europe by the time Aldus got going at the end of the century.
So it's 40 or so years later, there are 20,000 presses.
Aldo Minutio.
Is that right?
Yes.
Aldo Minutio.
His Latin, sometimes he's called Aldus Minutius in his Latin form.
But yeah.
And, you know, I've told the story of why books are the size they are because Aldus went out and measured saddlebags.
He wanted to know, just as Anjan wanted to know, you know, how big should a daylight be?
And, you know, can you carry it out on a picnic?
That was part of the fun introduction of the product.
But I think these things are critical to think about.
But one of the most difficult things for most people today to think about what computing might be about is what can you do that's importantly different about it?
Because for literally billions of people in the world, they only experience computing as a bunch of conveniences, essentially imitations of media that were invented before computers.
Made somehow convenient in one way or another access, being able to carry them around and so and so forth.
And they almost never get to touch any of the things that the computer might be good for.
I mean, one thing that apparently Aldus and the scholar Erasmus, who are friends, had as an idea in the early 1500s, so it's about 70 some odd years after the printing press, they decided to put page numbers in books.
And page numbers previously were only in books done by a marginalized society, which were the Jewish culture in Europe.
Why was that?
Well, because if you look at an edition of the Talmud, it looks like a hypertext document.
There's the main body of it.
Yes.
There are commentaries everywhere.
Overlapping windows.
Yeah.
And so numbering pages actually makes sense.
Yes.
When you're actually in a larger discussion or argument.
And I think the page numbers in books, because books were sequenced by printing the next two words on the next page at the bottom of the previous page.
So the people who are putting the books.
And this practice was carried on for a couple of hundred years.
Wow.
I had no idea.
I have some books from the 18th century, so several hundred years later, that still do that, because that was the way.
It's like QWERTY.
You know, people got used to a certain way of doing it.
And the numbers in the books were for this invention after the Talmud of Erasmus and Aldus of referring to things.
And it wasn't to refer to things in other books, because a typical press run in a town in Europe is several thousand volumes.
And the pagination was going to be different.
We couldn't refer to where did Plato say blah, blah, blah about writing and Phaedrus.
Because what edition?
It's all over the place.
But what they did was they realized, oh, wait a minute.
Something printed is going to spread around and it allows us to set up longer arguments than any oral culture can do.
And because of the printing press volume, it's going to have much more significance than manuscripts.
There are too few manuscripts around to have much effect, but this is going to balloon.
And so they realized the argument was going to change.
And we don't see that until the 17th century.
So now a couple hundred years after the printing press itself, we start seeing people arguing about politics, how governance.
We see the Royal Society being started here in England, and science involves argument.
And so both of these argumentative forms were able to be carried to a much greater depth because of the printing press.
Or so goes the story.
I mean, that's something that attracted us in the 60s.
Yeah, you know, for those folks, I imagine as they listen, like we really are actually talking about computing, even though we're talking about the printing press and in all of these different ways.
Something you said reminded me of the McLuhan quote, which you've talked about, which is, you know, I don't know who discovered water, but it wasn't a fish.
And when we think about computing and finding these alternative paths, it made me wonder, you know, Anjan, when you looked back at sort of some of the history of the industry, I know that it came more bottom up for you.
Where did you sort of see some of the opportunity to take one of those like more orthogonal tracks to do something that wasn't just, I don't know, faster, more RAM?
And how did you start to conceive of that?
I think the big sort of wow moment from all of this was, I think I read McLuhan, but I compartmentalized it and didn't really appreciate it and apply it to computers.
It's like Alan's work and so on.
The wow moment was like, whoa, this is a magical medium.
This is a meta medium.
And I think because of the way we use it, and because I grew up with this, you think a computer is a way to message, a way to email, a way to do your homework, a way to find your calendar, blah, blah, blah.
And you sort of see the caricature version of the authoring and magical medium, which is the Apple commercial where they show you using Final Cut Pro or GarageBand to make music, but it's actually totally inaccessible for most of us.
And so at least the way I relate to all of this is what a magical medium is, what a meta medium is, is magic.
It's actually an intelligent, interactive, dynamic way that you could be a better version of yourself.
And so at least for me, I've always looked at this in terms of, Alan always talks about Jerry Bruner and a man, a course of study, this curriculum on understanding the human.
I think that's the core of this for me is like, where did we come from?
How did we become the way we are?
Who are we today?
What's the world?
And where are we going?
And you actually can't appreciate that if you don't see the difference between an animal and a human and how we sort of created propositional ways of thinking.
And then from oral cultures to writing cultures and all the different knowledge media along the way.
And, you know, it's like history is the history of kings and wars and winners.
The true history is this history of these sort of ideas and technologies, whether it be the axle, the printing press or the codex.
And so if you sort of, in that lineage, take computers as this beautiful evolution of everything that came before, to me, the key application of that evolution is we can access more of human potential.
And at least for me, that's the real juice of this all is the way we are is a subset of really what we could be.
And I think the three ways that shows up is one is I think often because of our difference between how we were evolved in the environment we're in, we're sort of dominated by genetic predispositions, the lizard brain.
And so the first aspect of computing, at least where I approach it, is sort of how do you help access the front of your brain, your prefrontal cortex, the higher version of yourself versus falling into the lizard brain aspect of yourself.
I think the second aspect of computing is how do you go from the reduced version of yourself that's sort of determined by society, the way you're socialized, by the culture of the time, by our environment, to actually a holistic individual, all of our capacities and ways of being.
And I think the third is sort of, you know, the top of Maslow's hierarchy is sort of what does it mean to fully actualize your special capability?
So not be your lizard brain, be the best version of you as a human and be the best version of you as an individual.
And at least for me, the power of a medium is it can work with you to help accomplish each of these three sort of expansions of your being.
Alan, when you were at Xerox PARC and you were, you know, you know, devising the idea of the DynaBook, was the concept that these could be, you know, computers could be so opiating, addictive to the lizard brain part of us?
Like even something that crossed your mind, was that like a path that seemed open?
What Anjan just said was is quite important and, you know, it's worth it's worth looking at it.
So one of the things we're aware of in the mid-60s was the idea of personal computing, which occurred before there were personal computers.
So you could do personal computing on a suitably set up terminal to a time-sharing system.
Yeah.
And so the early conceptions of it were more of, not unlike what we have today.
Today we have a cloud and we rely on the cloud.
And the early notions of it came from the analogy to power, water, gas, utilities.
This is something not just for single people.
So it's not a person in a castle, but it's basically something that is delivered one way or another.
And so when John McCarthy saw an air defense graphics terminal in the 50s, which is designed for tracking Russian bombers, his first thought was every home will have one of these.
So he's a good person to start with thinking on this, because he instantly could see, and so could the research community, could see that the networking part of this air, what became air traffic control, but back then was tracking Russian bombers.
Each of these complexes could run about 150 graphics terminals, and there were 24 of them.
They were connected by telephone lines.
And so in the 50s, you had the first glimpse of what could be thought of as personal computing for the general public.
Yeah.
And so that gave rise to a set of ideals that, well, we should try and invent that.
So the original name of the internet before it was invented was called the intergalactic network.
And they asked the guy who made up the term, why did you call it that?
And he said, well, engineers always give us the minimum.
He said, I want a worldwide network, so I'm asking for an intergalactic one.
That's amazing.
Yeah.
And if you think about it, many people, especially funders, tend to be rather conservative.
And so if you can get away with hyperbole, then pretty much everybody is served.
So one of the interesting things that happened in the mid-60s was the official first article by Gordon Moore
about what is called Moore's Law.
And the first prediction was things that would improve a factor of two every year, which is really exponential.
More careful work was done.
And I guess a couple of years later, he said, well, it's not going to be worse than a factor of two every two years.
And the reality was about a factor of 1.5 or so, a factor of two every year and a half.
So that gave us this, not just the exponential curve, but it also gave people who were thinking about the future something to hang their hat on.
Now, the problem with this prediction was it wasn't just a physical prediction.
It required stages of engineering to do.
And engineering is very obstinately connected with the real world.
So there had to be faith, there had to be funding, there had to be changes in technique.
But those of us who are thinking about future computing relied on it.
So just, you know, let's just make it an article of faith.
But the other thought was when you ran it out, because his prediction was only 30 years, his prediction was basically to 1995.
And my fervent hope is that Moore's Law would not extend much beyond 1995.
Is that right?
And do you know why?
Why?
Because if you go give it a couple of more notches, you can actually simulate television.
Hmm.
Wow.
And television is actually not good the way it's used in America and now the UK.
Yeah.
And I remember way back explaining to my friends in the UK, do not let commercial television come in here.
And they say, no, it's okay.
We're, you know, we're much more sophisticated than you Americans.
It's not going to affect us.
The other thing that McLuhan didn't actually realize, but he sensed, is that they said, you know, Marshall, why don't you use psychological terms?
Why do you make up all of these things?
And of course, he was a literary critic.
He didn't, he wasn't a scientist or anything.
Yes.
Yeah.
But his rejoinder was really good.
He said, well, it's like in the 50s, he says, well, psychologists are studying white rats.
He say, I look to see what advertising people are doing.
They are the ones who are studying human beings.
Wow.
Okay.
So that is a really, that's a beautiful.
Brilliant line.
Yeah.
Yes.
And he wrote one of his books was called The Medium is the Massage.
Yes.
Right.
Not the message, but the massage.
He loved puns.
Yeah.
There, and he wrote another book called Mechanical Bride.
He was trying to wake people up.
He realized he couldn't, he couldn't tell them just as you could not tell an Archie Bunker fan that this is satire.
Yes.
Because you're talking to somebody who actually doesn't understand satire.
So the thing about reality TV is what Archie Bunker did is allowed him to use racial slurs.
As coming from an ignorant guy who shouldn't be like what an American should be like.
Right.
But in fact, what happened is as you move into reality television, you actually wind in, wind up with people who are making money at it, realize, oh, people love bad behavior.
Yeah.
Interesting.
Let's see what we can get away with.
So once you get that and you combine it with the fact that television is everywhere and is on most of the time, you have actually changed the environment that people are living in.
And when you change the environment that people are living in, they start accommodating to it.
It's like going to Venice or going to Paris.
After you've been there for a month, you will be acting much more French than you ever thought you would.
Even if you don't want to.
Yes.
Because it's a rhythm.
It's something that's built into our genetics.
It's something that makes us want to accommodate to whatever culture is around.
And if you can change the culture through some medium like television, then you have to be worried about it.
So for computing, it's the ultimate double-edged sword.
Like the printing press could print Mein Kampf.
It could print books for and against evil.
Yes.
But because of what we're talking about, because what we're doing here is something oral and visual, we're doing something that is much more human.
And then McLuhan points out one of the best things about reading is how alienating it is.
Basically, when you got rid of illuminating books and went to exact same type, that its greatest power happened.
Because people now start to be able to read for the first time internally and much faster and more efficiently than sounding out the letters as they did before.
How interesting.
Yeah.
So that's a big deal.
And so, you know, we could spend the whole time just talking about McLuhan.
But, you know, I think Anjan understood more of McLuhan when he first read him than I did.
I couldn't deal with him.
But I had a professor in college that I wanted to talk to, and he's like graduate students.
And so drinking beer with some of my fellow graduate students, how can I have a conversation with this?
Because he was a genius.
Was this Bob Barton?
This is Bob Barton.
I want to just, for those who haven't heard of him, I love the way you talk about him as this teacher who didn't necessarily, you know, you talk about how he was such an amazing teacher because he removed knowledge from you.
Yes, he killed it.
Yeah.
And allowed you to think freely.
Yes.
Which I think is such a gift.
But anyway, you were saying you used to drink with Bob Barton.
Well, I wanted to have a conversation with him, and he had gotten dragooned there by his friend who was the head of the department and really didn't like being a professor.
Yeah, he was a grumpy old guy.
But somebody said, well, you know, Barton likes to read, and so do you, and he likes McLuhan.
He always talks about McLuhan.
I said, oh, no.
I tried to read McLuhan last year, and I couldn't understand him.
And so the summer of 67, I spent most of that summer determined to actually understand McLuhan.
So I read all of his books and did little else that summer, but tried to get to the bottom of what the heck was this guy about.
And when I finally got through the barriers, and it was actually by Gutenberg Galaxy book was the one that helped me the most.
I realized, oh, this guy's insights are right up there with Shannon's and Einstein's.
They're like the most important insights of the 20th century, and, you know, we're basically doomed unless we can understand them.
So they became a very important, not just the actual insights, but the, you know, McLuhan's approach.
How was he able to have them?
What detachment did he have from what seemed to be real and definable right in front of us that allowed him to see what was actually going on and so forth?
All of the, all of those things were tremendously helpful.
And, you know, as was this famous class with Bob Barton, where basically stomped into the room and he gave us a sheet of paper that had about, I don't know, 15 things on it.
He said, there's very little known about advanced system design, but what is, is written down in these, these books and papers.
And he said, I expect you to read them and understand them completely by the end of this course.
Then he said, but my job while we're in this class is to firmly disabuse you of any fond notions you might've brought into this classroom.
And so the class was finding out what we believed in relative to computing.
And this very articulate, and he was an enormous guy.
He's like six, four, very articulate, super brainy giant of a man demolished any belief we had.
Amazing.
Completely.
And I happen to know he demolished a few things he believed in.
And so if you know the process of garbage collection and software, what he did was to garbage collect our brains.
Yes, right.
So what he did was to remove this fallacy about knowledge.
And I was just talking to Anjayan about it.
And that, you know, knowledge is really processes rather than things.
Our English language is too noun heavy.
Yes.
You talk about this in the Japanese word ma.
Ma means what's in between.
And then there's this interesting question of once you learn a little science, you realize, oh, wait a minute.
Nothing is static.
Everything is some kind of system and everything is in process.
And so when they were trying to define computer science, what could those two words mean together in the early 60s?
One of the great men of our field said, well, computer science is the study of processes, every kind of process, including biological process.
You know, every kind of process in a system is the grist for the mill of computing.
Also, the 60s was a good time in the U.S. for getting loose of hard-nosed definitions.
And categories have a real problem in that once you put a label on something, you're more or less screwed because the label, a category is composed of the reasons why something is in the category.
So when you're trying to think about something, putting a name on it can really hurt because it will cut down the kind of thinking you're able to do about it.
Yes.
So you kind of have to encircle it.
But before you go deeper into that, I just want to click on something he was saying and go up a level.
Yeah, please.
Before I knew Alan's work well, like from sort of afar, call it Hacker News and Quora and so on in some of his talks, the two things I thought described him were as one computer scientist and number two was curmudgeon.
And I think the most fascinating thing from the time of getting to know him and learning from him is Alan is humanistic.
The actual key part, this is my interpretation, the actual key part is him bridging the humanities and a deep understanding of the human into the world of technology or computers.
And the second quality is one of being childlike.
I find you unbelievably childlike.
And it's interesting that we talk a lot about, and you have historically computers apply to kids, but I did not expect how deeply you went into psychology, how deeply you went into anthropology.
Well, I'm not a computer scientist.
We talked about this before.
You know, when somebody asked me, what is your identity?
Computer science doesn't.
Yeah, I'm curious.
Yeah.
About a lot of things.
And basically, when you're interested in a lot of things, one of the things I learned when I was a kid is if you don't go into them deeply enough, you're basically just dicking around.
This episode of The Generalist Podcast is brought to you by our very own Generalist Plus, the premium newsletter that's redefining how investors and builders navigate the technological frontier.
Generalist Plus delivers a mini MBA tiering box at just a teeny fraction of the cost, just $22 a month or $220 annually.
So what's included?
One, tactical interviews where elite founders and investors reveal their actual strategies and decision frameworks.
Two, comprehensive guides that distill hundreds of hours of research into actionable insights on investing and company building.
Three, an exclusive database of emerging startups poised for significant growth.
And finally, complete access to our archive of meticulously crafted case studies.
All of this comes wrapped in the distinctive storytelling and incisive analysis that readers have come to expect from The Generalist.
We've designed Generalist Plus to level up your capabilities as an investor and operator through knowledge that matters, delivered with precision and depth.
So join a community of strategic thinkers who are gaining an edge in understanding markets, technology, and business fundamentals by visiting thegeneralist.substack.com.
That's thegeneralist.substack.com.
I want to double click on the notion of computers and learning, though, and specifically in the context of artificial intelligence.
One of the things that, Anjan, you've talked about, I think, with Alan before, is this idea of, you know, computers can be this incredible amplifying learning instrument, but how much help is too much help?
Yes, I think that's the operative phrase.
And how do you think about that, especially with AI today being more than willing to just give you the answer if you want it to?
What are the, like, right ways to think about designing these systems?
To me, what we're doing right now is not actually a podcast.
I would call it a video shoot.
Yes.
The term AI today means almost nothing overlapping with what the original coining of the term meant.
When I grew up with the term AI in the 60s, it meant what today is called artificial general intelligence.
And so this changing the meaning of words for the cachet of a friend of mine, Rich Gold, called colonizing.
So what lazy people do, and in this case it was academics, they wanted to write papers about artificial intelligence, but it's hard.
And so they decided to write papers about a very limited subset and call it AI.
Okay.
This is similar to the revolution in teaching mathematics in the U.S. that came about after Sputnik.
So it's very, very difficult to do.
It didn't happen, but they achieved it by renaming arithmetic mathematics.
Right?
So this is like putting Harvard on your dungareets.
It's a brand of genes.
You know, it's called designer genes.
Right?
So this has happened over and over and over again.
So when we say AI being an old fogey, I respond to it as McCarthy originally coined it.
So here's a story from back in the 60s.
So graduate students were used as the messenger particles between the 16 or 17 laboratories that ARPA ran around the country.
So we were always traveling.
And because they treated us like human beings, most places exposed their graduate students to what the grownups were doing,
like they would take us to Washington when they needed more money so we could see how you did that.
You know, realizing we weren't going to be grad students forever.
So in one case, I was at Technology Square in MIT and visiting Marvin Minsky and his grad students.
And it just happened that day that three generals from the Army were visiting.
So this big, huge general with stars and decorations and everything.
And I'd been in the Air Force, so I was somewhat amused.
About the whole thing.
But so the general said, you know, we came to find out about our robot soldiers and intelligent tanks.
They were making a system to do symbolic mathematics.
He finally said, well, in three or four years, we might be able to make a pretty good robot dog.
Wow.
And another general said, we don't even want ordinary human intelligence.
We can draft, we have two and a half million, this is doing the Vietnam War.
We have two and a half million soldiers we've drafted.
We can train them to do whatever we want.
We already have robots of normal human intelligence.
And the third general said, we need superhuman intelligence.
One of my first thoughts was, you know, have you ever thought about safety?
Yeah.
And the thing about doing, as anybody who's ever done a software system, eventually finds out one way or another, if you want that system to be safe, you have to start off with it being safe.
You cannot bolt on security from the outside in any pragmatic way.
When you let the genie out of the bottle, you have to let it into another bottle where you can get the genie to do some things for you.
So this is something that was completely understood by the culture that did the internet and personal computing, completely non-understood by the culture that did the web and what we have today.
So it's really two completely different cultures in as different a way as you could possibly come out and have both be able to write a few lines of code.
So that's something to think about.
Yeah.
So the interesting question here is what we don't need is something that mimics fallible human beings magnified by the Industrial Revolution.
That is exactly what we don't need.
It's bad enough having fallible human beings putting out garbage and having the internet multiplying it.
What we don't need is a generator that has the Industrial Revolution behind it putting out garbage.
Is it better to have, let's say, a thousand times more fallible human beings if they're in the top 20% of intelligence?
At what stage of intelligence compared to humans is it?
Well, I think the operative word is wisdom, not intelligence.
And so if you go back and you take Anjan's journey, and what's interesting about we humans is how clever we are and how unwise we are.
You know, what happened with us is, in part because we had language and in part because we had writing, we were able to co-opt the ability to do that, to lay on much stronger methods.
So these are sometimes called human non-universals.
Yes.
So something like mathematics or science is a perfect example of an invented set of schemes that nobody is born with.
But once you learn the things, you can put them on top of your language apparatus, and you can act much more widely and deeply than humans without it.
And if you put together a community of scientists, you also have the possibility of debugging what's wrong with our brains.
And all of a sudden, you have created exponential power.
Couple that to engineering.
And you don't manage to scale wisdom as quickly.
Well, wisdom is tricky, isn't it?
Yes.
Because it goes against almost every instinct our genetics endow us with.
Because, you know, our evolution created us in the midst of scarcity and danger and a whole bunch of other things that are normal triggered reactions.
Yeah.
And we have hundreds of cognitive biases.
We form neuroses almost at will.
And so if you lay all of these things down, their wisdom has a really hard time functioning.
Because it's a lot of wisdom is just not acting when you feel like it.
How do you think about making a personal computer, which is what daylight is in, you know, sort of the most fundamental sense, that is intelligent and wise?
Like, does that sort of distinction have to be thought of from your perspective as you start to engineer this, as you think about the operating system and how it works?
Because for me, the first lesson of wisdom is humility.
And I think the simplest application of that is less.
You can't govern a bigger area until you've learned to govern a small area.
You can't govern something hard until you can learn to govern something smaller and easier.
And so, at least when I think about the power of a computer, it's a lot easier to gain efficacy with something that is small.
And so the point of daylight is to not bite off all of computing, but to bite off a certain subsection of it.
Sort of writing, reading, note-taking, thinking, this sort of magical piece of paper aspect of being.
And then from there, slowly grow it outwards.
And in a similar sense, I think the reason of, you know, Alan always talks about everybody thinks the Dynabook was him talking about a form factor.
You know, inventing the tablet, inventing something that's the size of a notebook, but he always says it's the concepts behind it.
And, you know, the form may be a room that's got dynamic surfaces.
I think one advantage of making a piece of hardware, of making a separate computer, is you can have it separate from the rest of your existing, unwise computing ecosystem.
And one piece of wisdom is sort of Odysseus tying himself to the mast so he doesn't get pulled in by the sirens.
By having something that does less, that sort of is away from everything else, you don't need to constantly be making decisions about what to prioritize.
And when you have junk food and candy, the sort of dopamine that feeds and videos is, it's really hard to be this better version of yourself.
And so there is an emergent wisdom, I think, that comes from a thoughtful application of constraints.
And I think my job as a designer is to sort of think of thoughtful constraints that allows you to make wiser decisions.
And I think often wiser decisions in this context means the things you want to do that you know are nourishing and good for you, but you don't end up doing.
I always like Alan's definition of hard fun.
It ends up being as fun.
Seymour Papert.
Okay.
Yeah, that's right.
Yeah.
If I can call it fun, one of the fun things of having cancer and getting to 85 is, I think even without the cancer, what happens is your world starts shrinking, starts becoming smaller.
And the fun things for me is that I'm very much enjoying the smaller nutshell.
You know, Hamlet has this line, I could be confined in a nutshell and count myself king of infinite space.
And, you know, I thought of that when I, when I, a few years ago, when I was recovering from an operation, I was thinking, oh, yeah.
And it doesn't actually, he didn't say how big the nutshell was, you know, it could be even a smaller nutshell.
But, you know, Anjan and I have talked about like an interesting thing to do with the, the daylight is like, if you just take one really important thing, that's a large job, but it's smaller than trying to do every important thing.
So, like one important thing might be to take what the human factors are on it and say, oh, this is, it's really interesting to think of, could there be something like better than a moleskin notebook for ideating?
Mm-hmm. I mean, I think it's already, I think Tyler Cowen said this, that this is the, arguably the best general reading and writing device that's ever been created.
And I think it's.
Yeah, well, the question is, what could it, so it's, it's fabulous at any number of things.
Yeah.
The interesting question goes back to this, how much help is too much help?
For instance, one of the things we did at Xerox PARC early on, I did a fair amount of it, was to say, let's not give people something useful and that they'll want to use, but take something away when we do it.
And that was a reference to how bad the typography was on CRTs back then.
You couldn't really read a CRT and because one of the scientists at Xerox PARC invented the laser printer right then, we were very interested in what, what would it mean not just to be able to print out like a book, but also to be able to compose, to write as though we're writing a book.
And so then the question is, uh, you know, how readable are these displays anyway, and would doing a careful job on the fonts make a big difference?
And the answer is yes.
Yes.
And.
Which was a big part of DynaBook.
Well, but then we, uh, the, if you look at the early, uh, stuff that was written, one of the first fonts I wound up doing was a handwriting font.
Because once you do the good fonts, it makes tentative thoughts look too official and is now a bot because you need noise to think.
So the question is, if this is a dynamic medium for creative thought, you have to ask questions like not just what is it as a retainer of stuff, but what should the actual markings be like?
And that gets, gets you into this larger thing of user interfaces, like how crisp is the user interface, how machine-like should they, how organic?
Yes.
So, so, uh, many of the commercial companies went through a phase where they wanted their user interfaces to look as, as it was called Chrome at Disney.
They wanted to really impress you with, you know, the 3D-ness of the boundaries of the windows and everything.
Now we're in a thing where the, that is de-emphasized and we're into unsaturated, uh, colors and something like that.
But I, I think the whole thing needs to be rethought.
You mentioned in, in preparation for this, how you and Anjan have talked about, you know, hardware is maybe 5% of it and the operating system is, is 95% of it.
Like how, how, like, what do those discussions look like as you guys talk through this and, uh, and those sort of considerations?
Well, it took me, uh, six years to do the hardware and therefore people then define this project similar to how the form factor of the Dynavo people think is a tablet.
They define this as a hardware project, but I sort of think if the goal here is to have a vector to bring this more humanistic perspective of personal commute, uh, computing to come to fruition, literally like fruit.
The six years was to sort of remove the rubble and the rocks and the weeds until the soil and the ground was compacted and hard.
And I sort of think of hardware as that it is the actual underlying substrate.
And the reason we're sitting here is because of his idealism, not, I mean, the hardware is nice, but his idealism means there's a pathway.
Yes.
It's not a place.
I totally agree.
That's the, that's the, that's the key thing on this.
And I think we don't, you know, he's one of the few who have done something with a screen that you can write on and cared about what's called tooth or teeth.
It's one of the attractions of the moles, particular moleskin that I use.
And by that, you mean the amount of, just the way the, if the drag is just right for you.
Um, makes a huge difference as to like, one of the things we found out when we were experimenting with, uh, the park version of the GUI was that the feeling of intimacy did not come from the fact that you were manipulate.
You had a stylus or a, or a mouse and clicking on things, but feeling of intimacy came from being able to drag things.
Hmm.
Because it was more tactile somehow.
Well, uh, one of, you know, one of the things we did at Apple that never got out as a product is we did several kinds of mice that gave tactile feedback.
Uh, one of them, I think they could, they should have put out, which, you know, so when you dragged a folder, you could feel its mass.
Oh, interesting.
Wow.
So you had, so, uh, so I think one of the things that's been sort of in the deck, especially for children is, uh, the haptics.
Um, like if you look at children playing games, most, most user interfaces of the past and in the games world are two handed.
Um, whereas the, uh, if you look at the iPhone, the only two handed use of the iPhone is typing with your thumbs, which is completely retro, right?
Because it's aimed at an audience that doesn't want to learn anything and it satisfies marketing people who do not want to have learning as being part of what their product is.
And so this is a big drag on what, on John and this notion of, uh, a real computer revolution.
So the, the irony of it though, is, uh, you know, when we were at park, we used to say to each other, thank goodness we're doing, we're doing this.
We're going to, we will remove the 200 years of bumbling between the printing press and, uh, the 17th century because we're going to do it right.
Get it right.
The first, we're going to, well, we're going to work on it in the future.
We're not going to work on it in the present.
We're going to build time machines.
We're going to spend money to compute it, do our computing physically in the seventies, but to have it on machines of the kind that will be sold in the late eighties.
So as a, so we had to spend about 25, you know, in today's terms, well over a hundred thousand bucks for each machine.
Cause it was essentially giving people, individuals in the seventies, seventies, a supercomputer that 15 years later would be affordable, right?
So the whole flow there was software is difficult user interfaces, even more difficult.
And if we try and do any of this work on current day, hardware will be screwed.
We have to make the hardware of the future and just pay for it to do it.
And, but the irony is great because, uh, whoops, we thought we were going to get rid of those 200 years, but guess what?
We got 200 more, it, it could take that.
You think so?
Wow.
Well, it, I don't think so.
Oh yeah.
Yeah.
Let's hope not.
Yeah.
Because the, so I would say, I don't think so either because none of the intellectual revolutions hoped for in the sixties have taken place.
We've got, uh, not just pandemics, but we have the climate problem, which has been known about for since, uh, publicly since 1963.
So we're talking, uh, 60 some odd years, but nobody's taking it seriously yet.
Um, and the problem is we've gotten in 1990, we crossed where we should have kept it level.
Hmm.
The threshold.
Yeah.
Would you say that's sort of the name of the game?
Like us as a collective effort, we're sort of having seen what has actually happened versus our ideals.
We now have a second shot to sort of start from scratch again with computing and build it up now with all the lessons we have and the wisdom.
Is that, is that fair to say that's really the game we're playing?
Um, no, it's an interesting question.
Cause even the first computers, right?
They talk about the friendly orange glow.
Uh, and this is a friendly orange glowing thing.
That's monochromatic.
It's sort of where it started.
So when, one of the props I use when I give a talk, actually up there, I, I have my globes.
But I usually carry, carry a bottle like that in after an empty one.
And I point out, if you have it the way it is on a table and you poke it a little bit, it will rock back and forth, but everything is all right.
If you turn it upside down and poke it a little bit, it will fall over.
So a small amount of energy, put it into a state where an enormous amount of energy comparatively is going to be recorded.
So one of the great difficulties is that the voting public, its normal way of looking at things is through common sense and local situations, which is something that goes all the way back to paleolithic times.
The idea of systems, of scaling, of great power and all of that stuff is not in most people's common sense.
Yes.
It's hard for us to reason across a civilization.
Yeah.
Like Brexit didn't take into account the actual situation.
It was mainly a protest.
Hmm.
Yes.
Take back control is what the buses said.
We were here when that was going on.
And we see similar sentiments in the U.S. about people feeling out of control but not understanding the system they're in, as indeed the government itself did not understand the system it was entwined in.
And so to loop it back to the computing and the idea of this bottle being on the table where you give it a little bit of force versus a lot of force to tip it over depending on how it's positioned, is the idea there that for us to avoid this being another 200 years, it's going to take a lot of force?
I agree with Anjan, it's not going to be 200 years because the disasters that are possible are much more short term now.
So it's more urgent than ever that we figure it out.
Yes, it's beyond urgent.
Yes.
But neither the Gardner nor the Telegraph, for example, have a banner about the climate every day.
Like that is the big news.
And the problem is this acclimation.
People have renormalized.
And at some point, as the bottle goes over, people will say, well, why weren't we informed about this?
Yes, yes.
And the whole point of science is to be able to reliably imagine what's going to happen before having to experience it.
Right?
That's what's being missed here.
And one of the ideals in the 60s about what personal computing was about was to not just have something to do with education, but to have something to do with the new thinking that scaling and the Industrial Revolution and so forth have brought to the human dilemma.
Yeah.
Right?
That's the key.
So right now we're in a situation where certainly in the U.S., the attempts to even get school, like the attempts to even teach reading are failing.
So what we have is a systemic problem of getting back to a normal that was desirable 100 years ago.
Now we're in a situation where we have to deal with some new normal that most people can't even understand is happening.
So I think the, and I think people will, you know, to get back to your AI, quote, AI thing, once you devalue a trusted source of knowledge so that, and I think that's, we're close to that.
That's what the use of the Internet has actually done now, we're basically in a situation where something like a new religion, you know, because people are going to start relying on how they feel, which is actually a good thing to pay attention to.
But in fact, it doesn't flow into dealing with the, how to deal with complex systems.
Einstein pointed out that the kind of thinking we use to get into trouble is not going to be able to get us out of it.
We need a different kind of thinking.
That's a, that's a big thought there.
So even trying to get back to zero is actually a disaster.
Yeah.
Well, so many threads that I, I want to follow.
But in the interest of time, we always like to end the podcast with one of my favorite questions to collect reading recommendations.
And maybe I'll start with you, Anjan.
If you were given the opportunity to assign a book for everyone on earth to read and understand, what book would you choose?
It would be this book by Kent Stanley called Why Greatness Cannot Be Planned.
And, um, if it was for everybody in the world, I'd probably want to make a graphic novel version of it.
So it'd be more accessible to, well, you don't have to worry about that because everyone understands it, but that's implied in the question.
Um, but, uh, really what the book speaks to is so much of the way we live our lives today is very top down and convergent.
We want to be on the cover of Forbes.
We want to be a billionaire.
We want to do this.
And so what we do is we pick objectives and we try to reverse engineer our lives towards it.
And the great beauty of his book is he sort of speaks to actually, when we're trying to do something that is fundamentally creative or innovative, venturing into new possibility space, the best algorithm to do so is not this sort of reverse engineering optimization algorithm, working backwards from an objective.
But actually sort of bottom up algorithms, what he calls open-endedness or which are, you know, sort of old uncle wisdom would be pursue your passion, do what's interesting, notice your little instincts and intuitions to do stuff.
And what's fascinating about the book is he shows computationally, not just anecdotally, he shows computationally how there's a class of problems that actually, when you try to do it in an objective-based way, um, it, you can't solve it the same way you can in this sort of open-ended way.
Um, they pursue novelty because it's, it's not as easy to model interestingness, but for me, that is the big change in the world is everybody sort of follows their own bottom-up instincts.
Um, and that's how you get this beautiful blooming versus right now, everybody's trying to get into the same couple spots and repeat the same couple of behaviors.
And I think the essence of our conversations about education is sort of, how do you help empower a child to take those bottom-up instincts and curiosities and empower them to pursue that, to scaffold them such that they can do it in ways that they wouldn't be able to do on their own.
I'll learn everything that's the best from the past and everything that's the best from today.
And so that would be, yeah, mine.
Amazing.
Alan, if you had the chance to.
No, I wouldn't argue with Anjan.
But my, my relationship with reading was, um, started early before I could remember doing it.
And the two keys for reading were, uh, how many points of view there were.
So I wouldn't recommend one book.
So I think it's many books, um, good books and bad books.
What's a bad book you would recommend?
A book that probably isn't true.
Hmm.
That is still provocative, uh, can be extremely useful.
Like one of the books I've most enjoyed, now I'm mentioning one book, but one of the books I've most enjoyed that probably isn't true is a book called The, um, Origin of Consciousness in the Breakdown of the Bicameral Mind by Julian Jaynes.
Some of the best conversations I've had with other human beings have been with other people who read that book a few times and have thought deeply about it.
It's a book that by its premises and the nature of what the author drew on to make his premises plausible and by actual history, uh, more or less contributing to making it plausible.
It makes this very implausible thing, very, very provocative towards thinking.
It's, it's, it's a very good catalyst.
I don't know what my top 10 is, but that's one.
Um, but I think the other, the other thing that's critical, most people have never seen what is called a McGuffey reader.
Hmm.
I don't even know what that is.
People have heard her.
They're, so these are used in America mostly, um, or much of, much of the use was in one room schools, which is a very interesting dynamic.
It's done, done well.
It's a great dynamic for kids.
Many parts of the United States in the 19th century, the primary aim of teaching children to read was
not to teach them to read English, but to teach them how to learn from reading English, right?
So it was not being able to read the words.
It's not being able to see street signs or read a pill bottle or something like that.
It was actually to be able to put together complex thoughts expressed in prose, usually.
But the McGuffey readers also had poetry because the, the thought process of the people who
are doing public education in the 19th century was, well, everybody's spread out.
It's mostly agrarian.
The knowledge has exploded, especially in the 18th century.
And we're in the 19th century now.
And we actually can't teach what we think children need to know in a school now.
Yeah.
So we can't do it orally.
So what we need to teach the children is something meta.
It's not just to read, but it's how to learn from reading and how to deal with that.
And what do you do with other people, but thereby I would do a yes.
And with Anja, because I, I think human beings give, uh, you know, following their own instincts
is too anarchistic.
I think the best things that we've come up with really hard inventions and we should not,
uh, require children to, to reinvent them without help.
I think helping them to reinvent them is not a bad way of helping them to learn them.
That's pretty good.
But I think the, uh, I think the, the things that actually convey, uh, real perspective,
and I think wisdom comes out of more perspective.
I think that's a critical kind of idea.
The, the, the problem with these thresholds, if this is reading scores in the U S every time
it goes up, there's a yay.
And every time it goes down, there's a boo.
And the, but if you don't draw a threshold in there.
Yeah.
What's going on.
So the actual threshold in the U S is this wavy thing is below thresholds.
Yes.
The, the children are not learning how to read, whether this reading scores are going
up or down.
Yeah.
There's a threshold you have to get to.
Like one of my slogans that people find popular is the best way to predict the future is to
invent it.
Yes.
That you are famous for that one.
Um, I'm, I have instructions that it not show up on my tombstone, but I've used it in,
I used it in a talk not too long ago at the national Institute for health, uh, which was look
people right now in Washington, this is before the current day, but people right now in Washington
are busily, uh, predicting the future by inventing it.
The problem is they're inventing a bad future.
They're predicting badly.
They're inventing badly.
And so there's nothing in the slogan that says you should take it in a positive way.
Yes, that's right.
Right.
Point of view is worth 80 IQ points.
There's no sign.
It could be minus 80 IQ points.
We know plenty of people who act much stupider than they actually are because their point
of view is so messed up.
Yeah.
So this, these slogan things, I, I started making them up mea culpa because
Xerox executives did not respond to paragraphs.
You needed to give them, we need to give them something to think with.
And the first one I came up with was done spontaneously, but then I realized, oh, they
actually responded to that.
And this is more like advertising than I ever wanted it to be.
Yes.
If there's any cognitive bias humans have to the utmost, it has to be confirmation bias.
We'd love anything that supports our opinion and we ignore as much as possible.
Can I ask a last question?
Yeah, please.
Um, I sort of founded daylight because I'm like computers could be better for you and
computing could make you a much better version of yourself.
What I'm curious about is let's say we do collectively pull off this computer revolution.
We do actually get it right this time.
What does it look like?
Like, what is that world?
What, what image do you have of what's on the other side?
Well, so more than any other species, we are the species that does not put up with nature.
That, uh, when we can think of something, uh, that will help us better than we think nature
is helping us.
So we make tools, we make housing, we make clothing.
Uh, we don't let bad eyesight bring us down.
We don't let getting cancer bring us down.
And I think we have to encompass that in any theory of the future that our basic premise
is that we're not, we are animals, but we're not animals that wish to be pushed around.
And, and we occasionally overshot, we occasionally ruin nature when we're just trying to make
things more convenient with ourselves.
So that's a lack of wisdom, but I think we have to take this idea that a, so I, when I
think of human beings, I don't think of them as, as in isolation.
If you bring up a baby without any other humans around, you have something like a wolf child
or worse.
So I have a, I have a four or five books.
Those are book.
This is why I wouldn't go for one book.
I have four or five books just on wolf children that everybody should read.
And the bottom line there is you don't wind up with an adult that's recognizably human or
even able to acquire language in the way that children can acquire language.
So, so I always think of humans in relationship to some culture.
I'm always interested in what that culture is.
What is it doing for the individuals?
What is, what is, how is it hurting the individuals?
How is it helping them?
So I think that's a big deal.
The culture is something that has co-evolved with us.
So it's an extension of our biology.
We can't live without it.
We carry it along.
And I think a lot of the things that are most interesting and most powerful are things where
we've done the equivalent of inventing the bow and arrow or eyeglasses to ideas.
So we've invented a kind of mathematics that we're not born with, invented ways of knowing
about the world that we're not born with.
Just to return to the piece on like the computing revolution, to pull those threads that you
just mentioned and what it might.
Careful what you pull on.
Yeah, I can imagine.
Anjan knows I go on and on.
No, no.
Be careful.
We'll be, I'd be here happily all night.
But yeah, what's the image?
Like, yeah, if 30 seconds, you close your eyes, just give me, paint the image of, if
you pull it off, what it looks like.
I mean, Negroponte was the first to have the, I think, to have the audacity to, partly because
he was an architect, he wasn't worried about doing any, how do you do it?
But he was worried, you know, what he was thinking about is people are living in this world, they're
living in houses, they're living in.
So he was the first one that I knew of in the late 60s who said, well, it's going to be
inevitable that we're going to be living in a world that's active in a way that we've
never experienced before.
This ubiquitous computing sort of.
It's going to be, yeah.
So he wrote his master's thesis in the late 60s.
It was a masterpiece, actually, because it was the first real thinking.
It involved, he was a good friend of Marvin Minsky's, it involved how AI might be used.
It led to him getting some of this great research money of doing examples, getting people thinking
about it.
He and I were on each other's advisory boards.
He was the best man at my wedding.
You know, we were great, have been great friends for, you know, like almost 60 years now.
So, so this guy was a guy who in the late 60s, he was talking about Campbell's soup cans, talking
to you off the shelves of the supermarket.
He didn't care how it was done, but to him, that was more his law meant.
That's what it naturally happened.
Yeah.
That's where the, you know, when I first started thinking about how much help is too much help.
There's a modern equivalent, but what I went to an engineering high school.
Um, partly by circumstance is a very rigorous place, but a lot about of engineering in those
days was, you know, slide rule times.
And there was this book called the CRC tables and it was kind of the magic book.
It had every important engineering formula in it.
And part of becoming an engineer is learning how to use that book and how to use your slide
rule and modern equivalent of it is MATLAB.
And the problem with it was back then, and really with MATLAB is what MATLAB does for
you, it has a hard time getting in here.
So the 10, and this is true of like even the language we did at park called small talk.
Yeah.
One of the reasons it became popular was not from goodness, but because like many languages
now, it was the, what the library had in it.
So there are many things, many programmers would approach programming by asking themselves,
what's in the library first, rather than thinking, doing like a little mock-up or so on,
asking, am I asking the right, am I doing, even working on the right problem, any of that
stuff.
So having this stuff, having a big store full of tools is often the last thing you want
until you've gone through some form of minimalism.
And the last cautionary sentence I would say for this is, you know, above all else, understand
scaling.
Well, so many threads that we could keep pulling on, but you guys have been, yes, so, so, so
kind.
And, uh, I've enjoyed this very, very much.
So, um, thank you.
Thank you to you both.
It's great to meet you.
Lovely to meet you as well.
Amazing to learn from you and try to do some things together.
Yeah.
Thank you, Mario.
Yeah, absolutely.
That's it.
Thank you for listening to this episode of the Generalist Podcast.
Please subscribe on Apple Podcasts, Spotify, or your preferred podcast app.
Ratings and reviews help others discover these discussions.
So if you enjoyed the conversation, I'd be grateful if you could take a moment to leave one.
For all past episodes and more, visit us at thegeneralist.substack.com.
See you next time as we continue to explore the future.
