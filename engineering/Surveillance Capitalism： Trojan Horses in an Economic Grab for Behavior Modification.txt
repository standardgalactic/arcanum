This book asks the question, why does our economic system prioritize surveillance and also behavior
modification? What's going on with that? What is the nature of this economic system? And her
methodologies, she basically, she's a Harvard professor who spent years just going in and
interviewing people who are top executives and programmers in these big tech corporations trying
to figure out what is the strategy? What's going on? How does this fit in with the bigger picture?
Of our system. And you oftentimes hear the phrase, if it's free, then you are the product. And she
actually objects to that characterization. She says, no, no, you are not the product. Your behavior
modification and your data is the raw materials that go into the product. So the analogy here is
like a mine that's mining for ore or that's mining for oil or just taking stuff from the earth to be
used and packaged in some product that's sold to somebody. Well, your brain and your motivational
structure, that's just being mined where these companies are taking that stuff to sell to somebody
your behavior modification. And part of the deal with the shift in the framing here is that these
companies that are trying to get data and behavior change from you, they are completely indifferent to
you as a human being. They're not trying to change your religion in a particular way. They're not
trying to change your lifestyle in a particular way, except if that change in religion for you
personally will get the behavior modification that somebody else wants for their purposes, then
they'll use the religious language or the lifestyle language or the hopes and dreams to get those
people what they want. So this framing is really about the dehumanization, the fact that that the
treatment of people is not as people, the treatment of people is as raw materials, is as something that's
not human. And she contrasts this with totalitarianism, where she says in totalitarianism, they actually
want you to feel fear of them. They actually care about you getting emotionally and intellectually
on board with their political agenda. Totalitarians actually have this human-to-human relationship.
And it's of course an abusive relationship in totalitarianism. But what she says with this
other thing that we're in now, which she calls instrumentarian power, she says actually the people
who are extracting the behavior modification and the data from you, they don't actually care about
you being in fear or your anxiety. It just so happens that if fear and anxiety are the most
effective and optimized way of achieving what they need to get those people, the real customers,
the behavior modification, and the data they want, then fear will be used, anxiety will be used.
But it's not really about the fear or anxiety. That's just a means to an end.
I do believe, as she does, that our economic system is shifting under our feet. And she's
basically making the case that these large tech platforms are being incredibly strategic
about bending the direction of that shift toward their own vision, toward their own favor.
And my hope in this video is really to place this in the arc of the longer story of history,
and to do that with some of the language and the framing of other books that I've covered on the
channel that relate to the same topic. So where am I going? And I'll start with the long scale of
history and relating her book to techno-feudalism. Then I'll look at a quote that she keeps returning
to that comes from a Google economist that's talking about shutting off people's cars remotely if
they don't pay their insurance. And in particular, I want to think about that quote as it relates to
economic infrastructure and the infrastructure that is being built to support this new economic
system we're moving into. Then we'll ask the question, if our data and behavior modification
is the input to the product, what is being done to us through this economic system? Then how do
economic systems shift? And this has to do with economic mythology, which is the language used by
David Graeber. I did a series on this book recently. And even though she doesn't actually use the
language of economic mythology, it sort of bleeds from every page that that's what she's talking
about. At the core of all of her arguments is that what matters most is the economic mythology,
not the technology. The paradigm shift she's trying to bring to the table is that it's actually not the
technology itself that bends the direction of the economy. No, there's something more foundational
than the technology, which I'm calling economic mythology with Graeber. She uses other language,
but I'll go through some quotes to the book to sort of make the argument that these two people are
talking about the same thing. Then she uses the concept of the Trojan horse a lot. Personalization
is a Trojan horse. The internet of things is a Trojan horse. So we'll look at the Trojan horse story with
an eye toward what can we learn about what they're doing strategically to bend the economic system in their
favor. Then we'll look at the case of Google Glass and how that relates to the infrastructure being
built up to support this kind of system. Then we'll rewind to the introduction of Gmail to see how does
some of this strategy on their part work. And finally, if our data and behavior modification is the product,
then who is that product for? Who is on the other side of that market? With that in mind, I would like
to zoom back and place us in the longer scale of economic history. And a year ago, I did a review
of this book, Techno-Feudalism, where he basically says, yeah, I think we're moving into a new economic
system that is techno, meaning technologically enabled, and feudalism, meaning there's this
bifurcation of power between the lords and the serfs. And the question is, is this inevitable?
And both of these authors really push back against the notion that it's inevitable. So placing this in
economic history, we might think back, we've got the feudal system, and then we have the mercantilist
system, where we have ships and trade across the seas. Then we have industrial capitalism with the
factories. Then we have the rise of mass production, and that era came along with the rise of these
corporate bureaucracies. And sometimes I'll refer to that as the techno structure, the mixture of
corporate bureaucracies and government bureaucracies. And of course, in recent history, she's really going
through when this technology came on the scene, this digital technology, how is the system evolving in that
context? And she's actually going to push back against the notion that the technology itself is what's driving the
change in the system. She says no, there's a layer underneath that that's more foundational, that we
should actually have some say in, but that these tech firms do not want us to notice that we could
have a say. Now part of this story is going to have to do with the economic infrastructure being built
up. And when we think of infrastructure, we think of power lines and sewage systems and road systems,
highway systems. But there's also going to be a digital infrastructure and an institutional
infrastructure that's being built at present. And the question is, whose value is this infrastructure
being built up to serve? So she keeps returning to this one quote from Hal Varian, who's an economist
who works at Google. And I think the reason she keeps returning to this quote from him is that it's
representative of other types of digital infrastructure that's being put into place. Varian says that if
someone stops making monthly payments, nowadays, it's a lot easier to just instruct the vehicular
monitoring system not to allow the car to be started and to signal the location where it can
be picked up. Insurance companies, he notes, can also rely on these monitoring systems to check if
customers are driving safely and thus determine whether to maintain the insurance policy, vary the
costs of premiums, and decide whether to pay a claim. With that quote in mind, the question I always ask
is, whose interest or whose value is that economic activity attuned to? So anytime you're going to build
up any infrastructure, there's going to be an investment in resources. That's human resources,
physical resources. And here, the infrastructure is the ability to turn off somebody's car remotely.
And of course, infrastructure is designed to serve the ground layer of the economy. So the question
is, whose interest would drive an infrastructure that would make it really easy to just turn off
somebody's car remotely? Is that something the general populace would just consider to be super,
super convenient, something that solves a problem for them? Or is that economic activity,
that ground level infrastructure attuned to somebody else? And one of the things I appreciate
about this book is she keeps bringing up the myth of inevitability. Now, she doesn't use the word myth,
that's something I use on this channel. But is this inevitably the way the economy would evolve?
As long as you have digital tools on the scene, of course, you're going to be building up
infrastructure that enables turning off somebody's car remotely? Or is that actually inevitable? Is
that just something that we're sort of letting happen without people noticing that it's not well
attuned to the general population? So what is being done to us as they treat us like raw materials?
And really, the two types of raw materials they are extracting from us are data and behavior
modification. Where the data is really about prediction markets, it's about futures markets,
it's about reducing uncertainty for somebody who's trying to do their economic thing, whatever that
is, and they need to know how will people respond. With behavior modification, she classifies this into
three categories, which she calls tuning, hurting, and conditioning. Where tuning involves nudging and
subliminal cues, and it's subtle ways of influencing what I would call our salience frame, what is
prominent to us, what we notice, that the things that will enter below our level of consciousness into
our motivation. When it comes to what she calls hurting, this is really about the social cues and
the social norms in the environment we live in. So it's noticing that people tend to do what other
people do. That's a rule of thumb people use. Okay, if lots of people are doing this, then it must be a
good decision. And they use that perception of what other people are doing to actually bend
people's behavior and bend populations behavior according to what everybody believes everybody
else believes is the social norm, is the right thing to do. And then conditioning is something
that's used by B.F. Skinner, who has a really starring role in this book. Where B.F. Skinner is doing
this to animals, where he's conditioning animals towards certain behaviors by giving positive reinforcement
reinforcement, and away from other behaviors by giving negative reinforcement. Do you want the
mouse to avoid smelling flowers? Then give them an electric shock every time they smell a flower.
Or do you want the mouse to use the hamster wheel more often? Then give them a food reward every time
they use it for a few minutes. Do you want the mouse addicted to the hamster wheel? Well, you can
increase the chances of addiction by making the reward variable, where sometimes the mouse gets a ton of
food, and really delicious food, and sometimes just a little bit of food. And that variability actually
is going to feed into addictive behaviors. And the idea with conditioning on these platforms is that
you're doing the same thing to human beings. Now let me give you a quote that highlights how this
tuning, hurting, and conditioning taps into people's vulnerabilities as these companies prepare this
product for their real customer. The Facebook document details the many ways in which the
corporation uses its stores of behavioral surplus to pinpoint the exact moment at which a young person
needs a confidence boost, and is therefore most vulnerable to a specific configuration of advertising
cues and nudges. By monitoring posts, pictures, interactions, and internet activity, Facebook can work
out when young people feel stressed, defeated, overwhelmed, anxious, nervous, stupid, silly, useless,
and a failure. So if our economic system is doing more of that, we want to return to the long scale of
economic history and ask the question, how do economic systems change? And David Graeber, I think,
gets this right in his book when he basically says, systems change as the economic mythology,
the way people think about their system changes. So what is economic mythology and why is it at the
heart of what she's talking about in this book? It's basically a set of anecdotes and stories and
models and perspectives that shape people's understanding of how their economic system works,
and ultimately that shapes the understanding of what is legitimate and illegitimate economic behavior
inside that system. And in a lot of ways, this book, even though she doesn't use the word mythology,
this book is about the changing nature of our economic mythology, and the way these large tech
platforms are actually being incredibly strategic at bending the direction of that change in the economic
mythology toward their own favor. And this is why she pushes back so hard against this notion of
inevitability. It's these tech platforms want everybody to think, of course, as long as technology existed
like this, it's inevitable that a few large companies are going to amass power for themselves and just come
in and use people and nudge people and modify people's behavior, or at least that's what they want
people to think so that people don't push back and bend the direction of the economic mythology changing
towards something that's more democratically accountable. Now if she doesn't use the language
of economic mythology, how do I know that that's what she's talking about? And I really need to do a
whole other video just on economic mythology in this book, but for now I just want to give you a taste
for why what she's saying maps so well onto this concept. We remember that economic mythology captures
the concepts that define what is legitimate and illegitimate economic behavior. So let me read
you a quote from her on decision rights, who has a right to legitimately decide, and privacy, who gets
that, who doesn't. Surveillance capitalism lays claim to these decision rights. The typical complaint is
that privacy is eroded, but that is misleading. Privacy is not eroded, but redistributed, as decision
rights over privacy are claimed for surveillance capital. Our legal system devotes massive energy
toward coming in and protecting the rights that these companies have to keep their algorithms private.
And yet there's no such efforts to protect the privacy rights of the people who are being herded,
tuned, and conditioned. And this movement of privacy rights from the people to the tech platforms,
that movement is a shift in the economic mythology. And let me give you a couple more quotes that I
think will drive home the point that she's talking about economic mythology, even though she's using
other language such as logic in action. Logic in action is kind of jargony and it's why I'm not using
her specific language here. But she's talking about the same thing Graeber is. That surveillance
capitalism is a logic in action and not a technology is a vital point because surveillance
capitalists want us to think that their practices are inevitable expressions of the technologies they
employ. Surveillance capitalism was invented by a specific group of human beings in a specific time
and place. It is not an inherent result of digital technology, nor is it a necessary expression of
information capital. It was intentionally constructed at a moment in history. And those are not the only
examples of her talking about things that are clearly economic mythology. I have pages and pages
of notes where I'm like, this is exactly what she's talking about. It maps so perfectly onto Graeber's stuff.
Now, economic mythology is not all bad. As a matter of fact, you can't have a system of any kind,
whether it's economic or otherwise, without some kind of mythology. It's just a collection of ideas and
concepts and stories and whatnot. I oftentimes refer to an economic mythology as a constellation of
ideas. It's not just a single idea. It's really how a bunch of ideas are woven together and interrelated.
That's an economic mythology. And yet, economic mythology changes one concept at a time. So for
example, if we wanted to replace some of the more misleading concepts in our current economic mythology
with more accurate ones, we can use concepts to make that shift. And one such concept she uses a
lot in that sense is the Trojan horse. And she says, actually, personalization is the Trojan horse that
is allowing these people to get away with this. Because they say, actually, we're gathering your data
in order to personalize your experience. And that creates this perception that all of this infrastructure,
all of the tools, all of the taking of people's data is actually attuned to people's interest.
We're just trying to make the user experience as good as possible. And it creates the perception or
the misperception that that's actually necessary. Do they need to be collecting as much data as they are
to personalize it in a way that we would experience well? And then do they need to sell the data and sell
the manipulation, sell the behavior modification on the other end in order to finance this
personalization that ultimately is aimed at us. And if we look at the actual Trojan horse story,
we can learn some things. So the Trojan horse story, basically, there's a war and there's two sides
to the war. And one of them gives as a gift this huge horse to the other city. And of course,
they take this this huge horse into the city gates, and it's beautiful. But inside this wooden
horse are all of these soldiers who are going to come out of the horse at night and defeat the
city through the horse. So it's designed to be a gift. It's designed to look like a gift.
But in fact, it's very aggressive. And it's a move to come in and take over the city
by the other side on that war. But one lesson we can take from the Trojan horse
is that it actually is a gift. Even after all is said and done, the horse is beautiful. Like
the wooden horse will still exist. And personalization is a gift. So this is why it's so important for us
to avoid either or thinking is people can get wrapped up in the battle. Either these things
are a gift to people, the gift of personalization, or they are an aggressive act by somebody who's
going to come in and take territory where that territory is your brain and your motivational
behavior. Either or. And people can get into these huge battles. Is it this or is it this?
And in fact, it's both. It's both personalization, which is a gift. And also it's an aggressive act
at the same time. Now that was not the only time in the book when she uses the concept of the Trojan
horse. She actually also uses a Trojan horse when she talks about the internet of things.
So the internet of things is basically where you have your thermostat and your refrigerator and your
printer and your car potentially that are attached to your phone or that can be controlled through your
phone. And of course, if you can control it through your phone, it can also be controlled remotely,
as we saw in Hal Varian's quote about the car. But let me read you a quote on the internet of things.
Between 2012 and 2015, I interviewed 52 data scientists and specialists in the internet of things.
They came from 19 different companies. The agreement among their responses was striking. Nearly every
interviewee regarded inevitability rhetoric as a Trojan horse for powerful economic imperatives.
And each one of them lamented the lack of any critical discussion of these assumptions.
If Google is a search company, why is it investing in smart home devices, wearables, and self-driving
cars? If Facebook is a social network, why is it developing drones and augmented reality? Why are
these companies investing so much in the internet of things? And her answer, of course, is that Google
is not a search company, and Facebook is not a social network. Their primary product is data and
behavior modification. And everything she lists there — these smart home devices, the drones,
the augmented reality, the wearables — all of those ramp up these companies' ability to give their
real customers what they want. And it's easy to be misled about the economic role of these
products. These are not just products. They're also infrastructure. And I think a case that will
help us think about this is the case of Google Glass. Now, Google Glass was those glasses that had
the internet sort of superimposed on whatever you were looking at. And she says about them, Google Glass
was all push and no pull. In other words, it wasn't that people really, really wanted the internet over
their eyes and superimposed on what they're looking at at all times. That was not the industry responding to
the deep needs and solving the problems of the population. That was all push. In other words,
Google Glass was really attuned to the needs and desires of these companies and what they wanted.
The attunement was not to the population. And yet it was a product. It was a product that was intended
to build this infrastructure that would make behavior manipulation and data collection easier.
For example, with Google Glass, you could see where people's eyes were pointed, which would be another
data point. And of course, behavior modification. If you're nudging people toward one restaurant and
away from another restaurant, you can do that with the internet that's superimposed on top of their
eyes. But people weren't interested in that. So unfortunately, for these companies, that product
did not pick up. So that infrastructure did not get built, which goes back to this notion that it really
is a balance of power between the people, attunement toward the people, economic systems that attune
toward the people, and attunement toward the needs of the technostructure or the digital companies,
the question is which direction ultimately has the stronger pull. Now, if she's claiming that these
companies are being highly aggressive at bending the economic mythology in their favor, the question
is why doesn't it feel like that? Why do we hardly notice this at all? And of course, her answer is
that that's part of the strategy. Making sure that this is happening under people's noses without
them paying any attention to what's going on. That is important for what they're doing for them to
succeed. They need people to not notice. And Gmail is a case in point. So the economic mythology goes like
this. If we want something like Gmail, which we really value, it has a lot of population level value and
productive value, then the only economic system that would give us this is an economic system where
somebody is harvesting our interpersonal messages for their own use to modify our behavior or to sell
whatever that data comes out of it to somebody else. This is the only system possible that would allow
the economic investment in something like Gmail. So we just need to sit back and be like, okay, that
trade-off is worth it to us because we value Gmail so much. Could there be an economic system that
would give us something like Gmail while also having limits on the data that could be collected or could
be used? And the answer, of course, is yes. But even thinking about that is kind of outside the Overton
window outside of acceptable discourse at the moment. And she talks about something that she calls the
dispossession cycle, which is the strategic way of pushing back against people's revulsion to something
when it first comes out. So I remember 2004-2005 when Gmail came out, they had advertisements on the
side of the screen that oftentimes related to the direct message that you had up on the screen. So if you
were talking about getting your mom jewelry for Christmas, then you'd see these jewelry ads, which was kind of
disconcerting to people. It was like, whoa, what I'm talking about with my friend is now being
advertised. And it was just a little bit too in your face. So of course, there was a rise up of
people trying to push back against that, both legally and just activists doing various sorts of things.
And the dispossession cycle she talks about is really the strategic way of getting people used to
it. Okay, they'll move the advertisements to other places so that it's not so obvious that that's what
they're doing. So it's not on the front of people's minds. There are a whole bunch of strategies for
sort of warding off people's objection to the to what they're doing with the data and what they're
doing with and what they feel like they have a right to do with modifying our behavior. And that
strategic battle between them and people who are trying to push back, that battle is a battle over the
economic mythology. Now let me point out two things that shifted in this story. We saw the jewelry
advertisements shift from the side of our Gmail where we're talking about jewelry right now to the
YouTube video where people may not make the connection that oh, this is a direct response
to your email to your friend. So that shift happened. And at the same time, we had this shift
in the privacy rights that was sort of underpinning some of this change, which is the shift in the
privacy rights from the privacy of the individual to the privacy of the firm. The firm can privately do
what it wants to with your data without you having access to knowing how it's who it's selling to how
it's using that all of that. The first shift was designed to shift our attention so that we don't
notice what's going on. The second shift was designed to shift the economic mythology so that they have
economic rights that they can build upon as they build a system that works in their favor. Now if our
data and our behavior modification is the input to the product, who is that product for? Who is on the
other side of that market? And I think this was one thing I was slightly frustrated with the book is that
it felt a little bit nebulous. She never came out and said, this is who is on the other side of the
market. And if I asked the question, does it matter who's on the other side of the market,
I could imagine cases where it doesn't matter. But I could also imagine cases where the other side
actually does matter. So there were four answers to this question I came up with. Who's on the other
side of the market? Advertisers is one, obviously, she talks about. Along with advertising,
we have propaganda. I'm not sure she mentions propaganda much or at all in the book. Then we
have various types of companies like the insurance company that would shut off your car if you didn't
pay for insurance. And then we have kind of a fourth category, which is utopian visionaries who are trying
to implement their vision of the society they want to live in. And she does talk a lot about B.F. Skinner
and his vision for the future. As a matter of fact, she goes through this book that is his fiction book
depicting how he hopes the future will turn out, his utopian vision. And it is a utopian vision where
there's no more politics, there's no more disagreement over different things. Instead,
you just have a group of people at the top who is cooperative and collaborative among themselves,
who is modifying people's behavior in all of these ways. And Skinner is actually trying to avoid
totalitarianism by coming up with this new utopian vision where technocrats at the center of the
system get to nudge people's behavior according to what they think is most prosocial. So these utopian
visions are trying to avoid totalitarianism, but of course they're putting forth this vision that is
something that is actually way more dehumanizing than even totalitarianism. And yet if utopian
visionaries like Skinner are part of the customer base for these tech platforms, what does that look
like? Is that government? Is it corporate sector stuff? Just what would that even look like? And I did
not have a vision for that at all coming out of her book. So I do want to do a couple more videos on
this book. I'll do one on economic mythology as she talks about it in this book, and then I'll do one
on B.F. Skinner's vision and other thinkers that she talks about in the book who have this utopian vision
for basically a technocratic elite nudging everybody's behavior into an optimal society.
And then I also probably need to do a video asking the question, is behavioral economics the economic
foundation of techno feudalism? Because she does mention how behavioral economics is absolutely
part of what's going on here. And I teach behavioral economics. It's one of my favorite things to teach
actually, and one of the ways that I've developed my own thinking. So I want to lay out what is my
thinking around that topic.
