An AI company stole my work. And I'm far from the only one.
Over recent months, there's been a veritable avalanche of revelations about the unauthorised
use of artistic, journalistic and video works to train generative AI tools such as OpenAI's ChatGPT,
Google's Gemini and Anthropic's Claude. Where once there was merely a mountain of suspicion
that such theft was taking place, now sits a stack of cold, hard evidence that some of the
most valuable companies in the world right now have been developing their tools on the backs of
the stolen labour of video creators, journalists, artists and authors. A lot's been said about the
legalities and morality of all of this, but I want to talk about its broader potential impact on the
online media and creator economy. Because even at a point where the AI stock bubble looks set to burst,
the rise of generative AI looks set to significantly alter who gets to profit from the works of writers,
journalists, artists and others. And this has the potential to not only shortchange individual
publishers and creators but to have a desperately damaging impact on who's able to contribute to
our popular discourse and debate. The future is AI. To understand and create language.
It understands prompts written the way people write. Copyright Shield means that we will step in
and defend our customers and pay the costs incurred. Is the AI boom actually a bubble? Two major copyright
lawsuits against AI art generators. A couple of months ago, my agent got in touch. They were giving me
advance notice of an article which was about to be published by a recently launched news startup
called Proofnews. The piece in question was the result of an investigation carried out by journalists
Annie Gilbertson and Alex Reisner into the use of YouTube videos to train the AI models which power
generative AI tools including Anthropik's AI chatbot Claude and Apple's new Apple intelligence system.
See, as you probably know by now, generative AI, that is, AI tools which respond to user inputted
prompts by producing text, images or video, require huge swathes of data to train. Generally speaking,
the more data a tool can be trained on, the better results it will produce. And there's been a widely
held assumption that the companies developing these tools have been freely helping themselves to the
work of creators, journalists, artists and others in order to improve their products.
These AI companies have been pretty cryptic about what bodies of work they've been using for this
purpose. And the suspicion upon many has been that this is because they've been helping themselves
to huge quantities of copyrighted material without asking for permission or giving any kind of payment
to the creators of that work. But Gilbertson and Reisner, the writers of that article,
wanted proof, which, you know, is kind of fitting given the name of the outlet they work for.
They thus began to dig through the research papers which developers often publish following new
breakthroughs. And when they did, they found repeated references in publications from Anthropik,
Apple and Nvidia to something called The Pile. The Pile is a dataset developed by a non-profit
organization called Eleuther AI. It weighs in at a whopping 825 gigabytes of data, which,
given it's comprised solely of text, is absolutely wild. Comprising books, Wikipedia articles,
forum posts, email chains and much, much more, The Pile is an absolute treasure trove of written
English. It's perhaps no surprise, then, that Anthropik, Apple and Nvidia have all made use of it in
training their respective AI models. As they trawled through the pile, however,
Gilbertson and Reisner found something else. They discovered that around 6 gigabytes and 500
million words of this massive text file was made up of subtitles scraped from YouTube videos.
The exact videos which had been stolen for the dataset had been obscured, but when they spotted
that the dataset included references to the video ID codes which are contained within YouTube links,
Reisner was able to reverse-engineer the dataset to create a tool through which creators and their
fans can find out whether their work had been used. And, when I searched my name,
I indeed found that 18 of my own videos were among them.
Now, I was far from the worst affected creator here. Some channels, such as Ted's TedEd channel,
had hundreds of videos stolen. And the response to the Proof News article from creators was,
unsurprisingly, one of despair. Scott over at NerdSync made a quick response video,
which brimmed with unapologetic rage. Jacob Geller described the revelation as nauseating.
And Abby from Philosophy Tube described a similar sense of violation.
I felt a little less personally wounded by all of this. Perhaps it was because the videos were old,
and thus the memory of the work that I put into them has mostly faded. Maybe it's because my videos
tend to be less personal and vulnerable than those of other creators. More than anything though,
I think I'm just used to this kind of stuff already. I've been working in creative fields most of my life,
and particularly when it comes to making and distributing my work over the internet,
I think I've just come to accept that someone, somewhere, is usually ripping me off in one way or
another. I didn't like it, but I have come to accept that this kind of thing will happen.
Even so, this revelation did set alarm bells ringing in the back of my head about the ways
in which the embrace of AI tools, such as Claude or ChatGPT, look set to reshape the economics of
the creative portions of the web, particularly when it comes to journalism, commentary, and other
forms of social and political discussion. One of the promises of the early internet was that it would
give us a space in which we could more freely discuss the world around us. Many of us hoped it
would allow us to come into contact with new perspectives and voices. And, to some extent,
this has been the case. Even just on YouTube, I'm constantly confronted with new outlooks and
viewpoints which would never have been given airtime or page space in traditional media.
But what if this shift to an AI-centred media economy is about to place that at risk?
What if the widespread theft of the work of journalists, commentators and creators,
and its subsequent remixing and regurgitation by AI tools,
has the potential to place new limits on the kinds of perspectives we're able to come into contact with?
Because there's a real danger that this could happen… and not for the reasons that you might
initially think.
See, there's been plenty of concern from right-wingers that AI models like ChatGPT or Midjourney might impede
political debate by being too woke. The accusation is that developers might be so keen to avoid any
controversy or offence that they'll set these systems up to only give right-on, happy-clappy,
liberal answers to use as prompts. Which isn't an entirely unfounded concern.
Google recently had to pause the rollout of image generation on its Gemini chatbot
after requests for it to produce pictures of German soldiers from World War II returned a plethora of
racially diverse Nazis. Which is pretty historically inaccurate. In a predictably ludicrous response,
Elon Musk decided to fix this dilemma by instructing developers of X's Grok chatbot to program it to
avoid answers that are woke.
This kind of institutional bias, whether woke or, in Musk's case, anti-woke, is certainly a real
challenge. But there's a slightly more complex threat, which emanates from how AI risks reshaping
the economic model, which currently funds the production of news-related media. Because the
embrace of tools which have been set up to instantly scoop up any form of journalistic, political or
critical expression, in order that they can be repurposed to generate profit for AI companies and
their customers, places the entire economic model on which such work relies, at risk. And where the
internet has previously had at least something of a democratising effect on the media landscape,
such a shift has the potential to return considerable power into the hands of corporate media magnates.
Now, the internet has never been particularly kind to journalism.
The site now reports having 100 million videos and claims 60,000 new videos are posted every single day.
One journalist typed relevant words into the internet.
One website alone, the Consumer Action Group, has 113,000 members.
I mean, I was actually amazed to learn 7 million people use the internet.
As the World Wide Web started gaining widespread adoption during the 1990s,
more and more newspaper publishers began launching websites for their titles.
The New York Times, The Wall Street Journal and The Washington Post all began publishing
daily articles on newly minted websites in 1996, while The Guardian followed suit three years later.
Doing so had immediate trade-offs. Making the reporting freely accessible online surely meant
that some people who otherwise would have paid to purchase a physical newspaper no longer would.
Nevertheless, the hope among media company owners was that publishing online would massively
increase their newspaper's reach. Not only might some readers, who previously would have been fiercely
loyal to a rival publication give them a chance, but they could reach international readers and others
for whom buying a physical copy of their paper might not even have been an option.
Where going online meant for going upfront sales revenue, then, the general hope was that additional
advertising might make up the deficit. A slide deck produced for staff at The Guardian at the time
revealed their hope to become the intelligent person's home on the net. The assumption was that
internet users who wanted to find out what was going on in the world on a given day would log onto the
internet, head to the homepage of their paper of choice, and browse around a bit reading a whole
bunch of articles and think pieces. As they did, they would be served with a veritable feast of ads
which would fund that journalism and line the pockets of each publication's owners.
That, however, is not the direction that things went in. Instead, two new phenomena emerged which would
fundamentally alter how people engage with the news. On the one hand, search engines, and on the other,
social media. From the very beginning, Google stated that its goal was to
organize the world's information and make it universally accessible. And both Google and social
media have played a key role in making the internet less foreboding. Long gone are the days where one had
to remember the URLs of the various websites you wanted to catch up on. In fact, to many people,
even typing in the URL of a website other than Google, Facebook, or Twitter now seems kind of
archaic. It's these services, not the likes of The Guardian or The Washington Post, which have become
our metaphorical homes on the net. Even for folks like me who boot up our phones or computers with the
explicit intention of catching up on the news, few navigate directly to newspaper websites. Most will,
instead, load up social media to see what stories people are sharing and discussing there.
Which, as I mentioned before, has had huge benefits for media plurality. It makes it much easier and
more natural to engage with multiple perspectives on a single news story in a way which would have been
much less likely or at the very least much more expensive in the print era. The challenge is that
this has also made news publishing a much more precarious game. A world in which readers simply
dip into a news site to read a single article and then instantly return to social media is one in
which publications aren't able to show as many ads to each reader. The associated reduction in reader
loyalty also means there's less certainty in terms of how many people are going to visit each day
and in the associated revenue which comes from that. What's really crucial to understand, however,
is that this doesn't mean that news reporting, journalism and other forms of current affairs
commentary generate less economic value than it once did. Journalism continues to be incredibly
lucrative. The real shift is that a significant chunk of the value it creates now gets sucked up by
Google, Facebook and other social media companies. In pre-internet times, newspapers could charge
hefty sums to companies wishing to advertise on their front pages, but the role of the newspaper
front page has effectively been replaced by the news feeds and results pages of third-party companies
who now get to pocket that cash for themselves. There's two ways to view this. Search and social
media companies will argue that they deserve that money. Google boasts that its products give people
choice and help them find more high-quality journalism than ever before. They would argue that they are
delivering new readers to news publications and deserve to be financially rewarded for that.
The alternative perspective is that the key appeal of Google, Facebook and the rest is massively boosted
by the fact that users can turn to them as a portal to access the news. One recent study suggested that
Google searches for news stories generate the company US$440 million every year. In this view,
Google is effectively using the work of journalists and their employers as free content for their
sites. Newspapers thus find themselves in a position where they are generating significant value for
big tech companies whilst they themselves struggle for cash. Some media organizations have sought to
reassert their revenue-generating abilities by introducing paywalls, with some success. Where
articles remain free to access, several governments have begun to step in to protect publishers.
In 2021, the Australian government introduced the News Media Bargaining Code. This forced Google and
Facebook to hand over around US$150 million to a variety of large media organizations in return for being
allowed to list their content on news feeds and in search results. Nevertheless, this is a mere slither
of the $11.9 billion worth of revenue which researchers at the Centre for Economic Policy Research have
suggested tech companies are effectively scalping from media companies each year. The consequences for
the quality of reporting that we rely upon to learn about the world around us are plain to see. In a world
where every single article has to fight to be read, journalists are further encouraged to frame their
reporting in sensationalism and clickbait. Where this hasn't helped to increase revenue, layoffs have been
the order of the day. 8,000 jobs were lost across the media industries in the US, UK and Canada in 2023 alone.
So bad of things got that the UK's Press Gazette now keeps a regularly updated page of redundancies.
But what does all of this have to do with AI? Well, in effect, what we've been left with is a
system in which a huge chunk of the economic value created by journalists is scooped up by a new breed
of intermediary companies who have inserted themselves between publishers and readers.
I've discussed this model of what the Canadian writer Nick Cernick calls platform capitalism in a
panned full of videos before, and again, there have been some positives to come out of this so far.
It's maybe worth acknowledging that you probably wouldn't be watching this video if YouTube hadn't
emerged as a platform which connects people like me who create news-related videos with potential viewers.
Regardless of what you think of the quality of my work or that of any other creators, this has allowed all kinds of
perspectives and opinions which would never find a voice in legacy media to get a fair shake.
Nevertheless, the rise of AI tools such as ChatGPT and the content theft which makes those tools possible
will only serve to turbocharge the power of these new intermediary companies.
And the way in which it will do so risks crushing this more positive aspect of the new media economy.
It's certainly not all good news for media barons such as Rupert Murdoch or Jeff Bezos either,
but there's a real danger that it adds a further twist to this story, in which the power of such
figures to shape the news that we read, watch and listen to is stronger and more insidious than ever before.
Large language models have captured the world's imagination.
This is the humane AI pin.
About a year ago, November 30th, we shipped ChatGPT.
Apple intelligence is the personal intelligence system that puts powerful generative models
right at the core of your iPhone, iPad and Mac.
Ever since the first mainstream generative AI tools were announced in 2022, we've been encouraged to view
the likes of ChatGPT, Claude, Gemini and Midjourney as completely new and revolutionary. And, on a purely
technical level, it would be ludicrous to suggest that they're not pretty impressive.
That being said, they didn't come from nowhere, and they're really much more of an incremental
step forward from previous machine learning technologies than some kind of pure, unpredictable
invention. The same is true of the economic impact AI is likely to have on our online media ecosystem.
As we've seen, the trajectory of the digital economy to date has been one in which the economic value
created by journalists, along with that created by visual artists, video creators and others,
has increasingly been siphoned off by big tech companies. These companies have inserted
themselves as intermediaries between content providers on one hand and audiences on the other,
and expect to profit handsomely from allowing the former to share their work with the latter.
Generative AI tools, and the people and companies who use them to create new works,
are effectively another form of intermediary. Let's say that I decide to launch an AI-powered
news website, and because I want to attract a young, heavily online audience, I decide to publish,
as my first article, a 1000-word piece about Charlie XCX declaring that Kamala Harris
is Brat. Now, I'm not a young man anymore, I've not listened to Charlie XCX's album Brat,
I don't know what a Brat summer is, and given it's now autumn, it's probably too late for me to find
out. But that doesn't matter, because I'm not actually writing the article, ChatGPT is. Although,
in reality, ChatGPT isn't writing the article either. Instead, some of the article's substance will be
drawn from ChatGPT searching the internet, and some of it will be produced by calculations the
tool makes based on its prior training. The resulting article is actually a Frankenstein-like
amalgamation of perhaps hundreds of previously published articles. Some of those will explicitly
be about Kamala Harris and or Charlie XCX, whilst other articles and books, and yes, YouTube video
subtitles will have been used in a more broader sense to teach ChatGPT how to construct a decent
sentence and paragraph and argument. In short, then, ChatGPT is acting as an intermediary. It's
taking a huge sample of pre-existing work written by journalists, music reviewers, social media users,
and others, and simply rewriting it for a new audience. What makes this far worse than the large
chunks of revenue which Google, YouTube, TikTok, and Facebook take from publishers is that neither
OpenAI, as the creator of ChatGPT, nor I, as the publisher of this fictional website, are sharing
any of the revenue we make from subscriptions or advertising with those original authors at all.
In fact, they're not even getting the basic decency of credit for their work. Whether or not this is
legal, it's obviously immoral. ChatGPT might occlude this act of plagiarism by combining an unknowable
number of sources and processing them through a mystery box of maths and code, but it and I would
still be taking the work of others and presenting it, even not as my own, then as the work of ChatGPT.
Whatever hurt or damage this individual example might cause, however,
the broader consequences of such practices becoming widespread are even more troublesome.
Because the bigger question to ask is this. In a world where anything that someone writes and
posts on the internet, including journalists, can quickly be gobbled up by a generative AI tool,
regurgitated back out and republished elsewhere, that's not only going to lead to a handful of
individual writers or news publishers being shortchanged. It has the potential to make original
writing or indeed video production or podcast development completely financially unsustainable.
Journalism, in particular, can be really expensive to produce. I can tell you firsthand,
from my experience making videos for this channel, that the cost of researching and writing and
editing and arranging interviews and travelling to any necessary locations to report on events
adds up incredibly quickly. I'm also pretty lucky in this regard. My work, and that of most other
creators and publishers who make journalism-adjacent content for YouTube, largely revolves around
analysing topics and events which other, far more qualified journalists have already reported on.
Producing breaking news is endlessly more expensive. It requires reporters to have the time to go to press
conferences and knock on doors and interview politicians and visit crime scenes and submit
freedom of information requests and monitor email inboxes in case anyone gets in touch with a lead
on a story which no one else even knows about yet. It's not even particularly reliable in terms of
producing a monetisable end product. A reporter might spend ages working on a story, only for it to
not really go anywhere. Of course, the discursive nature of journalism and current affairs commentary
means that no writer or publication is ever able to monopolise every single penny of the economic
value that each of their stories generates. Even when a reporter has the honour of breaking an entirely
new story, or when an opinion writer offers a particularly spicy new take on a topic, that story
or analysis is often quickly picked up by other journalists and publications who want to discuss it
too. That's all an accepted part of the game. But an AI-fuelled media economy in which any article,
video or audio piece can be instantly sucked up by an AI tool, regurgitated into a new form and then
republished elsewhere, is going to place the very financial viability of all forms of journalism into
question. At best, such a shift will likely mean that even the most well-meaning journalists and writers
will have to cut corners. They'll have less time to dig beneath the surface of a given story
to see what lies beneath. This would only further embolden politicians and PR companies to fill their
announcements and press releases with more questionable claims, knowing that overworked and underpaid
journalists won't have the resources to fully investigate whether or not they're true. At worst,
it has the potential to kill off small, independent news outlets entirely, leaving behind only the
handful of large legacy outlets which have dominated our political discourse for more than a century.
See, over the past year, news organizations have begun to fight back against the impact AI tools have
been having on their revenues. In December 2023, the New York Times began the process of suing OpenAI for
allegedly using its articles to train the AI model behind ChatGPT. Terrified that it might face further
lawsuits, OpenAI began to make deals with other publishers, including Rupert Murdoch's News Corporation,
which owns The Wall Street Journal and The Sun, and Condé Nast, which owns The New Yorker, Vogue and
several other titles. The former deal was reported to be worth, in the region, of $250 million. Which
might seem like the beginnings of a more equitable model for training AI tools whilst also better
reimbursing journalists and publishers for their work. The reality, however, is that such deals are
likely to remain the preserve of large corporate media organizations with both the legal heft and
political connections required to force AI companies into making such arrangements.
There will have been plenty of journalism-adjacent creators and channels in the training data stolen
from YouTube and used to train Claude, Apple Intelligent and NVIDIA's AI models, but regardless of
whether those companies stealing those video transcripts was legal or not, most of them simply won't have
the ability to act on these revelations in order to secure a payout. In short, then, the impact of the AI-ification
of our public discourse will not be shared equally. Established publishers will be able to defend
themselves and their revenue streams from the fallout, whilst, without much broader legislative
intervention, independent creators, publishers and smaller outlets will largely have to accept their
work being routinely stolen. Of course, some writers, podcasters, creators, etc. might be saved by their
audience having enough of a personal connection to them as personalities that they continue to engage
with their work even if it could technically be found elsewhere. But this in itself merely presents
new challenges. A popular discourse based on personalities and parasociality rather than ideas
isn't necessarily a great one. Others might continue to publish for fun or out of a sense of civic duty.
Nevertheless, their ability to grow the scale of what they do and improve its quality is likely to
be severely hindered. The result is that the more negative aspects of the new media revolution,
in which intermediary companies skim revenue from writers and publishers, will be turbocharged,
while, at the same time, the more positive outcomes relating to media plurality are rolled back.
We risk once again finding ourselves in a position where our collective social, political and cultural
conversation is dominated by just a handful of corporate outlets, owned by an ever-diminishing
and merging number of companies and proprietors. We might read their articles directly on their websites,
or through an AI chatbot or articles plagiarised through their use. But it will be those corporate
media outlets who will be the only ones with the means to do the original reporting which powers these
tools, and therefore who will still be shaping the assumptions and perspectives which these tools spit out.
That such a scenario would be devastating for our ability to think and engage critically with the
world around us barely need saying. A healthy, journalistic ecosystem needs more voices, not less.
But if AI companies continue to be allowed to steal the work of independent writers, journalists and
creators of all stripes without permission or, as importantly, compensation, the ability of anyone,
without considerable financial and institutional backing to contribute meaningfully to our collective
discourse, is going to be severely constrained. Thankfully, some companies are beginning to reject
the generative AI invasion. Just last month, the team behind the graphics app Procreate pledged
never to add generative AI capabilities to their software or to use their software to steal users' work.
Which seems like a ridiculous statement to have to make, but Adobe found themselves in hot water in
February when their new terms of service seemed to imply that they would be doing just that.
Another company which has come out swinging against AI theft is Nebula, the creator-owned streaming
service that I've been a part of for some years now. The publication of the Proof News article that
I mentioned at the beginning of this video was a real wake-up call for many creators on the platform.
And so the team opted to make a stand by decisively declaring that none of the platform's original
productions will use generative AI tools. And what's particularly exciting, for me at least,
is that the next of those original productions to be released, as of the uploading of this video,
is my feature-length Nebula Original documentary of Boomers. If you're a regular viewer of my channel,
you'll have probably heard me talk about Boomers already. Perhaps you've seen the announcement
video which went out a couple of weeks ago. It's a feature-length documentary which dives headfirst
into the generation war which sometimes seems to have taken over our politics. Boomers has been
about a year in the making at this point and has involved me travelling to various spots around the US,
the UK and over to France in order to interview experts, ordinary folks and even my own mum.
My goal has been to try and shed some light on the lives and legacy of the baby boomer generation.
I wanted to understand why it is that the Boomers often seem to have soaked up all the wealth and
power in our society and why everything seems to be so much more difficult for the generations which
have come after them. Housing, university tuition, pensions, the climate crisis, it covers a lot.
And by some weird twist of fate, also ended up involving me driving a golf buggy around a fake
Spanish town in Florida. You'll have to watch the film to understand that one.
The fact that Boomers is a Nebula Original production has allowed me to be so much more ambitious with
this project than anything I've ever made before. This is a giant leap up from making these little
YouTube videos into making a proper full-scale documentary. I've worked with a hugely talented
team of producers and camera operators and editors and production staff to make the whole thing look
and sound absolutely gorgeous and I cannot wait to share it with you all extremely soon. Boomers will
be available to watch exclusively on Nebula. And if you're not signed up already, now is a fantastic
time to get on board. Over the course of this year, we've really upped our game with an incredible
slate of original films and series which, like Boomers, aren't available to watch anywhere else.
Just recently, we released Abigail Thorne of Philosophy Tube's fantastic new short film Dracula's
Ex-Girlfriend. We also recently announced a feature-length documentary by Bobby Broccoli called
17 Pages which covers The Baltimore Affair, a massive scientific scandal retold through interviews
and some really cool original artwork. This is just a taste of some of the fantastic stuff which has
been coming out on the platform lately, all of which is allowing creators like me to push ourselves
beyond the limits of YouTube and to make full professional films and series that we're really
passionate about. If you want to sign up for Nebula, you can get a cheeky little discount on doing so
by using my personal discount link at go.nebula.tv.com. That will give you 40% off an annual plan,
allowing you to watch Boomers and all of that other exclusive video goodness for just $3 per month.
That's so much cheaper than any other streaming service out there, it's basically a no-brainer.
Or if you don't want to add another monthly subscription to your budget, we've also recently
been experimenting with lifetime subscriptions which have proven really, really popular.
These naturally cost more upfront but give you access to Nebula and all the great new stuff that
we're making for as long as both you and the platform exist. Signing up using my personal link
really, really helps to support my work. I'd love for Boomers to be the first of many large-scale
documentary projects that I'm able to work on and, if lots of people sign up early,
then it helps to signal to the team at Nebula that folks are interested in seeing what I make
and will help me make the case for them to throw more time, resources and money my way
for some of the cool projects that I've got planned in the future.
That link again is go.nebula.tv forward slash TomNicholas. I'll see you over on Nebula and we'll
look forward to sharing the trailer for Boomers with you very, very soon.
Thank you so, so much for watching this video. I hope it has given you some food for thought around
AI theft and let me know your thoughts down in the comments. All that's left for me to do right now is
to thank my top tier supporters over on Patreon. Those supporters are Agent Maxwell, Alexander Blank,
Alan Gann, Amit Singh Paraha, Bill Mitchell, Christopher Cowan, Dickon Spain, Fiasco Linguini,
Gabriel Koch, Gary, Glenn Sugden, Jarabar, Jimmy Dunn, Lisa Yuan, Neil Zbildgaard, Paulius Edekus,
Richard, Richard Rappoon, Sergio Suarez, Sophia R, Strange Weekend, Yillamson, Zedzi Rees and Zoe Alden.
If you want to join them in getting copies of the scripts to these videos, my weekly blog,
the Friday Update, some early sneak peeks at stuff that we're working on and a bunch of other stuff,
then you can find out how to do so over at patreon.com forward slash Tom Nicholas.
Thank you for watching so much once again, and I'll see you in the next video.
