Yes, I'm very happy to be here and and you will see this is really much inspired by a lot of
work that has been done in this lab for in the last 10 years so I'm really excited to share
this formalism. So the first part will be a more like soft introduction of why I'm interested in
biology and how I think about biology-like design and why I think it's like a good idea to try to
formalize from a very very abstract perspective mathematical principles that underlie biology-like
design which is as I would like to emphasize fundamentally different than the engineering
we are currently doing and then the second part will be specifically about this goal assemblies
formalism that is a minimal formalism for compositionality of physical goals.
So okay so this is why I'm interested in biology and this is why I think it is an inspiring direction
to take when we think about the future of engineering and design specifically. So I will be continuously
in the boundary between science and engineering and design so like I try to always always one step here
one step there. Okay so one thing is the underlying natural philosophy so I think that these three
things that I will tell you will help to form an angle onto goal assemblies so this is another reason
why I try to emphasize these three angles of how we can approach the concept of biology-like design.
Okay so the first one is the underlying natural philosophy which I deeply believe in and it might be
controversial but I think it's also good to talk about it which is that biology is the most fundamental
science in an emergent universe which is which is our universe and it's because because biology builds
emergent phenomena on top of each other cumulatively so the most fundamental laws those that most likely
to generalize will be the convergent emergent features that that happen multiple times across biological
scales so if we end up looking at a totally new system for example an ecosystem of of AI agents I would
suggest that that biology is a better starting point than for example physics to understand such a new
emergent system so so in this sense biology is the most fundamental science in the emergent universe
and I call this the magnifying glass of self glass of information propagation because without selfish
information propagation you don't have this cumulative emergence you might have emergence very clear
emergence and separation of scales and all these kind of things in physics but you don't have a cumulative
emergence so okay so what are these computational primitives of of emergent engineering well in words I
would suggest that this is the three main domains we should focus on one is is cumulative selective
history dependence so how a very small fraction of complex objective objects are being selected in the
huge space of possibilities the second one is more inspired by metabolism but more generally how functional
complexes interact with each other combinatorially and the third one which I will focus on today is
hierarchical goal and competency integration so how we can integrate uh small competencies to form bigger
and bigger competencies and what are the properties of of such systems okay so number two is design um
so okay so you can be complicated in very many ways so so this is the this is uh uh the overlapping ruby
gold mag machines uh including those objects that occur uh in multiple ruby gold mag machines uh and uh zebrafish
um uh signal transduction pathway in in in its early development and the key pathways and how they overlap
so this is obviously mostly a joke but you can be complicated in very many ways complicatedness is not a feature of
biology um something else is the future of biology and what is it uh and when we when we do engineering
when we when we create designs why do I say that we don't really make biology like design we make engineering
like design and the reason we make engineering like design is because we cannot not categorize and that and and
we cannot not ask what for so what is the purpose of this what is the purpose of that and I would like to
suggest uh um to to designers and to engineers to try to abandon these uh inherent biases and try to um
focus on another domain of engineering which is of course um um needs a totally different conceptual
ecosystem uh but um but what is that ecosystem so the best way I think about it or I like to think
about it is biology is existentialist technology so uh what does it mean it means that uh that biology
doesn't use compressed models so uh doesn't categorize and doesn't use compressed models um um it uh it is very
very different when when you don't do multi-step planning but uh and you don't force the different
solutions into categories in the very first place so number two is the huge difference between theoretical
versus practical freedom of choice um and the number three is historical contingency and responsibility
so these these three are present in existentialist philosophy and also in the in in in biology in the material form
um okay so number three is recursivity so in in computation uh recursive and language recursivity gives uh uh uh
this huge space of possibilities that uh we can we can describe basically endless space of possibilities
um uh and product productivity and um um um it is key to try to understand emergent engineering system through
building blocks that that can be used recursively um so this has been talked about a lot right uh but the
key to this is that the building blocks have double rule uh double roles uh they can be both functions or
arguments or they can be both uh um um um you know in a more physical sense uh
uh the building blocks and and one that is using the building blocks i i i will i will very specifically
talk about this in in this goal assembly formalism so how should we proceed uh there are multiple um um
already um already um well understood domains where the condensation of these recursive building blocks are
are better understood one is language right so how symbolic city uh emerges into multiple steps
steps and then and the other is ai um so we can look at these these domains but generally i would like to
suggest this kind of meta factorization uh of of of a recursive modeling framework of emergent engineering
why i talk why i say meta factorization because it's a factorization of the theory
of or the general framework um and uh it is that there's the big picture which is which
is uh this uh structural recursive assembly of the of the of the final object there is the central picture
which is uh which is uh which is uh um as we as we will see multiple steps of composition and then
reduction composition reduction so it's kind of expansion reduction expansion reduction the composition
step uh it describes uh a combination of possibilities mathematically speaking a direct product of of the
the possibility spaces and there is a reduction step which might be a selection among those possibilities
or a dimension reduction in a more general sense and then the number the the third one which is uh um
the more microscopic one is the representational picture where you parameterize somehow
these operations of composition and reduction and they can be described all these three can be described
multiple ways um and i would like to suggest that we should try to figure out how to to formalize
these three separately and then put them together to um um form a coherent model of recursive um
emergent engineering modeling framework okay so here is the the the more crisp more well-defined
part of the of the presentation which is goal assembly formalism um so this is a holistic story
uh which means that it has been made holistically uh which means that it has been made holistically
but i will tell tell tell it semi-deductively which means that i would like to emphasize the
hypothesis uh that underlie the the the this holistic framework um first and then i will try to
explain what general features this um um kind of minimal and not fully mathematically formalized
framework framework has okay so this is the number one approximation which is that
you have you have one uh system that can achieve a bunch of goals uh lowercase g1 g2 and so on
and you you um so you you already observe that and there is another one uh in this specific example
it's also g1 that can also achieve a um a set of goals and the question is what happens when you
when you put them together in a very well-defined specific way right so um um this is uh uh these
capital g's i call goal variables this is just just to name these objects obviously these are very simple
very simple objects um and uh the lowercase g's i call goals and when you put these two together then
you have a complex object that some behave somehow um and um the question is can we describe this
this complex object that that behaves uh that that follows the joint behavior of these uh two coupled
g1s in a way that also follows the general framework uh of uh of a goal variable that can be later on
further integrated in this uh compositional sense um and so the simplest way this this can be done
is to assume that the goal goal achievable goal states of the of of the of this g1s will form
all combinations of those will form the state space of g2 and then within that phase space
the goal variables of g2 will be selected so the achievable goal states will be selected
and later on this will happen again and again and again and again so this tries to be a very
practical framework which means that i suggest that that this this transformation should be learned
so um so this this theta one one two symbolizes goal combination so goal combination makes the state
space of the of the higher level variable goal selection and potential goal transformation as those goals
might be transformed uh um as a consequence of the interaction between these two g1s
so this is this is a approximation number one why is it an approximation it's because obviously the direct
product product of all goal states of g1 and g1 is a very large set of of possibilities um and uh all
and if g1 and g1 are independent they don't interact then they will be the goal states of g2 as well
so the assumption is that somehow through their interaction this state space will be reduced to a
smaller set of states that are the goal states of g2 and that's a meaningful uh configuration space reduction
and if we iterate this step many many times or multiple times then we get overall a large enough
configuration reduction configuration space reduction to find those phenotypic global phenotypic states
that are functional or have non-zero fitness or and so on and so on okay so um so the other assumption
is that these goal variables interface only through goals which means that in this previous case
no other information is kept as you integrate to the hierarchy then the goal states at every given step
um this is a very important assumption and it's uh it's probably an over obviously an over
simplification in in in case of real systems um um but but i i would like to suggest that this goal
assembly formalism is is a core and then uh it is intentionally over simplifying on top of which you can
also add additional corrections um so this is a top-down view which is which is uh that that large
emergent design should be broken down to smaller emergent designs recursively so that the small competencies
uh the the small uh uh parts of behaviors in this specific sense of how these uh uh goal variable
combinations happen they can be learned effectively and then build up the system from that so these are the
two representations um um two visual representations um i i use throughout this uh through this paper um
which really helped me to understand how you can combine and and and and how a course draining can
correspond to uh a visual hierarchy okay so um what happens when you combine multiple of these goal
variables uh the idea is that the phenotype is encoded through this vertical encoding through multiple goal
composition rules as opposed to a horizontal encoding which is local configurations so the horizontal
encoding g1 g1 g1 g1 you might imagine these as cell states uh or in a in a in a more physical setting
uh uh spin uh spin configurations but what i would like to say is that instead of that we should focus
on a vertical encoding which is uh to encode the phenotype to this goal composition rules that are themselves
learned and then when you look at the phenotype this way it will turn out that the selected goal lineages
will represent the phenotype and also will uh take care of the internal robustness of of the system
so so here's an example this is a super exponential configuration space reduction
in terms of the hierarchical depth um so so you have four possible states for each variable or m m in
general m possible states for each variable and you combine two such uh um um two set systems and then in
the combined system you have m m square um potential states from which you choose m to be the goal states
and then you do it again and again and again and again and again again and in this specific case where
you select m out of m square you get a double exponential reduction of configuration space
uh in in the depth of the hierarchy but generally if you select a sublinear number of goal states at
every every specific step you get a super exponential configuration space reduction
so this is just an illustration to um to build intuition um and um and uh to see what kind of uh
systems we can build from from the same building blocks
so another important feature is uh that these goal assemblies in this hierarchical
uh uh in this hierarchical formalism they reproduce uh a genotype phenotype map statistics which are
generally observed across different uh toy models of phenotype genotype genotype phenotype maps but also
uh input output maps in uh in artificial neural networks uh which is the parallel uh distributed rep
representation of phenotypes by genotypes so there are a few phenotypes that are represented by many
genotypes and there are very many phenotypes that are represented by few genotypes and this is
very generally observed um and it turns out that when you have a hierarchical system like this
uh and you assume dependency cascades which means that uh if you go from top down if you find a variable that
doesn't depend on the variables uh um under it then the whole subtree is is neutral meaning that they
they also don't matter in the global um um global outcome uh which is represented by the top node
so this i call dependency cascades and this obviously has an exponential amplification effect
and that exponential amplification effect um uh generally produces uh parallel
uh distribution of uh distribution of of uh of the representation of phenotypes by genotypes so this is a
very general mechanism not just for goal variables but general hierarchical systems uh where these
dependency cascades take place i haven't seen this uh uh articulated in the literature but uh
uh uh um it might be the case that uh that i'm not uh aware of it um uh but specifically for for
this goal assembly formalism this is true as well can i ask a question yes yes uh so so when you combine
two goals uh are are you considering the goals from the same agent or from different agent because for
different agent you might get something like the the collection of the goal collection the goal or
collected uh a combined goal might be contradictory to the individual goals exactly exactly i don't assume
anything whether it's the same agent or not the same agent i what i have in mind is a very practical
setting where you measure the possible outcomes the possible um goals or small volumes of possibilities
that the system achieves under very different um settings initial conditions and and and uh and
experimental conditions um these are the the lowercase g goal states so you you you measure in a specific
case a collection of cells uh or any any uh collective in in in collective behavior um you you can you can
name multiple systems where you can actually carry out this this experiment very well and then
then then you combine and then you try to use these goal states and only these goal states to understand
what are the goal states of the combined system of in this case 2g once and uh you try to
approximate as approximate this learn this combined behavior by only using the goal states of of the of the
the input variables um you try to learn the goal states of of this combined system and uh um the assumption
is that if you break break down the the many steps to the the whole system in in enough number of steps
so that these little combinations are small enough that they can be learned and this uh this and and
obviously also factorizing the overall behavior um um good enough then um then this framework uh
might help understanding how the global um um what what the global goal states are in this combine in
this like hierarchical systems um and also guess new combinations so what if you what if you put this
and this and this and this together but if you put this and this and this together so so i imagine these
details as a as a library of uh of of of uh composition of collective behaviors then the when the collective
behaviors are well uh approximated as as goal directed
we did did it answer the question yeah yeah thank you no please please ask question this is the first
time i'm talking about this whole thing so uh um um i very much appreciate if uh if uh you help me with
this yeah so so the goal here is uh it's more like does it have some like uh can can you consider that
as a reward function or or you didn't specify that it's a it's a um a state or in the continuous
systems you can imagine a small um volume in the in in in configuration so you want to go through that
so it's it's it's a it's a subset of configuration space and this subset is assumed to be um
um composed of of of of smaller smaller subsets yeah interesting and obviously the point is that um
that they can be attractor states too but they can also uh be um representations of achievable goals
of of uh cognitive agents which means that under new perturbations they can also reach reach these goals
uh but it's kind of intentional not to specify what the goals are because uh because then the the much
of the attention is about uh what goal states are so i try to not talk about that at all or as me as as
little as possible okay so so when but uh in in real real world uh the the collect uh the the combined
goal it's uh it's highly dependent on how you combine exactly exactly yeah like if you consider
game theory then it's uh it's quite hard to solve but if it's just like multiple loss function in
machine learning is it's quite easy exactly exactly it's very much uh um dependent on how you combine
so one specific microscopic implementation of this um i call this a cognitive framework
uh could be coupled hoffield networks and the hierarchy of coupled hoffield networks when you
when you put two hoffield networks together you can put them together very and couple them very many
ways right and and the collective behavior of what are the attractor states that stay in the system and
what are the basins of attractors and how they are transformed uh through the interaction will very
much be determined by how the coupling takes place so the coupling is must be well specified just
as well as the system as the g as the underlying goal variables themselves
so in this sense if you put two g ones together uh um you in in this specific um description this theta
should also depend on how these two two ones are combined to a two very much interesting thank you
so well so so so so this is the framework but the the the um the whole point of making this framework is
to point out evolvability features how they enhance uh the um the ability to find useful new
structures in the huge space of possibilities and so i divide the these general mechanisms of evolvability
in a general sense so not only in an evolutionary sense but in a general sense uh to two types parametric
and structural and so so the uh um and within within each uh there are two two two mechanisms so
number one which is kind of the most microscopic in terms of changes is a goal state gradient
back propagation
which can be understood by looking at this graph of how the goal variables are being combined hierarchically
um and understanding that as a computational graph of of of a coarse graining approximation of the collective
behavior of the whole phenotype and then you can if it's differentiable which is obviously a
whole field network for example as is in this in the standard case is not uh um but if it's if you can
differentiate you can differentiate uh back through um through this computational graph and um uh what you
get is a relationship between the global change so how the this g4 variable which is assumed to represent
the phenotype the global phenotype or the full the whole object uh uh how the change of that and the goal
states of that relates to the the change of the goal states of the lower level variables uh including the bottom
variables g1 and um um so this is one one thing you can get out of it right so how the the different
changes changes back propagate through to the system from the global scale to the local scale but now you can
also get another thing out of it which is if you uh assume that select that the different phenotypic traits
are coupled so you can imagine that um at the at the g4 level you have a bunch of phenotypic traits
um um and you apply some selection to the phenotype so this is specifically from evolutionary theory where
definitely where the different uh phenotypic traits are generally coupled and when you select on one you
might uh end up having or changing another one um or many other ones and this is described by uh this um
um um the c matrix uh which is the uh this uh phenotype covariance matrix and it turns out that you can
also relate the phenotype covariance matrix at the top level and the bottom level through this back
propagation um um so this might be a very useful um so this is another thing i i haven't seen
in and anywhere else but that might be applicable to more general uh coarse graining
approximations hierarchical coarse graining approximations of this kind
and would obviously the benefit would be to
i cannot say more than than what the benefit has been in in in in artificial neural networks
okay so the the second one uh um which might be very intuitive from the very beginning
is this hierarchical decision making and memory retriever um so this might be a a trivial
evolvability mechanism uh but also a very important one uh because that's the whole point of having goal
states and having um um um these these target states that are reached under different perturbations
to um um to avoid avoid the right the rest of the states um so
you one specific phenotype is represented by one specific goal uh but uh the system itself contains a
hierarchy of latent goals and so selection between the late hierarchical selection between the latent goals
is a is a very significant reduction of configuration space compared to all possibilities
so only already having the hierarchy of latent goals that has been either encoded by past selection or
or uh to some other mechanisms um in particular it might be the case that new goals uh emerge
not not through direct path selection but as as an as an emergent
uh um um new potential goal um which might be a perfect example of induction um of of these new goal states
um um so this is this is another mechanism of evolvability avoiding um um others achieving other states and
uh instead focusing on this hierarchical uh retrieval uh retrieval of of uh of goal states
and decision making among among those goal states to arrive to a global phenotype
um okay so so the other side is structural mechanisms of availability uh and these might be more
more straightforward um and more intuitive consequence of uh of uh this um um um um hierarchically modular um
structures and this approximation of this hierarchical model approximation to any any phenotype
uh which is that which is which is which is reuse of models across chaos um so in this specific example
one might try to imagine how to guess the goal states of uh of of of of the of the right
object based on the goal states of the left left object
and generally speaking how to guess those objects that haven't been observed or measured
but are in in kind of the neighborhood of of of the existing possibilities
and then when you extrapolate this to longer scales you can try to understand
uh um in in for example a computational simulation setting uh where the actual phenotypes that exist
at a particular moment of time or has been existed throughout the history of the process how they
occupy the the space of possibilities and what kind of like simple dynamical models can reproduce
that specific subset or approximately that specific subset
um okay so this is the last slide which is um um
which is a kind of a philosophical ending but i think also extremely important which is that when you
do this um hierarchical modular decomposition in in such um evolutionary and learning setting
uh you it is very important to uh you it is very important to uh be clear about about what the modules are
but they that they correspond to what are they the units of and so i would like to tell you at least five
uh different types of units um and i think it would be very useful to try to relate these uh in
uh hierarchical decomposition according to these different definitions of what the units what the modules are
and uh try to relate these to each other um one is is the units of selection um i just i just tell you
all the all the five and then maybe um we can we can discuss later if uh if um if we want to discuss
any specific two or or in any combination of them but so units of selection in an evolutionary setting
uh so this is uh what the left uh um figure tries to represent which is that the g2 the selection on g2 might
happen in at least or can be factorized to three different sources
um and they might contradict to each other and uh this is the core of
uh of a conflict of interest between levels in evolutionary theory
it is very important in an evolutionary setting when we don't design these architectures but we
have all of them to talk about uh units of selection then the other is units of competency
which here are represented by these goal variables
which might be different than the units of selection in a general setting
the number three is the is the units of dimension reduction of some behavior
so if you if you try to imagine this as a as a top down as i said the top down view which is that
you try to factorize the behavior and try to do effective factorization effective approximation of
the global behavior to this hierarchical modular decomposition
this dimension reduction might again lead to different modules in this hierarchical modular decomposition
uh number four is physical structure right so you can imagine like coupling strengths or in any
other way physically measuring what are the what are the the modules of of such a global uh phenotype
and the number five is uh is is the historical contingency right so what are the stepping stones
that have been used and also possibly or likely modified of course but what are the stepping stones that
have been used uh to build uh build the current objects and so these are five different uh concepts of
uh of modules in a hierarchical modular decomposition um and i think it would be a very productive
conversation to to to try to relate to try to relate these five to each other in uh in um in specific
circumstances or or more general uh formalisms
um okay so um just to relate back to the to the very beginning of of the of the presentation uh the
emergent universe is surplus all the way down in this sense um and with that uh thank you very much and
the first preprint is is on archive uh with probably a crisper explanation of of of of these ideas
so thank you very much and uh i'm happy to discuss yeah thanks so much uh very interesting um anybody else
questions first
oh i do i do have a uh question thank you for the great presentation uh so um one thing i noticed uh in
in your in your slides is that you have these pictures where the modules are the capital g's
right they they are like nicely demarcated and when they combine they still have the sharp uh boundaries
in biology presumably these boundaries are fuzzier and overlapping you know you find this in metabolic
pathways in brain networks even in artificial neural networks uh because uh typically they follow
what's known as sub symbolic computation you cannot neatly now put the boundary around symbols that
they're using so much is or like overlapping and so on and so forth do you do you um think about that
in your framework uh and how do you think it might affect uh i think it's a very good good question um
i think about my framework or this specific framework uh not as a fully defined mathematical formalism
um so as a first as as a my first transfer is that i'm agnostic to that uh obviously if there is
overlap uh then you might try to exploit that structure to be more precise right so it's all about
it's all about what what are the structure what is the structure that you can exploit that you already know
um um so i haven't thought about uh this this setting i what what i have in mind had in mind is uh
is an x is is this is this experiment where you where you uh try to observe from this goal directed
point of view what are the different goals a specific collective of of of of cells or elementary
components can pursue can achieve under different conditions and then you start to combine these
hierarchically and and you try to um come up with a minimal formalism where you have the
have a chance to to learn the composite behaviors hierarchically and potentially arrive to
to to a well to to have a good approximation of the global behavior
which is obviously a guess right so that's why i'm uh um and and experiments will will will
will decide if this is a useful framework or not
anybody else
i was hoping to uh ask a question about um earlier in your talk you mentioned uh the genotype
phenotype uh mapping and i was just curious what what have you have you done some sort of modeling
of that in in any kind of detail and if so what what sorts of uh yes yes so so i didn't do i i i did
some analytical calculations um they are also also in this preprint uh they are the the most boring part of
this spread print or maybe the most interesting depending on the point of view but um um
it turns out that
you can have i go back to that that slide uh first
so you can have two representations one is the distribution of the number of local variables
or genes um this the the bottom squares here
that um that that are important in determining the global the top variable right so so here is is two
and two four six eight right so it's the distribution of of the number of those variables
um and so that's another that's that's one distribution and there is another distribution
uh which is the the number of genotypes that represent a phenotype that i have been mentioning
so these are two distributions and they are uh one can be transformed to to the other so in if if the
variables are well defined so for example let's say the local variables are binary variables
or any other well-defined variables then there is a clear mapping between between these two distributions
um it's just a change of variable in a probability density function and um and um intuitively it's uh and
not just mathematically also it's an exponential transformation because um because the number of
possibilities is a product of of the number of states of each of these local variables that matter
um um so so it's an exponential transformation of the of this random variable uh and it turns out that
if you have a very narrow uh distribution of uh of the number of variables you that this exponential
transformation of the underlying uh um um random variable makes the genotype phenotypes that is
very uneven and parallel like uh in a very broad range uh over many scales so what i did for example
in in this specific group is is is i uh i assume that uh um the bottom the the number of variables is
represented by by a poisson distribution which is which is a pretty narrow distribution uh and even in that
case this exponential uh transformation uh that that maps that distribution to the genotype phenotype uh
statistics distribution that we're interested in uh will be a parallel distribution with with some kind
of exponential cutoff in the end but the exponential cutoff happens uh where it doesn't matter meaning
that you we already covered the whole genotype space um um so so um yes sorry so so what i was trying
to understand is um what exactly do you mean by phenotype because at least on the biology end and so this
is why i'm asking like what kind of simulation or whatever you're you have in mind because in biology
there are some phenotypes that are very close to the genetics so for example there are properties
of a protein which are encoded directly by the genetic sequence great and then there are other
phenotypes ranging from a large-scale organismal anatomy to behavioral traits to you know all kinds
of stuff that is many many steps away from from the genetics and actually what's important is that
those steps are not just complexity there's actually a lot of uh intelligence and problem
solving built into turn to turning the genetic sequence into into what people then score as
phenotypes so i was just curious what kind of phenotype you know what what genetic representation
are you looking at are you looking at the biology or or something else and how far you know what
what how how directive and encoding are you thinking for for what you're calling the phenotype
i uh generally assume that there might be this transformation delta g at every single step
that transforms the goals so it might be the case that the global target state or goal state
is not very close to any of the local goal possible gloss goal states and understood it can be far but is
it in the same space even because typically the things we measure as phenotypes are not even
they're not in the same space as as what as the genotype at all yes so so so the g so the g2
already tries to be a different space uh and uh um i think the underlying assumption that these
transformations gradually transform the spaces and uh um instead of assuming which might be a good may
may might be a bad approximation for a specific case instead of assuming that those are separate spaces
the the suggestion is is to try to do such a small step in this compositional sense
uh that that that the spaces can be transformed and the the higher level spaces can be approximated
from the lower lower level spaces instead of being separate
