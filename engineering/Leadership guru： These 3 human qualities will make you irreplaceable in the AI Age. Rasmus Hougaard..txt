Welcome to Mindful AI, the podcast where we explore how to create AI that is beneficial
to humanity, ethical, and promotes human values and flourishing. In today's episode,
we interview Rasmus Hurgard. Rasmus is the founder and managing partner of Potentia Project.
He was nominated by Thinkers50 as one of the eight most important leadership thinkers in
the world today. In this episode, Rasmus shares research and real-world examples that reveal
how AI can actually amplify human qualities and create more compassionate organizations.
We also discuss how AI acts not just as a tool, but as an active agent reshaping the way we approach
leadership and human resources. If you find this episode insightful, please subscribe to Mindful AI
and leave us a review. Your feedback helps us bring more of these important and meaningful
conversations to you and others. And there we like our recording.
Okay, here we are. So welcome, Rasmus. Thank you so, so much for accepting to be our very first guest
in the Mindful AI podcast. What an honor. So I'll go through your official bio and then we will get
started with the conversation. So Rasmus Hurgard is the founder and managing partner of Potentia
Project. He was nominated by Thinkers50 as one of the eight most important leadership thinkers in the
world today. He writes for Harvard Business Review, Forbes, Fast Company, and Fortune. He's a sought-after
keynote speaker and leadership developer who coaches and supports C-suite executives at global organizations
such as IKEA, Accenture, Citi, and Unilever. Rasmus is also a co-author of the best-selling book,
The Mind of the Leader. How to lead yourself, your people, and your organization for extraordinary
results. And also compassionate leadership. I'm impressed, Nat. I'm very impressed.
How to do hard things in a human way. So jokes aside, it's an absolute honor to have Rasmus here.
Rasmus, for those who already listened to episode zero, we had a chat, myself and Martin. Rasmus is the
reason why we connected. So we used to work under Rasmus leadership in the past with Potentia Project.
So that's how we actually met myself and Martin. So welcome, Rasmus. Thank you so much. And yeah,
look forward to the conversation. Over to you, Martin.
Yeah. First of all, is there anything you'd like to add to the bio or anything about your background
that we missed? Yeah. Anything that maybe the listeners, you know, something that is not your
LinkedIn in your Potentia Project website that people would actually not find out about you on
the web. Perhaps something more personal. Yeah. The human side of Rasmus.
Only more personal would be that I'm, let's say, a meditation practitioner, a Buddhist practitioner for
30 years. And that's how Martin and I met. And Natalie, I believe that's also what somehow
graduated into Potentia Project. So the whole wisdom tradition, leading and doing long-term retreat
is something that has been my biggest passion throughout my life and also informed the work
that we'll be talking about today. So that is definitely a big, big, big part of it. And I would
say Martin has been a very good, close friend and brother in that journey for what, 15 years at least?
something like that? At least 2010. Yeah. So 15 years. Yeah. Yeah. So, interesting. I just recently
had the opportunity to give a presentation on this idea of mindful AI for 3M. And one of the ideas that I
introduced is this possibility of actually using AI as a way of strengthening some really human
qualities. So potentially using AI to help us raise self-awareness and those kinds of things. And so
you've written a couple of articles for Harvard Business Review, and you touched on this subject on
how to use AI to kind of augment leadership and introduce those kind of human qualities. So could
you elaborate a little bit on what's going on? Yeah. Very happy to, and very passionate about it.
But the preamble to that is when ChatGPT was launched and it was clear that AI was out of the box for the
mainstream. I was super scared. Like I was literally deeply, deeply skeptical. I thought that AI was going
to lead us down to dystopian, robotic, mechanical, dark future where people at work would be sitting in
dark basements being told what to do by AI. And while there is a real risk that it will also go that way,
what we have found through our research is that the exact opposite is also possible. So our purpose is
to create a more human world at work. And AI can become a real amplifier in that journey in so many
different ways. And it's been deeply, deeply fascinating to hearing the stories of how companies
are actually using AI to create more human organizations, to create better leaders and have
lots of great stories that I can share and share in that regard.
Yeah, I think that's a great place to start. Because I guess AI is, like you said,
it's out of the bottle now or the box, Pandora's box, and it's not going back in. And every single
company needs to relate to the AI. So it would be really interesting to hear some of the success
stories in relation to ethics and human values to share some of them to share.
Absolutely. I can start with one of them. And for all of these stories, let's use the analogy that AI
has the potential to become like an exoskeleton, as in this contraption we can put on that makes our
muscles stronger. AI can do the same for the mind and the heart of human beings. I'll tell one story,
which was one of the really inspiring for me was Ellen Shook, the chief HR of Accenture, one of the
biggest or the biggest tech firm in the world, probably, who shared that she would use to spend
like one hour to prepare for a performance review conversation. So 45 minutes to gather all the data
from the different systems, 10 minutes to structure it well, and then the last five minutes to rehearse
what she would say. Now with this AI performance review coach, she'll literally just press one
button and out she gets a report that she'll just skim through. There's all the data there and so on.
And then she will spend the rest of that one hour to ask herself much, much deeper questions.
Where is the person at in life? Where are they at in their career? If she really senses into her
iteration, like what's the next developmental stage? And a really important question, how does she want
people to leave that conversation? What is the feeling, the emotion that she wants people to leave
the annual review conversation with? So it's a real shift from managing people and tasks to suddenly
leading an experience, leading emotions, seeing humans as the whole humans that they are. And this
is just a simple basic performance review AI coach. And that's just one example of how incredibly powerful
AI can be to augment and support our leadership to be more human oriented.
Great story. Thanks for sharing Rasmus. So what I'm hearing here is, and having worked for Accenture
myself, I remember the performance review process could be very, very lengthy and cumbersome. And I
think it's much shorter now, you know, but anyhow, so saving time with the data analysis, which is actually
one of the key strengths of AI processing all the data, and then using that time instead of massaging
the data and, you know, running reports and everything to reflect on actually what's going on here, what's
the situation with this individual and thinking more about the human aspects. So that's a beautiful example
of how can AI can be used, you know, in a very mindful and useful way. As you mentioned before, AI can,
and there are still those two scenarios, right? I think even researchers, they're very divided.
We have the very optimistic note talking about the golden age, leveraging AI, and we have the more
pessimistic who have made the realises in between, if you could maybe classify that way. And you mentioned
that AI can amplify, can be a big amplifier. So in terms of using AI, make sure how can leaders, if there is
an answer for that, how can leaders ensure that we are using AI in an ethical and responsible manner? Yeah, given the
potential, you know, slight different directions that we could go, what are your thoughts around that?
Yeah. So how leaders can make sure that we use AI in the most ethically correct way? They can't. Only companies can.
And preamble for that is, you said AI being a tool that can amplify, and that's true. That is what AI is. It's a tool that can amplify, just like a hammer. And a hammer, we know, can be used for building shelter. So we have roof or a head, or it can be used to knock someone down the head and do bad things, just like any tool. Though the difference with AI is,
AI is, it's not a tool. You can use it as a tool, but in its essence, it's more of an agent.
If we look at tools, the way tools have been designed up until a few years ago, they were, let's call them passive tools, like a hammer, a shovel, an email, whatever.
All of those things were just sitting there and waiting for a human to tell it what to do, or to do with it what you wanted it to do.
AI, while it is reactive, as in a passive, you can use it in a passive way, it's also an active. Anybody that has co-pilot will know that it's already reading your emails, it's recommending what you respond, it's prompting you to do things that you wouldn't have thought about.
So it's an active, it's an, it's an active agent rather than a passive tool.
And that's why the responsibility for using AI in ethical ways is actually not very much up to the leader, him or herself, because they have little agency in changing the agents.
Rather, it is, of course, the tech departments of companies, but more so it's the HR.
What HR needs to make sure that they do the first, like most important is, of course, all the ethical considerations, getting all the consent and having absolute 100% transparency.
I talked about Ellen Shook and Accenture before the system that they've built, you know, when I talked to her about, I was like, what do people think about this?
And she said, well, people actually have 100% access.
People can, before she pulls her data, the person she pulls data on has the same access to look at that system as she does, and also has the ability to remove data from there.
If they think that that's the right thing to do so transparency is 100% important.
If we don't have that, nobody will trust an AI.
And I think we should learn to trust AI because it has great potentials, but it will require incredible collaboration.
So it's coming down to HR more than anything else that they do it in the right ethical, transparent data privacy considerations way.
Thanks, Rasmus.
I really want to pause, shut up and give a chance to Martin to jump in and ask a question because I'm sure you have like 10 questions in his head.
But just based on what you said, Rasmus, if I may, and I'll zip after this.
When you started, I thought that, ah, I know, I guess, you know, when Rasmus is going on, because I think that's probably my projection.
AI can only be as ethical as the people behind it.
And I was thinking about the tech, you know, the tech developers, solution architects, project managers, design and developing AI.
And that's one of the areas that I think we look here into the Mindful AI podcast.
We want to talk to the other scientists and machine learning experts, because until we have robust, solid governance frameworks in place and legislation, which is still catching up.
Who is actually in the front line, they are making decisions.
These people are making decisions, right?
But for my surprise, you mentioned HR, which is very interesting.
So, and how you position AI being active versus a passive agent.
That's very interesting.
Just thinking out loud.
I'll zip now.
Thank you.
Over to you, Martin.
I'll just, I'll just one comment on, which really makes clear how serious I am about this.
AI is two things.
It is an amplifier of effectiveness.
And that's a tech, like that's just something that tech and IT people can take care of.
That co-pilot is installed and trained the right way so that people can save time.
But the much more important is all the areas where AI serves as an agent in all the human processes.
That is 100% an HR function.
And therefore, AI functions in the future are already used today.
Have to really, really, really educate themselves and become experts in how to design HR functions, leadership development functions, culture processes through AI.
Because that is by far the most powerful way that you can secure.
You have the right culture and right leadership behaviors in the future.
And yeah, now they don't, they don't have to submit on my account.
I, it is true.
I'm storing like a backlog of comments and questions as this progresses.
So I, one thing, one thing you mentioned in, in these articles is the capacities of awareness and wisdom and, and compassion.
Um, and so, so one of the things I've been just thinking about is, is if these are things that, um, AI could actually be helpful in us developing.
And I, I've been thinking, for example, it would, I would, if I had a, an AI that received the same kind of sensory input as I do, heard the same things, saw the same things.
And then, uh, watched my behavior.
Maybe that AI could point out that potentially I have a unconscious bias to, I don't know, obese people or elderly or people of other ethnicities, whatever it might be.
And, and it could actually confront me with those things and say, Hey, look, you have these unconscious biases and that could then help me develop more awareness, more self-awareness and more.
Um, so do you, do you agree with that kind of function for AI in the future and have you seen any seeds of that kind of thing?
Yeah, two answers to that one is yes, AI can actually do that.
And let me give a, an example of a company that's doing that well to those qualities that you talk about awareness, wisdom, and compassion.
I'll come back to those, why they're so important and no AI can ultimately not help us to train those.
So it's a little bit like the exoskeleton while it makes us stronger.
When we take it off.
We're not stronger anymore.
So for that reason, AI doesn't really ultimately make us more of that, but it can alter our behaviors.
So let's come back to the example CVS, which is the, I believe is the largest pharma firm in the world have developed AI for many of the leaders and, and client facing leaders.
Which, and I can't share too many details, but imagine a meeting that's happening online, you have an AI agent that's sitting and analyzing the emotional sentiment of the person that you're talking with.
So let's say Martin and I are having a conversation, I may not be the most emotionally intelligent or empathetic person.
So I may not pick up on some of the words that I'm saying is actually making Martin feel uncomfortable, but because of, you know, our emotions showing up in the facial expressions and so on, a good AI, and that's pretty much any AI today has more empathy and emotional understanding than most humans.
We'll pick up on that very, very easily, and it will trump me with a little like scripts down in the screen that Martin can't see, but that I can see, hey, Rasmus, you may be aware that what you said before makes Martin go a little bit in defense position, or it just made him sad, or he's upset.
Here's, here's a recommendation for you to say the following, and then with all the algorithms of empathy and emotional intelligence that AI, like, objectively does have.
It can help me to moderate my behaviors to make sure that Martin feels better cared for.
So that's an incredible, I mean, I find that just deeply fascinating because we know that there are many leaders that are not emotional intelligent or very empathetic.
It's very hard to be a leader, we should not point finger at those leaders, not all human beings have those skills in the same amounts.
So it's not about, are you a good or a bad leader because you have those skills or not?
No, it is how can AI help you to develop more awareness of those areas of your leadership and AI can 100% do that.
That's amazing.
The three areas that you talked about, Martin, awareness, wisdom, and compassion are indeed the three core ingredients for leaders in the future.
We did a, the first study we did was in the age of AI, where things will be more automated, more robotic and so on.
What's the most important qualities for leaders?
It was indeed awareness, wisdom, and compassion.
Leaders with higher awareness, wisdom, and compassion have employees that have, and I'll just throw some numbers, 97% higher trust in company leadership, not just in their own leader, but in the company leadership, which has the ripple effects from peer review studies finding that product quality, financial performance, many, many other things for the company is increased significantly.
And there's a whole hoax of other benefits that came out of these leaders as rated by their employees.
So it's a real powerhouse for leaders to up their game on those areas.
And therefore, the other part of the equation of AI and leadership, apart from using the, let's say, the tech to help me be more emotionally intelligent when I'm talking to Martin, is how do we help me?
How does HR leaders help each individual leader to be more aware, more compassionate, and more wise so that they can bring that into the leadership in a world that is more robotic?
So how do you train those specific qualities?
I guess that's not necessarily related to AI, but it seems to be really important in leadership in general.
And, and I guess it might be becoming even more important in the age of AI.
So, so how would one, one go about, is this great?
I suspect you know the answer, Martin, but I suspect you know the answer, Martin, but I suspect you know the answer.
No, no, no, no, no, no, no, no, no, no, no, no.
Yeah, so there are the, the, the, the, the core of the study was really to find out what's the most important leadership qualities and how do we augment ourselves with AI?
The three most important leadership qualities are awareness, wisdom, and compassion.
The question is, how do we then bring them into play with AI?
And when it comes to awareness, the role of leaders in the future in the realm of awareness is to be excellent in mastering context.
Human leaders must set context and let AI deliver content.
And humans in the future will not be delivering content anymore.
It's just a matter of years.
It'll not be a thing anymore.
So humans need to be really excellent in setting context.
When it comes to wisdom, human leaders need to be really good in asking the right questions to the right things and let AI provide answers.
And when it comes to compassion, human leaders need to always check with the heart.
What is my intention for the person or the people that I'm with?
And then leverage the power of the algorithms of AI to make sure that our behaviors or our intention is translated into right behaviors.
As an example, I had before with me having a conversation with Martin.
So that means it's not just awareness, wisdom, and compassion, but it's also the implications of that, which is to be good at setting context, ask the right questions, and checking in with the heart all the time.
And then we, in the study, we looked at what are the underpinning mindsets.
So now I'll just give you an exhaustive list of 15 mindsets.
To be aware and master context, leaders need to have adaptability, self-mastery, equanimity, presence, and clarity.
And to do the good at questions.
And wisdom is about critical thinking, beginner's mind, selflessness, humility, and integrity.
And finally, to master the heart and have great compassion is about trust, courage, resilience, purpose, and emotional intelligence.
So those are basically the three foundational qualities and the 15 underlying mindsets that we see leaders in the future need to master if they want to be relevant and good in the age of AI.
Now, that was a lot of talk.
I'll just shut up.
I have five.
I think, sorry, before you go, Natalie, I just want to say we'll extract those 15 from Rasmus and put them, I don't know, in the comment or the description of this episode so that, yeah, because my brain isn't AI augmented yet.
So I couldn't keep track of it.
The business review article in, I think it'll be coming out in early November, so you can also make a link to that if you want.
Yeah, we'll definitely do that.
We'll link, we mentioned already a couple of articles.
We'll make sure that they're all linked in the episode description and all of that.
Sorry, Natalie.
No, no, no, not at all.
Oh, wow.
Two things that, two questions that I can still remember that I didn't lose as listening to Rasmus, one was around, which is really the tagline of this podcast, how to advocate for human values in AI.
So one question that I had for you before, but now is actually evolving here, if we were to train AI, as you know, AI models can be trained or whatever, I know, information we're putting, it learns and goes beyond what programmers actually understand how far AI, you know, the AI models are going.
So if we were to train AI to learn core virtues, core human virtues and, you know, characters, strengths or virtues, however we want to call, you know, some of those mindsets, you mentioned courage, integrity, and so on.
What would be a good framework to use?
And I think we mentioned before that Martin Salomon had put together, as a result of his research, you know, the 24 universal character strengths under the six virtues.
So that's one question.
And another question that came to mind, and maybe you choose, Rasmus, which one would you like to answer?
It's around decision making, because AI is making decisions right now in sectors like education, government services, insurance, and so on.
So, yeah, so I think it's kind of related to that.
So those human values or mindsets, how can we actually embed those?
Because decisions are, you know, we have the human in the loop, you know, Stuart Russell, which is one of the researchers in the AI field.
He's a big advocate of having humans in the loop when a big decision or a crossroads is met.
But, you know, smaller, simple decisions can be made by AI.
So, yeah.
So how can we enable AI with those mindsets and human virtues?
And if we were to do that, what do you think, based on your extensive knowledge, what could be a good model, you know, in your framework?
Yeah.
Yeah.
I don't think that there's one model or one framework that's the right.
I think it's important that different AIs are fed with different synthetic frameworks, as in you feed information into an AI and say, this is, let's say the AI freedom to choose based on the context with which it is asked.
And I think it's also very important that there are actually different, like, by nature, different DNA of AI out there.
If you take and ask the same, as you do with ChatGPT, you get very different answers.
And it is us as humans that need to learn which AI to go to for what kind of questions.
If there was just one AI that was trained in all the same things, we would all become one big, horrible echo chamber.
So I'm not a fan of that.
Having said that, when it comes to training on emotions, I think the examples you had are great.
Paul Ekman's work on the universal emotions, I think would be a fantastic starting point.
Thank you.
Um, yeah, so, and, and just tying onto that one, one thing that, um, you hear a lot is, is how important it is to develop ethical AI and, and, you know, obviously it is.
But it's very, very seldom that you hear, um, um, um, people go into any detail as to what they actually mean when they say ethical, it's like, it becomes this little placeholder.
And then everyone is, is, um, saying, yes, yes, it needs to be ethical, but there might not even be agreement.
But, um, so, so just as for me as a, as a really pragmatic definition of what is ethical is, is, you know, not harming, uh, people and, you know, contributing to, to, to wellbeing and flourishing.
So that's, that's like the, that's the basic, but then, uh, on top of that, as humans, when we do that, we need to, like you said, we need to check our intention.
Um, so intention is really key in, in relation to ethics.
So if, for example, if I, you know, I give you a present, but if my intention is to manipulate you, it's not ethical, but if my intention is to make you happy, then, you know, it's ethical.
So, so we have it, we have the intention piece.
And then the final piece is, is the wisdom and the clarity, because, you know, even if we have good intentions, if we lack the wisdom, we just tend to mess things up.
So that's a long, for example, to my actual question, which is, um, uh, can we, so the intention and the wisdom part is, is that something that we can convey to AI?
Do you think, or are those, uh, something that will remain in the human domain?
Um, I don't know, clearly we can convey that to AI.
It's just, you know, AI is nothing but what we train it to be.
And granted it does get more and more complex and we'll need more and more training as models grow bigger and bigger.
Um, but the seeds that we put into, into AI, the way we train it determines how it responds and how it, how it reacts with us.
And it is very, very important that AI is of course made with the right ethical considerations, like should never give advice on, let's say how to take a life, which it, at least those models that I'm working with, they just refuse to go there.
Um, I actually had a really, a terrible situation.
I was working at an animal shelter in India for a while.
And it was, uh, a, a, a little monkey that had, uh, been, uh, electrocuted by, uh, uh, electric masts, a fallen down.
It was still alive, but his arm was dead.
The doctor didn't know how to take it off.
They didn't know how to like, they couldn't find any drawings or anything.
And I thought, great.
I find answers to everything on chat GPT.
Um, but it simply wouldn't give me, even though I know it has access to those kinds of things, it wouldn't give that.
That to me is ethical, even though it's, of course it was super annoying.
Um, so I think it's just very, very important that we as humans program it in these early days of AI in race that we wanted to function because it is shaped.
It's mirrored on how we shape it.
And as with any other baby that grows up, they will start to have a life of their own and the same will happen with AI.
It will be harder and harder to control because the models are bigger and bigger.
So the, the, the, the first seats are the most important.
Hmm.
I think the, the, the interesting question, at least in my context is, is, is also when companies or organizations, institutions start to develop their own AI based on already existing AI platforms.
Um, how do they create the ethics that they want in there and this is something that we talk to a lot of our clients about when they start to adopt, whether it's co-pilot or, or, or, or, or chat GPT enterprise version.
Like, how do they train it to have the right values, to have the right ways of giving feedback, the right culture and all of that stuff.
That's super, super exciting.
Yeah.
And I mean, it's, it's already, um, one really basic conundrum that's arisen is that, you know, we train these by necessity, we train these large language models on copyrighted.
And then we have lots of artists and musicians and, and so on, it's feeling that they have their rights being violated.
So, um, so we're causing harm to potential harm to, to those groups of people, but we're bringing potential huge benefit to, to other groups of people.
And, and that's happening right now.
We, we can't train those things without violating, uh, people.
People's compromise.
Impossible.
Impossible.
Personally, being the author of many books and having, giving tons of talks and all of that, because it is accessible for AI is impacting the answers that AI gives.
I'm very happy about that.
I may lose money, but I'm very happy that our thoughts on leadership, on ethics, on compassion is part of impacting AI.
Happy to, happy to, happy to.
That's right.
I'm very happy that you're, uh, don't letting your, uh, royalty payments trump that important.
One, such a nice pause, a little bit of silence is good, isn't it, talking about silence.
One thing that came to my listening to you just before Rasmus is the talk.
There was a keynote from a lady called Shannon Vela, I hope I'm mentioning her name correctly,
a researcher from Edinburgh University.
She was here at Melbourne Uni in April this year and she delivered the keynote and was
talking about her book called AI Mirror, which was in essence, I mean, I guess my interpretation
was around the fact that AI is basically reflecting, is a reflection of where humanity is in a way,
the content in terms of content.
Which leads me to the point that I mentioned earlier that AI models and AI solutions can
only be as good in terms of ethics as the people that are behind those projects, initiatives
and, you know, and HR actually coming up with requirements, as you said, which kind of makes
me think of the way that Potential Project does, you know, and you do with, you know, been
doing over the last 10, 15 years, more now, I guess.
Which is like, for me, it's like a full circle back to the humans, right?
AI is great.
But if we really want to make AI articles and in terms of governance, I think having worked
in the governance space for business intelligence and analytics in the past, it's great to have
rules, but not necessarily rules, we'll make sure that people are following those rules,
right?
And those frameworks.
So, yes, I'm just thinking out a lot.
I don't know if there is anything that you'd like to comment.
I don't have a question as such, but just a reflection on your comment before that AI content
will be a reflection on where humanity is, which I think makes a priority to go back to humans
again.
Yeah.
Yeah.
And as it does that, and as we know, humanity is not necessarily at its best when it's engaging
with the digital realm.
Don't need to talk about any particular social media, but obviously all of them are examples
of how it's just the lowest common denominator with the worst trash and filth and making us
deeply, deeply unhappy.
So, and intentionally triggering our worst-based emotions.
I mean, all of that, like it has everything that's bad for humanity.
There's no doubt about it.
Also has good things, I'm sure, not sure what it is, but has definitely downside there.
So what is it that humans need to contribute in the future as AI is getting better and better
and better, more knowledgeable, better answers than any human being.
We as humans need to really double down on vertical development as in, if we want to be relevant,
if we want to add value in the future marketplace, whether we're leaders or employees, we need
to start with a mind that's very clear and calm.
See the bigger picture has the wisdom to step away from knowledge and answers and ask the
right questions.
So in the future of work where AI is taking over more and more, the competitive advantage
of humans is the spaciousness, the depth of our minds and the warmth of our hearts, periods.
Yeah, that's, that actually, that gets me thinking about something that I find a bit troubling.
Not those things you mentioned.
I don't find them troubling at all.
I agree that that's what's, that's, what's going to be needed, but what I find troubling
is that I often hear experts in the field even saying, you know, that they say once AI reaches
AGI or artificial general intelligence, and then they continue the sentence with, and thus
have feelings, emotions, and consciousness, then we will.
So there's this, and there was actually a recent study that came out that surveyed people that
are interacting with chat GPT and two thirds of them attributed some kind of consciousness
to this chat bot that they were interacting with.
And, and I just from, from my personal perspective on that.
I don't think consciousness will pop out of, you know, even doesn't matter how sophisticated
those algorithms will be, consciousness will not suddenly magically pop out of them.
AGI might, you know, intelligence is even at this point, you know, will we reach that kind
of goal?
I don't even know, but certainly I don't think we'll have conscious machines that, that feel
and intend and all those things.
I don't know what's, what's your take on that?
Do you, do you think it's dangerous that we ascribe already consciousness to, to these algorithms?
I think the algorithms are dangerous.
That's my first answer.
There's so many predictions on where AI is going to go.
A lot of it is going to do us great good in healthcare and leadership in so many areas,
but it is not, it's not without reason that some of the biggest AI experts in the world
are really cautioning the use of it.
And even someone as reckless as Elon Musk has been warning humanity against AI for so many years.
So I think AI in itself is problematic, let alone the climate impact and everything, but
I think it's problematic.
But when it comes to consciousness, I think it's wonderful engineering, tech nerd, wishful
thinking to think that AI will, there's no doubt it will have free will and it will have
like intelligence at levels that are far surpassing any human being or any sentient being that
has ever existed.
I have no question about that, but there's a very big leap from being intelligent or having,
having intelligence and into consciousness.
Consciousness doesn't arise out of nowhere.
Emotions doesn't arise out of nowhere.
There has to be someone that can actually feel things and algorithms, which AI is, cannot feel
things.
It can tell itself it can feel things, but it can't feel things.
So I'm not so worried about that.
It's not, I don't believe it's going to happen, but though there was one movie that really
troubled me.
Now I can't remember the name of it and for any listener out there, if you want to understand
AI, don't read, just go and watch all the great AI movies.
There was a movie that came out recently.
I can't remember the name, but which has the most incredible plot twist, which was basically AI
where the monks that were sitting in monasteries up in the Himalayas that AI were the ones that
actually had the deepest emotions and the greatest care for others.
And humans, as we know, that were symbolized by the US army, of course, were just the ones that were ruthless
and effective and everything else.
It was kind of interesting.
Yeah.
And that movie was the creator.
That's the title.
Well, going back to Rasmus' previous state, I thought it was so beautiful.
I thought we should just finish this episode there, you know, with the statement that you made before.
But thanks for your question, Martin.
Something that came to my listening to you just then, Rasmus, was this, I think it's Live 2.0 or Live 3.0
from Marks Tegmark.
I don't know if you came across the book.
Marks Tegmark is a big research in the AI field and his book, I think it's Very Balanced
Life 2.0, so I must check it out if you can.
He articulates the view of the optimist, the pessimist, and he calls that there is still time.
As you mentioned, there are both ways.
There is still time for us to get it right.
But yeah, there's a lot of risk with algorithms, as you said.
So, yes, I think it was good to hear that from you, that, you know, I feel that I'm not alone,
that you also have concerns about algorithms.
And as much as, you know, there are wonderful things that AI can do for humanity.
We need to be very, very, very mindful, very careful about the direction it's going.
Yeah, and that's, you know, involving governments, organizations.
And I'm sorry, and that's actually what I wanted to share with you.
Yuval, the author of Sapiens, when he was interviewed by Tim Ferriss in his podcast, Tim Ferriss podcast
a few years ago, when Tim Ferriss asked him what was his major concern around history of humanity,
and Yuval being, you know, Yuval, having studied history of humanity for so long.
So between, among climate change, advance of AI and nuclear, you know, a risk of a nuclear war,
Yuval responded that AI was his main concern because we have so many organizations in the rush
to actually to advance AI without really necessarily thinking about the consequences.
While climate change, we don't have anyone trying to accelerate nuclear war, we don't have anyone
trying to accelerate, but AI, we have, you know, the four largest companies in the world trying to
win the race, let alone governments as well.
Yeah.
I think AI is out of the bottle, out of the box, whatever we call it.
There are so great capitalist interests for this to be furthered that there is no chance,
there is zero chance that AI will be stopped, zero.
And there is zero influence that all of us normal, mortal beings can have on it.
We can impact maybe a little bit how it's implemented in our company or how we engage
with ourselves, but ultimately it is so far out of normal people's control and within the control of
very few men. And I'm saying men very deliberately that where this is going is just one big experiment
that we have no idea how it's going to end. Just like with social media and we've seen it hasn't
done good for us. It hasn't lived up to its promise. I personally doubt AI is going to do it,
but I will also say we can't fight against it. There's nothing we can do,
so we might as well learn and enjoy the ride.
I think also as we get, yeah, so this is, I guess, the question I'm trying to formulate. So we,
I'm the CEO of a software company and I got lots of programmers working and they are getting massively
helped by AI. And then you think, you know, a task that would take them two days before now they can
do in two minutes. And initially I thought that's great because then, you know, more free time for
humans, but then the usual thing tends to happen. So instead of now we do 32 minute things in an hour
and we just, we constantly just keep filling up with work anyways. So yes, AI is making us more
efficient, but then we just cram more work in. And I think personally, it's great if AI takes a bunch of
our tasks and our jobs and our work, because then maybe if we make that choice, we can have more
space to cultivate exactly the things we talk about and lean into it means to just be human and explore
this wonderful experience and not just cramming more shit in there. But where do you think that is
going, do you think we'll take our free time and use it? Or do you think we'll just kind of become
hyper effective and even more, more, more and more busy because of, because of AI?
I can talk at it only from a company perspective, like what's, what are companies doing?
And I've talked with probably a good 150 CEOs, chief of HR and chief of learning.
And everybody acknowledges that AI is a new email in that email came with the promise. We're all
going to save a lot of time so that we can do more important things, but nobody's doing more important
things. Everybody's doing less important things, more emails, more business. So when I asked them the
question I've asked every single one of them, do you have plans to make sure that AI does not just become
a new email? Only one has answered yes. The CHRO of IBM, Niggle, actually has implemented the first
structure or process in IBM whereby when leaders save time through AI that is directly funneled into
higher value work as in having a particular conversation with a particular person in the
area where you save that time. That's the first story I've heard. And given that I've talked to
so many, I am a little worried that not more people have thought about that yet. So I'm not too optimistic.
Yeah. And I, I mean, I, I tell my employees that if you, you know, if you feel that you've saved an hour,
you know, just feel free to use that hour for something that you find, uh, meaningful and, and, and,
you know, Martin, you're a very, very, you're a very, I wish, wish there were more like you, but I doubt it.
Yeah. Well, um, I think we, uh, hopefully we will be able to do what we haven't been able to do so many
times before and, and take the opportunity to, uh, not just become more and more busy because of AI,
but I guess we'll see. We will see. That's the mantra. We will see.
I'm, I'm getting conscious of time. Um, and, um, uh, I don't know if it's nearly time to wrap up
conscious of Rasmus style more than anything. Um, I just wanted to say that, um, of course I could not
expect anything less, but thank you so much for your very sincere, honest, well-balanced, you know,
sharing Rasmus, you know, um, it was very refreshing and, uh, very insightful. So, um, yeah, thank you
for making time for, to, to talk to us about this very, um, hot topic, you know, uh, and, uh, very,
very relevant to really, you know, not exaggerating to future of humanity really. So thank you.
Yeah. Um, yeah. Thank you so much. I, uh, I truly enjoyed this conversation. And as I said, we will
post the links to the things we've mentioned and, you know, people can go to potentialproject.com if
they want to know more about your works. You're on LinkedIn. If people want to follow you there and,
uh, and so on and so forth, I don't know. Is there any particular thing you would like to mention in
terms of what people can, um, where they can turn if they want to connect with some of your work or is
the site covered? LinkedIn potentialproject.com, probably the best ones. Yeah. Yeah. Buy Rasmus books.
They're available. They're available. They're available on Audible.
I saw, I thought you got it from, um, um, I was thinking maybe you're selling them to see how to,
no, I'm just very biased. I give those, those books to my clients, you know, that's how I,
the welcome pack, here it is, do your homework and then we can talk, get some foundation, right?
Um, so beautiful to have your conversation with the two of you who are well-versed in all areas
of the conversations. They really nice to see both of you. Thank you.
Yeah. Thank you so much. And, um, hopefully you'll, uh, even though you try not to travel,
you make it to Melbourne sometime and we can maybe have a second follow-up conversation face to face.
That would be great. That would be lovely.
That would be lovely.
Good love dance.
Take care. Be well. Thank you.
