Do we see reality as it is?
Do we see reality as it is?
If you open my eyes and I have an experience that I describe as a red tomato a meter away,
most of us believe and most vision scientists believe that in fact there is a red tomato a meter away.
So that in the normal case our perceptions are vertical.
But if we close our eyes and you have an experience that you describe as a gray field,
most of us believe that in fact there is still a red tomato a meter away.
And it is standard in vision science to point out that about a third of the brain's cortex is engaged in vision,
so that when you open your eyes and just look around the world here in this room,
billions of neurons, billions of synapses spring into action
and their activity is highly correlated with the vertical perceptions of a 3D world that we experience.
The idea is that we have all this cortex because we have to do some kind of construction process along the lines that Zig was talking about.
It is not trivial to get to a 3D world, so you have to do a tremendous amount of construction to get there.
And so the idea is that we construct what we see and in fact it takes a lot of hardware in the brain to do that for us.
And just an example, a funny little example of this, we construct all the colors and shapes we see.
This is a flat screen, you see a 3D hat, so you are constructing a 3D that is not there.
And you see a yellow rectangle there and a brown one there, but in fact they are the same.
So you are constructing different colors as well in real time.
And we know that this color construction is correlated with area activity in area V4 and V4 alpha.
And so we have all these tight correlations between brain activity and the kinds of constructions that are going on.
Now there is an interesting example.
You see probably some blue bars with sharp edges going across the screen.
There are no blue bars, there are no sharp edges, and there is actually no motion in this at all.
All I am doing is changing the colors of black dots to blue and some blue dots to black.
But I do it in such a way, if I do it quickly enough, then your vision system kicks into gear and it constructs a world of bars with edges.
Fills in the blue color that is not there between the edges of the bar, and then sets the bars in motion.
So it is highly constructive activity that we are engaged in.
But the standard view, as Zig pointed out, is not just that we construct, but that our perceptions in the normal case
are in fact a reconstruction of the true properties of preexisting objects that really exist in a real space and time.
So most vision scientists believe in local realism and non-contextual realism.
That is part of what we believe in.
And I published papers along that line myself.
So we reconstruct reality is the idea, not just construct reality.
Notice this is a stronger claim than just saying that we construct what we perceive.
This is a much stronger claim than that.
It is saying that not only do we construct what we perceive, but that in fact our constructions are reconstructions of the true properties of a preexisting reality.
So this is a very, it is a stronger claim than just saying we construct what we perceive.
I am going to propose the weaker claim instead of the stronger claim.
My advisor, David Marr, made very clear this idea.
He said we very definitely do compute explicit properties of the real visible surfaces out there.
And one interesting aspect of the evolution of visual systems is the gradual movement toward the difficult task of representing progressively more objective aspects of the world.
So his idea is there's an evolutionary process that's involved more advanced creatures have evolved to do this hard problem of recovering the true objective properties of objects like their surfaces.
So I believe that.
He was my advisor.
So why?
Why would human vision reconstruct reality?
The standard view in the field is an evolutionary view.
The argument is evolutionary.
This is from the standard textbooks that we use in our department here for graduate studies in vision science.
Evolutionarily speaking, the student is told in the introduction, vision is useful precisely because it's so accurate.
So the idea is that accurate perceptions were favored by natural selection because they're actually more fit.
And the argument is actually seems quite compelling.
It's because of our ancestors who saw more truly had a competitive advantage over those who saw less truly and were thus more likely to pass on their genes which coded for the true perceptions.
And so after thousands of generations, we can be quite confident we're the offspring of those who saw more truly.
And so in the normal case, we see reality as it is.
We recover reality.
But there's a clean mathematical question here.
Is it in fact the case that natural selection favors true perceptions, vertical perceptions?
I mean it's a clean technical question.
We don't have to wave our hands and the argument I just gave you was a hand wave.
It sounds really compelling, but it is just a hand wave.
And so you can use evolutionary game theory, evolutionary graph theory, genetic algorithms, and so forth to try to answer this question.
In game theory, you have lots of different strategies, XI, with different fitnesses, F, and you can look at how they compete and who survives and doesn't.
Or you can look at species and their fitnesses.
And so the key notion is fitness.
Most people here know it.
I'm just going to mention the key notion because it's what I'm going to really push on.
What are the fitness payoffs offered by a steak to various organisms?
Well, if you're a lion and you're hungry and you're looking to eat, that's going to give you lots of fitness payoffs.
But if you're a lion and you're full and you want to mate, that gives you no fitness payoffs at all.
And if you're a rabbit in any state and for any action, that is not going to give you any fitness payoffs.
And the key notion of fitness in evolution at the top level is fitness functions do depend on objective reality, whatever that objective reality might be.
I'm using the steak as a concrete, for example.
But it also depends not just on objective reality but on the organism, lion versus rabbit, its state, hungry versus sated, and its action.
Feeding, you know, the four Fs, for example.
Any of the famous four Fs.
So fitness functions are these complicated functions.
They depend in part on objective reality, but they depend in many parts not on objective reality.
And they can be all over the place.
So, for example, suppose that there's a resource in the world that behaves much like, say, water does for us.
Small amounts of the resource, if it's too small, you die of thirst.
Too much of that resource, like water, you die of drowning.
And somewhere in between, it's just right, you have the Goldilocks effect.
And many resources in the real world affect us in terms of their fitness payoffs in this kind of way, this non-monotonic kind of way.
And so you can think about two different kinds of perceptual strategies.
And I'm saying this just to give you an intuition about a theorem I'm about to present.
You can have a truth strategy for perception or a fitness-only strategy for perception.
So suppose that you're an organism that has only four colors for your perceptual system in this simple case.
Red, yellow, green, and blue.
And suppose that you're going to devote your perceptual resources as best as possible to give you the most accurate information about objective reality as you possibly can.
Okay?
Well, the objective reality in this case is the amount of the resource from, say, zero to 100.
Okay?
So if you're going to deploy your sensory information, your sensory system, in the most efficient way to code reality, you'll use the top scheme.
That way, if you have a sensory experience that you describe as red, you know that the resource quantities, say, between zero and 25, and so forth.
So that gives you a best way to estimate the true state of reality from that.
On the other hand, if you're interested in fitness, and you want your sensory information to be deployed to represent fitness for you,
you're going to do something very, very different with those colors.
You'll use, say, blue just for this middle area of high fitness.
And you'll use, for example, red for things that are, say, between zero and 12 and a half, but also, you know, 87 and a half and 100.
And so, if I see something that's red, I'm getting really important information about fitness.
I'm getting no information about the truth.
And that's going to be the big story here, is that there is this trade-off.
Because fitness functions are not nice monotonic functions of reality, and in general, for any structure in reality that you might think of, groups, rings, fields, whatever it might be,
they are not homomorphisms of those structures in reality.
You have, as an organism, a trade-off.
You can either be tuned to the truth, or you can be tuned to fitness.
But those two will, in general, be opposite directions of tuning.
And the key idea is going to be that in evolution, if you play any other game than going for fitness points, you die.
And so the idea is going to be that if you play for this game of verticality, you will die and evolution will drive that to extinction.
So that's the idea of the theorem.
We actually ran evolutionary game simulations with my graduate students, Justin Mark and Brian Marion.
Hundreds of thousands of worlds where we had organisms competing for resources, and they had these fitness-only strategies versus truth,
where you could actually use basic estimation to estimate the truth and so forth.
And organisms that saw reality as it is had a pathetic tendency to go extinct all the time.
The organisms that saw none of the truth and were just tuned to fitness were the winners, even many times when they had fewer perceptual resources given to them than the organisms that saw the truth.
But this is just simulation. It's not a theorem.
So I proposed a theorem, and Chaitan Prakash, who's a long-time collaborator of mine, approved it.
And it's what we call the Fitness Beats Truth Theorem over all possible fitness functions and a priori measures on the state of the world.
The probability that a fitness-only strategy strictly dominates the truth strategy is at least cardinality of x minus 3 divided by cardinality of x minus 1, where x is the size of the perceptual space.
So in the case, for example, we had 4 when I had red, green, yellow, and blue. That was the size of the space.
As this size increases, the probability becomes arbitrarily close to 1.
In the limit, fitness-only will generically strictly dominate the truth.
So this means that natural selection is uniformly against veridical perceptions.
If an organism ever happened to appear with a mutation that allowed it to see reality as it is, natural selection would swiftly go about stamping it out.
So perception of reality goes extinct, and so the idea is, so what kind of perceptions do we have?
And the idea is that think about our perceptions as more like a user interface.
So space and time is your desktop, and physical objects are like icons on the desktop.
So if I'm writing an email, and the icon for that email is blue, rectangular, and in the lower right corner of the screen,
does that mean that the email itself in my computer is blue and rectangular in the lower right corner of the computer?
Of course not.
The icons and the information on the desktop is not intended to resemble, in this example, the objective reality.
I'm taking it to be the diodes, resistors, the megabytes of software in this example.
In fact, the point of the interface is to hide objective reality because it's not what you need, and it's too complicated.
It gives you eye candy, like blue icons, that lets you do what you need to do and control objective reality while you're utterly ignorant about that objective reality,
even if you're utterly ignorant about it.
That's what a desktop interface is for.
And that's what I claim evolution has done for.
Space-time is our desktop.
Physical objects are the eye candy that we use to tell us what we need to know about fitness so we can act the way we need to behave.
None of it's true.
It's there, in fact, to hide the truth because we don't need the truth, and truth is just both too complicated and irrelevant.
So, the idea then is that when you open my eyes and I have an experience that I describe as a red tomato, I am interacting with an objective reality.
I'm not denying that there's an objective reality, but it's utterly unlike anything I'm perceiving.
So I've got digital rain there just to indicate that.
Same thing if I have an experience that I describe as a lion.
I'm interacting with something, but it's not a lion.
It's an utterly different objective reality.
And for the mind-body problem, this has interesting implications.
When I look inside brains and hit heads and see brains and see neurons, I'm interacting with an objective reality, but it's not brains and neurons.
And so brains and neurons actually don't exist when they're not perceived.
They're just symbols that we construct on the fly, and that's why we have a hard time with the mind-body problem.
We assume that neurons have causal powers, that they exist when they're not perceived.
And according to this, it's false, if our senses evolve by natural selection.
So what about symmetry?
I mean, I've only argued from evolution.
What about symmetry?
Does the symmetry argument somehow overcome this?
Well, so I went back to Chaitan again on this one.
It seemed to me that you can invent symmetry.
And Chaitan agreed.
So suppose you have an observer, and the observer has his own experiences and his own actions that he can take.
And then there's some external world.
I don't know what it is, but I'm no longer assuming it's space and time, but it's some external world.
And so there's the world, the experiences, the group G of actions that the guy's got.
And then I have these kernels, say Markovian kernels, by which I can act.
The idea is I can act on this unknown world through a kernel A.
The world then will in turn act on me through some kernel P.
As long as the kernel AP has X as a G space.
So the G is a space that's being acted on by whatever symmetry group I've got down here in G.
It doesn't have to actually act on W in that way.
In fact, W doesn't have to enjoy any symmetries at all.
So this is just the top idea of the theorem.
I can act on a world through a kernel A of actions.
The world acts on me in P.
As long as AP acts on my experiences in the right way, I will perceive symmetries in my experiences.
And that does not entail anything about symmetries actually being part of the objective world.
I just have to have that the relationship of my P kernel to W satisfies certain fiber relations.
So it turns out it's actually straightforward to prove a paragraph.
The proof is trivial.
It's the invention of symmetry theorem.
Again, Chaitan Prakash proved it.
Anybody who wants this, I can give you the paper's already been published on this one.
But I gave you the idea of the proof.
So what it means is that the symmetries in our perceptions do not give us any logical grounds to infer anything at all about symmetries in the objective world.
The only valid inference is the symmetries of our perceptions put a lower bound on the cardinality of the set of states that the objective world has to have.
The objective world has to have as many states as our perceptual states, at least.
But there's no valid inference from any symmetries in our perceptions at all to symmetries in the world.
In fact, any structures in the world.
This is not just an invention of groups.
It's any structure.
It's completely different.
So I show you a bunch of dots.
Here's just a concrete case.
I show you a bunch of dots.
Moving around, you see a 2D random thing.
But if I move them like this, you invent a symmetry.
You see a three-dimensional shape with a circular symmetry.
And there's no such thing.
You invent it.
And I'm claiming all of your symmetries in perception are of this type.
We invent all the symmetries that we perceive.
And of course, the question is why?
Why do we invent symmetries?
And I think that we have to be thorough-going evolutionists on this.
There's only one game in town.
Fitness.
Anything else is irrelevant.
So everything about the sensory system is a satisfying solution to the problem of getting us the information we need about fitness to stay alive and nothing else.
So I think that space can be viewed perhaps as an error-correcting code for information about fitness.
So we think of space as a pre-existing stage, all of my colleagues do, as a pre-existing stage in which the drama of life plays out.
I'm saying it's no such thing.
It's a species-specific data format.
That's it.
Data format that we use to represent information about fitness.
It's like an error-correcting code.
There's redundancy in space.
It's not a true objective reality independent of us.
It's literally we're living in the data format that we use to have information about fitness.
And so we then use our perceptual system really instead of recovering true properties of the world.
Think of it as an error correction, error detection mechanism for information about fitness.
We're building symbols about fitness.
So here's an example.
I have these two guys like this.
If I rotate them, all of a sudden you decide that there's an error that you need to correct, and you insert a glowing line.
So instead of saying that we're recovering a true line, there is no true line.
Think of it this way.
It's an error-correcting code for information about fitness.
You're trying to construct codes that will allow you to do what you need to do to stay alive.
Fitness information only.
So these are error-corrections.
They're not recovery of anything.
Same thing here.
Here's the case where you do it in 2D, and of course you can do it also in 3D.
But now the 3D thing you're creating here is also completely a fabrication.
Why are we fabricating it?
We're getting, again, codes for fitness.
Not for truth, but for fitness information.
And if that's the case, then you might find that space itself has unexpected properties.
If it's not a pre-existing three-dimensional reality, it is just a data format, then maybe there's certain things that it will do that surprise us.
For example, here's one surprise.
If I ask you, how much information could you store in the volume of that volleyball?
You can say, I can stick a terabyte hard drive in there, maybe two terabytes.
But then there's the question, if you keep compacting those drives, you get to the ultimate.
What's the ultimate amount of information you could store in that volume of space?
And the physicists, in fact Stephen Hawking, answered the question.
It doesn't depend on the volume.
In fact, volumes don't hold information.
It depends only on the surface area that bounds the volume.
The amount of information that you can store in a volume is independent of the volume.
And what that means, this is called the holographic principle in physics.
And that means the following.
Suppose you're a computer designer.
You're going to build a memory.
And I say, well, you can have this big sphere here and you can use that.
Or I'll let you have these six smaller spheres that just pack inside of it.
Which would you use if you're trying to build the computer memory with the most memory?
We might think, well, it's the big sphere.
And you'd be wrong.
The universe doesn't work that way.
Space does not work the way you think.
You would actually do better.
You'd get 3% more memory if you used the six smaller spheres.
Now do that recursively.
Take each of those six smaller spheres and pack it with six.
And do that 20 or 30 times.
Now you've got a structure that has essentially no volume
and millions of times more memory capacity.
That's what space is like.
That's really confounding if space is an objective 3D world that exists whether or not we perceive it.
It's not confounding if space is simply a data structure with interesting properties that we have employed to get us information about fitness.
So Gerard de Hooft, who was one of the first to propose, to discover this, he won the Nobel Prize.
To discover this, he said, the fact that the total volume inside is irrelevant may be seen as a blessing since it implies that we don't have to worry about the metric inside.
The inside metric could be so much curved that an entire universe could be squeezed inside our closed surface regardless of how small it is.
Now we see that this possibility will not add to the number of allowed states at all.
Then he says, we suspect that there simply are not more degrees of freedom to talk about than the ones we can draw on the surface.
So the idea of space that we have in vision science is completely confounded by these kinds of results of the holographic principle in physics.
And in fact, many physicists are already saying, including Nima Arkani Hamed, David Gross, Ed Witten, they're all saying the same thing, that space time is doomed.
It's not a fundamental reality.
It's not a fundamental concept in physics itself.
We have to let go of it partly because trying to get general relativity and the standard model of quantum physics to play well together, you have to let go of space time.
It will not work.
And so Nima Arkani Hamed said this in lecture, space time is doomed.
There's no such thing as space time, fundamentally, in the actual underlying description of the laws of physics.
That's very startling because what physics is supposed to be about is describing things as they happen in space and time.
So if there is no space and time, it's not clear what physics is about.
And that's where physics is right now.
Space time is not a fundamental reality and the symmetries that we perceive in space time are not giving us any indication of the nature of objective reality.
From an evolutionary point of view, they're just simply a user, a species specific interface for information about fitness.
But there are other intellectual disciplines that have already been telling us.
Cybernetics had already been telling us this a long time ago.
The black box theorem from Moore.
If I have a black box and I can only see certain degrees of freedom on the surface, dials and knobs on the surface, and I ask, well, what's going on inside the box?
It doesn't matter how many symmetries and how much structure I see in the surface, Moore's theorem says there is no way for you to ever infer what the program states of the box are.
It's impossible.
In other words, it is the failure of the invention of symmetry idea that Chetra and I proved, but well before we did that.
You can't look at the dials on a box, our sensory system, our perceptions, and ever expect to get the structure of the world.
That's just from cybernetics black box theory.
And then in Markov blankets, when you have, you know, Markov Bayes nets for example, you have this notion of a Markov blanket.
So the Markov blanket of a node is all of its parents, all of its kids, and then all the other parents of its kids.
And it turns out when you take, when you look at the entire Bayes network and you divide it into the node on this side, the Markov blanket and the rest of the environment,
the Markov blanket makes the node conditionally independent from the entire rest of the environment completely.
What that means is, if this is my sensory system, and this is the node, what I can see here, my perceptions, give me no ability at all to make any inferences about the structure of the environment.
End of story.
So we have it from black box theorem, we have it from Markov blanket stuff, we have the invention of symmetry theorem, and we have the fitness speech truth theorem.
And then we have what I would call the generalized holographic principle, that inter-system boundaries are information channels, and there are no other information channels between systems.
And more specifically, I'll just go down to here, no more classical information can be transferred between two jointly closed physical systems, A and B,
than can be encoded by the eigenvalues of the interaction Hamiltonian H, A and B.
This is a general, my claim, a general principle.
So, what this means is, all you can read is the interaction Hamiltonian, that's all the information you can ever get,
and that never allows you to infer anything about the structure, the mariology of what's on the other side of the system.
It's just not possible.
So, as Zig just talked about, many people in our field believe that verticality is an essential characteristic of perception and cognition, that it's absolutely essential.
That perception and cognition without verticality would be like physics without the conservation laws.
But verticality violates Moore's law, for black box theory, for the fitness beats truth theorem, it violates the invention of symmetry theorem,
the notion of conditional independence that comes out of Markov blankets, the holographic principle in physics, and then the generalized holographic principle.
It's violated by all of these things.
I think we have to take a completely evolutionary view.
An organism has tons of fitness functions it's trying to deal with, but can't deal with them all.
It's got finite memory, finite computational abilities, and so it has to have a satisfying solution to the problem of understanding fitness.
So, it uses data compression, where you will, data compression, error correction, that's where symmetry comes out.
If you look at the theory of data compression, error correcting codes, symmetry is everywhere.
And I think that's exactly where symmetry comes into our perceptions.
Misreading fitness makes you less fit.
If you have errors about fitness, and so there will be error correcting codes, and again you'll get symmetry there.
And then physical objects, like tables and chairs and the moon, are not pre-existing objects that were recovering their true properties.
They're symbols that we invent to give us codes about fitness information that we need and actionable ways of getting that fitness.
And they're telling us nothing about the truth.
It's just like the blue icon on your screen.
It tells you what you need to do to open your email and edit it and so forth.
But the colors and the shapes and so forth are just conventions.
They're not the truth.
So, shapes and physical objects in space, space-time itself, are satisfying solutions to the problem of getting the fitness information we need to be a little bit better off than our neighbors.
And my final slide.
I like this quote from Arthur Eddington.
I was held back by the common feeling, which I now see was not philosophically well grounded, that it was necessary to leave at least one objective peg on which to hang all the subjective cloaks.
Certainly, an objective peg is necessary, but we do not need to suppose that it disguised itself to resemble the cloaks.
And I agree with him.
I agree with him.
I agree with him.
wnie just Munich Slearing.
I agree with him.
We answer the question.
I agree with him.
And now, you know what I learned over here.
We have to choose from each section of this country.
We need to choose from each section of the Coalition.
And we, I agree with him and I agree with him.
The inner contact is not a tool that this language is defined by an Islamic environment.
I agree with him.
In this company I go to find FromGirning.
You want me to choose from eachеля of the church until the Huang sort of church,
and I agree with him in airi.
