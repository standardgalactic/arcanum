the caterpillar wants to encode and the butterfly wants to decode in a way that um reuses the
information uh adaptively and we see this we see this a lot in experiments and memory transfer
they train a sea slug and they and they extract the rna from from its nervous system and then they
inject it in the into the into the brain of a naive donor and then you can see memory transfer
i mean it's fabulous work wow most likely you don't just want to persist you want to expand
into other spaces which means you want to alter yourself in a way that would allow you to colonize
as as many other thinkers and as many other um action spaces as you can and then of course
they face exactly the same paradox that we started out with which is that if you change enough you're
no longer what you used to be and so is that okay is that persistence or is that you know you've now
you're gone now and some something else exists michael levin is a scientist at tufts university
his lab studies anatomical and behavioral decision making across biological artificial
and hybrid systems his work spans developmental biology artificial life bioengineering synthetic
morphology and cognitive science today we'll discuss his recent paper self-improvising memory
a perspective on memories as a gential dynamically reinterpreting cognitive glue please like and
subscribe and i hope you enjoy our fourth conversation together michael levin thank you for coming on for
the uh fourth time yeah thanks for having me good to see you again great to see you it has been a
while maybe 18 months to uh to two years uh since we last connected and i'm so excited to cover the
the papers the recent papers um that you that you've published here it was we'll discuss today but
i'm going to start it off if you wouldn't mind you know for the year of 2024 do you have any uh say broad
highlights that you want to share with the about the lab um let's see highlights about the lab boy
it's been there's been a lot of stuff uh yeah yeah um well a number of a number of papers some things have
um really moved along um on the on the anthrobots front um with respect to uh our ability to track
communication between embryos so so attempts to like really understand um collective intelligence above the
cellular level uh also some new work uh below the cell level looking at the gene regulatory networks
and how they solve problems um so yeah some uh some uh some there's some stuff coming actually uh soon
that was developed mostly in 24 years and published yet but some things on um novel transcriptomics of
anthrobots and sonobots and uh yeah lots of lots of interesting things lots of stuff that's so cool it's so
cool to follow uh all of your work and your your team's work um and today in this discussion we'll
cover we're going to try to cover three of uh your recently published papers and i'm going to try to
structure it uh like past present future so we have a the past we'll focus on this paper called self
self-improvising memory and then uh the presence the second act will be the second paper on stress
sharing as cognitive glue and then the third uh ai a bridge toward diverse intelligence and
humanity's future so that'd be ideal to cover all three of those i know touch but if we if we get
into one and we're you know very in depth into one that's totally fine we can know we can just cover one
or two of the papers but let's get started with this self-improvising memory and uh could you explain
the essential thesis of this paper yeah well it it started when i uh when i started thinking
more deeply about what's going on with the caterpillar butterfly transition so for years
uh i've been thinking about this so let's just let's just say what the what the data are so the
data are a caterpillar um it's a soft-bodied creature has a particular kind of controller that
it uses to move around basically in a two-dimensional world eating leaves uh which is this very specific
type of brain that it has and it was it it it turns into a butterfly which is a hard-bodied kind
of creature completely different controller flies in three-dimensional space and in order for that
to happen the brain is is is massively remodeled so most of the connections are broken many of the
cells are killed off and then it rebuilds basically rebuilds new brain so the remarkable observation this
was made uh for um certain kinds of uh certain kinds of metamorphic systems years ago uh by uh by the
shaman group um and then uh more recently uh in in caterpillars and by doug blackison who's currently
a staff scientist in our in our center was that if you train the caterpillar the butterfly remembers the
original information now one of the cool things about that of course is that uh we have here a
computational medium that um where the information survives massive refactoring so we don't have any
technologies like that where you can store some data and then you you sort of rip up the medium
reconfigure it completely and everything is everything works so so i've thought about this
a lot over the years as a um as a as a challenge to our uh computational kinds of architectures you
know what what does it mean to store information in a way that survives that kind of uh that that kind
of massive damage and and remodeling but um i i realized uh earlier this year that the much more
interesting feature there isn't the uh maintaining the fidelity of the information but it's actually
remapping the information onto a completely new uh in a completely new kind of being with new problems
because the butterfly doesn't need the exact memories of the caterpillar in fact it can't use them
the specific memories of the caterpillar are of no use to the butterfly because it doesn't move the same
way it doesn't want the same things it doesn't want the leaves that the caterpillar was trained to
to find at a particular color it's not going to move the same way uh you can't you can't just keep
the same memories what you have to do is remap these memories onto a new substrate so and and make
them make sense make those memories be useful to you in a completely novel configuration so if you think
more deeply about it it you you realize that this isn't some weird unusual uh feature of this of this
lifestyle you know this metamorphic lifestyle it's actually extremely fundamental in biology and this
goes back to a paradox and and um uh i used to think it was bait since paradox i'm actually not
sure who who came up with it but the idea of the paradox is is this if as a species if you remain this
you will eventually die out when the environment changes you can't keep up and you'll die out but if
you do change then you're not the same species anymore so once again you're gone right that that
original being is is no longer there so the paradox is how do you survive and persist while necessarily
changing fundamentally and this is true for all of us this is this is uh the the the consequences
of education of uh transformative experience of of puberty of uh the the question is you know is is
is the past me still still around or is this or is this uh different in some way this being different
so so i started thinking about this and i and i generalized this in the in the following way um
that that paper um the self-improvising paper does a couple of uh things that i think are are
useful one is that it um proposes this architecture which is which is uh useful both on the kind of uh
time scale of a single cognitive agent but also on the evolutionary time scale and the
and the and the system looks like a big bow tie it's also uh it also looks exactly like in auto
encoder architecture for uh used in in computer science and machine learning so what you have is
you have this this big funnel on the left side and um then there's a there's a thin um node or layer
in the middle and then there's a big funnel going out right so you can imagine that kind of bow tie
and so the is this so let's just let's just imagine this for our for the for the cognitive case um
um you as a as a as a as a as an active agent you have input stimuli experiences that you have so
these come in with very specific details if you're a cell it means there are specific molecular things
going on let's say on your membrane if you are an animal you are receiving uh signals from from
certain receptors that you have in senses and so against and so on um so so all of those are coming in
but but you can't you can't afford to store the exact details because by trying to track the micro
details right by by trying to be a kind of laplacian demon that that that just tracks the micro details
you will be eaten and and die in no time the real world does not afford you the the time and the
energy that it takes to do all that so instead what you have to do is you have to generalize you have
to compress all of those instances into some kind of generative some kind of very simple generative
kernel that um is going to capture the what's essential about all the different details like
lots of those details are are not essential you know if you saw a particular stimulus the the exact
shade of color and you know where the pixels were on your right now those are not typically the useful
things but but there's something else about that experience that um maybe you've maybe you've inferred a
pattern of in the stimuli you know so this intelligence does is is it goes from from from
particular instances to a general rule so then you remember this pattern you learn and you remember this
pattern and so that's what you have access to uh it as as a memory engram so you you uh you you store
that as a memory engram but then then later and it might not be very much later it might be you know
this you can think of the center of the vota as the now moments you've got the past right you've got
this now moment and then you've got your future and that now moment moves along and and uh very
very shortly thereafter you now have to reinflate um those generative uh memory traces into some kind
of coherent story about what's happening now and what it means and how you can use those memories
and so another thing that i try to do in that paper is to recast your memories as messages from your past
self so to use the same kind of um formalism that we use to analyze communication between agents at
a given time so laterally right the way you communicate with others is um you can also think
about um all of your memories as communications from a past version of you and all of your actions
and the things you learn now are messages that you are recording for your future self um i long after
i read that i i wrote that i i read a funny uh i think it was a tweet by sam gershman who said that
your most important collaborator is you six months ago and he's not answering emails and that's you
know that's that's really that's very good that's that's good yeah if i had had that back then i would
have used it as this as the subtitle of a section in that paper because it's basically what what what it
reminds us of is that you don't have access to the past what you have access to are the memory traces the
engrams that have been left by your interaction with the past in your mind and your brain and body
and now now at every at every given moment and and this i think is interesting for kind of the
definition of what it means to be an agent or to to have a mind is to be in charge of constantly and
and be driven to constantly figuring out what do my memories mean you know you don't you don't think
of it typically i think typically we don't think about it we just assume we have memories and we know
what i mean well right that might be true in our computational systems where the uh the bottom
layers are highly reliable and and and there's this abstraction where when you program at a higher
level you don't expect uh you don't have to worry about the the the data in your register sort of
floating off and changing into something else and so on and so we can get into that too with the
difference with computation but but the thing about biology is that uh you are you are always working in
an unreliable medium and so this is where so so um i just finish finish the the thought on the on the
cognitive side so so you've got these engrams and then you have to reinflate them and in order to
reinflate them here's here's the thing about uh reinflating them is that you've lost information uh
there are lots of um uh correlations and other things that were specifically squeezed out of that
data when it was when it was written down but now that you have it you don't know exactly what it
means you don't know exactly how your past self interpreted you don't you don't have access to
that what you have access to is the recording itself and now it's up to you to re reinterpret
it and you might reinterpret it in exactly the same way but you might not and you don't have to you don't
have any allegiance to that you you have to biology um tries to make use of information at the moment in
whatever best way that it can you know and it's it's sort of like um i mean in literature they have
this concept when when somebody writes something you are not forced to interpret it the same way
that they did even though they say well i wrote it i know what it means and you say well guess what i
got something else out of it so so now i think this is what it means right so it's that's it's that sort
of it's that sort of thing and it it relates to the polycomputing um a paradigm that josh bongard and i
have developed where the idea is um you you know there isn't there isn't an objective fact of the
matter about what a particular physical event is computing and it doesn't matter if if someone wrote
the algorithm and says no i know what it does i i wrote the algorithm well there are multiple
observers that could potentially look at those events and have a different model of what's being
computed and they're equally equally valid to the extent that they can make some use of it right you
have to be able to adaptively use it so um that means that uh the uh the left side of the funnel
is largely algorithmic because you know compression and inference and so on you can imagine that as an
algorithmic process but the right side of the funnel is creative because it's under determined you can't
simply uh deduce what was meant by the memory traces you have you have to interpret them in the current
context so it's a view of cognition as a continuous sense making where you're trying to make models of
of yourself and your world and you have to reconstruct them all the time because all you have is the traces
that were left to you by the past self and your past self may be very much like your current self in
which case it might not be too hard but also it might not and so uh and so that that then leads to
uh to an interesting uh thing where you can apply these concepts on a on an evolutionary time scale
and you can then see immediately the uh the origin of the incredible plasticity and the problem-solving
capacities of cells and tissues and molecular networks and so on because unlike unlike in our
computer technology biology is working with a fundamentally unreliable medium not only when you come
into the world as a new being not only can you not be certain of what your environment is going to be
but you also can't even be certain of your own parts in fact you're guaranteed that your own
parts are going to change they're going to mutate there's going to be errors again all kinds of
things um and this is why you know i think we've talked before about like one of my favorite examples
of this of this new kidney tubule right that that you you can make these these nudes with different
copies of chromosome number and basically the cells adjust their size to the amount of dna and then
morphogenesis adjusts itself using novel mechanisms to make a perfectly good nude
out of cells that are completely the wrong size and in fact that you might differently building the
same pattern but in quite different ways and so as a new as as a creature coming to this world you
can't be sure of much you know you can't be sure that of your environment but you also can't be sure
of your own parts you don't know how many copies of your genetic material you're going to have you don't
know uh how many what what the size of the number of your cells you have to construct
uh a viable way to move forward on the fly right this is you know play the hands you're dealt kind
of kind of thing and so that means if from the beginning biology and evolution uh commits to this
idea of an unreliable substrate where you don't really know what's going to happen but you have to
interpret that information left for you so the genome was left for you by eons of experience of your
experience of your ancestors but you're under no obligation to interpret it the same way and this
is why with exact same genome we can have planaria that make heads of the wrong species we can have
xenobots made from with a frog genome we can make anthrobots made of a totally normal human genome
the meaning of that information is not hard-coded at all right issues and so and so this is this is the
the origin i think of that incredible plasticity in biology and i also think that this provides kind
of a um an intelligence ratchet where once you once you uh start down the road of making active problem
solving agents not solutions to fixed problems which i think most organisms are not there may be a few
exceptions um but most organisms uh and cells and even you know even unicellular organisms are problem
solving agents once you start down that road the meaning of that information becomes less and less
determined because the agents are going to be better at re reinterpreting them and so eventually
you start projecting that kind of uh willingness to confabulate i mean literally this is this is where
confabulation is a is a is a feature not a bug because the ability to ignore whatever the information
used to mean and to make up a story that helps you right now is is is really helpful in a wide range
of of context and so i think that kick starts what we eventually recognize as intelligence which is
increasingly um creative uh on the fly reinterpretation of information based on whatever problem
you're trying to solve and then the last bit which we can we can talk about the the title of the um
the title of the of the paper actually is is really only touched upon at the very end which is
uh this idea of the memories themselves as agents and so we talk about with that that's a whole other
thing we can talk about is patterns as agents and so on yeah well that was wonderful you answered about
six or seven of my questions already so that was great thank you michael um and that actually actually
is one of the let's see i go so many different places here let's start off with what you just
mentioned about memories as agential um what do you mean by that yeah how do you define agential memories
and what evidence do you have to support that idea yeah um okay so so let's first uh let's first just
nail down um how how i think about agency so so there's there's a there's a feeling among many that uh
there's there are certain certain kinds of things or agents so let's say humans and maybe some animals
and so on um and that the use of that word in other contexts it's some sort of a category error
so so my feeling on all of this is that these categories are are not uh sort of given to us by
on high and that we are then uh required to stick by them i think the category should follow the science
and that means that the way you know when you have agency is you take the the the tools that we
normally have so these are the tools of behavior science of cognitive science and so on the tools
that you normally use to interact with agents and you and and then you empirically you don't sort of
sit back and assume but but empirically you apply them to other types of things that being molecular
network cells tissues organs cyborgs biobots whatever and you see how far that gets you and you see where
where that gives you advantages and disadvantages so i see agency as something that's only
applied um it's a term that can only be applied after experimental study and you and you need to
have a specific hypothesis about what problem space it's working in and by the way that problem space
does not need to be three-dimensional space so when people talk about embodiment and they mean some sort
of wheeled robot or something that runs around and does things i'm talking about solving problems in
transcriptional space in anatomical mortal space i do all these other spaces that are that biology
navigates but are hard for us to to to visualize so so that's that's my take on agency so now so now
okay so now let's think about the you know the spectrum of agency what kinds of things are on that
spectrum so um i've previously talked about placing some some unusual things on that spectrum like cells
and tissues and and uh you know and slime molds and and even molecular networks we've shown learning and
molecular network and models and so on uh but i think we can get much weirder than that even and i
think that's a good idea um because it's good to push through um push past our uh typical kind of uh
limitations and thinking about these things because i think you know we've inherited some some very
specific firmware from our life on earth and and especially you know our our our um our latest
history on the savannah or you know all that kind of stuff we've we've inherited specific ways that
were very expedient for thinking about things but i think i think they're quite um constraining actually
and so so now it's right now it's time to break through some of that so so i started thinking about
the following uh the following that and the following dichotomy because we typically most people
typically think well okay we have we have uh actual physical um beings and so those might be biological
beings they might be some sort of you know um engineered machines or whatever but we have things
things that do things um and then we have patterns we have data we have we have information that these
things process we have uh patterns in various media so so whether they be in a cognitive medium or
pattern in a you know in a digital a memory maybe whatever we have patterns so we have patterns and
then we have we have cognizers so we have thoughts and we have thinkers and um william james said
something interesting he said that thoughts are also thinkers and so how would that how would that
work so so so first let's um just to kind of warm us warm us up let's uh let's think about a science
fiction story and this is i think based on a story that i read many years ago i'm actually not sure
if that's really the case or what the story was but uh and and no doubt i i've bent it completely out of
shape but but anyway but but here's the but i think it's good and here's the here's the story
so so just imagine uh from the from the core of the earth from the center of the earth come these
beings they sort of warp their way up and uh they're incredibly dense because they come from you know
the center of the earth so so they're incredibly dense um their vision is i don't know in a gamma ray
range or something like that and they're walking around what what do they see well the first thing they
see is uh that the earth is enveloped in this very tenuous kind of plasma um that's all of us and
everything that we see as physical objects they don't see any of this they uh to them they are so
dense that to them all of these kind all of the things that seem solid to us are just um you know
just ethereal uh wispy kinds of gaseous patterns that exist around the earth and um uh much like much like
when you walk through a garden there's all sorts of patterns of of of pollen and smells and there's
all this stuff and you just sort of walk through it you don't even see it it's you know these patterns
in the in the in the medium so they're walking around and and and uh kind of stomping through
everything and and one of them is a scientist and he says um to the others you know i've been i've been
i've been watching the gas that that our planet is surrounded by and i and i see these kind of
patterns in the gas and say what what kind of patterns well they're sort of temporarily persistent
patterns they kind of hang around for a while and they seem to be doing things it's almost like
they almost they almost seem agential they almost seem like they you know they move around and they
try to protect themselves from from dissipating and they have certain goals and it almost looks
like they're they're doing stuff and the others say well that's well that's crazy but like we're real
we're physical patterns patterns can't be agential and by the way how long do these patterns stick
around well about 100 years well that's nuts nothing nothing interesting can happen in the space of 100 years
um and so and so uh you know and and and uh i've i added to this uh to this story there's a there's a
blog post that i have where i kind of do a dialogue between you know um the one of those one of those
core scientists and one of these patterns and and he says look uh you know i feel i feel crazy talking to
you because because you're just a pattern in this in this medium and the human which is the of course
the pattern is trying to convince them no no we're we're we're real too it's just a matter of perspective like
we you know we're we're real um and it's funny that there's there's another story which i'm quite
sure is is a is a is a is a real sci-fi story about a uh uh a stream of uh plasma pattern that
gets ejected from the sun and the humans are flying by in some sort of spacecraft and they don't realize
that this is also a sentient being that's just been sort of ejected from this uh from from its home and
and so on so anyway so so the point of all of that is to remember and to remind ourselves that
we are actually also temporary patterns we are temporary patterns in metabolic space and we
persist for some amount of time let's say on the average of 100 years or so on the scale and uh and
and we try to keep ourselves together but much like hurricanes and solitons and gliders in the game of
life and various other you know temporary um self-organizing and uh self-persisting patterns
one can take that view and so that that reminds us that this this distinction that everybody makes
very categorically between real be you know real things or thinkers and the patterns within them or
thoughts is really a continuum it's very much a continuous measure that's up to the eye of an observer
to to note and so that then uh suggests the following which we are now just beginning to
um this is something that you know josh bongard and i and and um and um richard watson and chris fields and
some others are starting to think about which is what if what if you turn the standard computing paradigm
on its head so normally you have these turing machines you got the machine and that's the agent
doing things and then you've got its memory tape and so it's writing things and so what if um what
if what if you look uh from the perspective of the tape so in fact not not just the tape itself
but the patterns on the tape because in a certain sense they run the show the machine is going to do
what it does based on what the information on the on the tape says and so you can imagine uh with these
so so now so now back to memories as as agents so so imagine this continuum so you've got you've got
these um you've got fleeting thoughts so these are patterns that run through a cognitive system and then
you know if it wink out of existence they disappear so they're very short short lasting but then you've
got some persistent thoughts or recurrent thoughts that are kind of difficult to get rid of and we know
from clinical psychiatry that that there are there are those kinds of thoughts that once they establish in
certain minds they um they're hard to they're hard to get rid of depressive thoughts and you know
obsessive thoughts and things like that and in fact some of these thoughts do something interesting they
do a kind of niche construction meaning that they actually the more you have those thoughts the easier
it is to have more of those thoughts they literally change the brain there have been studies on
on how uh you know brain ultra structure changes with with those kinds of those kinds of
thoughts that makes it easier to continue having that cycle right so these thoughts these kinds of
thoughts are a little more permanent um they're a little more uh they contribute a little more to
their own survival they're in fact changing the thinker uh by their presence and then then you sort
of move up the spectrum and you can say well what about uh dissociative identity disorder personality
fragments they are even more agential they have they have goals some of them can talk uh they will
certainly um affect the thinker in ways that uh that changes how you know how they persist and how
others persist and then you know eventually then you have a full human personality and then who knows
what's after that right transpersonal psychology suggests there may be something past that so you
can imagine these different much like like you have for um quote-unquote physical objects of which all of
us living things are really just metabolic temporary metabolic patterns um you have you have a you have
a spectrum of of agency there and then you can have a spectrum of agency in these kind of patterns too
so so that's so that's what i'm talking about you know this and this is just the very beginning of
this research program so uh uh the the conceptual part of it is to start looking at it as active data
so so yes you have the machine that's moving the data around what if you look at it from the
other direction and especially in um in systems like biological systems where the information
patterns themselves and these might be patterns in the neural substrate so these might be like full
on um thoughts you know traditional thoughts but they also might be patterns in physiological state
space they must they might be um uh patterns of of stress or they might be you know all kinds of things
that physiologists and and uh and different kinds of uh but you know therapists uh deal with
right uh there could be all sorts of unusual patterns and to what extent can you think of uh data
as as driving the show and having its own uh its own life and trying to persist in its environment the
way that the way that we try to persist in ours um so so that that has all kinds of interesting uh
practical implications for for example regenerative medicine and that's the kind of thing that we're
working on now so so could we you know could we look at some of the um you know one way to think
about it for example for example look at our bioelectric patterns right you can you as as we
have for years describe that describe the bioelectric patterns that we see during morphogenesis during
regeneration as literally the thoughts of the morphogenetic collective intelligence so you have a
cellular collective intelligence it's trying to navigate morphogenetic space to get from from an egg to
uh to a full body or to regenerate a limb or something so it's navigating that space and the
bioelectric patterns are the thoughts of and we can read and rewrite them now to some extent they they
literally are the thoughts of that agent in exactly the same way that electrophysiology in the brain
represents the cognitive content of beings navigating three-dimensional space so that's the the the more
conventional story as weird as that is but but that's a that's a more conventional sir the the new way that um
i'm starting to explore now is what if it's actually backwards what if the physical body that we're
looking at is the tape and it's the it's the bioelectric patterns that are really the driving
agent and that what we see when we look at the consequences of that which are changes in second
second messenger function gene expression uh chromatin you know epigenetic changes and then finally cell
behavior changes and morphogenetic changes what if what if that's the tape right the physical body
is the uh is the is the memory medium and uh and and uh there's there's significant um
significant action going on at the level of the physiological patterns themselves and so that
suggests some more applications uh and ways to test these ideas and that's what we're doing now
this is very very early days that's fascinating so i have so many different questions i could go here
but i do want to stick on this um concept of memories as agents so correct me if i'm wrong and
uh i'm gonna try to restate some of this so we can think of memories as let's say transmissions from
the past and we have to interpret those they're not just given to us memory i'm sure many many many
listeners know but not not everybody knows that memory is not like a storage cabinet you don't just
go in pull out the thing you have to actually not confabulate that's going too far probably maybe not
but you have to um recreate the memory um there's some trace of it memory trace of it and you have to
actively i mean we're doing it we do it spontaneously right it's uh not a conscious construction but we have
to do that so if we think of them as agents is then would we have to think about say information
patterns more broadly as being agential so some of the examples you gave memory is like say one example
but is any pattern of information potentially agential then yeah that's a great that's a good point
but potentially yes you we don't know you can't automatically um decide that that's the case
any more than you can do that with with with physical objects but yeah potentially that's the
case which means that you have to uh you have to try to apply the tools that exist for this uh to see
to see whether that gives you an advantage and if you find one then then there you go um you know
you can imagine and so this is this is a part that i left out about these um these patterns these
memory patterns that have to be reinterpreted uh from from from sort of time slice to time slice of
a being when you look at it from the perspective of the of the being themselves you see that uh you see
that um uh bow tie architecture so you see that okay you're the recipient of a bunch of compressed
information and now you have to creatively expand that engram into what do i do you know the choice okay
that's that's from the perspective of the of the of the thinker now from the perspective of the thought
itself it might be and i'm not i'm much like with our basal cognition models i'm certainly not
claiming that uh these that these thoughts are high high level agents like humans you know i mean some
of them might be you know the dissociative um sub personality alters are close i mean they're you
know they they they have a lot of those features but but some could be very low level intelligences
and doesn't you know you don't have to be a high level self-reflective
mind to be a to be some kind of intelligence but but but from the perspective of that system
what what might your goals be well one goal might be simply to persist that that you know that might
be a simple kind of darwinian way to think about it so so from that perspective if you're a pattern
what you would seek to do is to change yourself and also the the thinker or the system around you in
a way that makes it easy more easy for you to propagate into the future or in fact uh you know
most likely that's not a sufficient story most likely you don't just want to persist you want to
expand into other spaces which means you want to alter yourself in a way that would allow you to
colonize as as many other thinkers and as many other um action spaces as you can so for example you know
so so so that means that the the caterpillar wants to encode and the butterfly wants to decode in a way
that um reuses the information uh adaptively but the information itself uh might work in to to uh to
have features that make it easier to be encoded decoded and propagated into new uh into into into new
embodiments and and we see this we see this a lot in experiments and memory transfer um they kind of um
you know you see you like like like when when david glansman does this the the the rna uh you know
they train a sea slug and they and they extract the rna from from its nervous system and then they
inject it in the into the into the brain of a of a naive donor and then you can see memory transfer
i mean it's it's fabulous work wow yeah and there's been definitely with that oh yeah yeah so this is so
this is david glansman's work um looking at the the basis of memory and there are there's a lot
of other work in the past that's been done about moving either either chemical extracts or pieces of
tissue from a trained animal to a naive animal and so on but but to me one of the most amazing things
about that kind of work is that you know when you introduce let's say the rna extract into the donor
into the host recipient you don't micromanage where the rna goes you don't put it into the right
neurons to run the thing like a puppet you just sort of you just sort of inject it somewhere into
the brain and yeah you know no it works it's no problem it just kind of picked up and so so this
idea if we have other examples that are others that are still unpublished of of something similar in
morphogenetic space so so yeah you know i i think there are incentives on both sides actually for these
to be uh reinterpretable and for the for the agent to be good at reinterpreting them and for the
memories to be good at uh at being the subject of that kind of process and thus colonizing the future
you know colonizing that and expanding into into new spaces and then of course they face exactly
the same paradox that we started out with which is that if you change enough you're no longer what
you used to be and so is that okay is that persistence or is that you know you've now you're gone
now and some something else exists yeah it's beautiful it makes me think of you say persistence a few
times the persistence of memory by salvador dali just makes me think of that uh of that painting
the and i know i wanted we wanted to cover three papers but i actually think that there's so much
meat here i'd love to stay on this one if that's okay with you and the bow tie architecture in
particular that's something i wanted to definitely dive into because it's not a familiar concept to
myself and i imagine for many listeners it won't be it either but it seems like there's something
about this this shape the structure that you know it cuts across it's like a pattern across patterns
right um so can you tell us a little bit like how did you discover this i mean it also looks like a
cognitive light cone i mean it's just like this pattern that you see over and over again
and how did you first come across this idea or i don't know if you came up with it or
um brought it together but can you tell us more about it well i certainly didn't come up with the
bow tie architecture so so that's been around for a really long time uh it's been around in biology if
you look at um things like signaling networks you know a real um common one is there's a million
different things that cause calcium fluxes and calcium fluxes cause a million other different things so
you have this boat where like all this different stuff feeds into calcium and then and then it
fans out again and and there's a lot of discussion in the community okay but how does the specificity
work if everything boils down to calcium how do you figure out on the other end what which one of
these things and that's the whole point is that it's not meant to be a one-to-one mapping uh it's not
that the end the endpoint tries to figure out okay so i know you're encrypted but which one but i'm
going to decrypt you to know exactly which microstate caused it that's exactly not the point of these
networks um the other the other place that this cropped up and i didn't invent that either is
um the autoencoder architecture which is used machine learning where the idea is that you have
these these layers of a of a neural network like structure but in the middle there's a very thin layer
that forces um generalization it's it's it's thin and it's in its uh its information capacity is small
such that you cannot afford to remember details the only way the information is going to come through
in a in an adaptive way is that you uh you compress and you generalize so and that and that forces the
generalization by not by by putting a layer or or several layers in the middle that are um that are uh
very uh very very thin in terms of how much information they can propagate you're forcing the
system to generalize it's a bottleneck that that that that requires you to uh uh to learn concepts
and not try to not try to recover individual details and so that's very important for intelligence
because the whole point is that you should abstract patterns of what's happened before and apply those
patterns to scenarios you haven't seen before so so that so that architecture has been used in a few
different um in a few different uh systems but what i do think is new in this and and there's another um
there's another paper related to this um uh that's uh that's uh come out uh well it's a it's a preprint
that that came out recently by kevin uh mitchell and then nick cheney that also looks at this at this
concept where uh we can now use that architecture to understand what's going on in biology the idea that
these really are i mean the i i i think there's two fundamentally um unconventional things in this in this
paper like two big themes one is the symmetry or the invariance between cognition and uh and and and
development so um development broadly speaking the you know morphogenesis and so so the idea is that
uh there's a reason you know uh why um uh there are there are there are deep deep deep fundamental
similarities between how you construct bodies and how you construct minds and so what i'm after is
the what those those principles and what is what is happening with the information that requires
morphogenesis to be an intelligent process and how that works during on an individual scale but also
on an evolutionary scale i mean that's the other nice thing about this is that you can apply this to
whole lineages you can apply this to an individual being uncertain about what their memories mean or you
can apply this to a um uh an evolutionary lineage where you come into the world and you have this dna
but you know you you're going to need to reinterpret it and this is why by the way this is this is um
something that's going to come out in the next uh in the next uh month i guess or so uh is some of
our work on transcriptomics in um in xenobots and anthrobots so the bottom line is that they have a they
have a both of them have a radically different transcriptome than um than the tissue of origin
in vivo and so the dna is the same but in your new environment and more i mean the environment's
not that different actually the environment's almost the same what's different is your embodiment
you have a new shape a new a new way of getting around a new a new function new behaviors and how are
you going to use the affordances you receive from evolution all the dna and all the the other
uh cytoplasmic components that you have how are you going to use them for your new for your new life
and so that's so that that i think that that invariance and that that scaling across space
across time the the the movement of of concepts from from cognition and behavior onto uh the construction
of bodies you know morphogenesis so i think that's that's kind of that's kind of new and also uh this
this idea of uh the information that moves through these um these these kinds of bow ties as being
potentially uh an agent too which means asking ourselves what does the world look like from the
point of view or from the perspective of that information it's interesting from perspective
information i mean i think a very uh this is like comical that that going through it to a bottleneck
right the information i mean as if it had a perspective or as if it could see but uh imagine
that being very quite scary actually to be condensed down and compressed down but then of course there's
the way through and then more expansion on the other side of it yeah so right so so i think i
think scary is the is the right term because this and and you know i don't not to get into matters
that are kind of above my pay grade but but uh it it does sound like a lot of things that um people who
and and i've had a lot of um contact from from people who work in therapy and psycho psychiatry and
and on on these kinds of ideas this idea that you're going to go through a bottleneck what comes
out on the other end if you if you want to compare details it's not going to be you because
you're not going to be the same on the other end of it um but that's the price you pay for improvement
for learning for growth for projecting into new problem spaces for creating new meaning and so right
so so that is scary and it's especially scary if you commit to a kind of um object permanence with
respect to the self so if you think you are a stable thing then yeah you're in trouble because no matter
what you're not going to be here for very long but if you have a more process view where what you are
are a kind of pattern with certain features and you have the ability to shape those features over time
and that already means that you the old you is not going to be here but you get to shape the new
you in the in and but the environment's going to try to shape them as well so there's some some
tensions there but but yeah yeah i think i think i think you're exactly right it's this it's it's back
to that same paradox that that that kind of architecture gives you the plasticity and the intelligence
to uh to adapt and exploit other uh other realms and other domains of activity and and and so on
but that means you are not going to be the same right there also this brings to mind of course it's
a speculate very speculative idea uh the idea of like white holes black holes and white holes on the
other side of them and i see this pattern i have the paper in front of me and i can't help but think of
that connection there potentially i know that's way out there um sci-fi land here but do you think it
gives any credence to that idea or it's it's interesting i mean i i don't know this is this
is the kind of thing you know paul davies or somebody would probably want to want to talk about
that too so i i don't have the physics to know what's supposed to happen to patterns as they as they
go through a wormhole like that but um i i don't think it's crazy to to ask the question uh with respect
to i mean especially if okay under normal under sort of conventional theories you wouldn't expect
anything like that uh you wouldn't expect there to be any reason why the the these things would map on
to uh to that to that wormhole scenario but if you buy into some of the um evolutionary universes
approaches like i think lee small and has one and then um then then it becomes uh i think perfectly
a perfectly reasonable hypothesis to say that the same dynamics that led to this bow tie architecture
in the biological world if if those dynamics exist at the scale of whole universes maybe maybe maybe
they give rise to exactly the same kinds of information dynamics through the word through these
wormholes i mean this is like way beyond you know anything i don't know as far as realistic physics
but um i i think i think i think if you take the longer view of like some of those some of those
um some of those models then then i don't see why not yeah it's fascinating the other thing too i'd
love to a big topic um in the paper you talk about confabulation and actually would you mind
potentially defining confabulation uh for the audience that you talk about in the paper a bit
but i just wanted to get like um can we think about it like as being like hallucinations with ai
i know that's something that's brought up or i've heard that term discussed with ai uh before is that
the same kind of idea are those different so i i i okay um i i don't have any reason
right now to think that the kinds of phenomena that we see in uh in in current language models
are the same have the same origin where where the confabulation has the same origin as it does
for us i will put a asterisk there that we can talk about which i think is that we have to be very
humble about our claims of even though we write these things and we make them and whatnot i i for for a
number of reasons that we could talk about i think we have to be um quite agnostic still at this point
about what's actually going on there but um uh but but the end point is is actually i think quite quite
similar which is the desire to uh or the or the functional drive to uh output behaviors that are um
more adaptive given current circumstances versus the circumstances that gave rise to them so an
allegiance to saliency and adaptive quality not to history or veracity or uh or fidelity of the data
and so so so let's just let's just define um what what we mean when we talk about confabulation
um here are some here are some examples that uh that that people have found in in human human patients
uh some of the some of the um earliest ones were from split brain patients where you sever the corpus
colossum and so you have the the you know there's a speaking you typically there's a speaking hemisphere
and one that doesn't but but the one that doesn't is operating half of the body and when that half of
the body does certain things uh the the speaking half makes up stories about what's going on there
even though we know so so so so we can put you know we can you put a piece of a piece of cardboard
between the eyes like this and you show one side of the brain uh some kind of thing and then you ask
the uh the the opposite um you ask the opposite hand to pick out a relevant object and then you ask the
language speaking side hey why did you pick up this object well it has no actual idea because it did
not see the prompt but it'll come up with some story that vaguely makes sense and it doesn't feel
like lying to the subject it just feels completely natural because we are driven to make stories about
ourselves in our world that makes sense that's a that's a fundamental thing and um uh so another
example i can think of is uh there's a there's a video on um that i saw where a patient had a um
he had an electrode uh i think it was for epilepsy um in his brain and it happened to be uh touching
a region that course that that induces laugh laughing behavior and so the uh the scientist
pushes the button and the the person's mouth starts laughing and then you ask uh then then he's asked
so why are you laughing and the answer isn't gee i don't know i was sitting here thinking of serious
things and suddenly my mouth starts laughing that's never the answer the answer is oh i thought of a
funny joke and and again if this isn't this isn't them trying to fool anybody this is this is what
it feels like to them because because because all of us are trying to uh uh continuously modify our
models of ourselves in our world to make it to make things make sense and so so that that kind of uh
basic fundamental feature i think is really important now when it goes too far when the horizon gets really
short and you lose track of long-term patterns then that's not adaptive either because because
then you end up with explanations that have maybe immediate value but in the in the long run they're
you know and and i think this is functionally i think this is what's happening with these language
models they they tell you something at the moment that is plausible of the kind of thing you want to see
but but big picture they're not if they're not tied to uh what's actually if they're not good at
reinterpreting the past then then this then this doesn't work i mean it's a deep skill to be able to do that
so so i think it's i think it's fundamental but i think we we still don't understand i mean the
biggest mystery to all of this is like the one the one thing that um you know i've hardly uh cracked
this this deep issue here but all i've done is is draw attention to a new way of thinking about it
the deep issue is how the creative interpretation actually works when you're handed these engrams
decoding them in a way that uh that is adaptive that's really important i think if we understood how
that works we would have much more insight into into ourselves but also into new uh computational
frameworks that would do a better job than than our current efforts
okay interesting okay so it's a little different than it's a little
askew from what i was thinking of originally are you familiar with it all with um
greg henriquez he's a psychologist at james madison university yeah this reminds me a little bit of his
one of his course concepts around uh that we're self-justifying apes and so when you say something
like yes one part of the brain is explaining something that has no access to the thing that
we're doing all the time much of the time is just sort of justifying stuff is that right or is
i mean i mean yes yes i think i think there's a lot of value in that but also um i don't remember who
said this it might have been uval horari or somebody said that you know humans are fundamentally
storytellers like yes but this isn't just about humans this is about all agents so all good agents if
if you're not a good storyteller in a in a primitive way right meaning making models making actionable
models of yourself and your outside world you will never get out of the single cell phase in fact in
fact you will not survive as a single cell and i don't think you'll survive as a persistent uh
you know chemical pathway either you this this this storytelling uh you know by the time you get to
humans we call it storytelling but but that fundamental thing that active inference kind of loop that
causes you to to store some priors and to try to figure out what exactly is going on in a way that
is going to allow me to make the decisions which are you know are coming up very you know constantly
you have to write in the in the real world you're going to run out of energy and die and be eaten very
quickly if you're not constantly taking actions uh that requires modeling and that does not wait till we
get to human stage that was there from day one of evolution and possibly before that
storytelling are there any let's see i'll say patterns or
huh in terms of these information patterns do you notice any patterns that resemble anything like
storytelling frameworks or elements of storytelling that we are more familiar with as humans
yeah well i i do think it would be a it would be an amazing project for somebody uh and and you know
maybe there's there's a few people i've i've talked about this around here that might want to do it is
to take something like joseph campbell's um uh right on of archetypes or or you know these kinds of things
and try to recast them as what what what do those things look like for single cells what do they look like
for pathways and and i mean here's right i'd like i think i think that would be that would be completely
uh fascinating um but uh you're speaking my language that's like amazing that that is a great idea
yeah i think i think that would be really interesting and you know like like one pattern i mean i'll tell
you one one that i can think of right off the top of my head uh and i'm no i'm no you know
expert on on myths or anything like that but but but one thing that i think is really fundamental
is uh seeing agency in the world telling stories about agents doing things i think is really
critical and here's why if and and i think and i think any any real realistic agent that had that
evolved under constraints of energy and time is going to need to do this because again just to come
circle back to the beginning if you you as a living system that is vulnerable you know these mortal
computations uh as as a few people have called them um you do not have the luxury of being a laplacian
demon that says i don't believe in mesostates or large scale patterns i'm just going to track
microstates all i care about is every particle every atom i can measure and and i'm just going to track
them okay well you don't have time to do that you'll be dead if you if you try that strategy so the only
things that survive that filter are agents that are good at core screening so what they do is they say
okay i'm going to take a bunch of these these all of these states i'm gonna i'm gonna ignore what's
different about them but i'm going to establish a category that i'm going to treat them all the
same way i'm going to generalize and i'm going to say all of this is you know that it's this this is
hunger or this is a chemical attack or this is danger or this is a stress or this is um you know
whatever right and so and and then later on it's like oh this is a tiger and i don't care if the pixels
are this way or that way or there's lighting shadowing you know and so on so um you have to get
good at it in order to survive you don't have the computational uh resources to to avoid that and
and that leads to that that kind of thing if you become an agent that is constantly telling stories
about other agents in the world doing things that then leads to you making models of them well how do
what are the properties that these agents have do they what do they notice what do they you know can
i hack them can they hack me are they dangerous are they positive whatever uh and then eventually you
turn that on yourself and you say wait a minute i'm an agent too that does things and now you've
got a model of yourself as this magnificent you know uh moral moral being that that exists right
this kind of self-reflective loop but but you can but you can in fact must do that long before you're
capable of of doing that um that self-referential stuff you know that self-referential loop so i think
that one you know uh that fundamental that that concept of an agent in the world doing things not
just not just uh standing back and saying here's a bunch of stuff that happened and i've totaled up
all the atoms that zigged and sagged and whatever but but but i've course grained them into a into a
some kind of a larger scale pattern where the pattern makes decisions it has memories and by the
way it pays off if i try to make a model of well what kinds of things does it remember for how long
what does it like what does it not like uh what some level of you know uh some level of of predictive
description that i think is is extremely fundamental yeah and even well and i think about it in terms
of more broadly the the effectiveness of great storytelling and how yes you might have a con a
concept a complicated thing in physics right but if someone a great educator
can hone it down and break it down and have an anecdote about it and maybe give some personalities
to the quarks and electrons so that we can kind of glom on to certain things and we interpret those and
we kind of make sense of them in a better way even though they don't have personalities per se um i
like to think about them as having personalities or having not not personhood but um attributes let's
say or or things that um like i can understand um i'm kind of talking in circles here but yeah yeah
it's a really cool idea i i like that yeah i mean it makes what what you just said makes it makes sense
for in in two ways one is that like in that paper we give a table um or i give a table of things that
act as uh as these bow ties and uh scientific papers language literature all of those things act as
bow tie fashion you have some very complex mental states you have some very complex um synaptic uh
you know molecular states there's no hope of you communicating those states and mapping them onto
my brain so that we understand each other my brain is different it's not going to work anyway what we do
have is a very thin interface that you know however many bits per minute we can do it that's language
that allows this very complex set of events to come forward and to then in then to be expanded in my brain
into whatever it takes for me to understand whatever part of what you said i understood
you know whatever whatever i'm supposed to get out of it and so the same thing with science papers
right so these brilliant people have these incredible ideas they boil it down to a you
know to a nature paper that's like this compressed you know squeezed a couple of pages representation
and then all everybody else the rest of us read it and try to reinflate it and say well what does
this mean what am i going to get out of it and and right so so a lot of these things are like that
yeah yeah great i know you have to run i just want to ask you one one last question
um so based on the conclusions of this paper uh are you going to follow us up with any research do you
have anything uh what comes after this basically yeah yeah we yeah we have we have a ton of stuff so
so well conceptually uh what comes off after is some computational work that we're doing to tie
um uh the uh the polycomputing framework into all of this and so um uh atusa parks who uh was uh was
a student with uh josh bongarden was responsible for a lot of the actual primary work on the polycomputing
i mean she she drove the the early polycomputing work um she's she's now in my in my group and we're
going to uh basically turn this whole thing into a uh a model of uh an evolutionary model a model of
for a new type of um you know a computational uh platform and so on but then but then the biology of it
uh becomes really a search for the mechanisms of this creative interpretation so when you do have
uh when you do have these engrams what are the mechanisms by which those get mapped onto whatever
the novel um scenarios and the novel problems are and that's that's something that we're using in our
synthetic morphology models like anthrobots and abouts and some other things that will come out this
year where we can actually start to ask because because they're i mean one reason for making those
things is that they're the problem is is stands the starkest you're you're you're a xenobot you've
been given some dna was any of that dna about how to be a xenobot most of it wasn't at all there's never
been any xenobots there's never been selection to be a good xenobot um you know there's some physiology
in there that you have in common but but but a lot of it um and the same thing the same thing for
the endrobots when you one of the values of making these uh synthetic models is that you force them
to break free of a specific evolutionary history and then you get to find out how do they reinterpret
the the affordances that they've been given um and where do these novel patterns come from they have
new patterns of behavior and and so on so so memories that were not specifically encoded for them right
because if you i mean just think about this if if you have the ability to reinterpret these little
these little um engrams that you've been given that creative ability you can now nucleate that off of
a lot of other things you know you could there are lots of prompts that that you can apply that same
capacity to it doesn't have to be the same the same materials that you were given before if you have
the ability to interpret specific memory engrams that were used for behavioral memory you can turn
that capacity onto almost anything so i almost visualize that like the right side so you got
this bow tie you know they meet in the middle i almost like visualize unmooring this side and and just
start start nucleating it off of off of other things this is this is like again brand new i have
no idea how this is going to play out but something that we're interested in is uh studying how cells and
tissues do that in health and disease and and so on oh so cool all right mike thank you so much for
your time we we want to cover three papers i wanted to but we got we got deep into one which i think is
i i prefer that in terms of going deeper into one thing than glossing over uh maybe three but maybe we
could talk again and we go into the uh stress sharing paper and i can reach out to uh to you and emma and
uh sure yeah yeah yeah i got some time uh and we'll we'll we'll talk about the other stuff yeah no
problem great thanks so much mike thanks really appreciate it thank you
