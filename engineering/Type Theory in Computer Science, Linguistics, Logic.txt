Hi guys, today we're going to be talking about type theory, what it is, where it comes from,
how it works, and what it's used for, how it's going to be used in computer science,
in linguistics, in logic, and in philosophy. I think this is going to be a pretty big one,
so grab your cup of tea, strap yourself in, here we go. So type theory is, like the name says,
a theory of types. So to understand it, we need to know what we mean by types, and the best way to
get a grip on that is through some really simple examples. So here's a really simple example from
basic arithmetic. Let's talk about the natural numbers, call that nat. That's going to be the
type we're interested in, in this example. Okay, so 0, 1, 2, they are all objects of type nat. Okay,
now think of the kind of functions that we can do on those objects. So we've got the successor
function, or the plus 1 function. So that's a function that takes in one natural number,
and it gives us back a natural number. So it's got the type nat2nat. Okay, we're going to write it like
this to mean it's a function whose input is a natural number, and its output is a natural number.
Okay, pretty simple there. We've also got the addition function. Okay, what's its type going to
be? Well, that takes in two natural numbers, or a pair of natural numbers, and spits out another
natural number. So we can say it's got this type, from a pair of natural numbers, we'll write that
like that, to a natural number. But there's another way of thinking about it, okay? Rather than thinking
of it as taking in two natural numbers at once, or a pair of natural numbers, we can think of it as
first taking in one natural number, and returning another function from a natural number to a natural
number. Okay, often when we do type theory, we're going to consider functions like this. So this is
sometimes called the curried form of that function. It always takes in one input, but it gives us back
another function, which maybe takes in one input, and gives us back another function, until we get
the output. We should call this a function from natural numbers to functions from natural numbers
to natural numbers, but let's just abbreviate that too. It's a function from natural numbers to natural
numbers to natural numbers, and it basically means the same as from a pair of natural numbers to a
natural number. Okay, so there's some simple examples of some types, types of numbers, and types of
functions from basic arithmetic. Here's an example from linguistics. So here we're going to consider
two basic types. We've got the type of individuals, so like people, let's say, we'll call that I,
and we've got the truth values, because in linguistics, ultimately, we want to evaluate sentences
for their truth. That's kind of how we're going to assign meanings to them. So we've got the type T of
truth values. So in a linguistics context, we can either assign the types to the words or to the
things that they denote in the semantics. We can kind of do it either way. Let's just do it with the
words here. So we've got this name, Anna, that's going to denote an individual, and then we've got
this verb, sings. Okay, so that is going to be something that takes in a name for an individual and
gives us back a truth value, depending on whether that person sings or not. Okay, so it's going to
be of type I to T, from individuals to truth values. So one-place predicates, like sings, are going to
have type I to T. Okay, a transitive verb, a two-place predicate, like likes, okay, X likes Y, that's going to
be something that takes in two individuals and gives us back a truth value, depending on whether the first
person likes the second person or not. Or the way we're going to do it here, we're going to do the
covered version. It's going to take in one individual and give us back another function from individuals
to truth values. Okay, so it's going to be of type individual to individual to truth value. Okay, so
given that those words have those types, we can start combining those words into meaningful sentences.
Okay, so likes needs an individual term first, like Anna. So likes Anna, that is going to be
something that takes an individual term to a truth value. Okay, so likes Anna combined with Beck,
that's going to be something of type T, a sentence, something that has a truth value.
Let's just continue this example a little bit further because it gets a bit more interesting.
Okay, so we've got sings of type individual to truth value. What about a quantifier like everyone?
We'll forget how quantifiers work in logic for the moment. Just think about how they work in English.
We would normally say something like everyone sings. Okay, so everyone should be something that takes a
predicate, a one place predicate to a truth value. So everyone is going to be of type IT, that's predicate
type to truth values. So its input is going to be a predicate. The output is going to be a truth value.
So we can form everyone sings. That's going to be a sentence of type T. It's going to be true or
false. Okay, great. What if we want to get a bit more complex here? Rather than just everyone sings,
we want to say something like everyone likes Anna. This is going to be a bit more tricky because given
the types that we've assigned so far, the only way of putting together everyone likes an Anna is like
this. First of all, we have to put Anna together with likes to give us something of type I to T.
That is going to be the input to everyone. So we can form everyone likes Anna of type T. However,
this isn't going to be the sentence that we wanted. Everyone likes Anna. Likes Anna is going
to be a predicate applying to the people that Anna likes. Okay, so if likes XY means that X likes Y,
then likes Anna means Anna likes whoever you apply to that function. So likes Anna means Anna is doing
the liking. So everyone likes Anna means Anna likes everyone. But that's not what we wanted to say.
If we wanted to say everyone likes Anna, that's not something we can yet do. To be able to do that,
we are going to need lambdas. We're going to need to use the lambda calculus. Type theory and lambda
calculus, they go together so well that they're basically considered the same theory in computer
science. We're going to get on to that in a bit. If you're enjoying the video so far, do me a favour,
give it a thumbs up, subscribe to the channel. That really helps me out. And if you want to help
support the channel, you can buy me a coffee over on Ko-Fi or sign up there as a channel supporter.
Okay, before we get to the details, let's talk a little bit about where type theory comes from.
It's got a really interesting theory. Let's go right back to the beginning because type theory,
like lots of stuff in philosophy and logic, it starts with Frege and Russell. So Frege, he was
interested in trying to understand all of mathematics in terms of logic. Okay, he wanted to reduce
mathematics to logic. That's a view known as logicism. He had this principle he called basic law five,
that every concept has an extension. In modern terms, we might say that every predicate or every
open sentence determines a set of things, the things that satisfy that predicate. And this principle was
central to Frege's demonstration of the reduction of mathematics to logic. Unfortunately, the principle
is inconsistent. This is what Bertrand Russell noticed. And one way of seeing that it's inconsistent is with
the Russell set. Okay, so we think of sets of things that contain themselves, we think of sets of things
that don't contain themselves. And then we try to form the set of all sets that don't contain
themselves. Okay, then ask yourself the question, does that set, the Russell set, contain itself or
not? Well, if it does contain itself, then it's by definition, not a member of itself, contradiction.
And if it doesn't contain itself, then by definition, it does contain itself. So either
way, we've got a contradiction. It's a paradox. It's Russell's paradox. It's a paradox of naive set
theory. Okay, this confused a lot of people at the time, not just philosophers, but logicians,
mathematicians. They thought there might be a problem right at the heart of mathematics. And a lot
of people tried to work out a way of formalising logic and mathematics that wouldn't have this kind of
problem. And the solution that Russell came up with is type theory. So he developed this in an article,
Mathematical Logic as Based on the Theory of Types, 1908. And then this forms a central part of his
Principia Mathematica, this kind of huge book or three books that he published with Whitehead between
1910 and 1913. It's a bit tricky to see exactly what Russell's type theory looks like, because
although it's the central part of Principia Mathematica, which is this huge formal work of
logicism, he doesn't really spell out the type theory in perfectly precise formal terms. And
basically, it's a very, very complicated theory because he wanted it to do many, many things. It's
not what we call simple type theory. It's called ramified type theory. He wanted his theory not just to
avoid his own Russell's paradox, but also to avoid any kind of circularity in definitions, what are
sometimes called impredicative definitions. And basically, as a result, the theory got kind of
really hairy and complicated. And yeah, it's just not very nice. We're going to make life a little bit
easier. We're going to look at simple type theory. Russell's theory really didn't catch on at the time,
partly because it was so complicated, but also because around the same time, people have been
developing new kinds of set theory. So you've got Zemilo, 1908, so same time as Russell's theory of
types. And that was kind of added to later by Frankel. So you've got ZF set theories, Zemilo,
Frankel set theory. You've also got Thoros Skolm in the picture there. ZF set theory kind of doesn't do
everything mathematicians want set theory to do because it doesn't decide the axiom of choice.
It doesn't prove the axiom of choice, but it also doesn't prove the negation of the axiom. So what
are you going to do? A lot of people just add choice as a basic axiom, and that gives you ZFC set theory.
And that's been super, super successful as a foundation for mathematics. It's used by working
mathematicians like all the time. You open up a book on mathematics. There's going to be some set theory
in there. You know, you're probably not going to see type theory. So Russell was kind of unlucky,
I guess, in that a competitor theory did really well. And that meant that type theory was almost
forgotten about. Quote here from Skolm, 1922. Russell and Whitehead, too, constructed a system
of logic that provides a foundation for set theory. If I am not mistaken, however, mathematicians have
taken that little interest in it. Yeah, that was definitely true for many, many years after
Russell developed type theory. But then things started to change. And one of the reasons things
could change is the development of the lambda calculus. Lambda calculus was developed in the
30s by Alonzo Church. I'm going to give you a super, super quick overview of it here. I'm going to skip
out loads of details. Otherwise, we're going to be here all day. OK, let's start off with the pure
lambda calculus without types, untyped lambda calculus. What have we got? We have got variables.
They all count as terms. We've got constants. They all count as terms. OK, and if you give me any two
terms, one thing I can do is put them together. That's called an application. That's a term. And the
other thing I can do is I can abstract on that term. So you give me a term, I can form the lambda
abstract. Basically, I put lambda X or lambda Y, any variable in front of it, and that counts as a
term. And it's this kind of construction, the abstractions, that really is the interest in
lambda calculus. What does it mean? Well, you know, good question. But think of this as creating a
function from a term. So I'm kind of adding an extra argument place. So think of this as a function,
and that is its argument. And what we're doing with an application is I'm taking a function here
and I'm applying it to this term here. So creating a function and applying a function. So we can think
of the abstractions as function definitions, and we can think of the applications as functional
application. So the terms of lambda calculus, they're really terms for naming functions.
OK, things get a bit more interesting when we add types there. We've got the simply typed lambda
calculus. OK, so to do a system of types, I need some base types. So that might just be nat, or it
might be i and t for individuals and truth values, whatever. Got some base types. And then we have a
recursive definition. So one way to do simple types is to say, whenever I've got two types,
I can put an arrow between them. So alpha to beta is going to be a type. Sometimes you'll see this
written like this without the arrow, or there's different ways of writing it. But basically,
we're always saying it's a type from type alpha to type beta. And we're going to think of things of
that type as basically being functions from alpha type things to beta type things. OK, so if those
are the types, what does the simply typed lambda calculus look like? Well, its terms are going to
be, we're going to have variables of each type. We're going to have constants of each type. If I've
got some term M of type beta, and I take a variable X of type alpha, then I can abstract. OK,
so lambda X of type alpha M, that's going to have type from alpha to beta. OK, because the variable
has type alpha and M has type beta. Think of this as a function from alpha type things to beta type
things. And we can do applications when M's got type alpha to beta and N has type alpha. OK, so an
application kind of works when the input has type alpha and the function that's M has type alpha to
beta. So that term should have type beta. That's the output type of a function when the input is type
alpha. Now, I'm kind of running a few things together here. I'm giving you the definition of
the terms. That is the syntax of the language. And I'm telling you what types they're going to have.
OK, often in a computer science setting or a proof theory setting, what we're going to do is we're
going to first define these things, our language, and then we're going to set up a proof system with
a bunch of rules that take us through proving these things do or don't have a certain type.
OK, we're going to look at that in a bit. Now that we've got our lambdas, let's go back to the
problem that we had before, our linguistics example, where we're trying to say everyone likes
Anna. But the only way we could do it is like this. And that's going to mean Anna likes everyone.
That's assuming that likes X, Y means that X likes Y. What we need to find a way of doing is putting
these words together kind of in a different order, applying them in a different order without
breaking these types. Here's how we can do it. So likes needs two individual inputs. So we can take
an individual variable X and the name Anna. That's going to make a sentence something of type T. And
then we can abstract on that X. So we get a lambda abstraction. Lambda X likes X Anna. OK, this is
something of type from I to T. So it's a predicate. Think of it as a function from individuals to truth
values. And we're abstracting on the first place of the likes relation. OK, that's the person who does
the liking. So the person who will go in for X here is somebody who likes Anna. That is, if they like
Anna, the value is going to be true. And if they don't like Anna, the value would be false. So what
we've got here is a predicate, meaning is a person that likes Anna. And it's the right type to be the
input to everyone, because everyone wants a one place predicate. So we can form the sentence, everyone,
lambda X, X likes Anna. That's going to be of type T. It's going to take a truth value. And it's going
to mean that everyone is an X that likes Anna. Everyone likes Anna. That's what we wanted to
express. And we can do that because we've now got access to lambdas. In effect, what we've done is
we've taken the lambdas and they've allowed us to swap around the argument places of likes,
so that the first thing you put in isn't the liker, but it's the person who is being liked.
OK, that's the kind of thing you can do with lambdas. OK, so there is a super quick introduction
to type theory. But what is it for? How does it get used in various different disciplines,
computer science, philosophy, linguistics and so on? Let's start with computer science. So in this
setting, what we're often trying to do is prove that a certain term has a certain type or to put
it another way, that a certain type is inhabited. There is some term that belongs to that particular
type. OK, so the way we would prove that is kind of like in a proof system. So we're going to have a
bunch of rules, a bunch of axioms. And what we're going to try and prove is that term T has type alpha.
Let me give you a super simple example of how that might look. Suppose we just take it as axiomatic
that our constant zero is a natural number. OK, so it's got type nat and the successor function
has type nat to nat. OK, takes a natural number to a natural number. One kind of inference rule that
we've got is the application inference rule that says from those two things, I can infer that this
term successor applied to zero is of type nat. That's pretty obvious, right? If a function
takes me from nat to nat and I give it an input that's a nat, the output successor of zero is going
to be a nat as well. OK, nothing particularly exciting going on there. But as often in proof
theory, you combine a bunch of super simple things and you get interesting things. So we can do it
again. We can apply that same structure to our successor function again and we get the successor
of the successor of the successor of zero, i.e. two. That's a natural number two. We can do the same
kind of thing with our addition function. So if we take it as an axiom that that's got type
nat to nat to nat, then we can combine that axiom with our previous proofs to infer first that this term
is a predicate from natural numbers to natural numbers. And this term is a natural number. OK,
so adding two to one, that's a natural number. So one thing to notice here when we are doing
proofs involving types, that is a kind of type checking, we're not actually calculating the
numbers, right? We're not calculating the answer of two plus one. What we're doing is we're saying
what kind of type does that expression have? It's going to be a natural number. We're not saying what
natural number it is. We're just saying it's got the right type. So when we're doing program
verification, type checking in a formal setting, like with computer programs or whatever, we're not
always checking that the program is going to give us the right answer. We're checking it's going to
give us the right kind or the right type of answer. Like it's not going to give us something completely
random. It's not going to throw an exception or try and put the wrong kind of thing into the next bit
of the program where it kind of gives up and goes home. OK, that's kind of what we're doing when
we're type checking program verification in computer science. OK, let's take this idea a little bit
further. So we've shown the highly exciting results that adding the number one to the number two gives
us a natural number. But what about if we wanted to do something more general, like adding any two
natural numbers gives us a natural number? How would we do that? So what we're going to do is make some
assumptions. These are called contexts. Our proofs are going to be proofs from assumptions or within
a context. OK, so our assumption is going to be that we've got two variables, x and y, and they are
both standing for natural numbers. So our context is going to be this, x and y are natural numbers,
and our proofs are going to be proofs from that context. So we've got our axiom, we've got x is a
natural, y is a natural number, and we can reason as before and say that x added to y is a natural
number. So we could take this further with some universal introduction rules because x and y are
basically dummy variables, and we can infer that adding any two natural numbers, x and y, will give
you a natural number. OK, now let's have a look at how type theory works in logic, and this is going
to be related to higher order logic. So what do we mean by higher order logic? Well, lots of people
are familiar with first order logic. The first order bit there means that our quantifiers are
quantifying over things, the x in fx. OK, so over people and rocks and chairs, objects, basically,
particulars. Then we've got second order logic. Here we've got quantifiers that quantify over the
predicate position. So you can think of that as meaning quantifying over the properties and
relations. OK, so this sentence might mean for any property, if a's got that property, then b's got
that property too. OK, you don't have to read it in terms of properties, but it's kind of what's going
on in second order logic. We've moved up a level from the objects to the properties of the objects or
the ways that they are. OK, go up another level. We're now talking about third order logic and we're
talking about properties of properties. So things like red is a colour. OK, I'm applying a property
being a colour to a property being red. Red is a colour. So a sentence like this here, we've got a
third order quantifier. This is a property of properties. So what this is saying is there is some
property of properties like, I don't know, being a good property such that for any property, if it's
one of those, like if it's a good property, then a and b don't differ. So this might reflect a
situation where a and b share all their good properties, but maybe they differ in their bad
properties or something like that. So here we've got some specific levels of logic. First order,
second order, third order type theory gives us a way of going up the orders or up the type hierarchy
up as high as we want to go. OK, so arbitrarily high kind of what we've been doing implicitly in
these logics is saying here's a predicate and it's taking an individual variable and here's a quantifier
and it's quantifying over individual variables. And here's a second order quantifier. It wants a
second order variable and here's a third order quantifier. So we're kind of defining these
implicitly with types by saying what kind of thing does it want as input and what kind of thing does
it want as output? So if we do that in a completely general way, we use type theory and then we can have
logics of any type or any order. OK, to make that a bit more concrete, a bit more specific, let me give
you an example of one particular higher order logic. So this is from Galen 1975. It's called TY2.
OK, so to define it, first of all, we define the types. So we're going to have three base types. We've
got E for individuals. We've got S for in effect possible worlds or world time pairs. Kind of ignore
that for the time being. And we've got T, the truth values like we had before. And the complex types of
the theory are just the ones that we saw before. So you give me two types, alpha and beta, and I can
put them together in a new type. So we're just writing this to mean the type from alpha to beta.
Sometimes we write it without the arrow, basically just to save space on paper. So that's the types.
What are the terms of the logic look like? Well, we've got constants of each type, variables of each
type. We've got lambda abstractions and we've got applications, just like in the simply typed
lambda calculus. We're also going to be able to form a term A is identical to B whenever we've got
two terms at the same type. OK, so we've got identities, not just between objects like I am
the person talking on this video right now, but also between like properties. So saying that, you
know, being triangular is the same as being trilateral. So we've got the ability to form identities
for any type. OK, that's quite a novelty of higher order logic. We've also got a special type, things
that are of type T, like the sentences. They are the formulas and we are going to apply logical
operations to them. So negation, conjunction, disjunction and universal quantification. In more
complex type theories or higher order logics, we might be allowed to apply some or all of these
operations to things of any type. So like if you say, you know, me and you, that is a conjunction
applying to individual terms. We're not doing that here. We're only applying the logical operators to
sentences, just like we do in standard logic. That kind of keeps everything a little bit simpler.
OK, what does all this stuff mean? Well, we give this logic a semantics and the way we do that is
through frames. OK, frames is just a way of assigning the terms of the logic to basically
functions. So a frame is a set of sets. We're going to have one set D alpha for each type alpha.
Really, these can be anything we want as long as those two aren't empty and the domain of the true
values has to be the true values. So zero and one or true and false or whatever you want to call them.
And then for each complex type alpha beta, we want that to be a set of functions from domain alpha
to domain beta. So we're interpreting the terms of a complex type from alpha to beta as functions
from the domain of alpha to the domain of beta. So the domains kind of run in lockstep with the
definition of the types. And then on top of this, we give a truth definition, which tells us
when these sentences are going to be true or not. So we inherit all the stuff we know and love from
standard logic. So, for instance, a conjunction, it's true. Well, it's just a minimum of A and B.
So it's true when both A and B and true and it's false otherwise. But we also have to give
denotations to the other terms, the lambda abstracts and the applications. Applications are easy,
right? Because if we're applying A to B, A's got to be a function and B is going to be an argument
that we can put into that function. The type system guarantees that. So how do we interpret
A applied to B? Well, we just apply function A to input B. Easy. So what is the denotation of a
lambda abstract going to be? Well, we want it to be a function. We want this to be a function
that takes in things of type and gives us back something in the domain of the type of whatever
A is. OK, so this is going to be the function such that if you put in any D from the domain of A,
it's going to give you the denotation of A. OK, that is quite a mouthful. But if you work your way
through that definition, it's basically just saying it's the function it should be. It's the function
from things of type alpha such that you put in any one of those things in and it's going to give you
back the the denotation, the meaning of A relative to that input. I am being a little bit sloppy here
because A might have some free variables in it, in which case we have to substitute into it. But,
you know, rather than going into the whole business of variable assignments and that,
let's just leave it as, you know, it's the function that we kind of expect it to be when we do a
lambda abstraction. OK, so this is not the only way to do higher order logics. There are loads of
different varieties, but this gives a sense of how we can come up with a very well-defined logic
using type theory. Let's move on to linguistics and how type theory gets used in linguistics.
Now, this is a huge, huge subject because if you look at any textbooks on Montague semantics or
formal semantics, compositional semantics, compositional linguistics or whatever, it's
basically going to be just chock full of lambdas and type theory. In some ways, modern compositional
semantics just is applying type theory and possible world semantics to natural language.
OK, so these theories are kind of so closely intertwined. Let me just give you a few examples here
just as a flavour. So suppose we're trying to understand adjectives. OK, like quickly. OK,
so I can run quickly or I can run slowly or badly or whatever. So quickly, how does that function as a
term? So let's think about how quickly might work, what its meaning might be. It's not really working
like our property of a property example that we had earlier. Right. So red is a colour. OK, I'm applying
the property is a colour to a property is red. But I can't really say, you know, runs quickly.
That doesn't make a sentence. It's not true or false. So it's not a property of a property.
Really, what it's doing is it's taking a predicate and it's transforming it into a new predicate.
OK, so taking a predicate like runs, which is something I can do, and it's transforming it into
a new predicate. Runs quickly, which is something I might do or not do. OK, this is called a predicate
functor. It's something that takes one predicate and gives us back a new predicate. So it's got this
type. OK, it's taking in a predicate, something from individuals to truth values, and it's giving me
as output something from individuals to truth values. So the input might be runs and the output
might be runs quickly. OK, something that applies to me is false, but applies to a speedy person is
true. So then we can analyse a more complex sentence like runs quickly and gracefully,
not something I do like this. So here we've got one predicate functor, an adjective. Here we've got
another and we've got this dummy variable here. We can lambda abstract on it, and that gives us a
a one place predicate, something from individuals to truth values, and it's going to apply to people
who run quickly and gracefully. OK, so we've got a predicate formed from these predicate functors.
And a nice thing here we can do is we can use the deductive power of type theory of type lambda
calculus to beta reduce. OK, so if we take this predicate and we apply it to Anna, this will reduce
to the sentence Anna runs quickly and Anna runs gracefully. So we've got this nice kind of
equivalence between applying the predicate to an individual and just the straightforward sentence
in which we're expressing each of those conjuncts of Anna. There's a more general reason why people
working in contemporary formal semantics really love type theory, type lambda calculus, and that is
because it meshes in a really nice way with the way people look at syntax. OK, so if we take some
sentence, we want to be able to analyse its syntax and then, as it were, pass that over to the semantics
people to to analyse its meaning. And the way a lot of people analyse syntax is in terms of what's
called categorical grammar. So we're going to take some terms, some words, and we're going to assign
them categories which are going to be like instructions for telling us how to put sentences
together in well-formed ways. Let's take the example of a transitive verb likes. It's going to have this
category and that means it wants a noun phrase like a name on its right and it wants another noun phrase
on its left. And if you do that, it's going to give you a sentence. So this is the grammar,
the syntax of the term likes. But that's going to correspond really closely to what we said in our
type theory, right? Because likes as a meaning is going to be a function that takes in one
individual, something corresponding to a noun phrase, and then gives back another function,
which again takes in an individual and gives us back a truth value. And a truth value is the kind
that corresponds to a sentence. So we have this lovely matching up between the syntax and the
semantics when it's done with type theory. So this kind of approach to semantics, formal semantics or
compositional semantics, comes from Richard Montague in the 50s, okay? So it's sometimes called Montague
grammar. It was really developed by Montague in a couple of papers. He died pretty early, but then it was
taken up by people like David Lewis. He introduced it to philosophers. And then it's been developed by a
whole bunch of linguists and philosophers, notably by Barbara Party. Finally, let's talk about type
theory in philosophy. And I'm going to think particularly here about metaphysics. Now for a long
time, type theory, Lambdas, they just had no role to play in philosophy. You know, it started in
philosophy with Bertrand Russell, but it was kind of ignored by a lot of people. And in philosophy,
you know, I never learned about this stuff. Pretty much right through the 20th century, you hardly
saw a Lambda in a philosophy paper. I learned about this stuff by going over to the computer science
department, where lots of people use this kind of every day. But in the last, I don't know, 10,
15 years or so, you've started seeing Lambdas cropping up in philosophy papers. I wrote a paper back in,
I don't know, 2011 or 12 about states of affairs that kind of use type theory. Other people have
been using it. Kian Dorr had this very influential paper, to be an F is to be a G, I think it's from
2013, that basically used type theory to analyse these kind of locutions. And basically, there's
been an explosion of people using type theory in metaphysics, higher order metaphysics. So higher
order metaphysics is the idea of basically using higher order logics, higher order quantification
to address traditional metaphysical issues. Okay, so one way we can do that is we can be really clear
about the distinction between first order quantification over individuals, second order
quantification, which you might think of being over properties, propositional quantification over,
you might say over propositions, but essentially, it's allowing us to quantify into sentence position.
So what is the philosophical import of this? Well, think about those age old metaphysical disputes like
over properties, what are properties? Do they really exist? Are they platonic, located nowhere in space and
time, but really existing? Or are they Aristotelians, somehow multi located in space and time? Or are they kind of just
like nominalists, say in words or in thought, having no real existence beyond that? Well, the defender of higher
order metaphysics might say, all of this way of talking is a mistake. Okay, because to say, where are properties? Are they in
space or space or not? Is to kind of confuse this kind of quantifier, the quantifier over properties,
with this first order quantifier? Okay, when we're talking about things being located, we're talking in
first order, objectual terms. But it doesn't make sense to apply that kind of quantifier to that kind of thing.
They are second order things. I'm not sure I agree with that. But that is what the higher order
metaphysicians say. Similarly, think about all the debates in philosophy of language about propositions,
like do propositions exist? What is their nature? Do they exist, you know, even if we didn't have
language or thought or whatever? Well, again, higher order metaphysicians can say that's a mistaken way of
thinking because it's confusing this kind of quantifier over propositions with this kind of
quantifier over objects. It's trying to turn proposition talk into object talk. And at least
according to the higher order metaphysicians, propositions aren't objects. In fact, when I said
that's a quantifier over propositions, that's probably a bad way of talking because that makes it sound like
it's a quantifier over some kind of object. This quantifies over things that this is doing something
else. And then you might say, well, what's it doing? And what defenders of higher order metaphysics tend to
say is, well, you have to learn what these things mean by using the logic. Okay. Maybe we shouldn't even
read this as saying there exists an x. Maybe we should just say something like some x or whatever.
Okay. It's its own locution that you learn about by learning how to use the logic. Definitely we don't
work out the meaning of that by thinking about the meaning of the first order objectual quantifier.
Now, you know, I'm not saying this is the right way to think, but it's a way of thinking that has become
very, very influential in contemporary metaphysics. Okay, guys. So there you have it. Type theory in
computer science, in linguistics, in philosophy, in logic. I said it was going to be a big one and
it was. I've really, really enjoyed putting this together. I think this has been the longest and most
in-depth video I've made in a long time. If you would like to see more in-depth content like this,
you can buy me a coffee over on Ko-Fi or sign up there as a subscriber. If you've enjoyed watching
this, do me a favor, hit that thumbs up, subscribe to the channel. That really helps me out. If you've
got any questions about this content, leave me a comment down below. I'm going to try to respond to
all of them. Thank you so much to all my Ko-Fi supporters for making this content possible
and to you guys for watching this far. I really appreciate it and I hope to see you back on Attic
Philosophy soon.
