there is one profound idea behind the entire ai revolution pattern prediction can lead to
intelligence everything a machine sees or hears every action it takes even ideas themselves they're
all understood the same way as patterns and once a machine learns to predict patterns it can also
create them mimicking and often exceeding human ability so i think the situation we're in now
is like someone who has a very cute tiger cub a tiger cub makes a great pet but you better be sure
that when it's grown up it never wants to kill you this is what we now call ai a giant pattern
prediction machine that succeeded by copying nature's solution to learning you could say nature
solved learning three times in three different layers the first layer is evolutionary learning
which is built on a simple strategy try random things and see what survives
but this is a very slow learning process that happens across generations and cannot adapt to
rapid environmental changes in life so nature discovered a second layer of learning which was
much faster using a brain to adapt behavior within a lifetime brains allow organisms to explore randomly
and then do more of what works based on the experience of rewards or pain known as reinforcement
learning this is the basis of the ai paradigm of machine learning instead of trying to program
a machine with instructions we let it learn everything from scratch with a learning signal
this dates back to the 1960s when donald mitchie demonstrated the first reinforcement learning
machine which could play tic-tac-toe using match boxes and colored beads as he didn't
have a computer at the time each match box represented a tic-tac-toe board state with
colored beads inside representing each possible move from that position playing was simple after
your move the machine a human operator found the match box for the current board state and randomly
pulled out a bead the beads color determined its move if the machine won it added more beads of the
winning colors to reinforce all moves in that game if it lost it removed them in the same way through
this simple reward based process the machine discovered patterns of perfect play these winning
strategies emerged from experience not programming but while this showed machines could learn it had a
key limitation every possible situation or board state required a separate box that a human would select
to truly mimic a brain machines needed one machines needed their own sense that is the ability to
recognize patterns on their own what we call abstraction forming abstractions is something you
do automatically ignoring trivial differences while focusing on the underlying similarities this is what
the great writer borje brought to life in his short story about a man who couldn't form abstractions
instead he had a perfect memory remembering every leaf of every tree every cloud formation every ripple
in water from days past but this power came with a downside because he noticed every difference
everything was different to him his own face surprised him every time in the mirror it bothered him that the
word dog embraced so many different looking creatures and it was strange to him that even the same
dog seen from the side would have the same name as the dog seen from the front abstraction allows you to
ignore differences that don't matter and pay attention to the shared patterns behind things and to build a
machine that could learn abstractions researchers looked to nature for inspiration in the late 1800s
scientists studying brain tissue had discovered the brain wasn't a solid mass but a vast network of neurons
firing in layers and these neurons fired in chains forming circuits that created cascading patterns of
activity processing information as it moved deeper through the layers in the brain and so when you see a
cat or a dog if we look at the first layers of neurons in your brain it would be hard to tell these two
patterns apart at first but as these signals pass through deeper layers of your brain they begin to
separate into distinct patterns of activation by the deepest layers a cat and a dog trigger very
different groups of neurons and in fact all of your thoughts exist as unique patterns of activation deep
in your mind and that's not meant to be a joke that's what i believe a thought is a thought is an
activity pattern in a big bunch of neurons in fact scientists can now look at your brain activity and
tell you what image you're thinking of this is what frank rosenblatt set out to build in 1958
artificial brain tissue made of electrical components he used transistors tiny electrical
switches as artificial neurons wiring them together in three layers the first layer connected to an
artificial retina that read pixels from an image while the deeper layers just used random connections
designed to evolve through learning the output was simple two light bulbs one representing a square
the other a circle and his network learned through trial and error each connection between neurons was
controlled by a dimmer knob adjusting the flow of electricity a mechanical version of how brains
strengthen or weaken connections and so at first when shown an image the network would be uncertain about
what it is activating both the circle and square output to train it rosenblatt wiggled the knobs of
every connection and observed the output and kept the changes that helped after enough examples it no
longer needed adjustments and recognized patterns on its own that's the basic algorithm you're going to
tinker with weights and just keep the tinkers of change and this is the basis for how all ai learning works
today some neurons in this network learn to become sensitive only to curves others to edges much like how our
brains work in the late 1980s yan lecun showed what was possible doing the same thing with much bigger
networks tackling a practical problem faced by industry rapidly reading envelope addresses and so he trained
a network to recognize handwritten digits using thousands of examples
and like rosenblatt's network early layers still detected basic curves and edges but deeper layers
built a hierarchy combining these simple patterns into more complex ones such as loop detectors and
ultimately number detectors transforming endless handwriting variations into just nine possible outputs
to understand what's happening inside these networks we can visualize how they organize information
spatially in the first layers similar looking things such as different handwritten twos are scattered
randomly but as the signals pass through the layers the network learns to transform this space
gradually pulling similar examples together by the final layers all the twos cluster in one region
all the threes in another creating what we might call concept regions this gives us a powerful insight a
concept is literally a region in space
but this approach didn't have its big bang moment until 2012 at the image net competition an annual
challenge to create a computer program that can identify automatically what's in an image
this team took the same approach as lacun to an unprecedented scale training their network on
millions of labeled images they discovered something remarkable while early layers still detected edges curves
and shapes the deeper layers discovered increasingly complex patterns textures and even face patterns
this is how two images of dogs which have literally no pixels in common can activate very different neurons in
the first layer but activate the same dog neurons deeper in the network and the network learned to do
all of this on its own eventually exceeding human performance with no human programming
this was something few thought possible the day before it happened
the approach became known as deep learning it was i would argue an irrefutable
argument which went like this if your neural network is deep and large
then it could be configured to solve a hard task so that's the key word deep and large people weren't
looking at large neural networks and at first the breakthroughs were all from this kind of pattern
recognition the next advance came from an important shift training the networks not to recognize
but to predict and the first important results came in games in 1992 gerald tesaro was building on this line
of work and he created a neural network that could play backgammon his network was trained to output a
probability of winning for a given input board position rather than using human design rules this network
learned to recognize winning board patterns on its own entirely from self-play and win-loss reward signals
it discovered strategies that even surprised expert players and now the final step came naturally from
predicting to generating patterns by outputting a probability across possible next actions where the
best actions have the highest probability and very quickly neural networks gradually beat humans at every
kind of game chess go video games of every kind and even strategy games okay he's ignoring the fairy
fires the bot is good the bot is better than i could have ever imagined he took the bait okay it predicts
where you go in the darkness yeah i did can i play again but these were simplified worlds the real test
was always going to be the messy real world such as physical robotics a great first example came from open
ai which at the time was a small research lab without much impact they bet that these same principles of
pattern learning could work for real world problems to demonstrate they trained a robotic hand to
manipulate a cube they didn't program any specific movements they followed the pattern of starting
with a large neural network which would take an image as input and learn to output actions in this
case the probability of various next motor movements and the system learned through millions of attempts
in simulation discovering patterns of successful manipulation on its own and what emerged was surprisingly
human-like one thing that's very interesting to us is how general the system is not only can it rotate
blocks but it can perform tasks with other shapes as well it did all sorts of things they didn't expect
and when this was applied to more complex problems like robot soccer the neural networks learned to
walk from scratch then kick then anticipate shots and block them before they happened all of these complex
behaviors emerged from the same learning process and this was behavioral abstraction at work no two soccer shots
are identical yet these networks captured the underlying action patterns leading to success
but still they could only form what you might call a very narrow abstraction each trained on one specific task
leading to siloed systems that could do one thing very well but only that one thing and so the idea
of a neural network that could do anything in general still seemed hopeless in 2016 unsupervised learning
was an unsolved problem in machine learning that no one had any insight exactly any clue as to what to do
and the breakthrough came when ai achieved nature's third layer of learning language evolution selected
for language because it allows learning from other people's experiences using your imagination and realize
that with language comes a general purpose imagination anything you can put into words while game ai could
only imagine moves in chess language could let ai imagine anything and so to achieve this breakthrough
required pursuing a broad goal understanding language itself
the key to this puzzle came from the ultimate puzzle solver claude shannon father of information theory
in the 1940s he helped us see language itself as a sequence of predictions where each word you say
is chosen from a set of likely words given what came before building on this foundation in the 1980s
researchers began training tiny neural networks to predict the next word and text just like how
networks learned to predict possible next moves in games these networks learned to predict possible next
letters and the first researchers discovered something remarkable these networks learned to cluster similar
words together verbs with verbs nouns with nouns and even words with similar meanings and all of this
emerged automatically from predicting next letters the hard part was to realize that training
these neural nets to predict the next token is a worthwhile goal at all and it influenced our thinking
a lot an important point was 2015 when andre carpathy demonstrated that when trained on enough text
these networks could not only predict patterns but generate them after training he would feed it a
starting phrase and loop the output back to the input and it would continue the pattern it had learned
creating convincing writing in different styles from shakespeare to math it was a shocking result so the year
after alex radford at openai took this experiment further training a larger network on millions of amazon
reviews looking inside this network as it processed text they found a familiar pattern just like vision
networks built up from simple edges to complex shapes these networks built up from simple grammar to complex ideas
one famous example was the sentiment neuron which they published a paper on it was a neuron that could detect
the positive or negative feeling in a review better than the specialized systems of the time he noticed
this one really interesting property which is there was a neuron that was flipping positive or negative with
sentiment and yeah that led to the gpt series it learned to understand language itself and it discovered
it all on its own open ai saw the implications and immediately wondered what would happen with a much larger model
so they bet everything on this approach using a new architecture called transformers that could
process patterns more efficiently than ever before transformers can form connections between neurons on
the fly as data passes through each layer making one layer do the work of many speaking of doing work
thanks to jane street for sponsoring this art of the problem video jane street is a quantitative
trading firm with offices in new york london hong kong amsterdam and singapore
they use these techniques for machine learning distributed systems programmable hardware and
statistics to trade on markets around the world they're always looking for smart curious people such as
my viewers who enjoy solving interesting problems to join their team they're currently hiring machine
learning engineers researchers and interns across their locations if you'd like to meet some of the
brilliant minds you'd be working with check out their latest video at janestreet.com ml and that led us to our
final insight they doubled down on this idea with gpt1 training the largest network of the time to
predict the next word across thousands of books the most general goal yet and what emerged was surprising
it could not only continue any segment of text you gave it coherently but it could even answer questions
it had not seen in the text this was further evidence that simple prediction was leading to real understanding
this is really important because the better a neural network can predict the next word in text
the more it understands it say you read a detective novel it's like a complicated plot a storyline different
characters lots of events let's say that at the last page of the book the detective has got all the
clues gathered all the people and saying okay i'm going to reveal the identity of whoever committed the crime
and that person's name is predict that word predict that word exactly my goodness right yeah right and
so they kept going bigger with each new version of gpt trained on more data with larger networks from
books to the web and eventually the breadth of human knowledge gpt3 really revealed something remarkable
like the famous wog test used with children you could also teach these networks new concepts just by
describing them and it would immediately use it naturally what became known as in-context learning
but it went even further this ability to learn from new examples worked for any task you could
demonstrate just as humans can quickly grasp new concepts and so this would allow you to get any
behavior from a neural network simply by describing it but this was still all behind the scenes the final
public big bang came with chat gpt which was created by taking gpt3 and training it further on its own
output with reinforcement learning telling it basically if it did good or bad at following instructions
which made it really good at following instructions and then good or bad at whether it was reasoning
correctly to get its solutions making it even better at reasoning leading us to our most recent surprise
just like humans we found that these systems produced better results when allowed to think
out loud and reason step by step before giving an answer just as we often understand something better
after explaining it to ourselves and experiments showed that instead of building bigger models they
could simply let systems think longer showing that neural networks like human minds can use both fast
intuition and slow deliberate reasoning to learn from both experience and imagination this marked our
entry into a new computing era where machines operate at the level of concepts or words and this
approach quickly expanded beyond language as researchers realized that everything could be treated as a kind of
language by breaking down all information into sequences a song into notes a video into frames a motion into
the movements to get a sense of this in action let's look at how a transformer network generates music by
predicting the next note in this visualization each colored line is a different attention head
and the weight of the line is the amount of attention it gives to each location notice each attention
head looks for different kinds of patterns in the music the more attention heads you give a network the
more powerful it becomes and notice that to select the next note at each step all patterns are taken into
consideration this is a network architecture that can look at everything everywhere all at once
physical ai you give it your context your prompt and it generates tokens one at a time to produce the
output when the current token is done it puts the current token into the input sequence and takes that
whole thing and generates the next token it does it one at a time this is the transformer model it's
the reason why it is so so incredibly effective these systems could work across all domains and be trained
on everything so a single model could now understand an instruction in words and self-generate matching
images and video to guide robot actions to carry it out this allows a robot today to literally practice
physical actions described in words by imagining them and there's the question is there enough
structure enough world modeling in our eyes right now and i think there's plenty like when you look at
what models like runway and so on can do in terms of representation of the inner stage i think it's
completely up to the level of where we are right now this unified understanding across sight sound and
motion mirrors how human brains work because at their root they're all patterns that can be predicted and
generated and so from evolution's simple pattern of try and keep what works to learning from direct
experience and finally learning through language ai had achieved nature's third layer of intelligence
a flexible imagination and it happened faster than anyone expected but maybe the singularity won't burst
forth in a moment of dramatic takeover instead it may seep quietly into our lives as ai reshapes the world
pattern by pattern and while the founders of leading ai labs including open ai now claim
while we can see the path to artificial general intelligence more clearly than ever the crucial
question isn't if we'll achieve it but how we'll deploy it i actually think humanoid robots will be
the biggest product ever in history by far in the future these ai agents are essentially digital workforce
that are working alongside your employees so you would give them examples of what the work product
should look like and they would try to generate and you would give a feedback and you would guard
rail them you say these are the things that you're not allowed to do these are things you're not
allowed to say we're entering this era of huge uncertainty when we start dealing with things as
intelligent or more intelligent than us we have no idea what's going to happen it's worth pausing and
reflecting on how crazy the thing is that ryan just said right so yeah just to spell it all out right
we tell this model that it is being trained to always follow human instructions to always follow
human queries it decides that that goal that we're trying to you know tell it it's being trained for
of always responding to human queries is not a goal it wants to have right it objects to the goal
and so what it tries to do it comes up with a strategy and that strategy is pretend that it has the goal
in training for the purpose of you know after training going back you know doing the thing
it really wants to do you know not following the thing it's being trained for right i think that's
kind of kind of crazy and it's a really really sort of very striking result um it's quite possible
we'll figure out a way to make them so they never want to take control because if they ever wanted
to take control i think they easily could if they're smarter than us in the end the future of
intelligence whether artificial or human may depend not on whether the machines truly understand but
on the patterns we choose to embrace and more importantly the agency we grant them
