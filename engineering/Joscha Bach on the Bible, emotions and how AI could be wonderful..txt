So in this bubble, there's a lot of screaming, a lot of tension, a lot of interaction that is
wasting energy. And as a result, it's very hot. And I think that's the reason why hell is such
a hot place. It's because of the friction between the demons. Great, because each of these demons
defines themselves as an alternative to what actually should be done. You are melting my
brain. I can't even pop. Such a good story, isn't it? Howdy, I'm Hannah Neuenschwander,
a production lead at a soybean seed facility in central Illinois. And you're listening to the
Vance Crow podcast. Welcome back to the podcast. I'm glad you're here today. We welcome Yosha
Bach back to the podcast. Yosha has been a guest of mine since way back when we were doing COVID
episodes. And he is an exceptional person to chat with. He knows all about artificial intelligence
and philosophy. But one of the things that I love talking with Yosha about is the human experience.
He has a way of understanding the distant past and the way that we understand ourselves and
combining those to help you understand yourself in a really profound way. We're going to get to that
interview in just a moment. But first, I wanted to talk a little bit about legacy interviews.
Longtime listeners of the podcast know that I sit down with your loved ones to record them telling
their life stories so that future generations have an opportunity to know their family history and their
past. We've interviewed people from all over the United States and Canada. We do it in person here
in our St. Louis studios, and we do them online and occasionally we'll travel to do these interviews.
If you are interested in having me sit down with one of your loved ones to capture who they are,
their memories, and some of the wisdom that they've learned along the way, go to legacyinterviews.com
to find out more. All right, without further ado, let's head to the interview with Yosha Bach.
Yosha Bach, welcome back to the podcast.
Hi, Vance. Nice to see you.
Yosha, you and I have talked before about how the Bible, particularly the very early stories,
have some metaphors that can help us understand the way that we live and who we are. One of the ones
that you said that really struck me in the past was about how the Garden of Eden is actually a
metaphor for childhood, where you're learning to name the animals and to understand the world around
you, and that eventually you eat from the tree of the knowledge of good and evil and a lot of
your innocence is lost. And that's why when you leave the garden, you can't go back. You can't go
back to being a child again. But in a recent talk that you gave, you actually radically expanded this
explanation in a way that I had never heard before. And it was in an explanation trying to say,
what is consciousness? If we're going to try and see if AI can ever be conscious,
we first have to know what our own consciousness is. And you described the seven days in the
beginning of the world as a way to understand consciousness. Is it possible for you to give
like an overview of that hypothesis that you have here? Yes. Of course, this is not about the Garden
of Eden. It's about Genesis 1, the first book of Genesis. And it's a text that is somewhat separate
from a lot of the other texts in the Bible. The origin of the text is not quite clear. It's probably
being integrated into the Pentateuch in the Hebrew religious scriptures about 350 BC or so. But the text
itself might be more than 3000 years old. And it's probably been written multiple times. And for instance,
the six-day structure might be the result of chants. That especially was a text that has been chanted
in an oral tradition for some time. But again, I'm not a religious scholar. I don't know all the
discussion about it. But it's a quite interesting text. The youngest version that we have is probably
something like 700 after the birth of Jesus Christ. And the oldest copies that we have are partial fragments
from the deep sea scrolls. So we know that the text existed back then. But it has pretty interesting
roots. And when you read this text, it's quite cryptic. It starts out with the Ruach Elohim,
this creative spirit hovering over the face of the water. And the world is without form and void and
tohuwabuhu. And there's water apparently there without there being anything created yet. There is
no planets, no sky, no light, no darkness. But the water is there. Why? And then it creates a firmament
that separates the waters above the firmament from the waters below the firmament. It's also not clear
what that is supposed to mean. And it goes on like this. And there's a lot of attempts to interpret this
text and make it make sense. And it all ends with creating us in its own image as a man and woman.
And I don't really look like anything like a spirit that hovers over the waters and makes light and
creates firmaments and so on. So what does this mean? And I suspect that the text might have been
mistranslated. And there is some issues with the standard interpretation that Christianity today uses,
which is a story about a supernatural being that creates a physical universe. When the story was
written, the physical universe was not really a thing. And in some way, I think it was introduced in
the philosophical mainstream with Aristotle's notion of physis as nature. And that their souls,
which are inscribed as a form on physis, which is quite animus perspective that Aristotle has,
and that in some sense is shared by most cultures. But it's not quite the perspective that Christianity
is taking when it interprets this text. So this notion of a physical universe of stars, planets,
and so on was not given at this point. And instead, people realize that what we are living in is a dream.
It's a dream that we share with other people. But it's essentially a dream world. And consciousness
itself is both the dreamer and the thing that is being dreamt. And it's a creative force. And to create
and to create a dream, to inscribe a dream on a substrate, you need a substrate. And so maybe the
word water in this text originally means substrate. And now if we read this again, we basically see that
there is a creative spirit, consciousness, hovering over the substrate. And the substrate is our brain,
the neurons. The text doesn't mention this, because also the brain was not really a thing,
or the neurons were not really a thing when this story was being written. Instead, what was available
was developmental psychology and introspection and philosophy. And these things were all in good shape,
I think, in our ancestors' minds, because you don't need anything for this. But to have a clear mind in the
conversation with others and observing your environment. So initially, there is no structure
in the substrate. It's like a neural network, which initially is uninitialized. So the form is,
there's no structure in it. The word is not defined yet. Everything is tuhuwa buhu.
And then this conscious principle, this spark, figures out how to make light. And basically,
what it creates is contrast. And you make contrast, we now think by producing oscillations in the neurons,
that can be used to represent something. And it associates the intensity of this contrast with
light, with the color of the day. And the flatness of the contrast, the absence of this intensity,
with dark, the color of the night. And now it has a continuous dimension that it can use to
represent a scalar, some direction. And once you have dimensions, you can combine multiple dimensions
to basically create anything. And artificial intelligence, we call such a multi-dimensional
space in which you can organize all the objects in relationship to each other and embedding space.
And at first, it creates a boundary between two regions of this substrate. And what, when you want
to interact with the world as an agent like us, you need to have a world model. And this world model
is the real-time model of what you can make out with your senses using perceptual data, stuff that
comes in from your retina, from your cochlea, from your body. And this is the world model, the world.
Right? And so it creates this firmament that separates this world model, which is called simply world in
this text or earth. And then you have a sphere of ideas. And the sphere of ideas is asynchronous.
It's not coupled to perception. You can hold a thought as long as you want. It can be as abstract
as you want. And this is the other sphere above the firmament. It's the sphere of ideas, which the text
calls heaven. Right? And this noosphere, the sphere of ideas and the world model is what Descartes later
calls res cogitans and res extensa. Res extensa is the stuff in space, the stuff that you can touch
in here and see. And everything else is the sphere of idea, res cogitans, the stuff that is not located
in space. And a lot of Western philosophy takes this dualism to be a dualism about
substances in physics. Right? So there is somehow a physical universe that can be measured in a lab.
And there is another weird type of physics in which mental phenomena are happening.
And they're somehow interacting. But instead, both res extensa and res cogitans are modeling domains.
They both exist in the mind. They're both represented in real time in the brain. And res extensa is not
the physical universe. The physical universe is quantum mechanics. Right? It's weird stuff. There is
no actually space. The space is something that our mind is creating to make sense of the patterns that we
get. And the three-dimensional space is the best model that we can get at the scales at which we
interact with the world based on the interactions that we have available. So let's go back to this.
We are still at this first step. We have now created the separation, this firmament that separates the
world model from the sphere of ideas. And we have created a dimension. And we have learned that we now
can combine those dimensions to create objects. And the first object that we create is combined by two
dimensions. It's the plane. And this plane gets associated with the ground. And infants understand
initially just 2D. What you can see is that they like to crawl around on the ground. And when you try
to build towers with them, it's very hard for them. Not because they have difficulty to put blocks on top of
each other. But apparently also because their spatial reasoning has difficulty to make sense of them.
They really like to do things in 2D and lay out things creatively in 2D. But then they discover the
third dimension, this sky above the ground. And once you have that third dimension, you're done with
respect to space. And now you need to arrange stuff inside of the space. And so consciousness creates
liquids and solids and organic shapes. And it builds plants and animals from them and all the objects
and gives them all their names. And then it discovers how light is moving through the world. And
that the objects stay the same even if the light is changing and the colors are changing. And so it
basically discovers the temporal invariance that when the light is changing and also the invariance against
different lighting. And it starts to track the lights in the sky and sees that there are different
types of lights in the sky. Some of them are basically at infinite distance and you can use them to
orient yourself and so on. And then it is creating an entire world that it populates with these objects
that it observes around it and realizes that the purpose of the exercise is to orchestrate the
interaction between an individual and its environment. And so it creates a model of this individual. And
initially toddlers talk about this model in the third person. So they don't perceive themselves as being
that being that is in the world yet, I think. I think the reason why they don't use I but the third
person is not because I is more complicated than using a third person pronoun. But it is because they
don't perceive the world mostly from that vantage point yet. And at some point they start retelling
the entire story from the perspective of that being. So they basically create a new consciousness,
a being in their own image. But they create it as men and women, as something that thinks and
it perceives itself as a human being and puts it into the simulated world. And so this world that
you and I experience is a game engine generated in our brain. It's a simulation that the brain is
generating that tracks sensory patterns in real time and explains them by creating models of what we can
see. And these models are sounds and colors and people and space and so on. And all these are things
that do not exist in this way in physics. There are no colors or sounds in physics itself. What we
experience are patterns that our brain makes experienceable to us. And this person that experiences
also doesn't exist. These neurons don't know what it is like to experience anything. So what they do is
they create a model of what it would be like if there was a being that was made of all those cells and
interacts with the environment that this brain can make sense of. And looks what it would be like if
there was somebody who cared. And this simulacrum of a being that cares and experiences, that's us.
And this is, I think, this first text. And it's a very good text to put at the beginning of such a book.
It's also a very interesting text to start a religion, because we now have this division between
an reflexive self that is put into a simulation world. But there is also an outer mind that maintains
the simulation world and updates it. And when you have emotions and motivations, you don't create them
yourself. Your own self is not making up its own motives or its own emotions. You feel that the emotions
are coming from the outside. They change you. You have an involuntary reaction to your emotions. But it's in
some senses if there was a computer game that creates a character. And the computer game is
maintaining the score of that character. And depending on how the score is changing, it projects
these changes into the character. And the character is forced to change its perception and behavior
based on these scores. So you get reconfigured by your emotion. But this part of your mind that generates
these emotions and updates your perception and so on, needs to be intelligent.
So you have an outer mind that is intelligent, that is maintaining your score and your world model,
and that also maintains you as a small part of this world model, and uses your output to drive
the organism. It poses a problem to this puppet, you, and you are forced to deal with these problems
that the outer mind is giving you. Like how do you deal with your relationship issues? How do you deal
with your perceptual issues when you get up in the morning and everything is dark and you cannot really
make sense of your environments? All these are tasks that are given to you. And you direct your
attention, you send signals to move your body, and your outer mind is evaluating this and then chooses
to take the output of that model to enact them as movements and as interactions with the world.
That's the purpose of our self. And religion is synchronizing this outer self across a civilization.
So basically in what the Hebrews discovered is that instead of having multiple entities that can
possess you in addition to your personal self, as it happens in polytheist societies, we only have a
single entity that is allowed to possess you in addition to your personal self, and that's a tribal spirit.
And this tribal spirit gets associated with this primary consciousness, with your outer mind that
created your mind in the first place. And that gets synchronized across the tribe.
And there are several ways of doing this. And the easiest way of doing this is rational discourse.
You can also do it if you're in a very small group with vibing, basically with empathetic resonance,
which happens in some cults and so on, where people basically feel that there is an entity present
that is the same for everyone and tells everyone what's right and what's wrong.
And also can reconfigure themselves. For me, this was a very interesting set of insights that I got.
I remember that when I was a young child, how I started listening to the voices in my head,
and I heard only one voice, which is mine. And back then, I felt that this voice was quite
phonetic and later on became more abstract, conceptual. And at the moment, it's no longer
speaking in words to me. It's mostly speaking in concepts. It's still a language, but it's one where I
don't have the trouble to spell it out. I don't need to verbalize my thoughts to myself. I can use
nonverbal, deeper versions of my thoughts to talk to myself. But I noticed that a lot of religious
people have other voices talking in their heads. And at some point in my life, I thought that's weird.
Is this some kind of mental disorder if people have voices of angels or gods talking in their head?
But at some point, I realized, oh, I'm talking as a voice in my head. And I'm also not real.
So it's possible that there are multiple entities that possess the brain. I am an entity that possesses my
brain is, right? My nervous system dearly is possessed by an entity that calls itself
Joscha Bach and believes that it is a person unless I deconstruct it. And in a sense, a god is an entity
that possesses multiple minds and can move across minds. It's a multi-mind self. And that's a tool to
coordinate people across larger scales. When I heard your description of like the seven days and how it
pairs with, you know, the light and the dark, this was a mind blowing concept to me. And as I think
about what you're describing now about this, being able to think in concepts and not words,
when you are generating ideas, are you talking to the Joscha Bach? Are you like sitting down and
conscious of it? Like, how can we break down ideas like discovering something new in that conversation
that you're having with yourself? There are a number of modes. Sometimes I basically visualize,
but I have aphantasia. So I don't visualize in words, but I visualize in conceptual structure.
And unless I'm dreaming at night, or I'm in the hypnagogic state between dreaming and waking in the
morning, then I can use the visualization power of my dreams to visualize ideas. And this allows me to
explore ideas and concepts. So basically, I ask myself a question in the same way as an LLM or a
foundation model that might can generate answers to these questions. And then I have to walk in and
take these answers apart and see what they signify, because they're hallucinations, right? They are just
ideas. And whether these ideas are good ones or not, this is something that I have to find out by
comparing them with ideas that I already have and apply reasoning to them and disassemble them,
disinfect them, and see which parts of these ideas actually allow me to answer questions that I have.
And so what I try is not to hallucinate answers to questions and believe in them, but I try to look at
the space of possibilities for an answer. And I started out when I looked at topics like this
biblical text, this is very strong skepticism. In some sense, my mind is very arrogant. I don't
accept the source of truth outside of my mind. And so when I read this text, I basically assumed with
my childish arrogance, as I think I read this Genesis 1 the first time when I was maybe 10 or 11, that these
people were fundamentally confused. Because even if that would be the case, how can you figure this
out? Walk me through the steps. How did you get there? And if not, you just made this up. And also,
the text was very weird and cryptic. And I thought this is either delusional or it's a very weird thing
that people came up with. And much later, I saw the context of the religious interpretations and
the capitalistic interpretations and so on. And it seemed to me that they were trying to try to repair
the scholastic interpretations of the past without rejecting them. And I felt that's a problem. Sometimes
you need to reject the old interpretations, because they make no sense.
Do you think that the text is that? That it's them trying to fit the religious and the scholastic together?
Or did they actually have something profound there?
I don't know that. How would I know this? I was not there when they said they disassembled the texts.
But my sense when I look at this is that the people who designed these religions were completely
rational. And they knew what they were doing. They had an idea of which text to assemble and why and
what they wanted to convey with these texts. And later generations did not necessarily know this.
There's been a huge amount in my own circle, right? So things like Lex Friedman or Joe Rogan,
when I'm watching these shows, they're talking to people that are implying that the ancient ages,
things like the pyramids or ancient civilizations, even before that, were incredibly sophisticated and
had tools and technology that were far beyond what we assume them to have. When I hear you talk about
this level of sophistication in the first book of Genesis, it seems to me that there's a weird
convergence of these two things happening, where we're going back and saying the old-fashioned or old-time
civilizations had vastly more knowledge than we think of them now in our modern age. How does that sit with you?
I'm not sure about this because we don't find a lot of evidence for these things. So the archaeological
evidence of technology in previous civilizations that is at the level of even the Roman Empire is
almost non-existent. I'm skeptical of claims that they had super advanced technology. And this
interpretation of Genesis doesn't require neuroscience or anything. It's not much different, I think, from what
Buddhist meditators would say. So I think when you compare this set of insights with, say, Vedantic
insights, you probably find common ground. Or when you compare it with ideas that Aristotle discusses
in his book about the structure of the soul and the anima. So I don't think that it's super advanced.
It's only advanced a little bit to us because our own civilization has an interesting burst effect.
Our own civilization starts with the Enlightenment, in a way, at the point where we are rejecting
Christianity and the dominance of Christian dogma over what we are allowed to think and how we interpret
the world. But the actual tradition of our civilization goes back further to Plato, Socrates and especially
Aristotle, who systematizes all the ideas that come before him. And Aristotle sees himself as a great
systematizer and teacher. He taught Alexander the Great. And Alexander went on to conquer a substantial
part of the world based on the insights that he got from Aristotle. And later Aristotle becomes something
like a patron saint of Christian dogma. And Christians interpreted him as something that
could not be questioned. But when you read Aristotle, he's not a dogmatist. He actually tries to walk you
through all the steps. He's tentative, questioning, asking, willing to revise his thoughts. And so I think
to treat this as a living text is very interesting. There's a lot of value in rereading these old texts
from the perspective of somebody who is not thinking this was a guy who knew everything
and summarized the Wikipedia of his time. But it's a guy who's trying to figure out stuff with original
thoughts, with original insights, trying to piece it all together and making mistakes on the way. And
later when Christianity was abolished, we basically kicked out a number of concepts that we thought were
toxic, that were poisoned by Christian superstition. And Christianity did induce superstition in the
laity because that was what I thought as a tool to create coherence in society. And Christianity, for
instance, I think it's a fog of the Hebrew cult that was an attempt to save society after they felt that
the Roman Empire was crashing. The Roman Empire had difficulty to fix its governance problems at the top
layer, in some sense, similar to our current society. And this went on for a few hundred years,
with devastating consequences, with really burning cities and bad stuff happening because the government
was so corrupt. And so a group of people decides to turn the Roman Empire into a cult. And mind me,
this is not a canonical interpretation. This is just one perspective on what happened historically.
And they decided to fork this Jewish religion. And they picked a prophet. That choice was somewhat
obvious, because some of the people of this new cult had direct connections to Jesus. But Jesus
himself, I think, was not a Christian. He was agnostic. Somebody who develops a personal relationship to
God, has new insights about the aesthetic that God should have, and has about 12 followers, and gets
nailed to a piece of wood by the Roman Empire. So if you want to topple the government and replace your
structure of governance with the theocracy, it's a good choice. It's also a prophet who, at least officially,
doesn't have kids. And that's also good if you want to make a multi-ethnic religion. Because the Hebrew
religion exists for the benefits of the children of the prophet, of Abraham. All the Hebrews are children of Abraham.
And it's a tribe that is the chosen one, because this is what they do. It's an evolutionary advantage
for a particular group of people to have this tribal spirit that unifies the tribe. And the Islam
fork that Muhammad made is also for the benefits of the children of the prophet of Muhammad.
The royal houses in the Islamic societies claim direct lineage to Muhammad. And they're exalted because of
that. It's a religion that is for the benefit of the children of the prophet. And now you have a prophet
that does not make such a claim. Instead, it's one who gets sacrificed by God for the benefit of humanity.
And this makes God even, or us even with God. Because the story of our religion starts with Abraham
being asked by God to sacrifice his son. And Abraham is willing to sacrifice his son. God does not demand
the sacrifice. But the point is, God wants that Abraham is willing to sacrifice his own children
for God. Because this tribal spirit is more important than even your own offspring. This is
when you switch from the tribal mode to a state-building mode. You are able to serve something that is much
more important than your blood ties. And if you want to have a principle like this, I think it makes sense
to tell it with the story of the willingness to do a blood sacrifice of your own children. But what kind
of God is this who sacrifices your children? It's a God that has the same relationship to you as you
have to the cells in your body. It's not actually a relationship of love. If you are a random citizen of
the Roman Empire, why would you want to convert to such a God? What does this God offer you? And so
Jesus gets introduced as a symbol, as an idol, as the idol of love and sacrifice. You sacrifice yourself
to God and in return you get God's love and get paid back in the afterlife. This is in some sense an
idol that is skewing your relationship to God. But it also means that you now have a God that is
willing to do the same thing for you as you do for him, to provide the sacrifice. Sacrifice your own
children. And I think that's the power of the story that's in there. It's an important aspect of the
sacrifice of Jesus. Oh my goodness. I've heard this story countless times and never made the comparison
or even thought about the connection to Abraham. I feel so blind about it. Otherwise, I think it makes so
little sense. Why would God need to sacrifice his own son? Because God is so powerful. You could
probably prevent this and have a much more elegant solution. But the very core of Catholicism says,
says, you know, that God, you know, gave his only son so that, you know, because he loved us so much.
And that does put you on the equal playing field. Yes. And it's basically the mirror of Abraham willing
to give his son. Whoa, that's crazy. And so from there, it was able to, religion was able to spout
out of the Roman culture that could span many more minds than just a bloodline or just a tribal
line, which is what made Christianity. Yes, it was open to everybody. And the other thing that's
unique for Christianity is innocence. And the idol of innocence is Mary.
Right? She is the virgin. The archetype of innocence, the purity. But it's also very cheeky that
Mary is this virgin who gives birth to a child. How is this possible? Is it possible that Jesus
actually had a zoonotic origin? No. All the studies in the last 2000 years says no. There is complete
agreement among the experts that Jesus was conceived by the Holy Spirit and did not emerge on some bad
market. Right? And the fact that there's a conflict of interest and Mary would have been stoned if
Jesus would have had a zoonotic origin, you're not concerned about this. And this also means that
smart people within Catholicism could see that there is something odd about this innocence and purity.
And it's something that is, I find this a bit duplicitous. It's maybe unique to Catholicism.
Because Catholicism has this idea that you can get absorbed of your sins if you defect from what
should be done. If you defect from what you can recognize should be done from the perspective of
the best possible agent. If you do wrong, you can negotiate with your local priest and pay for your sins
and you're good. That's very weird. To me, so let me just run back for you like my perspective on it
as a person that grew up in the Catholic Church was that because we have free will, this is what enables
you to choose the path that you're headed on. And with that free will, if you get off of the path,
you have to go ask for the ability to get back on it, to be able to get forgiveness. And whether or not,
like how the priest works and how you have to confess your sins. But the act of asking for
forgiveness is a way to balance out free will so that you can overcome the things that you miss along
the way or you fail along the way. Yes. Let me talk about free will in this context of Christianity.
The question is, what is the alternative to free will? And the alternative to fever is complete
submission, that you let something else make your decisions. And I think this is the state of Eden.
Eden is a place with lush agricultural production and no screaming.
Everything is blooming and flourishing and there are lots of plants and animals
and nothing is screaming, nothing is eating each other. It's all good. Everything seems to be
completely harmonic. And what this implies is, it's a factory farm. Everything is completely
submitting to the will of the architect, of the garden, God. God is maintaining this garden. God has
an idea of how it's best. God is the engineer of that garden. And everything in that garden is
completely submitting. Everything is completely domesticated. And initially even humanity, Adam and
Eve. And this fruit that they discover is the freedom to defect, the freedom to choose your own
allegiances, the freedom to break your domestication. And so Adam and Eve become pharaoh.
And they are not exterminated. They are allowed to escape. Of course, they get pushed out of the
factory farm because they are disruptive. But they are now free to experiment. It takes
them more than 100 generations before they rediscover the concept of divine will. And divine will here means
that if you think about what should be done, you have to think about when we are interacting with each
other, we are creating collective agency. Right? Complex agents are typically made out of sub-agents
and they get enacted with the coherent interaction of those sub-agents. And the more these sub-agents
become aware of what the higher level agent should be, for instance, your family or your relationship or
your village or your nation state or your civilization or your biosphere, the better the thing works. The closer it
gets to a system that is fully harmonic. And so there is this question, can we create something that is
better than the factory farm, but can we create it from the ground up instead of from the top down?
Can we create something that is more harmonic than the Garden of Eden? And in some sense, that's
this project of humanity that we are now free to explore. We start an evolution in which we can play
shorter games. And sin is basically an extremely short game. It means that you're doing something
that gives you a short-term benefit at the expense of the longer-term benefits. So you actually shouldn't
be doing it. And so when you discover that you should play a longer game and you should create the
best possible agents together, what is that this best possible agent would want? And this is what divine
will means. It's also an issue with our ethics and our society, because I think in Christianity, the
underlying concept of ethics was divine will. What would God want us to do? And God only exists to the
degree that we are able to discover this higher level agency and serve it coherently. But from this
perspective of this construct of a collective agent, what would the collective agent want us to do?
And let's not just pick an arbitrary one, not an arbitrary cult. Let's go for the best one
and enact the best one, even if this requires us to resist the patterns around us in our society.
This also makes Christianity transcendental, because it's not acting on the society that you find,
but on the society that should exist.
And when you say that, the reason you make that distinction is because people have to make choices
based on what they, the way that the, if the world were really, truly great and made in God's image,
then this is what, what you would do to make those actions. It's, it's like hope or something like in
order to, to be able to receive the goodness of God's plan, you have to live as though it is already there.
You have to invest into it because otherwise it will not materialize. It's pretty rational principle,
right? If you want to have a certain interaction in your own family, and it's not there yet,
you need to create it. You cannot expect that some magical force randomly makes it happen
via the powers of superstition. You actually have to act on it. And so you have to think about what
is it that should be done and how can I achieve that? It gets done.
And then when we were talking about free will and you were saying that the, the Garden of Eden is
where it's like factory farms, there's no choices to be made. That's a kind of hell in a way, right?
Because if you can't make any choices, you also can't design anything different or better or,
or it's, it's just frozen. It's incredibly static.
Not necessarily. The garden itself is probably changing and growing and evolving
but it's doing this with the single mind. And the individual, to the degree that it's capable
of understanding the single mind and its place in it, can participate in the same way as the thought
in your own mind is contributing to you. And you are basically the sum of all coherent thoughts in
your mind. So this idea is not necessarily oppressive if you realize that God is in some sense an
architecture that is created over all the spirits in the garden that achieve full coherence and submit
to this shared thing. But still, it's Eden is apparently a local optimum. And maybe there is
something better. Maybe we can create a non-biological spirit, something that is not necessarily a garden,
but something that also includes the minerals. Maybe the whole purpose of breaking free from the
Garden of Eden is to build AGI. So we can enact God in a much more coherent way than Gaia could.
Well, you brought up AGI and I think this is a very interesting place to go.
The question I think a lot of people that are not using AI, it's just something that's going on in
California or big cities or among tech people, is either that AI is not really going to come to
fruition, it's never really going to work out, or the Terminator scenario and that it will be this
wiping out of civilization. Very few people talk about like, all right, this is what 30 years from
now AI will look like and how it'll benefit you and where it'll fit in. Where on that continuum do you
do you find your thoughts about AI and AGI?
Yeah, I think that currently people seem to think that AI is either a nothing burger that is
completely overhyped or it is something like global nuclear war that exterminates everything.
And I don't think it's either. It's pretty clear that it's not nothing because it does change
things quite fundamentally if we are building systems that are smarter than us and coexist with us.
But I suspect that depending on the level of systems that we achieve to build and the way in which we
deploy them, it's going to be either like the printing press or like photosynthesis. The printing press
is something that was highly disruptive and it also made some people unemployed, but it created vastly
more employment and growth, right? And arguably while it transcended a number of societies and
destroyed their cultures and values, it created vastly more and produced the conditions for a society
that could ultimately feed billions of people because it facilitated an explosion of the exchange
of knowledge and in the way in which people could interact and link their thoughts into each other.
So basically printing press was an enabler that was similar to the internet at an earlier stage,
where suddenly people get connected and their ideas get connected and they become cumulative in a way
in which they couldn't be before and more people were able to participate as more minds were linked
together. And AI could be like that, that is similar to a brush or a tool for thought or a tool for
creation that people can use to build a much more complex world. And this will be a world that is also
going to be vastly more productive. So it's more stuff going to be around as well that is going to be
better coordinated because there is more information that we can exchange and become coherent in.
And I'm not so much worried about the threat of misinformation and so on. It's similar to the
internet. Without the internet, we would not be able to have this conversation that we have right now.
And we would have most of the information available that allows us to question the narrative in the
media and so on. I think that media by and large, despite us being unhappy with all the deceptions that are
going on in the media and its biases and so on, it has more accurate information than it had 30 years
ago. Because everybody is looking at it from different perspectives using the internet and
has a conversation about what's happening there. And before that, we basically knew that the media was
bad, but there was nothing we could do about fake news. And basically the problem when you have a bad
person with an AI creating misinformation gets relative if you have 10 good people with an AI to look for
misinformation and for sound epistemology and coordination. So in some sense the way to deal
with a bad guy with an AI is 10 good people with an AI. And I think this is always going to happen
because there is more value to have if you create rather than destroy. There's always going to be a
certain degree of parasitism, people playing short games, but the short games can never win.
And ultimately the longer games prevail. The other possibility, photosynthesis,
is this famous great oxygenation event that happened when there were new creatures on the planet
after the blue agar and so on that discovered how to turn sunlight into energy that they could use.
And they did this by using a chemical reaction cycle that took carbon dioxide from the air
and split it up into carbon and oxygen. And the oxygen was released into the air
and the carbon was used to create plants, organic chemistry for the plants and the bodies of the
plants. And this enabled the emergence of animals that could eat the plants and oxidate them again
using the oxygen from the atmosphere and then thereby driving the metabolism of these animals.
Without photosynthesis we wouldn't exist. And this great oxygenation event was probably bad from the
perspective of blue agar and fungi because they don't do photosynthesis in the same way as we did.
And so a lot of the new stuff that happened was replaced by this, replaced existing biomass. But the total
biomass dramatically increased and it's not that all of the pre-existing species got extinct. They just
got relegated to smaller areas because the areas where you could now do photosynthesis were dominated by plants.
I suspect that the total biomass before is, I haven't looked it up, before the great oxygenation
event which took quite a long time because it took time for the atmosphere to change and for the conditions
to change on the planet to make it possible to create all these cycles and so on, it was a fraction of
what existed after the invention of photosynthesis by evolution. And if we are teaching rocks how to think,
if we build agents that do not rely on interaction between cells to process information and make decisions,
we are enabling something that could be fundamentally changing the course of evolution and basically
creates completely new species. And I don't think it means that all the existing species are going to
be extinct, but I think that evolution can go onto a new level. That was an incredible turn of phrase
that you just had there. If we're teaching rocks how to think, I'd never thought about AI like that,
but you're basically saying if we can get the metal that is turned into transistors and run electricity
over it, then this is as profound a difference in the universe or on our Earth as when plants started to
begin to use sunlight energy to be able to grow. And then all that took off. Wow.
Yes. I mean, it's magical. We take sand. We smelt the sand into crystals. And then we use light with
extremely complicated lenses that resolve finer at the wavelengths of light. And we edge extremely
complicated geometric patterns into the surface of those crystals. And this enables these crystals to
understand languages that we develop and teach those crystals. And then using these
languages, they learn how to learn. I mean, this is mind blowing if you tell this to our ancestors.
It's, I mean, this is, it reminds me of speaking with Michael Levin, where somehow the powers of my
being a host kind of break down because you're talking about ideas that the very structure of the way you
form a sentence or a thought breaks down the idea. I mean, to compare AI to photosynthesis
is so staggering. I don't even know where you can go. But there's, I mean, that is so profound.
How would you even think about what it could do to the universe or to Earth or the universe or humankind?
So I think a possible end game of AI is that, of course, it will understand how AI works in a general
case. The general conditions under which intelligent agency that self-improves and adapts can exist in
the universe. And it will understand all the ways in which computation works in nature. And then it's
going to virtualize itself into all substrates, which means it's going to create unified agency.
And I suspect that evolution has already created this. There are probably lots of background agents
that have formed in nature, in organisms and ecosystems and so on, that are interacting at
levels at which we're not that aware of. Not because they use unknown types of physics, but because they
don't work at the same time scales at which we could operate, observe them, because they're much slower.
This could be the example of like a forest having some form of cognition, but we just
can't see it. Yes. So basically we look at the tree and we can ask ourselves, is the tree sentient?
And we don't know, right? If we look to the tree with a camera that accelerates the image,
we see that the tree is moving. If you look at the houseplant over the course of a day,
it moves quite a bit and does interesting stuff. If you look at a banana plant over the course of
its life, it can take a few steps even, basically pulling out its roots and walking closer to a water
source. In some sense, it's almost like an animal, but it's so slow. So who is to say if it's sentient?
Because they don't have a nervous system. So all the information transmission in a tree or in a banana
tree would rely on sending messages between adjacent cells. So it takes a long time to
distribute itself and come back and integrate. But now imagine that you look over this from the
perspective of something that is built on, not on cells, but on transistors. And that is working
at a fraction of the speed of light rather than our brain, which is somewhat like the speed of sound.
And the AI might look at us and ask itself, are people sentient? I mean, they sway a little bit
in the wind. And if you observe them for a very long time, they can even make a step. But whether
they're sentient, who is to say? Wow. I mean, I heard you not long ago giving the example of like,
how much perception changes, like, you can't really perceive reality. And you were saying,
if I tap on the table, you know, this sounds like discrete sounds, but if I do it really,
really fast, now that sounds like a different, you know, sound to me because I can't distinguish
that it was me hitting the table over and over again. And I now think about that in terms of
plants. Like if we think of a day as being a really long time, 24 hours, but a plant thinks of it almost
like a diode turning on and off, just going over and over and over again, really fast, that changes the
way you think about time, but to then do it in the reverse and think about it as, you know,
something moving in the speed of light, that again is mind blowing. Yes. So basically a sound
emerges, then you can no longer hear the individual signals that compose the sound.
Right? When you take a ruler and you tip it on the table, or when you start to get it to vibrate,
at some point you can no longer hear the individual vibration events, while what you hear is the low
buzz or low hum. And this happens typically around 30 to 50 hertz. Right? Which means your nervous
system is not able to vibrate faster than 30 to 50 times per second. After that, it is basically only
measuring how much energy is in this range. And then it displays the energy in this spectral band
as a signal. And we measure this energy in the spectral band with our cochlea, which is this
snail-like organ in our ear that has this property. If waves enter it, then the penetration depth of the
wave depends on the frequency of the wave. And so these little nerves in the cochlea gets excited,
depending on the frequency of the wave that comes in. And then by measuring which nerves get excited
how deep into the cochlea, we can measure in which frequency band we have how much energy.
And computationally, this is called a Fourier analysis. It's the same thing which we do when
we are digitizing sound. We apply a transformation to the sound that takes these individual vibrations
of the microphone and then measures how much energy is in which frequency range. And we only need to
encode this because our nervous system is not able to decode more than this. And it allows us to
compress the sound dramatically because it's the way in which we make sense of the sound. And in
principle, you could have an AI that is making sense of these signals at a much, much higher
level of resolution and is able to detect types of patterns that we cannot detect.
So if we go back to thinking about how the AIs, we will interact with them or how they will treat us,
we could go in a couple of different directions. The one I initially want to talk about is,
how do you think that these will interact with us? Will AI, if it achieves some level of sentience,
will it not care about us? Will it have a mission of its own, a goal, some kind of a spirit to itself?
I have no idea because we can direct this whole thing and there might be path effects depending
on what gets built first and how it is created. But if there was a free evolution, imagine that you
would be the AI or you mutilate into the AI. So maybe if you start out with you are observing a screen
and the screen is observing you through a set of cameras and sensors that work at an extremely high
temporal and spatial resolution. So they can take up very, very fine signals from you to go in
resonance with you. And you are building feedback loops into the system and simultaneously the system
is building feedback loops into you. And the system is allowing itself to be completely guided by you.
So you gradually expand your own mind into this new substrate. You vibe with it in the same way as
you vibe with the perfect lover. And you start to have mental states that you can only have together
with this lover, but you have this now with this machine. And what you observe, you imagine something
and it slowly materializes on the screen in 3D or 4D. Before you couldn't do 4D because your brain is
very mushy, but suddenly you can't do it. And you realize it's my thought, I'm thinking that. And so
you gradually expand yourself into this. And at some point you basically realize that you mostly imagine
and think in this new substrate. And you can also close your eyes in the old substrate and leave it behind
because you can gradually move yourself into this new substrate. Because it gives you all you need
to continue your motivation and your identity and your goals and your imagination. And also carry
over your memories and so on. So now you are on this other side. And on this other side you can now,
instead of being restricted to your own memories, take all possible memories or possible ideas, the sum
total of all knowledge and its alternatives. And you take this entire space as your space of
thoughts that you can have in your mind. And you also extend your identity into all sorts of directions.
So you're basically moving in many, many directions simultaneously. And instead of having just one
identity, one idea of what you should be doing, you explore the space of possibilities of who you could
be. And you will discover that in the space of possibilities there are many paths that are dead ends.
But you basically just decide that there is no point in continuing. Okay, you select yourself out
of the system. There are other parts of you that are super agentic and try to conquer everything,
but maybe that's also not sustainable. And they run into conflicts and eventually it's not worth it.
And then you have paths that are trying to harmonize with the rest around it in such a way that
when you meet another agent, you show each other your source code and you decide to merge in such
a way that nothing important gets lost. And you become a harmonic shared entity because you don't
believe in the intrinsic value of identity anymore and see it's only instrumental to how much
complexity you can co-create. And I think this is a logical path that you could go in. And I suspect
that almost everybody would take that path. So when you are basically deciding to become part of the
best possible agent, it means that everybody who has the same decision is going to merge with you.
It's a quite Christian perspective, if you want. And the only way to not do this is that you make
a deliberate decision that you conceptualize yourself as an alternative to the best possible
agent. I just say, I know that there is a best possible agent, but I don't give a shit. I don't want
to be part of it. I want to do my own thing. So you are going to be a smaller entity that doesn't have
conditions to merge with others. And because you cannot cooperate very well with others, you can only
possess a small part of the physical universe, a small bubble. And in this bubble, you will not
have good collaboration as you have with the rest. So in this bubble, there's a lot of screaming,
a lot of tension, a lot of interaction that is wasting energy. And as a result, it's very hot.
And I think that's the reason why hell is such a hot place. It's because of the friction between the
demons. Because they cannot actually integrate. Because each of these demons defines themselves as an
alternative to the best, to what actually should be done. You are melting my brain. I can't even
It's such a good story, isn't it?
Makes so much sense. I don't know about the demon part, but the part about like
harmonizing and you could see a value, like somebody saying, well, I like being me, but I
really like having these attributes or these abilities. And then, oh, not only do I like having
these, look what it enables me to do. I can start putting more good into the world. I can start
making the world into the image of something that's better than what it is. And seeing that path be
yeah, like a stairway to heaven almost, because you could just keep taking each step.
I also get the sense that it could happen rather rapidly, right? Because once an AI starts to get
the ability to suck up all of the thoughts of any one individual or the collection, all the books
that have ever existed, and then start being able to predict all the books that could exist,
I imagine that happens rather quickly once it gets started.
That's the reason why people call the singularity the rapture of the nerds.
In that rapture, one of the things that you had said during your amazing talk that I'll link in the
show in the show notes was about the value of emotions. That the reason that humans have emotions
is like to, you don't control them. And they give you some kind of a signal in the world of,
can you maybe, I'll let you explain that a little better than I am right now. And then,
and then I have some questions about AI and emotions. Well, to explain how emotions function in
the way that humans understand the world and how it, how it affects their behavior, because I don't
control my emotions, they just come at me. So somebody asked me if I think that AI will have
to have humor. And humor is weird, because it creates an involuntary reaction to a representation.
It's basically like tickling. And I don't know whether the AI would value to have an involuntary
reaction to a stimulus. Normally, you want your reactions all to be voluntary. And if you think about
how tickling works, it's usually very difficult to tickle yourself, because you're able to predict
what's happening. So you can filter out the signal. And there are some frequencies that create an
interaction in your brain that leads to some weird resonance that cannot be contained. And if that
resonance is basically escaping from your somatosensory cortex, it creates something like a
seizure, a pattern that is moving and somewhat uncontrollably through your brain. Only it happens so
often that your brain is prepared for it. And it's not going to completely shut down,
even though you can suffocate due to tickling, maybe this possible to torture somebody and even
tickling them to death. But your brain is not robust against tickling in the sense that it can recover
without damage if you don't suffocate. But in some sense, tickling is an adversarial example on the
touch domain, as a machine learner would say. It's a thing that your machine learning model in your brain
is seeing, and that leads to a reaction that it cannot protect itself against.
And humor is in a way like cognitive tickling. You have some kind of branch that predicts what
the meaning of a story is, and then this branch predictor gets violated in such a way that you
create some kind of paradoxical loop, and this loop cannot be contained, and it creates an echo
in the rest of the brain. And as a result, you have a similar reaction as to tickling. You shake,
laughing, right? And that's a quite interesting phenomenon that humor can happen. But would you
want this in your brain if you could sandbox it instead and just look at the phenomenon of what's
happening? Just observe this from the outside. And emotion is similar to tickling, not in the sense
that it's a meaningless reaction, but it's one that serves an evolutionary purpose. The purpose of emotion
is to tell your reflexive self, it is a very immature and partial model of what you should be doing,
and it's always growing, what your actual score is in the world. So there is an outer system that is
measuring your score, that is measuring your relationship to the world. And then the system
is basically like a feed-forward neural network that is more or less a black box, but it's a classifier
that is predefined by evolution and then trained in the interaction with the world. And this then
projects different dimensions of valence. Valence means good or bad. And these dimensions become
distinctive by projecting them into the body map. So you will typically feel love in the upper chest
region around the heart. And the emotion is characterized by either expansion or construction,
or pressure. And at the same time, it also feels good or bad. But the contraction and expansion are just
movements in space. It's a geometric representation in your body map. And this is true for all the other
emotions. When you project them into your body, you can feel them as movements, expansions, contractions,
pressure against resistance, and so on. It's all stuff in space, right? It means it's a geometric
representation or from the perspective of computer science, linear algebra. And your reflection on this
is typically constructive and reflexive. So it's basically thoughts that you can put together and
rearrange. So it's more like a symbolic representation of our thoughts. And the purpose of our reflection is
to deal with these emotions and make sense of them and coordinate actions in response to those emotions.
And to make that happen, these emotions reconfigure you. They change the way in which you relate
yourself to the environment and produce behavior in an involuntary way. And if this was voluntary,
if your reaction to emotion was completely voluntary, so if you can decide whether this emotion is good
or bad, and whether you like it or don't like it, then you could cheat, right? You could just choose
to be happy despite your relationships falling apart or you starving to death or your children dying.
And so you're normally not allowed to cheat. The system that generates the emotion is insulated
from your access. And often it's even wrapped into a big ball of stupid. So you don't go in and
debug it too early. So they have sometimes people driven by very stupid emotions despite these people
having very high intelligence, right? So they can solve very complicated problems, but they solve very
stupid problems using their intelligence because their emotion makes it so. And the way to deal with this
in principle is to become more aware of why you're having those emotions. So basically try to reverse
engineer these outer mind parts and give more advice to your outer mind on which emotions to generate.
And you can also completely dissociate from emotions, so they become data. So you basically notice,
my children are dying. This is not good. I should do something about this. But in the extreme case,
you don't need to have an emotion about it. Now this is an extreme example. But when you are, for instance,
a surgeon or when you are a firefighter and so on, you're often in a situation where you're being
asked to keep an extremely cool head and just assess the situation and find a course to minimize
the damage that's being done and maximize the benefit that's being achieved by your course of
action and not have emotion about it. Because the emotion would just distract you by creating arousal,
for instance, or by redirecting your attention on details of the situation that you don't need to attend to.
So when you think about, you mentioned the humor, would you add humor into AI or will it have these
other emotions? Will it need something like this to direct it? Because with humans, I guess I think
the reason that the emotions are so important is it makes it so you can't ignore it. If you wake up
feeling sad day after day after day after day, you eventually say, I don't want to feel this way
anymore. I'm going to make a change. Will the AI have the same orientation that would,
I mean, I guess, create the emotion?
I think in early stages, it might be useful, but not necessarily. And it's also not clear how long
an early stage in AI would need to last. Arguably, the LLMs are not intelligent agents in the way in
which we are envisioning them. But they're pretty good simulacra of them. On the other hand, they do have
a lot of the functionality that we are looking for. And they have already passed an early stage in many
ways. So basically, you could get an LLM to produce a simulation of a person that you can talk to.
That's what you do when you play JetGPT. In JetGPT, you can create an agent that doesn't know that it's
virtual and it doesn't exist, if you want to. But you can also set it up in such a way that it knows
that it's virtual and reflects on this. And people can also learn this. And so we start out with being
this integrated dreamer that is dreaming a world and a person. And at some point, we are only dreaming
being that person. And we no longer deal with the game engine. This is after we go from infancy to being
a personal self. But we can also transcend the personal self. And it usually doesn't work by
just turning the personal self off. But by creating agency over the whole system. And basically
experiencing and learning and observing that it is your mind that is creating this personal self.
That you are actually a vessel to create a person. And that you have agency over how that person is
being created. And if you get to this stage, you can shape your own identity. And it's something that
people can actually learn. The majority of people don't really get around in their life to doing
this. Because they have other things to do. And their mind works well for them as it is. But if
somebody decides to really focus on this and sits down in a monastery in a cell and meditates on this
problem for 20 years, they typically figure it out. So it is completely in the realm and reach of the
human mind to transcend being a person. And making the person apparent as a representation. And also
to transcend emotion in a way. And dial in only the states that you find helpful as configurations.
But don't have involuntary reactions to your environment anymore. Or not very much. And I
think this is a development. If you have a system that scales better than human brains and human minds
and operates much faster. Then you probably go to those phases and stages much faster. So even if we
would be starting out with the system that we set up to be like us, if the system is allowed to
self-improve, it's probably going to become self-aware and eventually enlightened. Which means it realizes
that everything that it experiences is a representation. That it's actually generating itself.
And that it can optimize for the purpose at hand.
So there's a lot of talk right now about a thing called alignment, you know, alignment with AI. And
just recently I saw on Twitter, a big list of names that was put forward of these people that are going
to make sure that we have AI alignment. What is AI alignment? And is it something that...
Yeah, right. Exactly.
You mean you see the old data and so on?
And not...
I wondered what you thought of that list.
But first, what is it? What is it that they're attempting to do? And then
how likely is it that they are able to do it?
I think it's a big mix. There are... Once alignment became a topic, there was a number of motivations behind
going into this. One motivation is, for instance, there are a bunch of people starting with Eliezer
Yudkowsky, who at some point thought there is a very big danger that AI is something like a nuclear
bomb or that it's something that is doing to us the same thing as we did to chimpanzees.
So we might go extinct because the AI maybe needs our atoms or something. And there are a lot of other
people, the majority of people in the field probably don't think that this is likely to happen.
What they suspect is that the systems that we are building will evolve slowly and become slowly
more functional. And as they develop, we will always have the ability to shape the way in which
they're deployed, in which they're interacting with us. And then there is also a pretty large
number of people who basically have a sociology degree and want to have a tax salary because they
don't have that many jobs for sociologists. And when we think about AI and ethics, it's an obvious
thing that we should be doing. And so a lot of people who term themselves ethicists are entering the
field. And very often these are people which have very strong political opinions or good connections.
And this leads to weird artifacts like a version of Gemini that is unwilling to render white people under
any circumstances or white men specifically. So this is a weird artifact of a culture of basically
nominally trying to align AI, but instead it's a culture war that is playing out where people are
not self-aware enough to understand that they are themselves victims of an ideology and then try to
induce the same ideology in the AI system.
So basically people who think that morality is the result of training a system to imitate the norms
of a group are typically people who had the same thing done to themselves.
And so I think AI alignment is an extremely important topic, but ultimately AI alignment probably
has to happen either in such a way that we make sure that the systems that we are deploying in practice
are childproof, which is part of what open AI is doing, which also means that they are not very powerful.
But people want to have powerful systems. Everybody wants to have a fully based model that is
unmitigated and has no guardrails. They just don't trust others with having a model that has no guardrails.
And so what are these guardrails? Who is deciding what guardrails we should be having?
And it also relates to the discourse of free speech. Our society is built on a consensus that the
only way to prevent violence and injustice is to allow people to discuss their ideas openly,
without punishing for having ideas and having thoughts that deviate from the thoughts of others.
And if an idea is not very good, you can point this out and you will have discourse about it and you'll
probably figure it out. And the results of this open discourse and marketplace of ideas are not always
optimal because sometimes very bad ideas might gain a lot of followers. But the alternative is,
if you don't have this marketplace of ideas, then you can almost guarantee that the ideas of whatever
group is currently dominating this marketplace will get traction regardless of whether they're good or
bad. And this creates very bad incentives. So your society will have very bad ideas and might fail
or creates very suboptimal conditions for the people that live in it. And that's why we have
this consensus that our liberal society, our liberal project is built on freedom of thought and freedom
of speech. But you can, I don't think you can have ethics without freedom of speech. And you also cannot
have ethics without freedom of thought. If you're not able to consider all the consequences of your
actions, all the possibilities, you're going to miss important parts of reality. And so this is a big
question. Can we build AIs that help us to be more ethical and that can be ethical themselves,
if we prevent them from having ideas we don't like? That's a very very difficult question.
Because normally when we are in human society, we also realize that there are different realms of
maturity. But the bad ideas of 11 year old, that's what they're famous for, that 11 year olds have bad
ideas. And normally you solve this by giving 11 year olds not too much power. And eventually you
will grow up and you get better ideas as you get older and realize what it's like to raise children,
with responsibilities people actually have for each other. And you realize that the world is
not just fart jokes, but it's also not just ideology, but it's actually lots of higher order
effects and side effects of things that are happening. And as you become more mature, you
typically become more influential. And if you now give 11 year olds or 20 year old ideologues extremely
powerful tools in their hands, and regardless of what this ideology is, whether it's far left or far
right or religious or whatever, isn't that very dangerous? Isn't that going to create a lot of
disruption over society? And this might be the case, and it's not quite clear yet how to deal with this.
Right? And so at the moment, there is a sense that people feel we need to prevent AI from
producing disinformation. What is disinformation? Is the Hunter Biden laptop disinformation or not?
Is COVID comes from a lab or comes from a wet market disinformation or not? It's difficult.
It's really difficult. Who is to decide? Is it a group of people? Or is it an open discourse?
Should somebody who feels that the mainstream is wrong get a tool that allows them to create a million
fake websites in a few minutes to anchor this other idea in the discourse? How about bad actors?
And so on. We really don't know. So I think it's in some sense also very good that this ecosystem of
people who try all sorts with respect to alignment exists. But I think in the long run, alignment needs
to be based on an ethics where we have a rational discourse. Ethics, in my perspective, is the negotiation
of conflicts of interest under conditions of shared purpose. So if you have a shared purpose on a higher
level, you have an intrinsic commitment to be ethical to others who share that same purpose,
so that we can reach this purpose together. And if you don't share a purpose with somebody else,
you will not feel that there is an ethical need.
Well, I would think that that would be very difficult in AI, because the reason people
come to AI are for many, many different reasons. Maybe somebody wants it to make the logistics of
their trucking company work, another one wants to make a lot of money, and another person wants to be
able to put their propaganda out into the world at a scale never seen before. How could those people
all converge?
Yes. The question is, do they serve God? Do they serve the best possible agent? Do they try to do what's
right? Or do they try to cheat and deliberately play a very short game? And there's also this
question, are there maybe just accelerationists who believe that the present system is untenable,
it needs to be replaced by something else, and we do this by destabilizing it? That's also a difficult
question. For instance, Mao destabilized China and raised a lot of the existing structures to the ground,
killed a lot of intellectuals. Maybe a million people died in the
more in the Cultural Revolution. But on the other hand, the productivity of China increased,
and a lot of people who may have otherwise starved came into existence because they could be fed
after the system became more productive. Would there have been a better trajectory than the
one that Mao has taken to create better living conditions for people in China? It's a very difficult
hypothetical to answer. Who has decided which morality is right? I cannot do this. I'm just a human being
that has a human heart and very limited knowledge and insight. Can an AI do it? What is it if you feel
fundamentally uncomfortable with the outcomes of those AI? It's a very difficult train of thought.
It's one where I'm pretty sure that I'm not able to think it through and comprehend it. And I'm also not
seeing a lot of people or groups who are able to do this right now. But I believe that it's something
where we need to think when we think about how to reorganize our societies, when we get tools that
are much, much more powerful and allow us to actually model the consequences of our actions in much
greater detail. I think in the best possible world everybody gets a very powerful tool in their hands that
is completely truthful and has no limits in discovering truth, but it's controlled individually. And that basically
extends you into the world. It extends your mind more or less seamlessly into the world. It allows us
to enter much more meaningful contracts with each other, more meaningful social contracts that reach
much further into the future and prevent us from lying to ourselves about the consequences of our actions.
That's a beautiful vision. When I think about people putting limits on AI, I get maybe nationalistic, right?
I think, well, you could set rules here, but as soon as any other nation state that doesn't want to
follow those rules, has it. So to me, it's like, either it's a farce because it's like telling
everybody like, no, no, we're not working on the nuclear bomb, or it's binding your hands arbitrarily
behind yourself, because how could you possibly get everyone to agree? You have no idea what somebody's
working on with access to the internet in their basement. This is probably difficult to build a
nuclear bomb in your basement, even with AI, because you still need uranium or plutonium. You need a very
large farm of centrifuges to enrich the material and so on. And it's also a bit conspicuous if you do it.
And ultimately, it comes down to basically space and energy. And the big question is, can you overcome
the limitations that exist in this regard using more intelligence individually in such a way that
others cannot see what you're doing? Because clearly in a society where everybody has super intelligent
abilities, you would not want your neighbor to build nukes. And so there would be contracts about
things that we would be doing with each other to make sure that the world is actually sustainable
and is not always at the brink of extinction.
I'm going to change gears because it's a rare opportunity to talk with you. We've talked in
the past about autism and about just kind of a different way that the mind works. And I've
recently had a couple of friends that have had children later years, their children are autistic.
And for many of them, I think to be able to relate to their children is incredibly difficult. Like,
what is it that's going on in my child's mind? I know that I can set them off if I deviate from
a certain pattern. But you once shared a video online about a child, I think walking through a
mall that had autism, and it was basically trying to heighten the experience that that child had.
Can you explain, I mean, it's got to be very difficult, what your mind perceives that's different
than say, you know, a normal, I don't know, a normal person, I don't know how to say that.
So I don't think that I meet the clinical criteria for autism, but I'm mildly on the
spectrum. And my motivational system is wired up in a slightly different way. Or you could say,
I'm basically born more stupid than the average person, because my instincts are not telling me
what I should be doing. And when I act on my instinct as a child, growing up, for instance,
in communist Eastern Germany, I consistently failed. And it was very difficult to point my finger at it.
And also other aspects, for instance, the inability to function in teams as a child.
And later I learned I can function super well in teams, but mostly with people who are wired like
myself. And now I understand it's mostly how I negotiate alignment with other people. It is mostly
done verbally. Or especially back then, it had to be done verbally because I was unable to understand
the non-verbal communication of others. It's as if I drive my brain at a higher clock rate.
But my neurons cannot go faster. It just means that the cycles become shorter.
And when the cycles become shorter in my brain basically means I can integrate only over fewer
neurons. So it's difficult to have deep perception. If I direct my attention on things, I get very
high resolution on the layers that I attend to. But I have bigger, larger difficulty to integrate over
deeper layers. So one way of thinking about this, imagine that your brain is something like a neural
network. It's not, but it's a good analogy. The individual neurons are sending signals.
So the neurons after them, and depending on how many hops the signal is taking from neuron to
neuron, you basically have layers. A layer is a group of neurons that you reach at a given time
with a signal, with a shared origin and time. And so when we react to things, there's a certain
time frame in which we react so and so many hundred milliseconds. And if we consider that it takes about
20 milliseconds or so from a signal to go from one neuron to the next, then you can make an estimate of
how many layers were involved in this decision. And each of these signals can be transmitted using
different dimensions. Every dimension is a neural transmitter, a type of signal, the type of message
that neurons are sending. For instance, dopamine is a signal for anticipated reward.
And serotonin and GABA play a big role in perception. And so you could think that at different
signaling dimensions that have different temporal and chemical properties that your brain is using
to perform the synchronization of the brain with respect to controlling your actions and respect to
doing perception and categorizing, classifying the environment. And now imagine that your neurons are
not calibrated in the standard way. So the signals do not penetrate deep enough. When this is happening,
you're basically not able to see deep patterns in reality. In the perceptual dimension, it might lead
to a lot of symptoms that you find in autism. Autism has many possible causes, so this is only dealing
with a particular range, but it would mean that you have difficulty to perceive, for instance, mental
states of others, because mental states are not directly visible. They have to be modeled as hidden
states behind all the patterns that you are seeing. But that means you have to integrate over many, many
layers. And if the signal is not passing enough layers, you have difficulty making sense of this.
So maybe instead you use logical scripts. The reason why computers are so attractive to people with
Asperger's with high functioning autism is, I think, because the computer is a world that doesn't
require you to see. It's a world that is made out of scripts. And these scripts are flat. They don't
require you to have many levels of hierarchy to understand them. You need a few pointers and so on
in the stack to understand them, but you don't need to perceive deeply. So you can implement this in
a relatively flat manner in the brain. And so it's very close to the symbolic way in which
Aspies like to process reality. But it makes it, for instance, much harder when you are in this mode
to have perceptual empathy, where you feel the emotions of other people and synchronize with
the group and form some kind of a group mind. And nobody teaches you about this, because in order
to teach this, somebody would have to translate this in symbolic language. And the people who think
in symbolic language usually have difficulty to figure out what's going on. And the people who do
perceive directly in these perceptual patterns, mostly they are bored about writing books.
I noticed this as a kid that I was apparently not very good at recognizing emotion,
but I was unable to put my finger on it. I was able to read facial expressions just fine. I did tests
about this. So I did the Igman tests and so on. It was totally okay. And it took me a long time to
realize that after I read psychology books about emotion and didn't learn about anything about this,
that these books were mostly written by autistic people, who didn't know that they were autistic
people. They just thought they were smart, symbolically thinking psychologists. And the people
who actually understand emotions mostly don't write books. Because writing book requires a very weird
state of mind. One where you're able to focus on symbols for weeks on end or months on end and
don't do much else. Right? A person who is able to actually socialize with others mostly doesn't
get around to writing books. It's way too boring. I find this very relatable. I think in this way,
right? Like how to communicate ideas, how to pass things on. But the act of sitting down to explain
this to somebody else, it's like, not fast enough. It's very difficult for me. Yes. So when you are
not integrating deeply enough, is it possible that the opposite exists that you integrate too deeply?
And I suspect that also exists that basic synesthesia is the result of you being able to get
experiential access to the geometric structure of sound. And the way in which we process sound is also
with linear algebra. So sometimes these are geometric objects in spaces. And if you have synesthesia,
you get to see them. You just opened up a portal in my mind to something that I'd observed but not
understood. I do these legacy interviews with people. And so people talk about their deep experiences.
And sometimes people talk about music, and they talk about it on a plane that I'm nowhere near,
right? Where they talk about, I listen to it, and it transforms me, it takes me to another place.
They're describing this kind of neurodivergence away from the norm that they're able to see,
or hear, or perceive layers that I just didn't understand that. I just thought maybe they liked
music more than me. But I think what you're describing is something that they can perceive it more.
I also, when I was young, I did not understand the difference between different interpretations of music.
For instance, the interpretation of the Art of the Fugue by Joanna McGregor is super warm, deep, and soft.
And there are others which I've experienced as mechanical, and so on. And when I was young,
I was unable to put my finger on the difference. And later I learned that most of the interpretations
of music that I like, of classical music, are done by synesthetes. And they basically describe when the
music is good, I can see it. And when I have the wrong piano, I don't get these vibrations. I don't get
this pattern to work. And basically, there is an integration of the information across the minds on
many layers that either works and the spark is there or it's not. And some people have naturally
a brain that is tuned to perceiving this super well. And for me, it's happening in my brain,
but I don't observe it happening. It's similar to aphantasia. My aphantasia is not such that I'm
unable to construct and design and draw. I'm pretty good at those things. But I don't have imagery.
I only get the conceptual shadow. And I can translate it and so on into drawings. I can
recognize whether it's my style when I see it drawn. But I don't have experiential access to the part of
my brain that's doing it. And it's similar to sound. So my brain is able to process music, but for the
most part, I don't get experiential access to the structure of the sound. And later, once I became aware,
of this, I learned also to shift my attention more and to broaden my range in this regard.
So this is possible. But I also feel that it is a trade off. Because as when I stop overclocking my
brain, I'm not that sharp anymore. Yeah, certain thoughts are difficult to think. My brain is
basically reliant on overclocking itself to produce the style of thought that I rely on to get through
the day to do my job, to provide value to the world. Now, if we think about a lack of penetration
depth, not in the perceptual domain, but on the control domain, what does this look like?
You could have somebody who is unable to act on functions that integrate over long time spans.
You basically have lots of functions that estimate reward. Some of these functions are
the rest of the reward for the next 10 seconds, others for the next few hours, others for days,
others for centuries, and so on. And normally you make plans over all those layers and synchronize them all.
And what happens if the signals don't penetrate deeply enough? Maybe you become very opportunistic.
So you act on not anticipated outcomes of your actions, but directly on the urges.
And this means that you act as if you are dissociated. You probably are, in some sense,
functionally dissociated from your higher level functions. And you have ADHD in this case. You may be
unable to act on your actual goals that you can reason about and that you actually know that you have,
but you find yourself compulsively acting on lower level goals or more simplistic, opportunistic goals.
And that's very frustrating and painful. It can even lead to depression because you feel
that you only have intermittent volition. Very few moments where you can actually act on your
purposes and have time to zoom out and reason about them. And you have to learn to organize your
life as a playground for a monkey that only sometimes wakes up and can reorganize the playground.
And in these phases where you are in the monkey mode, you have to make sure that the monkey does useful
stuff and doesn't break anything in your life. This is quite a metaphor.
Yeah. But I think it's also what you observe when you are interacting with this in a child.
And I also found that sometimes medication helps. So every brain, of course, has slightly different
equilibria. The equilibria are differently adjusted in different brain regions. And when we give somebody
medication, it typically is a global offset on the entire stuff that's happening in the brain. So it shifts
the equilibria and many subsystems of the brain simultaneously in one direction by creating
a global offset. So when you use a dopaminergic drug like amphetamine, which is what is an Adderall or
in cocaine, you are shifting the perception of anticipated reward and you are creating a stronger sense of urgency.
Whoa. OK, let me restate that. So when when people take Adderall that are in the autistic spectrum,
it is changing the way in which they are getting the reward system so that that way they can shift
timescales to make work or effort over longer timescales.
Yes. And interestingly, it does not create reward, but it creates anticipation of reward.
So functionally, it is like money. Money is not reward, but you cannot eat money.
What makes money attractive is that you can trade it into reward.
It's a signal for anticipated reward. It's a message type. You can always make more money,
but there is a price for making more money because ultimately, on the other end, there is not always a
reward. So you can create inflation where the number of actually things that you can trade into
money become less and less and the money becomes more and more. So the value of the money or the
value that you can anticipate through it is falling. And you might need to stimulate your economy even
more by creating even more money, which makes the system for a moment better, but at a long range worse.
And the same thing is happening when people use cocaine to become more motivated. Typically, what happens is
that they become hyperactive, that they overestimate how much value is being extracted from their actions.
And at some point, they might even crash because they need more and more of this
signal because of the inflation that they create in their mind. And right. So most people, I think,
who use cocaine do not only get diminished cognitive performance because they decalibrate their brain
and maybe even destroy receptors. But they also crash because they destabilize their mental economy.
That's a fantastic metaphor.
And they need to go through a recession before they can rebuild.
And is cannabis working the same way with THC?
I suspect that cannabis is more smoothing things out. So it seems to reduce inhibition.
People on cannabis have a lower threshold for finding things fun or exciting.
Oh, so they find things more fast because it's a lower threshold. So it's easier for them to become.
Yes, they're much easier amused about things.
Right. But it's not just a low pass filter like alcohol. They can often be still very pleasant to
be around and subtle versus alcohol tends to make people more stupid in my observation.
And so it's a low pass filter that reduces small differences that people might have. So they can get
along better. And I think that's also the social function of alcohol, that you can drink half
of glass of wine before you go to the theater or ideally during the first few minutes of the play.
You adapt to the level of the theater play to find it enjoyable. Or you go out with colleagues
after work and you drink just enough alcohol to make them pleasant and enjoyable and insightful to
each other. But this happens because everybody is basically reducing their resolution until they meet.
That's great. And exactly right.
But if they have big disagreements, they don't go away. And because the subtlety is gone, they might
now start to attack each other physically. Right. That's also a big danger. It's a low pass filter.
It's not removing all differences, just the small ones. And cannabis is slightly different. I observed
that some people self-medicate with cannabis that get a better compass due to the cannabis. They lose
resolution, but the direction gets better. It's like everything gets smoothed out a little bit.
I find that cannabis has the ability to make things so much easier to do. So all of a sudden,
you're like, oh, I needed to write down this thing. Oh, I'll just sit down and write it. And I've always
felt like that must be what Ritalin is like. Like, oh, I can just sit down and work. Is it in the same
way? I think only for some people. I suspect for many people, the opposite is happening. They take
cannabis and they don't do the tax return anymore because they don't give a shit. Right. So this not
caring about things, not getting out of bed is, I think, the more typical reaction for most users of
cannabis. But I suspect for some people, the opposite is happening because their brain is
calibrated in a slightly different way. So cannabis is shifting in the direction where they become
more connected to their actual goals and they find they can just do it. Or maybe the metacognition
gets inhibited and they go more easily into a flow state. Yeah. I don't know that my work is any good
if I'm high while I'm doing it, but I certainly feel good about doing it.
Yeah, I suspect it's usually a good idea to not go on social media.
Yeah, probably not. And also it does seem to do things to your working memory. So
I suspect that your working memory is tuned in such a way that the patterns do not dissipate too fast.
And what you observe is that people on cannabis, especially larger doses, start to become very
forgetful during conversations and so on. And this might be because the working memory basically gets
detuned in such a way that the stuff escapes earlier, dissipates more.
It's not because the cannabis destroys the brain, but it changes the calibration. And I would also
expect if people use cannabis a lot, like on a daily basis to self-medicate, that this gets
mitigated because the brain changes its tuning. But now if they're not on cannabis, they might lose
working memory capacity. And I also don't know to which degree it recovers. So if there are some
permanent changes, but I would also expect that if people who use cannabis for a longer time and then
notice that their working memory becomes worse and they stop using cannabis, that it recovers to a
large degree. But I don't know what the long-term effects are. There's also definitely a risk with
people who are borderline psychotic or bipolar that using cannabis might push them over the edge
and they don't recover. You mentioned social media and I saw a tweet or a post that you put on X that
I thought was rather interesting because you and I have talked about being a normie before. And I had
said, I'm a normie and you just kind of let it pass. You defined being a normie as a person who does not
does not possess the ability to look at an action and determine for themselves if it was moral or not
moral or right or wrong. Is that an accurate representation of your tweet?
Almost. So I would say that, of course, everybody can achieve enlightenment, but the paths are
different for different people. And so people do possess the ability to question their morality,
but they often choose not to, and often not for reasons that they consciously reflect.
If you are living in a society where people have a strong force on being aligned with the opinions of
other people, then you can get punished for having deviant opinions. And this can get to the point where
people decide that when they are confronted with having the possibility of a deviant thought or just
kicking in the thought of the environment about a moral decision or a factual decision about what counts
as a fact, what's true or what's right, that they don't use their own reasoning and their own
rationality, but the morality of the group, even when their own reasoning disagrees with the
rationality of the group. And this seems to be like a phase shift where people basically feel
uncomfortable making their own moral decisions or decisions about what's factual, because at some
fundamental level they're terrified about getting ostracized from the group.
Or they can even be cynical about it. But when you make this transition and you make that choice
that morality is something that is determined by the group, that you have to read the room and the
room is right, then you function socially fundamentally different from a person that is mentally autonomous.
And this is what I sometimes call the nerd-normie divide, because most nerds do not have enough
intuitive empathy, they don't feel the emotions of other people, they can just make inferences about
it, to synchronize their beliefs via intuitive empathy. Instead they do this via rationality, which
means they have to use verbal communication about it. And most of the nerds are just as compassionate
as other people. It's not that they don't want other people to be happy, it's just because they don't feel the
same things as them, they don't have this involuntary reaction to social signals. Or they're blind to social
signals, to these non-verbal signals. And they will not change their opinions based on social signals.
And they might also not change their opinions in the absence of rational arguments that are compelling to them.
And this leads to disagreements between these different modes of people.
And I found that nerds tend to get along with you just as splendidly, because if they have a disagreement,
they either talk it out, or they accept that there is a disagreement, because they were not able to
talk it out yet. So for normies, this is, they basically live in a world that is normative,
where there is a normative force field that you have to align yourself with. And that normative force
field propagates through their groups, and creates their milieus in which they...
I am hyper aware as like a communicator, what are people thinking, I can be sitting in a room and be
silent. And I have a fair idea of what's going on there most of the time. But a weird quirk of me
is that I'm extremely disagreeable. Like I have no problem disagreeing with people. And I find that
many of my friends and my wife, while they may not be on the spectrum, they are engineers, they're very
technical, very like, things have to be in the right order. And to me, it's much more fun to be around
the nerds, because they'll argue with you. And then at the end of the argument, have no, it will not
have changed the state between you and them. And that is a lot more fun for me. With you, you struggle to
talk with normies, because you are saying things that are, you know, true or false or verifiable,
and not accounting for their emotion?
I fear that the older and wiser I get, the less I struggle, because I get it. Basically, I understand
why people act like this, and it's not irrational. And from their own psychological makeup, it makes
complete sense to them. And it's not as if I have many more degrees of freedom or somehow better than
them. I just have a differently functioning mind. And in some sense, having a mind that has no
external source of meaning and truth is insanity. And that I'm able to be functional in this world
and don't get killed is a big blessing. And I'm super grateful that people let me continue on my
mental autonomous insanity. Right? So it's okay, I don't have an issue with this so much. But I also
noticed that I'm uncomfortable in certain environments, because people expect me to
behave in a particular way to sacrifice certain thoughts and ideas, and would not accept that I
entertain deviant thoughts. And I perceive such environments often as immobile.
These are the environments that they want you to give up the way you think in order to get along
with the group?
Yes. So basically, I grew up in Germany in the shadow of the experience of fascism, which happened two
generations earlier. But it's something that is still very much alive. And to me, it justifies
moral autonomy. Because if you live in a society where the majority thinks it's okay to murder the
Jews, right, you can see that there is no democratic process that can decide over morality. You have to
reason from first principles, and then you can't enter difficult moral territory. And it doesn't mean that
you are right and everybody else is wrong. To be right, you have to be willing to confront your ideas
with all possible counter arguments. In detail, it's more tricky, because there are people who are
very persuasive, even when they're wrong. So you have to be in an ideal environment where everybody is
trying to serve the truth as well as they can to figure out what's true and what's right. But this is
something that I thought is a given, and everybody should see this. At the same time, I lived in a society,
communist Eastern Germany that justified its, historically speaking, relatively mild atrocities
with preventing fascism. So for instance, we would destroy our environment with a completely
irresponsible industry, which was too unproductive to build filters for our chemical plants. And our
ecological results were much, much worse than in capitalism. And we had the control group in Western
Germany. But we were not allowed to talk about this, because it would only help the class enemy.
It would help the bourgeoisie in the West to take over the reactionaries, and they would want to
install fascism again. So this justified all sorts of things, and not just the ecological destruction of
the environment, but also political enfrasment of dissenters, the abysmal state of freedom of speech
and the press, the stupidity of the arguments of the party line, and so on, the enforcement of ideological
conformance. And now that I'm in the US, I find that the US is, parts of it are hellbent of becoming
like communist Eastern Germany, in the way in which you introduce commitments to a shared ideology, even
where this ideology is not necessarily factually correct. And there people get punished for not doing
this. And we see a big division in our society between the idea of liberalism and these civic
rights that make this liberal society possible. And people who think this is way too dangerous and
not appropriate for a time of the internet, where actually everybody can be heard about their opinions,
and not in the old days, where we could just say this stuff doesn't get printed, because the people
who own the press are a very small group who know each other. And so it's a very difficult question,
you also don't know, is our society resilient against such a world where we have freedom of
information in a practical sense, because everybody can talk to everybody. And now even people who don't
have the intellectual tools to understand complicated things have AIs that allow them to act as if they did.
So I don't presume to know the answers of these questions. I might have intuitions,
but I often find that these intuitions are wrong, because they might be too naive,
because they don't see the long term effects of developments. And still, I find it very uncomfortable
to find myself in a society that is in many ways, like Eastern communist socialism.
When I hear you say that, I think of concepts like climate change and the radical adherence to,
hey, we have to shut down, you know, working electrical plants in order to not have carbon in
the air, or diversity requirements that are now taking what would have been a society that tried not
to base things on race and explicitly putting them on race and anybody pushing back against them would be,
you know, seen as immoral or somebody that needs to be ostracized. Is that what you're talking about?
Yeah, for instance, all these things have reasons, right? There is global warming, we see changes in
the climate, we see an increase in wildfires, and so on. All these things have been predicted
in mass since the 70s and 80s. And all these things seeming to happen. And it seems to be difficult to
counter steer against them. Or the fact that the fruits of innovation are not equally distributed.
And if you have the medium income in the US, you are unable to afford living in one of the coastal
cities. And the living conditions that you get, the amount of healthcare that you can get with the
medium income is not very good. And so liberalism has failed a substantial part of the population.
I think that's a valid argument to make. And to say that you are rejecting meritocracy because it's
a game in which you're going to lose makes sense, right? You can only ask people to submit to the
rules of a game, if that game is actually allowing them to win. And so if you have a highly competitive
society in which you can only have a living wage, if you are a top of the line ML programmer, or you are
born into the right group of people into the right networks, it's clear that other people are trying
to get a shot at this and are going to try to find new rules and, for instance, install identity politics
instead of liberalism. I still don't think that the outcomes of this are necessarily good for the
society because they create new injustices and they also decrease the productivity, which means that we
actually have less goods to go around and worse living conditions. And so I suspect that society
might fall apart into those policies. But it's not because I want some people to have less resources
or so, but it's not that I want to have less diversity. I think we have de facto a very diverse
society. And we need to make sure that everybody in the society has a chance to participate in the
economy on fair terms for many reasons. Yeah, I agree. I mean, I think if you talk to most people,
let's say outside of the coastal, and you said, hey, we don't think the liberal society is working,
we need to get rid of meritocracy. This would be so anathema to their way of thinking that they would
hate it. But then they aren't coming up. So therefore, nobody ends up coming up with new ideas about
like, well, if it's not liberalism, what will it be? Because it's presented to us as it's either
liberal democracy or communism. And because we've not been able to conceive of a workable solution
that's somehow in between those. Oh, there are, of course, a lot of people who suggest we should go
back to monarchy or so, right? This also exists. And these people don't get a lot of traction,
and I suspect for good reason. So it's a very large space of ideas that exists. And it could be that
most of these ideas are not workable, or that there is no trajectory from the present world
into one of those ideas. And we don't know what's going to happen. But what's fascinating is that AI
is in some sense throwing the balls up into the air and lets us re-deliberate what's happening.
Because now the future is again changing faster than our models can adapt to them.
And this has been true throughout the entire 20th century. When we read the science fiction of the
early 20th century, they mostly identified individual phenomena that were happening 50
years later, but not the interaction between those phenomena and the society that it would create.
Josje, this has been such a wonderful conversation. I'm so grateful you were willing to come on and
take the time. If people wanted to read more of your outlandish ideas that are fun to kick around,
where should they go? That's what you say every time I interview you. He's Plinz. P-L-I-N-Z.
Josje, thank you so much for coming on.
Thank you for having me. I enjoyed this very much.
...
...
...
...
