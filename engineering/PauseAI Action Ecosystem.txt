Hi there. My name is Will Petillo. I'm on the onboarding team at Paws AI, and this is the
second video on internal strategy, this one on our action ecosystem. The purpose of this video
is to give an overview of the types of activism at Paws AI and how they all fit together. The
intended value is to give some ideas as to where you can slot yourself into the organization and
how your work as an individual serves the larger whole. This can help answer questions like why
does this matter? How is this actually helping? Another value I hope to convey here is an
appreciation for other people with different skill sets and diverse ways of thinking. This is a very
ambitious task that we're taking on, and it takes all kinds. A couple of core concepts that I want
to highlight here. The first one is this arrow in the top left called the value vector, where
how far you go is dependent on the magnitude and the direction. Put a lot of energy into activism,
but we don't put in the similar amount of effort to make sure that we're pushing for the right thing
or for policies that make sense. That would be magnitude without direction, which would be
making us part of the problem. Whereas if we put endless amounts of energy into getting the direction
absolutely perfect, just debating things endlessly, getting into finer and finer details,
that would be direction without magnitude. And we might come up with some really interesting plans,
but none of them would actually happen. And so it wouldn't matter. The next concept I want to bring
up are these arrows on the bottom called feedback loops. So there's three types, negative or self-limiting.
That's the one on the left. The one in the middle is positive feedback or self-reinforcing.
And the one on the far right is linear or no feedback. Negative feedback is whenever the more
effort you put in, the less results there are, either because of diminishing returns or because
of strengthening some opposing force. An example of a place where I see a lot of negative feedback
is narrative warfare on social media, where people just kind of go in and making insults and blasting
people and making really clever takedowns and whatever else. That generates a lot of engagement
pretty quickly and get a lot of views, a lot of likes, and maybe there's some impact there.
The big problem with it is the more successful you are, the more that angers people on the other
side of the debate, such as effective accelerationists or tech people or whatever else. And they start
putting more energy into making counter memes and counter arguments and pushing back harder and
harder. Also, if you come up with some clever rhetorical strategy, then the other side is just going
to reverse engineer it and use that against us. This doesn't necessarily mean that we shouldn't
pursue these kinds of activities at all. Just being aware that there's the potential for some negative
feedback to be present here. A positive feedback loop might look something more like recruitment,
where I bring in a couple of people and some of those bring in other people. And then the more
people that are in, the more people that are bringing new people in, and you have this kind of
exponential growth. For linear improvements, lobbying might be like this, where the amount
of effort you put into lobbying doesn't really have any impact one way or the other on how much
impact there'll be from being involved in more lobbying. That may or may not be true, but that's
the first example that comes to mind. The reason it's very useful to think about feedback loops is
this is probably the most important consideration in determining what kind of actions are going to
have the biggest magnitude. It could be very easy to look at just the immediate gratification of how
much impact does this seem to be having right now. But the bigger picture is, does this feed into a
positive feedback loop that's going to grow exponentially? Or is this something that's going to
limit itself over time? The next topic is over on the right side, interconnected systems. You may be
familiar with the idea that when you have a problem that you're trying to solve, if that problem is a
symptom of a different problem, then just addressing the symptom is going to be limited. It's going to
be a very negative feedback kind of strategy, because any progress that you make there, well, the source
of the problem is still showing up. So the problem will come right back, or maybe it'll show up in some
other way. Whereas if you address the root cause, then that'll address that, and then also make
downstream issues solve themselves a little bit more easily, at least. However, that kind of root cause
analysis assumes a relatively simple causality. You know, A causes B causes C, and so on. Whereas what
often happens in the real world is something that's a little more complex and messy than that, where A and B
both cause each other, and then C causes both of them and is impacted by everything. And everything's
all kind of jumbled up. A consequence of working in an interconnected system is that every single node
in this entire system is caused by something else and is also the cause of it. If you focus on any
single thing, then you're going to run into problems from the other nodes pushing against you and getting
very strong negative feedback signals there, where it becomes hard to change anything. However, if you're
able to work on all of the nodes simultaneously, then you get the opposite effect, where rather than
them fighting against each other, they all reinforce each other, and you get a positive feedback.
Now, it may be impossible for any individual to work on many different things at once, and that's what
collaboration is for. It allows people to separate into groups, work together, help each other out.
Then the whole is more than the sum of its parts. A last concept I want to bring up here is the
process funnel. So when we dive into any particular node individually, there's often this dynamic where
there's various levels of task. On the top level of the funnel that reaches lots of people, or it's
available for lots of people to work on. It's fairly low effort, low energy. Whereas when you go lower in
the funnel, that tends to take more energy, can be done by fewer people, is directed at fewer people,
is just higher engagement down to the bottom of the funnel, which is very intense, very focused.
The point of knowing when you're in a funnel is knowing which stage you're in and adapting the kind
of tasks you engage in, the mindset you use, and your just overall strategy accordingly.
Speaking of interconnected systems, the big one that I want to focus on, on a very high level for
Paws AI's Theory of Impact, is this idea of inside game, outside game, and organization. Where inside
game is working with people in power, outside game is mass mobilization, and organization is just the
logistics and behind the scenes kind of stuff. A point that I want to make over the next several slides
is to investigate what each of these are and how they interrelate. Starting with the inside game,
again, the meaning of this is convincing people in power. This could be legislatures, people working
at AI companies, anyone who has the capacity to make meaningful decisions. This can include emailing
politicians, drafting and critiquing legislation, changing culture in AI companies by having people
work within it or talk to people who are there, anything like that. The value of inside game
approaches is it has direct access to the mechanisms of change. Ultimately, change has to happen from
people who have the power to make decisions. Working with them directly or becoming them, you can
obviously have a lot of leverage. The danger of relying too heavily on inside game approaches is that
you're often just going to get the runaround. You go to lobby a politician and instead of meeting with
them, they just have you meet with a staffer and the staffer nods along, is very sympathetic, and it
says a lot of nice things. And then they take your little two-pager of the proposals you want and then
they just go toss it in the shredder and forget about the whole thing. Because they weren't actually
trying to help you, they just wanted to appease one of their voters and make it look like they're
helping you. If you can get past that being issue of being held at arm's length, then you can run
into Faustian bargains where they say, okay, this is a good proposal, but it's not really realistic.
So we're going to need you to compromise a little bit, cut this, tone this down, make it a little less
radical. And so you make a compromise, then you make a compromise on the compromise, then you make
a compromise on that. And then when something finally gets approved, then it gets watered down
through all the various layers until what actually ends up passing is something that's totally unrelated
to what you actually wanted. You end up getting nothing and sacrificing everything. And then even if you
can get past endless compromising and you get people in power to say, yes, we're taking this
idea, we're taking it seriously. We're not going to water it down. We get what this is about. Then
you can run into deception where they make all these promises when it's all stuff that's going to
happen in the future. And in return, they get your support in the present. And then once they don't
need you anymore, or there are other interests that are more important, then they immediately drop your
cause and do the opposite of everything that they promised. OpenAI is a good example. It started
off as a safety company, but really they ended up kicking off the AI arms race. All the people who
were really interested in safety have walked out when they tried to push out Sam Altman for various
deceptive practices. He just made it run a coup on the company and came right back in. And that's
actually indicative of just a general failure of the AI safety movement, which was that it relied
too exclusively on inside game type tactics. And they ran into all the dangers that I just mentioned.
This is not because they necessarily went about any of their lobbying or talking to people wrong.
It's that it wasn't supported by other things, like an outside pressure to make sure that the people
they were talking to actually listened and followed through. And there was some rationale behind it,
like some of the early thinking by Yudkowsky and other people in the AI safety movement believed
sincerely that the cause of making AI safe was too complicated. And if regular people got involved,
the messaging would get diluted and it would go off track and end up causing more harm than good.
So they tried to keep it to very elite groups of people. But this just massively backfired.
Now, I'd like to take a moment and balance out some of these criticisms I'm making of the early
AI safety movement, pointing out that it wasn't all failure. They made some pretty significant
successes, one of which was all the discussions of AI safety, figuring out that there actually was
a problem, identifying what it was and what would need to be done to mitigate it. And that's really
important because that lays the groundwork for the messaging that we're making today. Beyond messaging,
understanding the problem as well as possible is very useful in being able to move quickly into
proposing solutions that actually have a chance of working. My point in talking about the failure
here is not to bash MIRI or effective altruism. It's just that if we're going to be maximally
effective, we need to be honest about the mistakes we've made in the past and learn from them.
Inside game is really important stuff. It just needs to be supported by other things.
So let's take a little bit of a closer look at what actually happens in this category of action.
At the top, we have emailing politicians. This can be done by pretty much anyone. It doesn't take a huge
amount of effort and you can send lots of them. So this is a very top of the funnel sort of task.
If you get lucky, this email may result in actually meeting someone and being able to talk to them
one-on-one directly. This is going to happen less often and it's going to take a lot more preparation
work. You don't have to be super level expertise because just speaking authentically as a citizen
is pretty good. But the more prepared you can be, the better. So if you get to this point where you're
meeting, definitely recommend reaching out on the POSAI server and talking to some other people who've
gone through the process of meeting with politicians before and may be able to help you out, give you
some pointers, give you a chance to practice your pitch. Also, we have a lot of materials available
that you can hand out during the meeting. Now, if you meet with a politician, that's not just this
one-and-done kind of thing. Ideally, that's the beginning of an ongoing relationship that you have
with that politician. And that relationship is the essence of lobbying, where you continue to track
how things are going, give your input on various things. You establish yourself as being a trustworthy
source. That's essentially what a lobbyist is. The goal of this lobbying is to ultimately have
influence on the policymaking process, which actually changes what happens in the world. With each of
these core ideas, inside, outside, organization, I like to think of a core virtue that's associated
with it. To get in the right mindset for the kind of work that's involved. For the inside game, I
contend the core virtue is rationality. This is an area where it's very important to get the details
right. Maybe not so much on the initial email, but certainly as you go down the funnel, it becomes more
and more important to be really accurate on your direction. Because if you tell a politician the wrong
thing, and they believe it, then that might result in legislation that actually makes things worse.
So the more careful you can be, the better. And this involves being mindful of trade-offs, which may
involve having to accept some bad things to prevent other bad things, or give up some good things in
order to get other good things. This also involves recognizing that different people that you can talk
to have more power and influence than others. And if you have to choose who you give priority,
being mindful of these power dynamics and trying to play up as much as possible is part of this moral
calculus that you need when you're playing the inside game. Because ultimately, the focus here
needs to be on what generates the best outcomes, even if it might go against some intuitions that you
have. It's really important to go past ego and preconceived notions and say like what actually is
going to have the biggest and best impact. Moving on to outside game. This again is about mobilizing the
masses. So examples of outside game tactics include protests, local and virtual meetups, being
on the discord community and having conversations with people there, handing out flyers, putting up
posters, and so on. The value of the outside game is this changes the cultural conversation around AI and
also shapes the incentives of politicians. It also gives a lot of power to the people who are focused on the
inside game kind of tactics. So if I go into a meeting with a politician and I'm just some guy who cares
about this thing and no one else does, they're going to be polite and listen and all that. It's like,
okay, this that's an interesting theory you have there and then probably not think a whole lot more
about it. On the other hand, if I'm representing 10,000 of their constituents who are super active on this issue and
will vote for someone depending on how aligned that politician is with their interests, now suddenly
what I have to say becomes a lot more interesting because politicians want to get re-elected.
The danger of focusing too exclusively on outside game tactics is that it can end up being something
like a pyramid scheme where if the only thing that I am doing as an activist is to convince other people
to be activists. And then once I convince them, what am I actually asking them to deal? Well, that's
just to convince other people to be activists and them to convince others. At a certain point, you got
to ask like, what is this all for? Like, what are we actually trying to change? Do we need like everyone
in the world to be in our cause for anything to happen? And also if all this energy doesn't translate
into actual victories that are a little bit more tangible that people can point to and say like,
this is why we were doing all this. We have a win. Eventually all of that growing enthusiasm will
start to fizzle. That sense of growth is only going to go so far. People will start to get impatient and
then they start leaving and then the growth starts to slow down and reverse and then you start losing
energy because there isn't even that growth anymore. Eventually the whole thing fizzles and it didn't
really accomplish anything other than giving people a chance to virtue signal or whatever.
One comically severe failure of this was the Kony 2012, this really big social movement that came
out of nowhere and then quickly fizzled and didn't really have any point to it as far as I remember.
Also, and this one's a little bit more nuanced because it has had some impact on shifting what kinds of
things are acceptable to talk about and broader cultural impacts, but the Occupy Wall Street movement
didn't really have a whole lot of clear legislative wins in the moment and it also definitely fizzled
out. Whatever impacts it may have had, it did not become the sustained organized force that continued
to build over time. We want something that's a little bit more sustainable than that. Digging in to the
process of the outside game, there's a multiple different funnels here and how many of them might divide
them up is actually kind of arbitrary. But on the one hand, in terms of outreach, there's flyering
at the top. Anyone can do this. It gets lots of visibility, but it's not very high level of
engagement. Down a little bit in the funnel would be like setting up a table with some interactive
demonstration and really draw people in, get them to sign up for the website and have extended
conversations. And then both of these can, in addition to just talking about AI, they can also
have a second purpose of advertising a meetup that people can go to, to be in person. And they'll have
some kind of short lecture at the beginning to introduce a topic. Maybe people form into small
groups of like six to eight, have a conversation about something and then share the results of their
conversation with the whole group. And the topics could be like, well, what is the economy going to look
like in a time of mass automation? Something kind of open-ended where people can take a bunch of
different ways. The idea is to get people really thinking about the sort of issues that are relevant
and empower them to actually talk to each other rather than just being passive and going with the flow.
These meetups can then be in a series that builds towards the mission statement that we have and
culminates in a protest where people all get together, hold signs or chant. And this protest
serves as a capstone to the meetups where you have people talking about this thing and they're just
getting more and more engaged. And then eventually that needs an outlet to actually be active and move
around and feel like they're having some kind of impact. The protest does two different things.
One is it gains visibility to the movement as a whole. Maybe there's some reporters that show up,
maybe the people that walk by are like, hey, what's all this about? It gets attention.
The other value of a protest is it builds solidarity among the people who go. So now people,
after attending a protest, it starts to feel a lot more invested in what they're involved in.
And so then they become the next round of volunteers to flyer then table and host meetups and organize
the next round of protests. And again, all of this is to support the strength of the inside game
tactics that are happening in parallel to all of this. In terms of discussion, you can have another
process funnel that goes from just having conversations with friends and family towards
broader reach discussions on social media, where you build up a following and get to more people.
A broader reach than social media would be just the traditional media, getting someone to appear
on news outlets or talk to reporters. And then at the bottom of this funnel, you have someone who
becomes a public figure, someone like Jeff Hinton, who goes around talking to various media outlets and
their name and face gets associated with the movement. Again, this follows the same pattern where
the top levels of the funnel are available to anyone. And then as you go down lower, it's more intensive
and fewer people that are able to be involved with it. I point in all of this, there's a place for
all of these things. It's just a knowing which level of the funnel you're working at and adapting
accordingly. The core virtue of outside game tactics is sociability. The core thing to think about here
when you're trying to bring people in is what are the psychological reasons that people have
for joining a movement like pause AI. We like to think about it being rational. They're convinced
by the arguments, AI is going to become really dangerous, this is the best use of my time,
so I'm going to join it. And maybe some people from effective altruism think like that. But for the
most part, when someone joins something like this, it's for social reasons. It's because maybe their
friends are joining, or maybe there's just a really interesting community and interesting stuff to
talk about on the discord server, or there's just this kind of energy at the protest that they want
to be a part of. And it's really fun to be there. People want to be interconnected. That's a core need.
So when you're designing actions in the outside game category, the social impact and dynamics are
something that should be front and center of a lot of your considerations. A big part of this that I think
about a lot, especially in onboarding is empowering people. After talking to them for a while, you
should be giving them agency, lifting them up, giving them power to try things that they want,
and to have their voice heard. Not obsessing too much about over-optimizing and finding the perfect
process. It's really important to stay human. Because if you don't, like if you take a ends justify the
means kind of mindset, that might work great if you're lobbying. But when it's just talking to
people in community, and you're just using people as things for something else, that requires a
disconnect between what you're saying and what's actually really going on. And that's a level of
secrecy. In just one-off interactions, you might get away with secrecy and nobody notices. But the more
your relationships are ongoing, and the more they're with a community of people that all talk to each other,
the more they'll start to see that disconnect and notice that something isn't quite right or
even catch you in a moment of hypocrisy or lying or anything else like that. Holding on a mask is
going to be impossible the deeper these kind of relationships go. So the only way around it is to
just be genuine and to speak what's actually on your mind. Talk to people as people because eventually
they're going to notice. The last node in the interconnected ecosystem is organization. This is
the behind-the-scenes logistics. So examples of it include maintaining the website, managing the
server, organizing meetups, building teams, onboarding new people, training, fundraising.
The benefit of working in an organizational place is that it connects the inside and outside games together.
It makes sure that the systems that we build are sustainable
and intentionally designs positive feedback loops. The dangers of putting too much effort in
organization in the absence of other things is you could start getting some just ossification
where things just get really static and rigid and not responsive to change, bureaucracy, people seeking
power within the organization. It really needs to be in service of the other things rather than an end
in itself. We look at the process funnel for organization. At the top, volunteering. This is when
there's a very clearly defined task and it just needs people to work on it. Down a little bit further is
onboarding, where you're encouraging other people to volunteer. Next is organizing, where you're creating
and managing the tasks that the volunteers are working on. And then at the bottom of the funnel, there's
leadership, where you're setting the overall goals and direction of the organization as a whole. As with other
things in the funnel, everyone starts at the top and then some people move down to deeper levels if
they're a good fit and they have the time and interest. I think the core virtue of organizers is
humility because a lot of the work in this category is not necessarily glamorous. It's not on the front
lines. You're not super visible. Really, the goal is to lift up other people rather than actually doing
the things yourself. But it's very necessary. Without organizers, everyone else just gets stuck.
It's also very important here to be able to balance different interests against each other to accept
trade-offs and accept outcomes that are good enough. And that requires letting go of a lot of ego
or ideology of what has to be just this way and it needs to be perfect. No, there's different people
who think differently and you need to accommodate a lot of different things. And being able to let go in
that way is ultimately an act of humility. It's also very important as an organizer to be able to listen
and respond to feedback. Don't assume that you have all of the answers. One concept in this idea of
humility in the organizer role that I find very interesting is something called servant leadership.
So we're very used to leadership as being like a boss that orders other people around. Servant leadership
on the surface looks the same. But the rationale and the power is kind of inverted. At a certain
point, it becomes necessary to bring someone in whose job it is is to support everyone to just focus
on the communication aspects to listen to everyone. It's like, oh, hey, you're working on this thing that
this other person's working on the same thing. You should talk to each other and figure this out.
Or to just keep track of all the things that are being done to make sure that nothing's missed.
And then help people work on the things that are the most useful. Expertise is assumed to be primarily
with the people who are actually on the ground working and advancing the interests of the
organization. The organizers are there as support staff to make everything else possible. I'll post
some links for more about what servant leadership actually looks like. Now that I've talked about these
three different aspects. The key point I want to make with all of them is how they fit together. The power
of our organization, it's the how much effort is effectiveness is done on the inside game, multiplied by
the effectiveness of the outside game, multiplied by the effectiveness of the organization. If any of these
are not in place, then the value of the others gets multiplied by zero. And if all of them are in place, but to
varying degrees, then the biggest impact is going to go from strengthening whichever one is weakest.
That's one consideration in terms of where you want to fit yourself in. An even bigger consideration
is just finding what your own personal niche is. What are you good at? And what traits are you most
suited towards? Also have this diagram here of all these various parts and how they inform each other.
Organizers provide rules and unity and a clear sense of mission to the people working on the inside
game. They also provide order and clarity and guidance towards the people working on mass mobilization in
the outside game. Meanwhile, the insiders give the focus and the strategy to the organization and also
typically form the core leadership team of the organizers. They tend to be drawn from this group. And
they provide a sense of purpose and direction to the outside game. The people playing the outside
game and mass mobilizing provide a vitality and community and just raw numbers to filling out a lot
of the work in the organization. And then they also provide power and strength of representation to the
people who are lobbying. They also provide a certain sense of accountability. When you're on the inside
game too long, it's necessary to compromise a lot. It can be easy to forget what you're really there
for. You can start to feel like the compromised view is the point and that the more radical views
are going to destroy your credibility. And there's some truth to that. Like you can't propose something
to a legislator that's totally not feasible in the current political climate. But at the same time,
you need to remember what you're really here for, what the end goal is, and having that the energy
of the more radical conversation shifting people on the outside can help you stay accountable to your
true purpose. So I've been talking a lot about all the various parts and how they fit together, but
remember the original point of this presentation is can we make a difference? Here's where I start to
transition from the how to the why this matters. By hitting all the points of the interconnected system,
rather than having them each inhibited by the lack of the others, they all reinforce each other by their
presence. This makes it possible to say, recruit two people who recruit two other people, and that all
that relies on the people that you bring in actually sticking around, because there's nothing that feels
like this obvious weak point that makes them see like, we don't really have any clear goals,
or there's no popular force behind this, or it's all disorganized, all these things that could cause
people to leave over time. If you address all those, people can feel that and then they want to stick
around and so you can support this kind of exponential growth. Also, the more successful
we're able to be as an organization, without much in the way of fundraising, the more fundraisers can
say this organization is serious, they can do a lot with a little, I'm going to give them some money
so that it can open up options for further success, which could then feed back into more
fundraising. You know, these are just a number of a couple of positive feedback loops that can get
going once everything is in place. Once you have a positive feedback loop, you have an exponential,
and so it can feel like there's not much happening right now. But if you have this 2x growth and
followed by another 2x, 2x, 2x, eventually that can go from very little to just a massive amount in
potentially a very short time, depending on how tight that loop is. The power of this dynamo effect
becomes even more apparent when you imagine what it looks like from the tech lobby or people in power
who just don't want anything to change. If we get this positive feedback loops going, then that puts
them into a bit of a bind. Either they can just ignore us and say nothing, and then we're able to
just keep growing organically through this internal process that we have, or they can start attacking us,
trying to suppress our voice, call us crazy, cultists, whatever other nonsense they have.
And that's a total mistake, because that just gives us free publicity and builds public sympathy.
Now this, of course, is all assuming that we're clearly in the right. The more solid our arguments
are, the more effort we've put into really understanding the situation and the points that
we're advocating, that we're picking the right policies to support, the more people opposing us have to
resort to lies and self-contradictions, the more they have to rely on just obvious ad hominems and
nonsense to go on the attack. And the more they lean into these negative, ridiculous approaches,
the more that's just going to make the attackers seem ridiculous and drive people to us actively,
even faster than we would be able to recruit them ourselves. As an example of this, I think a very
common story for myself and a lot of other people who've joined. I first learned about AI and existential
risk from reading Less Wrong and Eliezer Yudkowsky's writings. My first thought on all this was like,
okay, this is, this is an interesting theory. This is worth a little bit more consideration. I wonder
what the other side has to say about all of this. And then I go searching online and find people who
are opposing a lot of those ideas and just run into nonsense. Like this is things that are totally
hand wavy, not really thought out, clearly contradicting reality, just total straw man's
not paying attention to what they're actually arguing against. And that's the moment where I
really started to become convinced. It wasn't from hearing the arguments. It was came from hearing
the counter arguments that were just terrible. And I think this is a fairly common experience. For that
dynamic to continue, we need to continue being responsive to changes and stay in the right. So if we become
too rigid, too radical or start endorsing bad strategies or policies that are going to cause
a lot of negative side effects or allow for negative dynamics to start showing up in the kind of the
social space such that there become legitimate criticisms, and then we fail to give coherent
responses to those criticisms, then that would cause those criticisms to stick a lot harder and have more
impact both internally in terms of like, oh, wait, maybe this is kind of true. I'm not so sure I want
to be so active. And also on the outside of like, oh, yeah, those those guys are crazy. I don't want
to join them. But as long as we stay on the right side of things and get our organization firmed up as
possible, the better trajectory is going to be. The next concept for theory of impact I want to bring up
is called the whirlwind is this is the idea that eventually there's going to be events that happen
in the world that scare people will shock them or provide some kind of energy that drives them to us
in large numbers, suddenly and unexpectedly. And I think that a popular pushback against AI is inevitable,
because the capabilities are advancing exponentially. AI labs are being just obscenely reckless on the
level of security. There's really nothing to stop any concerted effort from China from advancing their
AI just by copying us. They're reckless in terms of their safety teams walking out and not really
investing in that alignment or that side of things. And they're reckless in not even considering the social
impacts of their technology at all, not even trying on that front. And we can see some growth in pushback
happening now, from artists losing their jobs, from deep fakes making information on the internet less
reliable, scams starting to emerge and affecting more and more people, education being undermined,
students cheating in the education and not learning anything. AI is having impacts right now. And these
impacts are just going to get bigger over time. We've already been getting waves of people who are joining.
who've never heard of existential risk or any of that stuff before, who are joining for other
reasons that are more immediate, and that's going to grow. Our job is to channel the public energy
that's coming from these outside events towards pro-social outcomes, making sure that all the the
popular pushback goes in the direction of policies that actually make things better, rather than just
letting that energy fizzle out. Politicians creating satisficing solutions that just kick the can down
the road to cover up the problems without really dealing with any of the kind of root causes, and
then just keep doing that until it's too late. Or reactionary groups taking things in some other
direction that just makes things worse. There's a lot of ways that the future popular pushback could
not have any impact or make things worse. Our job is to is like carving out a riverbed so that when
the water shows up, it goes to the right place. The idea of things just chugging along in the current
way things are going, in just total business as usual sort of fashion, just does not seem realistic
to me, given how transformative AI is going to be on society, to the extent it already has been.
The outcome is not predetermined. Something's going to happen, but what happens could be good or bad.
That brings us to some of the failure modes, some of the ways that all of this could very reasonably go
wrong. One of them is polarization, AI safety being categorized as a left or a right issue. Once that
happens and starts to get entrenched, then we're going to max out at 50% of people caring about this,
and then the other 50% are just going to be super against it. This is what happened with the
environmentalist movement. Environmentalism used to be a bipartisan issue that both Republicans and
Democrats were equally supportive of, but then various forces, including mistakes,
made by the environmentalist movement, caused that to start to lean a little bit more to the left,
and then they didn't counteract that, and it became more and more associated with the left
until the right was just totally entrenched against it. We can't allow that to happen with AI.
How to prevent that from happening is it's a whole conversation in itself. I'll put a link to
further discussion of that in the description on this video. Another failure mode is timidity,
not respecting the timelines, whether that's from worrying too much about what's acceptable to say,
and not taking the initiative in setting the conversation ourselves. Just not putting in enough
effort would be a failure of timidity. This one would not be an issue if we had 100 years. One
saying I like is there are no impossible tasks, only impossible timelines. We might not have enough time
for the level of ambition that this movement is taking. We just have to rise to the challenge,
and hopefully it's enough. Another failure mode is disorganization. If we don't have enough people
on the inside or the outside or internal organization and there's processes that are not as good as they
could be, that can cause an opportunity to show up and just pass us right by. Another failure mode is
violence either by engaging in violent tactics externally or by social violence internally of
this top-down control, people seeking power, dominating each other, internal schisms. Violence
can be a very tempting thing because when you're trying to accomplish a lot, there's barriers and
say, well, I'll just destroy the barrier that I can get what I want. The problem with violence is it goes
against all the core virtues that I talked about earlier. It's behaving irrational. It destroys
sociability. People don't want to be around each other when there's just anger and destruction around.
That's scary and it hurts. It goes against humility. Actively power-seeking, that goes against servant
leadership. By breaking all these core virtues, it might get some short-term gains, but in the long term
is going to erode the foundations of what the movement relies on to work. One other potential failure
mode is fragmentation. For example, the people working on the inside get all concerned that the
outsiders are making them look bad, too radical or whatever else, and the outsiders are criticizing
the people on the inside that they're compromising too much and they end up fighting each other more
than working towards a common goal. Or if we allow ourselves to get distracted by this ridiculous debate
about whether we should be more concerned about existing harms versus future harms as if these
were somehow mutually exclusive, like I don't understand that at all. If that narrative of it's
one or the other takes the forefront and gets too much attention, that's something that could destroy us.
We're all concerned about the same things. We're all working towards the same goal. That's what matters.
So enough about failure. Let's talk about success. Pause AI is really focused on trying to stop AI
development. One question that can come up is like, okay, you know, so that gets us a little bit more
time. So what? We can't pause forever, right? My main response to that is to think about what is
necessary for a pause to happen. What are the things that have to be in place for a pause to occur?
Achieving those prerequisites are in many ways actually more important than the pause itself.
Let's think about the requirements for a pause. One is that we need international coordination to be
in place. If the United States just stops, for example, and China keeps going ahead, that's obviously
no good. It has to be across the board. And for a pause to happen internationally, there needs to be
international coordination. This means that countries have to talk to each other. They have to
agree to things about monitoring. There needs to be communication channels, mutual discussion of
enforcement mechanisms, ways of actually shutting down AI if there starts to be a problem. This might
look like some form of compute governance or something else. What that international coordination
looks like is an open question. The most obvious answer is some kind of international governance, but it
might look like something more bottom-up and distributed. We shouldn't be too attached to
particular solutions. The problem is what we're focused on. There may be many ways, some that haven't
even been thought of yet, of achieving it. And figuring that stuff out would be a really big deal. And then
actually implementing it is a complex process that we need to start on as soon as possible. One consequence of
this international coordination is overcoming all the barriers to coordination. There are a lot of
concepts around like multipolar traps, prisoner's dilemma, tragedy of the commons, race to the bottom,
arms race. All of these are failures of coordination. Nobody wants an out of control AI that destroys
everything. No one wants an internet that is so filled with fake content that nobody can trust
anything anymore. No one wants a destroyed education system. Nobody wants everyone to be losing their
jobs and have no way of supporting themselves. These are all terrible things. Nobody wants them, but we're
on track towards having them anyways. We're all part of this larger system that's moving in that direction,
and no one has the power to stop it for reasons that no one's individually responsible for, but
everyone is partially responsible for. What that looks like when we're no longer a bunch of individuals
all pursuing our own interests, even though it's destructive to the whole, is a world where there
is a broader care for the full ecology of values and what people care about. It's a world where everyone
has some kind of voice in what happens, so that everyone's interests can be considered rather than
just some people rising up and taking power from everyone else, and then them racing against the
other people who are in power. Having to act as if they're sociopathic, even if they're actually not,
that's the thing that we need to break away from. So then if we have this different paradigm for how
things work, for how we all relate to each other as a global society, you'll think of the implications of
that. In a world where we have succeeded in stopping the reckless advancement of AI, this is a world that
still has technology. It almost certainly still has artificial intelligence in some form. It might even
have some degree of artificial general intelligence. Maybe there's even an artificial super intelligence,
if we can really figure out how to align it in a way that doesn't have a bunch of negative consequences
or destroy all meaning or whatever else. It's hard to know how far that goes,
but there's definitely going to be technology. The difference is that it will be directed towards
actually solving problems without endlessly creating new ones. The consequence of that is being able to
work towards a comprehensively better world rather than just a locally better world that makes other
things worse. That is one path that we can move in. And another path that we can move in is this just
relentless progress towards some form of self-termination or dystopia. Which path we go down is dependent on
choices that are made in potentially in this decade. Timelines might be a little longer than that, but the
time we're in right now is the most important pivotal decade of any time in our past or any time in our
future. This is the most important moment that there will ever be. The actions that you take are
going to be a part of choosing which path we go down. Even if you're just sending out emails or putting up flyers,
that's a small piece of a much, much bigger thing. It's hard to imagine anything we could be doing with our time,
that's more important. So thank you so much for being a part of this.
