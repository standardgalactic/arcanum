Then, when it came to giving a talk, it made me think about some things that transpired
between both of our societies some decades ago.
For example, in 1957, when the Soviet Union launched Sputnik, the world's first man-made
satellite that orbited the Earth successfully.
Back in the USA, everybody freaked out about this.
They didn't like being behind in space and said, oh my god, we've got to catch up.
We have to get a satellite into orbit in 90 days, which seemed crazy.
And it was.
Our first attempt blew up on the launch pad, but the second attempt succeeded.
That was January 31st, 1958.
It was almost 120 days after that initial launch, which is pretty fast by modern standards.
In April 1961, Yuri Gagarin became the first human being to orbit the Earth.
And again, that made news all over the world.
Everybody was very impressed by that.
And back in the United States, people were upset because again, we're behind.
We were behind in what was becoming clear was the space race.
And we didn't like that.
And what were we going to do about it?
So in May 1961, one month after that flight, our president at the time, Kennedy, made a
speech to Congress saying like, look, if we're going to catch up and not be behind forever,
we have to do something big.
We have to commit a lot of money, a lot of resources.
We're going to go to the moon, right?
And that was kind of a crazy idea.
And in 1962, he reiterated this in a famous public speech.
And he said, look, we're going to go to the moon before the decade is over.
And that was crazy.
It was really crazy because we hadn't done anything remotely like that.
But lo and behold, eventually we did.
So Apollo 11 launched on July 16th, 1969, before the decade was over.
And just this year, there's a very good documentary that came out about this whole mission.
What it is, is it's made of all original footage that NASA took during the mission that's been
sitting away in cupboards and closets and they restored the footage and they sort of made
a recreation of what it was like to live through this mission.
And I'm going to play a short excerpt from that documentary just to give you a sense of
what the scale of this whole thing was like.
It's a lot.
And it's crazy.
We went from nothing to all that stuff in something like 12 years.
Before Sputnik flu, we didn't have much of a space program in the United States and in
the end, we had all that stuff.
And then of course, after that, we continued to do space things, right?
We made this space shuttle.
It seemed like a really cool thing.
It's like a ship out of science fiction.
It could like take off and then land again.
That's so great.
Right?
The problem is actually most of it couldn't land like those tanks in the background there.
And therefore, it was very expensive to fly and it was very unreliable.
People died on this on a couple of different missions and we decided to stop using it for
all these reasons.
So after that, if we wanted to put people in orbit, we had to get a ride on the Soyuz.
And then from there, the trajectory of our space program kept going downwards.
And so if you talk to somebody like me sometime around the year 2002 or 2005, we all had this
attitude like, isn't it a shame?
Like the USA used to do all this cool stuff in space.
And now we like don't really do anything.
And the science fiction future that we visualized isn't really going to happen.
And we don't ever see that changing.
And, but what can you do about it?
Oh, well shrug, right?
That was just everybody's attitude.
But not quite everybody, right?
At some point, somebody came along who'd made a bunch of money on a website and said,
Hey, I want to do something about this.
Despite having no rocket experience, I'm going to start a company to launch rockets
and to do bigger stuff than we've ever done before.
And so here's an excerpt of a video about why he did that stuff.
Ben, there's becoming a multi-planet species in spacefaring civilization.
This is not inevitable.
It's very important to appreciate.
This is not inevitable.
The sustainable energy future I think is largely inevitable.
But being spacefaring civilization is definitely not inevitable.
If you look at the progress in space,
in 1969 we were able to send somebody to the moon.
1969.
Then we had the space shuttle.
The space shuttle could only take people to low Earth orbit.
Then the space shuttle retired and the United States could take no one to orbit.
So that's the trend.
The trend is like down to nothing.
This is not...
If you are mistaken when they think that technology just automatically improves,
it does not automatically improve.
It only improves if a lot of people work very hard to make it better.
And actually it will, I think, by itself degrade actually.
You look at great civilizations like ancient Egypt and they were able to make the pyramids.
And they forgot how to do that.
And the Romans, they built these incredible aqueducts.
They forgot how to do it.
So his idea was pretty successful.
And today we're like landing rockets and we're seriously talking about doing another moon mission as soon as the year 2024.
We'll see if that actually happens.
But we're at least talking about it seriously.
And that's a pretty good thing given where we were not long ago.
So Elon talked about a few things from the past that were great achievements that have been lost.
And I wanted to go through a few more of those.
To reiterate his point, that technology automatically degrades.
This thing here that you see is the Lycurgus cup.
This was a relic found and dated back to the Roman Empire, 300 AD.
And it's made of glass.
And this glass that it's made of is the world's earliest known nanomaterial, okay?
The color of the glass changes based on how you look at it, like where the light source is.
So if you're looking at it standing in front of the glass and the light source is sort of over here with you,
so that you're seeing it with reflected light, then the goblet is green.
But if light is passing through it, the goblet is red.
They had this in 300 AD, right?
And then the Roman Empire fell and that knowledge was lost until basically forever.
The way this worked was actually, you know, it got figured out around 1990.
The glass is suffused with very small particles of silver and gold.
By very small, I mean 50 to 70 nanometers, which is so small you would not be able to see them
with a physical microscope.
You would require an electron microscope to see these particles, right?
But at some point the Roman Empire fell and they forgot how to do it.
A lot of craftsmanship went into this.
You could see, you know, how it's hollowed out on the inside where the little guy's body is
to give him more of a purple sheen as opposed to a red in the background.
And if you hear people talk about this today or you read up on this, they tend to have a dismissive attitude toward it.
Like, oh, the stupid Romans didn't understand technology.
They probably didn't even know it was silver and gold that made this happen.
It was probably just an accident and they made like five of these, right?
Which is complete nonsense.
Like anybody who actually builds things as opposed to just writing about them knows you do not get a result this good
without a constant process of iteration and refinement.
You can imagine there was some initial accident.
Like maybe somebody wanted to make glass sparkly and they tried to put silver and gold in it.
And then they noticed a little bit of discoloration and they said, like, why is that there?
And maybe they pursued that.
Like what happens when I change the proportions, right?
How thick should the glass be?
Like engineering results this good takes a long time.
And what that means is that in Rome, people were doing something that we would recognize today as material science.
And then that was lost.
Other stuff happened.
Like in the Byzantine Empire, they had flamethrowers.
And not like little dinky things.
They had giant pressurized vessels in the bellies of ships that shot out a napalm-like substance out of metal tubes
that they would use to incinerate neighboring vessels.
It was napalm-like in the sense that water would not put this fire out, right?
It was a very serious weapon.
It was a state secret of the Byzantine Empire.
They used it to defend Constantinople over and over again for hundreds of years
until one day they couldn't really do that anymore for whatever reason.
And this military secret just faded from knowledge.
Nobody knows how to do it now, right?
Obviously, we've reinvented flamethrowers, but they're different.
This is the Antikythera mechanism, which is named after an island in Greece where this was found on a sunken ship.
It was just a corroded hunk of metal or a number of corroded hunks of metal,
but it was very clear when they were originally discovered that gears were involved.
And over time people analyzed this.
They realized it's a mechanical calendar that was used to say things like, you know, what year is it?
What are the phases of the moon?
Where are the planets going to be right now?
When is the next Olympic Games, right?
And people have run scans on what is left of this and managed to deduce what all the gears were in this mechanism.
And it's very different from what I thought.
When I first heard news about this, I thought like, oh, they must have had some cute little gear things in Greece.
That's surprising.
But let me just show you the scale of the generally agreed upon reconstruction of what this device actually was.
That seems like a lot of gears, right?
But wait.
There's more.
There's more.
That there's more.
That's right.
.
So, ancient Greece had that.
But that is not the picture that we have today of ancient Greece, right?
And the thing to realize is, you don't just get here from nothing.
It's not like one day there weren't any gears, and then the next day some guy makes this, right?
You need a whole process of science to create something that sophisticated.
And we don't know anything about that today, right?
All of that was lost.
And I could go on and on with examples.
There's a whole bunch of things from history that are like this.
But we don't have time.
I just want to restate that right now we live in a very privileged time where technology
has been in a good shape for a long time.
We see it getting better.
And so we imagine that the natural course of history is that technology always improves
and that these moments in history are just like little blips or something that we heard
about.
But they're not just little blips.
It's actually sort of the regular course of world history that great achievements in technology
just get completely lost because the civilizations that made those achievements fell or, you know,
had a sort of a soft fall where they fail to propagate the knowledge into the future, right?
Technology goes backward all the time.
And not just in ancient history.
Also in the modern day, right?
We lose knowledge all the time.
So I'm going to read an excerpt from an interview with Bob Colwell, who was the chief microprocessor
architect at Intel for a while.
But this interview is from before that.
It was from the booming days of Silicon Valley when he worked at a startup called Multiflow.
They were trying to make a very large instruction word processor when that was a new experimental
idea.
And they were having a lot of problems.
Like when you try to design the chip, you're using components from other manufacturers.
And he just couldn't get anything to work reliably.
And he was like, what the hell, right?
So he says, Rich Lethen and I made a pilgrimage down to Texas Instruments in Richardson, Texas.
And we said, as best as we can tell, many of your chips don't work properly.
And does this come as a surprise to you?
I half expected them to say, what?
You're out of your mind.
You've done something wrong.
Come on.
You don't know what you're doing.
Go use somebody else's chips.
But no.
They said, yeah, we know.
Let me see your list.
And they looked at the list and said, well, here's some more that you don't know about.
And by the way, it wasn't just TI.
Their parts were no worse than anybody else's.
Motorola's were no good.
Fairchild's were no good.
They all had this problem.
And so I asked TI, how did the entire industry fall on its face at the same time?
We are killing ourselves trying to work around the shortcomings in your silicon.
And the guy said, the first generation of transistor logic was done by the old graybeard guys who really knew what they were doing.
The new generation was done by kids who are straight out of school who didn't know to ask what the change in packaging would do to inductive spikes.
So when you change the voltage in places on a chip, it generates a magnetic field because that's just what happens.
And when those fields interact across a chip, it's bad.
And the new people designing these chips didn't know to take that seriously.
And that's why technology degrades, or it's at least one reason.
It takes a lot of energy and effort to communicate from generation to generation these important things that you need to know in order to do a competent job making the technology.
And there are losses in that communication process, almost inevitably.
And without this generational transfer of knowledge, civilizations can die because the technology that those civilizations depend on degrades and fails.
So let's talk about a civilization that fell, actually a whole group of civilizations.
The diagrams I'm going to show here are from a lecture you can find on YouTube called 1177 BC, the year civilization collapsed by Eric Klein.
And we're talking about the late Bronze Age, which was the time of a number of civilizations you've heard of, probably like the Egyptians or the Mycenaean Greeks, right?
Or the Hittites, the Babylonians.
And so this civilization or this network of civilizations was sort of spanning Mesopotamia and the Mediterranean Sea.
And they had developed quite a sophisticated network of trade.
So in this graph here, each of these points is one of the civilizations and the lines are, you know, established communication and trade routes between those civilizations.
And whereas not all of them were connected to all of the other ones, they were interconnected enough that you could relatively efficiently route things from one place to another if you needed to.
And that was very important because bronze, which the civilization depended on for things like defense, was hard to make back then.
You had to do it by combining copper and tin.
And copper was relatively hard to find and was found in places like the island of Cyprus.
And tin was also really hard to find and was found very far away from those copper places like in Afghanistan.
And so you somehow had to persistently ship these things around in order to make your bronze and the other things that your society depended on.
And nobody's sure exactly what happened in this collapse.
But people believe there was some kind of environmental stressor to kick it off.
Like there was a huge drought, possibly also some floods are theorized.
And this led to some people attacking some other people.
And, you know, maybe you need to start using your ships for defense instead of trading.
And basically you went from all these flourishing civilizations to a hundred years later, none of them were left.
And by none of them were left, I don't even mean that like the nation states were gone.
Like many of the cities were burned to the ground.
And the languages and cultures don't survive.
Even though they wrote by, you know, pressing things into stone, like nobody was able to translate those languages.
Even today we still can't translate a lot of them.
So like so much knowledge was lost here in this collapse.
We'll get back to it later.
But so I want to bridge this to the modern day in some way.
And my thesis for the rest of this talk is that software is actually in decline right now.
It's in maybe a soft decline that just makes things really inconvenient for us.
But it could lead to a hard decline later on because our civilization depends on software.
We put it everywhere.
All our communication systems are software.
Our vehicles are software.
So, you know, we now have airplanes that kill hundreds of people due to bad software and bad software only, right?
There was no other problem with those airplanes.
Now, I don't think most people would believe me if I say software is in decline.
It sure seems like it's flourishing.
So I have to convince you at least that this is a plausible perspective.
And that's my goal for the rest of this talk.
And what I will say about that is these collapses like we're talking about, that Bronze Age collapse was massive.
Like all these civilizations were destroyed, but it took 100 years.
So if you're at the beginning of that collapse in the first 20 years, you might think, well, things aren't as good as they were 20 years ago, but it's fine.
We're basically the same, right?
But then you keep thinking that, you keep thinking that every 20 years, another couple cities get burned to the ground, and then eventually there's like nothing, right?
Fall of the Roman Empire was about 300 years.
So if you're in the middle of a very slow collapse like that, would you recognize it?
Would you know what it looked like from the inside?
So, of course, I expect the reply to what I'm saying to be, you're crazy, software is doing great.
Look at all these internet companies that are making all this money and changing the way that we live.
You know, and I would say, yes, that is all happening.
But what is really happening is that software has been free riding on hardware.
For the past many decades, we've had amazing advances in hardware technology.
Computers keep getting faster and faster.
It's really one of the greatest accomplishments in human history that we've somehow managed to do that.
And software gets better, in air quotes, because it has better hardware to run on.
That's the main reason.
Software technology itself has not improved in quite a while, I claim, right?
And you can say, but look at all these examples of cool stuff we can do, even in the past couple of years.
So, like AlphaGo was an AI that'll beat human players at Go.
And you can go on, like, Instagram or whatever app and, like, make your face look like somebody else's face.
That's crazy.
We didn't used to be able to do that.
And that's true.
But one, most of these, again, are products of hardware being fast.
Most of these cool things that we do now are due to machine learning algorithms.
And it's, you know, those really are relying on quantity of computation right now to produce impressive results.
It's hard to imagine being able to train AlphaGo 20 years ago on the computers we had at that time, right?
So, it's not a, there are software technology improvements here, right?
Machine learning algorithms have legitimately gotten better.
But there's two things to say about that.
Well, the main thing to say about it, I will say, is just that it's a minority of actual software technology, right?
So, of the volume of things that we run, the thing that runs the machine learning algorithm that produces the actual impressive result is a very small piece of the program.
It's actually really simple once you understand the math, and especially if you don't have to train it, if you just have to use it, right?
And so, when you take an app on your phone like that, that does something funny with your picture, the part of it that does the thing that we think is cool and really value, that piece of software is tremendously simple compared to all the stuff about, like, loading the bitmap for your face or responding to user input events, right?
But that part of the software is huge and complicated and is the part that's kind of falling apart.
So, I would characterize software as having small, local technological improvements, like machine learning, with overall inertia or degradation in the rest of the field.
And we're very impressed by the improvements, though, right?
And let me illustrate the degradation parts as best I can.
And it's to say that we simply don't expect software to work anymore.
And I'm not sure when this happened.
You know, computers always had a reputation for being a little bit funny, but, you know, if you go back many decades ago, it was generally due to, like, not being user-friendly or hard to understand how to use it.
But today, if you're using a program and it does something wrong, you're just like, yeah, it's software, restart it, whatever.
And that didn't used to be.
And if our standards are shrinking over time, how low can they shrink before it becomes unsustainable?
So, I decided to say, you know, I want to quantify or illustrate how much I put up with this from day to day.
So, from now on, I'm just going to take a screenshot every time any piece of software that I use has an obvious bug or, you know, unintuitive or incorrect piece of behavior.
And, well, right when I decided that, I was working on my compiler in the command line.
And the console that I use, after a while, just starts saying, attempt to index a nil value in the prompt because it's written in Lua for some reason.
Then I go to Emacs and I'm working on my code.
And Emacs is set to reload files that have been modified.
And that used to work fine.
But at some point, they broke it so that it reloads the file too early and doesn't get the whole thing and half of it is cut off.
And I have to, like, manually reset that every time it happens.
Then I go to Gmail.
And I'm going to send an email to the rest of the team about some graphics stuff, making decisions about what to do.
And I copy a line of a previous email and paste it into the reply box.
And then I start typing my reply.
And it goes into, like, a three-character-wide column over here because somehow they've managed to reproduce all the kinds of stupid Microsoft Word formatting bugs that everyone was frustrated with in the 90s and 2000s.
Now those are in Gmail.
And I don't know how to fix it.
Like, you fight with it for a while to get it to stop happening.
You have to, like, delete something invisible.
I don't know.
Very annoying.
So then I say, okay, I'm going to get some real programming done.
I go to Visual Studio and I say, I'm going to type in my command line arguments up there.
And as soon as I do that, we get this box that says, hey, collection was modified.
Enumeration option may not, or operation may not execute.
Why?
I don't exactly know.
Why that's a problem.
Like, I'm just telling it a string.
We're not even trying to do anything with the string.
It's just, like, save this for later for when we want to run the program.
But apparently that's too hard, right?
And this is far from the only problem with Visual Studio.
Visual Studio has many, many bugs.
But this is the funniest one because it's so simple what I'm trying to do.
And it can't do it all the time.
I don't know what percentage of the time this happens.
It's probably, like, 5%.
I don't know, 4%.
So then I decided to blow off some Steam and play some games.
So let me download a game on the Epic Store.
But we're unable to start the download for some reason.
So maybe I'll go to Steam because that's a more reliable, longer-lasting store.
And I'm able to actually download a game.
But then when I go to the install window, it's just like a black window.
And I have to restart Steam to play the game.
Then I manage to play the game.
And then I alt-tab out for a second to check something.
And then now full screen is all messed up.
And the game's, like, up in a corner of a window, right?
And then I have to restart the game to get full screen again.
And then I'm watching some Counter-Strike.
There was a really good match between Cloud9 and Luminosity Gaming about a month ago.
And, but for the entire match, there was a mysterious six player on the Cloud9 side called Undefined up in the corner there.
Let me zoom in on that map for you Counter-Strike fans.
It's Undefined is on the left.
A hundred thousand people were watching this match.
And it was there the whole time.
I was thinking about a game I like called Ultima 4.
So I went to this website that had the map.
And the map was, like, screwed up because it was, like, wrapping into extra lines.
So I opened a different browser to see it correctly.
I needed to get a visa to come to the Russian Federation.
So I go to the visa site and I start typing my information.
And maybe I typoed my phone number.
I put the plus one and it didn't like it or something.
So it says phone number is invalid over here.
But I couldn't fix the phone number.
No matter what I put in, it wouldn't accept it.
Because whatever the variable was for phone number is invalid would never get reset.
So I had to, like, stop the application, close the website, like, clear my cookies,
go back and reapply in order to be able to...
And be very careful when I was typing my phone number.
There's just so many of these.
All of this was within a couple days.
Like, I didn't have to try hard to find these, right?
I just had to stop collecting them.
But then I come here and as if to give me more examples in this talk.
So here in this hotel where I've been writing this talk for a couple days,
they have this software-controlled heating and lighting system
where it's like you kind of push the non-button buttons and things happen.
And some percentage of the time, not all the time,
when I turn the air conditioning on or off, the phone rings.
It's not a full ring even.
It's just like a little bloop, bloop, bloop.
And then it stops.
But I know it's not intentional because it doesn't happen every time.
And I am not making this up.
This actually happens in my room right now.
And then for this talk, two hours ago,
I was working at the last minute to make a diagram
and I downloaded fully legitimate, licensed, creative cloud Photoshop to my machine.
The first thing I do is go file new document.
Bam!
The new document extension could not be loaded because of a program error.
Right?
And so my whole point, though, is we are not surprised by any of this.
My other point is that it's getting worse over time.
So try this every day yourself because we've gotten used to it.
I didn't even think it would be as much when I had the idea to record this.
I didn't think it would be as much as it was.
Try counting for yourself just every day.
Just make a little list of all these things.
And I think you'll be surprised how many there are.
I don't know if anyone knows what this phrase means, five nines.
I'm sure a lot of people don't.
This used to be a very common phrase in the 1990s and 2000s
when people wanted to sell you software or a hardware system.
What it means is this system is up and working and available 99.999% of the time.
Right?
Four nines would be 99.99%, whatever.
And we don't use this anymore.
I think in part because the number of nines would be going down
and we can't make it go up again.
And nobody, well, certain parties don't seem to care.
So I was, you know, working on this speech for about the past week
and twice, once when I was asleep on the airplane
and once the other night in the room,
my laptop just rebooted while it was in sleep mode
and just killed all my programs and stuff.
I guess because it was an update.
Maybe it wasn't an update.
Maybe it was just the operating system failing,
but I think it was an update.
So that automatically takes my laptop down to like three nines or less,
less than three nines.
And if the laptop is less than three nines,
nothing running on it could be three or four or five nines.
Right?
So we've even lost the rhetoric of quality that we used to have.
Right?
And so if you say this kind of thing,
that software is buggy,
then people like web programmers or hacker news people or whatever
will say, yeah, we know, but the market won't pay for it.
Right?
Like we could make software better,
but that takes time and money to fix the bugs and all that stuff.
And our client won't pay for it
or the market punishes that because you take longer to get to market.
And that's true to some extent.
I could definitely argue with some parts of it.
But here's the thing that I'm thinking today.
If you haven't seen an entire industry produce robust software for decades,
what makes you think they actually can?
Right?
They're saying we could do it if we wanted to,
but we're just totally not.
But why would I believe that they actually can do it?
Right?
Because like we've said,
there's this generational transmission of knowledge factor
that I don't think is being passed along.
Right?
So I think the knowledge of how to make things less buggy is lost.
And even the knowledge of a technology company has changed.
And again,
this illustrates the difference between software and hardware.
A hardware technology company used to be a place that makes advanced materials
or designs new radar or like does something that you didn't used to be able to do before.
Right?
So now in Silicon Valley and as nearly as I could tell around the world,
a software, quote, tech company is just a company that does stuff with computers
and is then hoping to stumble into a market niche that it can exploit.
And the point is the market niche.
The point isn't the software.
And the point is especially not designing higher tech software
that pushes the threshold of technology forward,
which is what hardware companies always used to do.
And so we've even corrupted the words tech company.
Right?
Okay.
So now I want to bring it a little closer to what we do.
There's been this sequence of abstraction
that we've gone through as programmers over the decades.
Right?
Originally, you had to program your computer in machine language.
Then there was assembly language.
Then we had this sequence of higher level languages
like Fortran and C or C++.
And nowadays we have stuff like C Sharp or Haskell or JavaScript
that are even further away from the machine.
And the justification for this is like,
look, we're working at a higher level of abstraction.
The higher your level of abstraction, the more you work you get done
because you don't have to worry about scheduling machine instructions and stuff.
So we're really being smart and we're saving effort.
And I think that's actually true.
Like, I don't think we want to program things in assembly language.
That's a waste of time.
But somewhere through this chain, it becomes wrong.
And that's how people are wrong a lot of the times, right?
Like, you start out by being right
and then you extrapolate it too far into wrong territory.
But the important thing to all of this is that we only see one side of it.
We see that we're being smart and saving effort
and we don't see the flip side of all of these things,
which is that there's a corresponding loss of capability, right?
Because I don't program an assembly anymore,
I no longer am able to program an assembly, right?
If I don't, you know, if I use languages that are too high level
and I'm a little bit lazy, as people often are,
I don't know where my variables live in memory or what they look like
or even how remotely how big they are, right?
I certainly don't know what the CPU is doing
in response to the code that I've written.
I may be scared to use non-managed languages
because the very idea of memory allocation just seems too hard and scary.
or even if I'm a person who programs in a non-managed language,
maybe I'm afraid of pointers and start generating this cult of being afraid of pointers
and what to do about that like the modern C++ people do, right?
And so the rhetoric that we have is I'm being smart,
I shouldn't have to do the low-level stuff, right?
But part of the reality is the loss of capability that corresponds to those choices.
And both of those things can be true at the same time.
I'm not saying that we're not being smart by going up some, well, a little bit.
I mean, there's a problem, which is that the point of going up all these levels
is supposed to be to make everybody more productive.
But programmers are not more productive now than they used to be.
In fact, it looks to me like productivity per programmer is approaching zero.
And if that's true, then where's the proof that going up this ladder of abstraction
further and further is really helping.
So the way to at least, you know, get a feel for this
is you look at a company like, you know, Twitter or Facebook,
it employs a lot of people.
And you look at their product and you say,
how much does that product change from year to year, right?
How much functionality is added to Twitter year after year?
How much functionality is added to Facebook?
It's not that much, right?
And then just divide by the number of engineers at the company, right?
Which is thousands or tens of thousands sometimes.
That's a very small number when you do that division, right?
It's going to be pretty close to zero.
So what's going on, right?
And to illustrate again the difference in productivity
and that it's not just me that thinks this,
I'm going to show an excerpt from an interview with Ken Thompson,
who is the original author of the Unix operating system.
And he's talking about the time at Bell Laboratories
when he first started making Unix on a computer
that by modern standards had like no software at all, right?
At some point, I realized, without knowing it up until that point,
that I was three weeks from an operating system
with three programs, one a week.
An editor, I needed an editor to write code.
I needed an assembler to turn the code into language I could run.
And I needed a little kernel kind of overlay.
Call it an operating system.
And luckily, right at that moment,
my wife went on a three-week vacation
to take my one-year-old, roughly,
to visit my in-laws, who were in California.
Disappeared all alone,
and one week, one week, one week,
and we had Unix.
Yeah, I think programmers aren't quite as productive these days
as they used to be.
Yeah, he says programmers aren't productive these days like that,
and everybody laughs.
But it's funny, but it's not funny, right?
It's really not funny when you consider
like how much waste there must be
in the difference between how productive people are
and how productive they could be
if everything wasn't so messed up, right?
So I've made a case that robustness of software is declining,
productivity of programmers is declining.
So if you're going to say that actual technology of software
is somehow advancing,
it seems contrary to those two facts, right?
So I think the argument that software is advancing
is clearly false,
except again, maybe in tiny local bubble-like areas.
So now, why is it so bad?
Why is it so hard to write programs?
Why are we so miserable when we try to write programs today?
It's because we're adding too much complication to everything, right?
And I have a way that I think about this called
You Can't Just, right?
Where there's all kinds of things that you used to be able to do
on a computer that you can't do today, right?
So today, you can't just copy a program
from one computer to another and have it work, right?
You need to have an installer
or like a flat pack on Linux
or like containers if you're a server hacker news guy, right?
And so people think this is cool.
Oh, now we have containers.
That's an advantage
or it's an advancement of software technology.
All containers are doing is get us back to the 1960s
when we didn't have to do any of this stuff,
except it's actually not
because it's adding all these steps that you have to do, right?
And things you have to maintain.
So now let's think about for a second,
like why do you need an installer to install software?
Is it because of the CPU?
Not really.
Like imagine you have, well, you know,
imagine you have some X64 machine code
and don't worry about how you got it into a computer's memory,
but you just got it there and you just jumped to it.
You set the program counter to that code.
That code is going to do the same thing on a Windows PC
as it does on a Mac, as it does on a Linux machine,
as it does on an Xbox, as it does on a PlayStation 4, all right?
Because all of those systems use compatible CPUs.
So what's the installer for?
The installer is to get around the incompatibilities
that we added at the OS layer,
which is this immensely complex thing
that we mostly don't want, actually.
And so we tend to think about operating systems
as adding capabilities to a system,
to the system of the hardware and the software,
but they also remove capabilities like compatibility, right?
And it's often very arbitrary
and it doesn't get any worse
than I think it does for us today
when it comes to shading languages.
Anyone who ships 3D engines
is going to know what I'm talking about.
So it used to be that if you wanted to compile
a program for many platforms,
you could write it in some portable language
like C or C++,
and you might have to do some little if defs
to modify it for the different platforms,
but you could do that
and it's mostly the same program.
Today, you can't do that
because we've decided if you're running a shader,
it needs to be in a different programming language
on every single platform,
even if the hardware is the same, right?
So if you have an x86 CPU and an NVIDIA GPU,
then on one OS,
you need to write your shader in metal shading language
and on another OS,
you need to write it in HLSL, right?
And they're different,
even though they're the same.
And so you either have to rewrite everything n times,
where n is large,
or you have to start using auto-translation systems
to rewrite your shaders,
and those come with a lot of complexity
and annoyance and bugs.
And why, though,
a shader is a simpler program
than the old programs that we used to write,
but why have we made it harder
to build a simpler program?
It doesn't make any sense.
We don't care, right?
So the list of things you can't just do.
You can't just copy a program.
You can't just statically link.
You can't just draw pixels to the screen.
Oh, my God,
the number of steps you have to do
to draw a pixel today is crazy.
You can't just write a shader.
You can't just compile a program
on Windows without a manifest and stuff.
And on these new closed platforms,
you can't just run an executable
unless it's signed through this whole process, right?
And all of these things,
and many more that are not on this list,
add friction, bugs, time,
engineering time,
and headspace
that keeps us from thinking about
interesting things to actually do.
A couple of examples of this
that illustrate this isn't going to end anytime soon
have entered my own life.
So one of my side projects is a compiler
and two compile programs.
You need to link them against libraries
on people's machine,
like, for example,
the Windows SDK
and the C runtime library.
And now different versions of things
install those in different places
on the machine,
and so you have to, like,
be able to find them
to do the linking.
And rather than make this easy,
today, Microsoft gives you
a program called VSware,
which you can find on GitHub.
And the job of VSware
is just to tell you
where these libraries are installed.
It is more than 7,000 lines
of source code
in 70 files, okay?
And they didn't even try
to bundle it as a library.
It's a standalone program.
So what they're thinking now is
you can't just make a compiler
that's a standalone program.
It's obviously going to be
a suite of applications.
And once you have
a suite of applications,
what's one more?
What's like a little VSware
hanging out in there, right?
They're not even thinking
that this would be bad.
It's crazy.
I made my own version of this,
based on some other people's work
and got it down to like
500 lines of code,
which is still way too many
to basically ask two questions
that should be two lines of code, right?
It's a multiplier of 250.
And then, also in the
programming language world,
there's this thing called
language server protocol
that is pretty much the worst thing
that I've ever heard of.
And there are just proponents
of this all over.
They're building systems
for this right now
that are going to be living
on your computer tomorrow
or today.
Already, maybe.
And as far as I can tell,
it's basically a more complicated,
slower way to do libraries.
So say you've got an editor
for some programming language
and you want to be able
to do stuff that we've been doing
for decades already,
like look up the declaration
of an identifier by clicking on it
or have tool tips that say,
like, what type is this value, right?
Well, they say the way
you should do that is,
you know, you have your editor
and then it's a hassle
to make plugins.
This is the made-up problem.
It's a hassle to make plugins
for all these different things.
So in order to standardize,
you're going to run a server
on your machine
and then your editor talks
over a socket to the server
and the server talks back
and gives you the answer, right?
Which has now turned
your single program
into a distributed system.
But the flaw in this whole line
of thinking that none
of these people seems
to actually like think about
at all is that there's
nothing special about like
looking up the location
of an identifier in your,
that's just an API
like we have all the time
for everything.
So the obvious next step
if you're saying
that we should architect
our APIs like this
is to do this
for other tasks, right?
So now your editors
or whatever program
is going to be talking
to multiple of these things
and now if you ever
want to author anything
for this,
you now have to author
and debug components
of a distributed system
where a state is not located
in any central place
and we all know
how fun that is, right?
But of course,
libraries are not that simple, right?
Libraries use other libraries.
So what happens at that point
is you're running
all these servers
on your system
and who don't, you know,
some of them are going to like
go down and like
have to restart
and people are synchronizing
with each other.
No, this is a disaster, right?
And people are actively
building this right now.
And meanwhile,
while we're spending
all this time
overcomplicating stuff
that we used to be able
to do in 1960,
in the games industry,
we're not even able
to do the things
that we've needed
to do forever.
So like today,
games can't run consistently
in full screen
as you see from the screenshot
and I don't wish to bag
on that particular game
because we all put
a lot of engineering work
into trying to make
our game run
in full screen.
It's kind of embarrassing.
Like why?
Right?
Also, it's actually impossible
on a PC right now
to render it
a smooth frame rate.
It is simply not possible
no matter what you do.
Alan Latavats
of Croteam
has a talk at GDC
and a paper
about what you actually
would need to do this.
We just don't even
have that capability.
Which is insane, right?
And yet we're spending
all this effort
on other things.
And so this complication
that's introduced
into all of our systems
not only makes our lives
difficult in the present
when we're trying
to build something,
it accelerates
the loss of knowledge
over time, right?
So first of all,
there's more to know
when things are
more complicated.
And so if you talk
about a job spread
among many people,
each individual person
knows a smaller percent
of what they need to do.
They have a less global view
which makes it harder
to do good work, right?
And harder to transmit
their knowledge
onto people in the future.
Another thing that happens
is that deep knowledge
becomes replaced by trivia.
So deep knowledge
might be a general concept
like here's how
cache coherency works
and that enables software
to run fast
on like different processors
and stuff.
And trivia is something like,
well, this sprite in Unity
doesn't display properly
for some reason
but we know we can fix it
if you open this panel
and toggle this Boolean
and that fixes it for a while
but then some weeks later
for random reasons
the Boolean mysteriously untoggles.
So just make sure to check that
before you ship
and it'll be fine, right?
And the reason that's trivial
is not only because
it doesn't apply
to anything else in the world
but it's also going to be
outdated in six months
when the next Unity comes out
and it's just offensive
that we're spending
our brain power
on these things, okay?
And the third thing that happens
is good information
is drowned by noise.
So if something is really hard
to understand
the percentage of people
who put the effort
into understanding it
is going to be small
and the harder it is
the smaller that percentage.
And so if you ask people
or you learn at a school
or you search on the web
your probability
of getting a bad answer
to the problem
is much higher
for more complicated things
than it is for less complicated things.
And so the complication
propagates and magnifies.
So let's get back
to this collapse
of civilization stuff, right?
The more complexity
we put in our system
the less likely we are
to survive a disaster, right?
Because we have to maintain
all that complexity.
We're acting right now
like we believe
that the upper limit
of what we can handle
is infinity amount
of complexity, right?
But I don't think
that makes any sense.
So what's the upper limit?
How would we decide
how much complexity
we can handle?
And that's different
from what people today
actually can handle.
So if you have an engineer
who can hold
a whole system in his head
that's really complicated
and work on it
when that guy quits
and needs to pass on his job
to somebody new
he's not necessarily
going to be able
to communicate all that, right?
So the amount of complexity
we can sustain over time
is less than the amount
of complexity
that individuals can do today, right?
So why am I talking
about this at a games conference, right?
Like everybody knows
that games aren't serious
and whatever, right?
But video games
at least used to be
about maximizing
what the machine could do
and like really impressing
the people playing the game.
And maximizing the machine
means you have to understand
the machine very well
and that correlates
with robust software
because if you understand
the machine well
you're less likely
to make the kind of bugs
that come from misunderstanding.
There's anti-correlations
with robust software too.
But anyway,
now we're not really
about that so much.
Especially talking about
independent developers,
people are shifting
to Unity and Unreal
en masse, right?
Not very many people
write their own engines anymore.
So we have entire generations
of programmers
who have grown up
learning to program
by, you know,
making little C-sharp snippets
that just plug into
other parts of Unity
or something
and they've never written
something systemic
and they've never written
something low-level.
Which on the one hand
is fine.
Like I'm not saying
we shouldn't do that
because there's a degree
to which it's smart.
It reduces development time,
right?
It helps you ship
your game sooner.
But,
like I said before,
there's a flip side.
That flip side is
giving up the capability
of doing the other thing.
Giving up the knowledge
of how to do
the other thing.
So I don't think
it's bad in isolation
if a lot of people
make games
where they just put
snippets into Unity,
right?
But if everybody does that,
then nobody knows
how to do anything
but that.
And then after a while,
what's going to happen?
Because we're assuming
that we'll just be able
to use these engines forever.
But Unity and Unreal
were created
in an environment
where there were
lots of people
at games companies
making engines
all the time,
right?
And that's where
they hired people from.
And when there's
no longer a natural way
to learn how to make engines
because nobody does it,
where are Unity and Unreal
going to hire employees from
to maintain those engines
that everybody's using,
right?
And, you know,
to the extent
that they can hire people,
is the quality of people
going to go down
because they have
less experience?
It just takes a long time
to ramp up, right?
So then maybe
at some point,
well, certainly at some point,
there's not enough people
to make a new competing engine,
but maybe even at some point
you can't really maintain
the old ones
and they just keep decaying
over time.
That can happen.
And so the way
I used to think
about game developers
is kind of like
the foundation
in the Asimov books
where we kind of knew
how to really program computers
and, you know,
also some other kinds
of programmers
like embedded systems people
and high-performance computing people
all sort of knew
what was going on
with computers
and after the rest of software
just kind of decays
and falls apart,
we still have the knowledge
and we could bring it back
and give it to people.
But I'm not really sure
that that's going to happen now
because I just don't know.
I mean,
I don't know
if there will be enough of us
doing low-level work
or even people doing
high-level work
who understand what's happening
at the low level
while they do the high level, right?
So maybe there needs
to be a second foundation.
Spoiler alert
for anyone who hasn't read the book.
So back in the Bronze Age, right?
One of the reasons
those civilizations disappeared
is that the way things were set up
was that reading and writing
was only done
by a small elite class
who went, you know,
went to school for years
and this was protected.
The public couldn't know
how to do this.
They probably mostly
didn't want to know.
And because those skills
weren't widespread,
they were fragile.
So when the society
was disrupted,
they weren't continued
because not enough people
could carry it forward.
Today,
almost nobody knows
what's happening
on a CPU, right?
That skill is not widespread,
so it's fragile.
And so do we think
that this immensely complicated thing
that we've built today
is somehow more robust
than what they had
in the Bronze Age
with just making bronze?
Because that didn't survive.
If that didn't survive,
why do we think
what we're doing now
is going to survive, right?
And we might have
some similar stressors.
We might have
some climate change issues, right?
Or we might have
some new stuff.
Like what happens
if there's so many cyber attacks
that countries just start
cutting each other
off the internet, right?
Now, lots of people
in lots of countries
can't get to stack overflow
to figure out
how to copy and paste
their code.
So their code production
is impacted, right?
Or what happens
if China just says,
you know what?
We're just going to keep
all the CPUs now.
We don't want to sell you any.
What's going to happen, right?
None of these things
in isolation,
I don't think
will bring down civilization,
but it can certainly
hit the system
with a big shock.
And if the system
is too complex,
it may not survive
that shock very well.
And so I'm just trying to say,
like Elon Musk was saying,
the technology by itself
will degrade.
And we need to,
as soon as we can,
start working against this,
right?
At every level
that we have access to.
We have to simplify
the hardware we're running on,
we have to simplify
the operating systems we use,
the libraries we use,
the application code we write,
the communication systems,
we do this over,
like the internet.
We have to simplify
how we compile,
debug, and distribute software,
and we have to simplify
how people interface
with software.
And that sounds like
really a lot of stuff to do,
but the good news
is that all of these things
are so ridiculously complicated
right now
that it's very easy
to find things to improve.
Simplifying any of these systems
only requires the will to do it,
rather than,
and a taste,
you have to have a taste
to recognize
how complicated things are
and how they would be better
if they weren't so complicated.
Okay,
now a lot of people
are probably like,
okay, whatever,
software is complicated,
but I don't believe
civilization is going
to collapse or anything.
And so,
you know,
maybe,
maybe,
but I would say
if you're a programmer,
you should care about this anyway
because even just
your own personal future,
like programmers
are not that happy today.
We're often very grumpy
and the reason we're grumpy
is because we're doing
stupid things all the time
instead of interesting things.
And that's not going to get better
if we keep doing things
the way that we do them,
right?
So you personally
will be happier
if we change the way
we do things.
And if we do things
the way they are now,
maybe the future
is deeply mediocre
in the way that
America's space future
was going to be
deeply mediocre.
Now,
even if you just want to survive
as just an individual
game developer,
like you're thinking,
look,
I just want to get my game done,
I want to ship it,
I want it to succeed financially,
even if you just want to have
a very limited scope
of concern like that,
removing complexity
is still the right
short-term play,
even if it doesn't seem like it.
I'm sure we all
are very familiar
with cases like,
well,
we're going to ship
in five months
and we're having
a lot of problems
with this particular system.
It's really buggy,
you know,
it loses people's work
all the time,
whatever,
but we just have to stick with it
for five months
and it'll be past,
it'll be history
and that's good
because rewriting it
would be a lot of effort,
it might delay shipping
and so we're going to stick with it,
we're going to stick out
the five months
and that's always wrong
because always what happens
is it takes two years
to ship instead of five months
and so the amount
that you suffered
from this system
is way worse
than it otherwise
would have been
and maybe in fact
that system
was a large ingredient
in why it took
so long to ship.
So simplify
and in simplifying
your own code
to solve
your own local problems,
you're also building
institutional knowledge
about how to simplify
which sounds really basic
but I would claim
we don't even really
have that anymore.
Here's some references
of videos you can watch.
If you're interested
in this kind of topic,
Casey Meritori's video
The 30 Million Line Problem,
Sam O'Burja's video
Civilizations,
Institutions,
Knowledge and the Future
and then Eric Klein's video
which I showed
snapshots of earlier,
1177 BC,
the year civilization collapsed
and that's all
I have to say
for now.
Thank you for your time.
Wow.
Very impressive.
Don't you think
that the collapse
will happen
when we reach
the point
of technological singularity
because simplifying
is I think
some kind of
way to prevent it?
You know,
once you start
saying singularity
it's too hard.
The point of singularity
is you can't predict
what's going to happen.
Sure, yeah.
Maybe it'll be bad,
maybe it'll be good.
Yeah,
I don't believe
in singularity
the way a lot of people do.
It doesn't seem
realistic to me
but
as you get close
to that kind
of situation
things move faster
and if things
are moving fast
they break easily.
Okay.
Yeah,
it's what about
foundation by the way,
right?
Yeah.
Well,
and one of the objections
because I'm always
criticizing my own
like what is
the counterpoint
to this
and
what if we just
let software
get really complicated
and then just make
an AI that understands
it
and that's fine
and it's like
okay,
maybe
but you really want
human beings
to not be able
to understand software.
It doesn't seem good.
Okay,
we have about
five,
ten minutes
for questions
so if you have
one
you can ask.
Yeah,
come here
Thank you very much
for this
beautiful speech
and beautiful mind.
Welcome to Russia
by the way.
Thank you.
And I've been doing
games in Game Maker
for 17 years
and we spent
one year
doing 3D
in Game Maker
and I was asking
myself a question
why we did this
and actually
now I know
the answer
and I have
another thought
about it.
Friedrich Nitscher
when he was
already an old
man
he started
to lose
his sight
and he couldn't
write anymore
couldn't think
actually
because he would
think while writing
and so he started
using Hansen's
writing ball
and this was
the first typewriter
to use
but his style
changed
and when I
switched from
Game Maker
to Unreal
I'm
as a game
designer
saw that
my style
my
way of thinking
changed.
Don't you think
that tools
they somehow
force us
to think
in a certain
type of way
and for you
making a new
language
is
somehow
to break
through this
and start
thinking
wider
broader
I think
I would agree
with that
and I would
also say
though
because we
think
with tools
often
unnecessary
complications
or bugs
in the tools
interfere
with the thought
process
like you're
in flow
you're doing
stuff
and then
something bad
happens
and you're
like
now I have
to go
fix this
thing
and you
can't
do what
you were
doing
so
I definitely
think that's
important
you know
when I'm
making my
new language
I'm
trying as best
I can
to get rid
of all
these
complications
that don't
make sense
but there's
so many
of them
and some
of them
are baked
into our
assumptions
because
you know
I learned
to program
by using
these complicated
systems
so what
I see
as simpler
may be
very far
from the
actual
simplicity
that we
could achieve
because my
thinking
has been
trained
on those
tools
so we'll
see
we'll see
how it
comes out
thank you
thank you
thank you
hi
so let's
say I'm
an indie
developer
and I'm
sold
on your
ideas
I don't
like
unity
either
and I
want to
put
pixels
on screen
with
great ease
but I'm
not yet
ready to
write
my own
engine
as you
do
well you
you would
have to
write
your own
operating
system
to put
pixels
on the
screen
so
what's
what is
the
set
of
currently
existing
tools
I can
use
or
like
well I
don't
know
because
part of
the
problem
is
everything
is
this
way
so
really
what
needs
to
happen
is
not
about
specific
tools
that
you
use
it's
about
developing
the
aesthetics
for
things
that
are
not
a
giant
horrible
mess
and
whatever
tool
looks
like
that
to
you
just
use
that
instead
of
whatever
you're
using
and
then
maybe
we
could
migrate
everybody
slowly
over
time
yeah
yeah
the
problem
is
when
I
look
for
ways
to
like
get
to
the
lower
level
things
I
find
this
like
visual
studio
and
C++
and
it
doesn't
like
help
very
much
it's
super
complex
and
it
breaks
every
time
and
whatever
yeah
I don't
know
man
thank you
very much
for your
talk
my
question
is
in
1968
30
years
after
the
concept
of
the
computer
was
invented
Edgar
Dijkstra
said
that
program
where
the
main
frames
were
having
2 megabytes
of
memory
even
then
Edgar
Dijkstra
said
that
programming
is
just
too hard
by its
concept
to be
done
by
human
beings
are
you
sure
that
simplification
will
help
to
any
extent
well
it'll
help
whether
it
makes
them
completely
understandable
by
us
I don't
know
I mean
I think
I think
you could
I haven't
read the
Dijkstra
piece
that you're
talking
about
humble
programmer
okay
I think
I think
you could
rate it
by what
problem
are you
trying
to
solve
right
and
how
complicated
like
there's
an inherent
complexity
to a
problem
first of
all
and so
there may
be
problems
that are
so
complicated
it may
be
hard
to
understand
what
the
software
looks
like
to
solve
that
but
then
there's
also
added
complication
because
we're
solving
this
with
existing
systems
and
those
systems
already
prevent
us
from
doing
doing
certain
things
and
so
there's
a
difference
between
ideal
complexity
and
actual
complexity
and
I
just
want
to
get
closer
to
ideal
complexity
whether
that's
good
enough
I
don't
know
Thank you
very much
