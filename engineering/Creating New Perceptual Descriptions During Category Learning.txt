thanks it's it's wonderful to be here um and i have to say marina was a star pupil
at this windsurfing academy um she swam rather than sank passing so many spheres of of her
successes um i want to do a initial call out to eric weitnauer and helga ritter uh my partners
in crime for everything i'm going to be talking about uh this work that i'll be talking about
was the basis for eric's um phd back um i don't know maybe 10 12 years ago from university of
bielefeld in germany um i was an external member of his committee and since then he did a postdoc
at indiana university and he is now the ceo of a educational technology company in bloomington
called graspable math which is involved in applying some principles of embodied and
grounded cognition to improving algebraic mathematics in middle school and high school students
and there's a definite connection between what i'll be talking about and that work which maybe
we can talk about at the end um the other prefatory remarks i should be mentioning um here's a
anticipatory bongard problem um and i don't really know what uh is the difference between the scenes on
the left and the scenes on the right but i know that i i like the scenes on the right um i'm a huge fan
of everything that you guys have have done over the last many decades um i always find it incredibly
rejuvenating both intellectually and spiritually to to come to uh the institute here um and i just find
it an inspiration um that there's so many people here who are deeply passionate about uh what they're doing
and they're deeply passionate about uh instructing other people and sharing other people's deep passions
so yeah it's super exciting as always to be here um so i'd like to um introduce my problem as uh talking
about the bi-directional relations between our perceptual system and our conceptual system it's
relatively unobjectionable that um the concepts that we have are going to be based upon our perceptions
right so we combine together information about uh hearing a dog barking seeing that it has a tail
uh seeing that it has a tongue um feeling its fur these are all perceptual properties that we join
together to get an idea of of what a dog is um but i would like to argue that there's also this reciprocal
influence of our concepts on our perceptual skills the perceptual descriptions that we give of our world
and it would be easier if that were not true and many models in cognitive science um assume that it's
not true and rather than just um you know talking about people like doug medin and the audience and
brad love um i i'm just as guilty of this as most researchers in the field of concept learning many
models treat perception as separate from and completed before uh the processes that are going to be involved
in representing and using concepts there's many models out there that give featural encodings
of the objects ones and zeros sometimes sometimes they're vectors sometimes they're points in a high
dimensional multi-dimensional space but the idea for almost all models that i know of concept learning
is that you start with these representations and then you'll do some operations on these pre-existing
representations in order to form your concepts um it would be great if that were true but it it's not
that simple i'm going back to an example from doug medin um sitting over there next to marina um here's
a case where people are asked to to compare those two objects people will frequently list a commonality
between them that both of them have three prongs right uh they might go on to say that for the object
in the middle and that prong is a little warped or maybe stunted right uh but if you ask them to say
what are the properties that those two objects have in common they will very frequently say uh they both
have four prongs right so they're giving mutually exclusive descriptions of that middle object depending
upon whether it's going to be compared and contrasted to the object on the left or the object on the right
and that's going to be a bit of uh i don't know an embarrassment if you want to say that there's a static
representation going into the game for that middle object it seems like the process of comparison is
what is giving the object its description um so i believe that a crucial part of people's intelligence
comes in coming up with useful concepts is building new descriptions so um there is a long history of
this an artificial intelligence going back to the constructive induction movement maybe associated
with risard mikowski other people and it seems like that's exactly doing what i'm interested in doing
because it does create new descriptions unfortunately the descriptions it creates are rather trivial so a lot
of this old work if you started with descriptions of objects as having like a shape circle or a square
and a color black or white um then they would create new features but these new features were things like
black and square or white or circle right so they're just these kind of boring boolean concatenations
of existing descriptions that were created um in contrast to that we do have modern deep learning systems
and for now i'm considering systems like convolutional neural networks they do create internal representations
to support categories but they often require a large amount of training so if you're going to need
flexible in the moment re-description of objects they're not going to be very useful now there are
systems that are like foundational models like llms that do this and i'll return to them maybe if you ask me
at the end um so for real people it turns out that uh building perceptual descriptions for entities
occurs while concepts are being built um and a huge influence for me growing up was melanie mitchell
um and her copycat uh project this is very much along the lines of what we're going to be talking
about and you'll see many uh representational and architectural similarities to to melanie's work
with letter strings and copycat um and there's examples from marina's own work with learned
categorical perception that our ability to make subtle perceptual discriminations is going to be affected
by the the categories that we're learning um okay so that's sort of a preamble here's the um domain that
we're going to be looking at these kind of situations in um bongard problems for me my first exposure to
bongard problems was through my collaborator and colleague at indiana university doug hofstadter
and he presented many of these in gerda lesher bach they're called bongard problems because
there's some russian ai researcher from the 1970s called bachail bongard and he developed this he
didn't have a system that would solve them uh but he posed the problem so you're trying your task here
is to try to find a rule that will discriminate the scenes the six scenes on the left from the six scenes
on the right um anybody want to bravely make a suggestion for what that could be
oh very good so the left side contains small objects the right side does not contain small objects
okay that was a bongard problem um arguably does not involve the creation of new featural descriptions
that was probably in marina's lexicon of things that she was sort of coming into the game already
primed to try to test out okay here's another one um some non-marina person just to
beautiful nicely put black object is triangle on the left side black object is circle on the right side
this is well within the world of constructive inductions and concatenating boolean expressions
like ands out of maybe an existing set of descriptors um now we're getting a little bit more challenging
more harder problems um i just made this one so uh llms probably won't have access to it until tomorrow
um so again you're trying to find what is common to the scenes on the left versus scenes on the the right
yeah george
up on the right the ends are in the same direction
brilliant yeah so on the right side the two end points are in the same direction like they're both
facing up for this and they're both facing down for this whereas on the left side they're facing in
opposite directions excellent okay one final um hard one and this comes to us courtesy of doug hofstadter
doug has a list of a hundred or more extra bongard problems to be added to michael
bongard set of 100 problems and um there's if you're interested there's a whole website that just
has people proposing bongard problems you can add your bongard problem and you can solve other people's
bongard problems um and so this is um problem number 103 from hofstadter's set of problems um and i'm
giving it because it's hard but also because it makes an important point that sometimes to solve
these problems you have to impose additional uh features impose additional structures other than
the ones that you see um okay so have i stalled long enough for somebody to get the answer here
yeah
did you have an exception in in your rule well so like so the ball is like on the right
here but here i'd say it's on the left um so that would be considered unappealing to have exceptions
possibly but you could you could have a long horn clause i guess yeah um anybody else okay so this i did
not solve this one either so this is the addition of information that might provide uh some clue i mean
this is you know there's nothing magic there i mean so that's they're just finishing the triangles that
that are that are created here
doug what i heard somebody say oh
oh yes very good yeah excellent so the left side our isosceles triangle um two of the sides not always the
two dashed lines um but two of the lines somehow are going to be the same length for the ones on the
left on the left on the right they're all different lengths excellent yeah if i had a star i would
give it to you um and now you might think of this as um you know just the bastion of sort of narrow-minded
nerds um but i would encourage us to think of this as a good analogy to what some of the the biggest
thinking nerds in science also do so i feel like when john snow back in 1854 uh realized that there
was this pattern of people developing cholera based upon their proximity to a particular water pump
station in london that was creating a new description that wasn't in the original description of the cases
that he was given right or even more amazing uh james maxwell back around the same time around the
same place uh was developing kinetic molecular theory where he ends up postulating that there's these tiny
invisible billiard ball like things that are bumping into each other and giving rise to these macroscopic
properties like pressure and they're systematically related to other properties like the the volume and
the number of molecules and the temperature right so amazing to create this new description of these
invisible entities right so i feel like this is core to what scientists do the final thing that i will
throw out here for the kinds of bangard problems that we are focusing on are which we call physical
bangard problems and in physical bangard problems um the idea is that in order to solve them you have to
imagine that the scene is a two-dimensional scene where normal forces of physics apply to the objects
like you have collisions like you have gravity like you have support relations and those turn out to
be important in order to solve the problems um do we have a solution for this one how did you see the
solution what do you think um this is wrong but i'm going to say when the gravity applies on the left
the objects are all touching each other perfect yep so they're going to be end touching for the the things
up on the left and on the right side the objects do not end up touching brilliant so um this is um an
interesting case for us for a couple of reasons one is i think it makes it very clear that the
descriptions are not in the scene to begin with you have to apply something like a physics simulator in
order to get the right scene description um they also make the point that it would be um impractical
computationally speaking to think about applying all possible descriptors to these scenes to begin with
part of the process of solving the problem is to consider noticing things to um uh look at
the objects in new ways than you had seen before and it also fits in with a major interest in cognitive
science in in thinking about how people create possibly incorrect but somewhat correct uh virtual
physical physics engines that they interrogate internally in order to make predictions about
the external world okay so um for us a big part of the computer simulation that um we're developing which
is called paths uh which stands for something um is that there's going to be context dependent perceptual
descriptions being developed and the kind of context dependencies that we're going to be focusing on
are things like context dependent shifts in what is going to count for calling an object big or close or
next to or supporting or next to or supporting or above we use um irene block's fuzzy logic for uh determining spatial
relations and just to give you some idea for how that works we're imagining you have like this landmark
object and um that this or this big long rectangle let me let me see if i can draw on the screen
so this rectangle at the bottom is the the landmark object and if we want to figure out what is left we
imagine like all the pixels of this object and we imagine what would be left of each of these pixels
and for that pixel on the end that would count as what would be to the left of it and you can calculate
those for left and right and above below and it turns out that um if you do like a
um a contrast between opposing spatial relations you get a much better idea of what the relations are
so like you don't want to think of this object a as being uh left of the u-shaped object and the
way that you can get that is by subtracting the left of space from the right of space
so you're only left with uh this area over here so okay so that's uh one kind of detail by the way i'm
going to be sort of picking out some details and ignoring all kinds of details to try to fit this into
45 minutes or so but so there's going to be an inherent fuzzy logic to our determination of spatial
relations and one of the kinds of context sensitivity is to say well you know does this count as an area
that is to the left of the u and the answer is maybe maybe yes maybe no depending upon where your
threshold is so where the rubber hits the road for a bongard problem so i'll i'll just tell you what the
answer is here for the left side the triangle is above the rectangle for the right side the triangle is to
the right of the rectangle and um you'll see this display um by paths and by humans is going to be
unambiguously or very reliably uh interpreted as the triangle being above the rectangle okay but if
we had moved that frame over to the right side then it would be also a hundred percent of the time
interpreted as right of for the computational model as well as humans now you can't it would violate a
bongard problem if it was on both sides simultaneously then i would say it's unsolvable right uh but
you're you have a flexibility in all of your application of both predicates and and spatial
relations so that's one kind of context dependency another kind of dependency is this maybe the most
important one is that descriptions that are frequently given for scenes in a category like on the left side
say they will tend to be tested on other scenes from the same category so once you begin to notice
a touching relation on the upper left scene then you're going to begin to try to notice it on other
scenes and that's super important i believe for the scientific practice in general final point is the
immediate temporal and spatial context matters so you will uh tend to attend similarities for two adjacent
scenes if they come from the same category and you will tend to attend to two adjacent scenes differences
if they belong in different categories but in other words if these two things belong in different
categories then you're going to be paying attention mostly to what is different between them and if
they belong in the same category then you're going to maybe develop an idea of what characterizes that
category if you pay attention to their similarities um okay so yeah so this is the overall high level
loop of this paths algorithm and these are percentages with which it does each of these kinds of cognitive
actions and one of those cognitive actions is to perceive a new feature on the target you can
stochastically select a target scene and a target object within that scene and a kind of feature for it but
importantly this is where it's not all pre-computed but these are things that you're going to be
noticing as the c s the problem solving unfolds this is also what is going to be involved with the
physics engine so one of the things that you can use to create new features is a simulation in your
mind's eye of what will happen if you let the objects go we also have creating new hypotheses which is
going to be taking a feature that you select and applying it to a particular object and applying
a quantifier so we're in the world of first order predicate logic where we have three quantifiers
we have exist existential there exists we have a universal quantifier all and we also have a unique
quantifier exactly one uh so that's all one kind of thing you can do another kind of thing you can do
is check your hypothesis that you've developed on the existing scene or you can check it on the other
scenes that you're going to be pairing it with and this idea of pairing is going to be important but
let me hold on to that until we see the simulation in in action and the final thing that you can do is
you can recursively combine hypotheses to create larger hypotheses you can adjust a relation that's
changing the thresholds for example or you can be combining features together you can combine them
together with booleans or you can recursively nest hypotheses um okay so that's what's happening i think
this would be a good time for for the demo
oh we have a question yeah um is this all
we cannot solve our system does not solve all bongard problems for sure like can you
if you give unambiguance or create a same number of themes but you don't separate them you just mix
them up right and then you're trying to because that's more like what like a cholera example is
right you don't have a boundary or a boundary that's given to you like i know this kind of
difference in some ways i'm trying to figure it out it's often in many things you're like you have a bunch of
things and the like formation of the categories in the first place yeah so i so um this would be what
we will call um supervised concept learning where you know what the right concepts are um but i would
treat the cholera example as an example of supervised concept learning because you know that these people
got cholera these people didn't so there's something in the world that's giving you that those categories
so yeah
okay so um just to orient you what's going on these are the bongard problems um you can see the the
physics engine oh i didn't know go that way um so you can so this is uh part of what is in the system
is something like a a simple physics engine so it can execute that and i think we're using
box 2d if you want um if we uh run the algorithm so this is a pretty easy problem for it um and it
ends up saying only in the right scenes are all of the objects stable that's how i would read it
probably in in english um and it could be coming up with different results if we run it it's uh so
here it decided to talk about the left scene and only in the left scene does there exist unstable objects
and here we're seeing all of the hypotheses that it is entertaining in this hypothesis window and we have
this the features these are the the built in visual routines that uh paths is built to to try to notice
and behind each one of these boxes for far and topmost there's you could think of there being a bit of
javascript code which is going to be computing each of those um so this is an easy problem let me try to do
one that's a little bit more challenging um all right we'll we'll run through just a couple of these so
it eventually gets the idea that only in the right scenes do there exist parentheses objects that are
above bottom objects at the end and where you see these parentheses that's what i'm talking about the
the recursive generation using this grammar for combining together hypotheses to create um larger
hypotheses um and is it correct yeah i guess it's correct um you could say that this is over
particularized that it didn't have to say bottom objects at the end it could have just said objects at
the end um so that's not uncommon paths i would say that um it tends to be a little bit more narrow-minded
over particularistic than than humans are i feel like for humans there's another stage at the end
where they look at the rule and they would say no i can simplify that um so this is uh uh anything else i
want to point out here um well you could see it oh okay maybe one of the things to point out is you can
see that it's going through in this case it's going through a set order of comparisons did you see how
it was always comparing pairs of scenes in this case it's always pairing scenes that belong in different
categories uh with the idea of looking for contrasts looking for the single like difference between
uh two scenes that are otherwise very similar to each other because it says if i can identify
scenes that are similar to each other and see what's different then i'll probably have a pretty
good idea of what is going to be involved in the rule yeah with um allowing it allowing it to only
check certain numbers of hypothesis at a time like we'll figure that out uh so like you can do three
hypotheses check it at a time and you have to you know pop in another thing yeah yeah so yeah so the
way this is built it's only looking at one hypothesis at a time so it can it can go to this list of
hypotheses that it's already developed in order to develop larger hypotheses but it it in some ways
it's extremely inefficient in that if it was looking at the scenes with respect to one hypothesis and that
hypothesis is wrong um it kind of has to start over it has to either create a new hypothesis or join
together other hypotheses um and it's not very much like i don't know logistic regression or many neural
networks but um it does fit some of what we believe we know about concept learning that there seems
humans are very inefficient about um sort of retaining all of the the scene information or the situational
information in their mind um it seems to be very much more perspective based right but that
but it is a it's a weakness of the model if you're thinking about it from a perspective of
efficiency but a strength if you're thinking of it as a cognitive model yeah um let me take
one other example maybe so there's all kinds of problems um so we also make this all available
online so you can try these out yourself you can try tweaking with parameters of the model most
importantly you can put in your own svgs so you can put in your own images and see whether it can
solve your problem um will you be able to stump it yeah so um so pat i mean i don't want to oversell
pat says as an amazing vanguard problem um it's it's not too hard to to get it to fail um but we're
putting it out there in the spirit of reproducible research and so that other people will improve
upon the algorithm and you know add in their own visual routines uh yeah so all right so that enough
apology um all right so for this one it ends up with only in the left scene does there exist objects
that are colliding with small objects again if i were doing this myself i would have left off the
small objects there's sometimes i would do it um like in the example that you solved i think it felt
like there was such a regularity that it would be good to mention the black and the circleness um but
if we ran it again yeah that's a better solution so it's stochastic this time it says in the left scene
there exists objects that hit any objects i like that answer better so okay so that's what the game
is for this um a little bit um just sort of picking some things to talk about so i'm trying to get at the
idea here that i think this feels different to me than constructive induction sort of what i will call
trivial concatenations of boolean operators um and so here's how it gets at the idea of stability for
paths stability basically involves uh having a starting configuration that is randomly jittered
so it imagines adding a little bit of noise to these scenes and seeing what changes how much do the objects
move uh does the end state change and this is a graded concept so you can imagine things being
differing degrees of stable so this is rather stable here um this is rather unstable over here um and this
the other one is sort of pretty unstable as well but not as unstable as as that square exactly poised on
the tipi um here's how it understands the idea of supporting or one way it can understand supporting
this is you know back in the cognitive linguistics of your you could think of this as procedural
semantics so you're needing to develop a procedure in order to understand the the meaning of ideas like
support so what it means for x to support y is that if x were removed would wise and state change
again a graded notion because you could say well c isn't really supporting um b
as long as there's no noise but if there's a little bit of noise then i guess there is a sense in which
c is supporting b right so these things are are a little bit fuzzy here's the idea of free and stuck
which is important for some of the bongar problems so uh this ball here is free to move free to move
this object is stuck and the way that paths ends up thinking about this is kind of like if you imagined
a fragile string that was attached to the circle could it be moved in a particular direction without
touching another object and so that's why these simulations are important and they are doing a
little bit of what melanie has talked about by way of what she says bridging the semantic gap from these
things that you can register perceptually and these things that have like linguistic grounding
um okay these are some of the um uh ideas that we have in in the system we have routines for
calculating collisions and falling offs and constructions importantly uh these uh roles and selectors
for selecting different objects to pay attention to uh we have like in melanie's work with copycat
the important idea of groups so you can imagine a entire group of objects and you can apply
hypotheses to that entire group they could be based upon all in one spatial location but it could be
any feature it could be because they're all squares or they're all white okay so um these and i just truth
and advertising again we're building these uh visual routine operators into paths now could this be
extensible great question i'll leave that till later um so overall um here's the correlation um in solution
difficulty for this path system and humans so we give humans these same kind of problems and we
measure the human difficulty score which is going to be a combination of how long it takes them to
get to the solution and whether they can get to the solution and on the x-axis we have how difficult
it was for paths past doesn't always solve these problems and it also takes a different number of
steps to to solve the problems um so the there's a decent correlation between them it would be a lot better
without problem 31 we can just ignore that one um if you if you want to know but people want to
know the failure cases right so this is one where the the model is is um bad the model is worse than
humans so people don't have trouble uh seeing that the circle is free to escape on the left scenes and it's
not free to escape on the right scenes that is something that's sort of intuitively natural for
people but it's not for paths could we fix it we can cheat we can get it so it can solve it better
but at the risk of solving other problems more slowly so those are kind of decisions you make
you can just look at the solution times uh that's an even better correlation um how we're thinking
about educational applications of this um by way of like changing just the the spatial ordering of
problems so this is this is a busy slide um these are the same bongard problems um and the solution
looks like it's um on the left side the a side those are kind of hard to call they're um ambiguous
whereas the the right side scenes they're pretty unambiguous what's going to happen and that's the
problem and this is something that paths gets to this idea of ambiguity just by running the simulations
multiple times with multiple amounts of noise or jitter um so um i guess i've shown you the
empirical results here already the easy so this is the exact same um 16 frames in each of these
problems all we're doing is changing the positioning of the frames and this is the easiest uh way of
presenting this problem where um there's a natural tendency for people to compare things that are in
the same position like the upper left hand and upper left hand and if those are similar and they
belong in different categories that helps people it helps paths a lot um and the other thing that helps
is the fact that these two problems which are spatially adjacent to each other but belong in the same
category they're um very dissimilar to each other and the fact that they're dissimilar to each other helps
because it stops people from false alarming on wrong descriptions so the heart here's a hard one
so this is hard because there's all kinds of similarities between these two
objects and you might say oh i guess it has to do with whether it's a quadrilateral or something like
that and you'd be wrong um and the other thing that makes it hard is the fact that these two
two scenes are very similar are very dissimilar to each other so those so this is um
there's humans on the left and paths model on the right and um you can see both of these effects um
i won't make you interpret the bar graph unless you like to what what it's showing is that descriptions are
best inferred when dissimilar scenes are from the same category similar scenes are from different
categories that are presented together yeah a very simple question would i ask before how
have you changed the number of vertical panels and how much does that impact the fact it would seem
like that you know you just do two that's actually even in the harvest is much easier than that before
there and maybe if you had six or eight it would be that's a great question yeah no i'm i'm interested
in that we haven't manipulated that the only thing that we've done is manipulated um whether you're
influencing the adjacency either temporarily or spatially sometimes you like present two scenes
that belong in the different categories um that are very dissimilar on success set successive frames
or trials right so that's what we've done but yeah different spatial arrangements would be
be pretty interesting to to mess with yeah i like it um okay i think i'm pretty much done um here let me
just uh wrap up by saying what i think are um some of the core commitments uh that this paths model is
making and this one at the top is is maybe in some ways the big one that scene descriptions must
continually be created while concept rules are being constructed again maybe this seems intuitive but
it's amazing to me i don't know maybe doug will tell you what he thinks but it's amazing to me that
that this is not a major part of modern concept learning models in cognitive psychology as i i know it
we talked about the three different ways in which context is influencing the descriptions
the important point that new descriptions are coming from like the your perceptual systems
from simulations and not just due to recombination and that's an important component of some work that
i'm doing with doug hofstadter and francisco lara damer and that's different i think from
um uh constructive induction so i'm so i've been talking about visual routines and to me the the
classic reference to this is shimon allman allman the senior
um um and he was talking about uh grounded ways of understanding how people can uh reason about things in a
uh sophisticated way for us we're interested in these visual routines for you know detecting spatial
relations but also more semantic features like support and stability uh we do believe
unlike convolutional neural networks for example uh that these explicit rules should be composed into
these recursive grammars and under this view concept formation should be viewed as an open-ended search
of compositions of continually crafted descriptions
compositions okay i think this is a good stopping point thanks for your attention
