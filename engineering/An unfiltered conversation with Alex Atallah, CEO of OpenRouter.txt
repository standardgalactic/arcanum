and this was the first local model i ever used that i was like wow clearly we can actually get
within shooting distance of the closed models and there is a way for indie developers to look like
a company spending a hundred million dollars trading a model but with way less money and with
just one computer you know you're not really showing what the best model is but more so like
what model has the most traction how representative do you think some of those numbers are we've
experimented with a couple different complicated ways of ranking models so we figured to start with
we would just do raw tokens in and tokens out and that has a big con
alex do you want to take us back um and i'm curious what the what the inspiration was to start open
router sort of what the conviction was what was happening at the moment when you when you decided
to to create the project yeah so it started back in february or march when i was thinking about
uh llama had just come out and this was the first time we were kind of getting exposure to local
models this was llama one and it was surprising how like useful it was though it wasn't really like
a great chat bot and it wasn't reliable for knowledge retrieval but it it there was something there
that was worth exploring and i couldn't i didn't quite know what it was so um first project was
that i started was a chrome extension very much following the pattern of like my current paradigm and
and seeing like what about ai um could benefit from it my current paradigm was crypto because i
was wrapping up my time at openc um i was the co-founder and cto still on the board but i like
um i figured i was i wanted to look for something zero to one again and try to explore the ai space and
figure out what sort of interesting intersections would appear so i worked on a project similar to a
web3 wallet but for bringing language models to the browser and it was a standard for front-end
developers to just build api and model agnostic apps and that was the experiment and what became
clear is that there weren't that many closed models at the time it was really just like gbt3 gbt4 had
just come out and cohere and uh and there were a few open source models that were really tough to use
and then llama came out and after llama uh a group a research group took llama and generated a bunch of
synthetic data and then uh fine-tuned llama on that data and spent about six hundred dollars in the whole
process this was a group at stanford and they created alpaca and this was the first local model i ever used
that i was like wow this is this is huge this is something i like clearly we can actually get
within shooting distance uh of the closed models and there is a way for like indie developers to look
like a company spending a hundred million dollars trading a model but with way less money and with
just one computer and i thought that was huge it meant that maybe we'd have a world with thousands or
tens of thousands or hundreds of thousands of models and another takeaway from this is that
the data becomes more of the moat and data becomes like a more critical part of what makes a new model
unique and a new model useful where a closed or centralized model wouldn't be as good you know even
if a new model is just not as smart even if we have like you know take a person who's not as smart as
somebody else but that one person just knows a whole bunch of stuff they just have all of these
secrets locked in them um they've been exposed to like they know how something works the the smart
person's not gonna be able to just figure it out there's just knowledge they're missing and that is
something that like you know empowers the like or allows people to take data that's there's no way of
selling this data and find a way to monetize it so it creates a new economy and i thought well you
know we might need a marketplace then for models and the closest thing at the time was hugging face
but you couldn't really use the models inference was tricky and and often left up to the developer
and it was very hard to find the models to like figure out which ones would be good at different
things so that's why i started open router actually the one of the guys who was building
like the one of the top browser extension frameworks called plasmo which i used to build window ai the
chrome extension um for local models he ended up joining as a co-founder and we started open router
together i love that story and how for folks who haven't used open router um like what's
the basic pitch of like why as a as a developer do i want to use open router um and also like
who is the does it tend to be skew more indie developer persona today or is it like you know you also
have large fortune 500 companies or whatever like larger companies um who are building on an open router
so today it it skews indie developer for sure um and there are a couple companies that use open router
to do like benchmarking where they run a whole bunch of tests against new models that just emerge
and open router is the easiest api for doing that the primary like indie like developer use cases
that we see are people building b2c apps the top ones are either games or role-playing apps
apps um or like novel writing assistants they involve like probably the very top one involves mostly
generating code and that code like it's you know rendered in the top experiences and then we have
some that just help users generate code they're more programming assistants so it's really a big mix
of lots of stuff and we try to like developers can opt into sharing their their data with us and uh and
we give them a discount um if they do and that data we just use to classify prompts coming in and figure
out which models are good at what and we'll do you know well we're working on a router and some ideas for
for creating a router to help people find the best model and we're sort of shipping new experiments
all the time but the primary use that people have for open router is they know what model they want
to use they don't know where to get it from or they you know they want to explore models and they want
to figure out which model is really good at finance or really good at role play or really good at
programming or really good at trend machine translation and we just help them find the models that people
are really using a lot for those cases it's not really an eval it's more of a you know app any style
like engagement metric that we try to show for every model i have i have so many random follow-up
questions to this but i'll just i'll just ask one of them right now which is how um based on that metric
of you know you're not really showing what the best model is but more so like what model has the most
traction across a specific domain similar to that like how representative and i was looking through
some of the leaderboards um before we jumped on this call just to see where some of the models were
how representative do you think some of those numbers are like with actual production usage or
maybe maybe more broadly like developer mind share like and and the part of for folks who haven't seen
the leaderboards they should go look because it's interesting to see what what's showing up at the top and
right now showing up at the top are some of the claude models um and i'm curious if that's you know
obviously we've seen more people using cloud models uh because of the recent releases but do you think
it's like actually representative of mindshare or some some other metrics or proxies yeah it's a good
question we've experimented with a couple different complicated ways of ranking models and we're zeroing
in on one that'll come in the future but we figured to start with we would just do raw tokens in and
tokens out and that has a big con the big con uh the disadvantage is that one developer who's just
going bananas can uh skew the the data for some model um and they do have to pay a lot to skew that data
so it's not like i'm not aware of anyone trying to gain a model or trying to like gain the rankings
but it it's not ideal i think like a closer ideal would be something like retention where of all the
people who like test a model how often are they coming back with that same kind of prompt um that i
mean that's kind of what we look for in just you know analyzing websites you don't look at like raw
traffic you do sometimes it's the simple metric but um but what really matters is like are people
sticking and and and like coming back so we're gonna experiment with some of those other ways
of ranking models soon alex i guess kind of hitting on the creation of open router curious to hear kind
of from a technical technical perspective what issues or roadblocks you faced when you know creating
the platform itself and then you know how you're able to kind of combat some of those
uh there there have been a couple one was routing speed and we wanted to build something that ideally
would have almost zero latency impact on the process of routing through open router to the language model
that you want to use and to do that we we ended up moving more and more of our logic and
infrastructure to the edge and cloudflare is just huge here i i don't think people realize how many
things cloudflare offers and i'm not you know really familiar with cloudflare's competitors
but we we ended up like leveraging a lot of cloudflare's newer features to to like reduce the
latency of our routing process down as small as we could and really sort of like advanced types of
caching that we put in place and we like yeah i'll give an example cloudflare is a cool feature
called hyperdrive that lets you execute sql that is cached in the edge region of the user executing the
sql and you can kind of connect hyperdrive to your database and ideally you locate your database as
close to the edge center as possible but we found hyperdrive to be really really effective in
reducing routing latency and just any sort of database work that we have to do is like almost
zero zero latency because of of things like hard to drive in combination with a couple other components
so that was one and we've been spent i mean it's kind of a continuous project it's never going to be
fully over um there's all kinds of like caching that we're moving closer and closer to users
um but i haven't heard anybody complain about routing latency in like many many many months
another technical challenge has been making analytics that scale and we've uh and like the first thing we
did wasn't terrible but definitely is not going to scale and that was building our own sort of in
postgres uh analytics tooling to do all of our analytics and postgres and just move as much into
postgres as possible the postgres ecosystem similar to cloudflare uh seems to be a bit underrated there's
just there are a lot of amazing postgres extensions and having a lot of our like very stateful logic
um in the postgres ecosystem has been pretty interesting and like allows us to to feel like
there's just a lot of integrity in our data um also allows us to leverage triggers
um which have scaled very well for us actually so when things happen in open router postgres triggers
like update a lot of the analytics tables that we have or update a lot of our analytics logic
and we still have we currently have cron jobs doing analytics that are going to go away eventually
we're looking at timescale db as one like as like the next gen of all of our analytics which will unlock
tons of other cool ways of ranking models and is also just a lot more scalable for managing a really
massive uh data set like we have now so um those have been exciting and in the more like ai
sector of technical challenges we we we integrate a lot of different apis and we we host a few models
ourselves like every time a new like llm provider comes up it's api is never the same as all the
others uh there's always some kind of like weird edge case that we see at pop up at some point we
have like i think one thing that's worked to our advantage a bit is that we have this community of
power users they're not developers they're not um companies they're just normal users who
love llms and they they like have an open router account that they connect to apps that let you
bring your own key um there's also a way of using open router to sign in with open router like to do
an oauth into some apps i'm not familiar with like another way of doing oauth with llms so the this
community of power users it has been really good for just teaching us things um when you know when new
models pop up or when we start in it you know when we like host a new model or when we start integrating
a new api they'll discover these like very niche finish reasons that come out or like um you know
strange errors that will emerge that we we get immediate alerts for and then we can fix and then
i think like a last answer that i would have that that just reminded me of since we're aggregating so
many models and so many apis we decided early on to get really crazy about type safety so we have
extremely strict type checking across the whole code base and we sort of believe that as like a
foundational um energy engineering principle which is new we you know i haven't done that at another
company before and i haven't uh seen it really thought through as like an engineering principle
but by making it really serious for us we just catch a lot of errors before they ever happen
and it's like for us it's almost an imperative because there are just so many different schemas
that we're working with all the time and there's so many apis and so many different like formats for
models and uh getting like really really good alerts and really good error reporting kind of
necessitates us knowing exactly the date the shape of the data going in and out of every pipe in the
machine alex i love that a couple of a couple of quick reactions one the finished reason uh ptsd thing
i was just having flashbacks of all the of all the horrible um finish reasons that are possible that
are oftentimes not fully documented um so a lot of empathy for that i also think your comment about
solving i think that it's a very underappreciated problem space this like analytics problem for lm
is because of the volume of queries that you're often working with and like the size of the data it's
like a another order of magnitude we're like trying to deal with these problems at openai and it's just
really hard and like most of the off-the-shelf analytics tools like don't scale up to the
the order of magnitude that you might actually see with um with some of these analytics things i'm
curious though like your comment about this standardization or lack of standardization it
does seem that there's some amount of momentum around people standardizing on the way that openai
has built their api and you actually see this like even more so with the sdks where like together ai and
a bunch of other providers don't even make their own sdks they just wrap them directly as part of openai's
sdk i'm curious to get your reaction to this um where you think that's going shout out to the
folks at uh stainless who make the openai sdk um and and obviously in conjunction with the team at
openai and have done an incredible job they also do anthropics um sdk and and actually the cloudflare
sdk as well so they're they're they're sort of helping some of this but um it's been interesting to
see how and and maybe just as one other comment to get your perspective on like the how potentially
conversely things happened in um in like the nft blockchain ecosystem where it seems like like all
the different chains have like completely independent tool chains and like everything is um hard to do
it's hard to deploy projects to multiple chains like none of that really works super well i'm curious
yeah why people have been so willing to standardize around openai which seems like an interesting
decision at a high level i think there's there's a healthy do in both spaces there's a healthy duality
between standards and standard breakers or you know you might call it like innovation uh generously and
standard breakers less generously um the standards in either space uh they can be good for consumers
because they make it easier for new entrants to get adoption you know they lower the barrier of
entry for them so it makes it easier for developers to to switch their code over to a new language model or
new api and they that increases competition um which increases quality and and reduces costs for
consumers standards can also be bad for the consumer too if nobody tries to like improve upon the standard
and everyone just like locks in to the way things are it becomes really hard like for a company to get
any kind of traction uh from like deviating or making a breaking change but openai had the first attempt
that i'm aware of at standardizing something about the language model communication process with chat ml which
for uh anyone listening is a way of structuring a multi-turned conversation with an ai where a user
says something or ai responds back the user responds with something else and maybe there's a you know
overall context for the whole conversation called a system the system prompt and it's really a simple
standard um and it's a it's very extensible and it was the start of something like easy to set up and
i mean correct me if i'm wrong i'm not aware of like an like an earlier attempt at standardizing something
about the like about the prompt so chat ml was really interesting to to us and and it was part of the
reason we decided that our api was going to look very similar to opening eyes and just be a a superset
and i think you know some of that mentality probably meant a lot of other companies thought the same
thing and started implementing things that looked like open ai standard and this is like i think a
really healthy standard because if you want to deviate you can still just send a raw prompt there's like
basically an easy opt out for people who are trying to innovate on their prompt format and there's
tons of people who do there's basically like a really clear pathway for a developer to make a model
with like a really unique interesting prompt format an example is a open chat which um i believe at some
point i think they were training on this was a research model they were training on um synthetic data
and they found that the model performed better uh if these if the assistant's name was like gbt4
response it like if the assistant thought it was gbt4 this researcher found that the performance improved
so basically like doing these little tweaks to the prompt format was one way the model developer
community is has chosen to like innovate and deviate from the standard and they're not hosed they can
still plug in to a lot of the existing tools and hugging face now has like a really flexible standard
for tokenizer in the tokenizer config for the chat format that lets you use jinja which is a templating
language for really really complex chat ml formats so back to the overall picture i think like crypto crypto
is just very different the and part because it's financial fundamentally within like the ethereum
ecosystem ecosystem and all the layer twos on top of it conforming to the same rpc standard as all the
other miners just allows you to participate in earn mining rewards so there's like direct financial
incentive to adhere to the standard and there's direct there's direct financial disincentive to deviate
which is really tough if you want to like deviate from the standard in crypto at that level you kind of
have to create a new blockchain and that's why every new blockchain not everyone but a lot of
them have very different apis for interacting with them as as clients or as miners and i think that's just
why things work differently in that space yeah just a quick reaction nolan and then i'll kick it to
you for a question which is when chat ml was coming out greg brockman um was incredibly gung-ho
about chat ml and was like you know we're gonna build this standard it's i think the original
blog post when we released the chat completions api was accompanied by us saying like you know
i actually think the original iteration of that blog post was more of like we're building this
open standard yada yada yada um and i think it got sort of tampered down to like you know we're putting
out this product and we're also releasing the spec of of chat ml so that people can understand
and then sort of almost almost immediately the uh sort of even we diverged from what the standard was
and like we sort of had this reference implementation that was available to the world
with chat ml um and you know what what the path that we were on was like not actually keeping that
you know quote unquote standard up to date so i think this is a good reminder i'm sure greg's not
listening to the podcast but greg someone needs to ping greg greg's coding somewhere and putting out
tweets about fixing machine learning optimization problem uh code issues um somebody's got to ping greg and
remind him that uh they need to open ai should should do some active work to like actually keep
that standard like somewhat up to date because it it hasn't been maintained and it was actually like
removed from a bunch of the stuff that that they had put out um so it's a it's a good reminder
i'm curious are there other parts of the the api standard that drive more adoption of it in your eyes
i i think it's part of my mental model is it was less that like open ai sort of figured out the right
level of abstraction which they might have and like i don't know if i actually have the intuition
to know if that's true or not because i think people just became it became so clear that open ai
was so far ahead that like essentially if you wanted uh any of those users to be on your platform you
were required basically to um especially in the world where like everyone is experimenting always
like you were essentially required to use that spec um and the spec specifically of the sdks uh so that
developer didn't have to switch um over to something else and it just from my perspective like i think
it's obviously good for for open ai but it's it's interesting how it really was like the first like the
first iteration and it seems like to a certain extent like the first iteration without any level
of incremental innovation is like the thing that people are sticking with as like oh no you know
don't make a different thing like let's stick with the one that open ai came up with like literally on
the first shot and that just seems um yeah it'll be interesting to see like how how much that plays out
over time yeah i mean our view at open router has been like make every model work with the open ai
api format um but provide extensibility and advanced features that deviate from the standard
but aren't breaking changes for example like our mod you know normally the model field in your request
is just one single string with the model that you want to request for open router it can be an
array of models and uh and we have like different kinds of like prompt transforms that you can
configure one of them we call middle out which allows you to a little a little bit of a play on the
on the silicon valley tv show joke take your prompt and there's research that like llms mostly pay
attention to the beginning and end of very very large texts and pay less attention to the text in
the middle so you can have if you know if your prompt is too large for a model open router can like
squeeze it and remove parts from the middle in like a a strategic way so we we add different things
like that to our api but but but try to like our our overall goal is to reduce switching costs between
models so it has to you know we we try to make it really really easy to let developers like experiment
with new ones alex my question kind of ties back to your statement around the power users um that
you have currently i guess kind of curious as far as use cases as far as what those power users are
using this tool for and then kind of you know higher level question two when you're originally
rolling out with open router you know your thesis as far as who would be the end users did that stay
true or was there kind of a shift in personas as you kind of gradually rolled it out and got more
and more feedback i'm kind of curious to see where that stands and again kind of how it changed
throughout the evolution of open router itself we have seen more of our usage in terms of tokens
and dollar volume move towards developers over time um and it's a little bit hard to know this question
for sure but we still have a good chunk probably more than half of our users are are just prosumers
or power users or people using um open router directly um and yeah we also have like a playground
where you can where people can experiment with models and test new ones out and uh the playground is
often used or used by some people as just like a consumer experience for directly chatting with
models and uh and saving your history with all of them in one place but locally and privately on
your on your device so we've been seeing the ratio we think roughly not change for you know in terms
of users versus developers over time but developers have been getting more serious and um more active
and spending more over time yeah alex i have a follow-up on this um and i'm even more grateful that
we're having this conversation because i think like this is to a large extent some of the almost
the exact situation that the product that i work on you know many hours a day is sort of in the
position of google ai studio like there's a large consumer footprint for google ai studio because it's
an easy way for folks to sort of get access to the models for free and try out what's latest but like
the core market that we're going after is developers and i'm curious like how you've sort of navigated the
world of like you can't do everything um and you ultimately have to make those trade-offs and like
how you've made how you've thought about the trade-offs between like we want this thing to be for
developers potentially or um but we also still like don't want to actively make a bad product for
for the sort of consumer oriented uh user persona we struggle with this question all the time honestly
it is like uh or i i at least like think about it all the time i think the what the the biggest source
of the tension between uh building for users and building for developers uh at least to me is
differentiation just being different than everything else out there or different in a way that really
like works for us and feels like the open router thing to do the answer to this question for us
right now is building a platform that works for developers and building a marketplace that allows
people to discover and explore new models with ease and and p the people doing that are not just
developers um but we we've been we just we launched like a new marketplace ui last week um that lets
you you know see all the language models that we have but figure out which ones are free which ones
are really popular on finance or legal topics which ones support json output which ones support tool
calling and uh and then sorting all of them by price we're looking at which ones are new um sorting
them all by token usage in the last week giving people like really powerful tools for looking up models
that they want to use um and for exploring like how models rank and compare with each other is is sort of
like the big can you know not purely developer product that we spend a lot of time on um the playground
which we're going to be uh which we've been upgrading a lot recently is like a really easy to use
developer tool for for models and and it looks a little consumery um but i think like the developers
for language models are like bringing a lot of value that just the the you know the chat room or
playground is is not going to bring and we want them to feel like they're welcome so we've been we've
been sort of building a lot of developer platform and performance improvements uh recently this is
kind of a high level question too but i'm curious and again kind of over the past i mean close to a
year and a half not two years now again we've got kind of go back to all of this ai hype and alex i'd
love to get your feedback or perspective you know being at openc when nft and crypto was kind of on that
bull run as well you know what similarities you see between the ai hype and kind of those nft
crypto hype um and you know kind of where do you see that space going as we continue to move
further and further up that kind of chart and and maybe as an additional add-on to this like anything
that you have thought about doing differently with open sea to like or with open router this time um
to sort of make it resilient to like more resilient perhaps to like you know assume if we are in some
crazy hype bull run with ai right now um and it sort of flatlines in the future like is there still
a feasible way to to make you know the business or the project work however you want to frame it
with open router we haven't really been building that many hedges against like the ai market into the
product like you know if the ai market flatlines or declines i expect we will too and i think that's just
part of the bet it it is a bet that like when some part of the language model space is growing a
rising tide lifts all boats and i expect other parts of the language model space or the model
space to grow to we just focus on language models today but uh others will come in the future so
and examples of this and this is similar to this part i'll i'll draw similarity to crypto in a second
if you look at the rankings page on open router today um there are a couple moments where it just
jumps up significantly you know a recent moment like that was the launch of clod
cloud or actually a better example is the launch of cloud three which happened in early march of this
year and you see a lot of people trying out cloud three just tons of tokens processed um and then you
start to see open source models grow a lot as well like they follow it up yeah it's kind of one of the
mysteries of life why that that happens i think like one theory is that the uh like interests that
clod brought to the ecosystem um from developers who just weren't getting something out of it before
or for developers who wanted to achieve something and now could achieve it in a low-cost way
um it just made people look at the other things available it just it made people look around to see
wow i like i i thought i knew ai but then this new thing came out what if there's something else new
that i don't know about that is also underrated or you know undiscovered and there's just some kind
of there's something about like developers everywhere not just in ai um where i think this just happens
all the time like if a new thing emerges you start to wonder if you were overlooking the whole space
and if there are other new things that are just hiding in corners and uh and just need a light
shown on them and this happens in crypto too like um there's very uh and and we made a lot of a lot
of like inside jokes at open sea about rising tide lifts all boats um because everything is sea themed
and we spent uh you know we would look at like the analytics of the space and um every time a new
project emerged uh maybe it was like a new blockchain like polygon um you could just see a ton of other
projects like kind of similar to that project um or other creators um or apps start to just get more
interest and get more traction and um and and sort of follow the lead of the breakout project
um additionally when you know crypto like when prices are going up um just fungible tokens like
bitcoin and and eth when the prices are going up uh nfts values go up too and like they lag a bit and
they're not as they're not super correlated but um but i think it's it's partly because you know people
like have more liquid like crypto liquidity and are you know looking for things to do with them and nfts
are one of the ways that you can use your crypto that's like easiest and mostly visually and uh you know
digitally exciting so just like the whole rising tide lifts all boats phenomenon i i love like seeing
it happen and i just started to follow it around everywhere and think about what it means and i i
guess that's the like one of the the biggest commonalities between the two spaces too yeah i love
that i know we're we're almost coming up on the end of time so want to be respectful of your time alex um
um the two questions that we always close with and i'll i'll ask the first one and then i'll kick
it to nolan um just curious like what your personal ai text like tech stack looks like and this could be
you know from a tool perspective um like what are you using what's getting you excited from like an actual
uh tool consumer tool perspective yeah i've recently started to get more into super maven as my um
um like tool for code generation uh i've just found it to be so much faster than uh competitors i've
been kind of like blown away it's really hard to know but it feels like it has more of my code in
context when it generates code um and uh like creator seems really smart and uh it's also a new york
based team i'm in new york and uh and then and they just launched the ability to chat with models uh
with you know different kinds of models with with your code and i've started sort of like a new workflow
where i'll write the code that i want and then i just ask open ai or clod or gemini to generate tests
that you know just like show me which tests it thinks i should write which unit tests would be
good for the code i just wrote and i you know i accept most of them like they've been getting
better over time and if enough code is in context they improve exponentially so um i like write more
tests now than i ever have in my life and because i'm not actually writing them
um and uh and the tests i like read it and check over and i mean the end result is so much better
so uh that's been exciting another one that i've been using is i mean i'm an um angel investor in
devon by cognition and we've hooked devon up to our code base and slack and it's it's improving um and
and particularly good at like uh at sort of research driven tasks that really really need to
you to like you know explore things on the internet devon is like the most powerful scraper i've ever
seen and consumer wise i mean i switch i switch back and forth between like for just knowledge retrieval
um i i sort of bounce around to everything partly because i enjoy bouncing around um i bounce between
like open routers playground and and clod and perplexity and chat gpt directly uh as my primary
like knowledge retrieval places i think there's definitely in the future like it feels like there's
going to be some more ui differentiation that every platform does um the ui's all started the same
and have gradually diverged and tried to like keep users locked in with some unique thing i'm guessing
that's going to continue and alex our final question we like to end it on is uh already six and a half
months into 2024 we like to get the perspective of our our folks we speak with as far as you know
something that you're looking forward to or hope that happens within the next six to seven months
maybe early into 2025 and then on the flip side uh you know kind of given everything that's going
on something that you hope does not happen whether it has a negative effect on personally society
politics as a whole etc uh kind of the two-sided questions uh as far as again what you're looking
forward to and something that maybe you're not starting with something that i'm not or something
that i'm worried about uh i'm really worried about taiwan it doesn't feel like the ai industry or even
the computer industry has a great plan for removing the dependency on all kinds of industry going on there
um but primarily tsmc like it is like that kind of that kind of like critical component
basically not having an alternative or not having like a a great plan for what happens if if taiwan
you know if we can no longer depend on our uh uh supply chain in taiwan um it it would be so disastrous
and uh it's literally being verbally threatened all the time um i i i just haven't seen like
something that's calmed me down about it um so that's one one thing i think about and worry about
and uh in terms of like things i'm looking forward to i there's a lot of stuff i'm i'm you know i i
first thing that pops into my mind is a new architecture for language models and uh particularly
one that can do search um maybe maybe that's yeah reasoning would be maybe a subset or maybe i'm
misunderstanding how some language models are are trying to approach reason but it seems kind of
odd that the search process just like like doing inference and then revising your answer over and
over again is being handled by apps and agents today uh you get like a huge performance boost from
generating code with any of the language models and then saying do it better or like you know prompting
the model to like revise the code they wrote and improve it in some way and just you don't even have
to explain how you want it improved just like think twice not just once give me your best answer not
just the first answer that you thought of and uh moving this sort of search process or multiple
inference passes inside the model itself i expect would be a wild wild improvement um so i'm excited for
for that to happen somehow or or some kind of new architecture that allows for the model to like
actually think a bit i love that i completely agree on on both of those fronts um alex this was a ton
of fun i i wish that we uh that we had another hour to chat to chat about stuff um super excited about
open router it was awesome to hear your perspective um and yeah looking forward to to hopefully all the the
cool new improvements that y'all are working on
