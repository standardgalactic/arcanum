We actually feel like we have a very good idea of how to get to AGI,
but we just need to kind of execute. There's so much change coming so much faster than anyone
anticipated. I don't know where anyone can hide. What does the human become in the AGI world?
I am really worried about how it shakes things up, whether that's in Australia or more developing
countries, the kind of work that we rely on every day. Almost all of us would have had
work and work's been part of our purpose. The idea that we kind of don't have work
is like liberating, but also I think a little bit scary.
That's Casey Flint, ex-VC at SquarePeg, now leading AI business development at AWS.
She's met a thousand plus AI leaders to uncover where the industry is really headed.
And so we asked her, when AI reshapes everything, who wins and who gets left behind?
Growing up in rural Queensland, in my hometown, we did not have permanent doctors.
If you needed to go somewhere for something serious, you would get on a life flight, basically.
I remember being like 14, like reading medical research, trying to figure out,
well, what can I do to like help all of these panic attacks I keep having?
And so that kind of led me to be like, okay, I'm going to study biochemistry at university.
And I was interested in how early AI back then could be applicable to solving medical problems.
And then when I got to Uber, Uber had done some extraordinary amount of data science work.
I would work until like 1am and you do that on the weekends as well, because it was just really crazy.
And that kind of got me into technology, which I'm super, super grateful for.
And that was a bit over 10 years ago now.
Do you think there's like some universal things that are like worth people learning at the moment?
Ooh, that's such a good question.
What I've done that's given me the most leverage is actually...
And we're live. Casey, welcome to the podcast studio.
Thank you for having me.
I really want to start in a place that I think is quite contextual for where you are in your life.
You've gone from this massive shift from being at the precipice of investing in AI with SquarePeg.
And I think you've really established yourself as a domain expert in this space, especially in Australia,
and now started a new role at AWS.
I just want to ask, how are you feeling?
I'm feeling...
That's such a great place to start because I'm feeling hugely restless and anxious in an excited way.
But I just like the pace at which things are moving and the kind of surprises that keep popping up.
Like we'll talk, maybe we'll talk about DeepSeek later, but I think that was a surprise for more
reasons than people realize.
Those kinds of things are, yeah, just making me really anxious and like, oh my God, there's so much
change coming so much faster than anyone anticipated.
And that was part of the motivation for me to move to AWS is like get even closer to the forefront of
what's going on.
So yeah, I'm feeling restless actually.
And every night when I go home after work, I'm still thinking like, well, what should I be doing?
What should other people be doing?
What should Australia be doing?
Like, how should we be thinking about all of this change?
And I don't have a great answer yet.
I feel like there's no one that's on the precipice of what's going on that wouldn't be feeling restless.
Yeah.
Like I'm sure a lot of your friends in SF who are, you know, at the Model Makers and Deep
Into Space probably feel the same way.
Yeah.
They feel like right now is go time.
Like this feels like the most important year and like they just need to kind of lock in as
every NSS fits.
I hear like a lot of people are saying that there's, you know, there's this window now.
They need to be learning and up to date with everything because soon we're going to be
integrating this with all of our workflows and people that are up front are just going to be
getting enormous benefits from creating these huge workforces of agents.
And some people like extrapolate that to a crazy degree and they say like,
this is your time to make money now because in the future it's like people are just going to
have these huge AI companies that are going to be doing all the work and everyone's somewhat
unemployed or underemployed.
But yeah, no, it's something I think about.
I'm curious to like to know what do you think people should be learning?
Because an example is maybe a year ago when I was in VC, everyone used to talk about fine
tuning models.
Everyone was like, you know, let's get a bunch of GPUs and fine tune models.
And now people realize that if you just give them better context, you don't need to fine tune.
And that feels like there's just all these paradigm shifts going on all the time.
Do you think there's like some universal things that are like worth people learning at the moment?
Ooh, that's such a good question.
I do reflect on this as well.
And that's part of what makes me anxious, right?
Because I'm like, what should I be learning?
And I have two younger brothers studying computer science.
And it's like, what does the future look like for them?
In terms of what people should be learning,
I don't even know if playing with the models today will help you get ahead of all the change
that's happening because it could happen so suddenly.
What I would say is that it probably can't hurt.
And so rather than like, even rather than going and reading papers or trying to be across ML Twitter,
I'd probably just try and play with different things that pop up, right?
So I'd spent the last month playing with like windsurf and lovable and cursor.
And that alone has taught me a lot.
And so playing with the tools, trying new features.
And that might seem like an obvious suggestion,
but I think there's a lot of people who aren't doing that.
So most of my friends in Sydney are in tech.
They don't know about Claude by Anthropic.
I'm like introducing them to that.
They don't know, for example, that you can generate a video that doesn't have six fingers.
Now it has five because it's actually improved.
There's a lot of people who played around with tools like a year ago
and now just use ChatGPT, kind of like Google.
But actually the technology is progressing really quickly and you can do so much more.
And so my, yeah, I would be experimenting with things.
And I have also spoken to friends about the fact that you feel like you're paying
for so many different services, right?
Like I'm a pro member of Gemini, of OpenAI, of Claude, of Midjourney, like all of these products.
But to me, it just feels like such a big return on investment
because I'm keeping across what I can use and how I can use that in my role.
And yeah, what kind of opportunities there are for me beyond kind of my role.
Yeah, I think the plain anecdote is super important because like,
let's say someone just goes to sleep for five years and wakes up in five years time.
Like if they were instead learning about AI for those five years,
would it really matter if the models are so advanced in five years?
Like I think the way to get ahead is just like tweaking and seeing how you can use AI
in certain workflows and what can you get out of certain questions.
Yeah.
Just going down those sort of rabbit holes, which I know you've delved into.
And we're going to get really deep into AI soon.
But I'm pretty interested in your backstory because you grew up in a really rural
Queensland town of 600 to 700 people, a town called Winton.
Cattle farming country.
Yeah.
What?
But now you're really at the zeitgeist of AI.
How did you go from there to there?
So I suppose a shortened version of my story, growing up from rural Queensland,
in my hometown, we did not have permanent doctors.
And we had like a partially functioning hospital.
We didn't have dentists.
We didn't have any specialists.
We did have nurses in the hospital, like largely for emergencies.
If you needed to go somewhere for something serious,
you would get on a life flight basically to a different hospital or different town.
And for me, that was really difficult at times because I didn't have access to
the kind of healthcare resources I needed, particularly like from when I was about six,
I really struggled with anxiety.
And then when I was 14, I struggled with depression.
And then when I was a psychologist where I was from or like,
and people had like quite a backwards mentality towards medication for mental health issues.
And again, there wasn't a consistent doctor for me to talk to about that.
And so that set me on this path of being really passionate about healthcare and like
how you could, yeah, I guess make this information more accessible to other people.
I think when you have like a chronic condition, you kind of become your own researcher.
And so I remember being like 14, like reading medical research, trying to figure out, well,
what can I do to like help all of these panic attacks I keep having and help the fact that I
feel so tired because I'm anxious all the time.
And so that kind of led me to be like, okay, I'm going to study biochemistry at university because
that will give me the foundations that I need to do more of this research.
And I knew that I was really interested in businesses, particularly small businesses,
because my parents were always really entrepreneurial. And so, yeah, I went to
University of Queensland to study biochemistry and molecular biology and thought I'd turn that into
some kind of startup. I was very involved in like on campus startup events, right? And one day,
one person who I ran this startup club with said, hey, there's these like Uber people who are in town
and they've moved into the same co-working space as me, which was called River City Labs,
which Steve Baxter founded. And they said they're looking for people to work with Uber because it's
growing so quickly, they need help. And I was like, cool, I got, I did one trip on that Uber thing
and it was really magical. And so I rock up to what's literally a pub and meet these people who
were launching Uber in Australia and told them that I really, really wanted to work with them because I
loved the product. And they told me that because I was graduating four years, I should come back to them
in four years. They needed people who could commit full time because this thing was
going crazy. And I was like, okay, a bit disappointing, but kind of went away and
figured that was a no. About three months later, I just, I kind of kept in touch with them. And
three months later, I decided to reach out and just kind of grovel and beg to be part of the team
in some capacity. And so I said, I'll do graphic design, I'll hand out flyers, I'll reply to emails,
literally whatever they need. And fortunately, they thought, actually, we could use some help
with that kind of thing. And they brought me in. And then I ended up spending five and a half years
as part of Uber, which was really cool. I think I got like two and a half years into my biochem
degree before I formally switched to economics. Very, very hard to do biochem full time or doing
a startup full time, let alone a startup like Uber. And so yeah, I switched to a course, it'd be easier to
kind of manage with basically crazy startup hours, which was like, I don't know, you get into the
office in the morning, and then you're with I would work until like 1am. And you do that on the weekends
as well, because it was just really crazy. And so I was not fitting in any university work. And yeah,
and that kind of got me into technology, which I'm super, super grateful for. And that was
a bit over 10 years ago now. Just really exciting. Yeah.
A quick intro from the podcast, Adam and I spend a lot of time thinking about what would be the number
one company we'd join if we weren't founding Kindling. A founder that we've gotten to know
really well is Farooq Ismail, who leads Slice. They just raised a $7.5 million round and are changing
the world of travel. And Farooq told us they're on the lookout for exceptional talent. And we think
this is an opportunity that could change the trajectory of someone's career. And Slice are at
a really interesting point right now. They've just raised this big round, but they've still got a small
team. So this is an asymmetric opportunity for a young gun who's ambitious and wants to grow a really
fast growing company. Slice unlocks the future of travel for a lot of people. They're solving an
interesting problem. They also pay really competitively in this fast career growth.
So it's a great opportunity and we'll leave the links in the show notes if you're going to check
it out. Back to the episode. Did you feel like a shift in the way you were understood by the outside
world when you were in that environment coming from a place where it seems like you had ambitions
towards business and this interest in technology then being in that intense Uber environment where you
like, did you have a moment where you're like, I found my people? Yes and no. I actually really
struggled with being an outsider. Yeah. Uber had like, Uber hired a lot of people based on
referrals, which a lot of early stage tech companies do. And the benefit of referrals is if
you've got quality people, they're likely to refer quality people. The downside is it can make your
group of employees very homogenous, right? Because people refer people from similar backgrounds.
And so a lot of the people that I felt I was around were like law and commerce graduates from
great schools who went to really good private schools from like relatively wealthy families.
And I did not relate or really feel like I fit in with that kind of group. And so, and it was also
difficult, you know, Uber was so well funded and so there was a lot of cash being thrown around at
different things. And it didn't seem very material if someone made a SQL mistake and it resulted in us
spending like 30k more than we would have otherwise, or even 2 million more, which to someone growing
up in like a very disadvantaged part of Australia was very confronting. And then similar when I was
in VC, right, you talk about these really large sums of money for businesses that don't have much
to show for it. So I found that really difficult. But in terms of like finding people with very similar
passions to me, absolutely. Like being like ultra nerdy in a small country town, which, you know,
really values footy and kind of hunting and all of that stuff, I didn't feel like I fit in there.
So yeah, I kind of a bit of both really, I did definitely find my people and that people were
excited about the same kind of things that I was, which was technology and science. But I also felt like
I didn't fit in on a background basis.
And you were at Uber in a pretty wild time because they were, I think the fastest growing
company in the world for like from 2012 to 2017. And we chatted to a bunch of people from Uber,
like Emile Michael, and you can tell they're really intense people and intense culture. And
there's all these sort of like, I guess, Uberisms or thing that people remember from their time there.
So when you reflect on your time at Uber, like what are the things that you remember most vividly
as takeaways or lessons?
Yeah, I think the thing that changed my, you know, Gen Z loves saying,
oh, that changed my brain chemistry, right? The thing that changed my brain chemistry
most about Uber was the optimism and just the idea that like people in SF right now love saying,
you can just do things. That was the attitude back then, right? Like even if a government said no,
or there was some kind of reason that that was structurally likely to be impossible, people always,
always looked for a way. And I came, I was very cynical. Maybe it's the like kind of baby academic
in me at the time being like, no, you can't do that. Like, there's a reason you can't do that.
And there are rules and all of that. And people just never saw those as like hard walls. They saw
them as something to just run through. And time and time again, I would be proven wrong. And they
would show me that you could actually do that. And so that kind of optimism of we can do anything,
if we kind of put us, put a smart group of people onto that really changed me a lot and obviously
affected the way that I think about venture when I came to it. So that is a really big one.
Um, the other one, and I think about this again, in respect to a lot of startups is that
just hiring really brilliant people and letting them figure it out is so powerful. And there's a
book about the early days of Google called How Google Works, where they spoke about how their
investors did not like that they didn't have a business plan. And the guys basically said,
we do have a business plan. It's hire really smart people and they will figure it out.
And that might sound really ridiculous to some people, but it just really worked.
Uber hired such good people and gave them like really extreme autonomy. And I think that's what
made it actually really powerful. And so you might think that even though by the time I joined, I think
maybe it was Series B or Series C, very well funded, you might think that it was not operating in the way of a
startup anymore. You know, it was getting quite mature, but every individual team had so much autonomy that
you could operate, um, very similar to a startup and you had a lot of remit to do the things that you
thought were right. And so I think that's incredibly powerful. Um, I learned to suppose a lot about also,
like operating in different geographies was really valuable. I did work in Thailand and Singapore,
in India, in across Europe, Korea, Japan. And that was despite the fact that when I joined Uber,
I didn't even have a passport. I hadn't been overseas or actually across state lines, which is crazy.
Um, and so, yeah, it taught me a lot about, um, different cultural nuances. And I was reflecting on
this earlier today, because it's now something I see at Amazon where people prioritize scale too
quickly and particularly, um, international companies. So what I mean is if you're at a very
big company, you want to make sure that these initiatives will work across all of your different
regions and teams. And so people optimize whatever they're building for scale, as opposed to like what
best in class would be in general. And I think that's the wrong order to do things. And so what Uber
would often do is be like, well, here's the way that works in America. Let's try and scale that
exactly the same way in Korea and in India and all of these other places. And you just need a
lot more local nuance to be able to operate, um, in a different culture. Right. And so it took Uber
like a really long time to learn that. And I see other people make that mistake where they're just
optimizing so hard for scale rather than just like make a small version of it work in that kind of
local context. And then think about what's applicable and what's not.
Hmm. What's interesting in that kind of, um, those kinds of lessons is it seems like everything in
Uber is downstream off the founders personality, right? The whole running towards things seems like
very much what Travis Kalanick was all about. It seems like understanding cultural nuance isn't
probably in the DNA of the founders. Like when we talked to Emil Michael, he talked a lot about hiring
people from Bain because he had a chip on their shoulder of not getting into McKinsey and dropping them
into like different countries and letting them figure it out. Yeah. But then they ran into problems
like in, you know, in Brazil, in, in Italy, in, in the cultural nuances of breaking through those
things, which didn't quite work. And we reflect on that a lot internally where it's like almost all
the time, the strengths and weaknesses of a business are downstream of the founder strengths
and weaknesses and they flow in throughout, um, all the employees. I want to switch the conversation a
little bit more towards AI now. In 2023, you met over a thousand people working in AI. Actually,
maybe that was 2024. I don't even know anymore. What beliefs, um, have you updated since getting to
the AI landscape? Yeah. Um, I mean, I've long been interested in AI. That's probably part of the history
that I didn't give background on. So studying biochemistry, I was really interested in stats and I was interested in
how early AI back then could be applicable to solving medical problems. And then when I got to Uber, um,
Uber had done some extraordinary amount of data science work, right? Like, Surge is an amazing
example of that. Um, and having this fully dynamic marketplace, um, and also all of the kind of, yeah,
work associated with the complexity of that marketplace. Anyway, um, so I was doing some ML projects while
I was at Uber, um, in Singapore, which was really fun. And so we've kind of had this ongoing interest in the
space for a while and now it feels like a very good time to be doubling down. Um, in terms of like
things that have updated or ways that I've changed my mind, I suppose there's been learnings that have
been new for a lot of people, right? So one of them, one of them I talk about a lot is the value of data.
I think when I was at Uber, there was a huge amount of emphasis on how much data you have so that you can
use that to build custom ML models. So there was this like big data era where everyone was focused
on having this like, um, you know, big Hadoop warehouse where they can have all of their data in
it. Um, and so you kind of come into something like venture and the thing that people commonly
believe is, well, if you get this really valuable data, you'll be able to do something really powerful
with it. And that will give you this sustainable competitive advantage. I just don't know how
commonly that's actually come true in a lot of cases. And so the reason I talk about data not
being as powerful a moat as people think in, particularly in the context of generative AI
is that the kind of data that people often front up with is data that looks very similar to what's
on the internet. So for example, I would often get startups come to me and say, oh, hey, I have all
of this like Slack data from my Slack integration. And that gives me a great leg up for many of my competitors.
But one, it's super easy for other people to build Slack integrations. And two, the kind of
conversations occurring on Slack are pretty similar to the conversations occurring online.
I don't know if those conversations would meaningfully impact the way that the model is working
and hence meaningfully impact the product experience. And so there seemed to be this
disconnect where people were very focused on, well, if I have this valuable data, it will always
convert to a better product experience. But I just don't think that's been the case.
The way that that has evolved since is now we're in this era of reinforcement learning working,
right? So Deep Seek, I think a lot of people think that the Deep Seek announcement was exciting
because of what they quoted it, what they said it cost, and because it came out of China.
But actually, there's a secret third thing, which a lot of people haven't been paying as much
attention to outside of research, which is the fact that they were able to show reinforcement learning
at scale in a way that hasn't been demonstrated before. And that is really impactful from a data
perspective. And because the kind of basically the big labs right now are trying to create a lot of
data that they can feed into a reinforcement learning model. And that's going to take time. And they're
focused initially on software engineers, which is why you might see people on X talking about automating
like an L6, L5 software engineer by the end of the year. They're trying to get these teams of software
engineers to basically work as a teacher to the model and to build an even better reinforcement
learning model that can beat the kind of best coding benchmarks. And to me, this like revelation in
reinforcement learning being much more effective than it's previously been in the past was meaningful
because the way that they did it was very disconnected or the way that I understand that they did it
was disconnected to needing humans. So I'll slow down a little bit. The way that I understand
reinforcement learning to typically work, if we use like a chef analogy, is in the pre-training paradigm,
which has been the paradigm of the last few years, you basically give a model like thousands and
thousands of cookbooks and say, hey, learn the kind of pattern of recipes that results in like a good
outcome, right? And then you have more traditional reinforcement learning. I'm trying to think of the
best way to phrase this. There's like a distinction I want to make here on reinforcement learning.
So yeah, so and then if you imagine in like more traditional reinforcement learning, in this case with
LLMs, what you might have to do is get a whole bunch of people to contribute, like humans contribute
their thoughts on what a good recipe kind of tastes like, and what a bad recipe might taste like. And
then you use that to judge what the model has learnt. So you might have the model being like, okay,
there's this recipe, does that result in something tasting good or not? Well, you have to go to the
other model that you've trained. And so you end up with a model that's trained on like all of this human
feedback on like what a good recipe is. And then another model, your reinforcement model, learning
model that kind of goes back and forth to that kind of assessor or judgment. And then in the DeepSea
case, they actually don't have another model that they've had to train for all of that feedback. They've
just built the mechanisms for the model to basically check its own homework. And so what it does is create
the recipe, and then it is able to independently figure out whether it tastes good or not, or whether it
kind of meets this criteria for correct or not. And the reason that I think that's incredibly impactful
and why some researchers were freaking out about that is if you cut humans out of that work, of that
data creation, the model can theoretically like continue to improve without humans in the loop,
which, you know, could pretty quickly or more rapidly improve the capabilities of models. And the other
reason it's significant is the scales that people in these firms are seeing in terms of, okay, you do,
you provide this much RL data to this size of model, they're not seeing any like taping or tapering
off yet in performance. And so they still think they have a huge amount of like performance gains
that they can get by continuing to put in more data into these models, basically.
So to tie that back into how this affects AI companies, it seems like reinforcement learning
and post training, it's effectively a lot cheaper. It means that you can create better models for lower
price because you need less compute as if you're doing pre-training. Is that roughly correct?
I don't think that's the full story. So from what I gather, what kind of confused people is the DeepSeq guys
put in the R1 paper, or maybe it was the V3 paper, what the kind of final run cost. But the final run
and the compute cost associated with that doesn't include like buying all of the compute in the first
place, any kind of like human data that they did generate, acquiring the data, the multiple runs that
they would have done up until that final run. So yes, from what I understand, we are on a trajectory of
costs continuing to come down. I don't think it's like holistically quite as cheap. And they also had
the like V3 model that they used to help train the R1 model, right? And so the V3 model was your big,
like, I think, I don't know if it was the V3 model or the R1 model that was like 671 billion parameters,
but still a big model that you need to train in the first place, right? So yeah, costs are definitely
coming down quite significantly. I don't think it's like as material a story around like, oh my god,
it's cheaper than ever. And like, how can OpenAI like justify their training costs? It's just not
like the full story. What do you think that means for founders who are building this space? Like if
reinforcement learning becomes more accessible, where one model essentially helps the other,
and we don't need as many humans in the loop, does that mean that we're going to get accelerated,
almost domain specific AI use cases that were just really hard to do before?
Yeah, I think that's the implication, which is quite cool, but also nerve wracking, right?
And that's where I think things like the computer use API from Anthropic and the operator tool from
OpenAI comes into play, right? If you theoretically were a company trying to build a very large model,
or like one of these new reinforcement learning reasoning models, again, you need to get data
kind of explaining the steps and the ideal outcomes. Well, it'd be very useful to get that data by
actually having access to people doing the workflows, right? And so I think that having access to those
screens and how people are actually going about their day-to-day workflow is a means to effectively
train these new versions of models that are domain specific, able to execute on certain workflows.
Hmm. And I think tying this back to your last more than three years spent investing,
where do you think the opportunities are currently? I know these things change all the time. We talked
kind of before we hit record around how in 2023, late 2022, when I was also in VC, everyone was like,
oh, you're just a, you know, GPT rapper. And that was almost like an insult back then. And now,
you know, most companies are on application layer. And honestly, if you're trying to do
any of your own kind of fine tuning or building your own models, like most people are questioning,
why would you even try and do that, right? You need a lot of money to compete.
Where do you think currently where we are in February 2025, the opportunities are?
Yeah, I quickly pick up on the rapper point. I think maybe people think that the criticism around
rappers is, oh, well, you're not actually doing any R&D at the model level, right? You're not tweaking the
model or anything like that. That's not so much the criticism from VCs. And an analogy I really like
is, imagine back when the iPhone came out, and we have this brand new GPS capability on your phone,
right? The difference, if you were to create an app that basically just shows a compass,
thanks to that GPS capability, that is like, very close in concept to like having, how do I say this?
If you have like a compass app on your phone, it's not a very difficult thing to reproduce
now that we have GPS capability on your phone. What is very difficult to reproduce is Uber.
And that's because the capabilities and the features of Uber and the kind of things you need to bring
about like a marketplace with network effects, that is much more complicated to produce. And so it's not
necessarily that Uber was redefining GPS or like doing any research on GPS for it to not be a rapper.
It was about the like difficulty of reproducing. And so the criticism on, oh, you just built a rapper
is about, well, anyone can spin up a rapper faster than ever. And that's especially true in the age of
like using something like a cursor or a windsurf where we have these agentic kind of coding ideas
that can spin up an interface for you really quickly. So I just wanted to touch on that because
I think a lot of people talk about this rapper criticism. Where I think things are today,
it's incredibly difficult. I was talking to my old, um, I was talking to the person yesterday,
my friend, Tom White, who was general manager of Japan and Korea at Uber, who I worked with really
closely. He's doing like an AI masters and we were discussing, you know, where the future is going,
where the economy is going. And, um, he's much more like conservative on the pace of change,
which I think is fair. Whereas I kind of bounce between one, like it's so over because like,
there's no software that's going to exist anymore. Because if these AI companies can figure out how
to train these models to automate all these workflows and all of these different domains,
like it's just going to be so easy to spin up some kind of front end that you don't even need an
external software player, right? You can just build it yourself in like five minutes.
Um, and then the other side I oscillate to is, well, society just progresses so incredibly
slowly. There's so much inertia in a lot of industries, right? There are like so many companies
that don't even operate on cloud. Like they're still operating on-prem. There are hospitals that
should be using algorithms to help detect cancers, but because of inertia, we don't do that. And so I
oscillate between like, oh my, like, it's just going to be so much inertia that it's going to go much
slower than expectation to, oh my God, it's completely done. And the reason I set that context
is because I just don't know, like my, my best bet recently has been focusing on a specific domain
because at the end of the day, it has historically been very difficult for a large horizontal player.
Let's take like a Google, for example, to compete with the company that's hyper-focused on a problem.
Um, and you see this in a bunch of examples. Um, what's a good one? Like a company where they just
double down on a specific part of an experience. Um, like you see unbundling, for example, if you
have like a, like a Salesforce, right, they might have their big CRM, but then they don't actually do
what a VC wants. So then a VC, like a company comes out with a VC specific CRM, or they're not
actually very good for small businesses. So they bring out, someone brings out a small business CRM.
It's very difficult for a very large player to coordinate themselves, to compete with all of
those instances of what people want. And so that's why I've focused on like, okay, you're building
something domain specific based on your specific knowledge. And it might be in something really
boring. Like the Vuma guys, for example, are doing like invoicing for logistics companies.
It's like relatively untouched area, a Google or someone probably doesn't want to focus on
that specific niche. And so they can build something that's like beautifully tailor-made
for that particular problem. And that's going to really appeal to customers. What I don't know,
and why I'm hesitant to say that's the be all like strategy is yeah, if, if these like frontier model
providers can build a model that can see a workflow and like very quickly reproduce it,
I don't know where anyone can hide.
Yeah, that's super interesting. I do think there's a lot of opportunity in thinking about what the big
companies are not going to touch because they're such low hanging fruit. But then again, what you
just said, it's like, well, you can just reproduce things so easily in the future, maybe they'll touch
everything. Sort of tangential to this thinking about like, what company is going to win. So you
had a few AI insights from a blog you wrote a while back, and we sort of touched on one of your insights
as data is a potentially overhyped mode. Another insight you had was about the importance of distribution
in the AI world, which was saying that go to market and sales are going to become more critical
than ever before. Is that a belief you still hold? And if so, why?
Yeah, no, that's a great one to dig into. I still think a lot about that one. The reason being is,
well, firstly, I'll give a quote that I've said so many times. So apologies to anyone who's heard it
before. But there's a VC called Alex Rample from Andreessen Horowitz. And he said, the difference,
the battle between the startup and the incumbent comes down to whether the startup can get
distribution before the incumbent gets innovation, right? And so the main thing that I'd say that
startups have always had is speed. And they've been able to build something that people really want
in a very quick matter of time and adjust to kind of technological changes to get something out into
market. And that has enabled them to like chip into the market share of really big players that
haven't been able to innovate and produce something in line with what people really want.
I feel like that's possibly a little bit different these days where maybe a really big company can
innovate by like quickly plugging into an API, for example, like an OpenAI API or an Anthropic API,
and kind of like quickly inject some of this like innovative capability that these startups are
building. Now, I'd still say that they're probably not going to build, like rebuild their products in a
way that's truly thinking from a perspective of AI first, which is what a lot of people want. But
still, they're perhaps operating a little bit faster in terms of that. And so that puts us in a world
where incumbents possibly have, they always have the distribution because they're the existing player,
and they now have a bit more innovation. And so I think that just makes things a little bit more
difficult from the perspective of a startup. There's also the fact that like, if it's easier than ever to
create technology, a la like a cursor or a windsurf that does a lot of it for you,
what's your point of differentiation? Well, it's not like pushing out an app, or building an app that
people want. It's actually like, how do you get that in front of people? And how do you get people
to stay with your app, when actually, they could go to cursor and like build it pretty quickly
themselves. And so the it comes a lot more about distribution in that case. Where do you think
are kind of greenfield places where people can get distribution? Because obviously,
a lot of distribution has become gen AI led. And you can argue that that's not great distribution,
we've all scrolled through LinkedIn and seen just how much crap is on there. AI outbound has been kind
of almost commoditized with like, you know, everyone using these tools that will generate outbound,
it sounds kind of human isn't quite there. Now we have, you know, phone outbound, a lot of SDRs can call
people now. Where do you think of those opportunities in distribution?
Yeah, I feel like go to market and distribution are probably my weakest areas historically as a BC,
like my colleague Jethro, for example, is like brilliant on that front. So I'm not super strong
there. I think hopefully, if you're building in a niche that's small enough, you're like, it's not as
hard to get to your customers, right. So for example, if you're selling like a protein powder on Facebook
today, the cost per click would be so astronomically high. Whereas if you're selling something like
super targeted that you're not getting a lot of click competition on, like it's going to be a lot
cheaper. That's my like main thing, like drawing back to the domain specificity. But yeah, I don't
know, like it's very much not my kind of forte. Something you mentioned before, which was around
like really understanding a problem space and kind of building with a customer. I think that a lot of
people are talking about the FDA model, the forward deployed engineer. We had Steve Hein from Lorikeet
talking about this last week. And I feel like again, when I was in VC, anything that seemed consulting
esque was immediately a no no. And now I feel like a lot of the best companies that are emerging
do feel like that in the first kind of 12 to 18 months, because they really understand those workflows
as well. And, you know, a company like Cuttable, which is in Squarepex portfolio, I think that's a
really great example of that, like really understanding agency workflows and figuring out
where do we keep smart humans slash where can technology do a better job and really making those
specific. And it feels hard. That feels like a very human thing. It feels like a thing where if someone,
the way someone reports on a workflow wouldn't actually be the same as when you actually sit there next to
them and watch next, next to them and watch them do it. And that's maybe a space where the models
won't play for some time. Maybe. I mean, if you think back to my example about the computer use
style products that are watching people's screen, like they are seeing what people are doing. Right.
And yeah, there's a question of like, do you need a description alongside that? Are there offline
things that are happening that the model doesn't get exposure to? And again, for those kinds of cases,
you have these model, like these frontier model builders, physically having like teams and teams
of people trying to replicate that. So you might be familiar with ScaleAI, their business model is
basically like, for example, an open AI might come to them and say, hey, what I really want is to build
this, like enhance our models capabilities around medical workflows. And so ScaleAI will go, okay,
great, we're going to go get you a heap of doctors. And they go and effectively recruit a bunch of
doctors to sit there and produce data that's applicable to that workflow. And so even if
the model's not picking it up on a computer, which is the more scalable way, they are kind of throwing
a lot of people at the problem and they have the money to do so. I read somewhere that they hire like
600,000 people sometimes overseas in like 200,000. It was a ridiculous figure. Yeah. Yeah. To data
tagging itself. Yeah, exactly. Yeah. So they were, I think from memory, the company started in data
labeling. Yeah. So particularly for autonomous vehicles. Yeah. And now they've moved to kind of like
data creation. Yeah. Wow. That's like a exec recruitment company. Yeah. Thinking a bit on
the topic of like social unrest, potentially as off the back end of AI, I know you've had a few
tweets about that. It is a bit of existential angst. I think what's scary about this is that on that
inertia point, if I think inertia will always exist. So there's going to be a large majority of the
population that doesn't touch, doesn't play around, etc. And then there's going to be the small groups of
people that are the people that we follow on Twitter that are using this to the maximal extent.
And the amount of leverage that they're going to get from an AI is just so much more than previous
technology cycles. Yeah. Because in the future, obviously, we're all going to have these agentic
workflows where we're just going to have copycats of all of us and different people. And potentially
that creates the sort of the delta between the person that's in the know and the person that's not
is so much larger than ever before. So what do you see is the implications of this and how do you feel
about any sort of social unrest in the near future? Yeah, this is also what I was debating with my
friend Tom about yesterday, because I was basically trauma dumping all my anxieties around this onto
him. And basically, yeah, saying that I'm very anxious about this, particularly if you grew up in
an environment where you didn't feel a lot of financial stability. I think people I talk to who have
always felt a lot of financial stability are not that worried because they just expect that that will
continue to be true of their future. Whereas I don't necessarily expect that. The thing that worries
me is I think there's this idea that so long as AI can't do things like manual labor or like really
specific tasks, it won't impact social cohesion. The reason that I'm a little bit anxious about that idea
is because I think even if AI manages to take a small percentage, like a small absolute percentage
of the total number of jobs in a given labor market, it could have a material impact. So something I've
been wanting to do more research on, for example, is like what happened in the Rust Belt in the US.
And from what I've read so far, I think it was between the 1950s and 1990s, they lost about 4% of the total
number of American jobs due to the offshoring of that kind of work being done in the so-called Rust Belt.
And that's a very memorable part of America's history. And people still talk about it today,
and it caused kind of social unrest and a change in the social fabric in that part of America.
And that was only 4% of total jobs, right? That's a small number. And then you talk about,
well, if this first version of AI can attack knowledge work, which is 40% of the Australian economy
and a pretty similar amount of the US economy, that's a 10x, like an order of magnitude impact.
And so that aspect worries me. And then if we can get things like reinforcement learning working
better and better, feasibly, I think we can get robotics working better and better. And then you're
starting to lose the kind of non-knowledge, like the physical jobs as well. And so that's what freaks
me out. And also where you look at something like the Rust Belt, where it occurred over like 40 to 50 years,
I think this feasibly would occur a lot more faster. The Rust Belt involved like very physical
processes. The knowledge work that we might lose is very digital. And so you can replace them and
change them much faster effectively. So yeah, that's what freaks me out. But on the other case,
right, like in the conversation I had with Tom yesterday, he thinks that, yeah, people who are very
close to the tech over assume how quickly society moves, right? And when kind of not in the details of
like how much inertia there is in like parts of the world outside of technology, which I think is
very fair.
Yeah. I think also what's worrying was that I feel like any of the conversations that were happening
around the ethics of fast adoption are not going to happen as quickly now because now China is a major
player. And now it's become like a geopolitical battle. And now it's more like, let's go as fast as
possible because a lot of Americans think that beating China means protecting the Western world
and, you know, liberal democracy and all these values that we all hold true. And so it feels like
any of those conversations aren't happening anymore. Now it's like, let's go faster. Let's spend more
money. Let's not have any arrogance that we're winning this race because Deep Seek is extremely
impressive, but then the whole ethical conversation becomes in the back end. And yeah, I think it's
technology is like what 1% of GDP, but human capital is like more than 20% of GDP. And as you said,
a very important part of the Australian economy. And there's also like the whole point around like,
even now, a lot of economies like the Philippines that rely a lot on EAs and offshore labor, a lot of
that stuff can already be done by agents. Yeah. And these are already countries that are developing.
What happens to those people? Yeah, no, it's really scary. I think I'd just say on the like,
maybe people pushing safety and AI ethics and alignment to take a back step. I think that was
pre Deep Seek. Yeah. And that yes, absolutely. The interest in going faster is something that will push
it even like marginalize it even further. But it felt like there was this run up to the election
where we saw kind of like tech elites moving further to the right and kind of positioning safety
and alignment on this spectrum against speed, the whole like EAC thing that Andrewson was talking
about. And so that was kind of in motion already. And so, yeah, this is just, I totally agree with you
though, that like, now we feel like we're in a geopolitical race. It's like, well, we need to move even
faster and put even more capital into this thing. But yeah, also, I agree with you that I am really
worried about how it shakes up, shakes things up, whether that's in Australia or more developing
countries, the kind of work that we rely on every day. Yeah. And I don't mean to be a doomer. I feel
like when I talk about that, people are like, oh, you're like some kind of doomer and things that
it's not, I don't think I'm a doomer. I just want to talk to people about what we can do to protect
ourselves and our economies. Yeah. And from your perspective, what does AI safety practically
mean? Is that limitations on the amount of parameters in the model? We were sort of talking
about that before. Would it mean like limitations about the amount of capital investment? What do
you think? I don't have a strong view on that more because I haven't focused on that because I feel
like there's a lot of really smart people already focusing on that, maybe fewer at the moment because
of the kind of cultural change that's occurred. But yeah, that's not been my kind of domain at all.
Again, I focus a bit more on the like, or have more of an interest on the economic implications
because I feel like there aren't enough people focusing on that. And I've actually been asking
around to my friends at the frontier labs, like who's writing stuff on like what the economic
implications are. And they're often like, gee, I actually don't know. There aren't many people
solving that, which is really scary. So yeah, I don't have any good answers for you on safety. Yeah.
When you talk to your friends at the frontier labs, what is occupying their minds like right now?
Yeah. The fascination or the need to be first, I'd say need to be first with this idea of like
a fully capable remote worker to kind of be able to do that knowledge work. And they absolutely feel
that the path there is to producing more of this data to go into these RL models. They kind of, it's,
it's a bit interesting, right? There were, there was a phase where we knew that, or people felt that you
could continue scaling the model and you would get returns on performance in, by doing that.
But we weren't fully sure if that was the only path to AGI, if we needed different architectures
or different techniques. Now it feels like the mood is, we actually feel like we have a very good idea
of how to get to AGI, but we just need to kind of execute on this like RL work and feeding it with
the right kind of data, which is a different vibe to, oh, we just need to focus on like figuring out the
ways to, we need to scale it and kind of productionize it and yeah, feed it.
What is the, the human become in the AGI world? Like, what do you think are the important parts
of being human? A lot of people talk about creativity and the arts flourishing. Do you have a view on this?
Uh, something I've been asking friends as well. I don't have a good view. Um,
yeah, I, I don't know. I'm, I haven't figured that out to be honest. It's really hard,
right? To think that far ahead. It feels like such a, um, an experience we can't really relate to.
Like almost all of us would have had work and work's been part of our purpose. And obviously
family's been part of our purpose. The idea that we kind of don't have work, um, is like liberating,
but also I think a little bit scary for people and it's, yeah, I don't, I don't know. I don't have a
good answer. And tying this back into the role that you've just stepped into, what are you going to be
diving into in AWS and what are you excited about sort of learning and uncovering there?
Yeah. Um, what I want to focus on and what excited me to come across to AWS is the idea of working with
people who are building at the lower parts of the stack. Um, while we spend a bit of time talking
about building kind of software and whether you're building wrappers or domain specific stuff,
I get most excited about talking to researchers about the kind of big problems that need to be cracked.
Right. And so being AWS enables me to do that because they see this like full spectrum of
companies, whether it's the fact that they build chips or they work with foundation model providers,
like they're very close partners with Anthropic and Mistral, for example. Then they of course have
the startups building AI native software, and then they have the big old enterprises that are
incorporating AI. They see a bit of everything. And so it's really cool to have that kind of perspective.
Um, but yeah, just being able to double down on talking to researchers and hopefully finding
some folks that are doing like exciting research that pushes the frontier forward. I think for me,
part of my restlessness was like, holy moly, these people are building the future at this,
in these like frontier model, um, companies. How do I kind of be part of building the future and get a front
row seat to all of that change? And yeah, I want to be working with those people and I want to see
the kind of aha moments, like some of the founders that I talk to most who are researchers and have
research teams. It's so fun when I jump on a call with them and they're like, Casey, we discovered this
like genuinely transformational thing. It's like going to change the way we think about scaling models
or whatever. Like that is just so fun. Um, and I'm really excited about that because yeah, they're building
the future. Right. Did you ever think about moving to SF because it seems like, you know, all the
researchers there, they know each other, they go to parties and you know, the amount of information
just sort of retrieval there. It's like, it happens really quickly there just from being in the know
and knowing the right people. Yeah. I'm my director sees my role as like relatively global despite being
based in Australia. So I'm going to spend about a month in SF in March because I'm going over there
for Nvidia's GTC conference. And then I'll be in Singapore for ICLR, which is a big ML conference.
And so I will hopefully like be actually spending a lot of time over there while still hopefully
helping to build like what's going on in Australia and APAC. Yeah. But totally.
You're really across all the resources. I've seen on your ex, you spend a lot of time consuming
information. It's so hard to predict where things are going for founders and people that are interested
in the space. What are like the key resources you recommend staying up to date with or learning
concepts that they need to understand? Hmm. What I would recommend instead of resources specifically,
what I've done that's given me the most leverage is actually create a Claude project and you can give
it a system prompt. I think it just calls it like instructions or something. And I wrote in there,
like you are a world leading expert in deep learning from Stanford and you have an electrical
engineering background and you're familiar with some of the kind of world leading techniques
around building foundation models. And I just like ask it like any kind of question or term that comes
up that I don't know. I'm like, explain this to me like I'm a preschooler. And then it tells me
something else I don't know in that part. And then I just follow that. Personally, for me, that works best
because I'm very curiosity led. Other people, of course, might learn in a different way. I did on X, like
I've compiled a thread of all of the different like learning resources I'm coming across. Yeah.
But again, it really depends. Like some people just are not titillated by the technical details.
And so the kind of stuff that I'm sharing on my X is like, how do you build an LLM from scratch and
stuff like that? There's people that aren't interested in that. And in that case as well,
like Claude or any of those LLMs can be so useful for just having it step you through this stuff.
And there's some really great resources on YouTube, of course. I think it's three blue,
one brown or whatever it is. I always confuse that. The great YouTube channel. Andrea Kapathi
has a really great channel. He just did like a three hours, like everything you need to know about
LLMs video the other day. So yeah, probably like YouTube and using the LLMs, but it really depends
on your learning style. And I'll also shout out your newsletter, artificial intelligence. I think
that's either right, learning device. And I think you should write more as well. Like I sort of ran out
of reading all of your blogs, but I really enjoyed it. Yeah. I'm kind of, um, yeah, at a funny spot.
If I, I wanted to like refine it a little bit more in terms of how I stepped through what I'm thinking,
but that put a bit too much pressure on myself to write. And then I kind of stopped writing.
Whereas when it works well, it's just kind of like, here are all the things I recently learned about
that kind of learning in public kind of mode. And so I'm a bit like, should I, yeah, I'm still figuring out
like where to take it. Right. It's historically just been a journal, which is why I call it like
the rumination series, but I would love to turn it into something like a bit more structured and
strategic. I really love like Ben Thompson, actually. Like I think if anyone wants to think
about strategy and technology, they should be reading Ben Thompson's religiously. And I love like,
um, Matthew Ball, for example, who's a little bit less known, but his writing is really awesome.
Yeah. And I also shout out Dwarkesha. I think he's pretty incredible because you can tell
he's friends with all the living researchers as well. So he's like right in the middle of like
the hub where everything's happening and he's writing about it. He's doing podcasts.
Yeah. Yeah. And like, the guests that he gets on are just huge.
He's awesome. Like creators of Google Brain on just the other day.
Yeah. I saw that.
People from every frontier company.
Yeah. I think, yeah, I really love Dwarkesha's stuff. It's probably like a bit dense if you're not
really getting into the details. Um, but yeah, he's really awesome. He's got a lot of gravitas,
that guy. I've met him a couple of times and he's just like very, like, I don't want to say he's too
serious because that's unfair, but just like, yeah, very low, a lot of gravitas for someone
who's like 24, but he's really cool. Yeah. Well, cool. I think that wraps up the episode,
but that was a great one. I think there's so many great AI insights there and it'll be really
interesting, obviously to see what happens over the next year with all of this and to sort of
compare our notes and see what we got right, what we got wrong.
Yeah. Yeah. Yeah. For sure. I'm really excited, but also anxious as a mission.
Thanks for coming on the show. Thank you.
Yeah. Cool. That was awesome.
That's a wrap of this week's podcast and we hope you enjoyed it.
The way you can help us is by hitting that subscribe button, because then we can get
bigger and better guests and level up our production quality.
So you have a better time listening to the show. See you next week.
