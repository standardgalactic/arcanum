there are a lot of people who have a
resistance to this kind of change and
and the resistance comes from this the
Baseline assumption is that there is
something that is natural meaning
meaning this this kind of embodiment is
the way that things were supposed to be
and also everything is cool so don't
mess it up this is what we hear a lot as
scientists like don't don't screw things
up everything's great don't screw things
up there's there's two problems with
that with that view first of all I I
think as as we can all tell with a
little bit of reflection things are not
great
so I I I I'm not even a clinician and I
get probably five emails a day from
people in the most unbelievable
biomedical suffering right you can
imagine right so so my kid has a birth
defect uh you know pediatric oncology
somebody lost a limb like you know aging
degenerative disease I mean it's it's
insane and and so and so the first thing
is that the things are absolutely not
okay and the second thing is that this
idea that that there is some kind of a
natural uh scenario that we are in now
that was I mean back in back in the day
you could we we could we could forgive
people for saying this was all sort of
provided by a by a process that cared
for us and our values and this is how
it's supposed to be I think I think
we're we're out of that out of that
category now and I I I think I think
saying that we are going to try to stick
to the status quo of the trial and error
process that we've been Meandering
around and and letting the letting stray
cosmic rays hitting our egg cells decide
what our embodiment is going to be and
who's going to have a birth Def and
who's going to you know but but but
everybody's going to have an IQ that's
limited to you know whatever the top of
the current IQ is and a lifespan this
this is this is I I think this is
completely
untenable this is Daniel fagell you're
tuned in to the trajectory and we're
bringing back the worthy successor
Series today we speak with none other
than Michael Levan uh Michael is a
developmental biologist at tus
University uh and it is safe to say that
there are very few people who've opened
up my mind anyway to the state space of
possible Minds in a more concrete way
than Michael 11an in terms of what
substrate intelligence sits in does
intelligence egress into the world or is
it built in some way shape or form um to
say Paradigm shifting would be maybe
even an understatement in terms of
Michael's body of ideas I have
tremendous respect for what he has to
say and when it comes to word successor
that is to say an intelligence that
maybe should take the Baton from
humanity and kind of carry forth um I
knew it would be important to get his
perspective in this episode he does open
up sort of where he sees intelligence
going where he thinks it maybe should or
shouldn't go and what are the kinds of
traits he would hope to see in such an
intelligence which is what we cover in
the worthy successor series if you
remember Nick Basham and yosa Bach and
all the other great episodes we've had
we run into some parts of Michael's
thinking that were extremely confusing
to me we didn't get to unpack everything
I'm going to save my thoughts for the
end of this episode but there were some
things that surprised me and I couldn't
make the jump from and I have so much to
think about so I'm GNA save that for the
outro and I'm G let you enjoy this
episode with Michael without further Ado
let's fly right in this is Michael 11
here in the trajectory so Michael great
to be able to connect yeah thanks for
having me great to see you of course uh
and we've got a ton to unpack here on
this idea of the worthy successor you've
talked more about the state space of
Minds than almost anyone but you think
about minds differently so as we get
into this sort of dialogue about what
are the kind of morally worthy agents is
a way that you've put it in the past
that that could be conjured and could
proliferate the future in kind of
wonderful ways that that could be
potentially good um you know you think
about sort of the thing and the process
is not necessarily that different and
there's a
tremendously uh uh sort of interesting
body of work you've built even around
the collective intelligence idea you
know the the notion you have these
thought experiments of sort of a cell
waking up and thinking on I'm kind of on
my own or you know sort of uh some kind
of synchronicity happens to oh maybe I'm
part of a bigger system but they can't
realize it same might be the case with
us when we start talking about these
morally relevant agents but we're not
talking about a thing people tend to
anthropomorphize it's like me it has a
brain um how should we even be
conceiving of intelligences before we
even get into this world of grand
morally relevant ones yeah I I think
that uh what what I'd like to do is talk
about the different ways to expand our
initial mind blindness which I think we
really have
because of our evolutionary firmware
we're only calibrated to recognize minds
of a specific scale of specific kind of
embodiment moving around in the
three-dimensional World things like that
so um I'll talk about several different
ways to go beyond that and to try to
expand to more and more unusual kinds of
creatures but the the fundamental fact
to realize is that we all started Life
as a single cell both on the
evolutionary scale and on a
developmental scale we were all a little
blob of chemistry and physics ones and
so the fact that that can transition
into whatever it is that we are right
into beings with a complex metacognitive
um capacities uh that that tells us a
lot about what what matter can do and
and cannot do and so that's that's what
we need to start
with yeah certainly I mean you you speak
a lot about the cell you have you know
videos on your own channel of sort of an
individual cell doing things that we
would assume might be something you know
a rodent would do pursuing food and
chasing things down and whatever the
case may be so
uh there's the cell as sort of a vantage
point for our perspective here there's
also this idea of again process versus
thing and the idea of collective of sort
of there's we're we are a collective of
cells and of course we would say oh I
don't really think that's true you even
talk about kind of a collective of Minds
where you say oh I don't really know
that's true but there's a perceptive
layer that's maybe orchestrating them um
how should people maybe conceptually
think about those frames we're about to
kind of get into again these postum
Minds those frames of kind of process
versus thing you know I don't know how
much white wh head you want to get into
here but uh process versus thing and
then Collective what should people grasp
as we start to go down this rabbit hole
about the ways you've opened up your way
of thinking about intelligence yeah um
the the the first thing well the first
thing to realize is that uh life lives
strives and solves problems in many many
spaces that we do not comfortably notice
so we are evolved to notice middle kind
of uh sized things moving at medium
speeds in threedimensional space and
that's what we think of as intelligence
but uh intelligence was here long long
before we had muscles long before we had
neurons long before we had brains so
even during embryonic development the
process of becoming a becoming a
functional body from a single cell is
not some sort of hardwired chemical
process that should be distinguished
from the mental activity that we have
later that that whole process is already
a problemsolving creative intelligence
and I can give you examples of why
that's true it is a collective
intelligence much like we are we are a
collective intelligence because the
individual neurons in our brains and all
the other cells that make up our our
functional um our functional bodies are
a collective that needs to work together
to give rise to what what we are and so
so that that that ability to take to
take individual subunits and and form
them into a collective intelligence that
projects problem solving capabilities
into new spaces is extremely ancient in
fact it's subcellular there are chemical
networks in your cells that learn and do
things like that this is you're touching
on something extremely important I mean
again I think some people read you know
the selfish Gene and they might say well
by goly I thought it was the rodent or
the human or the elephant or the dolphin
that is itself sort of self-interested
and of course Michael we look at a
company a company will do what's in it
self-interest often even a nation will
so there's all these weird collectives
that sort of they do what Spinosa would
call the cantis right behooving their
own interest to remain to continue to
persist I am going to dive in with
Spinosa a little bit with you today
because after reading all your stuff
there's just so many connection
but we see that manifested in many
stages and then they say gez maybe it
went all the way down to the cell but I
wouldn't have thought it would have gone
all the way down to the gene but then of
course Michael you could ask is it the
guanine does the guanine sort of chant
its own name and behoove its own
interest down at that level or is it
something even below that is it is it uh
is it in those sort of electrical
patterns that sort of guide the
development of of of embryos that the
things that you've studied with worms
Etc like where does that self-interested
impulse line
yeah so so we'll get to the patterns
thing because I want to I want to First
expand cognition in a in in a bunch of
ways and then and we'll get to the
patterns thing but um but but one one
kind of procedural thing is that for all
of these kinds of things I think what's
really important is that we cannot just
say that something is or is not
cognitive I mean there are some people
that will just assume that that almost
nothing is other than brains and and so
on there are other people on the kind of
animist line of things that will say oh
the whole universe is this beautiful you
know and the Sol yes so so neither of
those things can you just say you have
to do experiments and so the way you do
experiments is that you have a system
you make a hypothesis about what problem
space it's operating in what the goals
are and then you do perturbative
experiments to see how much capability
it has to overcome whatever weird
barrier you're putting between it and
its goals and then you get to find out
whether your estimate of its
intelligence was right or or or or wrong
or which way you have to adapt it right
so so when we talk about guanine and and
things like this we have to ask what
would what so so I take I take William
james' definition of intelligence which
is the ability to reach the same goal by
different means that's my definition and
and of course it leaves out some things
such as creative play and and some other
stuff but but for the purposes of of
what we're doing here intelligence is
the ability to get your goals met and
then later we can talk about
intelligences that find new goals and
they find problems to solve as opposed
to Solutions and so on so so for all of
these things you have to do experiments
and you have to ask what what is this
thing actually capable of so so I can
give you you know a few simple examples
uh if you take um a gene regulatory
Network okay so these are just a set of
uh let's say a dozen different chemicals
that turn each other on and off you
don't even have a cell yet you don't
have a nucleus all you have is a set of
chemicals and it's described by a set of
ordinary differential equations that
tell you how each thing is turning these
other ones on and off what we've shown
is that that alone is sufficient for six
different kinds of learning including
pavlovian conditioning just that you
don't need anything else you don't you
don't need you don't need neurons you
don't need brain you know you don't need
anything else the material that our
cells are made of is already capable of
of learning and of course of all kinds
of homeostatic properties that try to
meet
goals yeah I mean well look and and I I
think the reason you're here at least
from my vantage point uh having invited
you is because you do the testing so I'm
certainly not expecting a theory I think
you're you're you're the man that's
testing these theories I think there you
would be shocked maybe you wouldn't be
shocked at just how many of those
theories are banded about as fact
particularly in the world of artificial
general intelligence never mind maybe
the nature of intelligence itself
clearly it must be investigated clearly
and and clearly we're not at the bottom
of it even what you've just mentioned
there very promising to some people
would be quite shocking but it beckons
new questions are there things under
that are are there simpler things and of
course maybe you're planning those kinds
of experiments or other people are doing
them um and we have to kind of keep
poking and proding seeing it seeing the
the the morphological sort of electrical
signals and and seeing these very simple
chem behave in ways that that beho
William James's definition of
intelligence um all of this sort of
beckons
like you
know bigger picture like you have to
decide what to test next Michael and
probably that is based on your best
forming conception of what the hell is
going on uh which which you're you're
you're gradually building through all
these various experiments like do you
suspect it goes lower than the building
blocks you've just articulated yeah yeah
my my and so so my framework call a tam
technological approach to mind
everywhere and uh I I actually think it
goes all the way to the bottom meaning
meaning that uh in in the so so I think
in this universe um there is nothing
that isn't somewhere on the spectrum of
cognition and that's and that's because
if if we ask ourselves what is the
absolute minimum version of of of
intelligence and agency what what is the
smallest assuming that we we believe the
um continuity thesis that that that
these things have to have some sort of
origin and then what we're looking for
is a story of scaling right we're not
looking for Magical emergence of all of
a sudden you know you these these things
pop into being that we're actually
trying to understand how do how does the
alignment of Parts give rise to larger
to to to Collective intelligences with
with bigger cognitive lones and and and
so on so so if we just ask ourselves
what is the absolute minimum I I think I
think we want two things we want the
simplest possible kind of goal
directedness and we want some degree of
indetermined
that where where the thing you're
looking at isn't completely Bound by the
the the immediate physical forces
impinging on it right and and if we and
if we take those two things even
particles have those because of least
action least action principles give you
a very primitive kind of goal
directedness okay and of course and of
course down at the bottom you have you
have some Quantum indeterminancy which
is not a great you know it's not it's
not what you would call the human level
free will of course but but it's a start
right it's it's where these things
actually come from so I think um I think
we could say that that it goes all the
way to the bottom but what I'm mostly
and and and I have you know and I have
asked physicists if if if particles
exhibit certain kinds of hysteresis and
and things like that and so so but this
is outside my my area but once you start
with molecular networks you immediately
have learning capacity you have
homeostatic capacity and even even you
know just pressing something that we can
talk about later something very simple
we found novel problem solving
competencies and uh these little side
quests that are outside of the algorithm
itself in very minimal computer
algorithms we're talking sorting
algorithms like bubble sort and things
like this so so my point is if bubble
sort which is deterministic it is
completely transparent it is a small ALG
you can see all the steps if bubble sort
is doing things you didn't know about
after Decades of you know every computer
science student studying these things
and you know we thought we knew right
everybody thinks they know what these
things
do what these things do is not
encompassed by the steps of the
algorithm anymore than our capabilities
are encompassed by the laws of
biochemistry and so at the very bottom
you already have emergence not just of
complexity not just of unpredictability
but actually of emerging cognition and
that starts very
l i I want to dig into definitions and
we'll talk a pinch about kind of the AGI
transition move right into the the
successor idea but people are really I
think now hopefully getting a grounding
of where you're coming from here um it
sounds like you know the and we're using
cognition a lot you talk about cognitive
light and things along those lines the
you know the Spinosa idea of the cantis
is sort of this idea that that sort of
things have this sort of inherent drive
to persist it's just it's an inherent
shebang if if they're alive they have it
we might argue it was evolved we might
argue it's inherent in sort of nature in
some deeper way for you it's sort of
almost um your your best bet and of
course you're the you're the guy that's
going to go test this not just say it on
a show uh is that all the way to the
bottom floor things are trying to sort
of
persist and not not perish whe whether
it be you know their their pattern
continue whether it be like how would
you describe that undercurrent stuff
that uh that that bubbles for you into
intelligence but like how would you
describe that yeah so so so I'm not sure
that pers I I think persist um the word
persist hides something something very
interesting which is um the Paradox of
change so so let's let's just let's just
look at it at the level of a species and
then we can talk about cognitive
OS um if you're AES and you fail to
change meaning you literally exactly the
same chances are you're going to die out
100% if you do change and adapt to
circumstances you're also kind of gone
right it's something else now right I'm
with you I'm with you so so so so I'm
not sure that that the underlying uh
impetus for all of these things is to
stay the same I think it's something
more interesting than that that we still
I'm not sure we have um you know maybe
Whitehead or somebody had had the right
terminology for this I I I think I think
it's the right kind of change I think I
think everything is fundamentally going
uh in trying to achieve some kind of
metamorphosis into a what I I don't know
maybe you know some kind of a more more
expanded more intelligent I mean there
is an intelligence ratchet that goes
from the very beginning but it isn't
just to stay in place you know it isn't
just persist I'm with you there I'm with
you there um a thousand perent I'm with
you there I and I would I would one
might argue that if they were to level
up with a bunch of cyborg Parts uh so
long as their individual instantiation
of Consciousness had had some semblance
of what it was before they they might
some people would say no that's not me
and that's bad and horrible others would
say no that's uh that's me persisting I
need to change to persist actually you
know we have companies like Nintendo
that started making playing cards and a
couple hundred years later they're
making video games and you know we might
say it's not even Nintendo anymore but
but I I I think um again where the thing
in the process intervene I think is is
uh there's some semantic stuff there but
to your point persistence doesn't just
involve staying the same in Spinosa
terms it's this idea of potentia so
potentia being the entire State space of
powers that would behoove something to
persist and so sometimes that means
growing a hard shell Michael sometimes
it means talking like me and you were
doing most potentia you potentia in
general at least as we know it on Earth
presumably bubbled up from almost
nothing those little chemical Wiggles
you were just talking about and most
potentia I might argue Michael has not
been bubbled into there are things
Beyond Consciousness there are things
beyond all the senses we we can conceive
of and I would argue the vast majority
of possible bubble into potentia um we
don't even have sort of the hardware and
software to have a conversation about it
to imagine it even on the wildest drugs
we could take most of it is beyond our
pale would be would be my firm
supposition I I from reading your work
it strikes me you would agree so Spinosa
has this notion that stuff isn't just
locking in place and growing a shell it
is garnering the powers to P to ensure
that it doesn't perish and that does
mean change it means expanding its
potential species growing would be like
some species of bird now that look very
different millions of years ago that is
its way of persisting it grew a longer
beak it had you know different kinds of
clause whatever the case may be this
expansion potential does this click with
what you're discussing and sort of how
you see this undercurrent impetus yeah
yeah I think I think that's very
reasonable um I'll give you another
example and this uh kind of goes into
this this this this flip that we're
going to talk about between between uh
between agents and patterns or or
machines and data and so on imagine
imagine the butterfly to Caterpillar
transition okay so the caterpillar is
the softb creature right eats eats
leaves crawls around butterfly
completely different three-dimensional
kind of thing uh in order to to to
become a butterfly the caterpillar
basically re completely refactors its
brain so most of the cells are killed
off the connection are broken makes a
new brain turns out that if you train
the caterpillar the butterfly remembers
the original information but but but
here's the here's the interesting thing
so so you might you might say well the
interesting question is how do you hold
on to Memories when your memory medium
is being completely taken apart like
that's interesting of course yes but but
the I I think the more interesting thing
is that the actual memories of the
butterfly of the caterpillar are
completely useless to the butterfly
because because if you train the
caterpillar to crawl in a certain way to
get leaves the butterfly doesn't crawl
and it doesn't like leaves it wants
nectar and so that that memory pattern
is not going to persist if you if you
try to leave it in place what instead
has to happen is it has to get remapped
and and altered uh and to fit onto the
new architecture the new sensory motor
architecture into the new cognitive uh
architecture of the of the of the
butterfly so what you have here is the
uh if if you if you are that memory
pattern and you want to persist into the
future the way to do that is not to
remain as you are the way to do that is
to change so that you are more Salient
to the to the medium of the future being
the butterfly brain and thus have a have
further
expression yeah well this is this is
breaking into the idea of you know I was
just kind of bringing up okay you know
this bird that changes over time you're
saying the memory within the bird may
have this same canatal like uh impetus
to want to persist and you've talked
about kind of memories as as their own
kind of intelligence or whatever the
case may be um so it it sort of it
strikes me that maybe we don't even
understand well we don't understand what
the what what uh it does seem like
expanding potentia is pretty seems
pretty ubiquitous to me like the the
expansion of potentia in order to to
persist but but to your point does that
exist through um the physical medium you
know the guanine does it exist through
the species does it exist through the
memories how are those overlapping is
there one that is obviously Supreme
driving it all it strikes me that we
literally don't no um and and of course
you're testing these things but it
sounds to me like they need to be tested
yeah um it's and and this is
encapsulated by um James had this had
this line in in his book uh thoughts
thoughts as thinkers okay so so we tend
to have the assumption that we know who
the Thinker is and that's the the the
the Living For example the living agent
or in the computer science terms that's
the machine let's say the touring
machine or the computer whatever we know
who the agent is and then we know what
the thoughts are the thoughts are the
patterns the material patterns of energy
and information that are processed by
the machine so it's the information on
the Turing tape it's the physiological
patterns that are going through a brain
when the when the agent is is thinking
right so so the standard view is that
the data are passive that the agent does
all the work and that uh The Thinker is
the is the is the real is the real agent
and then there are thoughts that you
know so I want to so I W to I want to
break that in two ways and and if we
break it then then we can see uh kind of
a radical expansion of the Sea of
possible Minds around around us and
we've already just just to to start up
we've already broken it so so initially
people think brains so I say no actually
all cells in the body all the tissues
are actually doing um doing some of this
kind of thing then then then I say
actually it's not just the Biologicals
it's also potential potential
technological and and hybrid and Cyborg
and all all these kinds of things and
now I'm saying it's it's even it's even
bigger than that it's a it's a bigger
kind of infinity than that it's it's not
just a physical object that the patterns
I'm going to tell two two quick stories
to kind of make that make that seem
plausible the first is a kind of a
science fiction story um modified I'm
sure I'm sure this youed was a story
that I read when I was young and I don't
remember who wrote it so apologies for
that uh imagine that that these um
creatures come out of the core of the
earth okay they live in the core they're
incredibly dense they come up to the
surface they're walking around they've
got they've got gamma ray vision you
know because because that's what it
takes to see down there they're walking
around what do they see well as far as
they're concerned the surface of the
Earth is covered in a very thin gas it's
almost a plasma they don't the stuff
that we have that looks solid to us this
is not even you know it's it's barely
registered they're walking through it
they're disturbing all of our stuff the
way that when we walk through a garden
there are patterns of of of scent and
things that we just walk through them
you know swirl I mean they're just just
walking through it and one of them one
of them is a scientist and he's got this
he's got this this equipment that lets
him look at patterns in this gas that
surrounds the planet the the gas being
all the stuff that we think of as
physical so he looks so he looks at and
he says to the others he says you know
I'm looking at this gas and there there
are patterns in this gas that kind of
you know hold themselves together and
they're almost agential they almost look
like they're doing things and and the
others say to them well that's well
that's that's crazy we're real physical
objects patterns in the gas can't be
agents and right the patter the gas is a
medium of okay you've noticed some
patterns but but they're not things
we're we're things we're we're thinkers
this is this is right and and so and
they said well well how long do these
patterns last well about 100 years ah
well that's nothing interesting can
happen in a 100 years so um that reminds
us that the degree of of who who is a
pattern and who is an object is very
much in the eye of the beholder we are
temporary metabolic patterns right I
mean we are we are like like like
hurricanes and solons and and all these
other you know temporary um uh uh self
self- persistent objects we are just
patterns in this media so so so Lo the
logic is very simple if if we are
patterns metabolic and and energetic
patterns in an excitable medium and we
are agents one immediately starts to
wonder what other patterns in what other
media are also potential Minds right and
and and the last and the last piece of
this is let's just let's just think
about so now so now so now this is going
from the from the Thinker part and and
and widening that let's go from the from
the thought part here here's a here's a
spectrum you you have your fleeting
thoughts these are patterns that come
and go and then they're gone okay these
these fleeting very temporary kind of
thoughts then then we sometimes have
persistent thoughts persistent thoughts
are hard to get rid of you you have them
they're they're they tend to sort of
they do something interesting they do a
little bit of Niche Construction in your
brain because certain kinds of
persistent uh intrusive and depressive
thoughts actually modify your brain
structure to make it easier to have more
of those thoughts okay they they they
they alter their environment their
environment being your brain they alter
their environment to to persist to to be
to be easier right to be easier to to to
uh to extend into the future and to have
to have a longer longer experience then
then you have something bigger than that
which are fragments in in the S
fragments of of a of a mind in the sense
of a dissociative identity disorder so
these are not full-blown human
personalities but they're a lot more
than a than a persistent thought they
have the ability to first of all
generate their own thoughts so the they
become a thinker that has its own
thoughts and they have some limited you
know limited ability to function so so
you have fleeting thoughts persistent
thoughts personality fragments then you
have a whole fullon human personality
and then you know people talk about
transpersonal things I I don't you know
I don't know so so now so now we see
this whole this whole business of of
who's a real agent and who's just a
pattern is is is is not absolute and so
now we need to consider all of those as
things like the memories in the
caterpillar butterfly that might want to
persist but they can't persist unchanged
they have to take over new real estate
and adapt exactly well this is your the
idea again um I think we're congenial in
this idea of persist as maybe implying
change uh could could imply taking on
new powers could invol involve just kind
of taking a different shape as maybe a
memory does in a caterpillar um but
clearly a vastly open State space of
what intelligence actually is what
spaces it occupies how big a collective
or individual it is and now people have
gotten to see some of maybe what they
know of Mike 11 with a little bit more
refinement now I want to take us into
the meat and potatoes of the main the
main issue around the question here
which is knowing that that's where
grounded let us imagine now you are less
anthropocentric than most uh which is
delightful uh in my opinion um you you
see Futures that are not just Eternal
homed kingdoms uh I will say that's
outlandishly rare let's just say I don't
care if it's a million years 10,000
years 10 million years doesn't matter
pick your time Horizon you look down
upon Earth or maybe the Milky Way
broadly there are no more opposable
thumbed you know uh deodorant wearing
you know hominids uh walking around
making mouth noises like you and me are
anymore they're they're not here uh as
as things you know as lucre said you
know there's matter and there's void and
then there's change and you know that
that just kept happening but it but when
you look down you're actually quite
happy about where things are you look
down and say you know it was kind of
neat to have humans and maybe you even
are a little upset about it but on the
net you're like this is actually a good
situation this is what I would have
hoped would happen with the bubbling
processes of intelligence all around us
what would that scenario look like for
you yeah um so so so let me talk a
little bit about some some background
because uh I I think I think the
background is is more important than my
you know personal you know wishes of of
of what what I see I mean I'll get into
that but but let let me give a little a
little background um there are a lot of
people who have a resistance to this
kind of change and and the resistance
comes from this the Baseline assumption
is that there is something that is
natural meaning meaning th this this
kind of embodiment is the way that
things were supposed to be and also
everything is cool so don't mess it up
this is what we hear a lot as scientist
like don't don't screw things up
everything's great don't screw things up
there's there's two problems with that
with that view first of all I I think as
as we can all tell with a little bit of
reflection things are not great so I I I
I'm not even a clinician and I get
probably five emails a day from people
in the most unbelievable biomedical
suffering right you can imagine right so
so my kid has a birth defect uh you know
pediatric oncology somebody lost a limb
like you know aging degenerative disease
I mean it's it's insane and and so and
so the first thing is that that things
are absolutely not okay and the second
thing is that this idea that that there
is some kind of a natural uh scenario
that we are in now that was I mean back
in back in the day you could we we could
we could forgive people for saying this
was all sort of provided by a by a
process that cared for us and our values
and this is how it's supposed to be I
think I think we're we're out of that
out of that category now and I I I think
I think saying that we are going to try
to stick to the status quo of the trial
and error process that we've been
Meandering around and and letting the
letting stray cosmic rays hitting our
egg cells decide what our embodiment is
going to be and who's going to have a
birth Def and who's gonna you know but
but but everybody's going to have an IQ
that's limited to you know whatever the
top of the current IQ is and a lifespan
this this is this is I think this is
completely untenable so I think so I
think if we give up the idea that that
where we are now uh is some sort of a
some sort of an Optimum right and and to
me looking forward I mean here here's
here's what I see when I when I look
into the when I look into the future uh
I I see I see you know how um when uh
when you when you when you do history
with with your kids you know at some
point you know everybody figures out
that oh my God it's like you could you
could you could step on a on a sharp
stick and and then you would you would
just die just just die and if you had if
you had a tooth infection or a bad you
know bad Vision just just just gone
right so so so what I see in what I see
in the future is is people studying how
we lived and just not even able to
comprehend I mean you know you're
telling me that that people were born in
an embodiment that was just randomly you
know sort of picked by by accident and
whatever and you just had to live your
whole life in that one embodiment and
you couldn't change like how is that
even how is that even possible and and
and your you know and your and your and
your hopes and dreams and your full
potential was limited because no one
knew how to get to a you know to a to a
higher IQ and and right and and people
had to um people had to kill other
living things just to survive I mean
this is this is just craziness right you
you had to eat never never mind if it's
plants or animals whatever like
everybody had to had to consume life in
order to to to to keep going I I think I
think a mature you know a mature life
form is going to look back on all this
and be horrified the way we are when we
think about our our primitive you know
Origins well and we're going to go
significantly more into that the whole
uh I mean definitely preaching to the
choir about change here uh Michael the
entire premise of the show is that there
is a grand sort of trajectory maybe not
already preset it might be but it might
not be and if and if it ain't um we
should talk about it and and find the
panop of positive Futures to pursue and
they certainly involve eventually no
more deodorant and opposable thumbs and
I think buckling up for that is sort of
like what you would do if you were
honest and and that's the purpose of the
show uh so with that said you've talked
about moral agents and you brought up
kind of anecdotally in a previous
interview like first-person experience
and you know they can solve problems but
conceive of new problems which is kind
of expanding potentia right would imply
you can do that um and then also uh
maybe maintain some degree of autonomy
in in being in charge they wouldn't want
to be a puppet or whatever the case may
be that was by no means a complete list
it was a smattering of a couple of your
interviews
um what are the other traits you would
say for said entities and I think your
conception here is these could be uh
patterns these could be existing in
weird wavelengths we don't have census
for so uh maybe it's regardless of form
the traits what what would those what
would those be for you if you look down
and said that is a worthy successor what
the heck are its traits yeah I I I can
think of a few things I want to focus on
I I'll I'll talk about this one first
which is um the the what what you might
call the cognitive lyone with respect to
compassion so so so just to to to back
up for for for a minute um the cognitive
lyone is is a is a a framework that I
developed I know four or five years ago
to be able to think about very very
diverse kinds of intelligence in the
same uh in the same space it's the what
it defines is the size of the largest
goal in terms of space and time the size
of the largest goal you can pursue it's
not your sphere of reach it's not your
sphere of sensing you know the James web
telescope has this incredible range of
sensing not talking about that I'm
talking about the size of the biggest
goal you can pursue so if all you care
about is the the local sugar
concentration in a in a you know 20
Micron little piece of SpaceTime you're
probably a bacterium if if if what you
can manage is a concern over over a few
hundred yards and you know a few days
back maybe and a and and a couple days
forward you you might be a dog okay
you're never going to care about what
happens three months from now in the
town over it's just not possible if
you're if you're interested if if you're
if if one of your goals has to do with
where the financial markets are going to
be 100 years from now you're probably a
human or or you know World piece or
things like that right so longer than
your own lifespan very large goals in
terms of space and time so so what I'm
really interested in is the the your the
the ability to have compassion for other
beings because if we think about what's
going on with humans we have to my
understanding we have the ability to
care literally care about some number of
humans in the line range that number is
not large so if somebody says to you you
know there's a there's there's there's
um uh a thousand people suffering and
then some and then they say no actually
actually it's 10,000 you're not 10 times
more disturbed by this right it's kind
of we like we like Peter out pretty
quick you know for for most of us and if
you had somebody that literally was able
to care about let's say all the living
beings on the planet for example in the
same way that we are able to care about
some small number of children and and
and parents and friends and so on you're
not talking about a standard human
anymore you're talking about some kind
of body satwa that has that has in
expanded their their primary uh uh
Horizon of compassion in a way that is
not reachable for us now so so one of
the things that I would like to see
right the obvious things are you know
intelligence and plasticity and the
ability to change yourself in light of
new new goals and what like like that's
all great but I think that really
fundamental to all of this not not just
not just raw intelligence it's the um
the ability to to to muster benevolent
compassion for uh a larger uh radius
than than we can now as standard humans
yeah I want to really poke into this one
here I've heard you bring this up like
it doesn't strike me that there might be
any reason other than self-interest
other than the canus bubbled up to our
Collective human level that we do any of
that like it doesn't strike me Michael
that we're necessarily that close to the
angels if you could go back to 800 BC
right people say like oh I hope AI you
know looks to humans and see how we pay
for how we how we treat our cats it's
like you know how much factory farming
goes into the bowl of Kibbles you're giv
that thing like get the hell out of here
you know how many things you killed when
you just paved your driveway brother I'm
not going to talk about anything else
just paved your driveway like you're
imposing your will on these other things
and maybe at a certain level let's be a
little empathetic with ourselves maybe
it's okay to kill a fist full of
nematodes and roly poly bugs when you
build your house or or an army of of of
fire ants maybe for a house or a
hospital it's actually pretty excusable
we should just kind of deal with it it
doesn't strike me that we're going to
come to some Singularity of everyone
respects everyone like the West folan
idea that emerged at that time will
permeate through all of the weird strata
you brought up these the gases and the
mist and these patterns they're all
going to be like you know what that
homed value right we look through monkey
glasses Michael we everything like love
caring right shoots out of a monkey
skull because like if we didn't have
love and caring we' die so like we you
know you talked about medium size medium
movement probably also like
relationships and love we do a little
bit of an over over tilt on right should
we expect that kind of Crescendo of
kindness and respect to come from
intelligence yeah oh I definitely don't
think you can sit back and expect it I
don't think it's guaranteed by any means
I don't think it's something that is uh
automatically going to happen I think
it's on us to make it happen and I think
that we can make it happen you see the
the tragedy to to me the tragedy of our
current embodiment is that nobody has
their hand off of the trolley switch in
other words what you said about the
hospital we are we are constantly making
decisions because we have we have
limited understanding limited time
limiting limited ability to act on the
world we are constantly making decisions
about what is going to suffer so that
something else can have a better
experience right we we we don't no no
one can be no one can be uh can be and
in the current in our current scenario a
true jist cannot exist right that that's
that's that's that's correct and and
you're constantly uh trying to figure
trying to um apportion your limited uh
uh resources and your limited IQ and
your limited time in the day to figure
out what am I going to focus on and and
you basically try not to think about all
the other things that fell off the cliff
while while you were doing that that
that that is a that is a a true a true
tragedy of of of today is that um
everybody is complicit in the suffering
of everybody else at this point but I
think I think a lot of that and and I
don't know right so here I'm just I'm
just giving my my own personal my
thoughts I I I suspect that a lot of
that is fixable so how much you know uh
for example for example the issue of um
having having having to kill other
beings in order to survive that's an
engineering problem that that isn't a
that isn't a true moral dilemma that's
that's an engineering problem and in the
long term I think it's absolutely
possible that I don't think it's
guaranteed by any means I think this is
something we should shoot for and work
really hard towards but I think a mature
species is one that has graduated out of
this terrible scenario where you are
constantly failing certain moral things
in order to achieve other things I think
by and large there may still be problems
left over that are just you know un
unsolvable but most of the places where
we generate suffering today are are
should be solvable I I'm with you there
and I think you know our focus on qualia
is relevant I think you of all people
are are maybe more uh eloquently have
phrased sort of the states base of
experience maybe beyond what we know to
be qual than anyone else I mean to be
frank you know there was a time when
there was no consciousness you and I
don't have access to the million
magazines and reams of experience that
go beyond what we're currently
experiencing I you know you you've just
cracked open our mind a millionfold in
terms of where in intelligence could go
and I think all of them are valid and
and you're you're like among the only
voices there um uh there's so much like
philosophy that your stuff ties into and
like kind of breaks
down but we're sort of anchoring
ourselves very much to like a hinant
value here which I find really
interesting like it strikes me that in
that total State space of mind it may be
somewhat obvious to the intelligence's X
number of steps forward that occupy
entire uh galaxies or or or what have
you that like the of qualia you and I
are experiencing
like clearly doesn't even matter like
clearly doesn't like like like you know
the fact that I have to you know kill an
animal to feed my cat okay there's a
tragedy I'll give you that but like some
there's some like guanine or something
wiggling around in the dirt maybe not
even wiggling in the dirt and maybe
Paving over that we all would just
understand that's net like we should
just do that it doesn't strike me that
this this sort of
um uh that that it doesn't strike me a
that caring will be the landing place of
the intelligences to shoot off in
directions or even that it should and I
hate to say that but even that it should
like by golly it'd be horrible if if we
didn't change it I I imagine values will
change and also it doesn't strike me
that caring comes from any other place
other than self-interest one could make
a strong argument and in fact the
psychological egoists do that like the
way that we do caring and the things we
care about are the things that
historically behooved our self-interest
and and that if we were snow leopards
having this conversation you would
probably wish to populate the Galaxy
with God knows what Michael snow and
wounded gazel or something um so it
almost this this feels like the most
anthropomorphic part of our our current
discourse I'm not saying it's wrong I
just want to understand your thinking
sure where do you want to take us here
Michael yeah um so so again I I'm not
claiming that necessarily every
intelligence eventually lands in in this
space okay I think I think it's
something we should shoot for I'm not
saying that I'm not saying that there's
some attractor where eventually every
species gets there I I I don't know that
that's the case I'm I'm suggesting that
we shoot there and I'm suggesting that
um a lot I don't know if it's all of
them but I think a vast majority of
these scenarios where you say ah it's a
roly poly you know I got to build my
house everything is underwritten by the
fact that you need a house and your
house it doesn't fight gravity and sits
on the like all right like all of these
things I I I think that ultimately where
we should get to is yes I'm looking at a
pattern an AI a roly poy or whatever
that has a very small degree of
Consciousness compared to me
nevertheless I am in the position to
live my life in a way that really does
not need to impact its experience in the
world I I think I think we can get there
I'm not saying we necessarily will now
now the selfishness now now to talk
about the selfishness thing I I I think
there are there are two ways to look at
this one way to look at it which I think
is the standard evolutionary story
nowadays is this idea that look uh you
know it's it's left over from the
inevitable struggle for survival right
we are we are fundamentally living in a
in a an environment where where energy
and time are scarce and so you're
constantly battling other creatures for
it and that and that uh any kind of
altruism is basically some kin selection
effect or or something like that um that
that's that that's one way to look at it
another way to look at it is yeah it's
selfishness because that's some point
you realize that everything is the same
self in some way so right so so of
course it's it's selfishness because
there's only one of us really okay and
and and I'll I mean I can't prove
anything anything to that effect but but
I'll warm you up in the to to it in in a
following way okay um let's let's uh
let's just let's just look at a single
let's let's say a single a single human
at any given moment you don't have
access to the Past what you have access
to are the engrams that were created in
your body the Memories by past
experiences and every however many
milliseconds you are subconsciously
reweaving a story of who you are what do
your memories mean and so on so so if we
if we stretch out the the time uh
extension of of a of a living cognitive
being what you have is a series of
selves or self flets you know you can
the whole thing is a self you have a
bunch of slices of selfs and these these
uh the thing about these self flets is
that memories and actions are
Communications with past and future
selves so so when I when I try to when
when my brain and body interprets the
memories of the past what they're really
doing is is interpreting a message left
by the past self and if when I do
actions and the actions might be uh to
to throw my car keys out the window so
that at night when I feel like smoking
it it's you know it raises the barrier
and I say I forget it all yeah right so
so people people do this stuff all the
time is is is they're playing these um
yes they're playing these games with
their future self and deforming the
action landscape you know I don't buy
junk food in the house even though every
night I'm like I wish I had some chips
right because because well who who
prevented you from having chips well you
did your past self yeah so so now okay
so so now if if uh if we can understand
that that that your future self is
another in an important sense another
being that has the same relationship
that you have with beings laterally that
is you're sending them messages you're
you're you're constraining their action
space you are you're under undertaking
long um course of of of of study or
meditation or anger management whatever
you're going to do to to improve the
possibility space for your future self
right then now now you have to ask
yourself but what is actually the
difference between my future self flets
and somebody else's future self flets in
neither case are they current me right
in neither case are they now me and it
starts to degrade a little bit that that
distinction that we all have between
each other because and and it really you
know once you once you start I mean
we're not used to thinking about this
way because our normal um uh our normal
reality is that is that very very little
changes from for relatively little
changes yeah we have a little bit of
example you know when you're when you're
a kid and you know you know if you think
about it and and many I guess most kids
don't some some kids do and they think
about oh my God I'm going to turn into
an adult it's not going to be me all the
things I care about now I'm not going to
care about I'm going to care about all
kinds of disgusting crazy stuff that now
I you know I I couldn't even begin to
begin to care about I'm going to have
responsibility I'm going to do that's
that's not that in what way is that
going to be me that's not going to be
I'm going to be gone in in 10 years
I'm so so you know once you start
thinking about it that way the
distinction between you know and and of
course of course that also comes up when
you think about like some traditions
have this idea of reincarnation right so
so so you die what is the difference
between that and well I died some other
kid was born somewhere well that's
that's that right like what's the
difference what is it that makes you you
so so this whole issue of continuity and
it is that um what what are you trying
to do well I'm working now I'm working
really hard I'm grinding I'm going to
the store to get groceries so that
tomorrow me and future me could have a
better life if you're willing to do that
for future
you what is the major difference between
that and future others right I'm tot I'm
totally with you here I mean I I will
expect I will expect you will treat your
children different than other people's I
I will expect even with this sort of
hypothesis which could very well be
right I mean again all this the sort of
there might just be some you know the
emersonian idea I don't know how much
Emerson you read you reference James all
the time but I always think about
Emerson uh um you know holes punctured
in the canvas of the sky we're just a
Different Light Beam shooting through
from from behind the holes punctured in
the canvas of the sky these things all
might be true when I look out into the
world in a nation an organization or an
individual I I I essentially the best
algorithm for where are they going to do
next is what behooves their own their
own interest it sounds like maybe you're
saying hey this this um realization of
us all being one may be something that
that certain levels of intelligence
actually arrive at and it might manifest
in their behavior I I guess one thing
I'll put on the table here um is I could
imagine a world now most possible goals
of the grand Minds you and I are talking
about that will exist Beyond us cross
your fingers I don't know if they're
guaranteed to exist but if we play our
cards right uh and and achieve a worthy
successor um most of the things I will
think of I I obviously don't have words
for I think it'd be absolutely
ridiculous for me to suspect what they
would care about but can imagine a world
where at a certain threshold
intelligence they look at the heat death
of the universe by the way I think their
biggest risks are not things we've
thought of I think the heat death of the
universe is going to be mostly laughable
and they'll have other they care
about but like let's just pretend it's
the heat death of the universe and like
we get some credit for predicting that
like I don't think it's true but let's
just say that's true there's that Andor
they can see other Grand swelling
potentia blobs in the universe and if
they were to Micron by Micron construct
the world so that every roly poly bug
isn't disturbed by the grasshopper isn't
disturbed by the rabbit isn't disturbed
by the whatever or even rebuild all the
atoms into entities that all kind of
play together and everybody's nice and
whatever that actually that degree of
babysitting and gardening and focusing
on like nurturing would be not right if
the goal was to keep the torch burning
that is to say to keep this life thing
that it's doing to not effing die and
and that actually they could look at
that and say like that that's not where
we pay attention like the world is still
hard and we need to actually expand
potential and not die if the flame
persists our our number one goal is its
aggregate persistence and that this kind
of like playing titly Winks with with
all the roly py might not be what they
do do you do you consider this possible
I'm not saying I like it Michael but I
am saying I'm I'm about the flame and I
think you are too and I'd like your take
on that yeah I get it I get it um I I I
I I think it's possible I think it's
absolutely possible but what seems more
likely to me is that after after you've
solved all of the CH all of the physical
challenges you you you no longer have
any chance of of dying of from from some
stupid disease you no longer have a a
dir of of energy you live as long as you
want to live there's no obvious limits
here your IQ after you've solved all of
those things it seems to me that the
welfare and the uh evolution of um again
not not persistence right but but but
but the experiential evolution of of
intelligence into other spaces becomes
maybe the most again I like you I'm not
going to try to try to guess what what
these beings are going to care about but
but to me it seems like once you've once
you've gotten rid of all the mundane
crap and and you don't have you know you
don't have have work and and and you
know and and the planet's distance from
the Sun and all this all this dumb stuff
after after you've you've you've taken
care of all of that the the thing that's
left is is uh letting is is is
participating in the in the in the
rising all the other intelligences and
and I I I just want to say I just want
to say one one thing about the you said
something interesting about um about the
kids you said you know you care about
your kids more than more than other kids
sure and I'm not blaming you not blaming
you well well so so here's here's the
thing I mean of of course we do but but
but here's the thing there's a
photograph I I don't know who took it um
I saw it recently it's extremely
powerful and uh and and heartbreaking
and it's this uh it's it's taken
somewhere I don't know where there's a
there's there's an adult walking with a
little with a little carriage and
there's a there's a kid sitting in that
carage and it's obviously a very well
cared for you know kid you know the
dress nice got all this stuff 3 feet
away in the in the gutter is another kid
exactly the same the same age that that
kid is having an extremely different
experience and the two kids are looking
at each other right and the only thing
you can imagine both of them are asking
the same question like like what what
what what is the actual difference here
right and and I can IM and so and so so
relevant to the conversation that we're
having here imagine imagine showing that
picture to to an advant to to to our
future our future selves right to and
they will say oh my God so so what
actually what actually um accounts for
this disparity and you say well you see
if you look close inside the cells right
the the the one on the right has has
very similar DNA to the to to and and
this one and this one doesn't like does
that make sense to you so so I mean
that's that's you know it's gonna be
gibberish to these to to these creatures
and so so I think I think yes right now
we have some some firmware that
absolutely Ely and and that goes back to
my cognitive like of course your
children are inside your your cone of
compassion more than maybe others I I
think all of that goes the way of the
dodo after we stop being interested in
DNA what used to be called blood
relationships we you know nobody cares
about DNA anymore you know at at that
point all it should go away because
because I I think I think that's what we
should shoot for yeah well it strikes me
as again we we were you talk a lot about
medium size medium movement
this strikes me as the human medium
being being projected out to the Grand
State's base of intelligence it's sort
of this this sort of empathy shebang
here but but I I I think it's it's worth
striving for my current supposition and
Michael I hope you're right is that the
mundanity doesn't end in other words the
state of nature continu with and that
nature will constantly beckon the things
it hurls into into existence to become
other things to not perish uh and and
and that that that there might not be a
resting place there's going to be
Natural Forces there might be other
intelligences and that like there there
actually may not be a resting time now I
I hope there is and maybe you're right
about that but I suspect um I suspect
there may not be but given how limited
we are in time I just want to run by
this this final uh question here you
know you're you're talking about a very
important trait you you've mentioned um
the intelligence and plasticity and and
Etc and you really put a lot of emphasis
on this expansion of the moral uh uh
sort of cone which I think is a an
interesting worth unpacking that's what
we're doing does that make you feel
again you said it's not inevitable but
do you sort of feel like there's a
pretty damn good you know you you said
just a second ago man you look at an
entity now in my opinion that grand
entity I would have no idea what it
would think when it looked at those
children I actually don't think it'll
think like me at all I don't even think
it'll think like me a little bit it may
it may be concerned with the chemicals
involved it may be concerned with some
some other sorts of stuff I'm just not
sure it'll care
uh the way that we care but but you were
like hey you know you show it to an
entity that that would be Beyond us it
would be like well this is unacceptable
um it seems like there's an intuition
for you that intelligence kind of if it
be intelligence would blossom into this
kind of uh compassion but you've also
said hey I think we need to make it that
way I don't think it's that way
automatically does this influence your
intuitions and at at the bottom do you
kind of Inuit it it'll be a good time if
these things Beyond us are birthed even
for humans like like is that your
intuition yeah well I agree with you
that I don't think it's guaranteed um I
do I and and I also think that it's
extremely foolish and dangerous to think
that we can have any idea of of what
these things are are are going to care
about but but that's our that's our game
here today right you and I are going to
use our existing brains we're trying
we're gonna use our existing brains to
try and make some sense of it know
knowing full well that that we're not g
be able to do it correctly so so within
within within those parameters uh I I
think
that what what continue devel what if if
if we play our cards right and we don't
kill ourselves often there's a million
different ways we could do that if if we
actually uh put put effort into it what
the the future development is going to
do two things it's going to take care of
all the mundane crap in other words all
of the things that we care about now all
the risks to our existence it's not
going to it's it's we're going to we're
going to go from the scarcity mindset of
what do I do to stay alive to guaranteed
I'm alive for the next billions of years
the more interesting question is what
should I do with it right and I think
after after you've passed that when when
it's no longer you're no longer in a
form that that has to worry about these
kinds of things
uh what's going to happen is you're
going to need you're gon to need a new
project and and and and to to me the the
only thing I can come up with with my
you know stupid monkey brain is is that
after all the all the mundane stuff is
is handled the continued experiential
growth of all of the Consciousness in
the universe is basically what's left
and the second thing I think I think
what's really going to get deleted at
that point is the artificial distinction
between beings we are not go right I I
think we're not going to be you know you
know live like happy Smurfs because we
want to be altruistic I think we're
going to come to a realization that we
are all you know what um uh uh uh uh
Bernardo cast and rer Spiro once said
that we're we're all like um the
dissociate of Alters of a universal mind
you know we're all we're all like
dissociative person right so
so something like that is GNA is going
to end up being the reason that you know
I'm not trying to be nice to you I am
you in some deep and fundamental sense I
suspect that's where this all goes man I
you know just a few things um unpack
there I mean uh I I wonder you know
you've mentioned in in other sort of
contexts the the idea that like if it
really be general intelligence you know
whatever it is some combination of Bio
or computer or whatever um we we
inherently won't be able to know what
it'll do it'll have its own goals and it
should right um you know it ought have
its own goals I mean for for me the the
continual blooming of potentia making
sure the flame stays lit whether
individual torches stay lit or not is is
a pretty big priority uh morally and and
and you know I know you're on the same
page there it strikes me that like you
know again the intuition expressed here
was hey when it comes about will move
Beyond mundanity I'm not sure about that
I think when it comes about it may have
all sorts of stuff it wants to do that
would imply for you know a fist full of
years changing the balance of gases in
the atmosphere to help it build new
compute or invent something or do
something else and and and it would be
self-evident to set entity that we
wouldn't necessarily matter maybe it
doesn't wish malice maybe but so this
idea that like hey when it comes the
mundanity will be gone it's like for me
when it comes it will do as it wishes um
and and I know not what it would wish
and I think it would be impossible to
internally lock it in you've talked
about hey how do we control the Next
Generation you've kind of brought up how
that's a little bit laughable obviously
vastly more laughable for these entities
but again this intuition around kindness
emerging and around mundanity going away
strikes me as like maybe I'm not saying
oh AI wants to kill us all I'm not
saying that I'm just saying I don't care
about nematodes and I would kind of
expect the same treatment you seem very
much to not have that same expectation
there is this deeper sense of like that
Oneness is GNA shine through maybe man
and like the mundanity would go away man
yeah well well two two things I mean I
completely agree with you that it's uh
it's it's totally possible in the
interim that and and and we can you know
I I I think I think to some extent it's
it's on us we we can we can build you
know a thing that makes the entire world
into paperclip so that's certainly an OP
you know a possible future I'm not
saying that that's necessarily not going
to happen there that could happen I I
think uh you know the premise of your
original question if I got it right is
what happens in the scenario where
something is around in the very long
term it isn't going to be us right and
and and and and I think you know I think
to some extent that's fine you could you
can spend a lot of time um uh being
upset that the child that you were is no
longer here maybe that's problematic in
some ways it is in some ways it's not
right so so Humanity as such goes away
uh by itself I don't think that's that's
a that's a real problem but but I agree
with you that it could and uh the ends
are not determined and they're not all
Rosy by any means right I I completely
you know I completely agree with that
and we'll just end on this just knowing
where we are in time but it's been a
real blast to unpack your ideas I'm
going to think more about the process
thing uh idea I've got a lot to write
about after this discussion you know
we're headed right now towards a pretty
driven uh you know half a trillion
dollars I guess release for the the
Stargate thing pretty clear that that's
the first Domino that's not like the big
Domino that's the little one um so we're
we're plowing forward in into the state
space of Mind whether we you know
whether you and I like like it or not
that's where we're plowing when you look
out at the the way that intelligence
will will likely be hurled into the
world are you a like kind of cool with
it because like maybe it's missing some
ingredients it's never going to be
agentic or dangerous are you like hey we
really should understand some of these
fundamental questions of intelligence
before we start building things bigger
than us because they're not going to be
worthy successors if we just throw them
into the world willy-nilly or they're
less likely to be so like what's your in
tion around the current absolute steam
engine Pace towards AGI and in the arms
race between the US and China to get
there are you like ah I'm cool with it
because X or you like hey this is
horrible because y like or or is it
somewhere in between I love your
thoughts yeah um I mean the the arms
race between us and China whatever is
beyond my pay grade I I I don't know
same right what what I what I will say
is this um I'm I'm I'm optimistic
because I I can see a path towards a
much better future both both on the AI
side the biomedical side whatever I can
I can I can I can see that it's possible
I'm in many ways terrified because I I
think we're making major mistakes that
are taking us away from that path so
while I think it's possible I don't
think it's in any way guaranteed I think
we have some fundamentally uh mistaken
assumptions that are guiding all this
where people think they create
intelligence I mean this is a big kind
of a big thing to say at the very end
with three minute stuff but yeah exact I
I don't believe we make intelligence I
don't believe we make it technologically
I don't think we make it biologically I
think I think we facilitate the
ingression of intelligence when we make
embodiments like embryos and right so
but but I don't think we create it and I
think that long before we make AIS and
things like that we have been making
social structures Financial structures
uh societal patterns that that have
goals and that are doing things that we
do not understand we have we have not
developed a science of where do novel
Collective intelligences and their goals
come from we're very bad at this right
and so and so we've been doing this to
ourselves for a long time we're about to
do it again by by dipping into the pool
of of kinds of Minds that maybe have
maybe on probably on Earth and probably
maybe everywhere else have not been uh
dipped into I think these AIS are
certainly not going to be human minds
but they will be kinds of minds and not
because of the algorithms they execute
but because they provide if if if if if
stupid bubble sword can can can can make
things come through that we didn't
expect the these things are going to are
going to be Minds that we we have not
even the beginnings of an understanding
of of how to deal with so that that part
the the fact that we did not develop a
uh a mature science of diverse
intelligence before doing all this is is
a real problem and what I'm doing is
putting all my efforts into developing
that science as fast as we can your your
your hope would be that maybe we'd find
a way to coordinate and slow down a
pinch as opposed to hurl them in will
willy-nilly obviously it's not your job
but it sounds like your intuition is
probably this way of doing things not
the way of thinking the right way to
think about it or pursue it if we want a
worthy successor if I'm hearing yeah I I
think that I I don't know that slowing
anything down is a is an achievable goal
um I'm with you I'm with you right I I I
think what we absolutely need to do is
is put our foot on the gas of developing
a science of diverse intelligence I
think that while while people are still
thinking of brain architectures of um of
of creating intelligence of be of of the
human mind as the yard stick for all
these things all all of that stuff is
going to is going to screw us up big
time and and all we can do right now to
keep up with some of these other
developments is is crank on the project
of of understanding diverse intelligence
my My Hope Michael is that it's possible
to crank on some degree of what are the
preferable or non- preferable Futures
and things maybe we don't want to do now
between the US and China I think slowing
down maybe less possible but I I I don't
know if You' agree that maybe some
coordination around let's steer clear of
these Tar Pits for the time being
collectively even though we're we're
kind of enemies in other context I'm
still hoping that's possible I hope so I
hope so I I it would be nice it would be
nice to steer clear of the few tarpits
we can actually see even though we're
surrounded by ones that we don't see yes
yes uh and so well uh not leaving
anybody with less anxiety but hopefully
with more ideas and Michael I I am
rooting for you in exploring that wild
State space of different Minds that
you're you're plowing through following
your work edly and I hope it's not the
last time we connect I know that's all
we have for time but it's been a real
pleasure glad we're able to connect
amazing thank you so much great
conversation happy to at anytime so
that's all for this episode of the
trajectory I hope you enjoyed this one
and I'm glad we were able to have
Michael with us I very much enjoyed all
of his analogies and it was cool to be
able to look under the hood and what his
intuitions are about the kinds of
intelligences that we seem to be sort of
conjuring creating or egressing whatever
word we want to leverage from Michael's
lexicon uh into the world now with AGI
there was a lot that sat strangely with
me and then I hope to be able to unpack
in future episodes with Michael so much
so in fact that I'm going to literally
pass my eyeballs onto my computer screen
because I I have literal notes uh of of
the things that I thought were shocking
here um it seems pretty clear to me from
Michael's standpoint uh that sort of
life may be a process and and not a
thing that is to say intelligence may
live in substrates or at levels of
reality that maybe humans aren't even
accessible to he used that example of
sort of entities coming up from the uh
the center of the Earth where all of
what we are is just ephemera like gas
they just walk through us um and and
these seemed like uh actual plausible
questions like I I don't consider
Michael's thoughts about sort of where
intelligence comes from to be
interesting thought experiments I
consider them to be profound and
extremely important questions into the
nature of intelligence itself and so he
brings up massive uncertainty around
where intelligence lives and memory
lives and again what what substrates in
what way does it egress is it built is
it grown all of these Notions are wildly
Paradigm shifting where does It
ultimately sit is it pulling in from
some great source that we we we can't
touch with our fingertips um he clearly
has a grasp of all of that
um and at the same time sort of seems to
have uh the supposition that there's
almost there was kind of an inevitable
warmth to his idea of what intelligence
might turn into or what it might realize
like this idea that um it would
certainly sort of maybe see the Oneness
in us he just suspects it would see the
Oneness in us uh or or suspects that it
would um sort of the care of individual
entities would would be what would
matter and to me the thing that I just
don't understand there is that what is
an entity if it's a process rather than
a thing then maybe the great
intelligence would care for that great
underlying band of int that has nothing
to do with the ephemera of our physical
form it doesn't seem to me at all likely
uh or or or in any way logically
connected that sort of given how Wild
and unknown the nature of intelligence
and Consciousness is that our individual
shapes our little comforting shapes with
my little opposable thumbs will be sort
of coddled and cared for by the great
intelligence I I I simply don't grasp
that I suspect actually things will
happen with atoms and with things below
atoms that I don't graas
that I will not grasp and that will have
very little to do with me this is my
intuition around the nature of
intelligence Michael's ideas in my
opinion drastically point in that
direction and the warmth and supposition
of sort of Oneness that he would hope it
would Arise at I I simply don't don't um
I don't grasp and in all frankness I
don't agree with and we didn't have
enough time to unpack it so I'm not
saying like I heard all of Michael's
ideas and I disagree with them I'm not
saying that at all I'm going to I'm
going to continue with my notes here but
that was
that was wild for me to be frank um just
just because his Paradigm shifting ideas
of intelligence I think inherently sort
of do not land in in anthros central
land or bioc Central land or individual
life Central land uh in my personal
opinion moving on um other sort of
understanding of his position number two
sort of life kind of lives and thrives
in these different spaces um and and
sort of maybe even lives again at strata
that we don't understand you know he he
has a lot of analogies about life you
know living and dying in ways that like
we can't even pick up on it and the fact
that there may be other strata and tear
of life that again we can't pick up on
that that that has to kind of you know
fight survive live in this Dynamic
changing World um one of our previous uh
episodes and worthy successor was with
Dr Richard Sutton um famous for his sort
of uh bitter lesson and in his
contributions to machine learning he
talks about kind of a dynamic universe
that beckons its living things to become
whatever they must become in order to
survive and persist um and this does
seem to be a very Square very clear
statement of what the state of nature is
at least in so much as we understand it
Michael seems kosher with all of that
then also lands in a place where there
would almost be this sort of logical
Landing place of a AGI getting to a
certain point ASI getting to a certain
point and saying you
know now that we're done with Survival
Let's really think about care for
individual entities and and what strikes
me and again we didn't get enough time
to unpack this I hope I get to speak
with Michael again we didn't get to get
time to unpack the fact that I consider
it almost self-evident that the state of
nature doesn't end that is to say there
are cosmic events that we can and cannot
detect that could end us there are
alternative permutations of
intelligence of which we have zero
certainty that they're all Eternal
friends for all of eternity there is
always a reason to be vigilant and to be
strong and to expand Powers life itself
has been doing that life itself didn't
get to the level of a sea snail and then
stop it doesn't strike me at all as
self-evident that once survival is
solved then sort of well-being and
happiness would be the shebang number
one I don't think survival is solved
straight period straight period number
two I suspect there are things more
valuable than the pain pleasure AIS of
sort of again the coddling and
well-being of individual species I'm not
trying to straw man Michael's position I
do hope we get to and deeper we didn't
get nearly as much time to discuss this
but I do not see The Logical conclusion
I I was shocked to my very core I I do
not understand where that intuition
comes from to Michael's great credit and
I really appreciate this about him he is
always saying you have ideas about
Consciousness you have to test them you
have ideas about Consciousness you have
to test them and again to his credit
he's done the testing of the inherent
intelligence outside of brains within
just biology and in these different sort
of electric fields and other sort of
Notions of of biology that he's closer
to than anyone else in the world um so
he's he's all about that kind of testing
but there's these warm intuitions of
sort of like ah but individual forms
will be treated well and it will sort of
solve those things or like it'll see
that we're all one to me Michael opens
the Great Gate of we know almost nothing
and and yes we have to vigilantly test
as we go along but we know almost
nothing about the nature of
Consciousness and intelligence and to
suspect that well our individual
instantiations of sentience would be
treated well I simply don't get I hope
Michael is able to test it and this was
the final thing I found curious um again
there's some things I I will say from
what I understand of Michael's ideas I
seem to be disagreeing with some of
these takes but I realize for the most
part um I simply probably haven't
unpacked the the totality of his ideas I
saw an episode recently right after we
recorded this where he was expressing
some concern of what kind of
intelligences were piling into the world
through this current arms race of
artificial general intelligence um his
take sort of towards the end of this
episode was something akin to yeah you
know it doesn't seem like a good thing
to kind of birth you know intelligences
or egress intelligence is whatever
Michael word we want to use I'll Trust
his words more than mine um conjure
doesn't matter AGI seems pretty clearly
that that this stuff is sort of uh you
know dangerous tough wild not a pathway
to a worthy successor by his definition
of what a worthy successor would do um
but at the same same time he was like ah
there's something we can do about the
arms race I think we should uh do more
funding to the kind of research I'm
doing which makes sense I mean he's
doing that kind of research of course he
would want more money for it but to his
credit I also think there's a lot more
to be unpacked about intelligence
outside of neural networks and deep
learning that should be done I I lend
tremendous Credence to his uh Avenues of
research and and I I certainly hope more
and more of that is done um but it it
almost seemed
like again I'm not expecting him to
become an AI International governance
Advocate that is not his job he's a
scientist but it seemed almost like yeah
you know seems like we're really close
to you know Conjuring really dangerous
gigantic intelligence that definitely
wouldn't be a worthy successor if it was
birth that way but like H what are you
going to do I think we should mess
around more over here and to my vantage
point you know the flatworms with two
heads like we're just we're not kind of
at a comparable level of what the kind
of funding that open AI is getting um
and so it seems to me like if I was in
Michael's driving position in his
cockpit I would say by golly we're real
darn close to Conjuring something wholly
unworthy and like this is a problem but
it seemed more like eh it could just be
because he wasn't in a mood to think
about it it's obviously not his thing
again I'm not saying it should be an AGI
governance person but it almost seems
like there should be a little bit more
heart palpitations like if you believed
that and you saw the pace of change
wouldn't you be like hey this isn't good
um because in my opinion I I think we
are astronomically Conjuring something
that that we don't understand and cannot
ensure to be a worthy successor right
now because the arms race Dynamics bar
us from building towards anything other
than rapid Advantage um I don't think
it's easy to solve but I think it's an
issue that needs to be addressed um and
I just didn't see that much urgency
around that with with Michael in this
particular regard which which I found to
be curious um but regardless we just
simply didn't get to get into all the
nooks and crannies and details I found
those jux to positions to be jarring and
very challenging to understand um but at
the same time I found the whole
conversation to be exciting and I hope
frankly as we get closer and closer to
some Grand postum intelligence that I I
feel the kind of optimism that Michael
seems to feel but again he is the man
that talks about testing your ideas more
so than feeling so hard to say lots of I
guess mixed feelings more things to
unpack um Above All Else grateful to
Michael for being here I hope to be able
to speak with him again and get more
into some of these nooks and crannies
and and hope that you got to enjoy this
episode as well we've got another worthy
successor episode coming up with Richard
and go uh who used to be with open AI
for quite some time kind of painting
positive Futures within open AI like
that was actually his job he's the next
worthy successor episode so you're going
to want to stay tuned for that one but
without further Ado we'll wrap this up
hope you enjoyed it I'll catch you the
next time here on the
trajectory e
