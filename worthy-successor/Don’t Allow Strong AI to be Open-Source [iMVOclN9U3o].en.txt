what does it look like to buffer against
some of those directions we don't want
to go in right now that feel more like
pure risk that maybe an international
order would decide we're we're too risky
what are ways to buffer against that
outside of looking at every one and
every zero that goes into somebody's
computer so first obviously we need to
accelerate regulation
that um like for example with licensing
that reduces the number of um and the
probability of Bad actors getting their
hands on dangerous stuff dangerous code
dangerous
models dangerous
knowledge
um and if you do a little bit of
calculation this is the most this is the
strongest effect of uh in terms of like
reducing the probabilities of um
something really bad happening like a
big misuse or loss of control that's
dangerous for Humanity
