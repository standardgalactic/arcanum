[Music]
this is Daniel fagella and welcome to
the trajectory this is episode two of
our AGI governance series Our Guest is
Mike Brown who is forly the director of
the defense Innovation unit for the US
DOD the diu was charged with the
adoption of a lot of Advanced
Technologies and various wings of the
Department of Defense uh primarily
artificial intelligence prior to that um
Mike was the CEO of sanch um and now
he's with Shield Capital he speaks with
us now as a man back in the private
sector with a wide sweeping view on the
international dynamics of artificial
intelligence Supremacy and he speaks
quite frankly about what it looks like
to maintain good relations keep Conflict
at Bay and even cooperation including on
the policy side with China and Nations
that might be considered adversaries but
at the same time bear in mind the need
to keep the West Strong uh particularly
with this technology that will Define
the century ahead this is my third
conversation with Mike over the last
half a decade and it's cool to be able
to pick his brain on a very different
topic here around AGI governance I hope
you enjoy it this is Mike Brown here in
the trajectory Mr Mike Brown welcome to
the
podcast well thanks for having me Dan
yeah it's been years uh since you were
in the the diu in our last couple
conversations and now back in sort of
the Venture ecosystem obviously very
plugged in to the the defense space but
getting all kind of Vantage points uh
that you you weren't able to get when
you were full-time inside of the the big
machine itself we're talking about AGI
governance and kind of strong AI
governance and coordination in this
particular series policy makers other
folks you've got kind of the
international competition take and
perspective here that I really want to
unpack before we get into that I want to
just ask a little bit around where you
think we are with relation to AGI
different opinions here we've had Benjo
on the show and Yan talin and Stuart
Russell and some folks who are you know
learned it in their domain famously you
know Elon Musk and Altman are sort of
AGI this this decade um but others are
you know not so uh uh sort of hasty in
terms of what our time Horizons are I I
know you tend to be a bit more in that
camp lay out where you stand Mike if you
would yeah well I think uh what we're
achieving in terms of the progress of AI
is truly amazing so we have to start
with that uh the Advent of the large
language models uh you know being
foremost in our minds that that's a big
change in terms of productivity but if
you take a longer term view we've been
working on AI and OD DARPA had a project
in the 1960s yeah working on so this has
not been a short Journey uh it's been
going on for quite some time we've now
moved away from kind of rules-based
AI uh you know big decision logic to
something that really works uh in a lot
more um uh streamlined fashion more of a
neural net uh Way Machine learning
there's a lot more techniques that that
we have now and are applying than what
we had early days absolutely all of that
uh leads me to believe yes we're on the
path but we are still in my mind quite a
ways away from AGI uh I think it can
happen but uh I think just like we've
seen with the self-driving cars have the
idea and have the basics uh are one
thing to actually get to the full
implementation that takes account of all
the things that we encounter in real
life is something else so not looking
for that around the corner but we're
we're definitely on the path as uh as
humans yeah well I so we'll unpack it a
little bit and and when you and I were
chatting off Mike I when you brought up
the very valid point and I think even
the people who are let's call it
extremely optimistic about artificial
general intelligence in the near term
uh would concur that hey you know
playing with language isn't the entire
Grand PBA of sort of what um capable
intelligence that could take the Baton
uh uh from from Humanity in terms of
Discerning the future and determining
the future it's it's a bit more than
that it's certainly a bit more than than
Wikipedia uh and and you know drinking
in YouTube um but you know over time I
suspect we will have you know speaking
of Shield there's obviously the The
Shield AI folks doing the pilot stuff so
there's more than just the humanoid
robots there's all these physical
instantiations you we had shield on not
terribly long ago on the AI and business
podcast um there will be more and more
physical instantiations dealing with
everything from probably running Life
Sciences tests in a robotics context to
you know working on heavy equipment to
cleaning houses Etc what are some of
those bigger Lynch pins you know to your
point around autonomous cars valid point
you know and I brought up musk was very
aggressive Rive on timelines for AGI
famously you know when we started
covering his his uh projections for
self-driving cars and whatever 2015 uh
famously was aggressive then and to your
point we're not there there were hurdles
legal legal and otherwise for
self-driving cars for AGI what would you
put on the table as some of the big ones
the reasons that you're not really
believing that this is going to be
emergent and postum anytime soon what
are those pillars for
you well I think you'd have to say uh
the advancement of sensors and the
ability to uh integrate sensor
information in real time from all
different uh you know types um because
AGI I mean if you think about what we
can do as humans where it's auditory
it's visual it's tactile I mean there
there's a lot that we're putting
together in real time uh at one time so
that that clearly would be one um I
think then uh you know some folks have
said the large language models are
actually creative um I don't know if I
would go that far I think there's
probably more that happens than uh we
can uh we can model today that really
goes into human creativity that that
that certainly is one we have to do more
specifying probably as to what that is
um I think the uh the sophistication of
the logic also is something that I would
want to see if I were thinking about
what what would a key determin of AGI uh
as taking some steps forward from where
we are now which is just doing things in
a mechanistic fashion at super speed so
I think there's a number of things uh
still yet to do but you have to say the
progress has been truly remarkable C
certainly has and I think it's it's
great that you can admit that there is a
camp uh Mike I'm sure you've seen online
you're probably a better man for not
being you know active on Twitter but you
know you get to see all the discourses
between the the Gary Markus and Elon
musks and everybody hashing those things
out there's some people who really try
to put up a front of not only are llms
not going to get us to AGI but they're
stupid they're good for nothing and
nothing about them is impressive and I
think that's also a pretty invalid
perspective if we're being honest but
but to your point we're certainly not
there yet you know you'd mentioned
creativity you talked about a few other
things in addition to um you know
certainty and logic you know uh famously
pretty rough at uh uh you know grounding
in facts and some elements of math and
and um being able to keep things
straight in terms of hallucinations Etc
there are you know there's particular
inies and I I I forget China talk
covered it recently I'd have to pull it
up overtly but it does
seem pretty you know it's it's quite
clear uh that open AI is here to build
general intelligence it's quite clear
that um Deep Mind is here to build
general intelligence and they got
absorbed like mitochondria into Google
because Google's not going to not going
to uh be last in that race right they're
pretty Ardent about getting there first
um presumably there would be grandiose
extens of power uh if someone was to
cross that Finish Line before uh others
um that's just between the labs now of
course you also have uh Zuckerberg not
just sort of doing AI in the background
where we know he's a player but overtly
saying no no no we're going to get the
general intelligence and now you have
musk of course who for a long time
summoning the demon oh my goodness this
is going to be terrible but hey Mike
when you got two choices which is be
consumed by someone else a sand god or
build your own sand god musk would
choose choose the latter as a man of his
stamp would and it's hard to blame him
in the state of nature that he's in so
musk is racing towards it now too
China's there as well I mean there's
been some overt statements of like
getting to general intelligence within
China they have an ability to talk about
coordinating within a nation they got
some UPS on us in terms of being able to
wield all of their their private and
public sector efforts uh together do you
think that's premature like do you kind
of look out a little bit at everybody
talking about that race and sort of
chuckle to yourself or do you say yeah
yeah okay maybe but it's going to take a
bit longer than they think like where do
you stand there because the world is
much more on that page but of course
there are some barriers what's your take
well uh there's no question in my mind
that we're in a race uh fortunately a
lot of us companies are in that race and
and leading yes uh and from a
competitive standpoint it makes sense
for that those individual players to
want to get there first and I think
that's because despite the fact that I
personally believe we might be uh a ways
away from AGI and I don't really know
what that means is that one decade is it
two decades I'm not a technologist close
enough to be able to pinpoint that even
technologists would probably find that
difficult to pinpoint but um there are
going to be very useful things we can do
with the state of AI before we get there
that's why it's so important for us to
make sure we don't get behind so llms to
me are just one uh marker along the way
um there's going to be other useful
things that we do uh certainly is we get
much better with computer vision uh
which is pretty darn good compared to
where it was a decade ago but still that
that can be fooled uh we have to make
sure that as we think about using that
especially with defense applications uh
we have some checks and balances in the
system um so I think because they're
going to be useful things that we can do
along the way and because as you point
out it's not just a US race it's Global
especially with China we have to make
sure that we're not behind so there I
would very much agree with the work the
national um Security Commission on AI
has done uh that Eric Schmidt LED we
need to make sure we're investing we're
developing the talent and the US
maintains its leadership in AI very
important in my standpoint I'm I'm with
you uh I I think that if it should be
birthed uh here or there I think you
know that that might be the final
Kingdom uh and if the final kingdom is
the CCP authoritarian version both might
be might be pretty rough for Humanity
but but yeah I'm I would say hey if one
dog's got a win um that said Schmidt uh
famously a little bit more optimistic
than you around general intelligence
right uh and um uh you know sees this
is stuff that could be uh coming up
relatively soon and there might be kind
of cut off points where when AI can
cross these two or three thresholds we
might want to straight up off button I
mean he's been quite overt about this um
and and really talking about kind of the
postum transition and trajectory uh uh
for you when it comes to the the
progress we can make in the near- term
you know there's no need to put an exact
and precise date but you had said hey
Dan it sounds like your ballpark is I I
don't have a date for you but I would
guess more than a decade and maybe more
than two so like at least one or two
decades out is sort of your present
ballpark guess if I'm picking up what
you're putting down that's right cool
that's right even with that said let's
just say it's 15 years uh let's say it's
25 um you know presumably you know you
and I'd be round um and presumably if it
were what you and I are talking about in
other words Mike uh you know we're a
ballpark 2% genetic difference from a
chimpanzee they can uh you know peel
bananas and they can climb trees
extremely well uh you and I can have
this conversation uh on zoom and have
Rovers on Mars and um you know build
machines that can do you know
self-driving fighter jets and things
like that right so a 2% genetic
difference pretty big jump if if such a
jump was even to start never mind hard
takeoff um 15 25 years out that would
feel consequential enough to to to not
to to be thinking yes about the
technological jumps along the way but
also about the crescendo itself do you
feel that impetus or for you is it like
I don't know cuz it still feels so far
out let's just focus on the things along
the way and less that Crescendo that
Schmidt and others uh talk about what is
your what's your take your gut on that I
think you're spot on uh it's close
enough in to where we willing to be
thinking about the consequences because
every technology that uh has been
invented can be used for good or for bad
so uh they start out uh as as they are
discovered and uh you can have a neutral
stance on it and we immediately start
thinking about what all the positives
are and companies start talking about
that but we've seen uh you know
technology used for for evil as well so
uh that means we should already start
thinking about what is the governance uh
that we want to have for uh AI
especially as it becomes more
sophisticated well you're you're leaning
us right into where we're headed next so
we're going to talk about kind of the
the what that would look like and what
it would achieve actually which I think
is beginning with the end in mind maybe
even more important than the nuts and
bolts details one of the frust for me
Mike is in the oecd and the UN and the
conversations in the intergovernmental
spaces that I'm in it's a lot more nuts
and bolts of oh you know should should
this be regulated or not like individual
end parts I'm really interested in your
take on what should it achieve but let
me first say you know right now 2024
time of this recording
anyway one to 10 uh how how imperative
do you think it is that there be some
degree of sort of intergovernmental
either coordination or regulation around
strong AI these vastly more capable
future um models it's not it's not a
tomorrow thing for you but also you do
see the consequences where would you
kind of score like how important that is
now and by the way I know you got your
defense background if you would say hey
Dan I don't think it's realistic with
China I would say it would be a NATO
Nation thing go ahead and put your
flavor on it but please do hit me with
that well it's a 10 uh so it's going to
be critically important because of what
the implications of what the technology
could do uh fortunately there's already
been a discussion I think uh with uh
China that we wouldn't want AI to be
controlling our nuclear arsenals well
okay thank
goodness great place to start I guess
yeah yeah it's the right place to start
but we can't take for granted what other
uh countries with different political
systems uh would think about where it
can be applied so yeah I think it's not
too soon to begin the conversations
uh just I mean just like with nuclear
technology we thought that was pretty
important not only to control in our
country and we set up a regulatory
framework for that yes pretty much right
after uh the bomb uh but uh we also
started working internationally and I
think both are going to be uh required
we're gonna have to have our own
governance here in the US um because
we're not going to want people using AI
to develop pathogens yeah other things
exctly uh and and for AI be uh uh you
know creating those uh using synthetic
biology so there's going to
be a governance system we're going to
want in our own country and we're going
to want to harmonize that to the extent
possible with other countries and there
may be different degrees of that in
other words there may be some things
that are possible with our closest
allies or other democracies in the world
and maybe we won't get Russia and China
on board with everything but to the
extent we can collaborate with them on
anything that will be a positive just
like it's a positive to be working with
those governments which we don't agree
with on climate change there are things
that affect the whole planet and uh it's
going to make sense to collaborate where
we can I uh I happen to personally
Concur and um when you mentioned sort of
this tertiary agreement between the
States and China you talk about the AI
safety Summit sort of those early
dialogues there about like hey let's at
least not let it do these things or yeah
yeah I think there there have been some
I mean this is to the positive that
there have been some positive steps
already uh I'll point to the state
Department's effort right now that Nate
Fick is leading uh on what should the
coordination be with respect to digital
policies so here the state department is
trying to get out in front of where
there are key Technologies whether it's
you know synthetic bio cyber what can we
do to make sure that we have a position
in the US that we are working with with
allies to do so that also provides a you
know one positive step it's not focused
on AI exclusively but it provides a step
there's going to be a number of
technologies that are going to be
affected by AI uh that we're going to
want to make sure that uh we're we're
coordinating to the extent we can with
other countries on yes yes it's it's
it's uh I think just pinning it under AI
there's going to be a the stream of
emerging Technologies we might presume
for all we know now what I've observed
uh Mike going back 10 10 11 years ago
interviewing people in the brain
computer interface and the AI space
there's really been one of those horses
that's been running quickly for the last
decade um and and brain computer
interface is in my opinion not wildly
more impressive than it was uh 10 or 11
years ago what brain gate and and other
folks were doing that um but who knows
there might be such barriers to a gii to
your analogy of autonomous vehicles that
all of a sudden brain computer interface
starts popping off we're adding memory
we're adding physical senses we've never
had before and and that kind of would
obviously require coordination too it's
still the future of intelligence not
just AI so I think you're bringing up a
great Point Let's Not limit it to a
technology let's limit it to those
things that would be so transformative
to sort of power intelligence The Human
Condition that we'd got to be on the
same page at least on some level
globally so that's right I think another
example is synthetic bio that I just
brought up a minute ago I mean that has
such consequences
for society life on our planet that uh
that we're going to want to make sure
we're thinking about what the
implications are yeah and AI is going to
be powering all of these Technologies
cyber synthetic bio so so they interact
it's not as if you can uh pigeon hole
them and say okay well we got it covered
now um they're all interacting they're
all being made possible by the advances
in semiconductor technology yeah
absolutely absolutely I I I sometimes
tremble to think how much of the Fortune
100 will be uh you know the mining of
metals the generating of power the
hardware the data center and then the
people who own the user relationships
and pipe the data to to the you know
individual consumers and the business
consumers like is it going to be 80% of
the Fortune 100 I have no idea but um
I'm with you I mean all of these things
are going to converge bio might you know
start splashing in there with its own
set of gigantic companies uh it's going
to be but but it feel does feel like AI
could be the Catalyst now uh that would
sort of get those comos going and then
of course anything else that fits under
that umbrella hopefully could fit under
that same structure um to talk a little
bit about what you would hope such
governance to achieve I mean 10 out of
10 is a pretty strong statement and
frankly I wasn't expecting it just
knowing that for you you know the the
blossoming of postum intelligence is not
a super near-term concern uh for you but
but to hear 10 out of 10 um I think it's
a valid take before getting into the
specific let me just say that the reason
for 10 out of 10 is because uh of what
AI could be used for
today yeah yeah yeah it wouldn't be good
so it's to kind of start those
conversations because there are very
negative
consequences um today even even today
okay even today so as as it gets more
powerful it becomes even more important
if you haven't even started the
conversation um you're going to be that
much further behind valid take well the
uh interesting too because when we had
Benjo on you know he had mentioned look
I don't I don't know if it's today's
Tech that would necessarily warrant us
to be able to shut down certain kinds of
Open Source Tech and and really have to
Foster some degree of international uh
governance but but you know he does
believe there is a line there is a
threshold at at some point um uh you
know for you it's like hey look what it
could do today already is concerning
enough at a global level we should be
this thing needs to be drawn up here and
you know you mentioned creating
pathogens very common used examples I'm
not going to say it's played out I think
it's a very valid one are there are
there any other perspective you you know
the impersonation of people the uh
replication of human relations ships and
what consequence that might have on
society I I could think of A500 of them
but if you were to think of sort of the
big pillars of hey Dan look I said 10
out of 10 because even if the tech stays
where it is here are some things that
are so internationally consequential we
should care about it you know I think
people want to know what does Mike Brown
think right now you know is is is
important enough uh to to Warrant that
what what is your
take well I worry about the uh threats
that uh we already know about today that
could be supercharged with AI so that
would be uh the chemical biological
radiological threats that come from
nuclear
technology what what uh if there's no
control over the uses um you know it's
it's kind of like in the same category
as the uh
uh you know if if you were able to take
a large language model and uh ask it to
uh use whatever resources it could find
to go out and lie cheat and steal to uh
create a pathogen I know that's an
overused example but think about it for
a a chemical at you know mass production
of um
uh Ryon or sing gas or I mean do you do
you want that to be you know out there
available for some new thing that could
some new thing that could poison the
water supply or something right some new
conjured things exactly okay I'm with
you yeah um so so that that I think we
want to make sure is not easy just
because the technology allows you to do
something that's not a good thing and we
have uh you know terrorist actors who
care more about destroying our society
than than helping us build a better
Society for everyone so we have we have
to take into account all these um
different motivations I like it I'm
going to drop an analogy and I'll go a
little bit farther in in this current
impact and see what things you think are
consequential and then we'll talk about
what governance would achieve but um
just building on what you've said the
analogy that I use we talked a little
bit about off Mike because you know I'm
sitting here in Weston Massachusetts a
little bit outside of Boston I get to
have this lengthy conversation with you
um because it is illegal for anybody to
like walk through that front door and
let's say take this computer setup and
all this camera equipment uh you know
they can't do that um and so I don't
have to spend a lot of time you know
looking out one of my windows with a
rifle because like that's not even a
realistic concern at this point and some
people might say well you know Le hey
you know AI look of course you can do
some bad things sure people can do some
bad things whatever let's just like get
along we're all building the tech I
think the argument that I would make
there is that the degree of governance
that has allowed um civilization to
Blossom uh has not probably been 100% or
0% um if we think about from you know
Mesopotamia up till now if we think
about you know the the you know
governance systems of did an our right
job you know we think about tongue
Dynasty China or or you know uh Venice
or or you know America I think all
things considered I think we've done a
decent Shake here um there are places
where we've probably governed way too
much and it's ridiculous and slowing us
down and silly and I think many people
call point at Europe and aren't really
looking to go down that road but at the
same time it's not the state of nature
here you can't just walk around clubbing
other Americans over the head and taking
their stuff and so the way that I think
about what you just said was if anybody
can do these raw physically dangerous
things with AI all of a sudden we're
we're going to be in kind of a attack
and defense in just these more physical
things and we won't be able to Blossom
the other potentials of the technology
because we'll be racing against physical
Force just like I said I couldn't have
this convo with you if I needed to be
facing out the window with a rifle
because people could take all this stuff
at knife Point um do you do you think of
a different analogy there or is there uh
uh yeah how would you explain I guess
the imperative because this is what
strikes me but I'd love to get get your
take no I think I agree with you
completely on that uh we want to make
sure to the extent possible you you uh
have laws against the things that uh
really would create harm for society and
we don't allow one person's freedom to
uh impinge on everyone else's and create
harm um but and you want to make sure
that the technology is not so accessible
that uh you make these things easy for
people with uh with bad motivations um I
mean I happen to think that we haven't
gone far enough with uh uh gun control
in this country with so many mass
shootings I know that's not a
universally held view but if you want to
stop the mass shootings uh you need to
do more um and and I'm personally tired
of you know uh hearing uh every day
there's been another school shooting I
think it's it's horrendous so so that's
just an example of where bad things can
happen you have to make sure you've
taken the
appropriate um you know preventative uh
actions uh to not get those bad
consequences and AI is going to fit into
that in terms of technology that can
create bad consequences we we've tended
to focus on the negative I I don't want
to just stay there because I do think uh
it opens up uh a tremendous uh
productivity enhancement for for society
so I'm I'm not uh in the camp that says
shut it all down take a I think all that
is crazy we should still be continuing
to progress technology we should still
be investing as a nation Federal R&amp;D
dollars uh to make sure this uh is on as
fastest track of Poss as possible
because we are competing geopolitically
as well so uh just wanted to make sure
that oh no no of course of course and
and well so Mike we're going to unpack
it I think when we talk about what
governance should do and I have one
question before we get there because I'm
dying to get your opinion on something
but when we talk about what governance
should achieve it's it's very clear to
me that for you it's like hey let's take
out just brute state of nature terrible
impacts and let's let's think about how
that would allow us to ease up and ask
about what the positive potential of
this Tech is so we're going to unpack
that we're not going to leave here with
you being a doom and gloom guy I don't
think that's what you are uh and for the
audience they'll be sure of that by the
end of this chat as well if they're not
already um one last thing about the sort
of governance now and sort of why it
might be relevant other things I've
heard in addition to kind of chemical
and biological uh Warfare and weaponry
are things along the lines of hey uh you
know I think already there might be you
know I'm going to throw I'm going to
throw a couple things at the wall I'm
not saying I believe in all of these
necessarily tomorrow but I think they're
somewhat valid uh you know hey with with
enough programmatically conjured content
uh the internet you know and maybe even
educational institutions that kind of
hinge off of pulling reliable things
from the internet could become sort of a
sloppy slush bucket that that none of us
can trust if if sort of we have a a 10x
increase in content and it's all
conjured by machines and Y there's like
those kind of concerns there's like the
the foundation of sort of what we can
know um there there's the concerns of
deep fakes and impersonations you are we
going to be in a world where everybody's
talking to an AI on the phone but they
think it's a human and and and there's
no rules about whether we need to
disclose that um where you know
politicians can Target a message to
Sally Jenkins in you know Shaban
specifically and say something about her
exact situation you know maybe she maybe
she does own a gun maybe she has a
pickup truck whatever the case may be
right um is is that okay is that not
okay there's concerns around
relationships I mean there was that that
application called replica uh and
there's a couple other kind of
relatively well-known examples here of
of people starting to kind of get their
friendship or even kind of relationship
circuits checked and if you get enough
of the youth who's sort of famously
pulled away from physical relationship
here Mike if if we look at the trends um
and and like physical intimacy uh if you
if you get them satisfying those
circuits in a way that becomes new and
reliable and normal are their social con
consquences there um I'm I'm throwing a
little bit of or or one
more Tik Tok great we're shutting it
down you and I probably on the same page
about that uh but YouTube doesn't matter
any social media if we can be scrolling
and have things conjured in real time
not not not brought to us from somebody
else's already made media but conjured
specifically based on what's going to
capture our attention right then and
there I'm not saying social media
companies are bad but if that's totally
able to be hooked into our our our
neural circuitry and and we're able to
swim in these programmatically generated
experiences this catalog of qualia if
you will these are all other things I'm
putting them all on the wall for you
Mike that people have said maybe that's
stuff nationally and internationally we
need to think about does any of that
stick with you or there any other
examples because I I want people to see
beyond just the the bio stuff um and and
get some other
takes well no you you're raising you
know while the conversation started with
kind of what are the uh most
harmful uh examples we can think of for
our society reasons to govern reasons to
govern is what I brought up yeah you you
you've broadened this to uh how is it
changing uh our society our
relationships with each other I think
these are very valid questions it's it's
very concerning already the impact that
social media has had on youth uh the the
change in perceptions the the ability to
uh you know have some students bully
others
so yeah we we clearly are catching up
there we
haven't we haven't even uh come up with
what are all the right mechanisms we
need for the power of social media today
much less if we start thinking about
some of the examples that you gave so
we're pretty behind there I'm certainly
not an expert in those areas but I would
say we're behind uh on what we should be
thinking about we're just now learning
about s's implications so we need to
incorporate at that learning into how we
uh how we want to control uh social
media it's it we can't just let the
profit motive Drive uh this to wherever
it wants to go I don't think that's the
right answer for for us I'm also not in
the camp of well you got to limit it in
case there might be a bad consequence
what I'm saying is now we know there are
some bad consequences and we got to make
sure you know it's just like with
election interference we've learned what
some of the challenges are now we're
taking corrective action I think the
same thing's going to happen on an
iterative basis uh for some of the
examples that that you gave uh I i'
concur just just wanted to at least get
your pulse check there we finally now
get to get into the what we would hope
coordination would achieve for you again
10 out of 10 the stuff already is very
consequential and if we're talking about
within our lifetimes bumping up from
chimpanzee to humans to the same kind of
a stepwise up we really you know got to
be thinking about it on some level be
before talking about between who and
exactly what kind of agreement what's
legal not legal how is it enforced what
should it achieve you know you're
clearly a guy that wants to see
Innovation you did that in the
Enterprise you did that in the dod
you're clearly investing right now
actively in Innovation that's that's
your goal what would you hope that
coordination would achieve
ideally yeah I think we want to be able
to come to uh you know a a shared point
of view to balance the risks of the
positive and the negative and come up
with okay what are the mechanisms that
prevent the negative and and as I said
already I think it's a it's a global
issue so you want to make sure we're
doing that within our own country then
we want to be working with other
countries uh to develop a shared point
of view and the more that can be shared
uh internationally I think the stronger
we are and there may be some things that
we'll be able to agree globally on
um so
uh I guess I'm going to try to roughly
nutshell or maybe extrapolate just to
pinch and see if I'm on the right page
if we're going to get basic
intergovernmental coordination around
this stuff maybe it's like hey uh that
coordination should identify the things
that are aggregately most harmful in
terms of international conflict maybe in
terms of danger to individual humans no
matter where the heck they live and what
their government is uh and figure out
ways to collectively sort of bar that
stuff um so that that seems somewhat
clear yes are yes are there are there
other things I've just I've heard
suggestions and I would love to know
what your take is here you know in terms
of innovation of maybe even sort of
circling out hey you know here's here's
Realms of innovation or capability space
that uh intergovernmental maybe
species-wise we just decided let's kind
of like hang back on that for a minute
let's all agree you know augmenting
human Minds with AI in XYZ way like that
that shouldn't really be now until we've
learned some of these things and maybe
this area around Diagnostics and medical
maybe we should have some joint
collaboration around that so for some
people there is a a pure harm prevention
which totally makes sense uh
internationally and nationally for
others there is a discernment of where
as a species or an International
Community we should maybe collectively
explore or individually explore as
Nations or or maybe agree with each
other let's not just like we do with
chemical weapons and other things hey
you know let let's not see how far AI
can go with uh whatever the thing is I
mentioned you know brain augmentation
stuff or maybe replicating romantic
relationships what whatever people would
want to Bar um what are your thoughts
there or do you see it more on just the
harm reduction side from your Vantage
Point the core of what you'd hope it to
get done fundamental coordination what's
your take well I'd say harm reduction is
probably upper most in my mind I'm less
enthused about restrictions saying it
can't go here can't go there because I
think uh just as we said earlier
technology can be used for good or for
bad purpose purp let's see where it
could be used for good and then how
would we balance that
um I I think that's where I would be
coming from primarily but as again as we
already talked about I think we should
be learning what the consequences of you
know widespread social media are uh deep
fakes I mean let let's not be ignorant
of that even though that doesn't fit in
the you know category of uh you know
poisoning the water supply yes yes um so
we have to be continuing to learn from
our experience and iterating on that so
that that to me is less of a don't go
there like you wouldn't want social
media around but just learning from our
uses of it so more informed maybe mold
more
informed regulations and trajectories
for those Technologies based on you know
being a bit more bit more proactive for
the next wave potentially so harm
reduction is kind of the main you know
objective of of coordination for you and
and it sounds like if I'm again I'm not
going to put any words in your mouth
here but knowing your other takes based
on our interview up until now that would
be harm reduction of the right here
right now which to your point and you
bring up some valid points here there's
plenty of it uh and but also also
coordination around um you know the
wielding of kind of a strong Ai and sort
of what what that might look like
because of course that would open up new
Realms of harm reduction we can do all
kinds of things to monkeys that they
don't even know about like they don't
have words for the kinds of stuff we can
do to them and or or to their
environment and it's not even out of
malice we've done plenty of stuff to the
monkey environment simply because we've
had better things to twoo Mike I mean I
don't know what to tell you I all doe
respect to the to the other apes and I
really do uh but we've just sometimes
built a highway or a hospital and there
might have been a tree there I don't
know what to tell you uh and and they
they can't possibly conceive of those
things so
um in terms of we'll focus on near term
first um um I'll I'll add I'll add one
more Dimension to which is uh thinking
more about the geopolitical is I believe
very strongly that we want to make sure
that the uh technologies that we're
supporting uh in the US and with our
allies uh continue to have the flavor of
uh
enabling uh basic human rights uh
freedoms that we hold dear so uh I think
any of these Technologies can be used uh
to create an orwellian worse than
orellan super repressive Society I I
happen to think that's what the PRC has
done in China y not just with the Wagers
which are a awful what they're doing
there but with their own people on the
streets of
Shanghai I don't want to see uh that
enabled um with our policies uh and I
think that's you know one of the reasons
why the state department created this uh
uh special position that that Nate Fick
holds in terms of our ambassador of
digital technology I don't remember the
exact title but to think about what can
we do in collaboration with other
countries to make sure that the
technology really incorporates our our
values well man this is a big topic so
let's poke into that obviously this is
dear to your heart and close to your
world um and and uh got some things to
unpack here um so let's make sure we
prevent the harms of today's current
Tech with you there this is going to be
more to unpack but you're touching in on
Also let's make sure the direction that
this takes certainly within our our own
country um but maybe even as AI starts
to be become an immersive element to the
social fabric of humanity uh that the
authoritarianism doesn't creep through
uh the hardware and software um in the
same way that I think you and I would
both concur uh whether it's the Wagers
or the social credit score we would not
want to see uh uh sort of expand um
elsewhere in the world that's right with
that with that said
what what would that take or look like I
mean would it would it be a kind of
containment exercise on some sense I
mean I doubt there's going to be very
much convincing of the CCP to to take
another path themselves right but I I've
made you laugh here today goodness um
but uh but but you know is it sort of
like making sure that that those
tendrils don't creep into Japan they
don't creep through the hardware into
Europe they don't creep into you know
Europe is going to be pretty ring on a
lot of Chinese stuff here uh especially
if they're not keeping Pace what would
that look like for
you I think it's educating uh ourselves
and
uh you know other countries around the
world what can be done what is being
done with uh with technology and so that
it becomes at least a more informed
choice and I would hope a less
attractive choice to be buying
technology that can be used um for
repression so you know there's probably
no more uh
photographed uh population than the UK
there's security cameras everywhere okay
that can be a positive thing because
it's a make sure that the society is
safe and you've Amplified productivity
of the police you got a lot of knives
out there but in China uh that's used
for a different purpose and the
government is is watching and making
sure that you're not saying anything
negative to the party or doing anything
that uh you know would
um would lessen their their grip on
power so uh I think uh it's it's
important for uh countries to be
educated to the different uses and
hopefully to make a choice uh that
that's not what we want in our society
and from my standpoint the more Society
is around the world the more governments
around the world that agree with that
point of view then we're building a
world that is infused with the basic
values and freedoms uh that that we
think are critical so there's a harm
reduction for what the tech can do today
there's also a as this becomes embedded
in the fabric of sort of our our Human
Condition whether that be in our town
somewhere or whether that be across and
between each other in business and
personal life internationally um that it
it not be an enclosing set of tendrils
uh that that would lead us away from
freedoms so that uh for you
International coordination would also be
hey let's at least for the countries
that are open to it um and I'm sure
China will have their campaigns of of
influence as well of why this is harmony
or whatever other phraseology will be
used and I don't mean to insult
everybody in China with with an opinion
but um but uh I'm sure they'll have
their campaigns too but for you and I I
believe most you know Japan I would
imagine you know India I would imagine
many of them will be like we would they
would probably concur uh at least on
some level let us not permit these
specific things happen so for you
International coordination should also
be hey can we really agree that as this
Tech Hardware software we're sharing
between each other we might not agree on
everything um uh but C can we make sure
that certain kinds of freedoms are sort
of fundamentally upheld and and not not
uh wildly violated it sounds like this
is also important for you
yeah yeah well I think you said that a
lot more articularly than I did oh
that's perfectly fine I here's here's
the thing you get to look really smart
when you do interviews because they get
to unpack the whole idea with the
spaghetti string from their head and
then you get to Nutshell it and you just
look like a genius every day so don't
give me any more credit any more credit
than I'm due but I'd love to I'd love to
touch in on that and and a couple other
things around what we would hope
governance would do and then we might
talk a bit about what that might look
like before we wrap up today but um I
recall speaking uh I think it was a
little more than five years ago at
United Nations Headquarters uh in New
York around deep fakes this is kind of
when it was just becoming a thing we we
deep faked the head of unicore so the
crime and Justice Wing we got a
two-minute video clip of her and have
had her said some things she didn't say
and then had a bit of a longer
presentation around sort of where this
stuff was going my take was very much
not limiting it to deep fakes but to
immersive programmatically generated
experience becoming a norm and frankly
that being able to be conjured towards
bending perceptions towards so not just
misinformation but uh propaganda I
didn't mention any countries in the
presentation but there was Mike I
remember and this was a very jarring
experience for me there were things that
were asked to be removed although no
country was mentioned I certainly didn't
say the word weager uh I certainly
didn't um I certainly didn't you know
have anybody's flag up there but things
like propaganda and some of some of
those influence of of really being able
to immerse people in virtual experiences
where every pixel is calibrated based on
their neuros circuitry and what they
want again 5 years ago um I remember
being Jarred that at an AI risk event
that was not permitted as a topic of
discourse I sort of Wonder for you you
know it sounds like we've got Nate Fick
out there sort of fighting the good
fight in this regard um what does it
look like to make it okay to say that in
an international and and again I respect
the UN tremendously still involved I
lived o i i I made sure I live close to
the UN building where those early talks
happen in San Francisco when I moved to
San Francisco very deliberate choice
what does it look like to make sure that
that's okay to say because that was a
tough thing for me and I'm sure you've
had some struggles there too yeah say
say more Dan uh that it's okay to have a
dialogue about this that it's that it's
okay to talk about these risks of
propaganda or what could be done with
screening for Wagers Etc because again
as I mentioned this uh just talking
about how authoritarian Nations might
wield this stuff for propaganda this had
to be removed from my initial you know
uh talk at the United Nations
Headquarters um and that felt to me like
I'm with you I believe that this should
be sharable but it was not sharable at
that time and that that's of course a
wonderful body that maybe should be able
to do some of that work uh what's it
take to make those things okay to talk
about
intergovernmental well it may be that we
need to create uh new institutions and
go beyond the UN I think that's what I'm
hearing from you disappointing that that
would happen at the UN but uh everyone
has a vote there uh and the security
Council includes you know CCP
and Russia so maybe new forums that
create from shared thinking that can
expand um I think we'll have to be
creative uh as we create those I think
that should be part of our thinking I
don't think what needs to be going
through the UN through NATO I think I
think these could be
um these could really be shared thinking
about technology and its uses as opposed
to our current security Arrangements
this is really interesting now and again
again for for the record I have nothing
but respect for the UN I think it is
challenging though sometimes when you've
got you know certain kinds of
stakeholder groups um uh if you if you
were a betting man it sounds like for
you you don't necessarily have a
preference these goals of yours of sort
of you know overt harm reduction as the
technology develops and today uh some
degree of insurance that globally we're
not moving wildly away from freedoms uh
and from the autonomy of individuals
that that might just as well be sort of
a non-un institution is it almost like
okay World War II very big change you
know globalism and global conflict and
nuclear weapons and we needed a new
institution to stand up is it reasonable
to say and again I'm not knocking the UN
or saying this should happen but is it
reasonable to say that we're crossing
some new thresholds where the degree of
connectivity and the kind of tech are so
wildly drastically different that maybe
something else gets stood up I mean what
are what are your thoughts there it
sounds like you see that as potentially
viable
well absolutely I think if we were to be
critical about the un uh we would say it
probably has not achieved the objectives
that were laid out in
1945 uh to really make the world
peaceful I mean the idea was we'd be
able to
bring uh you know controversies to that
body and prevent uh more war especially
a World War now the good news is we
haven't had a World War but we've had
plenty of conflicts that the uh the UN
has not been able to resolve
so very mixed result I think we would
say and it's not a place as you just
pointed out where you can you know bring
up anything for discussion so I think
that means we we're gonna have to uh
Branch out and create some new
mechanisms just like uh you know the
wasar arrangement that we have about
what we can uh trade among countries um
is probably not uh appropriate anymore
that was set up during the Cold War
right so time to think of what we need
to do and this should really about
shared values around the technology
that's what that would be my starting
point I actually think there's a role to
coordinate more technology development
with our allies so I think this could be
part of a broader Forum I don't think we
necessarily have a consensus to do that
uh in our government yet but you can see
the beginnings of it if you look at AAS
so AAS was the course created to you
know provide access to nuclear
submarines uh across that Alliance that
includes our closest allies of Australia
and the UK but imagine if we were able
to build a broader Alliance that
includes you know the rest of the five
eyes Japan other key allies where we
were really thinking about how could we
develop technology in the geopolitical
competition we talked about earlier we
want to make sure we're leveraging I
think all of our allies and partners to
make sure that we're not getting behind
in any of these Technologies and we
could add to AI Quantum Sciences
synthetic biology you could add a broad
I think there should be some
coordination there that leverages the
strengths of our partners and then how
to use the technology would be one
component of that that's how I would
approach it if uh if President Biden
called me and asked me how we should
organized which he has not call today so
far um that's how that's the advice I
would give him we need to be thinking
about doing that with our allies I'll
see if I can nudge we have a sense of
urgency about it which I don't think we
have today because I don't think enough
folks are thinking about the questions
you posed at at the top of the you know
our time together which is these are
very consequential Technologies AI is at
the Forefront y um and uh we need to
make sure we have a handle on where they
heading and how they don't create harm
yeah and and just for clarity for the
audience as well and Mike this is even
for me uh Aus is it just Au c s a Au Kus
so it's it's kind of a a combination an
acronym if you will of yeah okay good
people can people can Google it I just
wanted to have the right stuff for the
show notes or for the people that are
tuned in here so uh but but that for you
that's kind of a coraly um so
coordination might involve you know or a
metap point rather than a corollary it's
a what should we really be starting with
you as about the governance yep yeah so
okay so just uh that's important to note
you've talked about I've got one other
thing to dip into and then we'll talk a
little bit about the how as we wrap up
here today um shared prevention of harms
from what the tech can do got it uh some
degree of ensuring of freedom and again
I'm sure China will have their
diplomatic efforts but um for you that
that also feels like an important part
of this web here uh and then potentially
um some shared sort of research efforts
you know I could see there being a lot
of tension if it's sort of like you know
countries that aren't Russia and China
all building up their AGI power you know
like Russia was able to use that as a
bit of an excuse for for this recent
conflict of which I'm not a scholar and
I don't have a firm opinion but I think
it's it's a shame that we have such
conflicts um right but but you've got
the shared sort of maybe research
Alliance side of things which makes
sense
um it Dawns on me and you might not
agree with this I'm just going to throw
it out there I I think there's there's
definitely a possibility that we in my
opinion that we we just kind of whole h
throw ourselves into the brute arms race
of creating the strongest possible AI
once it's got a billion robotic
instantiations or a trillion robotic
instantiations and maybe that stuff does
things to us that we don't like but I
also think it's very realistic in my
mind that if China sees us getting close
to the development of general
intelligence or vice versa there's also
a real uh uh shot at conflict of sort of
the bad guy um you know depending on
what side of the def fense you're on
here uh is is about to birth this thing
and may be able to populate the Galaxy
with their permutation of intelligence
and certainly maybe wield tremendous
control over Earth for however long they
can stay in control of of said entity
which might be uh 4 seconds might be
four months four years might be four
decades who knows um I could see that
also being a ramp up for conflict and I
personally I I would go more if I was
going to say how would AGI lead us to
Extinction and this may maybe laughable
to you which is fine if if that is your
take but for me I'd say maybe it's 60%
International conflict over AGI and that
race watching somebody get so close to
something ungodly capable that conflict
occurs and then maybe 40% the stuff
itself ending us um what are your
thoughts there does coordination fit
into that mix is that so far off let's
just cross that bridge when we come to
it um what's your
take well I think uh the the the two
points that we've already made one is
we're in a race if you look at what uh
uh you know general secretary shei has
said leading the uh the CCP in China um
he has explicitly said uh China should
displace the us as the technology
superpower in the world by the 100th
anniversary of the uh of the PRC which
is 2049 so he's on a path whether we
want to recognize that or not whether we
want to be in the race or not he's he's
in his own race he's already there yeah
yeah yeah so we we could choose to
ignore that I think that would be
foolish but uh he wants to have control
of all of the key Technologies the ones
we've talked about here AI chips and and
no Reliance on the west so he wants to
make sure that China has its own
indigenous technology I mean you could
argue any country would want that um but
what's dangerous here is if he's
successful
not only is it the values of the CCP
that uh become you know more powerful
because the the technolog is there but
it also goes with military uh
prowess uh and economic uh Power uh
because uh the US has enjoyed basically
for the last uh you know 75 years since
the end of World War II we've been the
technology superpower and that has
allowed us a position in make sure that
it's our companies our standards around
the world that for most technologies
have been prevalent and it's what's
allowed us to really be in the lead with
chips and AI today um so it's it's a
it's a dangerous
uh hand to play to kind of ignore his
Ambitions and say we'll just see what
happens that's why I think we have to be
focused with allies on continuing to
invest and making sure we don't seed the
lead and so at the same time as we're
doing that uh we also need to be
thinking about governance um because the
state of the technology today as we have
already said could lead to some harm and
we need to be
building uh a as broad a consensus as
possible across governments in the world
that we don't want that to happen so I
think both of those Trends are in play
and we want to make sure the US and I
want to make sure the US is playing a
leadership role not not a head hegemonic
role where only our opinion counts but
we're in a leadership both with respect
to the technology and and the governance
yeah I I
um I'm with you if if there be a race
and there be whether we want it or not
uh might as well at least address that
seriously and and and make race is here
we can choose that we can choose We're
Not Gonna participate but the race is
here yep yep yeah the old paricles quote
about politics if you will so um with
with that said maybe
leaning a little bit closer to the nuts
and bolts and designing the governance
is not a podcast job it's clearly
there's going to be very smart people
involved and well at least I hope Mike I
don't know for sure um and and and folks
who can um maybe learn from what's
worked and not work for intern
intergovernmental coordination as it
stands there's going to be a lot of
nuance but at a high level you've
articulated what you would hope it would
achieve um you know freedoms overt harm
reduction uh um you know uh
and some some of the other stuff that
you've outlined here what does that
begin to look like and You' you've made
it very clear it doesn't have to spin
out of the UN there might be other
bodies or organizations or kinds of
coordination that could emerge um when
you think a little bit more about the
how what would that look like you know
the AI safety Summit in in the UK I I
thought was great just for the sake of
getting the bigger existential concerns
of this Tech not just like child's
privacy and other stuff which is
perfectly valuable but the grand
existential Big Stuff uh you know I'm
frankly glad more people are listening
to like Schmidt and other people that
talking about bigger bigger picture uh
things that's happening great what might
the beginnings of this governance
actually look like you know from a nuts
and bolt
standpoint yeah I would uh air on the
side of trying to build a a coalition a
uh uh a set of countries that want to
participate rather than going for
something that's Global and you know
we've got to get everybody involved so
to me that would start with allies it
probably would a good starting place
would be AAS or maybe the five eyes I
would expand that to the extent
countries are interested uh in being a
part of this uh and then I would make
sure that the folks meeting are
combination of
technologists uh uh
academicians um policy folks so we we
bring the state of the the art of the
technology into the conversation you can
have this just being done with folks in
government they're not as um as fluent
in what's happening currently and I
think you want to set it up so that it's
this isn't a set it and forget it
exercise you you have to have the
dialogue continuing some of
the use cases that we talked about here
you want to make sure people are
continuing to refresh the thinking bring
in the more controversial use cases so I
see this as kind of something that would
have to be uh created but it would
evolve and hopefully gain strength with
um more countries that see this could be
valuable to be a part of rather than
starting uh with something that tries to
incorporate you know hundreds of of
countries at once yeah I mean the the
discourse issues that I mentioned with
you within the UN are different in the
oecd where you know it's oecd countries
right I mean for free market democracies
um so what you're saying is maybe let's
start in places where some of those
freedoms uh are sort of already
grounded you know this is a race whether
we like it or not there are countries
that disagree whether we like it or not
um I don't like it frankly Mike but look
here we are right I mean there's there's
all kinds I don't I don't like they have
a cold right now and I'm interviewing
Mike Brown for crying out loud but but
I'm doing it um so uh beginning with the
sort of Coalition and and catalyzing
those folks that are on the same page
you know we could talk a little bit
about what that looks like
but I could see there being a dynamic
that's really just like hey let's gather
everybody that's not you know these two
countries these two authoritarian
countries and have them all start
getting way strong I could see it as
almost an accelerant to a felt sense of
aggression as a as opposed
to maybe some degree of deterrence of
conflict if such a thing is remotely
possible you know the safety Summit is
just words Mike I'm not seeing it as too
much more than that
but gez imagine if the safety Summit you
know either the China or the US was like
no AI will do whatever we damn well
wanted to do and that was the position
and posture I would say even though
those are just words too I would feel
like that's consequential and there's
ways that we're inching closer to a felt
National sense of tension and aggression
you know on either side of the fence or
not I could see the Coalition argument
which which I'm not disagreeing with um
feel like a
firm marshalling of power against um a
certain set of countries and potentially
accelerating conflict would you say Dan
look uh we're dealing in the real world
it's literally all we got or would you
say Dan maybe here are some ways that
maybe they're not going to be as
involved on some of the freedom stuff
but that I would hope we could get some
degree of Buy in in ways that would
reduce the likelihood of you know Wars
and whatnot I mean what are your
thoughts there
um well I think more important then
everyone agreeing and coming up with
kind of a least common denominator is
thinking about more the most that you
could get done and who are the countries
that are interested in that uh my guess
is China is not going to be aligned with
that but it would be great if at some
point they were aligned with that um but
I think we'd have to start with what are
the countries again you know part of my
uh thinking is you want to use the
technology to reinforce the values the
freedoms yeah basic human rights uh and
so if the countries are not aligned with
that um you know they're welcome to
watch but uh we're not going to be
bending to yeah again make this the
least common
denominator yeah
man you you brought up you know again
the the early kind of AI safety talks
some of the statements between the US
and
China we're we're in a tough spot with
different governance models here uh and
uh but is there anything you would hope
to see more of you don't want you don't
want a seating of common denominator oh
let's let's make it okay to do X number
of Wagers not all of them but X right
you you're not looking for that and I
get that I get that Mich correct correct
I think I think we're gonna have to live
in the complexity of uh if if we were
able to create what I asked for uh we're
doing that in combination with
discussions with China and Russia on on
what can be done that we can agree with
which might be the the least common to n
the minimum set those those will have to
coexist there might be separate sour so
there might be a pure existential threat
convo that we can all look each other in
the eye and say right you don't like how
I govern I don't like how you govern but
neither of us want our people to die and
this doesn't have to be personal like
what the heck can we do to make sure
that we're ramping that down but then on
the things that more overtly are about
anchoring in values let's just GA gather
up the the Allies there fin final sort
of quick Point here Mike would love
would love your take on this as I think
about where this Tech goes again I I
think it's going to be interesting to
see what nation is starting to ramp up
and really cross this threshold I do
believe Mike you know if we chat five
years from now 10 years from now there's
going to be some stuff skirting the
edges of of wow level like where it is
somewhat clear that maybe the road that
you said maybe would be 15 25 maybe
longer then maybe yeah maybe that
checkpoint at some point would would get
crossed and that something as not
tomorrow but as far above us uh as we
are above the the chimpanzees we're at
the wow level now exactly exactly but I
I think we're going to have we're going
to have a couple even even even more of
those I could see that ramping into
conflict there's a part of me that says
okay if open AI let's say they get a
gajillion robotic instantiations where
10 years in the future you know they've
raised another s 7 trillion if you're
Sam Alman right now right or whatever
the number was uh um and it's it's sort
of AI is doing physics humans haven't
done we're inventing entirely new
materials things are levitating like you
know continuous motion machine I mean
like I'm talking about clearly alien
things things that are starting to feel
like an alien is landing on the planet
my guess is that's not going to be able
to stay a private sector thing anymore I
have long felt as though there will be a
check mark and Microsoft an opening I
must already know of this and have a
plan for this whereby something's going
to get command deared um because uh I I
doubt the dod is just going to say well
you can birth the sand deity and we will
just sit here with our rusting tanks and
allow this you know nanotech you know
like thing that can conjure materials
from Air to just do whatever it does
over in this dark corner right it does
feel as though there's a threshold of
power where this becomes National and
not private
anymore does that sentiment click you
know with you do is that does that feel
like a reality if we start closing this
Gap here cuz I I kind of can't see it
any other way when I look at the next 20
years well it's a that's a really
provocative statement uh we'd have to
get into the specifics I think but I I
could see for the foreseeable future
again kind of where the conversation
started any technology you could
Invision whether it's you know infinite
amount of energy they get created
because you've done something beyond
what Fusion could do uh materials that
get created Al for good and for evil so
I think it's I think it will be the same
thing I think it will be we'll want to
enable use of that technology as broadly
as possible across Society to for the
good purposes but we're gonna have to
think about how what are the negatives
how could that be used to harm everyone
and that's where I think you want to
make sure you've already done some
thinking about governance and have some
things in place I don't think it's a let
the defense department decide whether
something gets
uh used broadly or not imagine if the if
the defense department had said to DARPA
great that you're working on AI or GPS
or you pick uh but uh we're not GNA
allow that you know into society we're
going to keep that in the military and I
think fortunately the military's done a
pretty nice job of even when things are
created for a National Security purpose
um the government has allowed that to be
Comm calized and and used for everyone's
benefit you know maybe this will emerge
as an ecosystem of
intelligence um where the dod will still
be able to play its its role in sort of
funding and still being the muscle um
but allowing these things to bloom
certainly being a customer of these
things right wielding it where it's
relevant for them and of course we cover
more and more uh of those kind of
companies here um at a merge uh you know
there's a part of me that says if there
is a singular company that quite clearly
is creating like post human intelligence
to the point where like this this
organization may just be more powerful
than any country in the world if if if
this thing can can do what we think it's
going to do I would think some weird
threshold would have to get across at
that point but to to your point um Maybe
not maybe it actually will remain pretty
correlative to the way other
technologies have come about where where
it is sort of a free uh environment of
innovation it'll be fascinating to see
where this stuff goes I would hope for
that that that's my hope for the world
not that things are going to be so
powerful they have to controlled in a
secret room I um I've got my fingers
crossed that too certainly not anytime
soon Mike I hope by whenever whenever
the heck you and I chat again uh we're
still pretty far from those big
thresholds because to to a lot of the
Credence of what you've brought up we're
not even doing the baby steps on
governance yet today but you've been
able to lay out a little bit of what
you'd hope uh this Tech or this this
coordination efforts to achieve um what
you think some of the immediate risks
are we should be mitigating and even
some of the early steps that you know
between allies and and between you know
let's say adversaries uh could happen
today to to to lean a little bit closer
to good and hopefully farther from Bad
outcomes and I can't thank you enough
for it Mike this is our longest convo
yet and I've enjoyed it tremendously
thank you so much for being here oh me
too me too Dan I'm glad that uh you're
raising the visibility of these types of
issues critically important so that's
all for this episode of the trajectory
this has been our second episode on AGI
governance Mike was less specifically
focused on aggi than Sebastian but
brought a very interesting perspective
nonetheless to the series I think some
of the international tensions have to be
addressed here if we're talking about uh
the policy for strong AI into the future
hope you enjoyed this one down below in
the show notes as always is the link to
the podcast if you prefer audio you want
to tune into this on Apple Spotify Etc
uh in addition to that um you can find
in the show notes the link for the
newsletter so you can see these episodes
as soon as they come out live in
addition to the latest articles and
infographics on the real politic of AGI
and the post in transition as well as a
full linked article which not only has
the embedded video for Mike Brown's
episode but a bit of a breakdown and
Analysis of his position to the four
core questions we're answering so if you
want to compare these guests as we
continue to go through and interview
other people you can click on the
article in the show notes and see a
written breakdown of sort of what their
position is about how urgent AGI
governance is what the purpose of it
should be and the other questions that
we're going to be asking all of our
guests the goal is to bring a panoply of
perspectives together and I hope it's
helpful for you our next episode is with
a man very well steeped in the
technology of artificial intelligence um
who also happens to have started the
most significant what could be argued to
be the most significant AI event in the
intergovernmental policy world for
artificial intelligence um and he's
someone with very much a perspective on
the bigger AGI picture brain computer
interface we get into some fun stuff
next time so stick around in two weeks
we're going to be jumping with our next
mystery guest here in the AGI governance
series here in the trajectory
