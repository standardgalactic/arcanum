I mean I I also don't want myself or my
my kids or grandchildren to be uh you
know turned into computronium to make a
new hard drive for the for the for the
super AGI however I have extremely
little faith
in existing actual real governments to
sensibly regulate AGI in a way that we
do more more more good than harm like in
in theory if we had a rational
democratic truly Democratic world
government then in in indeed having the
human species regulate and guide the
growth of AI will be a highly int
intelligent thing right given the
current actual situation I I I just
think the government getting involved is
more likely to more likely to mck things
up than to than than to help things
this is Daniel fella welcome back to the
trajectory we continue our focus of
destinations or future combinations of
man and machine that we might want to
move closer to and our guest this week
is someone who you really can't leave
out of an artificial general
intelligence conversation and that is
none other than Ben Gerel uh Ben has
been involved in this space for
literally decades and my first interview
with Ben was I think something like 11
years ago uh to this day hardly anyone
I've read more of in terms of their
social content their personal blogs than
Ben and as the big llm craze has sort of
taken off uh Ben certainly has some
interesting perspectives about what will
get us to or maybe keep us from uh
beneficial artificial general
intelligence Futures we disagree on a
great many things um AI safety being
very high among them uh in addition to
sort of the incentives of men in the
acquisition of power I'll talk about
that in the outro of this episode very
key to the trajectory to talk very
squarely about incentives and you'll
hear me do that in this episode but
respect Ben's perspectives regardless
it's great to be able to get some of his
Vantage Point as to where we might be
headed and what we might do to make the
future better uh at least unto his
perspective um so without further Ado
let's go ahead and dive into the episode
this is Ben gzel with us on the
trajectory
Ben good to be able to chat
again yeah good to be good to be back
it's it's been a while and with the as
fast as things are moving now like if
you if you miss a week there's something
amazing new in the world of AI right
exactly our first couple interviews were
six years apart and it feels like uh six
months is now a significantly greater
time Horizon for change so it's it's an
app time to talk about what we're
talking about here which is Agi big
series lots of great perspectives um
unlike some of the folks we've had on
the the program who have a different
background than yourself you've been on
the ad AGI tip for quite some time and I
was just talking to off microphone about
when Bostrom maybe it was eight years
ago 10 years ago kind of did a a poll of
AI researchers and different
organizations when might we get to AGI
there was some muddling consensus in the
2060 range we did the same thing and
emerg and got a similar kind of range I
forget if you were part of that series
or not um you're now talking much more
about Kurtz's time Horizons of
2029 I want to check in and see are you
still there or have you updated yourself
forward or back in any way shape or
form yeah I'm I'm I'm still there I mean
I think if I approach the question in
different ways I'll come up with
different answers but in the end Ray K's
extrapolation of human level AI by 2029
still seems like a perfectly reasonable
ballark estimate to me I'm still
skeptical as I've always been of his
idea that we'll get human level AI in
2029 and then not superhuman AI till
2045 though like I still think that he's
somehow underestimating the potential of
recursive ramp up yeah recursive self
improvement I mean if if I put my
Optimus head on and look at the work I'm
doing now with my own AGI projects and
open Cog hyperon and so on I could I
could see how in theory if things go
super well we could get there in two or
three years but still that sort of
thinking is always much rougher and more
dodgy
reay's extrapolation was you know
relatively rigorous as as as these
things go as you can yeah yeah yeah I
mean it's not perfect You could argue
about each point and his predictions
have not all been right but on the other
hand qu qualitatively he's clearly been
like in the right order of magnitude and
Jing in in the right direction I'm
actually shocked that more people don't
wake up in the morning and say to
themselves wow ctz wow was right about
so many things it's frightening like I'm
I'm shocked that more people don't say
that like he's out of the common
discourse today like back when you and I
first met I mean Ray was still kind of
the guy right if there ever was a wacky
TV thing because it was so far from
Baseline reality he would be the guy to
talk to he's out of the common discourse
but so much of that was right um if you
were going to distill for the people
tuned in what makes you feel like 2029
we're talking you know six years here
we're talking five six years to have ai
that's you know as smart as let's call
you know the phrase median human has
been bandied about and has offended some
people but I'll say it and then for you
there's going to be a f after that but
just to get to that
2029 what's your tightest distillation
of hey here's why this is completely
viable I think there's a number of
different lines of evidence rather than
only only one thing you could point to
go for it the first thing is Ray Kell's
extrapolation and many other
extrapolations along the same lines
where you're just you can take many
different indications of increasing ing
intelligence you know not just speed of
processor but you know how how advanced
are the math theorems and AI can do how
well can it recognize human emotion how
well can it do translation how how well
can an AI drive a vehicle all these
things you know they're progressing
erratically but on the other hand
they're all progressing e exponentially
and if you just plot all these curves
you come up with something around around
that time you could you could fudge on
the details you could say well maybe
it's 2026 maybe it's 2035 or something
but it's not like 2200 and it's not
tomorrow right so that that's that's an
important line of evidence because it's
somewhat rigorous and you can try to
make it more and more and more rigorous
but I I think that's that's quite
reasonable rational thing to look at now
if you look specifically at what AI
systems can do right now I mean I I
think that's another important line of
evidence I don't think that chat GPT or
llama 2 or any of these current large
language models are General
intelligences in the sense that humans
are and I don't think that just
tinkering with those is likely going to
be a successful path to human level
artificial general intelligence although
they may be part of the part of the
picture but still just like as a human
being interacting with these things like
there there's something there that was
not there before right like there there
has been a qualitative leap there's been
a qualitative leap to toward AGI even
even if it's not there right and that
and and I think dismissing that is a is
a mistake even if you see that no this
is not it's not the only yeah it's not
the only path I'm really glad glad
you're saying that because I I know that
you know you've got your own dog in the
fight right I mean you're You're
Building AGI yourself uh there's a lot
of big players in this space um and uh
at the end of the day like um the
uh there are yeah there's there's
players who are racing forward with
technologies that maybe you didn't
invent but maybe have had some ideas or
or kind of correlated ideas about has
there been anything you know I saw
something the other day um just the the
the ability very recently and of course
now Ben things are moving incredibly
quickly just this notion of sort of AI
to be able to take a screenshot of uh or
take a picture of a napkin that has some
kind of a drawing of how a website would
work and converting that into CSS or
taking a a photo of some kind of to be
honest that that that
stuff doesn't give me that same like the
inter the interpretation of jokes like
like a four square with like some actual
irony in there and then and then that
stuff
gez so there I mean there's a lot of a
lot of amazing things that large
language models can do I think for me
personally you know my original
background is mathematics so I tried
some experiments both with uh with llama
2 and with gbg4 I tried some experiments
where I took I took some new
mathematical ideas which I cooked up
with my friend Greg Meredith so I knew
these are not in the training Thea like
these is new weird math that Greg and I
made up right and so I just try to get
these large language models to take the
new math we made up and take some some
some some next steps right and then ask
it to justify those steps and it's quite
impressive how well it can do like it's
not always right and sometimes it's
judgment is demented and foolish but
then you can tell that it it will
usually direct it so it's it clearly has
the facility to play around with
category Theory as applied to various
Advanced data structures as applied to
different sorts of AI algorithms and I
was trying to do a test there on
something that we just made up so like I
know it's it's not in the training data
now to be to be noted the system was not
making this stuff up right like Greg and
I made this up yeah it's not able to
creatively come up with new mathematical
ideas but if you give it if you give it
a new mathematical idea it's very very
professional at you know shuffling
around mathematical Concepts and symbols
and ideas even at the like Advanced like
post post PhD level so that yeah that
particular particular experiment was
interesting for you that that that I
wouldn't say it blew my mind but that
made me think like wow like I if if IID
built this i' I'd be pretty damn happy
proud of myself yeah or not I would say
that's it's not the first thing in my
career that has seemed of course amazing
I mean I think you know computer algebra
seemed amazing to me like when you could
first take like Mathematica or Maple
when you could First Take A system that
would just do solve a differential
equation or or simplify an arbitrarily
big algebra expression like that that
was that was mind-blowing in a while and
then deep blue you know beating Kasparov
in chess B deal I mean that seemed like
he had to be a genius to play chess Soo
but nope just crunch crunch crunch
crunch crunch and in in robotics I mean
both things like big dog little dog like
these boson Dynamics robots that can
romp all over and then seeing Sophia
robot like help people meditate and
reach some some state of bliss by
looking in their eyes and smiling with a
robot face I mean there's there's been
yeah things that have turned there been
various other things that have made me
say like whoa this may not be AI yet but
it but it's real right but but yeah the
large language models definitely have
had that impact and then the I think the
the the third thing that gives me
personally confidence we're close got it
AI is just my my own my own research
right like we haven't gotten results as
shiny as as what large language models
have but I I can see just so many
research ideas and prototypes and
algorithms I've been working on for
years and my colleagues have been
working on for years they're suddenly
working working better and better right
so we're seeing like with more compute
power more more data modern languages
like things that we thought would work
10 20 30 years ago they're now seeming
to work you know the way that we thought
they would they would all along so just
there's yeah you got the general Trends
you got the observe functionality of
certain AI systems and then you have a
research intuition which is fueled by
just better backend functionality of a
bunch of longstanding AI ideas so
putting all those okay seems like we're
going to get there soon but then what's
what's the counterargument right the
counterargument is well maybe there's
some hidden rock that no one is for
seeeing and of course of course of
course maybe could be there could be
yeah and not the main focus of the
interview but I I think just hearing
that the three are sort of where the
majority of your confidence comes from
helpful to te us up I think there's
going to be people listening in that
that don't agree and others others who
do but I think there's a lot more who
are going to agree than who might have
four or five years it seems like chat
GPT blew everyone's mind AB Absol
absolutely and I you know rightfully so
again you have a dog in the fight you
can't be oooing and on about it quite as
much I get it I get where you're sitting
but um but yes it definitely splashed it
onto the radar for many many people
given the fact that this stuff is now on
on the radar this is where I wanted to
take us here
um the public now has thoughts around
artificial intelligence and what this
might imply for them there's even more
kind of common parlament discourse about
AGI we're looking at I mean there's an
oecd group that I'm a part of with Benjo
that's overtly have at least a pinch of
focus on strong AI or AI personhood the
UN is talking about consequential like
uh catastrophic risk from AI these are
things that I thought were going to be
2030 2040 things five years ago no lie
um when you look at where Society is
today I shared with you kind of that
intelligence trajectory brief Matrix for
a second I I kind of know where you sit
but let's just talk about kind of a roll
up of the average person in let's just
use America if you're okay with that you
know we just go out on the street to
Kentucky Massachusetts whatever we ask
people you're talking to a lot of the
the Deep Tech folks as Ami but your
sentiment around where people are where
do you think they are roughly on that
quadrant from sort of you know total
humans only to Ascension and then and
then kind of that that gradient of
freedom to
control I don't know that I'm a
particular expert on what on What random
people think I mean you speak in more
conferences than I pal so that's true
but but that's a particular selected
portion of the human human population
right sure who even comes to these these
conferences that's without a doubt I
mean it it's it seems
like qualitative
we could even just talk about your
average nerd the people that you hang
out I look at it a little differently I
think sure I think qualitatively the
average young person in us China Japan
Africa or wherever so the the average
let's say literate young person any
country I visit I just spent a month in
China talking to a bunch of people seems
like the average literate young person
now basically assumes that AI as smart
as humans or smarter than humans is
coming pretty soon and then that's going
to lead us in like wild unimaginable
directions what what one one one way or
another like this yeah this this
perspective is almost Common Sense among
pretty much everyone I meet everywhere
like uh under under 30 35 years old
okay and that I think they're just
looking at what's happening during
during their lives and and looking
looking around
I'd say in in Asia you have the default
assumption that this will all be for the
good of of humanity and it's all it's
all do you really that's a default you
would say across Asia across Asia in the
US it seems the default assumption is is
maybe the Terminator but that that that
I think is a particularly American F
fixation for some reason well yeah I
know we have differing perspectives a
little bit on AI friendliness but I I
was unaware of this General consensus in
Asia they seem they you know they love
robots
that's a Japanese thing they got the
Shinto deal I mean every China has so
many humanoid robots now you know so in
China this year there's probably been
around 70 large language models trained
by different Chinese institutions like
50 plus AI conferences with AGI as a
significant theme just this year right
so that there China is full on into this
and they they the Justa or vibe there is
that it can be
in a in a
positive and then just thought just
thought here is a little different right
so it's not that they think it'll be
entirely good and nothing bad could
could ever Happ ever happen there's just
there's a sort of
overriding idea that nature comes and
goes in in waves and things will correct
themselves and that they don't they
don't see AGI as like outside the
outside the big picture of universe
Evolutions somehow in that regard I
would concur with them
astronomically um uh but uh but I'm sure
there's other regards maybe I wouldn't
let's roll it back you're not an expert
on uh the American populace I to be
honest Ben neither am I if we just think
about when you're hanging out in North
America we'll just use this as a
reference point you're bouncing around
to different
conferences maybe it's just the people
at those conferences they've self-
selected they're AI people whatever um
do you see where do you see them on kind
of strata number one and strata number
two do you see people leaning more
authoritarian and totally humans first
do you see them kind of hanging in the
middle and not wanting to go full
Ascension which I know is a little bit
more of the camp that that you you know
hang out in at least in terms of the the
long term where do you see them sitting
plotted I
think I think people are fairly confused
on on most of those issues I mean I mean
I think I think most people who are
paying attention and who aren't wrapped
up in some religious perspective or
something have increased
their probability that something like
AGI or super intelligence what will come
soon right as which
is it's reasonable it it it makes sense
it's not just chat GPT it's like even
though Tesla self-driving mode isn't
really self-driving mode yet like it's
it's a lot better than Cruise control
from 10 years ago right so I mean I mean
people can see can see things coming
they can see you can you can translate
back and forth on your phone in a
passible way you didn't used to be able
to right so I mean you didn't used to
have grammarly right so I mean yeah I I
think people can see that as to
whether government or regulation
can really guide the advance sure I
think people are a bit
are a bit confused and as to as to
whether it's best to move ahead rapidly
or to slow down you know out of safety I
think everyone knows there should be a
balance but no one has a clear picture
of of of how the balance it's hard not
to be confused I think right no it is
it's confusing I think as far as how
fast to personally Ascend and plung into
the future like whether whether to fuse
your brain with the with the Matrix or
something again I think people will
defer that until the time comes just
like they'll defer whether to get a
folding phone until until a couple more
exactly exactly I mean that that's
that's the general the general VI Vibe
vibe that I get like most people are not
so ideological about they're not like
coming
down I don't think everybody should I'm
certainly not even asking you to uh but
in terms of it it sounds like on the
policy side you don't see them the
people you interact with let's just talk
North Americans Ben geril has conversed
with about AGI AI in general whatever
you don't you don't see them leaning
authoritarian or leading too much toward
freedom but maybe somewhere in the
middle kind from a Global Perspective
Americans lean quite far towards Freedom
yeah I think Chinese or Chinese or
Western Europeans are far more likely to
be in favor of of
heavy-handed government
regulations Americans are sort of
wavering about it but that but that
means that from a Global Perspective
we're we're quite far away now if you
talk to Africans um we have an AI office
in Ethiopia where SP the Africans have a
far greater mistrust of of government
than than than Americans for decent
reasons yeah yeah yeah all the
government of course corrupt
cannibalism they're just like you know
life is very difficult let's take a
gamble on building super AI we certainly
trust that gamble more than we trust any
of the corrupt governments around the
world may or may not be the best place
to come from but it's certainly a
valuable perspective and makes sense
given where they are um but I guess to
your point yes we're Americans are
leaning less towards authoritarianism
let's than let's say the rest of the
world I mean so so far we fa we failed
to reelect Trump so far also right so
sort of we'll see of move a little
bitan oh man well luckily luckily I
don't run a a politics podcast but by
golly that's going to be its own wacky
stuff when we talk about the the second
strata not the political control where
it sounds like for you America's a
little farther down than most but not
totally into Freedom land we're kind of
in the middle-ish confused as you said
on the strata uh from left to right
going from sort of humans forever top of
the food chain end of story billion-year
uh monkey Kingdom all the way to sort of
let's immediately blast off tomorrow if
possible uh as quick as we could go when
you think about that strata I want to
bring up something I've seen that you
mentioned about the flip phone and I
want to get your thoughts on this so
again we talk about this North American
population here my sentiment is so our
previous interviews in the series I I'll
use I'll use people who are not a man on
the street as our examples one of them
is Yan talin the other is Benjo so for
talin the last time I spoke to him which
was actually out in Dubai I know you
just came back from you know that region
not too long ago um he he spoke pretty
overtly about sort of the
inevitable you know blastoff of
intelligence into the Galaxy doing you
know vastly more interesting things and
that that this could be like a
beneficial sort of direction for us to
go when I spoke with him now he feels
the heat of how much closer this is
getting he's thinking a lot more about
regulations what the Safeguard should be
what the research alignment globally
should be and things like that and my
intuition Benjo oddly enough was uh
fully willing to concede hey just like
there were things before humans there
will be things after humans that you
know and and to you to your point about
the eastern perspective I frankly think
it's very very hard to look at the world
and not have at least a little bit of
that doesn't mean we need to eviscerate
Humanity but it's very hard to imagine
that this whole Grand project of
bubbling up potentia is going to end at
hinness but but for Benjo as well very
focused on regulatory my sense is these
are people who are alive now you know
some of them have children and maybe
they're thinking gez can I wait until I
get this flip phone like I I know this
is exciting maybe it's even where things
are G to go as you know five children
plenty yeah you got plenty one of which
I'm friends with on Facebook so yeah
five children and and one one
granddaughter which is Zar Zara's
production yeah yeah yeah yeah I mean I
mean I I also know want myself or my my
kids or grandchildren to be uh you know
turned into computronium to make a new
hard drive for the for the for the super
AGI however I have extremely little
faith
in existing actual real governments to
sensibly regulate AGI in a way that will
do more more more good than harm like in
in theory if we had a rational
Democratic truly democratic world
government then in in indeed having the
human species regulate and guide the
growth of AGI will be a highly int
intelligent thing right given the
current actual situation I I I just
think the government getting involved is
more likely to more likely to mck things
up than to than than to help things I
mean that's just a it's a practical
practical Point rather than in
principle the the theoretical point and
and I think think
Americans and venio is in Canada of
course so I mean Americans
have a healthy and sometimes unhealthy
mistrust of of of government right so I
think
there's certainly more people in America
thinking about it my way than in favor
of
Regulation what I think is it's it's
unpopular now to come out there publicly
and say like government pretty much
sucks it's not going to do any good it's
just going to make things worse like
most people who think that will just
keep quiet about it where it's coming
out there and saying yes we need
regulation we need the government to be
responsible and guide things this this
is a very socially acceptable you know
positive sounding thing to do so people
people who think that way are more
likely to go out to the media and and
and and and and say that right so I mean
I think you get I think we get a bias
view on how many people like the idea of
regulating AI just from the different us
us is very politically correct in in in
in in a strange way right s you are
right about that certainly much more so
than 10 years ago when we first started
chatting um I I think uh to your point I
think yes there is maybe there's more
loud voices on the regulation side than
the hey just stay away from me side
there definitely is that crowd on
Twitter you want people to stay away
from you the best way to do it is just
be quiet and just keep doing it exactly
right exactly stay away from me me
absolutely me well there's there is the
crowd on Twitter for example many of
them are Anonymous though to your point
Ben they're Anonymous who will say Hey
you know uh leave alone my gpus I'm
going to build AGI and we're going to
blast off and you know there's there's
this contingent which by the way that
that pedal to the metal contingent that
full Ascension full Freedom contingent
bottom right that really didn't exist 5
years ago in the common parlament or the
Twitter sphere even even in like the you
know the it back 10 years ago I don't
think in Twitter but those those people
they existed I mean I mean people those
people have been there longer than
longer than I've been alive I think most
of them have not had this possibility on
their state space of possibilities
though they've been they've been having
that attitude of accelerating towards
towards other things right this this
human propensity and I think much of
where we lean is just some nature
nurture hoopla that we then later
rationalize um that propensity has very
much existed since before you and I but
I guess where I was going to try to land
then I've got a little follow on to this
so I want to kind of get us back um this
trajectory from sort of pure
preservation of humanity at the top of
the food chain AI is a tool and nothing
more frankly never strong AI to
progression where maybe we start
tinkering into transhumanism maybe AI is
aiding us in a big way but it's very
much Still Human all the way to
Ascension which is hey let's hand the
Baton upwards and let's let potentia
continue to roll uh in in beautiful
waves towards places where where we have
I don't think many people want to make
that choice so I I mean go ahead I think
people will just
stay am ambiguous on that as long as
they as long as they possibly
can in the end people would like to have
it both ways and it may be possible to
have it both ways like it's it's not
clear there's a contradiction between
humans continuing to do their human
thing and some super AI being created
and ascending to to the infinite like
it's not clear that it's not clear that
both couldn't OCC I think that I think
that's like a Sophie's Choice thing
right you I mean you'll make you make
that hard Choice when you have to make
it and then then you'll see what regrets
you live with but you're not going to
you're not going to make that choice
proactively because each of these each
of these is important and amazing and if
you if you take it a little deeper so if
you sure if you look at the theory of
open-ended intelligence put forward by
my friend uh Weaver in his PG thesis
called open-ended intelligence from the
Free University of Brussels he takes a
sort of philosophical view of how the
mind works and he he says an intelligent
system is a complex self-organizing
self-creating system driven by two high
level motives one is
individuation like maintain your
boundaries maintain yourself survive the
other is self-transcendence like grow
and transform into something
fundamentally Beyond yourself and yeah I
mean this you could look at this is this
is what drives evolution of Life
absolutely but the dichotomy that you're
posing is just that right like do we
preserve what it is to be human or do we
radically self transcend and Ascend and
create something utterly different and
the thing is evolving living systems
don't usually choose one or the other
they they it's a dialectic right and
they they kind of get some of one some
of the other and from that intersection
maybe
something unprecedented comes out so
this is this is he hegelian hegelian
dialectic yeah yeah well if probably
baked into the Chinese view of things at
some level some some to there's probably
some tost corollary I'm sure but if
we're talking philosophers your
open-ended intelligence fell I mean
Spinoza's canus and Spinoza's potential
are pretty pretty well check in that box
already my dude uh you know in my
opinion and I and I think absolutely
right that seed of life I think has both
of those things to your point and I
completely agree with you I'll just make
a distinction here to your point I think
most people will be ambivalent and to
your point it is quite possible that
we'll see some piping plovers sitting
over on the corner remaining purely
hominids and we will see some uh you
know people racing off to you know jack
their brains into some other substrate
right right but if if we get good enough
nanotech you can do both right I mean
what one then prow in the field exactly
exactly I'm totally with you I don't
think I I don't think I'd keep the field
frer per se but but I get it um someone
else somebody else will someone else
someone else may generate one and who
knows what'll oh no replicated Dan in
the woods uh but uh but yes I but I we
are seeing so to your point I completely
believe most people are ambiguous and
they will go where the wind blows you
know I probably got a flip phone exactly
the way you articulated it and that's
probably how I make most decisions not
all but most decisions um there are some
people quite firmly been as you know in
the hardcore preservation Camp the
bioconservatives as our James Hughes pal
would might say and then there's other
folks who are very squarely in the
blastoff tomorrow Camp some of which
even to kind of a bit of a cartoonish
level of like you know uh AI could never
be a RIS to anybody let's just
completely pedal to the metal the first
thing that could blast off to AGI let's
absolutely do it there's sort of those
camps do exist but I guess what you're
saying is hey most people are ambivalent
here's what I'm here's what I'll kind of
pin down because I have one question to
follow it if you were to guess the
people who were maybe somewhat
deliberate who you've talked to at your
various conferences they're going to
skew nerdy do you think they'd hang out
in that middle slice of progression or
do you think most of them are still in I
don't think they're in Ascension your
average person I I don't unless you do
but do do you see them in progression or
do you see them maybe on the edge of
preservation but not quite cross
crossing that that line um in terms of
being I think a lot I think a lot of
teenagers are in Ascension in in your D
okay great wow I I think the old older
people get the more the more they get to
more I do agree with this Ben I do agree
with this yeah uh but but would you yeah
for you the older so for you it's
literally an age thing it's like yeah
young people today out here really old
fol among reasonably well-educated
people who aren't religious or otherwise
ideological like people in the same sort
of culture and mental world as as as we
are yeah I think I think it's sub it's
more an age thing than than anything
else awesome take I love this it could
be empirically evaluated though yeah
yeah I'm sure we could sample it but I
love this take it's like because I would
expect maybe you'd kind of have like oh
you know some people have but you're
literally you're just articulating it as
almost being that simple and I think
that's great here's the follow on
question so most people kind of confused
about regulation maybe they're floating
closer to freedom in America than others
but you know we're we're kind of
somewhere in the
middle the the progression to Ascension
thing sort of just varies by age is
there a Direction you feel us getting
pulled in North America in other words
do you see us getting pulled to the top
right towards maybe somebody controlling
and and sort of government really
closing in quite well right now there a
lot of forces there do you see things
moving maybe more in the decentralized
world which obviously that's the game
that you're in and it's it's your it's
that's your belief is more of kind of
that L Fair governance uh towards
Ascension what direction do you feel
like the strings are tugging Us in right
now if you and I just disappeared
tomorrow where would you as a betting
man guess that the world would
drift well you started with America then
you ended up with the world and then
well all right let's let's do America
Let's Do America brother let me let me
keep let me keep it bounded I think
America is clearly going in the
direction of giving vigorous lip service
to AI regulation but not actually doing
anything meaningful okay sort of like we
did with financial regulation right yeah
yeah I I I think China
is going to heavily not just regulate
but the central government will guide
the their their work toward toward AGI
and I think Europe is going in the
direction of heavy regulation right so I
mean that's how it seems to be in terms
of in terms of
Ascension I think you know from my sort
of age-based
analysis I think a consequence of that
is Ascension is going to become more and
more popular like I don't think all
these people I don't think all these
people are just going to change their
view when they get a few years older I
think it's not just that youth have a
higher risk tolerance and that these
people grew grew up online like you
know my son is 33 is you know I mean I
remember he was a little kid he's
watching I know Digimon or Transformers
like this this generation grew up
watching super intelligent robots and
mind uploading and virtual reality and
so for like it's this is sort of
programmed in their minds from from dumb
action cartoons from when they from when
they're when they're very little so and
that so the I mean slowly then the old
conservative people die off and the
people who grew up with with you know
Digimon and Transformers baked into
their brain are gonna are going to grow
up the the thing is though if 20209 is
right then that sort of process is very
slow compared to the actual Advent of of
AGI of course so so I mean then then
what really drives things is going to
be as people see what's inevitable they
going to embrace the inevitable because
this is this is what is what is what
people tend to do so I I think I think
when the likelihood of Ascension gets
more and more palpable then more and
more people will say yes that's what I
want all along right just like when the
immortality pill is there everyone who
used to say well death gives great yes
yes yes yes
there they will eat it and say Yeah in
fact I I never said otherwise I
always I I concur in that regard I I I
don't know precisely how everyone will
react because I I'm not sure if ens will
be available to each individual person
but in terms of where you hope for us to
go that's certainly part of the vision
so I've got one final question but I
want to touch base on I mean about about
Ascension not being able to every
individual person though I mean I mean I
think you know the the roll out of
mobile phones and prescription
medication and so forth is part of an
argument that it will be available to
every single person I mean that seems
the nature of most most Technologies I I
mean I mean once yes initially they're
not available to every single person but
making making it the first time is
always harder than scaling it up and and
and decreasing the cost I'm with you I
think the the the es here which I don't
think we're going to get to unpack in
full are sort of when we do get to
AGI um how much control do we really
have and I know you have a take there
but that's a different question
completely different question question
know if AI might not make it available
to any person if it comes out a bad AGI
my my argument was more if the AGI is
well disposed towards Humanity it's not
going to be hard for to offer Utopia and
Blissful mind uploading to everyone
inste this to its favor 500 people or
something I think there's there's
certainly some people in the why would
it have 500 favorite people at all camp
but I'm but I'm I'm with you so that
there is an if there but to your point
yes if there is a an AGI that is well
disposed towards Humanity I would expect
the benefits to be pretty widespread you
obviously have a pretty firm take on
what that might look like I know from
reading everything from the cosmos
Manifesto and a bunch of your other work
um I'm I'm a big fan of that one by the
way but uh that you do see a gradation
some folks that want to you know have
one physical body that's here and maybe
another that's uploaded and have kind of
a transhuman experience and maybe level
things up more gradually and that people
would have a Divergence of what growth
looks like for them uh and freedom looks
like for them um and uh this is sort of
your notion of course the decentralized
idea of AGI I know is pretty close to
your heart about how that gets achieved
if you're going to Nutshell and I know
this is hard and I encourage people to
read more of your work but if you're
going to Nutshell the pathway in other
words the most important elements of how
to get into that direction where this is
something decentralized the benefits are
incredibly widespread people have a lot
of autonomy about direction for their
own Ascension or not um what are the key
ingredients there for
you yeah there's a number of different
ingredients and if if if if I if I want
to break it down into several elements
so one element is how is the ai's Mind
designed what's the cognitive
architecture and another element is who
owns and controls the AGI and then
another related element is what is the
AI taught what what is it doing how is
its mind being shap being shaped by
action right and I think you probably
need all three of those things to to
line up well in in order for things to
have a high odds of coming out
positively so let's go going through
those in in the opposite order for doing
in terms of what the AI AGI should be
doing I mean I think there's a decent
argument that if early stage agis are
doing things like education and health
care and collaborating on Art and
Science rather than pursuing them in an
explod of way so if the agis are doing
things involve say I thou heart-to-heart
connections with human beings in helping
other human beings and creating things
to to help other human beings I mean I
think of a grows up in this sort of
positive activity that will help to to
shape it it its mind and that I
understand that's not an ironclad
absolute certainty of course even a
human being can be brought up in the
most wonderfully beneficial setting in
Apprentice for in the most loving tasks
and they could they could turn out being
an evil psychopath but but it seem it
seems like the odds are better in that
way for a variety of reasons so in terms
of the ownership and and control I mean
I I feel that if a narrow group with its
own special interests is in control of
an early stage AGI it will be very hard
for that
AGI in the sort of Just Around Almost
Human level stage right it'll be very
hard for that AGI not to go the
direction of pushing for the good of
that small group of humans to the to the
detriment of of of other other groups of
humans because that's
that that's what human organizations
tend to do I mean countries want to make
themselves the top country and and
squash down in some way the other
countries companies want to make more
money than other other companies and and
and so forth and these organizations
have come together sort of around that
principle of like we're we're going to
be better we're going to be better than
you right so again it doesn't have to be
that way I mean you like you had
gorbachov right who chose chose to down
down chose to down I the Soviet Union so
it's not it's not a guarantee but
certainly it's it's the way things seem
to go and so if if we look at you know
US Government I lived in DC for nine
years I worked with various US
government agencies on the whole most
people there are really trying to do
good but when I was working with folks
involved with the US Military and they
were you know blowing up people in Iraq
willy-nilly so what yeah these people
believe this was for the good of freedom
and democracy they're still blowing up
all these innocent people right so I
mean and you look in Google most or I
want to pick up pick on any particular
company yeah yeah yeah look at look at
that in particular like most Engineers
there are good-hearted people who want
to make great products that will serve
the world with great Tech but I saw like
a wired article yesterday explicating
what many people knew all along which is
like when you type a search query into
Google behind the scenes they have code
that rewrites that search query into
into into a different form that will
then make it more likely to make certain
certain ads pop up so if you if you type
in I want a vest they'll automatically
translate your query to like I want the
vest from L's end or something
and so they're they're actually
rewriting your query into a similar
query that will maximize their ad
Revenue in their responses right so on
this I don't think Google's especially
evil company no I think I think
incentives rule the world and I think
that no matter how you want no matter
how you want to centralize your D you're
always going to have some of that the
can is real everyone knew B did that
right everyone know Google did that
right so I mean what's the alternative
well Linux and the internet themselves
constitute some sort of alternative
right like Linux is open source not
owned and controlled by anyone as a con
as a consequence like China and Iran now
run on Linux even though the US
government doesn't doesn't like them
majority of embedded devices R run run
on Linux internet runs on Linux and
Android phones Android phones run on
Linux and huawei's phones use the open
source portion of Android even though
they're forbidden from using the the end
user layers like Google Maps and stuff
right so and the internet itself
manifests the same sort of sort of
principle right no one owns or controls
it's it's a protocol so I think the
spirit of the internet and of Linux
itself are are that's a different way
than countries or corporations so some
in Singularity net which we've talked
about before and in some Allied projects
like hypercycle and nunet we're trying
to make a software infrastructure that
allows like live running learning AI
systems scattered across the globe to
operate in a manner with no Central
owner or or or controller right and so
blockchain is one of the
Technologies enabling that that becomes
a confused complicated topic because of
the economics of blockchain with
cryptocurrency and all that but even if
there even if there had been no Bitcoin
and no decentralized blockchainbased
money like the core of blockchain
Technology would still be very useful
for creating a decentralized network of
AI servers with no no Central owner or
or controller right and so then then
then there's the first of my three
points which was how you actually
architect the system right and then
there's something to say about that yeah
and I'm sure that that's a vastly deeper
conversation than uh you know in terms
of math and and Tech it is deeper but
there it ties in with the politics in an
interesting way because I if you think
that the audience will digest it yeah
because I think
so what we have now I think we have a
situation where the actual
mind architectures being pursued are
shaped by the business models of the
large corporations creating the AI so we
we have AIS right now the large language
models as an example or deep net rision
we have AIS that have the property that
they need incredible amounts of data to
do anything and they work by seeking
reinforcement of a simply Quantified
reward so these are like rewards seeking
data intensive systems now it so happens
this is the kind of AI that exactly fits
the business model of big tech companies
right because these big tech companies
have more data than anyone else so of
course of course they would like to see
the AI field go in a direction where you
can't do anything with that amount of
data these big tech companies I mean
they they operate by very precisely
defined metrics like who clicks on on on
how many ads not all businesses do but
these do yeah so these guys would very
much like to have an AI system that
works are going do a precisely defined
reward and need needs needs a lot of
data because if if you had an AI that
didn't work according to precisely
defined Rewards or maybe according to a
complex mix of motivations and that
didn't need that much data then these
big tech companies would have far less
Mo around the technology right because
then then anyone can put it together so
I I think the economics the business
models of big tech companies actually
are biasing which cognitive architect
ures get built in a way that is is not
very good I think I you know that that's
been a point that you've touched on many
times over the years and again you got a
dog in the fight but I I think that it's
completely plausible I think the good
news maybe from your perspective is that
the open source world is running pretty
quickly right llama and some of these
other folks really really being able to
pick this stuff apart and I think that
most of the world maybe even some folks
who work within big Tech would love uh
to get uh better results with less data
frankly um so there are some pressures
hopefully countering that but to your
point there might be certain strategies
that lend themselves more to the folks
that currently have I'm not sure that
what you said is true because if you
could if you could get equally good
results with less data then I mean what
competitive Advantage did these
companies have with with with all this
data they have they have much less
competitive Advantage I mean the the
fact that it's so expensive to train
these models is a big Advantage for
companies with huge amounts of of money
also right so there there there's
certainly there's certainly a big comp
competitive advantage that that they
they get from from the way things are
now I mean granted there's both sides of
it right so from their point of view
there's some advantages to it being data
and resource hry and some disadvantages
yeah but from the point of view of
everyone else there's only disadvantages
relative Rel I would expect that at the
top the cantis would have to win out
just as the cantis has to win out for
everybody in my personal opinion and
that would imply that yeah at the top
the decisions should be made to sustain
sort of profitability Etc but I I would
be uh shocked to my very bones if there
was not some research group within
Google Facebook or Microsoft ardently
and consistently
Hur do this if you know how it works
inside these big tech companies they
will Foster a lot of different research
very diverse where the rubber hits the
road where you get your $10 million Bon
sure no that doesn't surprise me it's
when it's when the code moves to
deployment right and that's a decision
of course of no no I I I totally get it
Ben I'm not I'm not I'm not going to
deny that again I I believe the cantis
runs the world and runs me and it runs
you uh and but U but it does it doesn't
it doesn't run me no
no uh only only Blissful and and uh
virtuous incentives Drive Ben gzel so um
with with with that said you uh saintly
fellow you um uh in terms of what what
would happen for the world to choose
that more open-ended decentralized path
which again would certainly it would I
think I think so that the strategy I'm
attempting to follow within my little
corner of the AI universe is extremely
simple I mean I think if we can roll out
something that's palpably the smartest
and most useful AI system in the world
and it happens to be running on a
decentralized democratic
infrastructure then Bingo right like
people aren't going to use it because
it's more ethical they're going to use
it because because it it works better
but they're not gonna they're not going
to not use it because it has a
decentralized democratic infrastructure
yes yes yes definitely not definitely
not so so literally now there's probably
some color on this but I I want to
Nutshell this because I know we're
coming up in about seven minutes um the
idea here is that uh for you in order
for the world to maybe drift to the to
the place where we have Choice around
Ascension to the point where individuals
have freedom for kind of maybe where
they're they own intelligence trajectory
goes to this decentralized place uh
which is sort of your your position the
the most important thing is hey that
camp has to create that kind of
ubiquitous AI whether it's the person
the great personal assistant or whatever
what what is that killer app I mean
what's the killer app you got to come
out with well I don't I don't know that
that's the right way to think about it I
mean should we think about it it's
probably more a killer API right I mean
because even if you look at GPT I mean
that it's fun to interact with but the
biggest influence is going to be
integration of that API on the back end
of some of the other sof software
systems and it's not it's not just that
it's going to be cool to chat with but
there's there's a bit of nuance here
that is probably
worth understanding and going back to
your going back to your metaphor of of
having a dog in the fight I mean I do I
do have a specific AI approach I'm
pursuing
but I think the degree of overlap
between apparently Divergent AI
approaches being pursued on the planet
today is worth understanding so for for
example what's being done to go from gbt
4 to GPT 5 and and to go from llama 2 to
llama 3 and so forth to more advanced
llms part of it is taking large language
models and integrating them with other
sorts of AI systems so I mean gbd4 is
integrated with wall from alpha which is
a symbolic logical reasoning engine
right it's being integrated with
Microsoft Knowledge Graph right Google
is integrating Bard with its own its own
Knowledge Graph on the on the other hand
in my own approach I have this knowledge
metagraph the opencog adom space at the
center with logical reasoning in it but
then we're working with large language
models connecting to that to that atom
space right and so I I mean there is a
difference there because in one case the
llm is the Hub that other things are
integrated into and in our case this
self-organizing knowledge metagraph is
the Hub that the things are are plugging
into but then it becomes like do you
plug your logic engine n graph into the
llm or do you do you plug the llm into
your knowledge graph that contains your
logic engine right so I mean it's not
that there's no differences when you're
doing the research these are quite
different but on the other hand there's
a lot of cross-pollination of both ideas
and open source code absolutely back and
forth I mean it does it does make a
difference which system gets there first
and these choices of like which is the
Hub which is the periphery matter in
terms of which system will work better
but like from the big picture these are
all like they're all kind of similar
sorts of constructions being built on
similar machines with similar data
structures and and and and algorithms
right I mean that I mean that's not the
view I take
work a day when implementing stuff
because in the in the in the weeds it
seems quite different but I mean it's
it's just like okay yeah you know a
Tesla is pretty different from a Camaro
in a in a way if you're an automotive
engineer but if you're like looking at
the whole history of humanity and like
these most parts of these machines are
super super similar actually right so
that there so I I think in a
way the dog in a fight is not quite the
right metaphor because these dogs are
overlapping with each other in a weir
way and and there's and there humid
bouncing back and forth between the
different dogs
brains quite complex ecosystem but but
nevertheless though I think so some
important differences here are I think
that if if you place the reasoning
engine at the center instead of the LM
at the center
I think you have a much better chance of
the system having coherent and
consistent ethics over time because a
reasoning engine is reflective it
understands what it's doing in the way
that an llm doesn't sure so that's one
reason I think I think having the
reflective abstract system at the center
is better than having it at the
periphery and and the sort of data
mining engine at at the center and I
also think having a complex mix of
motivations I think that's better than
having system that's obsessed with
maximizing a single a single metric and
you could you could argue that either
either way if you love that single
metric you may like that better but
having a complex mix of
motivations is more like the open-ended
intelligences that that that people are
so I mean these differences are
are meaningful but yeah you know you
could you could also try to train an llm
with a mix of different motivations like
there's a lot of ways there's a lot of
ways to permute these the dog's brains
are getting swapped all the time to use
your analogy I guess right but but and I
do think that there's going to be a lot
of jousting as we get closer to the big
game of kind of the people who are
looking to be that AI infrastructure for
the
world actually I have I have I have two
questions for you I'm oh great if if you
got the time for it Ben peppermint I've
got a couple minutes so yeah one one I
mean yeah one question would be so
suppose we managed to roll out something
much smarter than GPT 5 yeah on a on the
decentralized infrastructure running on
like 500 crypto mining farms in all
different countries all around the world
sound of it and this is much smarter
than what centralized yes yes big tech
companies are coming up with like how
does the world react to that how how the
world governments react to that great
the followup question is as this super
AGI starts to reduce the need for human
labor
considerably what happens in the economy
of say Africa or Central Asia where
there's no money for Universal basic
income because these these these two
questions are not being considered much
in the debate over like how you know
gender biased or language models yeah
that's that's most of where the
conversation is right left right
politics is where America takes most the
AI ethics question so I'll try to
address press the first one Ben and just
Bandy it about with you the second one
I'm less of an economic expert for the
first one man how would governments
respond to
that I I think that that would be uh
wild I mean my suspicion is that you
know you'd be bandying
about uh or or at least be able to do
all the elbow rubbing that Alman has
recently done with the the world tour
there I don't know if that's your game
or not I'm sure you would say it isn't
and maybe it's not I know exactly but I
think that a lot of people would want to
know who the hell is running this and
what is it capable of and what if we
want to shut it down I expect that there
would be a contingent of really excited
people who are going to do the what if
we want to shut it down yeah will be
very different though it becomes more
like what if you wanted to shut Bitcoin
down yeah yeah exactly exactly so I
think but I do think that that reaction
would happen pretty immediately right if
we had something that was so intelligent
that it could replicate you pretty well
for this podcast maybe like Ben with the
right amount of coffee and in the best
mood to crack jokes right I could just
simulate that version of Ben not that I
want that version of Ben I like talking
to you don't don't get me wrong but
let's just say hypothetically I could
snap my fingers and record that episode
that would
be mindblowing for me that my mind would
would be blown and I think many people
experiencing that level of of amazing
capability would immediately be asking
the question who who runs this where's
it's going where is it going I I've I've
long suspected that the only two
questions eventually that will dominate
politics is um uh sort of how powerful
is the post-human intelligence and and
who is wielding it I I I've long
suspected that those will be kind of the
final questions and I think that those
two final questions would slam onto the
national and international stage if that
kind of a thing would happen um and it
that that that's that's definitely true
yeah and yet I mean governments haven't
even managed to shut down botn Nets that
are running credit card processing in
azerbajan or something right like we we
have a very poor capability we we
haven't managed to round up all the
Rogue nuclear material floating we
haven't Republic right so now we have it
what the governments may want to shut it
down but we not we're not the world has
no rational World Government right like
we're not really a able to act on that
no on that level so I think that that's
what makes it sort of scenario
interesting we're not a globo in your uh
your buddy Hugo dear's uh terminology
right we haven't we haven't gotten to
that point although I do think that
there is a chance Ben that this AGI
question uh tries to forge Us in the
direction of a globo in terms of
alignment but I but I don't think it's
going to work out with China and Russia
yeah yeah but okay but then it's not
Global then it's sure sure exactly what
I mean is I feel like the magnet but I
but I genuinely do believe that some
magnetism will increase for like where
are we taking this stuff but with
authoritarian regimes I I don't I don't
foresee that panning out um no but this
is that's also the sort of thing that
could nudge the us into an authoritarian
regime too right because people are very
xenophobic and if
they if they see you know all the nasty
Africans are going to flood in across
the border and they'll just elected
Trump or something like that right so I
mean it's quite it's that's quite
complicated but I I think in in in any
case in my view the way Global comes
about is by the ai's action rather than
rather than by humans waking up and
coming to their senses per perfectly
viable uh question and I guess I want a
nutshell this uh knowing where we are on
time it sounds like your your big
Crescendo here you know when I had asked
hey what's going to get us
in that direction of the world not
shifting towards a small organization
that runs this whole thing but towards
maybe that more decentralized vision and
we haven't talked about AGI risk and
that's not today's interview but let
let's just say it was going to be that
was going to be where the good stuff is
at your real crisp answer here is hey
Dan I think that that decentralized
group would have to be the ones that
create the API that adds the most value
just like how did Linux come about L
tals decided rather open source it than
than start a company and keep it private
right I mean for it to happen the the
group that makes the big breakthrough
toward an AGI has to not want to
personally be in control of the whole
thing right so I mean but but I mean the
history of Linux is one example that
shows this is within the scope of of of
human behavior right I would I'd love to
end on this analogy if I could Ben um so
this is this is great I'm definitely
going to point people to some of your
other work uh much of which I reference
on social on a pretty regular basis
there's this um uh Abraham Lincoln gave
the lysium address when he was in his
20s after coming out of the woods you
know reading the Greeks and whatnot um
and it's a beautiful speech the the most
profound part of it I think is that I I
believe it is the core argument undering
it is more or less him stating um that
in order to keep someone so that someone
born like a Napoleon would not want to
fit into this existing structure they
would want to run the show maybe we
could argue somebody like a trump who
knows um and he he essentially alludes
to how lucky we are that there was more
luster more Grandeur uh to creating
something new which was America right
this great experiment um then to being
the King right because Washington could
have been if he wanted to put the crown
on his head we're lucky that even just
raw incentive wise it would have been
kind of cooler and more unique for him
to do this different thing as opposed to
Simply wearing the crown and it sounds
like maybe there's going to be some I
think it's it's hard for you to accept
but
some of us are really driven more by
trying to sort of flow along with what's
best for the universe and sensient
beings as a whole not not that I'm
immune to incentives of of course sure I
don't think it is my it is not my my
primary driver so yeah yeah well I I
mean maybe Lincoln would disagree with
you uh but maybe you're smarter than
Lincoln and that wouldn't surprise me at
all Ben because you got to be one of the
smarter people I know and no matter what
it's a very different time as it is it
is no no doubt about it but we can we
can resurrect his digital twin and have
the debate which will be when you come
out with the API let's do that
regardless of perspectives then and any
differences always appreciate your ideas
follow your work uh rooting for you in a
big way brother thanks so much for being
able to join us it's been a lot fun
great
cool so that's all for this episode of
the trajectory a big thank you to Ben
for being able to be here with me and to
share his ideas with you today and thank
you to all of you for tuning in to this
particular episode today our third
episode of the trajectory series I've
had a lot of fun with these I really
enjoyed unpacking ideas with Ben and you
did get to see us kind of go at it a
little bit with regards to uh inherent
self-interest I think that you know the
dealing frankly with incentives and um
with the Dynamics of power will be
something that is absolutely mandated
and non-optional uh here in the
trajectory and I think that the take of
um not everyone is self-interested Ed
for example I am not but my opponents
are is just another manifestation of
self-interest uh and again I have
unlimited respect for Ben I I'm if
anyone's going to build the AGI I have
all the Hope in the world that it's him
uh and I have nothing but good good
things to say about all of his ideas but
uh you you'll continue you'll continue
to see that line towed uh here in the
trajectory for the long term because we
are going to deal with incentiv squarely
it just is what it is it's it's what
we're here to do um but regardless I was
glad to have Ben's ingredients in the
mix for this particular Series in the
next interview in this series we'll be
speaking with a uh AGI researcher
currently with Deep Mind who had raised
tens of Millions for his own AGI company
had previously worked at another AGI
company before that and is also a pretty
darn funny cartoonist in the domain of
AI risk you'll have to guess who that is
uh but I look forward to having you with
us here in the next episode of the
trajectory
