[Music]
this is Daniel fagell you're tuned into
to the trajectory and this is our third
episode in the AGI governance series Our
Guest this week is Step AB baraki serial
entrepreneur venture capitalist and very
involved member of various technical
associations and intergovernmental
associations he's well known for helping
to found AI for good which is a large
event in initiative within the United
Nations under the itu within the UN um
and Steven is one of the few people I've
ever met in the intergovernmental world
who sees a trajectory to posthuman
intelligence and is considering where
governance uh soft hard governance
technical standards Etc might fit into
bending that trajectory in a better
direction there's two parts of this
interview I think are really interesting
Steven's emphasis on technical
associations like the association for
computing machinery and the i e and
where they fit in so not just hard
governance but that kind of soft
governance and also his ideas around a
kind of natural alignment even among the
great powers like the US and China
towards a shared interest in aligning
artificial intelligence um you may or
may not agree with his perspectives but
I think they're worth chewing on and I'm
glad we got to speak with Stephen again
one of the few people in the iGo world
that I think really gets it so hope you
enjoy this episode this is Steven iaki
here in the trajectory so Stephen
welcome to the program hey Dan I'm
thrilled to be here in jazz I'm excited
about our upcoming conversation
absolutely we're talking about in my
opinion the fun stuff and and you've
been thinking about some of these ideas
for a little longer than most and you've
seen them applied in kind of the tech
space the governance space Etc uh AGI
governance not not an easy thing to
Nutshell but we've got a little bit of
time to unpack it I'll start on kind of
the timeline Horizon we've had the benio
and Bostrom and you know many great
luminaries in the AI space speak a
little bit about sort of how close they
think we are to AI That's more generally
capable than people in a in a more
completely General way um from your
Vantage Point where where do you suspect
we are with regards to that and why do
you think
so I would say from a AGI or artificial
general intelligence we have something
that sort of can mimic and and do things
that humans do perhaps better um I would
say we're about six years out maybe
seven years so within 10 years I would
say we're out and in fact I've written
forwards of books indicating that we'll
even have this by 2030 and I've
explained what that experience would
look like right where you'd have some
kind of assistant that's sort of
integrated with you you would treat that
assistant as if it's human like but it's
not and let's not get confused though
let's not say that this is human
intelligence it's just a different kind
of intelligence right doesn't have to be
human just like U Corbit a certain kind
of bird type uh has problem solving with
capabilities it's not human octopus have
a distributed neuron Network system it's
not human but problem solve some are
even saying plants can problem solve so
um doesn't have to be human it's just
different yeah I think some people
luckily our audience is probably not in
the camp of like well that means it's
just like people I think they would
understand it's sort of a submarine
doesn't swim like a fish step but it
still gets the job done there might be
kinds of thinking that are not precisely
the same as what we do but but still get
the job then in terms of General
capability would love to you know you
mentioned kind of writing forwards for
books I've seen some of your talks on
these topics you've talked about the
fifth Machine age and some other ideas
and we've got a little bit of time for
it in terms of what you would see AGI as
you know there's some folks who really
are kind of of a vision of hey this is
sort of an an eternal you know assistant
and then there's other folks that really
would see kind of a potential f is often
the term used of of sort of AI that can
build upon Ai and potentially AI that
can develop goals you know that might be
different than humans which could be a
good or a bad thing and maybe even goals
that are beyond our conception just like
our goals are beyond the conception of
sea snails when you think about AGI is
it more in kind of uh a tool camp and
would you always see it kind of staying
there or what's your vision of AGI when
you think about this first level we're
gonna we're going to get to here I see
AGI as being a tool but I actually see
AGI in this kind of spectrum right right
so uh we have classical humans like you
and I Dan you know kind of classical
humans that's awesome and then we have
augmented humans that means humans that
have some kind of AI embedded in for
example I wear hearing aids and my
hearing aids have ai and this AI is
going to get so good that I would say in
two to three years I'll have better
hearing than somebody who doesn't have
hearing absolutely yeah so I call them
augments or augmented human beings and
then we're going to hybrid human beings
and they maybe have some genetic editing
which is already occurring and they will
have some kind of AI enhancement as well
and it maybe even have a synthetic arm
or something that has AI embedded in it
and then together with hybrids will have
autonomous an autonomous could be some
kind of intelligence embodied into a
robot which would be your assistant at
home or on the job uh and you have a
kind of autonomous capability in cars
already like if you go to Phoenix you
actually have driverless cars and
they're all over the place and in parts
of China now they have uh driverless
taxis without Safety Drivers so so
really I see this world of transition
right classical augmented hybrids
autonomous yeah yeah so the spectrum is
fun and we can play along this there's a
lot of folks that really can't think
this far ahead they can't even really
think about augmentation they don't see
it as a spectrum from the hearing a that
you have to you know postum sensory
perception maybe even senses that humans
don't currently have today but might be
a lot of fun or might be very useful
these are all things that are
potentially accessible um there's some
folks who would think that uh you know
some of these autonomous intelligences
that you articulate um you know should
they be able to improve and leverage
their autonomy to do more and more fast
improving or if augmented humans are now
leveraging double the brain power here
at some point to be able to to work on
these technology systems that at some
Point these systems might develop agency
you know maybe to to go off very
autonomously and do things that that
humans want them to do but maybe even
just do things that seem you know
instrumentally useful to them and and
maybe again stretch Beyond sort of what
we can what we classical humans uh can
conceive of in terms of goals do you see
that as reasonable or even for the autom
the the kind of automated crowd there do
you see them mostly playing ball with
humans into sort of an indefinite future
or do you see a a forking happening
there I just want to get an idea of your
future Vision I see this as a transition
so you know because we're so steep in
kind of the traditional classical human
being uh whether it's going back to
hominids you know over a million years
ago to uh to you know um when we were
sort of cois theer yes yes that to
Modern homo saan we're sort of very
grounded in this old idea but what'll
happen is as we get enhanced as as we
have implants as we're augmented and we
get into hybrids then increasingly our
our frame of mind of what it means to
work with AI uh will change right and
our uh uh the expansion of our
intellectual capability will give us a
different mindset of what it means to be
working with AI and I believe that we'll
be more accepting of AI having some kind
of auto agency and having some kind of
automatic um development capability
because we'll be developing at the same
time with this AI because it will be
embedded with the AI right so yeah and
kurtwell has this optimistic permutation
that kurtwell famously a little bit
strangely really throwing on the
rosecolor glasses from the get-go kind
of always always has um uh not that you
know I think all optimism is you know
good or bad or all pessimism is good or
bad but I I I think probably there's
some some kind of gray here but this
notion that you know as we start to
augment ourselves there might eventually
be some kind of you either merger with
AGI or a real ability to have kind of
this cognitive freedom of what do we
want our experience to be uh whether it
be gradients of bliss whether it be new
senses new kind of bodies um you know
and and that the Spectrum would be able
to continue with great Freedom there's
other perspectives that hey it's only
been what less than a 100 years that
humans have let's call it pseudo
reliably not mostly been n War um you
know it's only been a minute it's been a
real evolutionary millisecond uh that
we've been able to have this sort of you
know peace period I think it's a great
thing and there there's some people that
would say man if you start really
throwing in Divergent intelligences
brain augmentations that have humans
with entirely new sets of goals and
drives right you and I might be very
different maybe we're on the opposite
side of some countries that hate each
other but we both like eating food we
both want to go home to our families we
both like reading good books uh you know
but there will be intelligences that are
almost like you take a a black widow
spider and scale it up that there's no
monkey values going on there right
there's no Beauty in a sunset these are
not Universal things to intelligence
they're particulars of our our kind of
intelligence there's there's a
supposition and I'm not saying it's
right but that there will be some
conflict to potentially manage as
divergent intelligences that are pure AI
that are these hybrids all start globing
together didn't work out super well for
the theander talls although I I'm sure
we inter Breet a little bit what are
your thoughts there about how that um
Cambrian explosion of of intelligence
upward uh will be able to maintain some
semblance of
Peace so everything is is a probability
right so it's a nonzero chance that we
could end up like the neandertal where
there's some kind of future hybrid
autonomous species of which we are part
of what they are but a minority part and
in in essence that becomes the next
stage of evolution yeah and it's machine
driven and it has unlimited
capability uh unlimited capability to
what we think we have comp yes yes but
really will have ex you know exponential
kind of capabilities that there's a
nonzero chance that could happen so it's
real um there's the other chance that we
will also just naturally evolve with
this extended capability
and hopefully as we continue to evolve
with its extended capability we can keep
it into sort of a safe a positive
optimistic view of the universe and and
sort of doing good and not so much doing
bad and and and being more like and so
on yeah yeah both are going to coexist
and that transition is going to
determine what we're going through you
know which direction we're going in and
and it may be that it's not a a um you
know a one in a zero Choice there could
be like a Quantum Spectrum yeah you're
going to have some entities that are
going to go off the rails you're going
to have some that live in between and
you're going to have some that are
really very positively driven and all
are going to
coexist the key is is that um at the end
of this that there's some glimpse of
humanity that still survives right yeah
yeah there although I think there are
some people who would hope that we would
have you know a worthy successor bubble
out of this is hopefully we are worthy
successors to the fish that had legs I
think I think we've done a good job I
think hopefully they would be happy with
what we are um but yeah to to your point
um uh your hope and I think the hope of
most humans is
that humans would have the freedom even
if it's not to maintain this exact same
form to still sort of be humans and
exist in peace Within These entities but
to your point non-zero chance that might
not happen with that said big panoply of
possibilities um lots of probabilities
of how it could shake out uh you know
you've been involved in many regards and
of the uh ethics and standards ecosystem
but but now increasingly the governance
ecosystem with sort of the AI for good
efforts where a lot of these
conversations are getting hashed out how
important do you see some kind of global
coordination Andor governance around uh
AGI specifically not just kind of AI for
bias or AI for privacy but this idea of
kind of postum intelligence how
important is that for you or in your
opinion so again uh you're going to have
people who don't want that conversation
and you're going to have people who are
really want that conversation to the
degree and almost like the European AI
act and then you're going to have some
kind of spectrum in between and the
reality is you're going to have all of
those occurring at the same time so
you're going to have people who don't
want any of this who you know in the
dark web let's say and and maybe in sort
of Rogue uh areas of the planet and then
you're going to have people who wanted
over you know maybe a lot of Regulation
a lot of governance in control over it
but it's going to be a spectrum what
it's going to happen though know is
probably a multi-stakeholder
conversation leveraging all of the great
work that's been done by the science
organizations like the association for
computing Machinery the itle E uh ifip
and others who have been working on
codes and a code of ethics and
principles of doing this right for
decades of which AGI and AI is a subset
and they're work working in conjunction
with uh you know the private sector with
CEOs and and corporates the educational
sector media and also within the UN
system itself so it it's you know the
ideal situation is uh a
multi-stakeholder uh conversation and
looking at can we put some kind of
umbrella that's Global and to the best
of our ability provide some uh you know
Universal AI governance guard rails
almost like an FDA of the world uh
you're not going to have a perfect
situation you're not going to be to
control a perfect because you got open
source and again Rogue entities out
there but at least you've got some kind
of a benchmark or standard that you can
measure against and AI for good is
trying to do that with their AI for a
good um Global impact initiatives on the
healthcare side in other words it could
going to produce an AI solution geez why
don't we measure it to make sure it
aderes to some basic standards uh these
are the Benchmark the data adheres to
some basic standards and let's kind of
agree that that these are things that we
feel uh AI should have before we will
say hey we we will trust it right so
that is not a bad thing that's a good
thing to at least have some kind of
standards in place that at least gives
us a framework and a grounding and and a
basis to start right I I'm I concur in
many regards and I'll just put a couple
things on the table you're sort of
mentioning this idea of the the global
FDA I think um
and to your point there will be folks
that want nothing to do with this we got
you know our dark web crowd but even
even on this show for example you know
we've had folks who really would see
that any kind of international
coordination or agreement around AGI
would be you know too much of a slippery
slope towards authoritarianism or
controlled by folks who don't understand
the tech and would prevent its benefits
and really they kind of want zero and no
joke there's actually some people that I
I respect and like as people that have
that opinion there's others who are of
the belief that to Frank and you're
clearly somewhere in the middle but I'm
just drawing our our our goal post here
are the edges of our boundaries there's
others who are like unless there's some
degree of very firm you know hate to say
policing of sort of computer at large in
a much
more tight Global governance it's not
necessarily authoritarian per se but
like it they would they would have to
have some very significant Powers across
every corner of the world without that
we're likely to just end up with an arms
race where this thing comes out of the
box uncontrolled by people and you know
harms us all and maybe ends life in
general and that would be a terrible
outcome so you you have people on both
ends you're sort of more you know a
little bit into the coordination side of
hey maybe there should be some
overarching uh body that can ensure that
some of these Technologies Beyond
certain thresholds adhere to basic
principles and we can come to agreement
on that and have multiple stakeholders
on that it sounds like that's the I
guess the the place on the Spectrum
where you let me know if I'm picking up
what you're putting down Stephen yeah I
mean I I have the advantage that I work
in the investment Community right and
I'm also work with Sovereign fund
investment communities so government
investment communities private
investment communities unb based
investment community so I'm work in
Investments across
multi-stakeholders I work in the science
community and the expert the engineering
community multistakeholder I work across
CEO communities uh again both uh
private uh privately held but also um
you know um Enterprise multinationals
and so on and in the Entre
entrepreneurship uh space so I work
across all of the kind of the major
entities including media and I would say
overall I hear an argument that let's
have some kind of oversight let's have
some kind of Regulation governance let's
not make it too extreme but let's not
have it under power do you right so I
I'd sort of concur I mean our our
conversations are you know CIO Goldman
Sachs CTO teada pharmaceutical all the
way down to you know the policy
ecosystem not involved in investing
myself but um uh business side startup
ecosystem policy world I see a good deal
of interest in AI governance um in a
general sense uh you know privacy bias
um is it going to you know is it only
going to be Microsoft that's rich and
you know Africa's going to be poor you
know maybe we want to control for that I
see those kind of
social concerns around AI uh and and and
economic and otherwise concerns around
AI have a you know within the halls of
the oecd or within the conversations
that I have if I'm at a un event um uh
whether it's you know um unic or iow or
whatever Branch we're talking about some
congenial to sort of hey yeah let's make
sure it's not biased let's make sure
it's not one or two companies or
countries that actually gets Rich when
this stuff really expands if it becomes
powerful I see not as much of that kind
of support and continued conversation
around the idea that this could be more
powerful than people even within the
oecd they have an AI Futures group uh
Franchesca and Benjo and Stuart Russell
and this whole crowd is sort of part of
that um where you know two-thirds of the
room not really too much on the page of
AGI it's either not a concern doesn't
feel like it'll be relevant in their
lifetimes or their children's lifetimes
so they disagree with you and that
respect or uh yeah they just don't
believe in it at all like it's it's all
llms are hoopla AI is never going to get
there it's it's literally a waste of
time for us to think about do do you see
within those communities an interest in
governance around a gii or is it mostly
around the more parochial uh AI concerns
I see around both uh the standard kind
of AI and the natural development and
evolution of AI of which AGI is a
portion of that Spectrum I age yeah say
the whole thing is is being covered and
I think the reality is is that if you
were to
pull um you know across the board
whether it's un CEOs investors
scientists experts
engineers and big Tech they will say
that AGI is it's a nonzero AGI is a
nonzero absolutely absolutely oh yeah
they don't think it's 2100 either no no
well and people used to think that right
you look at bostrom's polls from what
was it uh 2014 2015 when he did his
first poll of all the AI academics it
was like 2065 was ballpark average uh
around then you know and now it's like
we're in a little bit of a different you
know uh place but there's still a lot of
folks for whom it is not even remotely a
concern they just think it's totally
technically impossible I I happen to to
on some level disagree but this idea of
kind of beginning with a a standard sort
of body of some sort you know this FDA
globally some people would say that that
would be leaning us too much towards
authoritarianism some people would say
maybe that's exactly The Sweet Spot for
governance we need it feels like for you
it's about the right sweet spot um what
makes you feel like something more
stringent around police and compute
maybe would be too far uh and and what
makes you feel like like on the other
side of kind of having none of that
International FDA just every country
decides what they want to do with AI why
is that inadequate so maybe we could
talk about those polls like why why
don't you want something Tighter and
then we could talk about why don't you
want something a little looser
you know uh if if you get too tight then
you get a situation where people are
afraid to innovate because they think
they're going to get fined or um they're
going to put expend a tremendous amount
of energy and then find that they that
all of that resource and energy just
they they're not able to uh invoke a
particular kind of solution because
they're just the uh the regulatory
aspect is just too stringent so you want
to maintain some level of innovation and
in fact
if you have overregulation you're not
going to be a to regulate the entire
world so if you have overregulation that
could stifle a particular segment of
society and yet another one has no
regulation and they're going to continue
to be to innovate so you've got to have
something that everybody can at least
agree to um and that's the problem with
overregulation uh the lack of any
regulation of course I mean I I don't
think anybody reasonably wants that that
right at least the people that I'm I'm
in contact with now again because people
exist in the spectrum of course you're
going to have the ones and the zeros but
the reality is we coexist in some kind
of spectrum right totally most of my
conversations sit somewhere in what I
would call quite a reasonable middle but
I have I have had conversations on both
camps interestingly enough many more
conversations on the no International
coordination at all is better Camp which
which I don't agree with in totality but
I think it's you know to your point it's
a multi-stakeholder conversation I think
those voices have to be in the room when
we talk about this kind of FDI FDA for
AI a AGI idea we're talking about
general intelligence here not just the
par parochial concerns you know there's
sort of hey we want systems that aren't
you know biased in some you know racial
or gender oriented way okay you know we
want uh systems that aren't physically
dangerous in these other ways okay what
would you see as kind of the core
outcomes if it was set up well this
initial level of coordination that you
would see as the goldilock Zone what
what would it fundamentally achieve it
might be 50 things but if we're going to
boil it down to two or three that you
would say hey that would be a great
first job of AGI governance what are
those core things you'd hope to see it
achieve to have some kind of way of
benchmarking as this uh these systems
continue so the great measurement tools
great ways of testing the capabilities
great ways of anticipating emerging
capabilities right now we I don't think
we have a great way of of predicting
these emerging
capabilities um but putting more
resources into looking where these
things can predictably go let's say the
next two to three years and ensuring
that it's not going to go into that
dystopian side like you said where it
goes runs away and invokes some kind of
control where you know it it results in
something that's very dire to particular
segment of the population or the whole
population right and it's not just the
population of us human beings it's
really the safety of the planet overall
right this great project of life you
know I think the the big the big
concerns that I think people bring up
are certainly the extinction of humanity
but by golly if we had kind of a totally
unconscious machine system optimizing
for something somewhat strange and
arbitrary that you know needed to use
the Earth's atmosphere in order to
achieve that goal and could somehow get
its hands on a lot of physical
instantiations and Achieve that we might
just end up with you know no more no
more sentience uh at least in this in
this part of the universe and that would
be a bit of a a bit of a shame so
certainly we want to steer clear from
those things so achieving kind of
protection from that degree of safety
some degree of assurance on the other
side I'm with you there um what would
that look like and how might that
initially operate uh for you you know
you mentioned kind of multi-stakeholder
I'm wondering what kind of agreements
would have to be in place and what kind
of checks and balances and basic
regulations would exist to kind of have
this Foundation layer of AGI governance
come to
being I would say and you know those are
very good questions so why don't we then
leverage the work for decades of the ACM
and the i e and i50 science
organizations that are be looking at um
you know the development of tech for
good purposes and then managing and and
uh controlling to ensure that the bad
aspects don't happen and they've got a
lot of EXP experience on that they got a
lot of experience on establishing the
principles and the Frameworks and then
operationalizing and what I mean by
operationalizing is what are the tools
the benchmarks the the techniques we can
use to ensure that we're on Mark we
don't go off the rails right so leverage
that work and making sure that we
continue that work on the operational
side so we we can actually track the
progress see where there could be a
problematic situation and then uh
curbing those problematic uh situations
in a in a thoughtful way and providing
the tools so that could happen and the
oversight so that could happen so I
would I would um put more emphasis on
these science organizations who've been
doing this for decades and just giving
them or working with them with more
resources right well and I'd love to
poke a little bit into that and and you
know you've been involved in these
organizations for many many decades and
so probably have some more references
I've only been around for the last 10
years in this SP with uh you know the i
e as their ethically aligned design and
we've had constantinos and John Havens
and some of the folks from from those
efforts uh on the program over the years
but clearly their efforts around
standardization and kind of ethics and
thinking about outcomes is an older
Legacy both in the i e the ACM maybe
even some some other organizations what
are maybe some of the key uh papers
principles you know maybe starting
points for the listeners that are tuned
in to say oh maybe I want to look at
some of the older stuff maybe there's
some grounding elements there that we
don't want to reinvent the wheel on what
are some good places to go to to
understand that you know if you just do
a generalized search under I ACM code of
ethics and from there you can mine into
uh into Ai and which is really in my
mind a subset of the broader principles
of ethical conduct uh ethical
operationalization of these
materials um Kips would be another one
out of Canada we've been working on this
area for a long time iip for example has
adopted a code of ethics um for the
development of AI but also any kind of
tech so really it's not so much
remembering the the theme it's membering
the organization so ACM were the world's
largest Computing science organization
AI is a subset of what we do right oring
award all that yeah and then now you
know we do clearly work with triple AI
the artificial intelligence organization
but we were we were first right we were
there earlier the AI Organization for
much later right so
certainly um same thing with i e i mean
those are the formost organizations and
just staying in contact with them and
then you can do keyword searches on
anything of your
interest another area which is related
to this is UNESCO and and their programs
for the ethical use of AI uh they
they've um come out with recommendations
they're trying to operation Iz that as
well uh globally they're working with
itu itu is a standards organization
right uh nearly 160 years old so this is
in their framework of can we get to some
kind of global agreement so itu working
U with with with the scientific
organizations working with UNESCO in
fact there is a joint effort between itu
and uh UNESCO and they what they've done
is they've surveyed all of the available
kind of AI work and they tried to put it
all together and they're also working
together on on uh on the governance side
and some way right so so uh really
healthy handful of organizations for
people to look up but to your point some
of these considerations around
Technology's impact ensuring that
thinking about it from a standards or an
code of ethics uh domain probably
shouldn't be reinvented I mean I'm I'm
aware of you know the I E's newer
efforts of again ethically aligned
design and other efforts like that the
oecd of course has the oecd AI
principles and they're trying to make
those a little bit more applicable but I
think the Credence to your point is hey
there might be some of these things that
we have in common that we want to embed
in our Tech that we've already sort of
thought of and and instead of sort of
starting at the level of the clouds we
might be able to build up from some of
that foundation in an important way I
guess turning that into the brass tax
you know impact I could think about many
potential examples of what that would
look like and I'll just lay them out
here I'm not advocating for anything
right now I'm just putting ideas on the
table for you to uh batter around a
little bit I could see you know uh some
sort of uh set of rules or or code of
ethics around um you know the prevention
of of physical harms and maybe any kind
of robotic instantiation that's
controlling anything in the physical
world maybe we'd want to have some sort
of okay if if it's this level of risk
like it's a full-blown automo Automotive
vehicle that people are riding in we
need to be able to test it in these
three or four ways if it's this kind of
industrial equipment you know here's
kind of a benchmark for that if it's
this other thing here's kind of a
benchmark so maybe there would be
something like that there might be you
know uh race and bias kinds of things
that come up and and we might say okay
well if it has to do with these kinds of
hi touch consumer data applications
here's a couple basic tests we'd wanted
to pass but again this isn't quite
getting us to the AGI side of things um
uh this is more more on the parochial
side I think some of the concerns we've
seen around a GI are what can we do to
kind of make sure that no individual
party whether it's in China or the us if
we're just talking about you know some
of the bigger guys here are are blasting
off in a direction of capability and a
direction of kind of unknown maybe
uncontrolled capability that uh could
lead to the kind of negative outcome you
had so we've got our parochial concerns
but we also have the sort of keep in a
little bit of tabs here that if we say
here's where we're going here's where
we're going to experiment and kind of
gradually move forward as a species that
no one's just taken off like a rocket to
build something that might bring about
these gigantically bad outcomes which of
this panoply of things would you want
this org to do and and maybe a little
bit of how how would you want it to go
about that to sort of maintain that
transparency and steering of these
factors so you have these existing
organizations so what you do is you just
make sure that there's specific uh
Targets on the AGI side in terms of
outcomes where it could possibly go and
then what are the the Frameworks and the
principles and underlying that the tools
and processes to ensure that we can stay
safe so leverage the existing work add
add or um add more resources to the
teams that are working on the AGI side
and and the futuristic kind of uh
outcomes and probabilities but
operationalizing it in other words here
are tools and ways to manage and look
for and monitor
bring some transparency to these opaque
models so you have a better idea where
there's going and there's a lot of work
like frontof for example has these heat
Maps uh technologies that they developed
on the llm side so you can have a better
idea what's happening so um once you've
got some kind of organizational
structure um that's proliferating
everybody's agreeing to it everybody's
speaking sort of the same language
within the UN within corporates also
with and these science organizations
then you can start populating and
bringing resources of there's an entity
as I mentioned FR hoofer is working on
this there there's different University
Stanford and others are working on these
kind of problems right and then bring
those resources to bear and put them on
the table the issue right now in the
world is so so much a cal you got
different people sort of work yeah and
that's where the coordination is
required I mean you're going to be a big
part of this right you're putting out
the message of saying here's this entity
working on a particular aspect why don't
together so why don't you harmonize this
by the way the it UNESCO is trying to do
that they're trying to bring all the
principles and parties together try to
harmonize ah so UNESCO has some existing
efforts
around okay interesting I I'll have to
look up if that has a particular name I
haven't seen a lot from UNESCO around I
guess the general intelligence side of
things but it sounds like at least just
terms of AI at a high level they're
aiming to pull this under a roof
somewhere yeah I would say uh UNESCO and
itu are are trying to bring these um
kind of collective capabilities between
the two organizations together in the
healthc care area there's a new
initiative that's been launched and it's
a partnership between the World Health
Organization uh because of the health
side and the implications of AI and
potentially AGI and Healthcare uh
together itu which is also looking at
AGI but also where AI is progressing you
saw some of that at the AI for good
Summit right yep yep set topics together
with very practical topics so you got
the World Health Organization the itu
and the world IP
organization um which is on the
Innovation intellectual property side
which is more uh you know what is new
teack what is new capabilities are
coming about what are the intellectual
property considerations of that and then
these three forces working together in
harmony uh to address the bigger issue
of AI and Healthcare and then also the
future implications of where AI is going
into Healthcare and then how do you do
that well you do that by saying hey
we're an open platform uh we're building
benchmarks and you can measure against
um they got open teams uh uh working
groups that can work on different
aspects of this um startups and
Innovation is part of that program as
well
so that they can see what's upcoming and
making sure that that Community is
embraced in into this Collective effort
uh but corporates are working on this
yeah I mean there's corporate entities
that have have come together to say how
can we do this in a in a controlled and
managed way and ensure that uh we can
start detecting whether there's going to
be issues that are upcoming and we can
amate amarate or put safeguard on this I
would say of all the Corpus that I see
out there probably the most mature would
be Microsoft only because they've been
around for so long and they're not
dependent on search or one particular
Marketplace they're they're basically so
uh diverse in terms of all of
the made right so um they provide a lot
of free material and responsible
AI um they have Innovation programs for
Youth and uh responsible AI um which a
youth can
Embrace excuse me they have
co-pilots even in things like Quantum
Computing because Quantum Computing is
an area that's going to accelerate all
of this development and of course huge
interest in the intersection of quantum
and Ai and and what could that possibly
mean and in fact uh they produced um
Quantum co-pilot so that let's say uh
you're a student let's say you're grade
11 students somewhere in the world and
you're really interesed in in accessing
this where they have co-pilots that
allow you to program and it'll guide you
through writing your own you know your
first Quantum uh program but that
doesn't have to be Quantum it could be
AI yeah yeah uh program right so and and
because AGI is the nearer term people
are afraid of that term uh in a
way yeah they are right because they
don't want to turn people off right oh
yeah yeah they're they're like oh has
religious connotations and oh it's
impossible and so some people believe
it's possible they don't want to say it
CU people are going to look at them like
they believe in aliens and then other
people uh you know want to shy away from
it because they just think oh it's bunk
and you know Jeff Hinton has lost his
mind he's not a serious person anymore
there's a lot of different opinions out
there yeah so Dan that's what that's why
I'm saying that even though it may not
seem like AGI is not being addressed
it's such a controversial term in the
background the future of the development
of these different AI models is being
addressed and where it's going to go
that's even though they may avoid the
word yeah yeah yeah yeah still Thea
influencing the trajectory to your point
here and you brought up another really
good point I mean indeed the the purpose
of the conversations here on the
trajectory is around where are we taking
ourselves and and what's going to be the
best way to go about doing that I think
that has to be a multi-stakeholder thing
communication will be part of it but
there's so much more than just getting
the word out of course um you had
brought up some of the great
organizations that you know are are have
have moved forward in principles and
codes of ethics and and maybe efforts
around around these things but how
siloed it is I think that is indeed some
of the concern here is that um you know
things do feel kind of siloed now and I
think there's a lot of folks that are
real Skeptics that okay if let's say
it's the UN hypothetically um you know
if the the UN has some sort of a body
around a basic kind of coordination and
governance about AI systems above power
level X whatever the case may be um that
if the US starts really playing ball
will China or if China starts playing
ball will will the United States I think
that uh there's an arms race somewhat
overtly between the private sector
organizations meta Deep Mind open AI are
all pretty overt like we're aiming to
build posthuman intelligence and and
they know that if they don't do it their
competitors will that's some people have
argued that that could be dangerous
assuming AI could do the things AGI
could do the things we suspect it could
same thing internationally and this is
why some folks think it would be bunk or
it would be impossible or a waste of
time to set up this coordination what
would be your response to that or maybe
your hope for how such coordination
could have maybe this is too aggressive
of a term but could have enough teeth uh
to to make sure we are gauging the you
know Frontier gigantic leap efforts of
big Nations like the US and China who
probably do see each other as Rivals now
um what what what could be done to still
make this kind of coordination
given those
Dynamics there are power dynamics and
there there's competition but overall um
there is an interest in all the major
countries um who are dominant in this
area to want to at some level cooperate
and to have some level of common
understanding I don't I don't hear
counter to that yeah I think that's true
on some level yeah and the same is true
of corporates uh even though they
compete at some level they want some
Cooper ation particularly on the policy
governance how do we ensure that we
maintain some level of control o over
this as it it's escalating and
accelerating so uh that will
self-organize and into itself but there
are governmental efforts anyways which
will require people to come to the table
right it's just like the European act if
if you want to do something in Europe
you have to play now some some
corporates may not want to play in that
Marketplace because they think the risk
is too high but what'll happen is is
that will re that will then um maybe
cause some changes and transitions
people will learn from that experience
what's happening in Europe if some
people don't want to play in that
Marketplace and um and they'll maybe
produce something that's a little bit
more middle ground and you're seeing
that happen in different parts of the
world right like in the US and Canada
and so on and even the European effort
maybe they will look at who's willing to
get into their Market who has some
opposition to how they're structured and
maybe they'll make some amendments as
well I mean we're we're learn
everybody's learning in real time and I
think those adjustments overall will
harmonize and overall those those
adjustments will lead to something that
everybody agrees to well I I uh some
people would call that a rather
optimistic take on the future I don't
think it's a totally non-zero chance
that that could bubble about I I do
recall some people being rather excited
that at that first AI safety Summit
which I know now its name has changed
away from safety uh because different
countries have different views on on AGI
uh uh um you know countries that the
croissants maybe don't don't care about
it as much but uh either way um at that
first summit there was some sort of
optimism around hey you know at least
China gave some lip service to or you
know I don't know sign some basic words
about sort of some degree of cooperation
around sort of the runaway capabil of AI
which is just a tip of the hat I don't
think we should really see that as some
kind of assurance of global coordination
but if the hats keep tipping and if they
keep tipping across organizations and if
citizenry themselves start worrying
about arms races and things like that it
sounds like for you the emergent
coordination between the groups and then
between the Nations and and these these
bigger broader International
conversations you're optimistic conal
into something where we feel good enough
about the checks and balances to not not
be in this tension arms race scenario
anymore yeah the key is not to get so
caught up in the daily volatility and to
start averaging out over a period of
time so in general if you average out
over a period of time the trend is in
the positive direction right the trend
is towards some level of governance the
trend is toward towards some
establishment of policies and that's
already happening at the country level
yep but keep in mind that when a country
comes out with a particular uh framework
work or model policy regulatory aspect
um they're not doing it in isolation
they're looking at what other countries
are doing yeah yeah so there's already
kind of an implicit Equalization that's
occurring without it being
explicit and and there and if you were
to examine all of the existing programs
that are already out there you'll see
common many common elements right and
those common and and those common
elements are are a foundation for
everybody you do agree to right so so
we've given the listeners a little bit
of kind of homework and some
organizations to look at kind of a
vision of what the goldilock zone for
AGI governance might be and you've also
been pretty Frank about
this cyborg human AGI sort of future
which which I am very congenial with and
and think is something that honestly we
should be contesting with even more in
the intergovernmental world I don't see
those conversations happening enough uh
right now I'm very much on your side in
that regard in closing here you know as
you think about about some of the
initial things that you you hope will
start to happen that could start to roll
the snowball in this direction you've
kind of mentioned you know countries
make their their governance and then
they kind of share that and there's some
emergent ideas about the principles we
want to stay attuned to so hopefully
some of this stuff will Bloom unto
itself but if you think about early
moves that maybe the UN could make or
maybe one of the great Powers could make
or one of the AGI Labs could make that
would sort of inch us towards that
goldilock zone of governance what would
be some of those things you'd be Hing
for those early first steps that that
would be a sign of progress for
you probably the the corporates and him
are demonstrated programmatic way coming
out with messaging as a community and
this could be through the world in um
innovation technology Systems Alliance
called witsa wit so yeah so back in 1978
a a Consortium of all of the or an
alliance formed of all of the industry
associations around the world so keep in
mind you know 50 years ago or or 40
years ago you have all of these tech
companies right and these tech companies
realize that they're competing but they
also have common interests so they form
associations within their individual
countries so for example in India it's
nascom nascom is yeah okay I've heard of
nascom yeah yeah and in the US you got
CPA which runs the CES conference and so
each country has done this right as tech
industry used to say you know what we
compete but we have common interest and
then uh back in
78 um all of these individual country
organizations realize we have Global
interests in common so why don't we form
a global industry Association and it's
called WIA the world innovation
technology Systems
Alliance and they're actually setting up
uh multiple uh centers of excellence
around the world to to bring kind of a
unification of the sort of thinking
around Ai and doing it safely and making
sure you're working with governments do
you think the private sector really
could be the crucial Catalyst to maybe
starting this
International uh because Microsoft of
course operates in all these countries
so you you see that as actually an
important spearhead here yeah in fact
they're they they're already working on
this uh with AI cers of excellence and
they represent over 90% of all tech
industry globally uh as an industry uh
um sence right so that's called WIA but
there's there's other examples within
different sectors all of them have ai on
their you know on their agenda radar
yeah how to manage it but not just to
how to integrate it but how to manage it
safely and and so on right so because
nobody wants to take a reputation hereit
if and it doesn't work right yeah
absolutely well yes I I think maybe it's
a good closing note uh we compete but we
have common interests I would say it's
true for for big Tech it's pretty darn
true for Humanity RIT large in general
uh and maybe to your point these kind of
faster moving technology companies could
start some of that International
becoming intergovernmental conversation
maybe even a little bit faster than the
pure policy ecosystem so I've certainly
got my fingers crossed that you are
right there and I think these are an
important set of ingredients to getting
us there and I know that's all we have
for time but Stephen thanks so much for
being here yeah it was a real pleasure
it was thrilled to be here with you
today Dan and very thoughtful questions
I just love the way you manage the whole
conversation and you know and we got
some important points and resources that
maybe the audience wasn't aware of that
existed right exactly giving people
homework is part of what I do and
Stephen you kind of did the work for me
today so I appreciate that very much
again thanks so much for being here so
that's all for this episode of the
trajectory I think there's a few things
to chew on from Steph's episode that I I
I think are worth considering and I'll
probably be doing more thinking on
myself the first is again this idea of
soft governance and where some of these
organizations that have worked on the
early proxies of sort of uh ethics and
governance within technology sort of fit
in again i e standards ACM um people
often think okay to control AGI would
imply you know men with machine guns
next to every data center but I think
there really is a much more Rich
tapestry of ways to align and incent
shared interests around maybe steering
clear of some of the more overt dangers
of artificial general intelligence and
Stephen opened some of that up his ideas
around the alignment of the US and China
I think most of the talk we see now even
among the big AGI leaders Dario you know
ultman many others have kind of
sprinkled in this idea of kind of
staying ahead of the the
authoritarian um you know adversary here
in terms of China uh it'll be
interesting to see if some of these
forces of alignment such as sort of this
shared interest in where the heck is
this going what is this turning into um
also manifests on the table and maybe
can counterbalance some of the natural
race Dynamics we're seeing now again uh
Stephen's one of the very few people in
the intergovernmental world I've ever
spoken to that cares about these things
most of the time if I'm in the UN the
oecd ETC really well-intended folks
often a lot of good discussions not so
many of them around post-human
intelligence Stephen gets it he's had
Sam Alman Jeff Hinton a lot of great
speakers at AI for good talk about the
bigger picture issues and it's really
cool to see folks in the policy space
who can get to this level and really
talk about transhumanism and other
things like that so hopefully enjoyed
this one stay tuned for our fourth
episode of AGI governance next up on the
trajectory
