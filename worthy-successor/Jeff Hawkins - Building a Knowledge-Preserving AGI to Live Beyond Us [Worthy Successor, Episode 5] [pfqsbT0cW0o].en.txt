[Music]
this is Daniel fagel and you're tuned in
to the trajectory before the iPhone was
the pal pilot and that device was
brought to you by Jeff Hawkins Our Guest
this week is Jeff Hawkins who has
written a number of books about
intelligence and is essentially been
working on replicating the brain since
the early 2000s when he got out of his
other Tech Adventure uh Jeff runs
numenta now which is a company that one
of our previous guests delip George used
to work at back in the day dpp's early
days working on artificial general
intelligence Jeff has talked a lot about
his theory of intelligence he has a book
called a thousand Minds which is worth a
read um but we're not here to just
unpack that theory we're here to talk
about something Jeff often doesn't get
to talk about which is this notion of
intelligence blooming Beyond Humanity uh
Jeff hasn't interviewed frequently about
this I would suspect this is about as
deep as Jeff has ever gone in an
interview about how intelligence might
Blossom Beyond humanity and what kind of
intelligence should Jeff is pretty
adamant that in a long enough time
Horizon that will be the case but what
could be good or bad about that and
what's the purpose of it all Jeff has an
interesting theory about where knowledge
fits into that uh question but I'll
tackle that in the outro you'll pick it
up from Jeff himself for those of you
tuned in on YouTube unfortunately there
was no video that came through on Jeff's
side for this interview a little a
little bit of a flub up uh of a
technical matter there but I hope Jeff's
personality comes through loud and clear
through his voice and more importantly
his ideas um so without further Ado
we'll fly right into the meat and
potatoes this is Jeff Hawkins here in
the trajectory so Jeff welcome to the
program thanks for having me Dan yeah
glad to be able to dive in i' I've
followed your work for a long enough
stint of time used to live pretty close
to where your guys little laboratory is
there uh and many people have sort of
caught wind of your book before we get
into this Worthy successor theme that I
know you've already seen bostrum and and
a little bit of Benjo stuff I want to
touch on um your grounding around
intelligence itself we're going to be
talking today about the trajectory of
intelligence where we think it's headed
maybe where it should head you began
somewhere different than a lot of
computer scientist of sort of the origin
of intelligence itself within living
creatures you know like ourselves how
did that study of where it started
influence your ideas of where it is
going or should go yeah sure you know
I started my career in computer science
and um but I fell in love with brains
really early on when I was in my 20s and
I decided that understanding how the
brain worked was the most fascinating
thing that anyone would do in in my
lifetime it was like the great unsolved
question and I also realized that once
you understand how the brain works you'd
have a deep understanding of what
intelligence is uh exactly because we
want to understand the brain in
sufficient detail that we could build
machines that work on those principles
so that's where I came into it I didn't
come in from an AI perspective I came in
from a neuroscience and brain
perspective but I always knew that once
we made progress in understanding the
brain we would have a better insights on
what intelligence actually is um and we
would have then a really clear idea of
what it is to how you go about creating
something that's intelligence and with
that background knowledge which most AI
people don't have it leads you to
different uh conclusions about uh what's
possible in the future likely in the
future how we might get there so I have
a I have a very different perspective
coming from the Neuroscience background
yeah I mean and that's clear in
listening to some of your interviews
here when you think about um where
intelligence sort of is going that
there's a lot of perspectives in this
domain and I think for many for many
folks it's a little bit up in the air
you know Benjo certainly doesn't have a
crystal ball and I don't think any
anybody necessarily does but uh when we
think
about what intelligence is bubbling up
into if that is happening what what
further development would look like
where things are headed did did the
grounding in its Beginnings influence
for you what maybe the next kind of
posthuman steps might look like and if
so Happ well absolutely absolutely it
leads me a very different opinions than
most AI scientists um for example I
don't think today's Transformer networks
are truly intelligent and I don't think
they're on the path to AGI there's a lot
of people believe that I I fundamentally
think think it's not true and I say that
because I know how brains go about being
intelligent it's really really different
and it's not just different it's a
difference that makes the difference and
so from that perspective I could say
yeah I'm not worried about today's you
know chat Bots or Transformer networks
you know becoming sensient being taking
over the world or anything like that but
I can see how we can build machines that
truly are intelligent they work on
different principles principles of the
brain and with that perspective I can
say well what's possible what could we
do you know what would a super
intelligent machine actually look like
um and what would it capabilities be and
what are the risks and rewards of doing
so but and I just reach different
conclusions than most people um having
that sort of deep Neuroscience
background um yeah so it's not that I I
I'm not worried about the future of
today's AI or I think it's useless or
anything like that it's real important
work um but I don't actually think it's
the trajectory to when we talk about AGI
or truly intelligent machines I don't
think we're on that trajectory with that
technology we have today yeah well and
you're not alone there I mean in all
fairness right laon is kind of famously
in that camp and there's a whole bundle
of folks some of whom are a little bit
more disparaging than you are of llms
you know like really laughing it off as
like a total joke or a bad invention I I
think that's a bit of an exaggeration
personally I think we should give credit
where it's due and this Tech is imp
impressive but again to your point
doesn't look like intelligence in terms
of the way that you define it in all
fairness and I'm not making an argument
on either side by the way I'm just
juggling the idea in all fairness is it
possible that thought in machines or
intelligence you know we could even use
terms like agency would manifest you
know in practice in a way that would be
intelligent but through means and
mechanisms that aren't like ours you
know I think about submarines not really
swimming and airplanes not flapping
their wings and whatever you've heard
all those
analogies I'm not saying that the the
brain approach is the wrong approach by
any means I'm just saying is it
hypothetically possible intelligence and
agency might manifest very differently
outside of human SKS it's possible but I
don't think it's it's I don't think
we're going to end up there okay um I
think if you really want to create
intelligent machines and that that we
would all agree with intelligence we're
gon to end up in a point which is much
more brain likee um it's I don't you
know your question is I don't think that
today's technology could actually do
that get there yeah um I really don't um
but I know how to get there through
brain like mechanisms um and I can look
at we can talk about those differences
not getting too technical about them we
can some pretty simple ways of
explaining the difference um and um and
so I I I it's possible I you know a
scientist will will never say nothing is
impossible I I think that's I think
that's a good position to have I think
yes but but for you it's very it's very
so you is like we're gonna coales
there's almost a singularity of how to
get smart and for you it's like it's got
to go through a filter where it looks
feels smells operates just like what
upstairs well it it has to operate on
the same principles and we can tell what
those principles are it doesn't have to
be a brain we don't have to emulate a
brain but we have toate what a brain
does and brain what brains do is not
what today's neural networks do yeah
yeah we can touch a briefly I know some
people have seen your book and there's
tons of talks where you're kind of
summarizing the Core Concepts if you
want to give us one or two that's
perfectly fine I do want to get into the
worthy successor stuff but maybe you got
one or two core distinctions we can just
lay out briefly we could just lay out
one b distinction wonderful uh brains
learn through Movement we are sensory
motor systems uh we learn by moving our
Limbs and our bodies and um and our eyes
we do this constantly and you can't
under the brain can't understand these
changing inputs which are rapidly
changing all the time unless it knows
how the body is moving so we are able to
explore the world we're able to pick
things up and manipulate them we have
choices about what we learn and because
we can explore and build tools we can
learn new things um
that you know today's neural networks B
they don't basically things they're cons
they're basically taking human knowledge
as it's capsulated in various ways and
making a good model of it so we're
sensory motor systems in fact if you
look at the brain the neur cortex this
is the deepest all get okay a big or up
on top we have a Neo cortex every part
of the Neo cortex has a motor output
there's nothing in our intelligent and
nothing about intelligence it isn't
motor related meaning movement related
so we are in curently movement related
um systems and that makes a huge
difference it makes a difference how the
models are built in our head that we are
naturally robotic systems if I want to
make um an AI system that explores the
universe and manipulates tools we do
that naturally brains do that naturally
today's AI systems don't do that
naturally at all um and very it's just
hard fit for them um so this idea that
it's all about sensory motor learning
and sensory motor modeling that's a huge
distinction uh between almost every AI
system today I I I think well I I would
concur monumentally I I I don't have a
really hard stance I actually think Jee
it's a screaming shame how little we
know about Consciousness um like wow to
think 12 years ago 15 years ago you know
first getting into this space and being
like well man we're gonna you know AI is
going to get smarter we're going to know
more about this secret light going on
inside of skulls like the ladder really
just didn't happen uh unfortunately so I
don't have a lot of takes there you know
hinton's made some interesting Illusions
to llms being capable of potentially
feeling or whatnot I'll leave that to
the side I tend to to to be very much in
your camp that um intelligence in a in a
genuinely agentic uh generally capable
way would have to have embodiment in
maybe in in uh in many dimensions I mean
the way the way some people imagine um
AGI potentially emerging Jeff and I I'd
love your take on this is you know you
take these gigantic systems that are
just vacuuming up Wikipedia and YouTube
um and then you give them a million
biped robot instantiations where they're
fixing cars and cleaning floors and you
know working on roofs and whatever and
then you give them a a bunch of uh
industrial uh implications where they're
they're putting together machines and
electronics and then maybe you make tiny
little beetles shaped ones that go into
burning buildings and try to see if
there's any children in there right all
these different all these different
wacky physical instantiations maybe even
with senses that we don't have you and I
I mean you know what we got five and a
half or whatever I mean you might build
a robot that's got 12 and a half maybe
maybe 50 that's one of the things about
we talk about the future of intelligence
even though I believe it's going to be
based on the principles of the brain
work they may me nothing at all like
humans they have to have sensors but not
human sensors they have to be able to
move Those sensors relative to something
through the world through cyber space
something this this got to be a concept
of I'm sensing different parts of the
world um but the sensors and the
embodiment don't have to be at all like
humans um and they could be I think you
know and I'm not going to pretend I know
what that future is I've written about
this but essentially we're bad at
imagining things like that and I'm bad
at too so we imagine we imagine the
future is GNA be like oh just like it is
now but better like oh it's gonna be
like human like but but reality AI is
not gonna be like that at all AI is
gonna be some embodiments that are be so
different than we can imagine today it
doesn't mean it's bad like these things
are out not out of control these are
things we're going to create it's not
like you know these things are going to
happen on their own um um but that's the
history of technology and history of
that we we're really bad at imagining
future users like you could ask Alan
Turing and John V Norman who invented
the computer in some sense um they
wouldn't have thought about the internet
or satellites or GPS or email or you
know anything like that none of that
stuff would made any sense to them yeah
but you know all they could imagine was
calculating numbers I literally that's
what they did right so y they were we're
in that mode right now think oh these as
are going to be like human I don't think
so well I I'm I'm glad you bring that up
I mean I I always cha at this notion of
sort of like well it's trained on our
data so it will have our emotions and
our senses and it'll talk like us and
walk like us I mean it feels you know
Bostrom does a great job of painting
kind of the the possible State spaces of
being right and the human circle is like
this big and you got some animals over
here but then you just have a canvas
that just goes on maybe infinitely we
don't really know of conceivable ways to
drink in senses and to act physically in
the world and to to to sort of you know
inhabit it and there are questions about
where is the human place in a world
populated with such entities but let's
save that for a little bit later in our
chat well that's that's that's part of
this podcast we'll get into it exactly
we're going to dive in so we'll talk
we'll talk next about kind of the core
brunt of what the the theme in the
series has been about which I think
Bostrom did a great job of opening up
around this notion of the worthy
successor and the idea here Jeff is that
um you know I've heard some of your
talks where you've you've been pretty
overt about hey you've got a vision of
life that is uh a Continuum and is quite
longterm uh and that that what populates
the Galaxy or you know terraforms Mars
might not be us it might be machines and
maybe there's certain things that only
machines would do long after we're gone
hypothetically you've you've spoken
overtly about this um when you when you
think about what traits an AI would have
to have so that it if it went off and
populated the Galaxy and at some point
attenuated you if you could look down
from the Stars although you know
presumably you won't be but let's say
you could you would look down and say
you know what that worked out okay I
actually feel pretty damn good about
that what what are those traits of a
worthy successor for you and why right
well I think first all I want to be
careful about the word successor that
sort of implies that we're replacing
ourselves perhaps I get it no you're
right I think it it does have
connotations I don't want to use that
word right I mean there Humanity I'm a
human you're a human we have human needs
there's there's a view of the world from
a human perspective I also spend a lot
of time thinking about a view of the
world from um a non-human perspective
imagine I was some sort of uh just an
observer of the universe and not a human
and and maybe I some super intelligent
system someplace but just looking at
objectively what the universe is going
on and that's what science does right we
we kind of take a lot of science is
taking it's just turn say one of the
fundamental things are actually
happening here yeah and of course you
know the history of science sort of
takes humans further and further from
the center of the universe right we're
We Now understand that we're just a
teeny little part of the universe so I
want I like to think broadly like you
know I can talk about what's the future
of humanity we can talk about that what
would be good for Humanity okay but I
also think we don't spend enough time
thinking about um what role could we
play in a universe where uh maybe humans
aren't around anymore you know um and
and I I I have a chapter I wrote called
you know State planning for Humanity I
like you know it's not like I'm planning
for humans to disappear
but you know what happens it's it's
likely actually at some point we don't
know how long it would be but that's the
history of of you know nature that you
know we're not even a constant species
you know we Chang it constantly so so
okay go ahead go ahead if you want to I
was I'll get to your your point now like
what would these things so I've asked
myself what's you know what's the point
of it all right you know absolutely good
question I think that's the best
question Jeff I love it so so the only
thing I mean our existence is important
to us and I'm a father and I'm a
grandfather and you know these I'm
important these are things important to
me but the universe doesn't really care
about us and um and so what would what
would other intelligent species care
about what would other entities care
about to know about what could we do to
help the future broader than our own
future that's it's not the only thing to
do but one thing we I don't think people
spend enough time thinking about and so
I ask myself is there a trajectory to
the universe at the moment we don't know
about that we don't really see there's a
purpose to anything we haven't figured
that out yet
um one thing that seems constant to me
is um we as humans and I think every
inen species that ever would ever exist
in any part of the universe would want
to gain knowledge we all want to
understand how the universe works what's
its past what's its future and the
knowledge that any other being would
create would the same as our knowledge
knowledge about the science and the
universe as a whole seems to be
Universal that is there isn't a
different reality someplace else in
space um and so you know much of what
drives the intellectual abilities of
humans is to understand our universe
understand who we are how we got here
and that information continues Beyond
where our you know our lives over you
know my particular life a million years
from now No One's Gonna know about it
won't make any difference but perhaps we
can gain knowledge and that knowledge
will continue on and so I think that you
to me the only
worthy a goal that we could have broader
than our own existence is to accumulate
knowledge and make sure it's not lost
that is it is preserved uh for some
future potentially future intelligent
species on this planet or some future
intelligent species that come visits or
someplace we go the point is that's the
only thing I can think of that is that
is a worthy goal um and I can't prove
that it's worthy it's not worthy to whom
it's worthy to any other sent of being
right that's that's the best I can come
up
with so uh it motivates me yeah so well
we're definitely gonna unpack that I
want to if if you don't mind I'll just
do it in a couple layers so one idea
that Dawns on me and I think when I
first heard you articulate I mean I I
think
there's I I would completely Concur and
have been ardently focused for 12 years
on the whole what's the point question I
think it is very easy to say well put
your kids through college and you know G
get a vacation house and like you can
say that but but I think that from my
standpoint again the reason the worthy
the term is worthy successor and you
don't have to use that phraseology if
you don't like but you even wrote the
chapter on estate planning is that um
you know lucretius was right there's
matter and there's void and things are
coming in and out of existence and and
there there isn't so if we look at the
options that we have I don't think it's
realistic for us to say that there is
one option called Eternal hominid
Kingdom where where for uh the next 200
billion years it is hominids as they are
uh trimming our fingernails getting
jealous um you know eating vegetables
because we have to you know I just
that's not actually one of the options
that we have so it's it's it's okay for
a minute but there is there is going to
be either a bubbling out of us
biologically and brain computer
interface wise it will be a bubbling
Beyond Us in the digital side and I
don't mean this to say I think some
people have very frankly said and
Bostrom as well that a worthy successor
should you know treat the other
intelligence as well for example so it's
it's not like a worthy successor implies
you know that dark destruction of all
other life but I think you're you're
bringing up a point that I think more
people should look at frankly maybe as
frankly as you do which is that long
long long
term this is turning into something and
there will be a day when we'll attenuate
and we should think
about how that baton gets passed off if
I'm if I'm picking up that's right and
here here's another way of thinking
about it as a biological species we're
not particularly impressive you know
we're not particularly strong we don't
fly we're not very good swimmers we're
not really particularly fast the only
thing that makes us unique is our is our
intelligence that's it yeah and and so
we have that's our and that's it's
really a completely different type of
thing because no other animal that in
our on our planet has knowledge about
the universe no other planet knows that
you know the Earth has ground in a
certain size how old things are look at
only That's Unique that's our that is
our thing and so that's the thing that
if we if we to preserve something if we
want to progress something we might as
well progress the thing we're good at
you know and and and survival and having
sex and having kids yeah that's good we
should do that but that's not really
unique to us you know yeah yeah yeah so
it's kind of like shortsighted I think
that that's all you want to focus on I
mean let's pick a worthy goal right
something we should
attain that's just beyond life uh Beyond
at least biological life on this planet
absolutely so that's that's that's what
I think about it I I think it's
incredibly important I mean you know
just just to pick up what you're putting
down I mean if you well towards the end
we'll talk a little bit about Innovation
regulation decision-making what what
could or should humans do to move closer
to such a worthy successor and and and
or or such a let's call it a blooming or
positive postum future for you the
nutshell here is hey uh knowledge is
sort of what makes us specially unique
it allows us to function it allows us to
even contemplate future intelligent life
or past intelligent life
um let's ensure a rolling snowball of
the acquisition and maybe distillation
of such knowledge about the universe and
other things that can continue to expand
and do other worthy stuff and then maybe
if we meet other species in some wild
wacky future you know we'll have
something useful for them and and there
will be a way to contribute but to your
point you know you brought up a great
point which is that right now you know
you just you just look out into the game
right the game being nature right uh uh
and and it doesn't seem like there's a
goal right there's no there's no goal
post for nature I mean nature wants us
to like have children and nature has
some immediate goals but there's no
Grand objective you know we've got to
pick it um my supposition is that if
there was a grander and higher objective
in other words if there was a more
coherent that would be the great thing
to do aim within the universe which by
the way I'm not at all convinced there
is one but if there is I functionally
guarantee it would require vastly postum
intelligence to access such a goal and
that may probably yeah and probably
right right there there are some people
who are of the belief and I'd love your
thoughts on this that you know David
deuts is a famous example I've never met
the man in person I have plenty of
respect for him um but there Yan talin
was on not terribly long ago and sort of
brought up this idea I don't think he
was espousing it but he brought it up
this idea of being humans being touring
complete that is to say anything that in
principle could be conceived of by a
grand vastly posthuman super
intelligence could in theory also be
fully understood by humanity and that
kind of it's possible that we've crossed
a threshold where the totality of at
least conceptual knowledge is fully
graspable within the hominid skull what
say you of that um I don't know I I
don't want to take a strong position on
that um interesting clearly we can
understand things that that we can't
directly sense right I mean I have
understanding of of atoms and quarks and
DNA I can't sense these things I have no
build but we've built tools that allow
us to visualize those things yes I also
don't I can't sense directly the size of
the universe or the age of the universe
yeah yeah but I know those things so
there's clearly stuff we can learn that
is not in our genetic past that wasn't
um conceived of but the on the other
hand our brains have limits right we're
we are limited in the speed of which our
neurons process we're Limited in the
amount of memory we have we we can't
really change that uh we're we're
limited in our senses but I just give
you example where our senses aren't as
limiting you think they are because I
can take things
like atoms and turn them into images and
I can try to imagine them um so I don't
know what the limits of our ability are
but I would say we have limits to our
speed and limits to our
capacity uh I also say that humans are
burdened with our emotional components
of Our Lives um you know I can say it's
a burden I can say it's a blessing
depending how you look at it I love
loving people and I love nature and all
these things but on the other hand you
know we're burdened by our competitive
natures and our and our you know
totalitarian inclination this kind of
other crap that we do um so that may get
in the way of our our sort of being tur
complete um you know tur complete
assumes that there's an infinite amount
of memory in some sense of like a
turning machine right so so I don't know
I don't think that's an important
question at the moment clearly we we can
we can understand more than we know
right now there's no question about it
right um we're learning new things all
the time that seemed pretty difficult to
learn and and they weren't in our back
past and so we' learning them what's the
limit there I don't know um we haven't
reached that yet and so I think we
should worry about that when we get
there I I do think uh you know we we are
limited I mean you mentioned early
clipping your toenails it's like you
know I we we're we're blessed that some
of us can spend some of our time
thinking about these problems absolutely
vast majority of humans have no time to
do this at all they're trying to get
food on table life is miserable I mean I
don't know it's I'm say miserable but
they don't have time or the ability to
education and so on to be able to spend
time on this so you know I I'm I'm I'm
on open about what's the future of
humanity right it's we got a difficult
problems to deal with we got all this
messy biology we're dealing with all of
our messy emotions and and and um
biological drives we have to deal with
so we're kind of a kind of a complex
messy system and I'm do I view is we're
trying to break out of that right our
our goal should be to break out of that
past because I don't really care that
you
know how my genes work it's more like
you know what animals eat other animals
I mean it's important from a our
personal biology but it's not important
from the big picture right the big
picture is like all about intelligence
and knowledge and humans will have some
capacity beyond what we have now I don't
know how much it is but we'll have it
yeah maybe we'll run into those at
sometime well I I my supposition is you
know again you're not taking a firm
philosophical stance but if you if you
believed that hypothetically we could
grasp it all presumably you wouldn't be
as enthused about the grand project of
higher and greater vessels of higher and
greater knowledge uh continuing Beyond
us well I think one thing one thing is
for certain is we uh will not be able to
travel um Beyond uh Earth very much um
you know it'd be nice but it just
doesn't look like it's going to happen
and so even just going to other places
in our solar system is very limited you
know just this discovery that happened
this week like oh maybe there's rock on
Mars that proves his life well we won't
get to see that rock for another two
three years or whatever years exactly um
you know what's you know what's the
universe have to offer we don't know you
know we'll never we can't travel there
we can't we're kind of limited so I
think even if we have the capacity to
know things we won't have the capacity
to discover them and um and that's
that's part of the process it's not just
knowing something it's being able to
explore and discover and find new
knowledge and we're Limited in that
regard yeah well I I I'll I'll roll over
into something that relates directly
what you're talking about here about
optimizing for knowledge you talked
about kind of the messiness of our
emotions there's this idea because I
look at my own Grand conceptions of the
big game like you do I mean I find it
hard to live without at least some
notion of what a North star could be at
least striving ardently to find one and
then striving ently to move in its
direction feels like you're pretty
compelled by by by such a drive any of
those distillations about that North
Star you know I'm eager for the day when
there's vastly more intelligence to
conceive of better North Stars I think
you and I Jeff we can conceive of higher
and I might even argue better goals than
a labador retriever my supposition is
that there will be entities Beyond us
that will conceive of better go goals so
I'm not too I I I I happen to believe
it's likely to be the case but it could
be wrong we'll get into that here's
here's the ear go ahead I I CAU I I I
said earlier the best thing I can think
of is the pursuit of knowledge I didn't
say that was the the only thing even the
best thing it was like in my lifetime
the time years I've had on this planet
that's the thing I can think of and
maybe there's better ones you know
that's all we can do is hand that baton
as far as we can go if if there if there
be something to us as we are to the
labrador someone will uh maybe be
grateful for your contribution probably
chuckle a bit at some of it and then
move on and and I would say that would
feel like so long as it's doing you know
interesting and good things and
surviving may maybe be a maybe a good
thing here's the thought experiment I'll
bounce off of you you know when you
think about the highest goal that you
can conceive of I almost think of and I
I haven't put this in an article but I I
need to at some point this notion that
AGI is almost a lit it's almost a roar
shark test for what someone's core sort
of drives or propensities are that is to
say the following if I I remember once I
had three employees this is six seven
years ago sitting around and talked
about sort of like if if AI cross these
thresholds of agency and intelligence
and capability and whatever and there
was someone who's like very it was
almost comical how it worked out there
was someone who's very curiosity driven
like totally about like researching and
finding things he was like well I think
it would want to discover everything
about the universe or something like
that and then there was someone else
who's like super like empathetic and
they were like well you know it would
have to be conscious and maybe it would
like experience all kinds of bliss like
beyond what current life can experience
and and maybe it would experience things
that are different than pain and
pleasure right totally different ranges
of sentience and and maybe it could be
like loving and like they they you know
uh there was someone else that was more
focused on connection they're like well
you know it would really exemplify love
and it would find ways to be caring for
other creatures and caring for alien
intelligences and so it's almost like
you you take the word AGI put it in
front of somebody and like they're going
to see a butterfly if they want to see
butterflies you know and they're they're
going to see a snowman if they want to
see a snowman like I'm not saying
anybody's idea is wrong here but I'm
just saying do you think there's some
Credence to that
idea
um well I mean there's creen to almost
every idea okay all right right right so
I don't want to cop out on it
um to me you know it's the the the the
emotions and the sentients if you look
at that from a biological point of view
it's actually less interesting than most
people think it is um huh go on that's
yeah that's you know the mystery of
Consciousness and so on I think you can
readily explain it it's like there's no
mystery to it it's only because people
don't they don't know what it is so
theme's
mysterious um so but to me it's again my
interest yes has been about knowledge
and intelligence totally how I look at
it I would I wouldn't tell you to CH I
wouldn't tell you to change Jeff at all
right right so other ideas are are not
valid they can be valid but if I think
about again like I mentioned earlier
what's unique about humans well you know
other animals have emotions don't don't
fool yourself you know dogs are
conscious totally totally I'm with you
I'm with you right they feel pain they
happiness um but again this this thing
that that's unique to us is our
knowledge and our ability to learn more
that just just cries out for like
attention like that's what we ought to
be thinking about that's that's what AGI
is all about it's not about building
humans I don't like the definition of
AGI which is like human abilities yeah
yeah it's not a good reference point
it's it's like it's a little bit like I
didn't like the Turning test it's like
it's not about ulating humans it's about
understanding the fundamental nature of
knowledge and intelligence and uh how do
we get more of it how do we build
machines that can do more of it and can
help us out but also exist independent
of us yeah um because because there was
that you know we we may not be here
forever y so so it's like it's not one
or the other it can help us too but but
but at some point exactly I think I
again I'm big on I'm big on getting
people to just swallow the horse pill
called eventual maybe it's tens of
thousands maybe it's a mill oh a million
I I think a million years is a goofball
number but let's just [&nbsp;__&nbsp;] throw it
out there a million years at some point
we're attenuating we're turning into
other stuff um and I think swallowing
that is really important and to consider
what that leads to I think this is the
most important question and you think
about it a lot to your point around sort
of you know emotions Consciousness being
less less interesting I mean I would say
that's definitely an opinion now I would
respect your opinion I would respect
your opinion more than mine because you
have a lot of grounding in the relative
construct construction of those things
but I would say it's certainly an
opinion because I could I could see
someone saying now by the way Jee I'm
not pushing back against knowledge I'm
trying to learn a thing or two from you
here today so I'm certainly not pushing
against knowledge but what I'm saying is
I could see someone saying hey if the
lights go out and this thing knows how
to do calculus that we can't imagine and
it understands something about black
holes that we don't grasp but like in
the form of like a hard calculator on a
table that would feel like maybe we're
losing something there um like would you
hope that your you what are we losing
exactly Consciousness let's let's assume
so you that's my conscious by if if if
if you build a machine it works on the
same principles as
that machine can learn it it it has
memory of what it learned um it has
memory of what it was thinking about I
believe Consciousness will come for free
that if I Consciousness is not something
embodied outside of the processes so
it's not like we have it's almost I'll
say it's impossible to have a machine
that is truly intelligent that learns on
its own that discovers principles of the
world that isn't conscious okay so your
suspicion is it will it'll come with the
it'll come with the package it's more
than a suspicion it's got a lot of
evidence behind it can't prove it yeah I
I hope you can get to proving it Jee
because I really do I wrote about it a
bit I gave some thought experiments
along these lines to help people come to
this conclusion um but look it's it's
unprovable at this point in time but I
think um you know some people argue that
even if you had a machine that acted
like it was conscious you could say no
it's not like it's say yes I am I'm
conscious you know trust me ask me
anything I'm conscious and they'll say
nope it's not only humans can have that
well let [&nbsp;__&nbsp;] I'm sorry I I I happen to
agree and and again it's it's very
interesting I get to interview a lot of
super brilliant triple PhD folks and and
to see the Divergence is a quite a crazy
thing um but but I I I agree with you I
concur on your side that the notion that
sort of Consciousness exists only within
hominids or only within you know uh uh
carbon based life I think does feel like
a silly supposition but for you it comes
with the package is your
perspective I'm not going to make a
direct likeness cuz I'm sure this some
differences but I remember in Kurds
Wild's how to build a mind you know the
basic notion is sort of that's some
emergent property of sort of complexity
and required activity and whatever it'll
be aware no I I don't I don't agree with
that that's U that's that's giving up
that's like saying I don't understand it
so it'll just happen no we can't
understand it I mean and again I wrote
about this but I don't want to get into
too much yeah yeah yeah it'll get a
little crazy all right we we'll put it
in the show notes we can understand this
it's not it's not a proper when people
use the word emergent properties they're
saying like hey the physics says this
but after you have enough complexity
something else appears that the physics
doesn't explain I don't buy that um yeah
it's not like some mysterious emerging
property you know there's there's a lot
of people who believe in um um that
everything in the world is conscious you
know a rock is conscious sure sure hand
psychism or whatever I think it's this
crazy this all this wild speculation
comes about from that no one really has
a deep understanding what Consciousness
is and if you have that then all that
craziness goes away so I can I have a
personally I think I have a good sense
of what's going on and I've written
about it and yeah and I'm just like n
it's not crazy it's it's pretty it's
interesting but you can completely
explain why we feel conscious um and
what is what is it what's going on in
the neurons that make that happen and
it's not an emerging property it's it's
just a proper the way the system works
well I I certainly hope you can make
some Headway there I I myself have yet
to escape hume's Fork so I'm not even
really sure that you exist but I hope
that you do um and and I'm conducting
this interview as if you do um but uh
but so I I don't have any certainties in
that regard but in terms of um I I have
a lot of Hope though or I have my
fingers crossed that there will be more
Headway on when the lights do go on
because I think it sounds as though you
would agree but you just think it's
going to happen automatically if by some
wacky chance whatever populated the
Galaxy was crazy smart and was
constantly acquiring numbers and
inventing Meta Meta Meta Meta Meta Meta
physics um but it was always lights out
like this experience of a movie playing
in your skull and in my skull was Gonzo
like for good at least from Earth life
totally toast that would be a shame for
you it's just like that's unrealistic
but I I think you would concur you would
concur it would be a shame or would you
say hey if it's still knowledge even if
it's not aware of
itself I'm not GNA give you ground on
this I don't think it's possible okay
got it got all right there we go it's a
valid perspective valid perspective
valid perspective
you can take a system that is has been
trained and learned and can do certain
things and you can turn it into a zombie
uh you know if it's a robot that just
does stuff but yeah anything that's
acquiring knowledge and exploring the
world um has to be learning have will
have these properties wow not that I
think like deep learning networks don't
do this because they don't they don't
remember what they were thinking about
they don't even think um they don't even
remember what you know we we store
memories of of not only our immediate
past experiences but what we're thinking
about and we can think about the future
and we can think about the past and
remember those things yeah so this gives
us this this sort of window through time
where we're recall these neurons are
recall recalling thoughts about what we
expected and what actually happened we
can go back and forth between these two
and that gives us a sense of a presence
we can say yeah I was there and oh I'm
going to be there and why did I go there
because I wanted to do this this um this
is this gives you this sense of being in
the world um that you you exist beyond
the moment because you can recall the
past and you can recall your thoughts
about the future so it drives from that
it's a bit more complicated than that
but it drives from that and and look I'm
certainly not here to change your
opinions about anything but it's your
your perspective is clear your position
is clear which is hey it's a package
deal there's no version of the world
where this thing does anything
intelligent and agentic and it's just
lights out inside it's going to be
conscious in some way so totally totally
gather where you're headed I I'll throw
one more quick thing on the table then
we'll talk a little bit about how to
tell if we're moving in the direction of
this uh uh this knowledge acquiring
expanding intelligence that for you is
sort of the the Bedrock of what what
kind of matters
um this question would sort of I'm going
to tie this to philosophy a little bit
that Spinosa has this notion of the
canatas and the potentia which which I'm
sure there's lengthier academic you know
uh treatises on but I'll try to a short
version the canus is basically this idea
that um uh living things organisms you
know complex or
non-complex almost by definition have as
their primary mandate non-death uh so so
or or persistence which sometimes can
involve reproduction but sort of
persistence would be mandate Numero Uno
so you know eating food reproducing what
have you not dying um and in order to
not die uh now he he wasn't an
evolutionary biologist or anything
because that stuff wasn't around then
but I'm going to tie it in a little bit
he has this idea of potentia so potentia
are the set of powers and abilities by
which something with a cantis tries to
not die or tries to persist so could be
you know mating eating not not perishing
um and potentia has bubbled up I mean
you studi the the history of
intelligence at some point nothing could
see there was nothing that had sight
right and then it's all of a sudden Jeff
at some point sight occurred at some
point there was no Locomotion and I know
you're very big on embodiment and then
at some point there was locomotion and
things could actually move at some point
um nothing could fly nothing could swim
so potentia has bubbled up in the form
of a turtle shell it's bubbled up in the
form of uh language capability like what
you and I have it's bubbled up in the
form of Claws and fangs it's bubbled up
in in camouflage being able to blend in
with trees and rocks and whatever so all
of those traits everything I just said
at some point never existed and here
here's the idea that the spinosin idea
is that what life is trying to do is not
uh
maybe it's not like be conscious uh
maybe it's it's aiming to expand its
potentia and I guess a potential
argument could be and I'm not saying
it's right or wrong would be that
knowledge and intelligence is a part of
that mix it's a part of that mix as are
many Myriad physical abilities as are
things that don't yet exist so if
potential was to keep blooming it
wouldn't just be a really good ability
to play Chess at a vastly postum level
it would be in entire Realms of uh uh uh
let's call them cognitive physical and
other capabilities for which we have no
words and no ability to ever put words
and that intelligence is ultimately
trying to Bubble Up not just proxies but
for we understand but proxy but but a
set of powers vastly beyond what
presently exists we have to be careful
here
because Evolution doesn't have a
direction it doesn't it doesn't want to
go in that direction it can but it can
go backwards too and so it's not like
the goal of life is to have those new
capabilities and new things it in
reality the goal of life is is based on
genes not individuals and this is
Richard Dawkins great discovery um one
of the biggest discoveries in biology
ever is that genes are the center of of
evolutionary um components genes compete
not humans not bio not our physical
bodies but it's individual genes are are
what is driving Evolution and they're
dumb they just you know it's like
they're dumb they they work together to
come to figure out ways of replicating
each other the individual genes that
replicate it's not individual phenotypes
humans or bodies and so you know I think
nature can go in that direction but it
doesn't have to that's not the goal what
I'm trying to you know I think we ought
to do is realize that there is a
trajectory that you can think of
knowledge and intelligence as a potentia
if you want to call it that but nature
not nature doesn't nature may or may not
select that oh totally totally I I would
concur I'm just saying maybe we should
select for it which I think you agree
with where I'm going a little Beyond is
that we should select not just for more
of discovering physics and playing chess
but the capability to rip open new
magazines of potential that have hither
to not existed and that we will never
have words for right but what is the
goal of those things the goal in my mind
goal the goal would be to not die the
goal would be to continue into the
Galaxy and not perish because I think if
your knowledge machine went into the sky
and did chess and then died you'd be
very sad about that knowledge machine
right right but again be careful here
because what is the goal the goal I mean
we all die right we all die you know
you've had your kids they pass on you'll
have your machines they'll pass
something on right right so I'm trying
to say like you should set your goal
like I'm not telling other people to do
this is how I view the world totally our
best goal is to is to is the acquisition
and preservation of knowledge and there
may be multiple ways of doing that um
one way you know it doesn't require a
species or or even a particular type of
entity to exist forever it just means
that we have ability to pass it on just
like we pass on knowledge to our
children totally we can pass on
knowledge to other species we can pass
on knowledge to other intelligent
machines intelligent machines can pass
on knowledge to other intelligent
machines it's and so just be careful
that you know living forever is this
thing a lot of people want to do and
maybe they think machines ought to do
that too I don't that may be true but it
may not be it doesn't in my mind that's
not the end goal I would say I'm happy
if such a potentia snowball is
constantly perishing and rebuilding
itself in the same way you passed on
knowledge to your children Jeff you know
what else you passed on eye color
physical dexterity of your hands some
degree of IQ you passed a bunch of stuff
on outside of like you know the English
language and whatever you taught them
right like you passed a bunch of stuff I
wasn't unique in that they would they
could they would have I get it I get it
I get it but but what I'm getting at is
like um the the the if the thing kept
perishing but it was it was passing
those things on I would consider that to
be worthy I think probably you would
concur like I'm not married to an entity
That Never Dies I'm definitely not
married to that I'm I'm I'm married to
at least presently as a human I can only
imagine so much the torch staying lint
that is to say the torch of life and and
I would consider knowledge to be uh a
part of that wide set of things that
could permit a thing to keep going out
and to Let's I would agree with all that
except I would say it's not important
that the torch stays lit it's important
that a torch stays lit so one torch can
go out and another torch can that maybe
thousand all the original ones I say the
because it it kind of started with
whatever the hell bubbled up here but
yeah to your point I'm I'm okay with I'm
not speciesist there we go all right
nice good good good yeah there
something's burning somewhere uh and
hopefully maybe a brilliant blaze of of
experience and knowledge and ability
that could continue and do things that
that we can't do um so seems like we're
on the same page at least in some regard
there I guess moving moving into uh the
direction of building these things of
course this has been your life's work
for quite some time now Jeff uh and and
you know uh your intellectual
contributions with your books and and
whatever as well um when we think about
moving closer to something for you which
would automatically be conscious if it
was smart but would be able to continue
to acquire knowledge and even if it
didn't continue pass that on through
other per mutations of this intelligence
that could grow in this knowledge
capability over time um which you maybe
we'd call a branch of potential whatever
we want to use as the the the uh
phraseology here how when you're when
we're boots on the ground let's say open
AI has a breakthrough or you have a
breakthrough or someone else has a
breakthrough and it's like wow hey this
biped robots are incredibly capable now
that's incredible how would you look
under the hood and say are we getting
closer to the kind of thing that would
we'd really be proud of you know a
million years from now if we happen to
be gone are we getting closer to the
kind of AI that is the right kind you
know what are your thoughts there so I I
give let me answer that in two ways if
you don't mind please please um One is
um we're trying to build that future
right now in fact um we think we know
enough about how the New York ctex works
and the brand Works uh We've proven that
internally our our research we've proven
we can build systems that work these on
these principles and just just a couple
months ago we announced the formation of
an open source project called the
Thousand brains project cool which uh um
we got funding from The Gates Foundation
to do this and other people um we open
sourcing all of our research we have we
have different Hardware companies
different actually government agencies
around the world have have joined with
us my book has created a lot of interest
in this and um so we're creating this a
real serious project to build this stuff
in an open a very open way so we're not
just sitting back and hoping it happens
we're going to be as AC we can to make
it happen the second thing is how would
you tell um I made analogies to this in
the past it's like how do you tell
something a computer or not you can't
you can't really judge it by the
behavior of the thing you can't say you
know like I use a very simple example I
could have a toaster which has a
computer in it that has dos all these
function functions or I could build a
dedicated machine that does those same
functions that doesn't have a computer
in it and from the outside you can't
really tell I saw a car going down the
street I can't tell if that car is
intelligent or there's a human driving
yeah yeah yeah yeah so so to me it's
like how we Define computers you say
well is it a computer or not there's a
set of things it has it has a memory and
ability to transfer information and it
has a a computational unit and has
instructions and and if a system has
that we call it a computer whether it's
made of you know Tinker Toys or silic
doesn't really matter same things I
believe should happen with intelligent
machines um there's a set of principles
which I've outlined which I think
defying what it required to be
intelligent and you can look inside a
system says is it doing that is it
learning through movement is it learning
continuously you know it doesn't you
know we don't train on a million data
sets we we train by selectively sampling
the world yeah um and what do the
internal models look like I gave a talk
at Stanford recently about this very
topic about the internal models what how
is knowledge represented inside the
system and in Brains it's used a type of
thing called the reference frame in
Trans in Transformers it's a different
type of system so you can say okay these
maybe you know I've I've offered a set
of principles maybe people Maybe I'm
Wrong maybe people want to offer a
different set but you can define a set
of things say is this thing really
working on the right principles or not
and if it is we're going in the right
direction if it's not it's not the wrong
direction it's just not the direction of
AGI or intelligence and this is why one
of the reasons I say that I don't think
Transformer networks the large language
models and so long we see today are on
the path to intelligence because they're
not working under the right principles
they're really powerful and they're
really cool but they're just not going
to get there in my opinion yeah so
that's a way you can tell whether it
it's like we have to come to agreement
about what is intelligence and what are
the principles by which it requires and
it it can't focus on the behavior this
is a big mistake I mentioned earlier if
we focus on the behavior you know when
when the computers first started doing
math the same thing happened people oh
my God these things are super
intelligent because look this math is
hard and they're doing it well now we
just don't think it's hard at all it's
like yeah calculator does that not a
problem at all it's like you know that's
not really intelligent um I think one of
the things these large language models
have showed us is that language modeling
isn't as difficult as we thought it was
um maybe humans aren't very good at it
um our brains weren't evolved for this
yeah and it turns out if you just want
to model language well guess what there
are better ways of doing
it um those models don't really
understand anything else but they do
understand language very
well did a really good job at it so I
think we have be careful not to get
fooled by the output of the system and
we have to we have to I think the world
will move in this direction I know it's
not there today but the world will move
into the direction of computer is like
well is this a computer or not here's
the principles it has to work by is this
a intelligence system or not here's the
principle by it has to work by yeah okay
really interesting there's a lot to
unpack here Jeff if we could so um one
one thing that you brought up uh you
know is this idea that okay if if it
abides by these principles then hey you
know we can say this is an intelligent
thing or this is a you maybe at some
point we could even say a conscious
thing etc etc um is there a world where
let's just say
hypothetically uh I don't it doesn't
doesn't really I don't have a dog in the
fight so I know I know you kind of do
but if I'm just looking as an outside
fella you know we've got our numenta
research folks we got our Deep Mind
research folks we got our open a
research folks whoever puts the thing in
a bajillion you know uh physical
instantiations again we got some Beetle
robots we got some industrial robots we
got some Life Sciences robots we got a
lot of bipad robots maybe we got cats in
people's freaking houses that are you
know running around and getting pet or
so whatever but it's getting tactile and
like you said it doesn't have to be
senses that humans have this thing could
be looking at infrared it could be
detecting chemicals with the ends of its
fingers or it you know fanges or
whatever who the heck knows but but it
could have a bajillion of these
instantiations and be acting
intelligently therefore um would any of
those so long as they're checking that
box basically be for you what would
eventually you know assuming long long
long into the future we attenuate would
any of those things be worthy successor
or would you see there being a way where
maybe there is a version of something
that could be intelligent built in the
wrong way or on the wrong principles or
whatever we're like it can do stuff but
when we're gone like it's not able to
carry on in any meaningful way and keep
that knowledge generation going in any
appreciable way is there a way to build
something that's a great tool but won't
be such a successor that that could last
Outlast I think in fact I think it's
hard to make the successor and it when
humans are gone you know imagine I can
build these really super intelligent
machines um I don't even want to say
machine because I don't know what their
substrate is but let's yep yeah we'll
say machine for now right right the
challenge is um is that anything we
create won't last it'll Decay and and
and so you end up forcing yourself
saying well do I have to give these
things the ability to procreate or
recreate or copy themselves um you know
what's the I gave the example once where
you you would send a bunch of super
intelligent machines to the next star
and they're exploring and they're having
a great time but now they're wearing out
how do they repair themselves there's no
factories there you know you can't go
give me another chip you know yeah
they'd have to they'd have to generate
Nanobots that could patch things or
whatever it is so the hard part actually
is um
replication and independent of humans
and and the ability to basically you
just can't design anything to last
forever so you have to have the ability
to replicate look like biology does and
um that is that's outside of
intelligence that's the saying the
reality is if I want to create
intelligence machines that last forever
they're not going to last forever so we
have to have the ability for them to
recreate themselves somehow and I have
no idea how to go about doing that yet
it's you know that's a challenge that we
can use intelligent machines here and
now for humans and we can use them to
explore our solar system and it could be
great but if want something to transcend
Humanity something survive after we're
gone that is a challenge because we are
not around you know they're no longer
our tools they have to be their own sort
of entities that can
survive abolutely absolutely how do you
do that I don't know how to do that you
know okay so for you that's that might
even be harder than intelligence would
be the It is Well I don't know it's just
I don't know if it's harder but it's not
something I'm thinking about something
it's not your problem exactly think it's
the first thing to worry about I mean
the first thing to worry about is not
how to create things that replicate
Beyond Humanity that's the first thing
to worry about is understand what
intelligence is build intelligent
machines those intelligent machines may
help us figure out how to solve those
other problems I mean day one figure out
intell is day two build machines are
really smart then figure how to use them
to advance uh our the world we want to
see yeah so I focus on on just you know
what is intelligence what are the
principles how do we build them
get that process started to be clear
you're you're you're you're you're being
uh you're putting a point out here of
hey for it eventually if it were to go
off and do worthy and great things
Beyond us at some long distant future it
would have to be capable of some degree
of replication or uh or or or I don't
know infinite repair or whatever some
some a combination of preservation
replication creation and and you're
saying so so that would be a worthy
successor quality we would want but I've
heard you say Obviously elsewhere that
just rampant replication could be a
danger even when humans are here on the
planet right right well we don't a virus
that can kill all humans right totally
yeah so that's that's a balance that's
tricky I think we're really far from
that I think as I said the order is
first building intelligent machines
understanding intelligence um we're not
there yet uh we're getting close and uh
once we get to that point once we get to
the point of saying you know maybe even
facing some our own demise which we
already facing it now's oh yeah yeah for
sure for sure
I certain yeah potential um that we'll
have to think about that as well I I you
know I did write about you know ways of
trying to preserve knowledge even if um
even if there's no intelligent machines
like like you could you could try to
preserve knowledge for future
intelligent animals on Earth or future
intelligent system things from elsewhere
in the universe coming to visit us but
that's not really the end goal that's
like a time capsule like hey here's
where we were here's what we knew
someone else might discover that um
really the goal would be to create in to
machine that could explore the universe
and could repair infinitely or replicate
replicate really because you'd want to
spread it out throughout the Universe
hopefully um and the moment we don't
know we don't have any evidence that any
other intelligence systems have achieved
that we're not you know some people have
argued that maybe it's happening we're
just not aware of it but we don't know
that yet and um we don't know how to do
it ourselves so let's start with the
thing we I think we can do today which
is build intelligent machines got it uh
so long enough term in the future it
sounds like I just want to I make sure
I've got this in a nutshell and we'll
move to our final question um for you it
would eventually need to either you know
repair replicate create into the future
that would be a necessity for such a
such a thing that could be a successor
if if at some point we're gone um and
similarly uh my guess is you wouldn't
want such an entity let's say it's
streaming through the Galaxy at you know
near light speed because it's discovered
all these things to just be executing on
some human level goal that was
programmed in it you know uh 2,000 years
ago my guess is you would like this
knowledge rolling entity to be able to
conceive of its own aims maybe perhaps
you know it's perhaps I I I don't know
if that's we have a choice in the matter
or not huh um yeah I don't either
honestly I I think I think the goal of
acquiring
knowledge the best as I can guess today
is a universal one that will transcend
time um it's hard to imagine how at some
point in time we won't want to some
future entity wouldn't want to acquire
knowledge I just hard to imagine maybe
it won't but if I had to pick something
that's the thing I'd pick I think what
you wouldn't want to do is transgress
and decide hey the only thing I care
about is you know making copies of
myself so I'll you know destroy
everything else to do that um that
wouldn't be a worthy goal so you so you
would want it to be locked into the
acquisition of a giant moving library of
knowledge so that other intelligent
entities it could interact with like is
the purpose of preserve preservation so
that when it meets some other foreign
alien or some other interdimensional uh
entity it would be able to say hey uh I
know uh I have Jeff Jeff's whole book uh
in in my backpack over here and I've
also discovered all these cool physics
things like is the purpose for that that
passing on to some other intelligence
what is the purpose for you right the
purpose well remember we started this
conversation saying there is no obvious
purpose to our existence y I'm with you
on that and so and so I don't want to
just blly go through life saying well
too bad you know let's say love we'll
just come and go let pretend that we
don't really care about the Universe um
and so I I have to pick something that's
I can at least I can personally say like
well that seemed like a worthy goal it
may be right it may be wrong but I have
no other alternate you got you got to
pick one yeah and so I don't have
anything else to go by so I don't I
don't think it's rampant replication to
me that's totally I would concur that's
an that's an unworthy successor right
what we've got today on this planet it
leads all kinds of problems so yeah
right again I don't want to say I know
the answer to these questions I just
don't have any other answers I I I
really appreciate your frankness on that
because some people would say I do know
the Eternal answer but like yours I mean
I tend to bend very much in the
direction of gez I can only imagine so
much I hope it can imagine more than me
um but like to your point you're saying
look this is the one I got this is the
one I'm hoping for th this is as much as
I can think of this is my contribution
here I'm swinging at this one and I
think that's very fair because you could
say nope there's only one eternally
right answer and I've actually
discovered it right I like this opinion
if someone else had a different opinion
I'd really like to hear it I mean I
there are there are a lot of people who
do think you know the propagation of our
genes is really the thing we care about
yeah um and I don't you know all right
fine but let's go to the next solar
system or the next you know star We're
not gonna get there okay um I I concur I
think just the replication of genes is
not the Eternal aim I I certainly I'd
have a nuanced perspective on kind of
where I stand I think it in many regards
has commonalities with yours maybe some
differences I'll email it or something
we don't have the
time give me the two tence on I mean the
the the two the two sentence version and
I'll I'll zip it along it's the original
worthy successor essay if you Google the
term like AGI worthy successor it's just
the the the one up there but I think
that the core idea um from my side is
that I think the acquisition of
knowledge is incredibly important I see
knowledge as um a branch a wing a
portion of the total State space of
possible powers that would permit a
thing to to keep uh to to to to survive
again even if that means it's it's dying
and then other things are created
doesn't mean one thing but it's keeping
keeping the flame burning I I would see
knowledge as a very important part of
that um I I would be excited to see uh
goals Beyond ours be reached and I don't
think Beyond ours means dumb replication
I would guess Jeff goals Beyond ours
might be as worthy and Grand and Noble
as your ideas are compared to your ideas
of you know that your house cat has
right your house cat's notion of the big
picture is a pretty [&nbsp;__&nbsp;] idea um I think
yours is a much better one and my
supposition is there are higher goods
for which we cannot currently conceive
and I think the best we can do to your
point and I very much agree with you
here is let's set a trajectory with what
we at least think would be the right
jump start and would be freaking
valuable and my my subtle caveat here is
um I think there's a big state space of
potential of those things that we would
want to grow and by go great yeah and I
think you'd concur with some of that
stuff so I do I concur with that but you
know again what can do today to get to
that understanding that future State
space yeah I can build machines that are
super smart machines that can explore
the world that we can't explore machines
send to Mars um machines that that can
you know do scientific experiments we
can't do um you know that's the thing we
can do today in this Century um that
seems uh seems worthy and um and we'll
have to leave it to the next Generation
figure out what St SP absolutely well
the Baton is going to keep going
hopefully like you said nature doesn't
always hand it up but hopefully we can
jump start it to go up and and in that
regard I totally concur with where
you're headed with that said I want to
make make sure we have a little bit of
time for me to learn from you uh
speaking of my acquisition of knowledge
uh
around what what your it could be
recommendations or hopes for what the
innovators and The Regulators do to get
us to a place where we have something
that could carry on on some kind of a
worthy project Beyond us into a deeper
future and also maybe hopefully make our
lives a lot better too you probably are
looking out at some of the policy
perspectives you know luckily you're not
on Twitter Jeff it's a very good choice
it's a very messy it's a very messy tur
conversation out there but you know you
look out at academic papers you look at
you know the EU passing laws and other
things there's probably some things you
like and don't like could be innovators
could be Regulators what what do you
hope leaders of the world sort of Bear
in mind as policies being Ste and
Innovation dollars are being funneled
towards different kinds of innovation
what do you hope for in that mix that
you think would bring us closer to a
better future for humans and postum life
yeah right right remember almost
everything that's being done today in
this area is based on today's AI
technology yeah yeah yeah and so and so
um I'm a potential consumer of that
technology I'm a potential someone who's
impacted by it I don't think as I've
said many times that that's the path of
you know AGR
so anytime people start saying worrying
about oh the you know intelligence
explosion or the you know runaway or
misaligned I just them believe that's
actually GNA happen with today's
technology so to me it's much more
pedantic or every day things like I
don't want my data stolen I you know I
don't like I hate you know we should be
doing absolutely everything to prevent
you know fake stuff being produced
because it's kind of wreck havoc um so I
think in some sense I think Regulators
are slow but they're they're in on to
the right things um privacy and
authenticity uh but I don't think the
they that that that they're working on
the the problem that you talked about is
like how do I what can we do from a
policy point of view to ensure the
really future of intelligent machines
yeah um you know I just think you know
honestly I'll be quite honest our the
way I view the world the kind of
research we're doing the Thousand brains
project these are all a very small
subset of what most people think about
AI I happen to think it's the center of
it it will the center of it it will be
the actual germ that turns into true AGI
stuff and but that's a very minority
opinion there are other people believe
that too but it's minority opinion so I
you know I'm I'm not too worried about
you know I'm more worried about a human
as a human and as a person about the
abuses of today's AI but less about that
ai's problems related to the future of
um intelligent machines and and you know
the successor to humanity yeah I don't
think that stuff's gonna get there I
mean I know Sam Al disagree with me well
and I think to be frank I think there's
probably many people within open AI who
look very frankly at what's going on and
say hey there's going to need to be more
fundamental breakthroughs here um and
and so I I would suspect even Within
These big llm camps people are assuming
open AI until the end of time is just
going to do what they're doing now my
guess is that might not be the case my
guess is they may be spending more than
you know the GDP of some smaller
countries on you know the whatever the
next Paradigm is so it sounds like one
firm supposition of course you have and
this is one I would have known is hey I
hope significant research dollars go to
llm Alternative Pathways to intelligence
and of course having a dog in the fight
you would say hey maybe we should look
more at something that's brain inspired
or or or brain cor correlative um if I'm
picking up what you're putting down so
that's that's clear it's true although
you know I've long ago I I came to the
conclusion that the approach I was
advocating this goes back in the 1980s
um was not viewed uh positively by a lot
of AI researchers like I was told like
brains don't matter you know why are you
studying Brains it's useless it's not
going to help us understand intelligence
systems I've been told that so many
times um trust me really well smart
people have that position and and so I
always felt like and this is this is
true in my other work too in Mobile
Computing I always felt like you know
what I'm I don't want to convince other
people I'm I'm tired of convin other
people I don't want to try to do that
I'd rather just do it yeah I just make
it happen and um and and don't be
sitting around you know begging people
to do things for me just if if I'm right
I should be able to do it myself I
should be able to make this happen I
should you know and that's what we're
doing you know the Thousand brains
project is we're not waiting around for
anybody we're doing it um and we're
building this stuff we're building a
coalition of researchers around the
world we're gonna do it and I don't need
outside funding for of this it'd be nice
we are getting outside funding but but
didn't ask for it it wasn't like oh we
need it it's like people said hey that's
cool what you're doing here's some money
yeah yeah um uh you know it's it's just
that's the nature true of me I'm not a
I'm not a very competitive person in in
the sense of like you know I want to
argue with people I don't want to get in
discussions with philosophers I would
lose that they their language is just
crazy complicated for me um and so you
know I have a vision of the future I
want to make it happen if if I'm right
time is on my side um I don't need to
it's it's if my if my vision is right
it's not going to be wrong because
someone else thought it was wrong it's
either right or is wrong and if I'm
right it'll happen and all I can do is
try to make it happen sooner absolutely
I don't need to get in argument with
people well I'm not I'm not I'm not
asking you to do so either I'm simply
saying hey you know what are your hopes
for the innovator ecosystem what are
your hopes for the regulator ecosystem
it sounds like I'm yeah again yeah go
ahead yeah yeah there two separate
things regulation of today's AI good
idea there some real problems here oh
really so this is this is a good point
so the the funding and the research for
kind of the brain correlative stuff and
llm Alterna is very clear from you in
terms of what you hope innovators do uh
and maybe that's both Hardware software
all that stuff but yeah on the
regulatory side I'm curious you know uh
I know you're not a big AGI risk person
um but I but you did just mention there
that maybe there's some reason to
regulate what's going on now what what
are your hopes assuming we want to get
to that successor what do you hope for
for
regulation uh only on I'm only
interested in regulating today's large
language models today stuff because it's
it's dangerous and I also think um uh I
think it's it's dangerous and it's also
violating people's property rights and
uh there is some of that for sure right
I I think for sure you know I think we
haven't seen the the full downside of
this yet but I think it's coming the
whole idea of fake images and fake
personalities and fake videos
um is very damaging and mean and that is
something that should be regulated or at
least I say regulated it should be very
clear you know we could have laws that
say like look if you generate a fake
image and you don't label it as a fake
image you know that's a crime um that
shouldn't be you know acceptable if you
put out a video of K Harris saying
something that she never said and you
don't say this is a fake one yeah yeah
you know I mean it's like that's should
be up there with li there's some there's
some of that stuff coming I mean in all
fairness is it Poss possible that non
llm systems could also generate
personalities that aren't humans I mean
like explicit to LM but that's what
we've got today so it's not that it's l
it's like whatever people producing
things today just like you can't they
are anti-al laws totally
totally it's a s of an extension of that
um so for you there privacy liable those
things those
practical lawbreaking things with
today's Tech you would say hey we should
focus on them but you don't but you
don't want to see a focus on hey there
should be Global coordination on some
level around artificial general
intelligence I just don't see the risk
there today uh I'm I'm as you said I'm
not a believer that the current
technology is going to blossom into
Super intelligence I don't believe that
any of the risks that people written
about of these existential risks yeah um
I think all of them could if you really
understand what intelligence systems are
and how they work you just you see
that's not going to happen um those
people who ose those things basically do
so because they don't really understand
what intelligence is they don't
understand what Consciousness is they
they're working in a a vacuum that's
like hey this stuff could happen and
humans are like this maybe it's gonna
happen where I'm thinking like I'm gonna
build them A system that works I have a
system I know I know how that system's
gonna work it's not like kind have
emerging properties that like whoa all
of a sudden the physics is different you
know it's like doesn't happen like that
well I I I I
think it does it does seem it does seem
uh it does seem uh
I have a reasonable amount of respect
for Benjo and of the people that maybe
understand intelligence maybe his his
his Neuroscience is weak but I think his
computer science is probably pretty
beefy and and I would say not that I
necessarily agree with all of his underg
guring theories as well but I wouldn't
necessarily presume uh all things
smarter than us hey if we just know how
it works necessarily we'll have a happy
go friendly place in an ecosystem with
it no I'm I'm not roting against I
didn't say that I'm just saying I
knowing how it works tells me that the
current technology is much less of a
threat than people think it is but but
we're going to bloom the post we're
going to bloom the big postum stuff
maybe even from your lab right
hypothetically right right but we're too
early to regulate that you so so your
thought is but do you think there is a
threshold after which you would say you
know what we got robots that are like
more human than human like I think like
is there a day maybe maybe okay maybe I
just you know until we have more data I
think Benjo said this too until we have
you know until you have data it's it's
like true he has said that he has said
that right you just have to we're not
there yet on the like the work we're
doing we're not there yet not you know I
wouldn't know what to regulate I don't
even what the problems are I'm with you
it's it's a valid point valid yep yeah
yep so well we'll deal with that problem
when it when it comes I guess yeah and
as as a non-competitive guy I think
there is something humorous here about
like all right well those guys in that
race regulate them but hey my stuff
don't but I but I get what you mean I'm
not I'm not actually picking on you
you're bringing technology actually
they're being deployed in the world now
in large scale totally and ways that are
yep no I would I would totally agree has
nothing to do with the technology itself
it just has to do with the impact
Society totally that it's real the work
we're doing right now hasn't impact the
society yet y so we get to that point
it's a good time to ask hopefully you
will get there sir I'm certainly rooting
for you Jeff and I I know we had a heck
of a lot of questions to go through
fortunately we got to dig through almost
everything so I very much appreciate
your time thanks so much for being here
well Dan it's a pleasure I enjoyed
speaking to you and uh he a fun topic to
talk about and uh what a pleasure that
with you so that's all for this episode
of the trajectory this is our fifth
episode in the worthy successor series a
big thank you to Jeff for being able to
join us again sorry the video didn't
work out but hopefully his ideas made it
more than worth your stay I appreciate
that you're here all the way to the end
as with all the other episodes in the
show notes is a link to the worthy
successor criteria of Jeff Hawkins as as
well as the governance recommendations
for Jeff to make sure that whatever AI
we create turns into a worthy successor
um I really like Jeff's ideas around
kind of the inevitable postum transition
given a long enough time Horizon
obviously he still has plenty of respect
for Humanity but he's just thinking in a
long enough term I think that his
rationale for that is absolutely well
reasoned I disagreed somewhat playfully
with his notion of knowledge being sort
of the grand purpose of artificial
general intelligence the acquisition the
collection of knowledge in my opinion
knowledge is sort of a a subset of
something that allows an entity to be
more powerful and act more powerfully in
the world but there are many other kinds
of capabilities outside of knowledge and
there are probably mental conscious or
otherwise unknown capabilities Beyond
knowledge that we don't currently know
um so I wouldn't concur entirely with
that particular idea but I'd love to
know your thoughts make sure to comment
Down Below in YouTube give me a sensus
of what you liked about Jeff's ideas
agreed disagreed we've had some very
interesting comments on Richard Sutton's
episode when it came out and Nick
bostrom's episode when it came out would
love to see what you guys think about
Jeff's episode as well our last guest uh
will be the only one in this series with
a German accent and if you're familiar
with AGI thinkers uh over the last
decade there should be one that comes to
mind but you're going to have to stick
around and see who that is without
further Ado we'll we'll wrap up from
here okay cat you in the next uh episode
and our final episode of the worthy
successor series here on the trajectory
