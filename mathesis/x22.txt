

7
14
−1
2

 .
Problem 8.3. Consider the matrix
A =

2 4 1
3 5 1
1 c 0

 .
When applying Gaussian elimination, which value of c yields zero in the second pivot posi￾tion? Which value of c yields zero in the third pivot position? In this case, what can you
say about the matrix A?
8.17. PROBLEMS 315
Problem 8.4. Solve the system


2 1 1 0
4 3 3 1
8 7 9 5
6 7 9 8




x
x
1
2
x
x
3
4

 =


1
−1
−1
1


using the LU-factorization of Example 8.1.
Problem 8.5. Apply rref to the matrix
A2 =


1 2 1 1
−
2 3 2 3
1 0 1 −1
−2 −1 3 0

 .
Problem 8.6. Apply rref to the matrix


1 4 9 16
4 9 16 25
16 25 36 49
9 16 25 36

 .
Problem 8.7. (1) Prove that the dimension of the subspace of 2 × 2 matrices A, such that
the sum of the entries of every row is the same (say c1) and the sum of entries of every
column is the same (say c2) is 2.
(2) Prove that the dimension of the subspace of 2 × 2 matrices A, such that the sum of
the entries of every row is the same (say c1), the sum of entries of every column is the same
(say c2), and c1 = c2 is also 2. Prove that every such matrix is of the form

a b
b a ,
and give a basis for this subspace.
(3) Prove that the dimension of the subspace of 3 × 3 matrices A, such that the sum of
the entries of every row is the same (say c1), the sum of entries of every column is the same
(say c2), and c1 = c2 is 5. Begin by showing that the above constraints are given by the set
of equations


0 0 0 1 1 1
1 1 1 −1 −1 −1 0 0 0
−1 −1 −1
1 −1 0 1 −1 0 1 −1 0
0 1
0 1 1
−1 0 1
−1 0 0
−1 0 1
−1 0 0
−1




a11
a12
a
a
13
21
a22
a
a
23
31
a
a
32
33


=


0
0
0
0
0


.
316 CHAPTER 8. GAUSSIAN ELIMINATION, LU, CHOLESKY, ECHELON FORM
Prove that every matrix satisfying the above constraints is of the form


a + b − c −a + c + e −b + c + d
−a − b + c + d + e a b
c d e

 ,
with a, b, c, d, e ∈ R. Find a basis for this subspace. (Use the method to find a basis for the
kernel of a matrix).
Problem 8.8. If A is an n × n matrix and B is any n × n invertible matrix, prove that A
is symmetric positive definite iff B> AB is symmetric positive definite.
Problem 8.9. (1) Consider the matrix
A4 =


2 −1 0 0
−
0
1 2
−1 2
−1 0
−1
0 0 −1 2

 .
Find three matrices of the form E2,1;β1
, E3,2;β2
, E4,3;β3
, such that
E4,3;β3E3,2;β2E2,1;β1A4 = U4
where U4 is an upper triangular matrix. Compute
M = E4,3;β3E3,2;β2E2,1;β1
and check that
MA4 = U4 =


2 −1 0 0
0 3
0 0 4
/2 −
/
1 0
3 −1
0 0 0 5/4

 .
(2) Now consider the matrix
A5 =


−
2
0
1 2
−1 0 0 0
−1 0 0
−1 2 −1 0
0 0
0 0 0
−1 2
−1 2
−1


.
Find four matrices of the form E2,1;β1
, E3,2;β2
, E4,3;β3
, E5,4;β4
, such that
E5,4;β4E4,3;β3E3,2;β2E2,1;β1A5 = U5
where U5 is an upper triangular matrix. Compute
M = E5,4;β4E4,3;β3E3,2;β2E2,1;β1
8.17. PROBLEMS 317
and check that
MA5 = U5 =


2
0 3
0 0 4
−
/
1 0 0 0
2 −
/
1 0 0
3 −1 0
0 0 0 5
0 0 0 0 6
/4 −
/
1
5


.
(3) Write a Matlab program defining the function Ematrix(n, i, j, b) which is the n × n
matrix that adds b times row j to row i. Also write some Matlab code that produces an
n × n matrix An generalizing the matrices A4 and A5.
Use your program to figure out which five matrices Ei,j;β reduce A6 to the upper triangular
matrix
U6 =


2
0 3
−
/
1 0 0 0 0
2 −1 0 0 0
0 0 4
0 0 0 5
/3 −
/
1 0 0
4 −1 0
0 0 0 0 6
0 0 0 0 0 7
/5 −
/
1
6


.
Also use your program to figure out which six matrices Ei,j;β reduce A7 to the upper trian￾gular matrix
U7 =


2
0 3
−
/
1 0 0 0 0 0
2 −1 0 0 0 0
0 0 4/3 −1 0 0 0
0 0 0 5/4 −1 0 0
0 0 0 0 6
0 0 0 0 0 7
0 0 0 0 0 0 8
/5 −
/
1 0
6 −
/
1
7


.
(4) Find the lower triangular matrices L6 and L7 such that
L6U6 = A6
and
L7U7 = A7.
(5) It is natural to conjecture that there are n − 1 matrices of the form Ei,j;β that reduce
An to the upper triangular matrix
Un =


2
0 3
−
/
1 0 0 0 0 0
2 −1 0 0 0 0
0 0 4/3 −1 0 0 0
0 0 0 5/4 −1 0 0
0 0 0 0 6/5
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. −1
0 0 0 0 · · · 0 (n + 1)/n


,
318 CHAPTER 8. GAUSSIAN ELIMINATION, LU, CHOLESKY, ECHELON FORM
namely,
E2,1;1/2, E3,2;2/3, E4,3;3/4, · · · , En,n−1;(n−1)/n.
It is also natural to conjecture that the lower triangular matrix Ln such that
LnUn = An
is given by
Ln = E2,1;−1/2E3,2;−2/3E4,3;−3/4 · · · En,n−1;−(n−1)/n,
that is,
Ln =


1 0 0 0 0 0 0
−1/2 1 0 0 0 0 0
0 −2/3 1 0 0 0 0
0 0 −3/4 1 0 0 0
0 0 0 −4/5 1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. 0
0 0 0 0 · · · −(n − 1)/n 1


.
Prove the above conjectures.
(6) Prove that the last column of A−
n
1
is


1
2
/
/
(
(
n
n
+ 1)
+ 1)
n/(n
.
.
.
+ 1)


.
Problem 8.10. (1) Let A be any invertible 2 × 2 matrix
A =

a b
c d .
Prove that there is an invertible matrix S such that
SA =

1 0
0 ad − bc ,
where S is the product of at most four elementary matrices of the form Ei,j;β.
Conclude that every matrix A in SL(2) (the group of invertible 2 × 2 matrices A with
det(A) = +1) is the product of at most four elementary matrices of the form Ei,j;β.
For any a 6 = 0, 1, give an explicit factorization as above for
A =

a
0 a
0
−1

.
8.17. PROBLEMS 319
What is this decomposition for a = −1?
(2) Recall that a rotation matrix R (a member of the group SO(2)) is a matrix of the
form
R =

cos
sin θ
θ −
cos
sin
θ
θ

.
Prove that if θ 6 = kπ (with k ∈ Z), any rotation matrix can be written as a product
R = ULU,
where U is upper triangular and L is lower triangular of the form
U =

1
0 1
u

, L =

v
1 0
1

.
Therefore, every plane rotation (except a flip about the origin when θ = π) can be written
as the composition of three shear transformations!
Problem 8.11. (1) Recall that Ei,d is the diagonal matrix
Ei,d = diag(1, . . . , 1, d, 1, . . . , 1),
whose diagonal entries are all +1, except the (i, i)th entry which is equal to d.
Given any n × n matrix A, for any pair (i, j) of distinct row indices (1 ≤ i, j ≤ n), prove
that there exist two elementary matrices E1(i, j) and E2(i, j) of the form Ek,`;β, such that
Ej,−1E1(i, j)E2(i, j)E1(i, j)A = P(i, j)A,
the matrix obtained from the matrix A by permuting row i and row j. Equivalently, we have
E1(i, j)E2(i, j)E1(i, j)A = Ej,−1P(i, j)A,
the matrix obtained from A by permuting row i and row j and multiplying row j by −1.
Prove that for every i = 2, . . . , n, there exist four elementary matrices E3(i, d), E4(i, d),
E5(i, d), E6(i, d) of the form Ek,`;β, such that
E6(i, d)E5(i, d)E4(i, d)E3(i, d)En,d = Ei,d.
What happens when d = −1, that is, what kind of simplifications occur?
Prove that all permutation matrices can be written as products of elementary operations
of the form Ek,`;β and the operation En,−1.
(2) Prove that for every invertible n × n matrix A, there is a matrix S such that
SA =

In−1 0
0 d

= En,d,
320 CHAPTER 8. GAUSSIAN ELIMINATION, LU, CHOLESKY, ECHELON FORM
with d = det(A), and where S is a product of elementary matrices of the form Ek,`;β.
In particular, every matrix in SL(n) (the group of invertible n × n matrices A with
det(A) = +1) can be written as a product of elementary matrices of the form Ek,`;β. Prove
that at most n(n + 1) − 2 such transformations are needed.
(3) Prove that every matrix in SL(n) can be written as a product of at most (n −
1)(max{n, 3} + 1) elementary matrices of the form Ek,`;β.
Problem 8.12. A matrix A is called strictly column diagonally dominant iff
|aj j | >
nX
i=1, i6=j
|ai j |, for j = 1, . . . , n.
Prove that if A is strictly column diagonally dominant, then Gaussian elimination with
partial pivoting does not require pivoting, and A is invertible.
Problem 8.13. (1) Find a lower triangular matrix E such that
E


1 0 0 0
1 1 0 0
1 2 1 0
1 3 3 1

 =


1 0 0 0
0 1 0 0
0 1 1 0
0 1 2 1

 .
(2) What is the effect of the product (on the left) with
E4,3;−1E3,2;−1E4,3;−1E2,1;−1E3,2;−1E4,3;−1
on the matrix
P a3 =


1 0 0 0
1 1 0 0
1 2 1 0
1 3 3 1

 .
(3) Find the inverse of the matrix P a3.
(4) Consider the (n + 1) × (n + 1) Pascal matrix P an whose ith row is given by the
binomial coefficients

j
i −
−
1
1

,
with 1 ≤ i ≤ n + 1, 1 ≤ j ≤ n + 1, and with the usual convention that

0
0

= 1,

j
i

= 0 if j > i.
8.17. PROBLEMS 321
The matrix P a3 is shown in Part (3) and P a4 is shown below:
P a4 =


1 0 0 0 0
1 1 0 0 0
1 2 1 0 0
1 3 3 1 0
1 4 6 4 1


.
Find n elementary matrices Eik,jk;βk
such that
Ein,jn;βn
· · · Ei1,j1;β1P an =

1 0
0 P an−1

.
Use the above to prove that the inverse of P an is the lower triangular matrix whose ith
row is given by the signed binomial coefficients
(−1)i+j−2

j
i −
−
1
1

= (−1)i+j

j
i −
−
1
1

,
with 1 ≤ i ≤ n + 1, 1 ≤ j ≤ n + 1. For example,
P a−
4
1 =


−
1 0 0 0 0
1
1 1 0 0 0
−2 1 0 0
−
1
1 3
−4 6
−3 1 0
−4 1


.
Hint. Given any n × n matrix A, multiplying A by the elementary matrix Ei,j;β on the right
yields the matrix AEi,j;β in which β times the ith column is added to the jth column.
Problem 8.14. (1) Implement the method for converting a rectangular matrix to reduced
row echelon form in Matlab.
(2) Use the above method to find the inverse of an invertible n×n matrix A by applying
it to the the n × 2n matrix [A I] obtained by adding the n columns of the identity matrix to
A.
(3) Consider the matrix
A =


1 2 3 4
2 3 4 5
3 4 5 6
· · ·
· · · n + 1
n
n n
.
.
.
+ 1
.
.
.
n + 2
.
.
.
n + 3
.
.
.
· · ·
· · ·
.
.
.
2
n
n
+ 2
.
.
.
− 1


.
Using your program, find the row reduced echelon form of A for n = 4, . . . , 20.
322 CHAPTER 8. GAUSSIAN ELIMINATION, LU, CHOLESKY, ECHELON FORM
Also run the Matlab rref function and compare results.
Your program probably disagrees with rref even for small values of n. The problem is
that some pivots are very small and the normalization step (to make the pivot 1) causes
roundoff errors. Use a tolerance parameter to fix this problem.
What can you conjecture about the rank of A?
(4) Prove that the matrix A has the following row reduced form:
R =


1 0
0 0 0 0
0 1 2 3
−1 −2 · · · −
· · · n
(n
−
−
1
2)
0 0 0 0
.
.
.
.
.
.
.
.
.
.
.
.
· · ·
· · ·
.
.
.
0
0
.
.
.


.
Deduce from the above that A has rank 2.
Hint. Some well chosen sequence of row operations.
(5) Use your program to show that if you add any number greater than or equal to
(2/25)n
2
to every diagonal entry of A you get an invertible matrix! In fact, running the
Matlab function chol should tell you that these matrices are SPD (symmetric, positive
definite).
Problem 8.15. Let A be an n × n complex Hermitian positive definite matrix. Prove that
the lower-triangular matrix B with positive diagonal entries such that A = BB∗
is given by
the following formulae: For j = 1, . . . , n,
bj j =
 aj j −
X
k
j−
=1
1
|bj k|
2
!
1/2
,
and for i = j + 1, . . . , n (and j = 1, . . . , n − 1)
bi j =
 ai j −
X
k
j−
=1
1
bi kbj k! /bj j .
Problem 8.16. (Permutations and permutation matrices) A permutation can be viewed as
an operation permuting the rows of a matrix. For example, the permutation

1 2 3 4
3 4 2 1
corresponds to the matrix
Pπ =


0 0 0 1
0 0 1 0
1 0 0 0
0 1 0 0

 .
8.17. PROBLEMS 323
Observe that the matrix Pπ has a single 1 on every row and every column, all other
entries being zero, and that if we multiply any 4 × 4 matrix A by Pπ on the left, then the
rows of A are permuted according to the permutation π; that is, the π(i)th row of PπA is
the ith row of A. For example,
PπA =


0 0 0 1
0 0 1 0
1 0 0 0
0 1 0 0




a11 a12 a13 a14
a21 a22 a23 a24
a31 a32 a33 a34
a41 a42 a43 a44

 =


a41 a42 a43 a44
a31 a32 a33 a34
a11 a12 a13 a14
a21 a22 a23 a24

 .
Equivalently, the ith row of PπA is the π
−1
(i)th row of A. In order for the matrix Pπ to
move the ith row of A to the π(i)th row, the π(i)th row of Pπ must have a 1 in column i and
zeros everywhere else; this means that the ith column of Pπ contains the basis vector eπ(i)
,
the vector that has a 1 in position π(i) and zeros everywhere else.
This is the general situation and it leads to the following definition.
Definition 8.10. Given any permutation π : [n] → [n], the permutation matrix Pπ = (pij )
representing π is the matrix given by
pij =
(
1 if
0 if
i
i
=
6
=
π
π
(
(
j
j
)
);
equivalently, the jth column of Pπ is the basis vector eπ(j)
. A permutation matrix P is any
matrix of the form Pπ (where P is an n × n matrix, and π : [n] → [n] is a permutation, for
some n ≥ 1).
Remark: There is a confusing point about the notation for permutation matrices. A per￾mutation matrix P acts on a matrix A by multiplication on the left by permuting the rows
of A. As we said before, this means that the π(i)th row of PπA is the ith row of A, or
equivalently that the ith row of PπA is the π
−1
(i)th row of A. But then observe that the row
index of the entries of the ith row of P A is π
−1
(i), and not π(i)! See the following example:


0 0 0 1
0 0 1 0
1 0 0 0
0 1 0 0




a11 a12 a13 a14
a21 a22 a23 a24
a31 a32 a33 a34
a41 a42 a43 a44

 =


a41 a42 a43 a44
a31 a32 a33 a34
a11 a12 a13 a14
a21 a22 a23 a24

 ,
where
π
−1
(1) = 4
π
−1
(2) = 3
π
−1
(3) = 1
π
−1
(4) = 2.
Prove the following results
324 CHAPTER 8. GAUSSIAN ELIMINATION, LU, CHOLESKY, ECHELON FORM
(1) Given any two permutations π1, π2 : [n] → [n], the permutation matrix Pπ2◦π1
repre￾senting the composition of π1 and π2 is equal to the product Pπ2Pπ1 of the permutation
matrices Pπ1 and Pπ2
representing π1 and π2; that is,
Pπ2◦π1 = Pπ2Pπ1
.
(2) The matrix Pπ
−1
1
representing the inverse of the permutation π1 is the inverse Pπ
−
1
1 of
the matrix Pπ1
representing the permutation π1; that is,
Pπ
−1
1
= Pπ
−1
1
.
Furthermore,
Pπ
−1
1 = (Pπ1
)
> .
(3) Prove that if P is the matrix associated with a transposition, then det(P) = −1.
(4) Prove that if P is a permutation matrix, then det(P) = ±1.
(5) Use permutation matrices to give another proof of the fact that the parity of the
number of transpositions used to express a permutation π depends only on π.
Chapter 9
Vector Norms and Matrix Norms
9.1 Normed Vector Spaces
In order to define how close two vectors or two matrices are, and in order to define the
convergence of sequences of vectors or matrices, we can use the notion of a norm. Recall
that R+ = {x ∈ R | x ≥ 0}. Also recall that if z = a + ib ∈ C is a complex number, with
a, b ∈ R, then z = a − ib and |z| =
√
zz =
√
a
2 + b
2
(|z| is the modulus of z).
Definition 9.1. Let E be a vector space over a field K, where K is either the field R of
reals, or the field C of complex numbers. A norm on E is a function k k : E → R+, assigning
a nonnegative real number k uk to any vector u ∈ E, and satisfying the following conditions
for all x, y ∈ E and λ ∈ K:
(N1) k xk ≥ 0, and k xk = 0 iff x = 0. (positivity)
(N2) k λxk = |λ| kxk . (homogeneity (or scaling))
(N3) k x + yk ≤ kxk + k yk . (triangle inequality)
A vector space E together with a norm k k is called a normed vector space.
By (N2), setting λ = −1, we obtain
k−xk = k (−1)xk = | − 1| kxk = k xk ;
that is, k−xk = k xk . From (N3), we have
k
xk = k x − y + yk ≤ kx − yk + k yk ,
which implies that
k
xk − kyk ≤ kx − yk .
By exchanging x and y and using the fact that by (N2),
k
y − xk = k−(x − y)k = k x − yk ,
325
326 CHAPTER 9. VECTOR NORMS AND MATRIX NORMS
we also have
k
yk − kxk ≤ kx − yk .
Therefore,
|kxk − kyk| ≤ kx − yk , for all x, y ∈ E. (∗)
Observe that setting λ = 0 in (N2), we deduce that k 0k = 0 without assuming (N1).
Then by setting y = 0 in (∗), we obtain
|kxk| ≤ kxk , for all x ∈ E.
Therefore, the condition k xk ≥ 0 in (N1) follows from (N2) and (N3), and (N1) can be
replaced by the weaker condition
(N1’) For all x ∈ E, if k xk = 0, then x = 0,
A function k k : E → R satisfying Axioms (N2) and (N3) is called a seminorm. From the
above discussion, a seminorm also has the properties
k
xk ≥ 0 for all x ∈ E, and k 0k = 0.
However, there may be nonzero vectors x ∈ E such that k xk = 0.
Let us give some examples of normed vector spaces.
Example 9.1.
1. Let E = R, and k xk = |x|, the absolute value of x.
2. Let E = C, and k zk = |z|, the modulus of z.
3. Let E = R
n
(or E = C
n
). There are three standard norms. For every (x1, . . . , xn) ∈ E,
we have the norm k xk 1, defined such that,
k
xk 1 = |x1| + · · · + |xn|,
we have the Euclidean norm k xk 2, defined such that,
k
xk 2 =
￾ |x1|
2 + · · · + |xn|
2

1
2
,
and the sup-norm k xk ∞, defined such that,
k
xk ∞ = max{|xi
| | 1 ≤ i ≤ n}.
More generally, we define the ` p
-norm (for p ≥ 1) by
k
xk p = (|x1|
p + · · · + |xn|
p
)
1/p
.
See Figures 9.1 through 9.4.
9.1. NORMED VECTOR SPACES 327
K1 K0.5 0 0.5 1
K1
K0.5
0.5
1
Figure 9.1: The top figure is {x ∈ R
2
| kxk 1 ≤ 1}, while the bottom figure is {x ∈ R
3
|
k
xk 1 ≤ 1}.
There are other norms besides the ` p
-norms. Here are some examples.
1. For E = R
2
,
k
(u1, u2)k = |u1| + 2|u2|.
See Figure 9.5.
2. For E = R
2
,
k
(u1, u2)k =
￾ (u1 + u2)
2 + u
2
1
