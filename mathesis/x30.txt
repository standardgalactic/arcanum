2
.
.
.
j − 1
j
j + 1
j + 2
.
.
.
n


1 0 . . . 0 0 0 . . . 0
0 1 . . . 0 0 0 . . . 0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
0 0 . . . 1 0 0 . . . 0
0 0 . . . 0 −cj+1/cj −cj+2/cj
. . . −cn/cj
0 0 . . . 0 1 0 . . . 0
0 0 . . . 0 0 1 . . . 0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
0 0 . . . 0 0 0 . . . 1


.
Observe that the (n−1)×(n−1) matrix obtained by deleting row j is the identity matrix, so
the columns of the above matrix are linearly independent. A simple calculation also shows
that the linear form u
∗
(x1, . . . , xn) = cjxj +· · ·+cnxn vanishes on every column of the above
418 CHAPTER 11. THE DUAL SPACE AND DUALITY
matrix. For a concrete example in R
6
, if u
∗
(x1, . . . , x6) = x3 + 2x4 + 3x5 + 4x6, we obtain
the basis for the hyperplane H of equation
x3 + 2x4 + 3x5 + 4x6 = 0
given by the following matrix:


1 0 0 0 0
0 1 0 0 0
0 0 −2 −3 −4
0 0 1 0 0
0 0 0 1 0
0 0 0 0 1


.
Problem 3 . Conversely, given a hyperplane H in R
n given as the span of n − 1 linearly
vectors (u1, . . . , un−1), it is possible using determinants to find a linear form (λ1, . . . , λn) that
vanishes on H.
In the case n = 3, we are looking for a row vector (λ1, λ2, λ3) such that if
u =


u
u
u
1
2
3

 and v =


v
v
v
1
2
3


are two linearly independent vectors, then

u1 u2 u2
v1 v2 v2



λ
λ
λ
1
2
3

 =

0
0

,
and the cross-product u × v of u and v given by
u × v =


u2v3 − u3v2
u3v1 − u1v3
u1v2 − u2v1


is a solution. In other words, the equation of the plane spanned by u and v is
(u2v3 − u3v2)x + (u3v1 − u1v3)y + (u1v2 − u2v1)z = 0.
Problem 4 . Here is another example illustrating the power of Theorem 11.4. Let
E = Mn(R), and consider the equations asserting that the sum of the entries in every row
of a matrix A ∈ Mn(R) is equal to the same number. We have n − 1 equations
nX
j=1
(aij − ai+1j ) = 0, 1 ≤ i ≤ n − 1,
11.4. THE BIDUAL AND CANONICAL PAIRINGS 419
and it is easy to see that they are linearly independent. Therefore, the space U of linear
forms in E
∗
spanned by the above linear forms (equations) has dimension n − 1, and the
space U
0 of matrices satisfying all these equations has dimension n
2 − n + 1. It is not so
obvious to find a basis for this space.
We will now pin down the relationship between a vector space E and its bidual E
∗∗
.
11.4 The Bidual and Canonical Pairings
Proposition 11.5. Let E be a vector space. The following properties hold:
(a) The linear map evalE : E → E
∗∗ defined such that
evalE(v) = evalv for all v ∈ E,
that is, evalE(v)(u
∗
) = h u
∗
, vi = u
∗
(v) for every u
∗ ∈ E
∗
, is injective.
(b) When E is of finite dimension n, the linear map evalE : E → E
∗∗ is an isomorphism
(called the canonical isomorphism).
Proof. (a) Let (ui)i∈I be a basis of E, and let v =
P i∈I
viui
. If evalE(v) = 0, then in
particular evalE(v)(u
∗
i
) = 0 for all u
∗
i
, and since
evalE(v)(u
∗
i
) = h u
∗
i
, vi = vi
,
we have vi = 0 for all i ∈ I, that is, v = 0, showing that evalE : E → E
∗∗ is injective.
If E is of finite dimension n, by Theorem 11.4, for every basis (u1, . . . , un), the family
(u
∗
1
, . . . , u∗
n
) is a basis of the dual space E
∗
, and thus the family (u
∗∗
1
, . . . , u∗∗
n
) is a basis of the
bidual E
∗∗. This shows that dim(E) = dim(E
∗∗) = n, and since by Part (a), we know that
evalE : E → E
∗∗ is injective, in fact, evalE : E → E
∗∗ is bijective (by Proposition 6.19).

When a vector space E has infinite dimension, E and its bidual E
∗∗ are never isomorphic.
When E is of finite dimension and (u1, . . . , un) is a basis of E, in view of the canon￾ical isomorphism evalE : E → E
∗∗, the basis (u
∗∗
1
, . . . , u∗∗
n
) of the bidual is identified with
(u1, . . . , un).
Proposition 11.5 can be reformulated very fruitfully in terms of pairings, a remarkably
useful concept discovered by Pontrjagin in 1931 (adapted from E. Artin [6], Chapter 1).
Given two vector spaces E and F over a field K, we say that a function ϕ: E × F → K
is bilinear if for every v ∈ V , the map u 7→ ϕ(u, v) (from E to K) is linear, and for every
u ∈ E, the map v 7→ ϕ(u, v) (from F to K) is linear.
Definition 11.4. Given two vector spaces E and F over K, a pairing between E and F is
a bilinear map ϕ: E × F → K. Such a pairing is nondegenerate iff
420 CHAPTER 11. THE DUAL SPACE AND DUALITY
(1) for every u ∈ E, if ϕ(u, v) = 0 for all v ∈ F, then u = 0, and
(2) for every v ∈ F, if ϕ(u, v) = 0 for all u ∈ E, then v = 0.
A pairing ϕ: E × F → K is often denoted by h−, −i: E × F → K. For example, the
map h−, −i: E
∗ × E → K defined earlier is a nondegenerate pairing (use the proof of (a)
in Proposition 11.5). If E = F and K = R, any inner product on E is a nondegenerate
pairing (because an inner product is positive definite); see Chapter 12. Other interesting
nondegenerate pairings arise in exterior algebra and differential geometry.
Given a pairing ϕ: E × F → K, we can define two maps lϕ : E → F
∗ and rϕ : F → E
∗
as follows: For every u ∈ E, we define the linear form lϕ(u) in F
∗
such that
lϕ(u)(y) = ϕ(u, y) for every y ∈ F ,
and for every v ∈ F, we define the linear form rϕ(v) in E
∗
such that
rϕ(v)(x) = ϕ(x, v) for every x ∈ E.
We have the following useful proposition.
Proposition 11.6. Given two vector spaces E and F over K, for every nondegenerate
pairing ϕ: E × F → K between E and F, the maps lϕ : E → F
∗ and rϕ : F → E
∗ are linear
and injective. Furthermore, if E and F have finite dimension, then this dimension is the
same and lϕ : E → F
∗ and rϕ : F → E
∗ are bijections.
Proof. The maps lϕ : E → F
∗ and rϕ : F → E
∗ are linear because a pairing is bilinear. If
lϕ(u) = 0 (the null form), then
lϕ(u)(v) = ϕ(u, v) = 0 for every v ∈ F ,
and since ϕ is nondegenerate, u = 0. Thus, lϕ : E → F
∗
is injective. Similarly, rϕ : F → E
∗
is injective. When F has finite dimension n, we have seen that F and F
∗ have the same
dimension. Since lϕ : E → F
∗
is injective, we have m = dim(E) ≤ dim(F) = n. The same
argument applies to E, and thus n = dim(F) ≤ dim(E) = m. But then, dim(E) = dim(F),
and lϕ : E → F
∗ and rϕ : F → E
∗ are bijections.
When E has finite dimension, the nondegenerate pairing h−, −i: E
∗ × E → K yields
another proof of the existence of a natural isomorphism between E and E
∗∗. When E = F,
the nondegenerate pairing induced by an inner product on E yields a natural isomorphism
between E and E
∗
(see Section 12.2).
We now show the relationship between hyperplanes and linear forms.
11.5. HYPERPLANES AND LINEAR FORMS 421
11.5 Hyperplanes and Linear Forms
Actually Proposition 11.7 below follows from Parts (c) and (d) of Theorem 11.4, but we feel
that it is also interesting to give a more direct proof.
Proposition 11.7. Let E be a vector space. The following properties hold:
(a) Given any nonnull linear form f
∗ ∈ E
∗
, its kernel H = Ker f
∗
is a hyperplane.
(b) For any hyperplane H in E, there is a (nonnull) linear form f
∗ ∈ E
∗
such that H =
Ker f
∗
.
(c) Given any hyperplane H in E and any (nonnull) linear form f
∗ ∈ E
∗
such that H =
Ker f
∗
, for every linear form g
∗ ∈ E
∗
, H = Ker g
∗
iff g
∗ = λf ∗
for some λ 6 = 0 in K.
Proof. (a) If f
∗ ∈ E
∗
is nonnull, there is some vector v0 ∈ E such that f
∗
(v0) 6 = 0. Let
H = Ker f
∗
. For every v ∈ E, we have
f
∗

v −
f
∗
(v)
f
∗
(v0)
v0
 = f
∗
(v) −
f
∗
(v)
f
∗
(v0)
f
∗
(v0) = f
∗
(v) − f
∗
(v) = 0.
Thus,
v −
f
∗
(v)
f
∗
(v0)
v0 = h ∈ H,
and
v = h +
f
∗
(v)
f
∗
(v0)
v0,
that is, E = H + Kv0. Also since f
∗
(v0) 6 = 0, we have v0 ∈/ H, that is, H ∩ Kv0 = 0. Thus,
E = H ⊕ Kv0, and H is a hyperplane.
(b) If H is a hyperplane, E = H ⊕ Kv0 for some v0 ∈/ H. Then every v ∈ E can be
written in a unique way as v = h + λv0. Thus there is a well-defined function f
∗
: E → K,
such that, f
∗
(v) = λ, for every v = h + λv0. We leave as a simple exercise the verification
that f
∗
is a linear form. Since f
∗
(v0) = 1, the linear form f
∗
is nonnull. Also, by definition,
it is clear that λ = 0 iff v ∈ H, that is, Ker f
∗ = H.
(c) Let H be a hyperplane in E, and let f
∗ ∈ E
∗ be any (nonnull) linear form such that
H = Ker f
∗
. Clearly, if g
∗ = λf ∗
for some λ 6 = 0, then H = Ker g
∗
. Conversely, assume that
H = Ker g
∗
for some nonnull linear form g
∗
. From (a), we have E = H ⊕ Kv0, for some v0
such that f
∗
(v0) 6 = 0 and g
∗
(v0) 6 = 0. Then observe that
g
∗ −
g
∗
(v0)
f
∗
(v0)
f
∗
is a linear form that vanishes on H, since both f
∗ and g
∗ vanish on H, but also vanishes on
Kv0. Thus, g
∗ = λf ∗
, with
λ =
g
∗
(v0)
f
∗
(v0)
.
422 CHAPTER 11. THE DUAL SPACE AND DUALITY
We leave as an exercise the fact that every subspace V 6 = E of a vector space E is the
intersection of all hyperplanes that contain V . We now consider the notion of transpose of
a linear map and of a matrix.
11.6 Transpose of a Linear Map and of a Matrix
Given a linear map f : E → F, it is possible to define a map f
> : F
∗ → E
∗ which has some
interesting properties.
Definition 11.5. Given a linear map f : E → F, the transpose f
> : F
∗ → E
∗ of f is the
linear map defined such that
f
> (v
∗
) = v
∗
◦ f, for every v
∗ ∈ F
∗
,
as shown in the diagram below:
E
f
/
f> (v
∗)
❇❇❇ 
❇❇❇❇❇
F
v
∗


K.
Equivalently, the linear map f
> : F
∗ → E
∗
is defined such that
h
v
∗
, f(u)i = h f
> (v
∗
), ui , (∗)
for all u ∈ E and all v
∗ ∈ F
∗
.
It is easy to verify that the following properties hold:
(f + g)
> = f
> + g
>
(g ◦ f)
> = f
> ◦ g
>
id>E = idE∗ .

Note the reversal of composition on the right-hand side of (g ◦ f)
> = f
> ◦ g
> .
The equation (g ◦ f)
> = f
> ◦ g
> implies the following useful proposition.
Proposition 11.8. If f : E → F is any linear map, then the following properties hold:
(1) If f is injective, then f
> is surjective.
(2) If f is surjective, then f
> is injective.
11.6. TRANSPOSE OF A LINEAR MAP AND OF A MATRIX 423
Proof. If f : E → F is injective, then it has a retraction r : F → E such that r ◦ f = idE,
and if f : E → F is surjective, then it has a section s: F → E such that f ◦ s = idF . Now if
f : E → F is injective, then we have
(r ◦ f)
> = f
> ◦ r
> = idE∗ ,
which implies that f
> is surjective, and if f is surjective, then we have
(f ◦ s)
> = s
> ◦ f
> = idF∗ ,
which implies that f
> is injective.
The following proposition gives a natural interpretation of the dual (E/U)
∗ of a quotient
space E/U.
Proposition 11.9. For any subspace U of a vector space E, if p: E → E/U is the canonical
surjection onto E/U, then p
> is injective and
Im(p
> ) = U
0 = (Ker (p))0
.
Therefore, p
> is a linear isomorphism between (E/U)
∗ and U
0
.
Proof. Since p is surjective, by Proposition 11.8, the map p
> is injective. Obviously, U =
Ker (p). Observe that Im(p
> ) consists of all linear forms ψ ∈ E
∗
such that ψ = ϕ ◦ p for
some ϕ ∈ (E/U)
∗
, and since Ker (p) = U, we have U ⊆ Ker (ψ). Conversely for any linear
form ψ ∈ E
∗
, if U ⊆ Ker (ψ), then ψ factors through E/U as ψ = ψ ◦ p as shown in the
following commutative diagram
E
p
/
ψ
!
❈❈❈❈❈❈❈❈❈
E/U


ψ
K,
where ψ: E/U → K is given by
ψ(v) = ψ(v), v ∈ E,
where v ∈ E/U denotes the equivalence class of v ∈ E. The map ψ does not depend on the
representative chosen in the equivalence class v, since if v
0 = v, that is v
0 − v = u ∈ U, then
ψ(v
0 ) = ψ(v + u) = ψ(v) + ψ(u) = ψ(v) + 0 = ψ(v). Therefore, we have
Im(p
> ) = {ϕ ◦ p | ϕ ∈ (E/U)
∗
}
= {ψ: E → K | U ⊆ Ker (ψ)}
= U
0
,
which proves our result.
424 CHAPTER 11. THE DUAL SPACE AND DUALITY
Proposition 11.9 yields another proof of part (b) of the duality theorem (theorem 11.4)
that does not involve the existence of bases (in infinite dimension).
Proposition 11.10. For any vector space E and any subspace V of E, we have V
00 = V .
Proof. We begin by observing that V
0 = V
000. This is because, for any subspace U of E
∗
,
we have U ⊆ U
00, so V
0 ⊆ V
000. Furthermore, V ⊆ V
00 holds, and for any two subspaces
M, N of E, if M ⊆ N then N0 ⊆ N0
, so we get V
000 ⊆ V
0
. Write V1 = V
00, so that
V1
0 = V
000 = V
0
. We wish to prove that V1 = V .
Since V ⊆ V1 = V
00, the canonical projection p1 : E → E/V1 factors as p1 = f ◦ p as in
the diagram below,
E
p
/
p1
!
❈❈❈❈❈❈❈❈❈
E/V


f
E/V1
where p: E → E/V is the canonical projection onto E/V and f : E/V → E/V1 is the
quotient map induced by p1, with f(uE/V ) = p1(u) = uE/V1
, for all u ∈ E (since V ⊆ V1, if
u − u
0 = v ∈ V , then u − u
0 = v ∈ V1, so p1(u) = p1(u
0 )). Since p1 is surjective, so is f. We
wish to prove that f is actually an isomorphism, and for this, it is enough to show that f is
injective. By transposing all the maps, we get the commutative diagram
E
∗
(E/V )
∗
p>
o
(E/V1)
∗
,
d
❍❍❍
p
❍
>
1
❍❍❍❍❍❍
O
O
f>
but by Proposition 11.9, the maps p
> : (E/V )
∗ → V
0 and p
>1
: (E/V1)
∗ → V1
0 are iso￾morphism, and since V
0 = V1
0
, we have the following diagram where both p
> and p
>1
are
isomorphisms:
V
0
(E/V )
∗ o
p>
(E/V1)
∗
.
d
❍❍❍
p
❍
>
1
❍❍❍❍❍❍
O
O
f>
Therefore, f
> = (p
> )
−1 ◦p
>1
is an isomorphism. We claim that this implies that f is injective.
If f is not injective, then there is some x ∈ E/V such that x 6 = 0 and f(x) = 0, so
for every ϕ ∈ (E/V1)
∗
, we have f
> (ϕ)(x) = ϕ(f(x)) = 0. However, there is linear form
ψ ∈ (E/V )
∗
such that ψ(x) = 1, so ψ 6 = f
> (ϕ) for all ϕ ∈ (E/V1)
∗
, contradicting the fact
that f
> is surjective. To find such a linear form ψ, pick any supplement W of Kx in E/V , so
that E/V = Kx ⊕ W (W is a hyperplane in E/V not containing x), and define ψ to be zero
11.6. TRANSPOSE OF A LINEAR MAP AND OF A MATRIX 425
on W and 1 on x.
1 Therefore, f is injective, and since we already know that it is surjective,
it is bijective. This means that the canonical map f : E/V → E/V1 with V ⊆ V1 is an
isomorphism, which implies that V = V1 = V
00 (otherwise, if v ∈ V1 − V , then p1(v) = 0, so
f(p(v)) = p1(v) = 0, but p(v) 6 = 0 since v /∈ V , and f is not injective).
The following proposition shows the relationship between orthogonality and transposi￾tion.
Proposition 11.11. Given a linear map f : E → F, for any subspace V of E, we have
f(V )
0 = (f
> )
−1
(V
0
) = {w
∗ ∈ F
∗
| f
> (w
∗
) ∈ V
0
}.
As a consequence,
Ker f
> = (Im f)
0
.
We also have
Ker f = (Im f
> )
0
.
Proof. We have
h
w
∗
, f(v)i = h f
> (w
∗
), vi ,
for all v ∈ E and all w
∗ ∈ F
∗
, and thus, we have h w
∗
, f(v)i = 0 for every v ∈ V , i.e.
w
∗ ∈ f(V )
0
iff h f
> (w
∗
), vi = 0 for every v ∈ V iff f
> (w
∗
) ∈ V
0
, i.e. w
∗ ∈ (f
> )
−1
(V
0
),
proving that
f(V )
0 = (f
> )
−1
(V
0
).
Since we already observed that E
0 = (0), letting V = E in the above identity we obtain
that
Ker f
> = (Im f)
0
.
From the equation
h
w
∗
, f(v)i = h f
> (w
∗
), vi ,
we deduce that v ∈ (Im f
> )
0
iff h f
> (w
∗
), vi = 0 for all w
∗ ∈ F
∗
iff h w
∗
, f(v)i = 0 for all
w
∗ ∈ F
∗
. Assume that v ∈ (Im f
> )
0
. If we pick a basis (wi)i∈I of F, then we have the linear
forms wi
∗
: F → K such that wi
∗
(wj ) = δij , and since we must have h wi
∗
, f(v)i = 0 for all
i ∈ I and (wi)i∈I is a basis of F, we conclude that f(v) = 0, and thus v ∈ Ker f (this is
because h wi
∗
, f(v)i is the coefficient of f(v) associated with the basis vector wi). Conversely,
if v ∈ Ker f, then h w
∗
, f(v)i = 0 for all w
∗ ∈ F
∗
, so we conclude that v ∈ (Im f
> )
0
.
Therefore, v ∈ (Im f
> )
0
iff v ∈ Ker f; that is,
Ker f = (Im f
> )
0
,
as claimed.
1Using Zorn’s lemma, we pick W maximal among all subspaces of E/V such that Kx ∩ W = (0); then,
E/V = Kx ⊕ W.
426 CHAPTER 11. THE DUAL SPACE AND DUALITY
The following theorem shows the relationship between the rank of f and the rank of f
> .
Theorem 11.12. Given a linear map f : E → F, the following properties hold.
(a) The dual (Im f)
∗ of Im f is isomorphic to Im f
> = f
> (F
∗
); that is,
(Im f)
∗ ∼= Im f
> .
(b) If F is finite dimensional, then rk(f) = rk(f
> ).
Proof. (a) Consider the linear maps
E −→
p
Im f −→
j
F,
where E −→
p
Im f is the surjective map induced by E −→
f
F, and Im f −→
j
F is the
injective inclusion map of Im f into F. By definition, f = j ◦ p. To simplify the notation,
let I = Im f. By Proposition 11.8, since E −→
p
I is surjective, I
∗
p>
−→ E
∗
is injective, and
since Im f −→
j
F is injective, F
∗
j>
−→ I
∗
is surjective. Since f = j ◦ p, we also have
f
> = (j ◦ p)
> = p
> ◦ j
> ,
and since F
∗
j>
−→ I
∗
is surjective, and I
∗
p>
−→ E
∗
is injective, we have an isomorphism
between (Im f)
∗ and f
> (F
∗
).
(b) We already noted that Part (a) of Theorem 11.4 shows that dim(F) = dim(F
∗
),
for every vector space F of finite dimension. Consequently, dim(Im f) = dim((Im f)
∗
), and
thus, by Part (a) we have rk(f) = rk(f
> ).
Remark: When both E and F are finite-dimensional, there is also a simple proof of (b)
that doesn’t use the result of Part (a). By Theorem 11.4(c)
dim(Im f) + dim((Im f)
0
) = dim(F),
and by Theorem 6.16
dim(Ker f
> ) + dim(Im f
> ) = dim(F
∗
).
Furthermore, by Proposition 11.11, we have
Ker f
> = (Im f)
0
,
and since F is finite-dimensional dim(F) = dim(F
∗
), so we deduce
dim(Im f) + dim((Im f)
0
) = dim((Im f)
0
) + dim(Im f
> ),
which yields dim(Im f) = dim(Im f
> ); that is, rk(f) = rk(f
> ).
11.6. TRANSPOSE OF A LINEAR MAP AND OF A MATRIX 427
Proposition 11.13. If f : E → F is any linear map, then the following identities hold:
Im f
> = (Ker (f))0
Ker (f
> ) = (Im f)
0
Im f = (Ker (f
> )
0
Ker (f) = (Im f
> )
0
.
Proof. The equation Ker (f
> ) = (Im f)
0 has already been proven in Proposition 11.11.
By the duality theorem (Ker (f))00 = Ker (f), so from Im f
> = (Ker (f))0 we get
Ker (f) = (Im f
> )
0
. Similarly, (Im f)
00 = Im f, so from Ker (f
> ) = (Im f)
0 we get
Im f = (Ker (f
> )
0
. Therefore, what is left to be proven is that Im f
> = (Ker (f))0
.
