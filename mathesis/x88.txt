

λ
0 λ
1 0
1 · · ·
· · ·
0
0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
0 0 0
0 0 0 · · ·
.
.
.
λ
1


.
1302 CHAPTER 36. NORMAL FORMS; THE RATIONAL CANONICAL FORM
Proof. Since E is a cyclic K[X]-module, there is some u ∈ E so that E is generated by
u, f(u), f 2
(u), . . ., which means that every vector in E is of the form p(f)(u), for some
polynomial, p(X). We claim that u, f(u), . . . , f n−2
(u), fn−1
(u) generate E, which implies
that the dimension of E is at most n.
This is because if p(X) is any polynomial of degree at least n, then we can divide p(X)
by (X − λ)
n
, obtaining
p = (X − λ)
n
q + r,
where 0 ≤ deg(r) < n, and as (X − λ)
n annihilates E, we get
p(f)(u) = r(f)(u),
which means that every vector of the form p(f)(u) with p(X) of degree ≥ n is actually a
linear combination of u, f(u), . . . , f n−2
(u), fn−1
(u).
We claim that the vectors
u,(f − λid)(u), . . . ,(f − λid)n−2
(u)(f − λid)n−1
(u)
are linearly independent. Indeed, if we had a nontrivial linear combination
a0(f − λid)n−1
(u) + a1(f − λid)n−2
(u) + · · · + an−2(f − λid)(u) + an−1u = 0,
then the polynomial
a0(X − λ)
n−1 + a1(X − λ)
n−2 + · · · + an−2(X − λ) + an−1
of degree at most n − 1 would annihilate E, contradicting the fact that (X − λ)
n
is the
minimal polynomial of f (and thus, of smallest degree). Consequently, as the dimension of
E is at most n,
((f − λid)n−1
(u),(f − λid)n−2
(u), . . . ,(f − λid)(u), u),
is a basis of E and since u, f(u), . . . , f n−2
(u), fn−1
(u) span E,
(u, f(u), . . . , f n−2
(u), fn−1
(u))
is also a basis of E.
Let us see how f acts on the basis
((f − λid)n−1
(u),(f − λid)n−2
(u), . . . ,(f − λid)(u), u).
If we write f = f − λid + λid, as (f − λid)n annihilates E, we get
f((f − λid)n−1
(u)) = (f − λid)n
(u) + λ(f − λid)n−1
(u) = λ(f − λid)n−1
(u)
and
f((f − λid)k
(u)) = (f − λid)k+1(u) + λ(f − λid)k
(u), 0 ≤ k ≤ n − 2.
But this means precisely that the matrix of f in this basis is the Jordan block Jn(λ).
36.4. THE JORDAN FORM REVISITED 1303
The basis
((f − λid)n−1
(u),(f − λid)n−2
(u), . . . ,(f − λid)(u), u),
provided by Proposition 36.16 is known as a Jordan chain. Note that (f − λid)n−1
(u) is
an eigenvector for f. To construct the Jordan chain, we must find u which is a generalized
eigenvector of f. This is done by first finding an eigenvector x1 of f and recursively solving
the system (f − λid)xi+1 = xi
for i ≤ 1 ≤ n − 1. For example suppose f : R
3 → R
3 where
f(x, y, z) = (x + y + z, y + z, z). In terms of the standard basis, the matrix representation
for f is M =


1 1 1
0 1 1
0 0 1

. By using M, it is readily verified that the minimal polynomial
f equals the characteristic polynomial, namely (X − 1)3
. Thus f has the eigenvalue λ = 1
with repeated three times. To find the eigenvector x1 associated with λ = 1, we solve the
system (M − I)x1 = 0, or equivalently


0 1 1
0 0 1
0 0 0




x
y
z

 =


0
0
0

 .
Thus y = z = 0 with x = 1 solves this system to provide the eigenvector x1 =


1
0
0

. We
next solve the system (M − I)x2 = x1, namely


0 1 1
0 0 1
0 0 0




x
y
z

 =


1
0
0

 ,
which implies that z = 0 and y = 1. Hence x2 =


1
1
0

 will work. To finish constructing our
Jordan chain, we must solve the system (M − I)x3 = x2, namely


0 1 1
0 0 1
0 0 0




x
y
z

 =


1
1
0

 ,
from which we see that z = 1, y = 0, and x3 =


1
0
1

. By setting x3 = u, we form the basis
((f − λid)2
(u),(f − λid)1
(u), . . . ,(f − λid)(u), u) = (x1, x2, x3).
1304 CHAPTER 36. NORMAL FORMS; THE RATIONAL CANONICAL FORM
In terms of the basis (x1, x2, x3), the map f(x, y, z) = (x + y + z, y + z, z) has the Jordan
block matrix representation


1 1 0
0 1 1
0 0 1

 since
f(x1) = f(1, 0, 0) = (1, 0, 0) = x1
f(x2) = f(1, 1, 0) = (2, 1, 0) = x1 + x2
f(x3) = f(1, 0, 1) = (2, 1, 1) = x2 + x3.
Combining Theorem 36.15 and Proposition 36.16, we obtain a strong version of the
Jordan form.
Theorem 36.17. (Jordan Canonical Form) Let E be finite-dimensional K-vector space.
The following properties are equivalent:
(1) The eigenvalues of f all belong to K.
(2) There is a basis of E in which the matrix of f is upper (or lower) triangular.
(3) There exist a basis of E in which the matrix A of f is Jordan matrix. Furthermore, the
number of Jordan blocks Jr(λ) appearing in A, for fixed r and λ, is uniquely determined
by f.
Proof. The implication (1) =⇒ (3) follows from Theorem 36.15 and Proposition 36.16. The
implications (3) =⇒ (2) and (2) =⇒ (1) are trivial.
Compared to Theorem 31.17, the new ingredient is the uniqueness assertion in (3), which
is not so easy to prove.
Observe that the minimal polynomial of f is the least common multiple of the polynomials
(X − λ)
r associated with the Jordan blocks Jr(λ) appearing in A, and the characteristic
polynomial of A is the product of these polynomials.
We now return to the problem of computing effectively the similarity invariants of a
matrix M. By Proposition 36.11, this is equivalent to computing the invariant factors of
XI − M. In principle, this can be done using Proposition 35.35. A procedure to do this
effectively for the ring A = K[X] is to convert XI − M to its Smith normal form. This will
also yield the rational canonical form for M.
36.5 The Smith Normal Form
The Smith normal form is the special case of Proposition 35.35 applied to the PID K[X]
where K is a field, but it also says that the matrices P and Q are products of elementary
matrices. It turns out that such a result holds for any Euclidean ring, and the proof is
basically the same.
36.5. THE SMITH NORMAL FORM 1305
Recall from Definition 30.10 that a Euclidean ring is an integral domain A such that
there exists a function σ : A → N with the following property: For all a, b ∈ A with b 6 = 0,
there are some q, r ∈ A such that
a = bq + r and σ(r) < σ(b).
Note that the pair (q, r) is not necessarily unique.
We make use of the elementary row and column operations P(i, k), Ei,j;β, and Ei,λ de￾scribed in Chapter 8, where we require the scalar λ used in Ei,λ to be a unit.
Theorem 36.18. If M is an m × n matrix over a Euclidean ring A, then there exist some
invertible n×n matrix P and some invertible m × m matrix Q, where P and Q are products
of elementary matrices, and a m × n matrix D of the form
D =


α1 0 · · · 0 0 · · · 0
0 α2 · · · 0 0 · · · 0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. · · ·
.
.
.
0 0 · · · αr 0 · · · 0
0 0 · · · 0 0 · · · 0
.
.
.
.
.
. · · ·
.
.
.
.
.
.
.
.
.
.
.
.
0 0 · · · 0 0 · · · 0


for some nonzero αi ∈ A, such that
(1) α1 | α2 | · · · | αr, and
(2) M = QDP −1
.
Proof. We follow Jacobson’s proof [98] (Chapter 3, Theorem 3.8). We proceed by induction
on m + n.
If m = n = 1, let P = (1) and Q = (1).
For the induction step, if M = 0, let P = In and Q = Im. If M 6 = 0, the stategy is to
apply a sequence of elementary transformations that converts M to a matrix of the form
M0 =


α
0
.
1 0 · · · 0
.
. Y
0


where Y is a (m − 1) × (n − 1)-matrix such that α1 divides every entry in Y . Then, we
proceed by induction on Y . To find M0 , we perform the following steps.
Step 1 . Pick some nonzero entry aij in M such that σ(aij ) is minimal. Then permute
column j and column 1, and permute row i and row 1, to bring this entry in position (1, 1).
We denote this new matrix again by M.
1306 CHAPTER 36. NORMAL FORMS; THE RATIONAL CANONICAL FORM
Step 2a.
If m = 1 go to Step 2b.
If m > 1, then there are two possibilities:
(i) M is of the form


a11 a12 · · · a1n
0 a22 · · · a2n
.
.
.
.
.
.
.
.
.
.
.
.
0 am2 · · · amn


.
If n = 1, stop; else go to Step 2b.
(ii) There is some nonzero entry ai1 (i > 1) below a11 in the first column.
(a) If there is some entry ak1 in the first column such that a11 does not divide ak1, then
pick such an entry (say, with the smallest index i such that σ(ai1) is minimal), and divide
ak1 by a11; that is, find bk and bk1 such that
ak1 = a11bk + bk1, with σ(bk1) < σ(a11).
Subtract bk times row 1 from row k and permute row k and row 1, to obtain a matrix of the
form
M =


bk1 bk2 · · · bkn
a21 a22 · · · a2n
.
.
.
.
.
.
.
.
.
.
.
.
am1 am2 · · · amn


.
Go back to Step 2a.
(b) If a11 divides every (nonzero) entry ai1 for i ≥ 2, say ai1 = a11bi
, then subtract bi
times row 1 from row i for i = 2, . . . , m; go to Step 2b.
Observe that whenever we return to the beginning of Step 2a, we have σ(bk1) < σ(a11).
Therefore, after a finite number of steps, we must exit Step 2a with a matrix in which all
entries in column 1 but the first are zero and go to Step 2b.
Step 2b.
This step is reached only if n > 1 and if the only nonzero entry in the first column is a11.
(a) If M is of the form


a11 0 · · · 0
0 a22 · · · a2n
.
.
.
.
.
.
.
.
.
.
.
.
0 am2 · · · amn


and m = 1 stop; else go to Step 3.
36.5. THE SMITH NORMAL FORM 1307
(b) If there is some entry a1k in the first row such that a11 does not divide a1k, then pick
such an entry (say, with the smallest index j such that σ(a1j ) is minimal), and divide a1k by
a11; that is, find bk and b1k such that
a1k = a11bk + b1k, with σ(b1k) < σ(a11).
Subtract bk times column 1 from column k and permute column k and column 1, to obtain
a matrix of the form
M =


b1k ak2 · · · akn
b2k a22 · · · a2n
.
.
.
.
.
.
.
.
.
.
.
.
bmk am2 · · · amn


.
Go back to Step 2b.
(c) If a11 divides every (nonzero) entry a1j
for j ≥ 2, say a1j = a11bj
, then subtract bj
times column 1 from column j for j = 2, . . . , n; go to Step 3.
As in Step 2a, whenever we return to the beginning of Step 2b, we have σ(b1k) < σ(a11).
Therefore, after a finite number of steps, we must exit Step 2b with a matrix in which all
entries in row 1 but the first are zero.
Step 3 . This step is reached only if the only nonzero entry in the first row is a11.
(i) If
M =


a
0
.
11 0 · · · 0
.
. Y
0


go to Step 4.
(ii) If Step 2b ruined column 1 which now contains some nonzero entry below a11, go
back to Step 2a.
We perform a sequence of alternating steps between Step 2a and Step 2b. Because the
σ-value of the (1, 1)-entry strictly decreases whenever we reenter Step 2a and Step 2b, such
a sequence must terminate with a matrix of the form
M =


a
0
.
11 0 · · · 0
.
. Y
0


Step 4 . If a11 divides all entries in Y , stop.
1308 CHAPTER 36. NORMAL FORMS; THE RATIONAL CANONICAL FORM
Otherwise, there is some column, say j, such that a11 does not divide some entry aij , so
add the jth column to the first column. This yields a matrix of the form
M =


a11 0 · · · 0
b2j
.
.
. Y
bmj


where the ith entry in column 1 is nonzero, so go back to Step 2a,
Again, since the σ-value of the (1, 1)-entry strictly decreases whenever we reenter Step
2a and Step 2b, such a sequence must terminate with a matrix of the form
M0 =


α
0
.
1 0 · · · 0
.
. Y
0


where α1 divides every entry in Y . Then, we apply the induction hypothesis to Y .
If the PID A is the polynomial ring K[X] where K is a field, the αi are nonzero poly￾nomials, so we can apply row operations to normalize their leading coefficients to be 1. We
obtain the following theorem.
Theorem 36.19. (Smith Normal Form) If M is an m × n matrix over the polynomial ring
K[X], where K is a field, then there exist some invertible n×n matrix P and some invertible
m × m matrix Q, where P and Q are products of elementary matrices with entries in K[X],
and a m × n matrix D of the form
D =


q1 0 · · · 0 0 · · · 0
0 q2 · · · 0 0 · · · 0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. · · ·
.
.
.
0 0 · · · qr 0 · · · 0
0 0 · · · 0 0 · · · 0
.
.
.
.
.
. · · ·
.
.
.
.
.
.
.
.
.
.
.
.
0 0 · · · 0 0 · · · 0


for some nonzero monic polynomials qi ∈ k[X], such that
(1) q1 | q2 | · · · | qr, and
(2) M = QDP −1
.
36.5. THE SMITH NORMAL FORM 1309
In particular, if we apply Theorem 36.19 to a matrix M of the form M = XI − A, where
A is a square matrix, then det(XI −A) = χA(X) is never zero, and since XI −A = QDP −1
with P, Q invertible, all the entries in D must be nonzero and we obtain the following result
showing that the similarity invariants of A can be computed using elementary operations.
Theorem 36.20. If A is an n × n matrix over the field K, then there exist some invertible
n × n matrices P and Q, where P and Q are products of elementary matrices with entries
in K[X], and a n × n matrix D of the form
D =


1
.
.
.
· · ·
.
0 0 0 · · · 0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
0 · · · 1 0 0 · · · 0
0 · · · 0 q1 0 · · · 0
0 · · · 0 0 q2 · · · 0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
0 · · · 0 0 0 · · · qm


for some nonzero monic polynomials qi ∈ k[X] of degree ≥ 1, such that
(1) q1 | q2 | · · · | qm,
(2) q1, . . . qm are the similarity invariants of A, and
(3) XI − A = QDP −1
.
The matrix D in Theorem 36.20 is often called Smith normal form of A, even though
this is confusing terminology since D is really the Smith normal form of XI − A.
Of course, we know from previous work that in Theorem 36.19, the α1, . . . , αr are unique,
and that in Theorem 36.20, the q1, . . . , qm are unique. This can also be proved using some
simple properties of minors, but we leave it as an exercise (for help, look at Jacobson [98],
Chapter 3, Theorem 3.9).
The rational canonical form of A can also be obtained from Q−1 and D, but first, let
us consider the generalization of Theorem 36.19 to PID’s that are not necessarily Euclidean
rings.
We need to find a “norm” that assigns a natural number σ(a) to any nonzero element
of a PID A, in such a way that σ(a) decreases whenever we return to Step 2a and Step 2b.
Since a PID is a UFD, we use the number
σ(a) = k1 + · · · + kr
of prime factors in the factorization of a nonunit element
a = upk
1
1
· · · p
k
r
r
,
1310 CHAPTER 36. NORMAL FORMS; THE RATIONAL CANONICAL FORM
and we set
σ(u) = 0
if u is a unit.
We can’t divide anymore, but we can find gcd’s and use Bezout to mimic division. The
key ingredient is this: for any two nonzero elements a, b ∈ A, if a does not divide b then let
d 6 = 0 be a gcd of a and b. By Bezout, there exist x, y ∈ A such that
ax + by = d.
We can also write a = td and b = −sd, for some s, t ∈ A, so that tdx − sdy = d, which
implies that
tx − sy = 1,
since A is an integral domain. Observe that

−
t
y x
−s
  x s
y t =

1 0
0 1 ,
which shows that both matrices on the left of the equation are invertible, and so is the
transpose of the second one,

x y
s t
(they all have determinant 1). We also have
as + bt = tds − sdt = 0,
so

x y
s t 
a
b

=

d
0

and
￾
a b  x s
y t =
￾ d 0
 .
Because a does not divide b, their gcd d has strictly fewer prime factors than a, so
σ(d) < σ(a).
Using matrices of the form


x y
s t
0 0
0 0
· · ·
· · ·
0
0
0 0 1 0
0 0 0 1
· · ·
· · ·
0
0
0 0
.
.
.
.
.
.
· · ·
.
.
.
0
.
.
.
· · ·
.
.
.
1
.
.
.


with xt − ys = 1, we can modify Steps 2a and Step 2b to obtain the following theorem.
36.5. THE SMITH NORMAL FORM 1311
Theorem 36.21. If M is an m × n matrix over a PID A, then there exist some invertible
n × n matrix P and some invertible m × m matrix Q, where P and Q are products of
elementary matrices and matrices of the form


x y
s t
0 0
0 0
· · ·
· · ·
0
0
0 0 1 0
0 0 0 1
· · ·
· · ·
0
0
0 0
.
.
.
.
.
.
· · ·
.
.
.
0
.
.
.
· · ·
.
.
.
1
.
.
.


with xt − ys = 1, and a m × n matrix D of the form
D =


α1 0 · · · 0 0 · · · 0
0 α2 · · · 0 0 · · · 0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. · · ·
.
.
.
0 0 · · · αr 0 · · · 0
0 0 · · · 0 0 · · · 0
.
.
.
.
.
. · · ·
.
.
.
.
.
.
.
.
.
.
.
.
0 0 · · · 0 0 · · · 0


for some nonzero αi ∈ A, such that
(1) α1 | α2 | · · · | αr, and
(2) M = QDP −1
.
Proof sketch. In Step 2a, if a11 does not divide ak1, then first permute row 2 and row k (if
k 6 = 2). Then, if we write a = a11 and b = ak1, if d is a gcd of a and b and if x, y, s, t are
determined as explained above, multiply on the left by the matrix


x y
s t
0 0
0 0
· · ·
· · ·
0
0
0 0 1 0
0 0 0 1
· · ·
· · ·
0
0
0 0
.
.
.
.
.
.
· · ·
.
.
.
0
.
.
.
· · ·
.
.
.
1
.
.
.


to obtain a matrix of the form


d a12 · · · a1n
0 a22 · · · a2n
a31 a32 · · · a3n
.
.
.
.
.
.
.
.
.
.
.
.
am1 am2 . . . amn


1312 CHAPTER 36. NORMAL FORMS; THE RATIONAL CANONICAL FORM
with σ(d) < σ(a11). Then, go back to Step 2a.
In Step 2b, if a11 does not divide a1k, then first permute column 2 and column k (if
k 6 = 2). Then, if we write a = a11 and b = a1k, if d is a gcd of a and b and if x, y, s, t are
determined as explained above, multiply on the right by the matrix


x s
y t
0 0
0 0 · · ·
· · · 0
0
0 0 1 0
0 0 0 1
· · ·
· · ·
0
0
0 0
.
.
.
.
.
.
· · ·
.
.
.
0
.
.
.
· · ·
.
.
.
1
.
.
.


to obtain a matrix of the form


d 0 a13 · · · a1n
a21 a22 a23 · · · a2n
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
am1 am2 am3 . . . amn


with σ(d) < σ(a11). Then, go back to Step 2b. The other steps remain the same. Whenever
we return to Step 2a or Step 2b, the σ-value of the (1, 1)-entry strictly decreases, so the
whole procedure terminates.
We conclude this section by explaining how the rational canonical form of a matrix A
can be obtained from the canonical form QDP −1 of XI − A.
Let f : E → E be a linear map over a K-vector space of dimension n. Recall from
Theorem 36.3 (see Section 36.1) that as a K[X]-module, Ef is the image of the free module
E[X] by the map σ : E[X] → Ef , where E[X] consists of all linear combinations of the form
p1e1 + · · · + pnen,
where (e1, . . . , en) is a basis of E and p1, . . . , pn ∈ K[X] are polynomials, and σ is given by
σ(p1e1 + · · · + pnen) = p1(f)(e1) + · · · + pn(f)(en).
Furthermore, the kernel of σ is equal to the image of the map ψ: E[X] → E[X], where
ψ(p1e1 + · · · + pnen) = Xp1e1 + · · · + Xpnen − (p1f(e1) + · · · + pn(en)).
The matrix A is the representation of a linear map f over the canonical basis (e1, . . . , en)
