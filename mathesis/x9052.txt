  µ
λ

,
with
P =

XX> −XX>
−XX> XX>  .
Let Kλ and Kµ be the sets of indices corresponding to points failing the margin,
Kλ = {i ∈ {1, . . . , m} | λi = C/m}
Kµ = {i ∈ {1, . . . , m} | µi = C/m}.
56.5. ν-REGRESSION VERSION 2; PENALIZING b 2105
Because λiµi = 0, the sets Kλ and Kµ are disjoint. Observe that from Definition 56.2 we
have pf = |Kλ| and qf = |Kµ|. Then by (∗ξ) and (∗ξ
0 ), we have
mX
i=1
(ξi + ξi
0
) = X
i∈Kλ
ξi +
X
j∈Kµ
ξj
0
=
X
i∈Kλ
(w
> xi + b − yi −  ) + X
j∈Kµ
(−w
> xj − b + yj −  )
= w
>

X
i∈Kλ
xi −
j
X∈Kµ
xj
 −
i
X∈Kλ
yi +
X
j∈Kµ
yj + (pf − qf )b − (pf + qf ).
The optimal value of the dual is given by
−
1
2
￾
λ
> µ
>

 P +

1m1
>m −1m1
>m
−1m1
>m 1m1
>m
  µ
λ

− q
>

µ
λ

,
with
q =

−
y
y

.
Expressing that the duality gap is zero we have
1
2
w
> w +
1
2
b
2 + Cν +
m
C
mX
i=1
(ξi + ξi
0
)
= −
1
2
￾
λ
> µ
>

 P +

1m1
>m −1m1
>m
−1m1
>m 1m1
>m
  µ
λ

− q
>

µ
λ

,
that is,
1
2
￾
λ
> µ
>

 P +

1m1
>m −1m1
>m
−1m1
>m 1m1
>m
  µ
λ

+ Cν
+
C
m

w
>

X
i∈Kλ
xi −
j
X∈Kµ
xj
 −
i
X∈Kλ
yi +
X
j∈Kµ
yj + (pf − qf )b − (pf + qf )

= −
1
2
￾
λ
> µ
>

 P +

1m1
>m −1m1
>m
−1m1
>m 1m1
>m
  µ
λ

− q
>

µ
λ

.
Solving for  we get
C
 ν −
pf
m
+ qf

 = −
￾ λ
> µ
>

 P +

1m1
>m −1m1
>m
−1m1
>m 1m1
>m
  µ
λ

−
￾ y
> −y
>


µ
λ

−
C
m

w
>

X
i∈Kλ
xi −
j
X∈Kµ
xj
 −
i
X∈Kλ
yi +
X
j∈Kµ
yj + (pf − qf )b
 ,
2106 CHAPTER 56. ν-SV REGRESSION
so we get

= −
 
m
C

￾
λ
> µ
>

 P +

1m1
>m −1m1
>m
−1m1
>m 1m1
>m
  µ
λ

+
￾ y
> −y
>


µ
λ

+ w
>

X
i∈Kλ
xi −
j
X∈Kµ
xj
 −
i
X∈Kλ
yi +
X
j∈Kµ
yj + (pf − qf )b
!
 (mν − pf − qf ).
Using the equations
w = X
> (µ − λ)
b = −(1
>mλ − 1
>mµ) = ￾ λ
> µ
>


−1m
1m

,
we see that  is determined by λ and µ provided that (pf + qf )/m < ν.
By Proposition 56.7(1),
pf + qf
m
≤ ν,
therefore the condition (pf + qf )/m < ν is very natural.
We have implemented this method in Matlab, and we have observed that for some ex￾amples the choice of ν caused the equation ν(pf + qf ) = m to hold. In such cases, running
the program again with a slightly perturbed value of ν always succeeded.
The other observation we made is that b tends to be smaller and  tends to be bigger in
ν-SV Regression Version 2, so the fit is actually not as good as in ν-SV Regression without
penalizing b. Figure 56.16 shows the result of running our program on the data set of Section
56.3. Compare with Figure 56.13.
56.6 Summary
The main concepts and results of this chapter are listed below:
• ν-support vector regression (ν-SV regression).
• Regression estimate.
• Kernel ν-SV regression.
•  -SV regression,  -insensitive SV regression,
• ν-SV regression Version 2; penalizing b.
56.7. PROBLEMS 2107
-40 -30 -20 -10 0 10 20 30 40 50 60
-40
-20
0
20
40
60
80
Figure 56.16: Running ν-SV regression version 2 on a set of 50 points; ν = 0.5.
56.7 Problems
Problem 56.1. Prove that if ν-SV regression succeeds and yields w, b,  > 0, then  -SV
regression with the same C and the same value of  also succeeds and returns the same pair
(w, b).
Problem 56.2. Prove the formulae
b =



X
i0∈Iλ
yi0
 /|Iλ| +

X
j0∈Iµ
yj0
 /|Iµ| − w
>

X
i0∈Iλ
xi0
 /|Iλ| +

X
j0∈Iµ
xj0
 /|Iµ|


 /2

=



X
j0∈Iµ
yj0
 /|Iµ| −  X
i0∈Iλ
yi0
 /|Iλ| + w
>

X
i0∈Iλ
xi0
 /|Iλ| −  X
j0∈Iµ
xj0
 /|Iµ|


 /2
stated just before Proposition 56.6.
Problem 56.3. Give the details of the proof of Proposition 56.6. In particular, prove that
C
 ν −
pf
m
+ qf

 = −
￾ λ
> µ
>
 P

µ
λ

−
￾ y
> −y
>


µ
λ

−
C
m

w
>

X
i∈Kλ
xi −
j
X∈Kµ
xj
 −
i
X∈Kλ
yi +
X
j∈Kµ
yj + (pf − qf )b
 .
2108 CHAPTER 56. ν-SV REGRESSION
Problem 56.4. Prove that the matrices
A =


1
>m −1
>m 0
>m 0
>m 0
1
>m 1
>m 0
>m 0
>m 1
Im 0m,m Im 0m,m 0m
0m,m Im 0m,m Im 0m


, A2 =


1
>m −1
>m 0
>m 0
>m
1
>m 1
>m 0
>m 0
>m
Im 0m,m Im 0m,m
0m,m Im 0m,m Im


have rank 2m + 2.
P
Problem 56.5. Derive the version of ν-SV regression in which the linear penalty function
m
i=1(ξi + ξi
0
) is replaced by the quadratic penalty function P m
i=1(ξi
2 + ξi
0
2
). Derive the dual
program.
Problem 56.6. The linear penalty function P m
i=1(ξi + ξi
0
) can be replaced by the quadratic
penalty function P m
i=1(ξi
2 +ξi
0
2
). Prove that for an optimal solution we must have ξi ≥ 0 and
ξi
0 ≥ 0, so we may omit the constraints ξi ≥ 0 and ξi
0 ≥ 0. We must also have γ = 0 so we
may omit the variable γ as well. Prove that ξ = (m/2C)λ and ξ
0 = (m/2C)µ. This problem
is very similar to the Soft Margin SVM (SVMs4) discussed in Section 54.13.
Problem 56.7. Consider the version of ν-SV regression in Section 56.5. Prove that for any
optimal solution with w 6 = 0 and  > 0, if the inequalities (pf + qf )/m < ν < 1 hold, then
some point xi
is a support vector.
Problem 56.8. Prove that the matrix
A3 =


1
Im
>
m 1
>m 0
>m 0
>m
0m,m Im 0m,m
0m,m Im 0m,m Im


has rank 2m + 1.
Problem 56.9. Consider the version of ν-SV regression in Section 56.5. Prove the following
formulae: If Iλ 6 = ∅, then

= w
>

X
i∈Iλ
xi
 /|Iλ| + b −

X
i∈Iλ
yi
 /|Iλ|,
and if Iµ 6 = ∅, then

= −w
>

X
j∈Iµ
xj
 /|Iµ| − b +

X
i∈Iµ
yi
 /|Iµ|.
Problem 56.10. Implement ν-Regression Version 2 described in Section 56.5. Run examples
using both the original version and version 2 and compare the results.
Part X
Appendices
2109
Appendix A
Total Orthogonal Families in Hilbert
Spaces
A.1 Total Orthogonal Families (Hilbert Bases),
Fourier Coefficients
We conclude our quick tour of Hilbert spaces by showing that the notion of orthogonal basis
can be generalized to Hilbert spaces. However, the useful notion is not the usual notion of
a basis, but a notion which is an abstraction of the concept of Fourier series. Every element
of a Hilbert space is the “sum” of its Fourier series.
Definition A.1. Given a Hilbert space E, a family (uk)k∈K of nonnull vectors is an or￾thogonal family iff the uk are pairwise orthogonal, i.e., h ui
, uj i = 0 for all i 6 = j (i, j ∈ K),
and an orthonormal family iff h ui
, uj i = δi, j , for all i, j ∈ K. A total orthogonal family (or
system) or Hilbert basis is an orthogonal family that is dense in E. This means that for
every v ∈ E, for every  > 0, there is some finite subset I ⊆ K and some family (λi)i∈I of
complex numbers, such that



v −
X
i∈I
λiui

 < .
Given an orthogonal family (uk)k∈K, for every v ∈ E, for every k ∈ K, the scalar ck =
h
v, uki /k ukk
2
is called the k-th Fourier coefficient of v over (uk)k∈K.
Remark: The terminology Hilbert basis is misleading because a Hilbert basis (uk)k∈K is
not necessarily a basis in the algebraic sense. Indeed, in general, (uk)k∈K does not span E.
Intuitively, it takes linear combinations of the uk’s with infinitely many nonnull coefficients
to span E. Technically, this is achieved in terms of limits. In order to avoid the confusion
between bases in the algebraic sense and Hilbert bases, some authors refer to algebraic bases
as Hamel bases and to total orthogonal families (or Hilbert bases) as Schauder bases.
2111
2112 APPENDIX A. TOTAL ORTHOGONAL FAMILIES IN HILBERT SPACES
Given an orthogonal family (uk)k∈K, for any finite subset I of K, we often call sums of
the form P i∈I
λiui partial sums of Fourier series, and if these partial sums converge to a
limit denoted as P k∈K ckuk, we call P k∈K ckuk a Fourier series.
However, we have to make sense of such sums! Indeed, when K is unordered or uncount￾able, the notion of limit or sum has not been defined. This can be done as follows (for more
details, see Dixmier [51]):
Definition A.2. Given a normed vector space E (say, a Hilbert space), for any nonempty
index set K, we say that a family (uk)k∈K of vectors in E is summable with sum v ∈ E iff
for every  > 0, there is some finite subset I of K, such that,



v −
X
j∈J
uj

 < 
for every finite subset J with I ⊆ J ⊆ K. We say that the family (uk)k∈K is summable
iff there is some v ∈ E such that (uk)k∈K is summable with sum v. A family (uk)k∈K is a
Cauchy family iff for every  > 0, there is a finite subset I of K, such that,



X
j∈J
uj

 < 
for every finite subset J of K with I ∩ J = ∅,
If (uk)k∈K is summable with sum v, we usually denote v as P k∈K uk. The following
technical proposition will be needed:
Proposition A.1. Let E be a complete normed vector space (say, a Hilbert space).
(1) For any nonempty index set K, a family (uk)k∈K is summable iff it is a Cauchy family.
(2) Given a family (rk)k∈K of nonnegative reals rk ≥ 0, if there is some real number B > 0
such that P i∈I
ri < B for every finite subset I of K, then (rk)k∈K is summable and
P
k∈K rk = r, where r is least upper bound of the set of finite sums P i∈I
ri (I ⊆ K).
Proof. (1) If (uk)k∈K is summable, for every finite subset I of K, let
uI =
X
i∈I
ui and u =
X
k∈K
uk
For every  > 0, there is some finite subset I of K such that
k
u − uLk < /2
for all finite subsets L such that I ⊆ L ⊆ K. For every finite subset J of K such that
I ∩ J = ∅, since I ⊆ I ∪ J ⊆ K and I ∪ J is finite, we have
k
u − uI∪J k < /2 and k u − uIk < /2,
A.1. TOTAL ORTHOGONAL FAMILIES, FOURIER COEFFICIENTS 2113
and since
k
uI∪J − uIk ≤ kuI∪J − uk + k u − uIk
and uI∪J − uI = uJ since I ∩ J = ∅, we get
k
uJ k = k uI∪J − uIk < ,
which is the condition for (uk)k∈K to be a Cauchy family.
Conversely, assume that (uk)k∈K is a Cauchy family. We define inductively a decreasing
sequence (Xn) of subsets of E, each of diameter at most 1/n, as follows: For n = 1, since
(uk)k∈K is a Cauchy family, there is some finite subset J1 of K such that
k
uJ k < 1/2
for every finite subset J of K with J1 ∩ J = ∅. We pick some finite subset J1 with the above
property, and we let I1 = J1 and
X1 = {uI | I1 ⊆ I ⊆ K, I finite}.
For n ≥ 1, there is some finite subset Jn+1 of K such that
k
uJ k < 1/(2n + 2)
for every finite subset J of K with Jn+1 ∩ J = ∅. We pick some finite subset Jn+1 with the
above property, and we let In+1 = In ∪ Jn+1 and
Xn+1 = {uI | In+1 ⊆ I ⊆ K, I finite}.
Since In ⊆ In+1, it is obvious that Xn+1 ⊆ Xn for all n ≥ 1. We need to prove that each Xn
has diameter at most 1/n. Since Jn was chosen such that
k
uJ k < 1/(2n)
for every finite subset J of K with Jn ∩ J = ∅, and since Jn ⊆ In, it is also true that
k
uJ k < 1/(2n)
for every finite subset J of K with In ∩ J = ∅ (since In ∩ J = ∅ and Jn ⊆ In implies that
Jn ∩ J = ∅). Then for every two finite subsets J, L such that In ⊆ J, L ⊆ K, we have
k
uJ−In k < 1/(2n) and k uL−In k < 1/(2n),
and since
k
uJ − uLk ≤ kuJ − uIn k + k uIn − uLk = k uJ−In k + k uL−In k
,
we get
k
uJ − uLk < 1/n,
2114 APPENDIX A. TOTAL ORTHOGONAL FAMILIES IN HILBERT SPACES
which proves that δ(Xn) ≤ 1/n. Now if we consider the sequence of closed sets (Xn), we
still have Xn+1 ⊆ Xn, and by Proposition 48.4, δ(Xn) = δ(Xn) ≤ 1/n, which means that
limn→∞ δ(Xn) = 0, and by Proposition 48.4, T ∞
n=1 Xn consists of a single element u. We
claim that u is the sum of the family (uk)k∈K.
For every  > 0, there is some n ≥ 1 such that n > 2/, and since u ∈ Xm for all m ≥ 1,
there is some finite subset J0 of K such that In ⊆ J0 and
k
u − uJ0 k < /2,
where In is the finite subset of K involved in the definition of Xn. However, since δ(Xn) ≤
1/n, for every finite subset J of K such that In ⊆ J, we have
k
uJ − uJ0 k ≤ 1/n < /2,
and since
k
u − uJ k ≤ ku − uJ0 k + k uJ0 − uJ k ,
we get
k
u − uJ k < 
for every finite subset J of K with In ⊆ J, which proves that u is the sum of the family
(uk)k∈K.
(2) Since every finite sum P i∈I
ri
is bounded by the uniform bound B, the set of these
finite sums has a least upper bound r ≤ B. For every  > 0, since r is the least upper bound
of the finite sums P i∈I
ri (where I finite, I ⊆ K), there is some finite I ⊆ K such that





r −
X
i∈I
ri



 < ,
and since rk ≥ 0 for all k ∈ K, we have
X
i∈I
ri ≤
X
j∈J
rj
whenever I ⊆ J, which shows that





r −
X
j∈J
rj


 
 ≤


 
 r −
X
i∈I
ri



 < 
for every finite subset
P J such that I ⊆ J ⊆ K, proving that (rk)k∈K is summable with sum
k∈K rk = r.
A.1. TOTAL ORTHOGONAL FAMILIES, FOURIER COEFFICIENTS 2115
Remark: The notion of summability implies that the sum of a family (uk)k∈K is independent
of any order on K. In this sense it is a kind of “commutative summability.” More precisely,
it is easy to show that for every bijection ϕ: K → K (intuitively, a reordering of K), the
family (uk)k∈K is summable iff the family (ul)l∈ϕ(K)
is summable, and if so, they have the
same sum.
The following proposition gives some of the main properties of Fourier coefficients. Among
other things, at most countably many of the Fourier coefficient may be nonnull, and the
partial sums of a Fourier series converge. Given an orthogonal family (uk)k∈K, we let Uk =
Cuk, and pUk
: E → Uk is the projection of E onto Uk.
Proposition A.2. Let E be a Hilbert space, (uk)k∈K an orthogonal family in E, and V the
closure of the subspace generated by (uk)k∈K. The following properties hold:
(1) For every v ∈ E, for every finite subset I ⊆ K, we have
X
i∈I
|ci
|
2 ≤ kvk
2
,
where the ck are the Fourier coefficients of v.
(2) For every vector v ∈ E, if (ck)k∈K are the Fourier coefficients of v, the following
conditions are equivalent:
(2a) v ∈ V
(2b) The family (ckuk)k∈K is summable and v =
P k∈K ckuk.
(2c) The family (|ck|
2
)k∈K is summable and k vk
2 =
P k∈K |ck|
2
;
(3) The family (|ck|
2
)k∈K is summable, and we have the Bessel inequality :
X
k∈K
|ck|
2 ≤ kvk
2
.
As a consequence, at most countably many of the ck may be nonzero. The family
(ckuk)k∈K forms a Cauchy family, and thus, the Fourier series P k∈K ckuk converges
in E to some vector u =
P k∈K ckuk. Furthermore, u = pV (v).
See Figure A.1.
Proof. (1) Let
uI =
X
i∈I
ciui
2116 APPENDIX A. TOTAL ORTHOGONAL FAMILIES IN HILBERT SPACES
E
V = span(u )k
v
 form c = k
v, uk
uk
2 u = c k uk
k K
Σ
e
E
V = span(u )k
v
 form c = k
v, uk
uk
2 c k uk
k K
Σ
e
=
(i.)
(ii.)
Figure A.1: A schematic illustration of Proposition A.2. Figure (i.) illustrates Condition
(2b), while Figure (ii.) illustrates Condition (3). Note E is the purple oval and V is the
magenta oval. In both cases, take a vector of E, form the Fourier coefficients ck, then form
the Fourier series P k∈K ckuk. Condition (2b) ensures v equals its Fourier series since v ∈ V .
However, if v /∈ V , the Fourier series does not equal v. Eventually, we will discover that
V = E, which implies that that Fourier series converges to its vector v.
for any finite subset I of K. We claim that v −uI is orthogonal to ui
for every i ∈ I. Indeed,
h
v − uI , uii =
* v −
X
j∈I
cjuj
, ui
+
= h v, uii −X
j∈I
cj h uj
, uii
= h v, uii − cik uik
2
= h v, uii − hv, uii = 0,
A.1. TOTAL ORTHOGONAL FAMILIES, FOURIER COEFFICIENTS 2117
since h uj
, uii = 0 for all i 6 = j and ci = h v, uii /k uik
2
. As a consequence, we have
k
vk
2 =

  v −
X
i∈I
ciui +
X
i∈I
ciui


2
=

  v −
X
i∈I
ciui


2
+

 
X
i∈I
ciui


2
=

  v −
X
i∈I
ciui


2
+
X
i∈I
|ci
|
2
,
since the ui are pairwise orthogonal, that is,
k
vk
2 =

  v −
X
i∈I
ciui


2
+
X
i∈I
|ci
|
2
.
Thus,
X
i∈I
|ci
|
2 ≤ kvk
2
,
as claimed.
(2) We prove the chain of implications (a) ⇒ (b) ⇒ (c) ⇒ (a).
(a) ⇒ (b): If v ∈ V , since V is the closure of the subspace spanned by (uk)k∈K, for every
 > 0, there is some finite subset I of K and some family (λi)i∈I of complex numbers, such
that



v −
X
i∈I
λiui

 < .
Now for every finite subset J of K such that I ⊆ J, we have



v −
X
i∈I
λiui


2
=

  v −
X
j∈J
cjuj +
X
j∈J
cjuj −
X
i∈I
λiui


2
=

  v −
X
j∈J
cjuj
