with λ ≥ 0, ν+ ≥ 0, ν− ≥ 0, and if we introduce νj = νj
+ − νj
− we obtain the following KKT
conditions for programs with explicit equality constraints:
Ju
0 +
mX
i=1
λi(ϕ
0i
)u +
p
X
j=1
νj (ψj
0
)u = 0,
and
mX
i=1
λiϕi(u) = 0
with λ ≥ 0 and ν ∈ R
p arbitrary.
Let us now assume that the functions ϕi and ψj are convex. As we explained just after
Definition 50.6, nonaffine equality constraints are never qualified. Thus, in order to generalize
Theorem 50.6 to explicit equality constraints, we assume that the equality constraints ψj are
affine.
Theorem 50.18. Let ϕi
: Ω → R be m convex inequality constraints and ψj
: Ω → R be
p affine equality constraints defined on some open convex subset Ω of a finite-dimensional
Euclidean vector space V (more generally, a real Hilbert space V ), let J : Ω → R be some
function, let U be given by
U = {x ∈ Ω | ϕi(x) ≤ 0, ψj (x) = 0, 1 ≤ i ≤ m, 1 ≤ j ≤ p},
and let u ∈ U be any point such that the functions ϕi and J are differentiable at u, and the
functions ψj are affine.
(1) If J has a local minimum at u with respect to U, and if the constraints are qualified,
then there exist some vectors λ ∈ R
m
+ and ν ∈ R
p
, such that the KKT condition hold:
Ju
0 +
mX
i=1
λi(u)(ϕ
0i
)u +
p
X
j=1
νj (ψj
0
)u = 0,
and
mX
i=1
λi(u)ϕi(u) = 0, λi ≥ 0, i = 1, . . . , m.
Equivalently, in terms of gradients, the above conditions are expressed as
∇Ju +
mX
i=1
λi∇(ϕi)u +
p
X
j=1
νj∇(ψj )u = 0
and
mX
i=1
λi(u)ϕi(u) = 0, λi ≥ 0, i = 1, . . . , m.
1790 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
(2) Conversely, if the restriction of J to U is convex and if there exist vectors λ ∈ R
m
+ and
ν ∈ R
p
such that the KKT conditions hold, then the function J has a (global) minimum
at u with respect to U.
The Lagrangian L(v, λ, ν) of Problem (P
0 ) is defined as
L(v, µ, ν) = J(v) +
mX
i=1
µiϕi(v) +
p
X
j=1
νiψj (v),
where v ∈ Ω, µ ∈ R
m
+ , and ν ∈ R
p
.
The function G: R
m
+ × R
p → R given by
G(µ, ν) = inf
v∈Ω
L(v, µ, ν) µ ∈ R
m
+ , ν ∈ R
p
is called the Lagrange dual function (or dual function), and the Dual Problem (D0 ) is
maximize G(µ, ν)
subject to µ ∈ R
m
+ , ν ∈ R
p
.
Observe that the Lagrange multipliers ν are not restricted to be nonnegative.
Theorem 50.15 and Theorem 50.17 are immediately generalized to Problem (P
0 ). We
only state the new version of 50.17, leaving the new version of Theorem 50.15 as an exercise.
Theorem 50.19. Consider the minimization problem (P
0 ):
minimize J(v)
subject to ϕi(v) ≤ 0, i = 1, . . . , m
ψj (v) = 0, j = 1, . . . , p.
where the functions J, ϕi are defined on some open subset Ω of a finite-dimensional Euclidean
vector space V (more generally, a real Hilbert space V ), and the functions ψj are affine.
(1) Suppose the functions ϕi
: Ω → R are continuous, and that for every µ ∈ R
m
+ and every
ν ∈ R
p
, the Problem (Pµ,ν):
minimize L(v, µ, ν)
subject to v ∈ Ω,
has a unique solution uµ,ν, so that
L(uµ,ν, µ, ν) = inf
v∈Ω
L(v, µ, ν) = G(µ, ν),
50.10. DUAL OF THE HARD MARGIN SUPPORT VECTOR MACHINE 1791
and the function (µ, ν) 7→ uµ,ν is continuous (on R
m
+ × R
p
). Then the function G is
differentiable for all µ ∈ R
m
+ and all ν ∈ R
p
, and
G
0µ,ν(ξ, ζ) =
mX
i=1
ξiϕi(uµ,ν) +
p
X
j=1
ζjψj (uµ,ν) for all ξ ∈ R
m and all ζ ∈ R
p
.
If (λ, η) is any solution of Problem (D):
maximize G(µ, ν)
subject to µ ∈ R
m
+ , ν ∈ R
p
,
then the solution uλ,η of the corresponding Problem (Pλ,η) is a solution of Problem (P
0 ).
(2) Assume Problem (P
0 ) has some solution u ∈ U, and that Ω is convex (open), the
functions ϕi (1 ≤ i ≤ m) and J are convex, differentiable at u, and that the constraints
are qualified. Then Problem (D0 ) has a solution (λ, η) ∈ R
m
+ ×R
p
, and J(u) = G(λ, η);
that is, the duality gap is zero.
In the next section we derive the dual function and the dual program of the optimization
problem of Section 50.6 (Hard margin SVM), which involves both inequality and equality
constraints. We also derive the KKT conditions associated with the dual program.
50.10 Dual of the Hard Margin Support Vector Ma￾chine
Recall the Hard margin SVM problem (SVMh2):
minimize
2
1
k
wk
2
, w ∈ R
n
subject to
w
> ui − b ≥ 1 i = 1, . . . , p
− w
> vj + b ≥ 1 j = 1, . . . , q.
We proceed in six steps.
Step 1: Write the constraints in matrix form.
The inequality constraints are written as
C

w
b

≤ d,
1792 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
where C is a (p + q) × (n + 1) matrix C and d ∈ R
p+q
is the vector given by
C =


−u
>1
1
.
.
.
.
.
.
−u
>p
1
v
>1 −1
.
.
.
.
.
.
vq
> −1


, d =


−
−
.
.
.
1
1

 = −1p+q.
If we let X be the n × (p + q) matrix given by
X =
￾ −u1 · · · −up v1 · · · vq
 ,
then
C =
 X>
1p
−1q

and so
C
> =

1
>p
X
−1
>q

.
Step 2: Write the objective function in matrix form.
The objective function is given by
J(w, b) = 1
2
￾
w
> b


In 0n
0
>n
0
 
w
b

.
Note that the corresponding matrix is symmetric positive semidefinite, but it is not invertible.
Thus the function J is convex but not strictly convex.
Step 3: Write the Lagrangian in matrix form.
As in Example 50.7, we obtain the Lagrangian
L(w, b, λ, µ) = 1
2
￾
w
> b


In 0n
0
>n
0
 
w
b

−
￾ w
> b

 0n+1 − C
>

µ
λ

+
￾ λ
> µ
>
 1p+q,
that is,
L(w, b, λ, µ) = 1
2
￾
w
> b


In 0n
0
>n
0
 
w
b

+
￾ w
> b



1
>p
X
λ
 −
µ
λ
1

>q µ

 +
￾ λ
> µ
>
 1p+q.
Step 4: Find the dual function G(λ, µ).
In order to find the dual function G(λ, µ), we need to minimize L(w, b, λ, µ) with respect
to w and b and for this, since the objective function J is convex and since R
n+1 is convex
50.10. DUAL OF THE HARD MARGIN SUPPORT VECTOR MACHINE 1793
and open, we can apply Theorem 40.13, which gives a necessary and sufficient condition for
a minimum. The gradient of L(w, b, λ, µ) with respect to w and b is
∇Lw,b =

In 0n
0
>n
0
 
w
b

+


1
>p
X
λ
 −
µ
λ
1

>q µ


=

w
0

+


1
>p
X
λ
 −
µ
λ
1

>q µ

 .
The necessary and sufficient condition for a minimum is
∇Lw,b = 0,
which yields
w = −X

µ
λ

(∗1)
and
1
>p λ − 1
>q µ = 0. (∗2)
The second equation can be written as
p
X
i=1
λi =
q
X
j=1
µj
. (∗3)
Plugging back w from (∗1) into the Lagrangian and using (∗2) we get
G(λ, µ) = −
1
2
￾
λ
> µ
>
 X
> X

µ
λ

+
￾ λ
> µ
>
 1p+q; (∗4)
of course, ￾ λ
> µ
>
 1p+q =
P
p
i=1 λi +
P
q
j=1 µj
. Actually, to be perfectly rigorous G(λ, µ) is
only defined on the intersection of the hyperplane of equation P p
i=1 λi =
P
q
j=1 µj with the
convex octant in R
p+q given by λ ≥ 0, µ ≥ 0, so for all λ ∈ R
p
+ and all µ ∈ R
q
+, we have
G(λ, µ) =



−
1
2

λ
> µ
>
 X> X
 
µ
λ
!
+
 λ
> µ
>
 1p+q if P p
i=1 λi =
P
q
j=1 µj
−∞ otherwise.
Note that the condition
p
X
i=1
λi =
q
X
j=1
µj
is Condition (∗2) of Example 50.6, which is not surprising.
1794 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
Step 5: Write the dual program in matrix form.
Maximizing the dual function G(λ, µ) over its domain of definition is equivalent to max￾imizing
b
G(λ, µ) = −
1
2
￾
λ
> µ
>
 X
> X

µ
λ

+
￾ λ
> µ
>
 1p+q
subject to the constraint
p
X
i=1
λi =
q
X
j=1
µj
,
so we formulate the dual program as,
maximize −
1
2
￾
λ
> µ
>
 X
> X

µ
λ

+
￾ λ
> µ
>
 1p+q
subject to
p
X
i=1
λi =
q
X
j=1
µj
λ ≥ 0, µ ≥ 0,
or equivalently,
minimize
1
2
￾
λ
> µ
>
 X
> X

µ
λ

−
￾ λ
> µ
>
 1p+q
subject to
p
X
i=1
λi =
q
X
j=1
µj
λ ≥ 0, µ ≥ 0.
The constraints of the dual program are a lot simpler than the constraints

X>
1p
−1q
 
w
b

≤ −1p+q
of the primal program because these constraints have been “absorbed” by the objective
function Gb(λ, ν) of the dual program which involves the matrix X> X. The matrix X> X is
symmetric positive semidefinite, but not invertible in general.
Step 6: Solve the dual program.
This step involves using numerical procedures typically based on gradient descent to
find λ and µ, for example, ADMM from Section 52.6. Once λ and µ are determined, w is
determined by (∗1) and b is determined as in Section 50.6 using the fact that there is at least
some i0 such that λi0 > 0 and some j0 such that µj0 > 0.
Remarks:
50.10. DUAL OF THE HARD MARGIN SUPPORT VECTOR MACHINE 1795
(1) Since the constraints are affine and the objective function is convex, by Theorem
50.19(2) the duality gap is zero, so for any minimum w of J(w, b) = (1/2)w
> w and
any maximum (λ, µ) of G, we have
J(w, b) = 1
2
w
> w = G(λ, µ).
But by (∗1)
w = −X

µ
λ

=
p
X
i=1
λiui −
q
X
j=1
µjvj
,
so
￾
λ
> µ
>
 X
> X

µ
λ

= w
> w,
and we get
1
2
w
> w = −
1
2
￾
λ
> µ
>
 X
> X

µ
λ

+
￾ λ
> µ
>
 1p+q = −
1
2
w
> w +
￾ λ
> µ
>
 1p+q,
so
w
> w =
￾ λ
> µ
>
 1p+q =
p
X
i=1
λi +
q
X
j=1
µj
,
which yields
G(λ, µ) = 1
2
 
p
X
i=1
λi +
q
X
j=1
µj
!
.
The above formulae are stated in Vapnik [182] (Chapter 10, Section 1).
(2) It is instructive to compute the Lagrangian of the dual program and to derive the KKT
conditions for this Lagrangian.
The conditions λ ≥ 0 being equivalent to −λ ≤ 0, and the conditions µ ≥ 0 being
equivalent to −µ ≤ 0, we introduce Lagrange multipliers α ∈ R
p
+ and β ∈ R
q
+ as well
as a multiplier ρ ∈ R for the equational constraint, and we form the Lagrangian
L(λ, µ, α, β, ρ) = 1
2
￾
λ
> µ
>
 X
> X

µ
λ

−
￾ λ
> µ
>
 1p+q
−
p
X
i=1
αiλi −
q
X
j=1
βjµj + ρ

q
X
j=1
µj −
p
X
i=1
λi

.
It follows that the KKT conditions are
X
> X

µ
λ

− 1p+q −

α
β

+ ρ

−1p
1q

= 0p+q, (∗4)
1796 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
and αiλi = 0 for i = 1, . . . , p and βjµj = 0 for j = 1, . . . , q.
But (∗4) is equivalent to
−X
> X

µ
λ

+ ρ

1p
−1q

+ 1p+q +

α
β

= 0p+q,
which is precisely the result of adding α ≥ 0 and β ≥ 0 as slack variables to the
inequalities (∗3) of Example 50.6, namely
−X
> X

µ
λ

+ b

1p
−1q

+ 1p+q ≤ 0p+q,
to make them equalities, where ρ plays the role of b.
When the constraints are affine, the dual function G(λ, ν) can be expressed in terms of
the conjugate of the objective function J.
50.11 Conjugate Function and Legendre Dual Func￾tion
The notion of conjugate function goes back to Legendre and plays an important role in
classical mechanics for converting a Lagrangian to a Hamiltonian; see Arnold [5] (Chapter
3, Sections 14 and 15).
Definition 50.11. Let f : A → R be a function defined on some subset A of R
n
. The
conjugate f
∗ of the function f is the partial function f
∗
: R
n → R defined by
f
∗
(y) = sup
x∈A
(h y, xi − f(x)) = sup
x∈A
(y
> x − f(x)), y ∈ R
n
.
The conjugate of a function is also called the Fenchel conjugate, or Legendre transform when
f is differentiable.
As the pointwise supremum of a family of affine functions in y, the conjugate function
f
∗
is convex, even if the original function f is not convex.
By definition of f
∗ we have
f(x) + f
∗
(y) ≥ hx, yi = x
> y,
whenever the left-hand side is defined. The above is known as Fenchel’s inequality (or
Young’s inequality if f is differentiable).
If f : A → R is convex (so A is convex) and if epi(f) is closed, then it can be shown that
f
∗∗ = f. In particular, this is true if A = R
n
.
50.11. CONJUGATE FUNCTION AND LEGENDRE DUAL FUNCTION 1797
The domain of f
∗
can be very small, even if the domain of f is big. For example, if
f : R → R is the affine function given by f(x) = ax + b (with a, b ∈ R), then the function
x 7→ yx − ax − b is unbounded above unless y = a, so
f
∗
(y) = ( −
+∞
b if
otherwise
y = a
.
The domain of f
∗
can also be bigger than the domain of f; see Example 50.8(3).
The conjugates of many functions that come up in optimization are derived in Boyd and
Vandenberghe; see [29], Section 3.3. We mention a few that will be used in this chapter.
Example 50.8.
(1) Negative logarithm: f(x) = − log x, with dom(f) = {x ∈ R | x > 0}. The function
x 7→ yx+ log x is unbounded above if y ≥ 0, and when y < 0, its maximum is obtained
iff its derivative is zero, namely
y +
1
x
= 0.
Substituting for x = −1/y in yx + log x, we obtain −1 + log(−1/y) = −1 − log(−y),
so we have
f
∗
(y) = − log(−y) − 1,
with dom(f
∗
) = {y ∈ R | y < 0}.
(2) Exponential: f(x) = e
x
, with dom(f) = R. The function x 7→ yx − e
x
is unbounded if
y < 0. When y > 0, it reaches a maximum iff its derivative is zero, namely
y − e
x = 0.
Substituting for x = log y in yx − e
x
, we obtain y log y − y, so we have
f
∗
(y) = y log y − y,
with dom(f
∗
) = {y ∈ R | y ≥ 0}, with the convention that 0 log 0 = 0.
(3) Negative Entropy: f(x) = x log x, with dom(f) = {x ∈ R | x ≥ 0}, with the convention
that 0 log 0 = 0. The function x 7→ yx − x log x is bounded above for all y > 0, and it
attains its maximum when its derivative is zero, namely
y − log x − 1 = 0.
Substituting for x = e
y−1
in yx − x log x, we obtain yey−1 − e
y−1
(y − 1) = e
y−1
, which
yields
f
∗
(y) = e
y−1
,
with dom(f
∗
) = R.
1798 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
(4) Strictly convex quadratic function: f(x) = 2
1x
> Ax, where A is an n × n symmetric
positive definite matrix, with dom(f) = R
n
. The function x 7→ y
> x −
1
2
x
> Ax has a
unique maximum when is gradient is zero, namely
y = Ax.
Substituting for x = A−1
y in y
> x −
1
2
x
> Ax, we obtain
y
> A
−1
y −
1
2
y
> A
−1
y = −
1
2
y
> A
−1
y,
so
f
∗
(y) = −
1
2
y
> A
−1
y
with dom(f
∗
) = R
n
.
(5) Log-determinant: f(X) = log det(X−1
), where X is an n×n symmetric positive definite
matrix. Then
f(Y ) = log det((−Y )
−1
) − n,
where Y is an n × n symmetric negative definite matrix; see Boyd and Vandenberghe;
see [29], Section 3.3.1, Example 3.23.
(6) Norm on R
n
: f(x) = k xk for any norm k k on R
n
, with dom(f) = R
n
. Recall from
Section 14.7 that the dual norm k k D
