of the norm k k (with respect to the canonical
inner product x · y = y
> x on R
n
is given by
k
yk
D
= sup
k
xk =1
|y
> x|,
and that
|y
> x| ≤ kxk k yk
D
.
We have
f
∗
(y) = sup
x∈Rn
(y
> x − kxk )
= sup
x∈Rn,x6=0
y
>
k
x
xk
− 1
 k xk
≤ sup
x∈Rn,x6=0
(k yk
D − 1) k xk ,
so if k yk
D > 1 this last term goes to +∞, but if k yk
D ≤ 1, then its maximum is 0.
Therefore,
f
∗
(y) = k yk
∗ =
(
+
0 if
∞ otherwise
k
yk
D ≤
.
1
50.11. CONJUGATE FUNCTION AND LEGENDRE DUAL FUNCTION 1799
(7) Norm squared: f(x) = 1
2
k
xk
2
for any norm k k on R
n
, with dom(f) = R
n
. Since
|y
> x| ≤ kxk k yk
D
, we have
y
> x − (1/2) k xk
2 ≤ kyk
D
k
xk − (1/2) k xk
2
.
The right-hand side is a quadratic function of k xk which achieves its maximum at
k
xk = k yk
D
, with maximum value (1/2)(k yk
D
)
2
. Therefore
y
> x − (1/2) k xk
2 ≤ (1/2) k yk
D

2
for all x, which shows that
f
∗
(y) ≤ (1/2) k yk
D

2
.
By definition of the dual norm and because the unit sphere is compact, for any y ∈ R
n
,
there is some x ∈ R
n
such that k xk = 1 and y
> x = k yk
D
, so multiplying both sides by
k
yk
D we obtain
y
> k yk
D
x =
 k yk
D

2
and for z = k yk
D
x, since k xk = 1 we have k zk = k yk
D
k
xk = k yk
D
, so we get
y
> z − (1/2)(k zk )
2 =
 k yk
D

2
− (1/2) k yk
D

2
= (1/2) k yk
D

2
,
which shows that the upper bound (1/2) k yk
D

2
is achieved. Therefore,
f
∗
(y) = 1
2

k
yk
D

2
,
and dom(f
∗
) = R
n
.
(8) Log-sum-exp function: f(x) = log P n
i=1 e
xi

, where x = (x1, . . . , xn) ∈ R
n
. To
determine the values of y ∈ R
n
for which the maximum of g(x) = y
> x − f(x) over
x ∈ R
n
is attained, we compute its gradient and we find
∇fx =


y1 −
e
x1
P
n
i=1 e
xi
.
.
.
yn −
e
xn
P
n
i=1 e
xi


.
Therefore, (y1, . . . , yn) must satisfy the system of equations
yj =
e
xj
P
n
i=1 e
xi
, j = 1, . . . , n. (∗)
1800 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
The condition P n
i=1 yi = 1 is obviously necessary, as well as the conditions yi > 0, for
i = 1, . . . , n. Conversely, if 1
> y = 1 and y > 0, then xj = log yi
for i = 1, . . . , n is a
solution. Since (∗) implies that
xi = log yi + log
nX
i=1
e
xi

, (∗∗)
we get
y
> x − f(x) =
nX
i=1
yixi − log
nX
i=1
e
xi

=
nX
i=1
yi
log yi +
nX
i=1
yi
log
nX
i=1
e
xi
 − log
nX
i=1
e
xi
 by (∗∗)
=
nX
i=1
yi
log yi +

nX
i=1
yi − 1
 log
nX
i=1
e
xi

=
nX
i=1
yi
log yi since P n
i=1 yi = 1.
Consequently, if f
∗
(y) is defined, then f
∗
(y) = P n
i=1 yi
log yi
. If we agree that 0 log 0 =
0, then it is an easy exercise (or, see Boyd and Vandenberghe [29], Section 3.3, Example
3.25) to show that
f
∗
(y) = (
P
n
i=1 yi
log yi
if 1
> y = 1 and y ≥ 0
∞ otherwise.
Thus we obtain the negative entropy restricted to the domain 1
> y = 1 and y ≥ 0.
If f : R
n → R is convex and differentiable, then x
∗ maximizes x
> y −f(x) iff x
∗ minimizes
−x
> y + f(x) iff
∇fx∗ = y,
and so
f
∗
(y) = (x
∗
)
> ∇fx∗ − f(x
∗
).
Consequently, if we can solve the equation
∇fz = y
for z given y, then we obtain f
∗
(y).
It can be shown that if f is twice differentiable, strictly convex, and surlinear, which
means that
lim
k
yk7→+∞
f(y)
k
yk
= +∞,
50.11. CONJUGATE FUNCTION AND LEGENDRE DUAL FUNCTION 1801
then there is a unique xy such that ∇fxy = y, so that
f
∗
(y) = x
>y ∇fxy − f(xy),
and f
∗
is differentiable with
∇fy
∗ = xy.
We now return to our optimization problem.
Proposition 50.20. Consider Problem (P),
minimize J(v)
subject to Av ≤ b
Cv = d,
with affine inequality and equality constraints (with A an m × n matrix, C an p × n matrix,
b ∈ R
m, d ∈ R
p
). The dual function G(λ, ν) is given by
G(λ, ν) = ( −
−∞
b
> λ − d
> ν − J
∗
(−A> λ − C
> ν) if
otherwise
−A> λ −
,
C
> ν ∈ dom(J
∗
),
for all λ ∈ R
m
+ and all ν ∈ R
p
, where J
∗
is the conjugate of J.
Proof. The Lagrangian associated with the above program is
L(v, λ, ν) = J(v) + (Av − b)
> λ + (Cv − d)
> ν
= −b
> λ − d
> ν + J(v) + (A
> λ + C
> ν)
> v,
with λ ∈ R
m
+ and ν ∈ R
p
. By definition
G(λ, ν) = −b
> λ − d
> ν + inf
v∈Rn
(J(v) + (A
> λ + C
> ν)
> v)
= −b
> λ − d
> ν − sup
v∈Rn
(−(A
> λ + C
> ν)
> v − J(v))
= −b
> λ − d
> ν − J
∗
(−A
> λ − C
> ν).
Therefore, for all λ ∈ R
m
+ and all ν ∈ R
p
, we have
G(λ, ν) = (
−∞
−b
> λ − d
> ν − J
∗
(−A> λ − C
> ν) if
otherwise
−A> λ −
,
C
> ν ∈ dom(J
∗
),
as claimed.
As application of Proposition 50.20, consider the following example.
1802 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
Example 50.9. Consider the following problem:
minimize k vk
subject to Av = b,
where k k is any norm on R
n
. Using the result of Example 50.8(6), we obtain
G(ν) = −b
> ν −
  −A
> ν

∗
,
that is,
G(ν) = ( −
−∞
b
> ν if
otherwise


A> ν

D
.
≤ 1
In the special case where k k = k k 2
, we also have k k D = k k 2
.
Another interesting application is to the entropy minimization problem.
Example 50.10. Consider the following problem known as entropy minimization:
minimize f(x) =
nX
i=1
xi
log xi
subject to Ax ≤ b
1
> x = 1,
where dom(f) = {x ∈ R
n
| x ≥ 0}. By Example 50.8(3), the conjugate of the negative
entropy function u log u is e
v−1
, so we easily see that
f
∗
(y) =
nX
i=1
e
yi−1
,
which is defined on R
n
. Proposition 50.20 implies that the dual function G(λ, µ) of the
entropy minimization problem is given by
G(λ, µ) = −b
> λ − µ − e
−µ−1
nX
i=1
e
−(Ai
)> λ
,
for all λ ∈ R
n
+ and all µ ∈ R, where Ai
is the ith column of A. It follows that the dual
program is:
maximize − b
> λ − µ − e
−µ−1
nX
i=1
e
−(Ai
)> λ
subject to λ ≥ 0.
50.11. CONJUGATE FUNCTION AND LEGENDRE DUAL FUNCTION 1803
We can simplify this problem by maximizing over the variable µ ∈ R. For fixed λ, the
objective function is maximized when the derivative is zero, that is,
−1 + e
−µ−1
nX
i=1
e
−(Ai
)> λ = 0,
which yields
µ = log 
nX
i=1
e
−(Ai
)> λ
 − 1.
By plugging the above value back into the objective function of the dual, we obtain the
following program:
maximize − b
> λ − log 
nX
i=1
e
−(Ai
)> λ

subject to λ ≥ 0.
The entropy minimization problem is another problem for which Theorem 50.18 applies,
and thus can be solved using the dual program. Indeed, the Lagrangian of the primal
program is given by
L(x, λ, µ) =
nX
i−1
xi
log xi + λ
> (Ax − b) + µ(1
> x − 1).
Using the second derivative criterion for convexity, we see that L(x, λ, µ) is strictly convex
for x ∈ R
n
+ and is bounded below, so it has a unique minimum which is obtain by setting
the gradient ∇Lx to zero. We have
∇Lx =


log x1 + 1 + (
.
.
A1
)
> λ + µ
log xn + 1 + (
.
An
)
> λ + µ.


so by setting ∇Lx to 0 we obtain
xi = e
−((An)> λ+µ+1), i = 1, . . . , n. (∗)
By Theorem 50.18, since the objective function is convex and the constraints are affine, if
the primal has a solution then so does the dual, and λ and µ constitute an optimal solution
of the dual, then x = (x1, . . . , xn) given by the equations in (∗) is an optimal solution of the
primal.
Other examples are given in Boyd and Vandenberghe; see [29], Section 5.1.6.
The derivation of the dual function of Problem (SVMh1) from Section 50.5 involves a
similar type of reasoning.
1804 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
Example 50.11. Consider the Hard Margin Problem (SVMh1):
maximize δ
subject to
w
> ui − b ≥ δ i = 1, . . . , p
− w
> vj + b ≥ δ j = 1, . . . , q
k
wk 2 ≤ 1,
which is converted to the following minimization problem:
minimize − 2δ
subject to
w
> ui − b ≥ δ i = 1, . . . , p
− w
> vj + b ≥ δ j = 1, . . . , q
k
wk 2 ≤ 1.
We replaced δ by 2δ because this will make it easier to find a nice geometric interpretation.
Recall from Section 50.5 that Problem (SVMh1) has a an optimal solution iff δ > 0, in which
case k wk = 1.
The corresponding Lagrangian with λ ∈ R
p
+, µ ∈ R
q
+, γ ∈ R
+, is
L(w, b, δ, λ, µ, γ) = −2δ +
p
X
i=1
λi(δ + b − w
> ui) +
q
X
j=1
µj (δ − b + w
> vj ) + γ(k wk 2 − 1)
= w
>
 −
p
X
i=1
λiui +
q
X
j=1
µjvj
 + γ k wk 2 +

p
X
i=1
λi −
q
X
j=1
µj
 b
+
 −2 +
p
X
i=1
λi +
q
X
j=1
µj
 δ − γ.
Next to find the dual function G(λ, µ, γ) we need to minimize L(w, b, δ, λ, µ, γ) with respect
to w, b and δ, so its gradient with respect to w, b and δ must be zero. This implies that
p
X
i=1
λi −
q
X
j=1
µj = 0
−2 +
p
X
i=1
λi +
q
X
j=1
µj = 0,
which yields
p
X
i=1
λi =
q
X
j=1
µj = 1.
50.11. CONJUGATE FUNCTION AND LEGENDRE DUAL FUNCTION 1805
Observe that we did not compute the partial derivative with respect to w because it does
not yield any useful information due to the presence of the term k wk 2
(as opposed to k wk
2
2
).
Our minimization problem is reduced to: find
inf
w,k wk≤1
 
w
>

q
X
j=1
µjvj −
p
X
i=1
λiui
 + γ k wk 2 − γ
!
= −γ − γ inf
w,k wk≤1
 
−w
>
γ
1

q
X
j=1
µjvj −
p
X
i=1
λiui
 + k−wk 2
!
=



−γ if

 
 1
γ

P
q
j=1 µjvj −
P
p
i=1 λiui





D
2
≤ 1
−∞ otherwise
by Example 50.8(6)
=
(
−γ if
 
 P q
j=1 µjvj −
P
p
i=1 λiui


2
≤ γ
−∞ otherwise.
since k k D
2 = k k 2
and γ > 0
It is immediately verified that the above formula is still correct if γ = 0. Therefore
G(λ, µ, γ) = ( −γ if
 
 P q
j=1 µjvj −
P
p
i=1 λiui


2
≤ γ
−∞ otherwise.
Since
 
 P q
j=1 µjvj −
P
p
i=1 λiui


2
≤ γ iff −γ ≤ −
   P q
j=1 µjvj −
P
p
i=1 λiui


2
, the dual pro￾gram, maximizing G(λ, µ, γ), is equivalent to
maximize −


 

q
X
j=1
µjvj −
p
X
i=1
λiui




2
subject to
p
X
i=1
λi = 1, λ ≥ 0
q
X
j=1
µj = 1, µ ≥ 0,
1806 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
equivalently
minimize

 


q
X
j=1
µjvj −
p
X
i=1
λiui




2
subject to
p
X
i=1
λi = 1, λ ≥ 0
q
X
j=1
µj = 1, µ ≥ 0.
Geometrically, P p
i=1 λiui with P p
i=1 λi = 1 and λ ≥ 0 is a convex combination of the uis,
and P q
j=1 µjvj with P q
j=1 µj = 1 and µ ≥ 0 is a convex combination of the vj s, so the dual
program is to minimize the distance between the polyhedron conv(u1, . . . , up) (the convex
hull of the uis) and the polyhedron conv(v1, . . . , vq) (the convex hull of the vj s). Since both
polyhedra are compact, the shortest distance between then is achieved. In fact, there is some
vertex ui such that if P(ui) is its projection onto conv(v1, . . . , vq) (which exists by Hilbert
space theory), then the length of the line segment (ui
, P(ui)) is the shortest distance between
the two polyhedra (and similarly there is some vertex vj such that if P(vj ) is its projection
onto conv(u1, . . . , up) then the length of the line segment (vj
, P(vj )) is the shortest distance
between the two polyhedra).
If the two subsets are separable, in which case Problem (SVMh1) has an optimal solution
δ > 0, because the objective function is convex and the convex constraint k wk 2 ≤ 1 is quali-
fied since δ may be negative, by Theorem 50.17(2) the duality gap is zero, so δ is half of the
minimum distance between the two convex polyhedra conv(u1, . . . , up) and conv(v1, . . . , vq);
see Figure 50.19.
It should be noted that the constraint k wk ≤ 1 yields a formulation of the dual problem
which has the advantage of having a nice geometric interpretation: finding the minimal
distance between the convex polyhedra conv(u1, . . . , up) and conv(v1, . . . , vq). Unfortunately
this formulation is not useful for actually solving the problem. However, if the equivalent
constraint k wk
2
(= w
> w) ≤ 1 is used, then the dual problem is much more useful as a solving
tool.
In Chapter 54 we consider the case where the sets of points {u1, . . . , up} and {v1, . . . , vq}
are not linearly separable.
50.12 Some Techniques to Obtain a More Useful Dual
Program
In some cases, it is advantageous to reformulate a primal optimization problem to obtain a
more useful dual problem. Three different reformulations are proposed in Boyd and Van-
50.12. SOME TECHNIQUES TO OBTAIN A MORE USEFUL DUAL PROGRAM 1807
u
u
u
u
u
u
1
2
3
4
p
i
v
v
v
v1
2
3
p
Figure 50.19: In R
2
the convex hull of the uis, namely the blue hexagon, is separated from
the convex hull of the vj s, i.e. the red square, by the purple hyperplane (line) which is
the perpendicular bisector to the blue line segment between ui and v1, where this blue line
segment is the shortest distance between the two convex polygons.
denberghe; see [29], Section 5.7:
(1) Introducing new variables and associated equality constraints.
(2) Replacing the objective function with an increasing function of the the original func￾tion.
(3) Making explicit constraints implicit, that is, incorporating them into the domain of
the objective function.
We only give illustrations of (1) and (2) and refer the reader to Boyd and Vandenberghe
[29] (Section 5.7) for more examples of these techniques.
Consider the unconstrained program:
minimize f(Ax + b),
where A is an m × n matrix and b ∈ R
m. While the conditions for a zero duality gap are
satisfied, the Lagrangian is
L(x) = f(Ax + b),
so the dual function G is the constant function whose value is
G = inf
x∈Rn
f(Ax + b),
which is not useful at all.
1808 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
Let us reformulate the problem as
minimize f(y)
subject to
Ax + b = y,
where we introduced the new variable y ∈ R
m and the equality constraint Ax + b = y. The
two problems are obviously equivalent. The Lagrangian of the reformulated problem is
L(x, y, µ) = f(y) + µ
> (Ax + b − y)
where µ ∈ R
m. To find the dual function G(µ) we minimize L(x, y, µ) over x and y. Mini￾mizing over x we see that G(µ) = −∞ unless A> µ = 0, in which case we are left with
G(µ) = b
> µ + inf
y
(f(y) − µ
> y) = b
> µ − inf
y
(µ
> y − f(y)) = b
> µ − f
∗
(µ),
where f
∗
is the conjugate of f. It follows that the dual program can be expressed as
maximize b
> µ − f
∗
(µ)
subject to
A
> µ = 0.
This formulation of the dual is much more useful than the dual of the original program.
Example 50.12. As a concrete example, consider the following unconstrained program:
minimize f(x) = log
nX
i=1
e
(Ai
)> x+bi

where Ai
is a column vector in R
n
. We reformulate the problem by introducing new variables
and equality constraints as follows:
minimize f(y) = log
nX
i=1
e
yi

subject to
Ax + b = y,
where A is the n × n matrix whose columns are the vectors Ai and b = (b1, . . . , bn). Since
by Example 50.8(8), the conjugate of the log-sum-exp function f(y) = log P n
i=1 e
yi

is
