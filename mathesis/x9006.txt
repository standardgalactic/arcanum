i dt.
39.7. TAYLOR’S FORMULA, FAA DI BRUNO’S FORMULA ` 1447
The advantage of the above formula is that it gives an explicit remainder. We now
examine briefly the situation where E is of finite dimension n, and (a0,(e1, . . . , en)) is a
frame for E. In this case, we get a more explicit expression for the expression
k=m X
i=0
k
1
!
D
k
f(a)(h
k
)
involved in all versions of Taylor’s formula, where by convention, D0
f(a)(h
0
) = f(a). If
h = h1e1 + · · · + hnen, then we have
k=m X
k=0
k
1
!
D
k
f(a)(h
k
) = X
k1+···+kn≤m
h
k
1
1
· · · h
k
n
n
k1! · · · kn!
 ∂x
∂
1

k1
· · ·  ∂x
∂
n

kn
f(a),
which, using the abbreviated notation introduced at the end of Section 39.6, can also be
written as
k=m X
k=0
k
1
!
D
k
f(a)(h
k
) = X
|α|≤m
h
α
α!
∂
α
f(a).
The advantange of the above notation is that it is the same as the notation used when
n = 1, i.e., when E = R (or E = C). Indeed, in this case, the Taylor–MacLaurin formula
reads as:
f(a + h) = f(a) + h
1!D
1
f(a) + · · · +
h
m
m!
D
mf(a) + h
m+1
(m + 1)!D
m+1f(a + θh),
for some θ ∈ R, with 0 < θ < 1, where Dk
f(a) is the value of the k-th derivative of f at
a (and thus, as we have already said several times, this is the kth-order vector derivative,
which is just a scalar, since F = R).
In the above formula, the assumptions are that f : [a, a + h] → R is a C
m-function on
[a, a + h], and that Dm+1f(x) exists for every x ∈ (a, a + h).
Taylor’s formula is useful to study the local properties of curves and surfaces. In the case
of a curve, we consider a function f : [r, s] → F from a closed interval [r, s] of R to some
affine space F, the derivatives Dk
f(a)(h
k
) correspond to vectors h
kDk
f(a), where Dk
f(a) is
the kth vector derivative of f at a (which is really Dk
f(a)(1, . . . , 1)), and for any a ∈ (r, s),
Theorem 39.23 yields the following formula:
f(a + h) = f(a) + h
1!D
1
f(a) + · · · +
h
m
m!
D
mf(a) + h
m (h),
for any h such that a + h ∈ (r, s), and where limh→0, h6=0  (h) = 0.
In the case of functions f : R
n → R, it is convenient to have formulae for the Taylor–
Young formula and the Taylor–MacLaurin formula in terms of the gradient and the Hessian.
1448 CHAPTER 39. DIFFERENTIAL CALCULUS
Recall that the gradient ∇f(a) of f at a ∈ R
n
is the column vector
∇f(a) =


∂x
∂f
1
(a)
∂f
∂x2
(a)
.
.
.
∂f
∂xn
(a)


,
and that
f
0 (a)(u) = Df(a)(u) = ∇f(a) · u,
for any u ∈ R
n
(where · means inner product). The above equation shows that the direction
of the gradient ∇f(a) is the direction of maximal increase of the function f at a and that
k∇
why methods of “gradient descent” pick the direction
f(a)k is the rate of change of f in its direction of maximal increase
opposite to the gradient (we are trying
. This is the reason
to minimize f).
The Hessian matrix ∇2
f(a) of f at a ∈ R
n
is the n × n symmetric matrix
∇2
f(a) =


∂
2
f
∂x2
1
(a)
∂
2
f
∂x1∂x2
(a) . . .
∂
2
f
∂x1∂xn
(a)
∂
2
f
∂x1∂x2
(a)
∂
2
f
∂x2
2
(a) . . .
∂
2
f
∂x2∂xn
(a)
.
.
.
.
.
.
.
.
.
.
.
.
∂
2
f
∂x1∂xn
(a)
∂
2
f
∂x2∂xn
(a) . . .
∂
2
f
∂x2
n
(a)


,
and we have
D
2
f(a)(u, v) = u
> ∇2
f(a) v = u · ∇2
f(a)v = ∇2
f(a)u · v,
for all u, v ∈ R
n
. Then, we have the following three formulations of the formula of Taylor–
Young of order 2:
f(a + h) = f(a) + Df(a)(h) + 1
2
D
2
f(a)(h, h) + k hk
2

(h)
f(a + h) = f(a) + ∇f(a) · h +
1
2
(h · ∇2
f(a)h) + (h · h) (h)
f(a + h) = f(a) + (∇f(a))> h +
1
2
(h
> ∇2
f(a) h) + (h
> h) (h).
with limh7→0  (h) = 0.
One should keep in mind that only the first formula is intrinsic (i.e., does not depend on
the choice of a basis), whereas the other two depend on the basis and the inner product chosen
39.8. VECTOR FIELDS, COVARIANT DERIVATIVES, LIE BRACKETS 1449
on R
n
. As an exercise, the reader should write similar formulae for the Taylor–MacLaurin
formula of order 2.
Another application of Taylor’s formula is the derivation of a formula which gives the m￾th derivative of the composition of two functions, usually known as “Fa`a di Bruno’s formula.”
This formula is useful when dealing with geometric continuity of splines curves and surfaces.
Proposition 39.27. Given any normed affine space E, for any function f : R → R and any
function g : R → E, for any a ∈ R, letting b = f(a), f
(i)
(a) = Di
f(a), and g
(i)
(b) = Di
g(b),
for any m ≥ 1, if f
(i)
(a) and g
(i)
(b) exist for all i, 1 ≤ i ≤ m, then (g◦f)
(m)
(a) = Dm(g◦f)(a)
exists and is given by the following formula:
(g ◦ f)
(m)
(a) = X
0≤j≤m
X i1+i2+···+im=j
i1+2i2+···+mim=m
i1,i2,··· ,im≥0
m!
i1! · · · im!
g
(j)
(b)

f
(1)
1!
(a)

i1
· · · 
f
(m)
(a)
m!

im
.
When m = 1, the above simplifies to the familiar formula
(g ◦ f)
0 (a) = g
0 (b)f
0 (a),
and for m = 2, we have
(g ◦ f)
(2)(a) = g
(2)(b)(f
(1)(a))2 + g
(1)(b)f
(2)(a).
39.8 Vector Fields, Covariant Derivatives, Lie Brack￾ets
In this section, we briefly consider vector fields and covariant derivatives of vector fields.
Such derivatives play an important role in continuous mechanics. Given a normed affine
space (E,
−→E ), a vector field over (E,
−→E ) is a function X : E →
−→E . Intuitively, a vector field
assigns a vector to every point in E. Such vectors could be forces, velocities, accelerations,
etc.
Given two vector fields X, Y defined on some open subset Ω of E, for every point a ∈ Ω,
we would like to define the derivative of X with respect to Y at a. This is a type of directional
derivative that gives the variation of X as we move along Y , and we denote it by DY X(a).
The derivative DY X(a) is defined as follows.
Definition 39.20. Let (E,
−→E ) be a normed affine space. Given any open subset Ω of E,
given any two vector fields X and Y defined over Ω, for any a ∈ Ω, the covariant derivative
(or Lie derivative) of X w.r.t. the vector field Y at a, denoted by DY X(a), is the limit (if it
exists)
lim
t→0, t∈U
X(a + tY (a)) − X(a)
t
,
where U = {t ∈ R | a + tY (a) ∈ Ω, t 6 = 0}.
1450 CHAPTER 39. DIFFERENTIAL CALCULUS
If Y is a constant vector field, it is immediately verified that the map
X 7→ DY X(a)
is a linear map called the derivative of the vector field X, and denoted by DX(a). If
f : E → R is a function, we define DY f(a) as the limit (if it exists)
lim
t→0, t∈U
f(a + tY (a)) − f(a)
t
,
where U = {t ∈ R | a + tY (a) ∈ Ω, t 6 = 0}. It is the directional derivative of f w.r.t. the
vector field Y at a, and it is also often denoted by Y (f)(a), or Y (f)a.
From now on, we assume that all the vector fields and all the functions under considera￾tion are smooth (C
∞). The set C
∞(Ω) of smooth C
∞-functions f : Ω → R is a ring. Given a
smooth vector field X and a smooth function f (both over Ω), the vector field fX is defined
such that (fX)(a) = f(a)X(a), and it is immediately verified that it is smooth. Thus, the
set X (Ω) of smooth vector fields over Ω is a C
∞(Ω)-module.
The following proposition is left as an exercise. It shows that DY X(a) is a R-bilinear
map on X (Ω), is C
∞(Ω)-linear in Y , and satisfies the Leibniz derivation rules with respect
to X.
Proposition 39.28. The covariant derivative DY X(a) satisfies the following properties:
D(Y1+Y2)X(a) = DY1X(a) + DY2X(a),
DfY X(a) = f(a)DY X(a),
DY (X1 + X2)(a) = DY X1(a) + DY X2(a),
DY fX(a) = DY f(a)X(a) + f(a)DY X(a),
where X, Y, X1, X2, Y1, Y2 are smooth vector fields over Ω, and f : E → R is a smooth func￾tion.
In differential geometry, the above properties are taken as the axioms of affine connec￾tions, in order to define covariant derivatives of vector fields over manifolds. In many cases,
the vector field Y is the tangent field of some smooth curve γ : ] − η, η[→ E. If so, the
following proposition holds.
Proposition 39.29. Given a smooth curve γ : ] − η, η[→ E, letting Y be the vector field
defined on γ(] − η, η[) such that
Y (γ(u)) = dγ
dt (u),
for any vector field X defined on γ(] − η, η[), we have
DY X(a) = dt
d

X(γ(t)) (0),
where a = γ(0).
39.9. FUTHER READINGS 1451
The derivative DY X(a) is thus the derivative of the vector field X along the curve γ, and
it is called the covariant derivative of X along γ.
Given an affine frame (O,(u1, . . . , un)) for (E,
−→E ), it is easily seen that the covariant
derivative DY X(a) is expressed as follows:
DY X(a) =
nX
i=1
nX
j=1

Yj
∂X
∂xj
i

(a)ei
.
Generally, DY X(a) 6 = DXY (a). The quantity
[X, Y ] = DXY − DY X
is called the Lie bracket of the vector fields X and Y . The Lie bracket plays an important
role in differential geometry. In terms of coordinates,
[X, Y ] =
nX
i=1
nX
j=1

Xj
∂Yi
∂xj
− Yj
∂Xi
∂xj

ei
.
39.9 Futher Readings
A thorough treatment of differential calculus can be found in Munkres [130], Lang [112],
Schwartz [151], Cartan [34], and Avez [9]. The techniques of differential calculus have many
applications, especially to the geometry of curves and surfaces and to differential geometry
in general. For this, we recommend do Carmo [52, 53] (two beautiful classics on the subject),
Kreyszig [106], Stoker [166], Gray [81], Berger and Gostiaux [13], Milnor [126], Lang [110],
Warner [186] and Choquet-Bruhat [38].
39.10 Summary
The main concepts and results of this chapter are listed below:
• Directional derivative (Duf(a)).
• Total derivative, Fr´echet derivative, derivative, total differential, differential
(df(a), dfa).
• Partial derivatives.
• Affine functions.
• The chain rule.
• Jacobian matrices (J(f)(a)), Jacobians.
1452 CHAPTER 39. DIFFERENTIAL CALCULUS
• Gradient of a function (grad f(a), ∇f(a)).
• Mean value theorem.
• C
0
-functions, C
1
-functions.
• The implicit function theorem.
• Local homeomorphisms, local diffeomorphisms, diffeomorphisms.
• The inverse function theorem.
• Immersions, submersions.
• Second-order and higher-order derivatives.
• Schwarz’s lemma.
• Hessian matrix .
• C
∞-functions, smooth functions.
• Taylor–Young’s formula.
• Generalized mean value theorem.
• Taylor–MacLaurin’s formula.
• Taylor’s formula with integral remainder .
• Fa`a di Bruno’s formula.
39.11 Problems
Problem 39.1. Let f : Mn(R) → Mn(R) be the function defined on n × n matrices by
f(A) = A
2
.
Prove that
DfA(H) = AH + HA,
for all A, H ∈ Mn(R).
Problem 39.2. Let f : Mn(R) → Mn(R) be the function defined on n × n matrices by
f(A) = A
3
.
Prove that
DfA(H) = A
2H + AHA + HA2
,
for all A, H ∈ Mn(R).
39.11. PROBLEMS 1453
Problem 39.3. If f : Mn(R) → Mn(R) and g : Mn(R) → Mn(R) are differentiable matrix
functions, prove that
d(fg)A(B) = dfA(B)g(A) + f(A)dgA(B),
for all A, B ∈ Mn(R).
Problem 39.4. Recall that so(3) denotes the vector space of real skew-symmetric n × n
matrices (B> = −B). Let C : so(n) → Mn(R) be the function given by
C(B) = (I − B)(I + B)
−1
.
(1) Prove that if B is skew-symmetric, then I − B and I + B are invertible, and so C is
well-defined. Prove that
(2) Prove that
dC(B)(A) = −[I + (I − B)(I + B)
−1
]A(I + B)
−1 = −2(I + B)
−1A(I + B)
−1
.
(3) Prove that dC(B) is injective for every skew-symmetric matrix B.
Problem 39.5. Prove that
d
mCB(H1, . . . , Hm)
= 2(−1)m X
π∈Sm
(I + B)
−1Hπ(1)(I + B)
−1Hπ(2)(I + B)
−1
· · ·(I + B)
−1Hπ(m)(I + B)
−1
.
Problem 39.6. Consider the function g defined for all A ∈ GL(n, R), that is, all n × n real
invertible matrices, given by
g(A) = det(A).
(1) Prove that
dgA(X) = det(A)tr(A
−1X),
for all n × n real matrices X.
(2) Consider the function f defined for all A ∈ GL+
(n, R), that is, n × n real invertible
matrices of positive determinants, given by
f(A) = log g(A) = log det(A).
Prove that
dfA(X) = tr(A
−1X)
D
2
f(A)(X1, X2) = −tr(A
−1X1A
−1X2),
for all n × n real matrices X, X1, X2.
(3) Prove that
D
mf(A)(X1, . . . , Xm) = (−1)m−1 X
σ∈Sm−1
tr(A
−1X1A
−1Xσ(1)+1A
−1Xσ(2)+1 · · · A
−1Xσ(m−1)+1)
for any m ≥ 1, where X1, . . . Xm are any n × n real matrices.
1454 CHAPTER 39. DIFFERENTIAL CALCULUS
Part VI
Preliminaries for Optimization Theory
1455
Chapter 40
Extrema of Real-Valued Functions
This chapter deals with extrema of real-valued functions. In most optimization problems,
we need to find necessary conditions for a function J : Ω → R to have a local extremum with
respect to a subset U of Ω (where Ω is open). This can be done in two cases:
(1) The set U is defined by a set of equations,
U = {x ∈ Ω | ϕi(x) = 0, 1 ≤ i ≤ m},
where the functions ϕi
: Ω → R are continuous (and usually differentiable).
(2) The set U is defined by a set of inequalities,
U = {x ∈ Ω | ϕi(x) ≤ 0, 1 ≤ i ≤ m},
where the functions ϕi
: Ω → R are continuous (and usually differentiable).
In (1), the equations ϕi(x) = 0 are called equality constraints, and in (2), the inequalities
ϕi(x) ≤ 0 are called inequality constraints. The case of equality constraints is much easier
to deal with and is treated in this chapter.
If the functions ϕi are convex and Ω is convex, then U is convex. This is a very important
case that we discuss later. In particular, if the functions ϕi are affine, then the equality
constraints can be written as Ax = b, and the inequality constraints as Ax ≤ b, for some
m × n matrix A and some vector b ∈ R
m. We will also discuss the case of affine constraints
later.
In the case of equality constraints, a necessary condition for a local extremum with respect
to U can be given in terms of Lagrange multipliers. In the case of inequality constraints, there
is also a necessary condition for a local extremum with respect to U in terms of generalized
Lagrange multipliers and the Karush–Kuhn–Tucker conditions. This will be discussed in
Chapter 50.
1457
1458 CHAPTER 40. EXTREMA OF REAL-VALUED FUNCTIONS
40.1 Local Extrema, Constrained Local Extrema, and
Lagrange Multipliers
Let J : E → R be a real-valued function defined on a normed vector space E (or more
generally, any topological space). Ideally we would like to find where the function J reaches
a minimum or a maximum value, at least locally. In this chapter we will usually use the
notations dJ(u) or J
0 (u) (or dJu or Ju
0
) for the derivative of J at u, instead of DJ(u). Our
presentation follows very closely that of Ciarlet [41] (Chapter 7), which we find to be one of
the clearest.
Definition 40.1. If J : E → R is a real-valued function defined on a normed vector space
E, we say that J has a local minimum (or relative minimum) at the point u ∈ E if there is
some open subset W ⊆ E containing u such that
J(u) ≤ J(w) for all w ∈ W .
Similarly, we say that J has a local maximum (or relative maximum) at the point u ∈ E if
there is some open subset W ⊆ E containing u such that
J(u) ≥ J(w) for all w ∈ W .
In either case, we say that J has a local extremum (or relative extremum) at u. We say
that J has a strict local minimum (resp. strict local maximum) at the point u ∈ E if there
is some open subset W ⊆ E containing u such that
J(u) < J(w) for all w ∈ W − {u}
(resp.
J(u) > J(w) for all w ∈ W − {u}).
By abuse of language, we often say that the point u itself “is a local minimum” or a
“local maximum,” even though, strictly speaking, this does not make sense.
We begin with a well-known necessary condition for a local extremum.
Proposition 40.1. Let E be a normed vector space and let J : Ω → R be a function, with
Ω some open subset of E. If the function J has a local extremum at some point u ∈ Ω and
if J is differentiable at u, then
dJu = J
0 (u) = 0.
Proof. Pick any v ∈ E. Since Ω is open, for t small enough we have u + tv ∈ Ω, so there is
an open interval I ⊆ R such that the function ϕ given by
ϕ(t) = J(u + tv)
40.1. LOCAL EXTREMA AND LAGRANGE MULTIPLIERS 1459
for all t ∈ I is well-defined. By applying the chain rule, we see that ϕ is differentiable at
t = 0, and we get
ϕ
0 (0) = dJu(v).
Without loss of generality, assume that u is a local minimum. Then we have
ϕ
0 (0) = limt7→0−
ϕ(t) − ϕ(0)
t
≤ 0
and
ϕ
0 (0) = limt7→0+
ϕ(t) − ϕ(0)
t
≥ 0,
which shows that ϕ
0 (0) = dJu(v) = 0. As v ∈ E is arbitrary, we conclude that dJu = 0.
Definition 40.2. A point u ∈ Ω such that J
0 (u) = 0 is called a critical point of J.
If E = R
n
, then the condition dJu = 0 is equivalent to the system
∂J
∂x1
(u1, . . . , un) = 0
.
.
.
∂J
∂xn
(u1, . . . , un) = 0.

The condition of Proposition 40.1 is only a necessary condition for the existence of an
extremum, but not a sufficient condition.
Here are some counter-examples. If f : R → R is the function given by f(x) = x
3
, since
f
0 (x) = 3x
2
, we have f
0 (0) = 0, but 0 is neither a minimum nor a maximum of f as evidenced
by the graph shown in Figure 40.1.
Figure 40.1: The graph of f(x) = x
3
. Note that x = 0 is a saddle point and not a local
extremum.
1460 CHAPTER 40. EXTREMA OF REAL-VALUED FUNCTIONS
If g : R
2 → R is the function given by g(x, y) = x
2 − y
2
, then g(
0x,y) = (2x − 2y), so
g(0
0,0) = (0 0), yet near (0, 0) the function g takes negative and positive values. See Figure
40.2.
Figure 40.2: The graph of g(x, y) = x
2 − y
2
. Note that (0, 0) is a saddle point and not a
local extremum.

It is very important to note that the hypothesis that Ω is open is crucial for the validity
of Proposition 40.1.
For example, if J is the identity function on R and U = [0, 1], a closed subset, then
J
0 (x) = 1 for all x ∈ [0, 1], even though J has a minimum at x = 0 and a maximum at x = 1.
In many practical situations, we need to look for local extrema of a function J under
additional constraints. This situation can be formalized conveniently as follows. We have a
function J : Ω → R defined on some open subset Ω of a normed vector space, but we also
have some subset U of Ω, and we are looking for the local extrema of J with respect to the
set U.
The elements u ∈ U are often called feasible solutions of the optimization problem con￾sisting in finding the local extrema of some objective function J with respect to some subset
U of Ω defined by a set of constraints. Note that in most cases, U is not open. In fact, U is
usually closed.
Definition 40.3. If J : Ω → R is a real-valued function defined on some open subset Ω of a
normed vector space E and if U is some subset of Ω, we say that J has a local minimum (or
relative minimum) at the point u ∈ U with respect to U if there is some open subset W ⊆ Ω
containing u such that
J(u) ≤ J(w) for all w ∈ U ∩ W .
40.1. LOCAL EXTREMA AND LAGRANGE MULTIPLIERS 1461
Similarly, we say that J has a local maximum (or relative maximum) at the point u ∈ U
with respect to U if there is some open subset W ⊆ Ω containing u such that
J(u) ≥ J(w) for all w ∈ U ∩ W .
In either case, we say that J has a local extremum at u with respect to U.
In order to find necessary conditions for a function J : Ω → R to have a local extremum
with respect to a subset U of Ω (where Ω is open), we need to somehow incorporate the
definition of U into these conditions. This can be done in two cases:
(1) The set U is defined by a set of equations,
U = {x ∈ Ω | ϕi(x) = 0, 1 ≤ i ≤ m},
where the functions ϕi
: Ω → R are continuous (and usually differentiable).
(2) The set U is defined by a set of inequalities,
U = {x ∈ Ω | ϕi(x) ≤ 0, 1 ≤ i ≤ m},
where the functions ϕi
: Ω → R are continuous (and usually differentiable).
In (1), the equations ϕi(x) = 0 are called equality constraints, and in (2), the inequalities
ϕi(x) ≤ 0 are called inequality constraints.
An inequality constraint of the form ϕi(x) ≥ 0 is equivalent to the inequality constraint
−ϕx(x) ≤ 0. An equality constraint ϕi(x) = 0 is equivalent to the conjunction of the
two inequality constraints ϕi(x) ≤ 0 and −ϕi(x) ≤ 0, so the case of inequality constraints
subsumes the case of equality constraints. However, the case of equality constraints is easier
to deal with, and in this chapter we will restrict our attention to this case.
If the functions ϕi are convex and Ω is convex, then U is convex. This is a very important
case that we will discuss later. In particular, if the functions ϕi are affine, then the equality
constraints can be written as Ax = b, and the inequality constraints as Ax ≤ b, for some
m × n matrix A and some vector b ∈ R
m. We will also discuss the case of affine constraints
later.
In the case of equality constraints, a necessary condition for a local extremum with respect
to U can be given in terms of Lagrange multipliers. In the case of inequality constraints, there
is also a necessary condition for a local extremum with respect to U in terms of generalized
Lagrange multipliers and the Karush–Kuhn–Tucker conditions. This will be discussed in
Chapter 50.
We begin by considering the case where Ω ⊆ E1 × E2 is an open subset of a product of
normed vector spaces and where U is the zero locus of some continuous function ϕ: Ω → E2,
which means that
U = {(u1, u2) ∈ Ω | ϕ(u1, u2) = 0}.
1462 CHAPTER 40. EXTREMA OF REAL-VALUED FUNCTIONS
For the sake of brevity, we say that J has a constrained local extremum at u instead of saying
that J has a local extremum at the point u ∈ U with respect to U.
In most applications, we have E1 = R
n−m and E2 = R
m for some integers m, n such that
1 ≤ m < n, Ω is an open subset of R
n
, J : Ω → R, and we have m functions ϕi
: Ω → R
defining the subset
U = {v ∈ Ω | ϕi(v) = 0, 1 ≤ i ≤ m}.
Fortunately, there is a necessary condition for constrained local extrema in terms of
Lagrange multipliers.
Theorem 40.2. (Necessary condition for a constrained extremum in terms of Lagrange
multipliers) Let Ω be an open subset of R
n
, consider m C1
-functions ϕi
: Ω → R (with
1 ≤ m < n), let
U = {v ∈ Ω | ϕi(v) = 0, 1 ≤ i ≤ m},
and let u ∈ U be a point such that the derivatives dϕi(u) ∈ L(R
n
; R) are linearly independent;
equivalently, assume that the m × n matrix ￾ (∂ϕi/∂xj )(u)
 has rank m. If J : Ω → R is a
function which is differentiable at u ∈ U and if J has a local constrained extremum at u,
then there exist m numbers λi(u) ∈ R, uniquely defined, such that
dJ(u) + λ1(u)dϕ1(u) + · · · + λm(u)dϕm(u) = 0;
equivalently,
∇J(u) + λ1(u)∇ϕ1(u) + · · · + λm(u)∇ϕm(u) = 0.
Theorem 40.2 will be proven as a corollary of Theorem 40.4, which gives a more general
formulation that applies to the situation where E1 is an infinite-dimensional Banach space.
To simplify the exposition we postpone a discussion of this theorem until we have presented
several examples illustrating the method of Lagrange multipliers.
Definition 40.4. The numbers λi(u) involved in Theorem 40.2 are called the Lagrange
multipliers associated with the constrained extremum u (again, with some minor abuse of
language).
The linear independence of the linear forms dϕi(u) is equivalent to the fact that the
Jacobian matrix ￾ (∂ϕi/∂xj )(u)
 of ϕ = (ϕ1, . . . , ϕm) at u has rank m. If m = 1, the linear
independence of the dϕi(u) reduces to the condition ∇ϕ1(u) 6 = 0.
A fruitful way to reformulate the use of Lagrange multipliers is to introduce the notion
of the Lagrangian associated with our constrained extremum problem.
Definition 40.5. The Lagrangian associated with our constrained extremum problem is the
function L: Ω × R
m → R given by
L(v, λ) = J(v) + λ1ϕ1(v) + · · · + λmϕm(v),
with λ = (λ1, . . . , λm).
40.1. LOCAL EXTREMA AND LAGRANGE MULTIPLIERS 1463
We have the following simple but important proposition.
Proposition 40.3. There exists some µ = (µ1, . . . , µm) and some u ∈ U such that
dJ(u) + µ1dϕ1(u) + · · · + µmdϕm(u) = 0
if and only if
dL(u, µ) = 0,
or equivalently
∇L(u, µ) = 0;
that is, iff (u, µ) is a critical point of the Lagrangian L.
Proof. Indeed dL(u, µ) = 0 is equivalent to
∂L
∂v (u, µ) = 0
∂L
∂λ1
(u, µ) = 0
.
.
.
∂L
∂λm
(u, µ) = 0,
and since
∂L
∂v (u, µ) = dJ(u) + µ1dϕ1(u) + · · · + µmdϕm(u)
and
∂L
∂λi
(u, µ) = ϕi(u),
we get
dJ(u) + µ1dϕ1(u) + · · · + µmdϕm(u) = 0
and
ϕ1(u) = · · · = ϕm(u) = 0,
that is, u ∈ U. The converse is proven in a similar fashion (essentially by reversing the
argument).
If we write out explicitly the condition
dJ(u) + µ1dϕ1(u) + · · · + µmdϕm(u) = 0,
1464 CHAPTER 40. EXTREMA OF REAL-VALUED FUNCTIONS
we get the n × m system
∂J
∂x1
(u) + λ1
∂ϕ1
∂x1
(u) + · · · + λm
∂ϕm
∂x1
(u) = 0
.
.
.
∂J
∂xn
(u) + λ1
∂ϕ1
∂xn
(u) + · · · + λm
∂ϕm
∂xn
(u) = 0,
and it is important to note that the matrix of this system is the transpose of the Jacobian
matrix of ϕ at u. If we write Jac(ϕ)(u) = ￾ (∂ϕi/∂xj )(u)
 for the Jacobian matrix of ϕ (at
u), then the above system is written in matrix form as
∇J(u) + (Jac(ϕ)(u))> λ = 0,
where λ is viewed as a column vector, and the Lagrangian is equal to
L(u, λ) = J(u) + (ϕ1(u), . . . , ϕm(u))λ.
The beauty of the Lagrangian is that the constraints {ϕi(v) = 0} have been incorporated
into the function L(v, λ), and that the necessary condition for the existence of a constrained
local extremum of J is reduced to the necessary condition for the existence of a local ex￾tremum of the unconstrained L.
However, one should be careful to check that the assumptions of Theorem 40.2 are sat￾isfied (in particular, the linear independence of the linear forms dϕi).
Example 40.1. For example, let J : R
3 → R be given by
J(x, y, z) = x + y + z
2
and g : R
3 → R by
g(x, y, z) = x
2 + y
2
.
Since g(x, y, z) = 0 iff x = y = 0, we have U = {(0, 0, z) | z ∈ R} and the restriction of J to
U is given by
J(0, 0, z) = z
2
,
which has a minimum for z = 0. However, a “blind” use of Lagrange multipliers would
require that there is some λ so that
∂J
∂x (0, 0, z) = λ
∂g
∂x(0, 0, z),
∂J
∂y (0, 0, z) = λ
∂g
∂y (0, 0, z),
∂J
∂z (0, 0, z) = λ
∂g
∂z (0, 0, z),
and since
∂g
∂x(x, y, z) = 2x,
∂g
∂y (x, y, z) = 2y,
∂g
∂z (0, 0, z) = 0,
40.1. LOCAL EXTREMA AND LAGRANGE MULTIPLIERS 1465
the partial derivatives above all vanish for x = y = 0, so at a local extremum we should also
have
∂J
∂x (0, 0, z) = 0,
∂J
∂y (0, 0, z) = 0,
∂J
∂z (0, 0, z) = 0,
but this is absurd since
∂J
∂x (x, y, z) = 1,
∂J
∂y (x, y, z) = 1,
∂J
∂z (x, y, z) = 2z.
The reader should enjoy finding the reason for the flaw in the argument.
One should also keep in mind that Theorem 40.2 gives only a necessary condition. The
(u, λ) may not correspond to local extrema! Thus, it is always necessary to analyze the local
behavior of J near a critical point u. This is generally difficult, but in the case where J is
affine or quadratic and the constraints are affine or quadratic, this is possible (although not
always easy).
Example 40.2. Let us apply the above method to the following example in which E1 = R,
E2 = R, Ω = R
2
, and
J(x1, x2) = −x2
ϕ(x1, x2) = x
2
1 + x
2
2 − 1.
Observe that
U = {(x1, x2) ∈ R
2
| x
2
1 + x
2
2 = 1}
is the unit circle, and since
∇ϕ(x1, x2) =  2
2
x
x
1
2

,
it is clear that ∇ϕ(x1, x2) 6 = 0 for every point = (x1, x2) on the unit circle. If we form the
Lagrangian
L(x1, x2, λ) = −x2 + λ(x
2
1 + x
2
2 − 1),
Theorem 40.2 says that a necessary condition for J to have a constrained local extremum is
that ∇L(x1, x2, λ) = 0, so the following equations must hold:
2λx1 = 0
−1 + 2λx2 = 0
x
2
1 + x
2
2 = 1.
The second equation implies that λ 6 = 0, and then the first yields x1 = 0, so the third yields
x2 = ±1, and we get two solutions:
λ =
1
2
, (x1, x2) = (0, 1)
λ = −
1
2
, (x
01
, x02
) = (0, −1).
1466 CHAPTER 40. EXTREMA OF REAL-VALUED FUNCTIONS
We can check immediately that the first solution is a minimum and the second is a maximum.
The reader should look for a geometric interpretation of this problem.
Example 40.3. Let us now consider the case in which J is a quadratic function of the form
J(v) = 1
2
v
> Av − v
> b,
where A is an n × n symmetric matrix, b ∈ R
n
, and the constraints are given by a linear
system of the form
Cv = d,
where C is an m × n matrix with m < n and d ∈ R
m. We also assume that C has rank m.
In this case the function ϕ is given by
ϕ(v) = (Cv − d)
> ,
because we view ϕ(v) as a row vector (and v as a column vector), and since
dϕ(v)(w) = C
> w,
the condition that the Jacobian matrix of ϕ at u have rank m is satisfied. The Lagrangian
of this problem is
L(v, λ) = 1
2
v
> Av − v
> b + (Cv − d)
> λ =
1
