u
.
n


.
Lemma 7.4. Let f : E × . . . × E → F be an n-linear alternating map. Let (u1, . . . , un) and
(v1, . . . , vn) be two families of n vectors, such that,
v1 = a1 1u1 + · · · + an 1un,
. . .
vn = a1 nu1 + · · · + an nun.
Equivalently, letting
A =


a1 1 a1 2 . . . a1 n
a2 1 a2 2 . . . a2 n
.
.
.
.
.
.
.
.
.
.
.
.
an 1 an 2 . . . an n


,
214 CHAPTER 7. DETERMINANTS
assume that we have


v
v
1
2
.
.
v
.
n


= A
>


u1
u2
.
u
.
.
n


.
Then,
f(v1, . . . , vn) =  X
π∈Sn

(π)aπ(1) 1 · · · aπ(n) n
 f(u1, . . . , un),
where the sum ranges over all permutations π on {1, . . . , n}.
Proof. Expanding f(v1, . . . , vn) by multilinearity, we get a sum of terms of the form
aπ(1) 1 · · · aπ(n) nf(uπ(1), . . . , uπ(n)),
for all possible functions π : {1, . . . , n} → {1, . . . , n}. However, because f is alternating, only
the terms for which π is a permutation are nonzero. By Proposition 7.1, every permutation
π is a product of transpositions, and by Proposition 7.2, the parity  (π) of the number of
transpositions only depends on π. Then applying Proposition 7.3 (3) to each transposition
in π, we get
aπ(1) 1 · · · aπ(n) nf(uπ(1), . . . , uπ(n)) =  (π)aπ(1) 1 · · · aπ(n) nf(u1, . . . , un).
Thus, we get the expression of the lemma.
For the case of n = 2, the proof details of Lemma 7.4 become
f(v1, v2) = f(a11u1 + a21u2, a12u1 + a22u2)
= f(a11u1 + a21u2, a12u1) + f(a11u1 + a21u2, a22u2)
= f(a11u1, a12u1) + f(a21u2, a12u1) + f(a11ua, a22u2) + f(a21u2, a22u2)
= a11a12f(u1, u1) + a21a12f(u2, u1) + a11a22f(u1, u2) + a21a22f(u2, u2)
= a21a12f(u2, u1)a11a22f(u1, u2)
= (a11a22 − a12a22) f(u1, u2).
Hopefully the reader will recognize the quantity a11a22 − a12a22. It is the determinant of the
2 × 2 matrix
A =

a11 a12
a21 a22
.
This is no accident. The quantity
det(A) = X
π∈Sn

(π)aπ(1) 1 · · · aπ(n) n
7.3. DEFINITION OF A DETERMINANT 215
is in fact the value of the determinant of A (which, as we shall see shortly, is also equal to the
determinant of A> ). However, working directly with the above definition is quite awkward,
and we will proceed via a slightly indirect route
Remark: The reader might have been puzzled by the fact that it is the transpose matrix
A> rather than A itself that appears in Lemma 7.4. The reason is that if we want the generic
term in the determinant to be

(π)aπ(1) 1 · · · aπ(n) n,
where the permutation applies to the first index, then we have to express the vj s in terms
of the uis in terms of A> as we did. Furthermore, since
vj = a1 ju1 + · · · + ai jui + · · · + an jun,
we see that vj corresponds to the jth column of the matrix A, and so the determinant is
viewed as a function of the columns of A.
The literature is split on this point. Some authors prefer to define a determinant as we
did. Others use A itself, which amounts to viewing det as a function of the rows, in which
case we get the expression
σ
X∈Sn

(σ)a1 σ(1) · · · an σ(n)
.
Corollary 7.7 show that these two expressions are equal, so it doesn’t matter which is chosen.
This is a matter of taste.
7.3 Definition of a Determinant
Recall that the set of all square n × n-matrices with coefficients in a field K is denoted by
Mn(K).
Definition 7.4. A determinant is defined as any map
D : Mn(K) → K,
which, when viewed as a map on (Kn
)
n
, i.e., a map of the n columns of a matrix, is n-linear
alternating and such that D(In) = 1 for the identity matrix In. Equivalently, we can consider
a vector space E of dimension n, some fixed basis (e1, . . . , en), and define
D : E
n → K
as an n-linear alternating map such that D(e1, . . . , en) = 1.
216 CHAPTER 7. DETERMINANTS
First we will show that such maps D exist, using an inductive definition that also gives
a recursive method for computing determinants. Actually, we will define a family (Dn)n≥1
of (finite) sets of maps D : Mn(K) → K. Second we will show that determinants are in fact
uniquely defined, that is, we will show that each Dn consists of a single map. This will show
the equivalence of the direct definition det(A) of Lemma 7.4 with the inductive definition
D(A). Finally, we will prove some basic properties of determinants, using the uniqueness
theorem.
Given a matrix A ∈ Mn(K), we denote its n columns by A1
, . . . , An
. In order to describe
the recursive process to define a determinant we need the notion of a minor.
Definition 7.5. Given any n×n matrix with n ≥ 2, for any two indices i, j with 1 ≤ i, j ≤ n,
let Aij be the (n − 1) × (n − 1) matrix obtained by deleting Row i and Column j from A
and called a minor :
Aij =


×
×
× × × × × × ×
×
×
×
×


.
For example, if
A =


−
2
0
1
−
2
1
−
0
1
0 0
0 0
−1 2 −1 0
0 0
0 0
−
0
1
−
2
1 2
−1


then
A2 3 =


2 −1 0 0
0
0 0 2
−1 −1 0
−1
0 0 −1 2

 .
Definition 7.6. For every n ≥ 1, we define a finite set Dn of maps D : Mn(K) → K
inductively as follows:
When n = 1, D1 consists of the single map D such that, D(A) = a, where A = (a), with
a ∈ K.
Assume that Dn−1 has been defined, where n ≥ 2. Then Dn consists of all the maps D
such that, for some i, 1 ≤ i ≤ n,
D(A) = (−1)i+1ai 1D(Ai 1) + · · · + (−1)i+n
ai nD(Ai n),
where for every j, 1 ≤ j ≤ n, D(Ai j ) is the result of applying any D in Dn−1 to the minor
Ai j .
7.3. DEFINITION OF A DETERMINANT 217

We confess that the use of the same letter D for the member of Dn being defined, and
for members of Dn−1, may be slightly confusing. We considered using subscripts to
distinguish, but this seems to complicate things unnecessarily. One should not worry too
much anyway, since it will turn out that each Dn contains just one map.
Each (−1)i+jD(Ai j ) is called the cofactor of ai j , and the inductive expression for D(A)
is called a Laplace expansion of D according to the i-th Row. Given a matrix A ∈ Mn(K),
each D(A) is called a determinant of A.
We can think of each member of Dn as an algorithm to evaluate “the” determinant of A.
The main point is that these algorithms, which recursively evaluate a determinant using all
possible Laplace row expansions, all yield the same result, det(A).
We will prove shortly that D(A) is uniquely defined (at the moment, it is not clear that
Dn consists of a single map). Assuming this fact, given a n × n-matrix A = (ai j ),
A =


a1 1 a1 2 . . . a1 n
a2 1 a2 2 . . . a2 n
.
.
.
.
.
.
.
.
.
.
.
.
an 1 an 2 . . . an n


,
its determinant is denoted by D(A) or det(A), or more explicitly by
det(A) =



  



a1 1 a1 2 . . . a1 n
a2 1 a2 2 . . . a2 n
.
.
.
.
.
.
.
.
.
.
.
.
an 1 an 2 . . . an n








.
Let us first consider some examples.
Example 7.1.
1. When n = 2, if
A =

a b
c d ,
then by expanding according to any row, we have
D(A) = ad − bc.
2. When n = 3, if
A =


a1 1 a1 2 a1 3
a2 1 a2 2 a2 3
a3 1 a3 2 a3 3

 ,
218 CHAPTER 7. DETERMINANTS
then by expanding according to the first row, we have
D(A) = a1 1

 

a2 2 a2 3
a3 2 a3 3



− a1 2

 

a2 1 a2 3
a3 1 a3 3



+ a1 3

 

a2 1 a2 2
a3 1 a3 2



,
that is,
D(A) = a1 1(a2 2a3 3 − a3 2a2 3) − a1 2(a2 1a3 3 − a3 1a2 3) + a1 3(a2 1a3 2 − a3 1a2 2),
which gives the explicit formula
D(A) = a1 1a2 2a3 3 + a2 1a3 2a1 3 + a3 1a1 2a2 3 − a1 1a3 2a2 3 − a2 1a1 2a3 3 − a3 1a2 2a1 3.
We now show that each D ∈ Dn is a determinant (map).
Lemma 7.5. For every n ≥ 1, for every D ∈ Dn as defined in Definition 7.6, D is an
alternating multilinear map such that D(In) = 1.
Proof. By induction on n, it is obvious that D(In) = 1. Let us now prove that D is
multilinear. Let us show that D is linear in each column. Consider any Column k. Since
D(A) = (−1)i+1ai 1D(Ai 1) + · · · + (−1)i+j
ai jD(Ai j ) + · · · + (−1)i+n
ai nD(Ai n),
if j 6 = k, then by induction, D(Ai j ) is linear in Column k, and ai j does not belong to Column
k, so (−1)i+jai jD(Ai j ) is linear in Column k. If j = k, then D(Ai j ) does not depend on
Column k = j, since Ai j is obtained from A by deleting Row i and Column j = k, and ai j
belongs to Column j = k. Thus, (−1)i+jai jD(Ai j ) is linear in Column k. Consequently, in
all cases, (−1)i+jai jD(Ai j ) is linear in Column k, and thus, D(A) is linear in Column k.
Let us now prove that D is alternating. Assume that two adjacent columns of A are
equal, say Ak = Ak+1. Assume that j 6 = k and j 6 = k + 1. Then the matrix Ai j has two
identical adjacent columns, and by the induction hypothesis, D(Ai j ) = 0. The remaining
terms of D(A) are
(−1)i+k
ai kD(Ai k) + (−1)i+k+1ai k+1D(Ai k+1).
However, the two matrices Ai k and Ai k+1 are equal, since we are assuming that Columns k
and k + 1 of A are identical and Ai k is obtained from A by deleting Row i and Column k
while Ai k+1 is obtained from A by deleting Row i and Column k + 1. Similarly, ai k = ai k+1,
since Columns k and k + 1 of A are equal. But then,
(−1)i+k
ai kD(Ai k) + (−1)i+k+1ai k+1D(Ai k+1) = (−1)i+k
ai kD(Ai k) − (−1)i+k
ai kD(Ai k) = 0.
This shows that D is alternating and completes the proof.
Lemma 7.5 shows the existence of determinants. We now prove their uniqueness.
7.3. DEFINITION OF A DETERMINANT 219
Theorem 7.6. For every n ≥ 1, for every D ∈ Dn, for every matrix A ∈ Mn(K), we have
D(A) = X
π∈Sn

(π)aπ(1) 1 · · · aπ(n) n,
where the sum ranges over all permutations π on {1, . . . , n}. As a consequence, Dn consists
of a single map for every n ≥ 1, and this map is given by the above explicit formula.
Proof. Consider the standard basis (e1, . . . , en) of Kn
, where (ei)i = 1 and (ei)j = 0, for
j 6 = i. Then each column Aj of A corresponds to a vector vj whose coordinates over the
basis (e1, . . . , en) are the components of Aj
, that is, we can write
v1 = a1 1e1 + · · · + an 1en,
. . .
vn = a1 ne1 + · · · + an nen.
Since by Lemma 7.5, each D is a multilinear alternating map, by applying Lemma 7.4, we
get
D(A) = D(v1, . . . , vn) =  X
π∈Sn

(π)aπ(1) 1 · · · aπ(n) n
 D(e1, . . . , en),
where the sum ranges over all permutations π on {1, . . . , n}. But D(e1, . . . , en) = D(In),
and by Lemma 7.5, we have D(In) = 1. Thus,
D(A) = X
π∈Sn

(π)aπ(1) 1 · · · aπ(n) n,
where the sum ranges over all permutations π on {1, . . . , n}.
From now on we will favor the notation det(A) over D(A) for the determinant of a square
matrix.
Remark: There is a geometric interpretation of determinants which we find quite illumi￾nating. Given n linearly independent vectors (u1, . . . , un) in R
n
, the set
Pn = {λ1u1 + · · · + λnun | 0 ≤ λi ≤ 1, 1 ≤ i ≤ n}
is called a parallelotope. If n = 2, then P2 is a parallelogram and if n = 3, then P3 is a
parallelepiped, a skew box having u1, u2, u3 as three of its corner sides. See Figures 7.1 and
7.2.
Then it turns out that det(u1, . . . , un) is the signed volume of the parallelotope Pn (where
volume means n-dimensional volume). The sign of this volume accounts for the orientation
of Pn in R
n
.
We can now prove some properties of determinants.
220 CHAPTER 7. DETERMINANTS
u = (1,0) 1
u = (1,1)
2
Figure 7.1: The parallelogram in R
w spanned by the vectors u1 = (1, 0) and u2 = (1, 1).
Corollary 7.7. For every matrix A ∈ Mn(K), we have det(A) = det(A> ).
Proof. By Theorem 7.6, we have
det(A) = X
π∈Sn

(π)aπ(1) 1 · · · aπ(n) n,
where the sum ranges over all permutations π on {1, . . . , n}. Since a permutation is invertible,
every product
aπ(1) 1 · · · aπ(n) n
can be rewritten as
a1 π−1(1) · · · an π−1(n)
,
and since  (π
−1
) =  (π) and the sum is taken over all permutations on {1, . . . , n}, we have
π
X∈Sn

(π)aπ(1) 1 · · · aπ(n) n =
X
σ∈Sn

(σ)a1 σ(1) · · · an σ(n)
,
where π and σ range over all permutations. But it is immediately verified that
det(A
> ) = X
σ∈Sn

(σ)a1 σ(1) · · · an σ(n)
.
A useful consequence of Corollary 7.7 is that the determinant of a matrix is also a multi￾linear alternating map of its rows. This fact, combined with the fact that the determinant of
a matrix is a multilinear alternating map of its columns, is often useful for finding short-cuts
in computing determinants. We illustrate this point on the following example which shows
up in polynomial interpolation.
7.3. DEFINITION OF A DETERMINANT 221
u = (1,1,0) 1
u = (0,1,0) 2
u = (1,1,1)
3
Figure 7.2: The parallelepiped in R
3
spanned by the vectors u1 = (1, 1, 0), u2 = (0, 1, 0), and
u3 = (0, 0, 1).
Example 7.2. Consider the so-called Vandermonde determinant
V (x1, . . . , xn) =




  




1 1 . . . 1
x1 x2 . . . xn
x
2
1 x
2
2
. . . x2
n
.
.
.
.
.
.
.
.
.
.
.
.
x
n
1
−1 x
n
2
−1
. . . xn−1
n











.
We claim that
V (x1, . . . , xn) = Y
1≤i<j≤n
(xj − xi),
with V (x1, . . . , xn) = 1, when n = 1. We prove it by induction on n ≥ 1. The case n = 1 is
obvious. Assume n ≥ 2. We proceed as follows: multiply Row n − 1 by x1 and subtract it
from Row n (the last row), then multiply Row n − 2 by x1 and subtract it from Row n − 1,
etc, multiply Row i − 1 by x1 and subtract it from row i, until we reach Row 1. We obtain
222 CHAPTER 7. DETERMINANTS
the following determinant:
V (x1, . . . , xn) =




  




1 1 . . . 1
0 x2 − x1 . . . xn − x1
0 x2(x2 − x1) . . . xn(xn − x1)
.
.
.
.
.
.
.
.
.
.
.
.
0 x
n
2
−2
(x2 − x1) . . . xn
n
−2
(xn − x1)










.
Now expanding this determinant according to the first column and using multilinearity,
we can factor (xi − x1) from the column of index i − 1 of the matrix obtained by deleting
the first row and the first column, and thus
V (x1, . . . , xn) = (x2 − x1)(x3 − x1)· · ·(xn − x1)V (x2, . . . , xn),
which establishes the induction step.
Example 7.3. The determinant of upper triangular matrices and more generally of block
matrices that are block upper triangular has a remarkable form. Recall that an n×n matrix
A = (aij ) is upper-triangular if it is of the form
A =


a11 × × · · · ×
0 a22 × · · · ×
0 0 .
.
. · · ·
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
0 0 0 0 ann


,
that is, aij = 0 for all i > j, 1 ≤ i, j ≤ n. Using n − 1 times Laplace expansion with respect
to the first column we obain
det(A) = a11a22 · · · ann.
Similarly, if A is an n × n block matrix which is block upper triangular ,
A =


A11 × × · · · ×
0 A22 × · · · ×
0 0 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
0 0 0 0 App


,
where each Aii is an ni × ni matrix, with n1 + · · · + np = n, each block × above the diagonal
in position (i, j) for i < j is an ni × nj matrix, and each block in position (i, j) for i > j is
the ni × nj zero matrix, then it can be shown by induction on p ≥ 1 that
det(A) = det(A11) det(A22)· · · det(App).
7.3. DEFINITION OF A DETERMINANT 223
Lemma 7.4 can be reformulated nicely as follows.
Proposition 7.8. Let f : E × . . . × E → F be an n-linear alternating map. Let (u1, . . . , un)
and (v1, . . . , vn) be two families of n vectors, such that
v1 = a1 1u1 + · · · + a1 nun,
. . .
vn = an 1u1 + · · · + an nun.
Equivalently, letting
A =


a1 1 a1 2 . . . a1 n
a2 1 a2 2 . . . a2 n
.
.
.
.
.
.
.
.
.
.
.
.
an 1 an 2 . . . an n


,
assume that we have


v
v
1
2
.
.
v
.
n


= A


u1
u2
.
u
.
.
n


.
Then,
f(v1, . . . , vn) = det(A)f(u1, . . . , un).
Proof. The only difference with Lemma 7.4 is that here we are using A> instead of A. Thus,
by Lemma 7.4 and Corollary 7.7, we get the desired result.
As a consequence, we get the very useful property that the determinant of a product of
matrices is the product of the determinants of these matrices.
Proposition 7.9. For any two n×n-matrices A and B, we have det(AB) = det(A) det(B).
Proof. We use Proposition 7.8 as follows: let (e1, . . . , en) be the standard basis of Kn
, and
let


w
w
1
2
.
.
w
.
n


= AB


e1
e2
.
e
.
.
n


.
Then we get
det(w1, . . . , wn) = det(AB) det(e1, . . . , en) = det(AB),
224 CHAPTER 7. DETERMINANTS
since det(e1, . . . , en) = 1. Now letting


v
v
1
2
.
.
v
.
n


= B


e1
e2
.
e
.
.
n


,
we get
det(v1, . . . , vn) = det(B),
and since


w
w
1
2
.
.
w
.
n


= A


v1
v2
.
v
.
.
n


,
we get
det(w1, . . . , wn) = det(A) det(v1, . . . , vn) = det(A) det(B).
It should be noted that all the results of this section, up to now, also hold when K is a
commutative ring and not necessarily a field. We can now characterize when an n×n-matrix
A is invertible in terms of its determinant det(A).
7.4 Inverse Matrices and Determinants
In the next two sections, K is a commutative ring and when needed a field.
Definition 7.7. Let K be a commutative ring. Given a matrix A ∈ Mn(K), let Ae = (bi j )
be the matrix defined such that
bi j = (−1)i+j
det(Aj i),
the cofactor of aj i. The matrix Ae is called the adjugate of A, and each matrix Aj i is called
a minor of the matrix A.
For example, if
A =


1 1 1
2
3 3
−2 −
−
2
3

 ,
7.4. INVERSE MATRICES AND DETERMINANTS 225
we have
b11 = det(A11) =

 
 −
3
2 −
−
2
3




= 12 b12 = − det(A21) = −

  
1 1
3 −3




= 6
b13 = det(A31) =

 

−
1 1
2 −2




= 0 b21 = − det(A12) = −

  
2
3
−
−
2
3




= 0
b22 = det(A22) =

 
 1 1
3 −3




= −6 b23 = − det(A32) = −

  
1 1
2 −2




= 4
b31 = det(A13) =

 
 2
3 3
−2
 


= 12 b32 = − det(A23) = −

  
1 1
3 3


  = 0
b33 = det(A33) =

 
 1 1
2 −2




= −4,
we find that
Ae =


12 6 0
12 0
0 −6 4
−4

 .

Note the reversal of the indices in
bi j = (−1)i+j
det(Aj i).
Thus, Ae is the transpose of the matrix of cofactors of elements of A.
We have the following proposition.
Proposition 7.10. Let K be a commutative ring. For every matrix A ∈ Mn(K), we have
AAe = AAe = det(A)In.
As a consequence, A is invertible iff det(A) is invertible, and if so, A−1 = (det(A))−1Ae.
Proof. If Ae = (bi j ) and AAe = (ci j ), we know that the entry ci j in row i and column j of AAe
is
ci j = ai 1b1 j + · · · + ai kbk j + · · · + ai nbn j ,
which is equal to
ai 1(−1)j+1 det(Aj 1) + · · · + ai n(−1)j+n
det(Aj n).
If j = i, then we recognize the expression of the expansion of det(A) according to the i-th
row:
ci i = det(A) = ai 1(−1)i+1 det(Ai 1) + · · · + ai n(−1)i+n
det(Ai n).
If j 6 = i, we can form the matrix A0 by replacing the j-th row of A by the i-th row of A.
Now the matrix Aj k obtained by deleting row j and column k from A is equal to the matrix
226 CHAPTER 7. DETERMINANTS
A0j k obtained by deleting row j and column k from A0 , since A and A0 only differ by the j-th
row. Thus,
det(Aj k) = det(A
0j k),
and we have
ci j = ai 1(−1)j+1 det(A
0j 1
) + · · · + ai n(−1)j+n
det(A
0j n).
However, this is the expansion of det(A0 ) according to the j-th row, since the j-th row of A0
is equal to the i-th row of A. Furthermore, since A0 has two identical rows i and j, because
det is an alternating map of the rows (see an earlier remark), we have det(A0 ) = 0. Thus,
we have shown that ci i = det(A), and ci j = 0, when j 6 = i, and so
AAe = det(A)In.
It is also obvious from the definition of Ae, that
Ae
> = Af> .
Then applying the first part of the argument to A> , we have
A
> Af> = det(A
> )In,
and since det(A> ) = det(A), Ae> = Af> , and (AAe)
> = A> Ae> , we get
det(A)In = A
> Af> = A
> Ae
> = (AAe)
> ,
that is,
(AAe)
> = det(A)In,
which yields
AAe = det(A)In,
since In
> = In. This proves that
AAe = AAe = det(A)In.
As a consequence, if det(A) is invertible, we have A−1 = (det(A))−1Ae. Conversely, if A is
invertible, from AA−1 = In, by Proposition 7.9, we have det(A) det(A−1
) = 1, and det(A) is
invertible.
For example, we saw earlier that
A =


3 3
1 1 1
2 −2
−
−2
3

