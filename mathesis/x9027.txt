x = u
(u,0)
L(u, λ)
(0, λ)
(u,0)
(i.)
M
Ω
(0, λ)
x = u
(u,0)
(0, λ)
L(u, λ)
(ii.)
Figure 50.18: Let Ω = {[t, 0, 0] | 0 ≤ t ≤ 1} and M = {[0, t, 0] | 0 ≤ t ≤ 1}. In Figure (i.),
L(u, λ) is the blue slanted quadrilateral whose forward vertex is a saddle point. In Figure
(ii.), L(u, λ) is the planar green rectangle composed entirely of saddle points.
Pick any w ∈ Ω and any ρ ∈ M. By definition of inf (the greatest lower bound) and sup
(the least upper bound), we have
inf
v∈Ω
L(v, ρ) ≤ L(w, ρ) ≤ sup
µ∈M
L(w, µ).
The cases where infv∈Ω L(v, ρ) = −∞ or where supµ∈M L(w, µ) = +∞ may arise, but this is
not a problem. Since
inf
v∈Ω
L(v, ρ) ≤ sup
µ∈M
L(w, µ)
and the right-hand side is independent of ρ, it is an upper bound of the left-hand side for
all ρ, so
sup
µ∈M
inf
v∈Ω
L(v, µ) ≤ sup
µ∈M
L(w, µ).
y = λ
y = λ
50.7. LAGRANGIAN DUALITY AND SADDLE POINTS 1775
Since the left-hand side is independent of w, it is a lower bound for the right-hand side for
all w, so we obtain (∗1):
sup
µ∈M
inf
v∈Ω
L(v, µ) ≤ inf
v∈Ω
sup
µ∈M
L(v, µ).
To obtain the reverse inequality, we use the fact that (u, λ) is a saddle point, so
inf
v∈Ω
sup
µ∈M
L(v, µ) ≤ sup
µ∈M
L(u, µ) = L(u, λ)
and
L(u, λ) = inf
v∈Ω
L(v, λ) ≤ sup
µ∈M
inf
v∈Ω
L(v, µ),
and these imply that
inf
v∈Ω
sup
µ∈M
L(v, µ) ≤ sup
µ∈M
inf
v∈Ω
L(v, µ), (∗2)
as desired.
We now return to our main Minimization Problem (P):
minimize J(v)
subject to ϕi(v) ≤ 0, i = 1, . . . , m,
where J : Ω → R and the constraints ϕi
: Ω → R are some functions defined on some open
subset Ω of some finite-dimensional Euclidean vector space V (more generally, a real Hilbert
space V ).
Definition 50.8. The Lagrangian of the Minimization Problem (P) defined above is the
function L: Ω × R
m
+ → R given by
L(v, µ) = J(v) +
mX
i=1
µiϕi(v),
with µ = (µ1, . . . , µm). The numbers µi are called generalized Lagrange multipliers.
The following theorem shows that under some suitable conditions, every solution u of
the Problem (P) is the first argument of a saddle point (u, λ) of the Lagrangian L, and
conversely, if (u, λ) is a saddle point of the Lagrangian L, then u is a solution of the Problem
(P).
Theorem 50.15. Consider Problem (P) defined above where J : Ω → R and the constraints
ϕi
: Ω → R are some functions defined on some open subset Ω of some finite-dimensional
Euclidean vector space V (more generally, a real Hilbert space V ). The following facts hold.
(1) If (u, λ) ∈ Ω × R
m
+ is a saddle point of the Lagrangian L associated with Problem (P),
then u ∈ U, u is a solution of Problem (P), and J(u) = L(u, λ).
1776 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
(2) If Ω is convex (open), if the functions ϕi (1 ≤ i ≤ m) and J are convex and differen￾tiable at the point u ∈ U, if the constraints are qualified, and if u ∈ U is a minimum of
Problem (P), then there exists some vector λ ∈ R
m
+ such that the pair (u, λ) ∈ Ω × R
m
+
is a saddle point of the Lagrangian L.
Proof. (1) Since (u, λ) is a saddle point of L we have supµ∈Rm
+
L(u, µ) = L(u, λ) which implies
that L(u, µ) ≤ L(u, λ) for all µ ∈ R
m
+ , which means that
J(u) +
mX
i=1
µiϕi(u) ≤ J(u) +
mX
i=1
λiϕi(u),
that is,
mX
i=1
(µi − λi)ϕi(u) ≤ 0 for all µ ∈ R
m
+ .
If we let each µi be large enough, then µi − λi > 0, and if we had ϕi(u) > 0, then the term
(µi − λi)ϕi(u) could be made arbitrarily large and positive, so we conclude that ϕi(u) ≤ 0
for i = 1, . . . , m, and consequently, u ∈ U. For µ = 0, we conclude that P m
i=1 λiϕi(u) ≥ 0.
However, since λi ≥ 0 and ϕi(u) ≤ 0, (since u ∈ U), we have P m
i=1 λiϕi(u) ≤ 0. Combining
these two inequalities shows that
mX
i=1
λiϕi(u) = 0. (∗1)
This shows that J(u) = L(u, λ). Since the inequality L(u, λ) ≤ L(v, λ) is
J(u) +
mX
i=1
λiϕi(u) ≤ J(v) +
mX
i=1
λiϕi(v),
by (∗1) we obtain
J(u) ≤ J(v) +
mX
i=1
λiϕi(v) for all v ∈ Ω
≤ J(v) for all v ∈ U (since ϕi(v) ≤ 0 and λi ≥ 0),
which shows that u is a minimum of J on U.
(2) The hypotheses required to apply Theorem 50.6(1) are satisfied. Consequently if
u ∈ U is a solution of Problem (P), then there exists some vector λ ∈ R
m
+ such that the
KKT conditions hold:
J
0 (u) +
mX
i=1
λi(ϕ
0i
)u = 0 and
mX
i=1
λiϕi(u) = 0.
50.7. LAGRANGIAN DUALITY AND SADDLE POINTS 1777
The second equation yields
L(u, µ) = J(u) +
mX
i=1
µiϕi(u) ≤ J(u) = J(u) +
mX
i=1
λiϕi(u) = L(u, λ),
that is,
L(u, µ) ≤ L(u, λ) for all µ ∈ R
m
+ (∗2)
(since ϕi(u) ≤ 0 as u ∈ U), and since the function v 7→ J(v) + P i=1 λiϕi(v) = L(v, λ) is
convex as a sum of convex functions, by Theorem 40.13(4), the first equation is a sufficient
condition for the existence of minimum. Consequently,
L(u, λ) ≤ L(v, λ) for all v ∈ Ω, (∗3)
and (∗2) and (∗3) show that (u, λ) is a saddle point of L.
To recap what we just proved, under some mild hypotheses, the set of solutions of the
Minimization Problem (P)
minimize J(v)
subject to ϕi(v) ≤ 0, i = 1, . . . , m
coincides with the set of first arguments of the saddle points of the Lagrangian
L(v, µ) = J(v) +
mX
i=1
µiϕi(v),
and for any optimum u ∈ U of Problem (P), we have J(u) = L(u, λ).
Therefore, if we knew some particular second argument λ of these saddle points, then
the constrained Problem (P) would be replaced by the unconstrained Problem (Pλ):
find uλ ∈ Ω such that
L(uλ, λ) = inf
v∈Ω
L(v, λ).
How do we find such an element λ ∈ R
m
+ ?
For this, remember that for a saddle point (uλ, λ), by Proposition 50.14, we have
L(uλ, λ) = inf
v∈Ω
L(v, λ) = sup
µ∈Rm
+
inf
v∈Ω
L(v, µ),
so we are naturally led to introduce the function G: R
m
+ → R given by
G(µ) = inf
v∈Ω
L(v, µ) µ ∈ R
m
+ ,
1778 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
and then λ will be a solution of the problem
find λ ∈ R
m
+ such that
G(λ) = sup
µ∈Rm
+
G(µ),
which is equivalent to the Maximization Problem (D):
maximize G(µ)
subject to µ ∈ R
m
+ .
Definition 50.9. Given the Minimization Problem (P)
minimize J(v)
subject to ϕi(v) ≤ 0, i = 1, . . . , m,
where J : Ω → R and the constraints ϕi
: Ω → R are some functions defined on some open
subset Ω of some finite-dimensional Euclidean vector space V (more generally, a real Hilbert
space V ), the function G: R
m
+ → R given by
G(µ) = inf
v∈Ω
L(v, µ) µ ∈ R
m
+ ,
is called the Lagrange dual function (or simply dual function). The Problem (D)
maximize G(µ)
subject to µ ∈ R
m
+
is called the Lagrange dual problem. The Problem (P) is often called the primal problem,
and (D) is the dual problem. The variable µ is called the dual variable. The variable µ ∈ R
m
+
is said to be dual feasible if G(µ) is defined (not −∞). If λ ∈ R
m
+ is a maximum of G, then
we call it a dual optimal or an optimal Lagrange multiplier .
Since
L(v, µ) = J(v) +
mX
i=1
µiϕi(v),
the function G(µ) = infv∈Ω L(v, µ) is the pointwise infimum of some affine functions of µ,
so it is concave, even if the ϕi are not convex. One of the main advantages of the dual
problem over the primal problem is that it is a convex optimization problem, since we wish
to maximize a concave objective function G (thus minimize −G, a convex function), and the
constraints µ ≥ 0 are convex. In a number of practical situations, the dual function G can
indeed be computed.
To be perfectly rigorous, we should mention that the dual function G is actually a partial
function, because it takes the value −∞ when the map v 7→ L(v, µ) is unbounded below.
50.7. LAGRANGIAN DUALITY AND SADDLE POINTS 1779
Example 50.5. Consider the Linear Program (P)
minimize c
> v
subject to Av ≤ b, v ≥ 0,
where A is an m×n matrix. The constraints v ≥ 0 are rewritten as −vi ≤ 0, so we introduce
Lagrange multipliers µ ∈ R
m
+ and ν ∈ R
n
+, and we have the Lagrangian
L(v, µ, ν) = c
> v + µ
> (Av − b) − ν
> v
= −b
> µ + (c + A
> µ − ν)
> v.
The linear function v 7→ (c + A> µ − ν)
> v is unbounded below unless c + A> µ − ν = 0, so
the dual function G(µ, ν) = infv∈Rn L(v, µ, ν) is given for all µ ≥ 0 and ν ≥ 0 by
G(µ, ν) = ( −
−∞
b
> µ if
otherwise
A> µ −
.
ν + c = 0,
The domain of G is a proper subset of R
m
+ × R
n
+.
Observe that the value G(µ, ν) of the function G, when it is defined, is independent of
the second argument ν. Since we are interested in maximizing G, this suggests introducing
the function Gb of the single argument µ given by
Gb(µ) = −b
> µ,
which is defined for all µ ∈ R
m
+ .
Of course, supµ∈Rm
+
b
G(µ) and sup(µ,ν)∈Rm
+ ×Rn
+
G(µ, ν) are generally different, but note that
Gb(µ) = G(µ, ν) iff there is some ν ∈ R
n
+ such that A> µ−ν+c = 0 iff A> µ+c ≥ 0. Therefore,
finding sup(µ,ν)∈Rm
+ ×Rn
+
G(µ, ν) is equivalent to the constrained Problem (D1)
maximize − b
> µ
subject to A
> µ ≥ −c, µ ≥ 0.
The above problem is the dual of the Linear Program (P).
In summary, the dual function G of a primary Problem (P) often contains hidden inequal￾ity constraints that define its domain, and sometimes it is possible to make these domain
constraints ψ1(µ) ≤ 0, . . . , ψp(µ) ≤ 0 explicit, to define a new function Gb that depends only
on q < m of the variables µi and is defined for all values µi ≥ 0 of these variables, and
to replace the Maximization Problem (D), find supµ∈Rm
+
G(µ), by the constrained Problem
(D1)
maximize Gb(µ)
subject to ψi(µ) ≤ 0, i = 1, . . . , p.
Problem (D1) is different from the Dual Program (D), but it is equivalent to (D) as a
maximization problem.
1780 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
50.8 Weak and Strong Duality
Another important property of the dual function G is that it provides a lower bound on the
value of the objective function J. Indeed, we have
G(µ) ≤ L(u, µ) ≤ J(u) for all u ∈ U and all µ ∈ R
m
+ , (†)
since µ ≥ 0 and ϕi(u) ≤ 0 for i = 1, . . . , m, so
G(µ) = inf
v∈Ω
L(v, µ) ≤ L(u, µ) = J(u) +
mX
i=1
µiϕi(u) ≤ J(u).
If the Primal Problem (P) has a minimum denoted p
∗ and the Dual Problem (D) has a
maximum denoted d
∗
, then the above inequality implies that
d
∗ ≤ p
∗
(†w)
known as weak duality. Equivalently, for every optimal solution λ
∗ of the dual problem and
every optimal solution u
∗ of the primal problem, we have
G(λ
∗
) ≤ J(u
∗
). (†w0 )
In particular, if p
∗ = −∞, which means that the primal problem is unbounded below, then
the dual problem is unfeasible. Conversely, if d
∗ = +∞, which means that the dual problem
is unbounded above, then the primal problem is unfeasible.
Definition 50.10. The difference p
∗−d
∗ ≥ 0 is called the optimal duality gap. If the duality
gap is zero, that is, p
∗ = d
∗
, then we say that strong duality holds.
Even when the duality gap is strictly positive, the inequality (†w) can be helpful to find
a lower bound on the optimal value of a primal problem that is difficult to solve, since the
dual problem is always convex.
If the primal problem and the dual problem are feasible and if the optimal values p
∗ and
d
∗ are finite and p
∗ = d
∗
(no duality gap), then the complementary slackness conditions hold
for the inequality constraints.
Proposition 50.16. (Complementary Slackness) Given the Minimization Problem (P)
minimize J(v)
subject to ϕi(v) ≤ 0, i = 1, . . . , m,
and its Dual Problem (D)
maximize G(µ)
subject to µ ∈ R
m
+ ,
50.8. WEAK AND STRONG DUALITY 1781
if both (P) and (D) are feasible, u ∈ U is an optimal solution of (P), λ ∈ R
m
+ is an optimal
solution of (D), and J(u) = G(λ), then
mX
i=1
λiϕi(u) = 0.
In other words, if the constraint ϕi is inactive at u, then λi = 0.
Proof. Since J(u) = G(λ) we have
J(u) = G(λ)
= inf
v∈Ω
 
J(v) +
mX
i=1
λiϕi(v)
! by definition of G
≤ J(u) +
mX
i=1
λiϕi(u) the greatest lower bound is a lower bound
≤ J(u) since λi ≥ 0, ϕi(u) ≤ 0.
which implies that P m
i=1 λiϕi(u) = 0.
Going back to Example 50.5, we see that weak duality says that for any feasible solution
u of the Primal Problem (P), that is, some u ∈ R
n
such that
Au ≤ b, u ≥ 0,
and for any feasible solution µ ∈ R
m of the Dual Problem (D1), that is,
A
> µ ≥ −c, µ ≥ 0,
we have
−b
> µ ≤ c
> u.
Actually, if u and λ are optimal, then we know from Theorem 47.7 that strong duality holds,
namely −b
> µ = c
> u, but the proof of this fact is nontrivial.
The following theorem establishes a link between the solutions of the Primal Problem
(P) and those of the Dual Problem (D). It also gives sufficient conditions for the duality
gap to be zero.
Theorem 50.17. Consider the Minimization Problem (P):
minimize J(v)
subject to ϕi(v) ≤ 0, i = 1, . . . , m,
where the functions J and ϕi are defined on some open subset Ω of a finite-dimensional
Euclidean vector space V (more generally, a real Hilbert space V ).
1782 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
(1) Suppose the functions ϕi
: Ω → R are continuous, and that for every µ ∈ R
m
+ , the
Problem (Pµ):
minimize L(v, µ)
subject to v ∈ Ω,
has a unique solution uµ, so that
L(uµ, µ) = inf
v∈Ω
L(v, µ) = G(µ),
and the function µ 7→ uµ is continuous (on R
m
+ ). Then the function G is differentiable
for all µ ∈ R
m
+ , and
G
0µ
(ξ) =
mX
i=1
ξiϕi(uµ) for all ξ ∈ R
m.
If λ is any solution of Problem (D):
maximize G(µ)
subject to µ ∈ R
m
+ ,
then the solution uλ of the corresponding problem (Pλ) is a solution of Problem (P).
(2) Assume Problem (P) has some solution u ∈ U, and that Ω is convex (open), the
functions ϕi (1 ≤ i ≤ m) and J are convex and differentiable at u, and that the
constraints are qualified. Then Problem (D) has a solution λ ∈ R
m
+ , and J(u) = G(λ);
that is, the duality gap is zero.
Proof. (1) Our goal is to prove that for any solution λ of Problem (D), the pair (uλ, λ) is a
saddle point of L. By Theorem 50.15(1), the point uλ ∈ U is a solution of Problem (P).
Since λ ∈ R
m
+ is a solution of Problem (D), by definition of G(λ) and since uλ satisfies
Problem (Pλ), we have
G(λ) = inf
v∈Ω
L(v, λ) = L(uλ, λ),
which is one of the two equations characterizing a saddle point. In order to prove the second
equation characterizing a saddle point,
sup
µ∈Rm
+
L(uµ, µ) = L(uλ, λ),
we will begin by proving that the function G is differentiable for all µ ∈ R
m
+ , in order to be
able to apply Theorem 40.9 to conclude that since G has a maximum at λ, that is, −G has
minimum at λ, then −G0λ
(µ − λ) ≥ 0 for all µ ∈ R
m
+ . In fact, we prove that
G
0µ
(ξ) =
mX
i=1
ξiϕi(uµ) for all ξ ∈ R
m. (∗deriv)
50.8. WEAK AND STRONG DUALITY 1783
Consider any two points µ and µ + ξ in R
m
+ . By definition of uµ we have
L(uµ, µ) ≤ L(uµ+ξ, µ),
which means that
J(uµ) +
mX
i=1
µiϕi(uµ) ≤ J(uµ+ξ) +
mX
i=1
µiϕi(uµ+ξ), (∗1)
and since G(µ) = L(uµ, µ) = J(uµ) + P m
i=1 µiϕi(uµ) and G(µ + ξ) = L(uµ+ξ, µ + ξ) =
J(uµ+ξ) + P m
i=1(µi + ξi)ϕi(uµ+ξ), we have
G(µ + ξ) − G(µ) = J(uµ+ξ) − J(uµ) +
mX
i=1
(µi + ξi)ϕi(uµ+ξ) −
mX
i=1
µiϕi(uµ). (∗2)
Since (∗1) can be written as
0 ≤ J(uµ+ξ) − J(uµ) +
mX
i=1
µiϕi(uµ+ξ) −
mX
i=1
µiϕi(uµ),
by adding P m
i=1 ξiϕi(uµ+ξ) to both sides of the above inequality and using (∗2) we get
mX
i=1
ξiϕi(uµ+ξ) ≤ G(µ + ξ) − G(µ). (∗3)
By definition of uµ+ξ we have
L(uµ+ξ, µ + ξ) ≤ L(uµ, µ + ξ),
which means that
J(uµ+ξ) +
mX
i=1
(µi + ξi)ϕi(uµ+ξ) ≤ J(uµ) +
mX
i=1
(µi + ξi)ϕi(uµ). (∗4)
This can be written as
J(uµ+ξ) − J(uµ) +
mX
i=1
(µi + ξi)ϕi(uµ+ξ) −
mX
i=1
(µi + ξi)ϕi(uµ) ≤ 0,
and by adding P m
i=1 ξiϕi(uµ) to both sides of the above inequality and using (∗2) we get
G(µ + ξ) − G(µ) ≤
mX
i=1
ξiϕi(uµ). (∗5)
1784 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
By putting (∗3) and (∗5) together we obtain
mX
i=1
ξiϕi(uµ+ξ) ≤ G(µ + ξ) − G(µ) ≤
mX
i=1
ξiϕi(uµ). (∗6)
Consequently there is some θ ∈ [0, 1] such that
G(µ + ξ) − G(µ) = (1 − θ)

mX
i=1
ξiϕi(uµ)
 + θ

mX
i=1
ξiϕi(uµ+ξ)

=
mX
i=1
ξiϕi(uµ) + θ

mX
i=1
ξi(ϕi(uµ+ξ) − ϕi(uµ)) .
Since by hypothesis the functions µ 7→ uµ (from R
m
+ to Ω) and ϕi
: Ω → R are continuous,
for any µ ∈ R
m
+ we can write
G(µ + ξ) − G(µ) =
mX
i=1
ξiϕi(uµ) + k ξk  (ξ), with limξ7→0  (ξ) = 0, (∗7)
for any k k norm on R
m. Equation (∗7) show that G is differentiable for any µ ∈ R
m
+ , and
that
G
0µ
(ξ) =
mX
i=1
ξiϕi(uµ) for all ξ ∈ R
m. (∗8)
Actually there is a small problem, namely that the notion of derivative was defined for a
function defined on an open set, but R
m
+ is not open. The difficulty only arises to ensure
that the derivative is unique, but in our case we have a unique expression for the derivative
so there is no problem as far as defining the derivative. There is still a potential problem,
which is that we would like to apply Theorem 40.9 to conclude that since G has a maximum
at λ, that is, −G has a minimum at λ, then
−G
0λ
(µ − λ) ≥ 0 for all µ ∈ R
m
+ , (∗9)
but the hypotheses of Theorem 40.9 require the domain of the function to be open. Fortu￾nately, close examination of the proof of Theorem 40.9 shows that the proof still holds with
U = R
m
+ . Therefore, (∗8) holds, Theorem 40.9 is valid, which in turn implies
G
0λ
(µ − λ) ≤ 0 for all µ ∈ R
m
+ , (∗10)
which, using the expression for G0λ
given in (∗8) gives
mX
i=1
µiϕi(uλ) ≤
mX
i=1
λiϕi(uλ), for all µ ∈ R
m
+ . (∗11)
50.8. WEAK AND STRONG DUALITY 1785
As a consequence of (∗11), we obtain
L(uλ, µ) = J(uλ) +
mX
i=1
µiϕi(uλ)
≤ J(uλ) +
mX
i=1
λiϕi(uλ) = L(uλ, λ),
for all µ ∈ R
m
+ , that is,
L(uλ, µ) ≤ L(uλ, λ), for all µ ∈ R
m
+ , (∗12)
which implies the second inequality
sup
µ∈Rm
+
L(uµ, µ) = L(uλ, λ)
stating that (uλ, λ) is a saddle point. Therefore, (uλ, λ) is a saddle point of L, as claimed.
(2) The hypotheses are exactly those required by Theorem 50.15(2), thus there is some
λ ∈ R
m
+ such that (u, λ) is a saddle point of the Lagrangian L, and by Theorem 50.15(1) we
have J(u) = L(u, λ). By Proposition 50.14, we have
J(u) = L(u, λ) = inf
v∈Ω
L(v, λ) = sup
µ∈Rm
+
inf
v∈Ω
L(v, µ),
which can be rewritten as
J(u) = G(λ) = sup
µ∈Rm
+
G(µ).
In other words, Problem (D) has a solution, and J(u) = G(λ).
Remark: Note that Theorem 50.17(2) could have already be obtained as a consequence of
Theorem 50.15(2), but the dual function G was not yet defined. If (u, λ) is a saddle point of
the Lagrangian L (defined on Ω × R
m
+ ), then by Proposition 50.14, the vector λ is a solution
of Problem (D). Conversely, under the hypotheses of Part (1) of Theorem 50.17, if λ is a
solution of Problem (D), then (uλ, λ) is a saddle point of L. Consequently, under the above
hypotheses, the set of solutions of the Dual Problem (D) coincide with the set of second
arguments λ of the saddle points (u, λ) of L. In some sense, this result is the “dual” of the
result stated in Theorem 50.15, namely that the set of solutions of Problem (P) coincides
with set of first arguments u of the saddle points (u, λ) of L.
Informally, in Theorem 50.17(1), the hypotheses say that if G(µ) can be “computed
nicely,” in the sense that there is a unique minimizer uµ of L(v, µ) (with v ∈ Ω) such that
G(µ) = L(uµ, µ), and if a maximizer λ of G(µ) (with µ ∈ R
m
+ ) can be determined, then uλ
yields the minimum value of J, that is, p
∗ = J(uλ). If the constraints are qualified and if
the functions J and ϕi are convex and differentiable, then since the KKT conditions hold,
the duality gap is zero; that is,
G(λ) = L(uλ, λ) = J(uλ).
1786 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
Example 50.6. Going back to Example 50.5 where we considered the linear program (P)
minimize c
> v
subject to Av ≤ b, v ≥ 0,
with A an m × n matrix, the Lagrangian L(v, µ, ν) is given by
L(v, µ, ν) = −b
> µ + (c + A
> µ − ν)
> v,
and we found that the dual function G(µ, ν) = infv∈Rn L(v, µ, ν) is given for all µ ≥ 0 and
ν ≥ 0 by
G(µ, ν) = ( −
−∞
b
> µ if
otherwise
A> µ −
.
ν + c = 0,
The hypotheses of Theorem 50.17(1) certainly fail since there are infinitely uµ,ν ∈ R
n
such
that G(µ, ν) = infv∈Rn L(v, µ, ν) = L(uµ,ν, µ, ν). Therefore, the dual function G is no help in
finding a solution of the Primal Problem (P). As we saw earlier, if we consider the modified
dual Problem (D1) then strong duality holds, but this does not follow from Theorem 50.17,
and a different proof is required.
Thus, we have the somewhat counter-intuitive situation that the general theory of La￾grange duality does not apply, at least directly, to linear programming, a fact that is not
sufficiently emphasized in many expositions. A separate treatment of duality is required.
Unlike the case of linear programming, which needs a separate treatment, Theorem 50.17
applies to the optimization problem involving a convex quadratic objective function and a set
of affine inequality constraints. So in some sense, convex quadratic programming is simpler
than linear programming!
Example 50.7. Consider the quadratic objective function
J(v) = 1
2
v
> Av − v
> b,
where A is an n×n matrix which is symmetric positive definite, b ∈ R
n
, and the constraints
are affine inequality constraints of the form
Cv ≤ d,
where C is an m × n matrix and d ∈ R
m. For the time being, we do not assume that C has
rank m. Since A is symmetric positive definite, J is strictly convex, as implied by Proposition
40.11 (see Example 40.6). The Lagrangian of this quadratic optimization problem is given
by
L(v, µ) = 1
2
v
> Av − v
> b + (Cv − d)
> µ
=
1
2
v
> Av − v
> (b − C
> µ) − µ
> d.
50.8. WEAK AND STRONG DUALITY 1787
Since A is symmetric positive definite, by Proposition 42.2, the function v 7→ L(v, µ) has a
unique minimum obtained for the solution uµ of the linear system
Av = b − C
> µ;
that is,
uµ = A
−1
(b − C
> µ).
This shows that the Problem (Pµ) has a unique solution which depends continuously on µ.
Then for any solution λ of the dual problem, uλ = A−1
(b − C
> λ) is an optimal solution of
the primal problem.
We compute G(µ) as follows:
G(µ) = L(uµ, µ) = 1
2
u
>µ Auµ − u
>µ
(b − C
> µ) − µ
> d
=
1
2
u
>µ
(b − C
> µ) − u
>µ
(b − C
> µ) − µ
> d
= −
1
2
u
>µ
(b − C
> µ) − µ
> d
= −
1
2
(b − C
> µ)
> A
−1
(b − C
> µ) − µ
> d
= −
1
2
µ
> CA−1C
> µ + µ
> (CA−1
b − d) −
1
2
b
> A
−1
b.
Since A is symmetric positive definite, the matrix CA−1C
> is symmetric positive semidef￾inite. Since A−1
is also symmetric positive definite, µ
> CA−1C
> µ = 0 iff (C
> µ)
> A−1
(C
> µ) =
0 iff C
> µ = 0 implies µ = 0, that is, Ker C
> = (0), which is equivalent to Im(C) = R
m,
namely if C has rank m (in which case, m ≤ n). Thus CA−1C
> is symmetric positive definite
iff C has rank m.
We showed just after Theorem 49.8 that the functional v 7→ (1/2)v
> Av is elliptic iff
A is symmetric positive definite, and Theorem 49.8 shows that an elliptic functional is
coercive, which is the hypothesis used in Theorem 49.4. Therefore, by Theorem 49.4, if the
inequalities Cx ≤ d have a solution, the primal problem has a unique solution. In this case,
as a consequence, by Theorem 50.17(2), the function −G(µ) always has a minimum, which
is unique if C has rank m. The fact that −G(µ) has a minimum is not obvious when C has
rank < m, since in this case CA−1C
> is not invertible.
We also verify easily that the gradient of G is given by
∇Gµ = Cuµ − d = −CA−1C
> µ + CA−1
b − d.
Observe that since CA−1C
> is symmetric positive semidefinite, −G(µ) is convex.
Therefore, if C has rank m, a solution of Problem (P) is obtained by finding the unique
solution λ of the equation
−CA−1C
> µ + CA−1
b − d = 0,
1788 CHAPTER 50. INTRODUCTION TO NONLINEAR OPTIMIZATION
and then the minimum uλ of Problem (P) is given by
uλ = A
−1
(b − C
> λ).
If C has rank < m, then we can find λ ≥ 0 by finding a feasible solution of the linear program
whose set of constraints is given by
−CA−1C
> µ + CA−1
b − d = 0,
using the standard method of adding nonnegative slack variables ξ1, . . . , ξm and maximizing
−(ξ1 + · · · + ξm).
50.9 Handling Equality Constraints Explicitly
Sometimes it is desirable to handle equality constraints explicitly (for instance, this is what
Boyd and Vandenberghe do, see [29]). The only difference is that the Lagrange multipliers
associated with equality constraints are not required to be nonnegative, as we now show.
Consider the Optimization Problem (P
0 )
minimize J(v)
subject to ϕi(v) ≤ 0, i = 1, . . . , m
ψj (v) = 0, j = 1, . . . , p.
We treat each equality constraint ψj (u) = 0 as the conjunction of the inequalities ψj (u) ≤ 0
and −ψj (u) ≤ 0, and we associate Lagrange multipliers λ ∈ R
m
+ , and ν
+, ν− ∈ R
p
+. Assuming
that the constraints are qualified, by Theorem 50.5, the KKT conditions are
Ju
0 +
mX
i=1
λi(ϕ
0i
)u +
p
X
j=1
νj
+
(ψj
0
)u −
p
X
j=1
νj
−
(ψj
0
)u = 0,
and
mX
i=1
λiϕi(u) +
p
X
j=1
νj
+ψj (u) −
p
X
j=1
νj
−ψj (u) = 0,
with λ ≥ 0, ν+ ≥ 0, ν− ≥ 0. Since ψj (u) = 0 for j = 1, . . . , p, these equations can be
rewritten as
Ju
0 +
mX
i=1
λi(ϕ
0i
)u +
p
X
j=1
(νj
+ − νj
−
)(ψj
0
)u = 0,
and
mX
i=1
λiϕi(u) = 0
50.9. HANDLING EQUALITY CONSTRAINTS EXPLICITLY 1789
