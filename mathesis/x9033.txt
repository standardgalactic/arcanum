p
such that (x, λ, µ) is a saddle point of L(x, λ, µ). Equivalently, x is an optimal
solution of (P) if and only if there exist Lagrange multipliers (λ, µ) ∈ R
m
+ × R
p
, which,
together with x, satisfy the KKT conditions from Theorem 51.41.
Theorem 51.42 has to do with the existence of an optimal solution for (P), but it does
not say anything about the optimal value of (P). To establish such a result, we need the
notion of dual function.
The dual function G is defined by
G(λ, µ) = inf
v∈Rn
L(v, λ, µ).
It is a concave function (so −G is convex) which may take the values ±∞. Note that
maximizing G, which is equivalent to minimizing −G, runs into troubles if G(λ, µ) = +∞
for some λ, µ, but that G(λ, µ) = −∞ does not cause a problem. At first glance, this seems
counterintuitive, but remember that G is concave, not convex . It is −G that is convex, and
−∞ and +∞ get flipped.
Then a generalized and stronger version of Theorem 50.19(2) also holds. A proof can
be obtained by putting together Corollary 28.3.1, Theorem 28.4, and Corollary 28.4.1, in
Rockafellar [138]. For the sake of completeness, we state the following results from Rockafellar
[138].
1862 CHAPTER 51. SUBGRADIENTS AND SUBDIFFERENTIALS ~
Theorem 51.43. (Theorem 28.4, Rockafellar) Let (P) be an ordinary convex program with
Lagrangian L(x, λ, µ). If the Lagrange multipliers (λ
∗
, µ∗
) ∈ R
m
+ ×R
p and the vector x
∗ ∈ R
n
have the property that
(a) The infimum of the function h = J +
P
m
i=1 λ
∗
iϕi +
P
p
j=1 µ
∗
jψj is finite and equal to the
optimal value of J over U, and
(b) The vector x
∗
is an optimal solution of (P) (so x
∗ ∈ U),
then the saddle value L(x
∗
, λ∗
, µ∗
) is the optimal value J(x
∗
) of (P).
More generally, the Lagrange multipliers (λ
∗
, µ∗
) ∈ R
m
+ × R
p have Property (a) iff
−∞ < inf
x
L(x, λ∗
, µ∗
) ≤ sup
λ,µ
inf
x
L(x, λ, µ) = inf
x
sup
λ,µ
L(x, λ, µ),
in which case, the common value of the extremum value is the optimal value of (P). In
particular, if x
∗
is an optimal solution for (P), then supλ,µ G(λ, µ) = L(x
∗
, λ∗
, µ∗
) = J(x
∗
)
(zero duality gap).
Observe that Theorem 51.43 gives sufficient Conditions (a) and (b) for the duality gap to
be zero. In view of Theorem 51.41, these conditions are equivalent to the fact that (x
∗
, λ∗
, µ∗
)
is a saddle point of L, or equivalently that the KKT conditions hold.
Again, by Theorem 51.40, if the optimal value of (P) is finite and if the constraints are
qualified, then Condition (a) of Theorem 51.43 holds for (λ, µ). Then the following corollary
of Theorem 51.43 holds.
Theorem 51.44. (Theorem 28.4.1, Rockafellar) Let (P) be an ordinary convex program
satisfying the hypothesis of Theorem 51.40, which means that the optimal value of (P) is
finite, and that the constraints are qualified. The Lagrange multipliers (λ, µ) ∈ R
m
+ × R
p
that
have the property that the infimum of the function h = J +
P
m
i=1 λiϕi +
P
p
j=1 µjψj is finite
and equal to the optimal value of J over U are exactly the vectors where the dual function G
attains is supremum over R
n
.
Theorem 51.44 is a generalized and stronger version of Theorem 50.19(2). Part (1) of
Theorem 50.19 requires J and the ϕi to be differentiable, so it does not generalize.
More results can shown about ordinary convex programs, and another class of programs
called generalized convex programs. However, we do not need such resuts for our purposes,
in particular to discuss the ADMM method. The interested reader is referred to Rockafellar
[138] (Part VI, Sections 28 and 29).
51.7 Summary
The main concepts and results of this chapter are listed below:
• Extended real-valued functions.
51.7. SUMMARY 1863
• Epigraph (epi(f)).
• Convex and concave (extended real-valued) functions.
• Effective domain (dom(f)).
• Proper and improper convex functions.
• Sublevel sets.
• Lower semi-continuous functions.
• Lower semi-continuous hull; closure of a convex function.
• Relative interior (relint(C)).
• Indicator function.
• Lipschitz condition.
• Affine form, affine hyperplane.
• Half spaces.
• Supporting hyperplane.
• Normal cone at a.
• Subgradient, subgradient inequality, subdifferential.
• Minkowski’s supporting hyperplane theorem.
• One-sided directional derivative.
• Support function.
• ReLU function.
•  -subgradient.
• Minimum set of a convex function.
• Direction of recession.
• Ordinary convex programs.
• Set of feasible solutions.
• Lagrangian.
1864 CHAPTER 51. SUBGRADIENTS AND SUBDIFFERENTIALS ~
• Saddle point.
• KKT conditions.
• Qualified constraints.
• Duality gap.
51.8 Problems
Problem 51.1. Prove Proposition 51.1.
Problem 51.2. Prove Proposition 51.2.
Problem 51.3. Prove Proposition 51.3.
Problem 51.4. Prove that the convex function defined in Example 51.4 has the property
that the limit along any line segment from (0, 0) to a point in the open right half-plane is 0.
Problem 51.5. Check that the normal cone to C at a is a convex cone.
Problem 51.6. Prove that ∂f(x) is closed and convex.
Problem 51.7. For Example 51.6, with f(x) = k xk ∞, prove that ∂f(0) is the polyhedron
∂f(0) = conv{±e1, . . . , ±en}.
Problem 51.8. For Example 51.7, with
f(x) = ( −
+∞
(1 − |x|
2
)
1/2
otherwise
if |x| ≤ 1
.
prove that f is subdifferentiable (in fact differentiable) at x when |x| < 1, but ∂f(x) = ∅
when |x| ≥ 1, even though x ∈ dom(f) for |x| = 1
Problem 51.9. Prove Proposition 51.15.
Problem 51.10. Prove that as a convex function of u, the effective domain of the function
u 7→ f
0 (x; u) is the convex cone generated by dom(f) − x.
Problem 51.11. Prove Proposition 51.28.
Problem 51.12. Prove Proposition 51.33.
Problem 51.13. Prove that Proposition 51.38(2) also holds in the following cases:
(1) C is a H-polyhedron and relint(dom(h)) ∩ C 6 = ∅
(2) h is polyhedral and dom(h) ∩ relint(C) 6 = ∅.
(3) Both h and C are polyhedral, and dom(h) ∩ C 6 = ∅.
Chapter 52
Dual Ascent Methods; ADMM
This chapter is devoted to the presentation of one of the best methods known at the present
for solving optimization problems involving equality constraints. In fact, this method can
also handle more general constraints, namely, membership in a convex set. It can also be used
to solve a range of problems arising in machine learning including lasso minimization, elastic
net regression, support vector machine (SVM), and ν-SV regression. In order to obtain a
good understanding of this method, called the alternating direction method of multipliers, for
short ADMM , we review two precursors of ADMM, the dual ascent method and the method
of multipliers.
ADMM is not a new method. In fact, it was developed in the 1970’s. It has been revived
as a very effective method to solve problems in statistical and machine learning dealing with
very large data because it is well suited to distributed (convex) optimization. An extensive
presentation of ADMM, its variants, and its applications, is given in the excellent paper by
Boyd, Parikh, Chu, Peleato and Eckstein [28]. This paper is essentially a book on the topic
of ADMM, and our exposition is deeply inspired by it.
In this chapter, we consider the problem of minimizing a convex function J (not neces￾sarily differentiable) under the equality constraints Ax = b. In Section 52.1 we discuss the
dual ascent method. It is essentially gradient descent applied to the dual function G, but
since G is maximized, gradient descent becomes gradient ascent.
In order to make the minimization step of the dual ascent method more robust, one can
use the trick of adding the penalty term (ρ/2) k Au − bk
2
2
to the Lagrangian. We obtain the
augmented Lagrangian
Lρ(u, λ) = J(u) + λ
> (Au − b) + (ρ/2) k Au − bk
2
2
,
with λ ∈ R
m, and where ρ > 0 is called the penalty parameter . We obtain the minimization
Problem (Pρ),
minimize J(u) + (ρ/2) k Au − bk
2
2
subject to Au = b,
1865
1866 CHAPTER 52. DUAL ASCENT METHODS; ADMM
which is equivalent to the original problem.
The benefit of adding the penalty term (ρ/2) k Au − bk
2
2
is that by Proposition 51.37,
Problem (Pρ) has a unique optimal solution under mild conditions on A. Dual ascent applied
to the dual of (Pρ) is called the method of multipliers and is discussed in Section 52.2.
The alternating direction method of multipliers, for short ADMM, combines the decom￾posability of dual ascent with the superior convergence properties of the method of multipli￾ers. The idea is to split the function J into two independent parts, as J(x, z) = f(x) + g(z),
and to consider the Minimization Problem (Padmm),
minimize f(x) + g(z)
subject to Ax + Bz = c,
for some p × n matrix A, some p × m matrix B, and with x ∈ R
n
, z ∈ R
m, and c ∈ R
p
. We
also assume that f and g are convex. Further conditions will be added later.
As in the method of multipliers, we form the augmented Lagrangian
Lρ(x, z, λ) = f(x) + g(z) + λ
> (Ax + Bz − c) + (ρ/2) k Ax + Bz − ck
2
2
,
with λ ∈ R
p and for some ρ > 0. The major difference with the method of multipliers is that
instead of performing a minimization step jointly over x and z, ADMM first performs an
x-minimization step and then a z-minimization step. Thus x and z are updated in an alter￾nating or sequential fashion, which accounts for the term alternating direction. Because the
Lagrangian is augmented, some mild conditions on A and B imply that these minimization
steps are guaranteed to terminate. ADMM is presented in Section 52.3.
In Section 52.4 we prove the convergence of ADMM under the following assumptions:
(1) The functions f : R → R∪ {+∞} and g : R → R∪ {+∞} are proper and closed convex
functions (see Section 51.1) such that relint(dom(f)) ∩ relint(dom(g)) 6 = ∅.
(2) The n × n matrix A> A is invertible and the m × m matrix B> B is invertible. Equiv￾alently, the p × n matrix A has rank n and the p × m matrix has rank m.
(3) The unaugmented Lagrangian L0(x, z, λ) = f(x)+g(z)+λ
> (Ax+Bz −c) has a saddle
point, which means there exists x
∗
, z∗
, λ∗
(not necessarily unique) such that
L0(x
∗
, z∗
, λ) ≤ L0(x
∗
, z∗
, λ∗
) ≤ L0(x, z, λ∗
)
for all x, z, λ.
By Theorem 51.41, Assumption (3) is equivalent to the fact that the KKT equations are
satisfied by some triple (x
∗
, z∗
, λ∗
), namely
Ax∗ + Bz∗ − c = 0 (∗)
52.1. DUAL ASCENT 1867
and
0 ∈ ∂f(x
∗
) + ∂g(z
∗
) + A
> λ
∗ + B
> λ
∗
, (†)
Assumption (3) is also equivalent to Conditions (a) and (b) of Theorem 51.41. In particular,
our program has an optimal solution (x
∗
, z∗
). By Theorem 51.43, λ
∗
is maximizer of the dual
function G(λ) = infx,z L0(x, z, λ) and strong duality holds, that is, G(λ
∗
) = f(x
∗
) + g(z
∗
)
(the duality gap is zero).
We will show after the proof of Theorem 52.1 that Assumption (2) is actually implied by
Assumption (3). This allows us to prove a convergence result stronger than the convergence
result proven in Boyd et al. [28] (under the exact same assumptions (1) and (3)). In
particular, we prove that all of the sequences (x
k
), (z
k
), and (λ
k
) converge to optimal
solutions (x, e ze), and e λ. The core of our proof is due to Boyd et al. [28], but there are new
steps because we have the stronger hypothesis (2).
In Section 52.5, we discuss stopping criteria.
In Section 52.6 we present some applications of ADMM, in particular, minimization of a
proper closed convex function f over a closed convex set C in R
n and quadratic program￾ming. The second example provides one of the best methods for solving quadratic problems,
including the SVM problems discussed in Chapter 54, the elastic net method in Section 55.6,
and ν-SV regression in Chapter 56.
Section 52.8 gives applications of ADMM to ` 1
-norm problems, in particular, lasso regu￾larization, which plays an important role in machine learning.
52.1 Dual Ascent
Our goal is to solve the minimization problem, Problem (P),
minimize J(u)
subject to Au = b,
with affine equality constraints (with A an m × n matrix and b ∈ R
m). The Lagrangian
L(u, λ) of Problem (P) is given by
L(u, λ) = J(u) + λ
> (Au − b).
with λ ∈ R
m. From Proposition 50.20, the dual function G(λ) = infu∈Rn L(u, λ) is given by
G(λ) = ( −
−∞
b
> λ − J
∗
(−A> λ) if
otherwise
−A> λ ∈
,
dom(J
∗
),
for all λ ∈ R
m, where J
∗
is the conjugate of J. Recall that by Definition 50.11, the conjugate
f
∗ of a function f : U → R defined on a subset U of R
n
is the partial function f
∗
: R
n → R
defined by
f
∗
(y) = sup
x∈U
(y
> x − f(x)), y ∈ R
n
.
1868 CHAPTER 52. DUAL ASCENT METHODS; ADMM
If the conditions of Theorem 50.19(1) hold, which in our case means that for every
λ ∈ R
m, there is a unique uλ ∈ R
n
such that
G(λ) = L(uλ, λ) = inf
u∈Rn
L(u, λ),
and that the function λ 7→ uλ is continuous, then G is differentiable. Furthermore, we have
∇Gλ = Auλ − b,
and for any solution µ = λ
∗ of the dual problem
maximize G(λ)
subject to λ ∈ R
m,
the vector u
∗ = uµ is a solution of the primal Problem (P). Furthermore, J(u
∗
) = G(λ
∗
),
that is, the duality gap is zero.
The dual ascent method is essentially gradient descent applied to the dual function G.
But since G is maximized, gradient descent becomes gradient ascent. Also, we no longer
worry that the minimization problem infu∈Rn L(u, λ) has a unique solution, so we denote by
u
+ some minimizer of the above problem, namely
u
+ = arg min
u
L(u, λ).
Given some initial dual variable λ
0
, the dual ascent method consists of the following two
steps:
u
k+1 = arg min
u
L(u, λk
)
λ
k+1 = λ
k + α
k
(Auk+1 − b),
where α
k > 0 is a step size. The first step is used to compute the “new gradient” (indeed,
if the minimizer u
k+1 is unique, then ∇Gλk = Auk+1 − b), and the second step is a dual
variable update.
Example 52.1. Let us look at a very simple example of the gradient ascent method applied
to a problem we first encountered in Section 42.1, namely minimize J(x, y) = (1/2)(x
2 + y
2
)
subject to 2x − y = 5. The Lagrangian is
L(x, y, λ) = 1
2
(x
2 + y
2
) + λ(2x − y − 5).
See Figure 52.1.
The method of Lagrangian duality says first calculate
G(λ) = inf
(x,y)∈R2
L(x, y, λ).
52.1. DUAL ASCENT 1869
Figure 52.1: The graph of J(x, y) = (1/2)(x
2 + y
2
) is the parabolic surface while the graph
of 2x − y = 5 is the transparent blue plane. The solution to Example 52.1 is apex of the
intersection curve, namely the point (2, −1,
5
2
).
Since
J(x, y) = 1
2
￾
x y 
1 0
0 1 
x
y

,
we observe that

1 0
0 1 , and hence to calculate
J(x, y) is a quadratic function determined by the positive definite matrix
G(λ), we must set ∇Lx,y = 0. By calculating ∂J
∂x = 0 and
∂J
∂y = 0, we find that x = −2λ and y = λ. Then G(λ) = −5/2λ
2 − 5λ, and we must
calculate the maximum of G(λ) with respect to λ ∈ R. This means calculating G0 (λ) = 0
and obtaining λ = −1 for the solution of (x, y, λ) = (−2λ, λ, λ) = (2, −1, −1).
Instead of solving directly for λ in terms of (x, y), the method of dual assent begins with
a numerical estimate for λ, namely λ
0
, and forms the “numerical” Lagrangian
L(x, y, λ0
) = 1
2
(x
2 + y
2
) + λ
0
(2x − y − 5).
With this numerical value λ
0
, we minimize L(x, y, λ0
) with respect to (x, y). This calculation
will be identical to that used to form G(λ) above, and as such, we obtain the iterative step
(x
1
, y1
) = (−2λ
0
, λ0
). So if we replace λ
0 by λ
k
, we have the first step of the dual ascent
method, namely
u
k+1 =

x
y
k
k
+1
+1
=

−
1
2

λ
k
.
The second step of the dual ascent method refines the numerical estimate of λ by calculating
λ
k+1 = λ
k + α
k

￾
2 −1


x
y
k
k
+1
+1
− 5
 .
1870 CHAPTER 52. DUAL ASCENT METHODS; ADMM
(Recall that in our original problem the constraint is 2x − y = 5 or ￾ 2 −1


x
y

− 5, so
A =
￾ 2 −1
 and b = 5.) By simplifying the above equation, we find that
λ
k+1 = (1 − β)λ
k − β, β = 5α
k
.
Back substituting for λ
k
in the preceding equation shows that
λ
k+1 = (1 − β)
k+1λ
0 + (1 − β)
k+1 − 1.
If 0 < β ≤ 1, the preceding line implies that λ
k+1 converges to λ = −1, which coincides with
the answer provided by the original Lagrangian duality method. Observe that if β = 1 or
α
k = 5
1
, the dual ascent method terminates in one step.
With an appropriate choice of α
k
, we have G(λ
k+1) > G(λ
k
), so the method makes
progress. Under certain assumptions, for example, that J is strictly convex and some condi￾tions of the α
k
, it can be shown that dual ascent converges to an optimal solution (both for
the primal and the dual). However, the main flaw of dual ascent is that the minimization
step may diverge. For example, this happens is J is a nonzero affine function of one of its
components. The remedy is to add a penalty term to the Lagrangian.
On the positive side, the dual ascent method leads to a decentralized algorithm if the
function J is separable. Suppose that u can be split as u =
P
N
i=1 ui
, with ui ∈ R
ni and
n =
P
N
i=1 ni
, that
J(u) =
N
X
i=1
Ji(ui),
and that A is split into N blocks Ai (with Ai a m × ni matrix) as A = [A1 · · · AN ], so that
Au =
P
N
k=1 Aiui
. Then the Lagrangian can be written as
L(u, λ) =
N
X
i=1
Li(ui
, λ),
with
Li(ui
, λ) = Ji(ui) + λ
>
 Aiui −
N
1
b
 .
it follows that the minimization of L(u, λ) with respect to the primal variable u can be split
into N separate minimization problems that can be solved in parallel. The algorithm then
performs the N updates
u
k
i
+1 = arg min
ui
Li(ui
, λk
)
in parallel, and then the step
λ
k+1 = λ
k + α
k
(Auk+1 − b).
52.2. AUGMENTED LAGRANGIANS AND THE METHOD OF MULTIPLIERS 1871
52.2 Augmented Lagrangians and the Method of
Multipliers
In order to make the minimization step of the dual ascent method more robust, one can use
the trick of adding the penalty term (ρ/2) k Au − bk
2
2
to the Lagrangian.
Definition 52.1. Given the Optimization Problem (P),
minimize J(u)
subject to Au = b,
the augmented Lagrangian is given by
Lρ(u, λ) = J(u) + λ
> (Au − b) + (ρ/2) k Au − bk
2
2
,
with λ ∈ R
m, and where ρ > 0 is called the penalty parameter .
The augmented Lagrangian Lρ(u, λ) can be viewed as the ordinary Lagrangian of the
Minimization Problem (Pρ),
minimize J(u) + (ρ/2) k Au − bk
2
2
subject to Au = b.
The above problem is equivalent to Program (P), since for any feasible solution of (Pρ), we
must have Au − b = 0.
The benefit of adding the penalty term (ρ/2) k Au − bk
2
2
is that by Proposition 51.37,
Problem (Pρ) has a unique optimal solution under mild conditions on A.
Dual ascent applied to the dual of (Pρ) yields the the method of multipliers, which consists
of the following steps, given some initial λ
0
:
u
k+1 = arg min
u
Lρ(u, λk
)
λ
k+1 = λ
k + ρ(Auk+1 − b).
Observe that the second step uses the parameter ρ. The reason is that it can be shown
that choosing α
k = ρ guarantees that (u
k+1, λk+1) satisfies the equation
∇Juk+1 + A
> λ
k+1 = 0,
which means that (u
k+1, λk+1) is dual feasible; see Boyd, Parikh, Chu, Peleato and Eckstein
[28], Section 2.3.
Example 52.2. Consider the minimization problem
minimize y
2 + 2x
subject to 2x − y = 0.
1872 CHAPTER 52. DUAL ASCENT METHODS; ADMM
Figure 52.2: Two views of the graph of y
2 + 2x intersected with the transparent red plane
2x−y = 0. The solution to Example 52.2 is apex of the intersection curve, namely the point
(−
1
4
, −
1
2
, −
15
16 ).
See Figure 52.2.
The quadratic function
J(x, y) = y
2 + 2x =
￾ x y 
0 0
0 1 
x
y

+
￾ 2 0  x
y

is convex but not strictly convex. Since y = 2x, the problem is equivalent to minimizing
y
2 + 2x = 4x
2 + 2x, whose minimum is achieved for x = −1/4 (since setting the derivative
of the function x 7→ 4x
2 + 2 yields 8x + 2 = 0). Thus, the unique minimum of our problem
is achieved for (x = −1/4, y = −1/2). The Lagrangian of our problem is
L(x, y, λ) = y
2 + 2x + λ(2x − y).
If we apply the dual ascent method, minimization of L(x, y, λ) with respect to x and y
holding λ constant yields the equations
2 + 2λ = 0
2y − λ = 0,
obtained by setting the gradient of L (with respect to x and y) to zero. If λ 6 = −1, the
problem has no solution. Indeed, if λ 6 = −1, minimizing L(x, y, λ) = y
2 + 2x + λ(2x − y)
with respect to x and y yields −∞.
52.2. AUGMENTED LAGRANGIANS AND THE METHOD OF MULTIPLIERS 1873
The augmented Lagrangian is
Lρ(x, y, λ) = y
2 + 2x + λ(2x − y) + (ρ/2)(2x − y)
2
= 2ρx2 − 2ρxy + 2(1 + λ)x − λy +
 1 +
ρ
2

y
2
,
which in matrix form is
Lρ(x, y, λ) = ￾ x y 
2ρ
2 −ρ
−ρ 1 +
ρ
2
!

x
y

+
￾ 2(1 + λ) −λ


x
y

.
The trace of the above matrix is 1 + ρ
2 + 2ρ
2 > 0, and the determinant is
2ρ
2

1 +
ρ
2

− ρ
2 = ρ
2
(1 + ρ) > 0,
since ρ > 0. Therefore, the above matrix is symmetric positive definite. Minimizing
Lρ(x, y, λ) with respect to x and y, we set the gradient of Lρ(x, y, λ) (with respect to x
and y) to zero, and we obtain the equations:
2ρx − ρy + (1 + λ) = 0
−2ρx + (2 + ρ)y − λ = 0.
The solution is
x = −
1
4
−
1 + λ
2ρ
, y = −
1
2
.
Thus the steps for the method of multipliers are
x
k+1 = −
1
4
−
1 + λ
k
2ρ
y
k+1 = −
1
2
λ
k+1 = λ
k + ρ
￾ 2 −1


−
1
4 −
1+λ
k
2ρ
−
1
2

,
and the second step simplifies to
λ
k+1 = −1.
Consequently, we see that the method converges after two steps for any initial value of λ
0
,
and we get
x = −
1
4
y = −
1
2
, λ = −1.
The method of multipliers also converges for functions J that are not even convex, as
illustrated by the next example.
1874 CHAPTER 52. DUAL ASCENT METHODS; ADMM
Figure 52.3: Two views of the graph of the saddle of 2xy (β = 1) intersected with the trans￾parent magenta plane 2x − y = 0. The solution to Example 52.3 is apex of the intersection
curve, namely the point (0, 0, 0).
Example 52.3. Consider the minimization problem
minimize 2βxy
subject to 2x − y = 0,
with β > 0. See Figure 52.3.
The quadratic function
J(x, y) = 2βxy =
￾ x y  β
0 β
0
 
x
y

is not convex because the above matrix is not even positive semidefinite (the eigenvalues of
the matrix are −β and +β). The augmented Lagrangian is
Lρ(x, y, λ) = 2βxy + λ(2x − y) + (ρ/2)(2x − y)
2
= 2ρx2 + 2(β − ρ)xy + 2λx − λy +
ρ
2
y
2
,
which in matrix form is
Lρ(x, y, λ) = ￾ x y β
2
−
ρ β
ρ
−
ρ
2
ρ
!
 x
y

+
￾ 2λ −λ


x
y

.
52.2. AUGMENTED LAGRANGIANS AND THE METHOD OF MULTIPLIERS 1875
The trace of the above matrix is 2ρ +
ρ
2 =
5
2
ρ > 0, and the determinant is
ρ
2 − (β − ρ)
2 = β(2ρ − β).
This determinant is positive if ρ > β/2, in which case the matrix is symmetric positive
definite. Minimizing Lρ(x, y, λ) with respect to x and y, we set the gradient of Lρ(x, y, λ)
(with respect to x and y) to zero, and we obtain the equations:
2ρx + (β − ρ)y + λ = 0
2(β − ρ)x + ρy − λ = 0.
Since we are assuming that ρ > β/2, the solutions are
x = −
λ
2(2ρ − β)
, y =
λ
(2ρ − β)
.
Thus the steps for the method of multipliers are
x
k+1 = −
λ
k
2(2ρ − β)
y
k+1 =
λ
k
(2ρ − β)
λ
k+1 = λ
k +
ρ
2(2ρ − β)
￾
2 −1


−λ
k
2λ
k

,
and the second step simplifies to
λ
k+1 = λ
k +
ρ
2(2ρ − β)
(−4λ
k
),
that is,
λ
k+1 = −
β
2ρ − β
λ
k
.
If we pick ρ > β > 0, which implies that ρ > β/2, then
β
2ρ − β
< 1,
and the method converges for any intial value λ
0
to the solution
x = 0, y = 0, λ = 0.
Indeed, since the constraint 2x−y = 0 holds, 2βxy = 4βx2
, and the minimum of the function
x 7→ 4βx2
is achieved for x = 0 (since β > 0).
1876 CHAPTER 52. DUAL ASCENT METHODS; ADMM
As an exercise, the reader should verify that dual ascent (with α
k = ρ) yields the equations
x
k+1 =
λ
k
2β
y
k+1 = −
λ
k
β
λ
k+1 =
 1 +
2
β
ρ

λ
k
