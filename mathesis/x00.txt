Algebra, Topology, Differential Calculus, and
Optimization Theory
For Computer Science and Machine Learning
Jean Gallier and Jocelyn Quaintance
Department of Computer and Information Science
University of Pennsylvania
Philadelphia, PA 19104, USA
e-mail: jean@seas.upenn.edu
© Jean Gallier
December 31, 2024
2
Contents
Contents 3
1 Introduction 19
2 Groups, Rings, and Fields 21
2.1 Groups, Subgroups, Cosets . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2.2 Cyclic Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
2.3 Rings and Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
I Linear Algebra 47
3 Vector Spaces, Bases, Linear Maps 49
3.1 Motivations: Linear Combinations, Linear Independence, Rank . . . . . . . 49
3.2 Vector Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
3.3 Indexed Families; the Sum Notation P i∈I
ai
. . . . . . . . . . . . . . . . . . 64
3.4 Linear Independence, Subspaces . . . . . . . . . . . . . . . . . . . . . . . . 70
3.5 Bases of a Vector Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
3.6 Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
3.7 Linear Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
3.8 Quotient Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
3.9 Linear Forms and the Dual Space . . . . . . . . . . . . . . . . . . . . . . . . 101
3.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
3.11 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
4 Matrices and Linear Maps 113
4.1 Representation of Linear Maps by Matrices . . . . . . . . . . . . . . . . . . 113
4.2 Composition of Linear Maps and Matrix Multiplication . . . . . . . . . . . 118
4.3 Change of Basis Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
4.4 The Effect of a Change of Bases on Matrices . . . . . . . . . . . . . . . . . 129
4.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
4.6 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
5 Haar Bases, Haar Wavelets, Hadamard Matrices 141
3
4 CONTENTS
5.1 Introduction to Signal Compression Using Haar Wavelets . . . . . . . . . . 141
5.2 Haar Matrices, Scaling Properties of Haar Wavelets . . . . . . . . . . . . . . 143
5.3 Kronecker Product Construction of Haar Matrices . . . . . . . . . . . . . . 148
5.4 Multiresolution Signal Analysis with Haar Bases . . . . . . . . . . . . . . . 150
5.5 Haar Transform for Digital Images . . . . . . . . . . . . . . . . . . . . . . . 153
5.6 Hadamard Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
5.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
5.8 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
6 Direct Sums 167
6.1 Sums, Direct Sums, Direct Products . . . . . . . . . . . . . . . . . . . . . . 167
6.2 Matrices of Linear Maps and Multiplication by Blocks . . . . . . . . . . . . 177
6.3 The Rank-Nullity Theorem; Grassmann’s Relation . . . . . . . . . . . . . . 190
6.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
6.5 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
7 Determinants 207
7.1 Permutations, Signature of a Permutation . . . . . . . . . . . . . . . . . . . 207
7.2 Alternating Multilinear Maps . . . . . . . . . . . . . . . . . . . . . . . . . . 211
7.3 Definition of a Determinant . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
7.4 Inverse Matrices and Determinants . . . . . . . . . . . . . . . . . . . . . . . 224
7.5 Systems of Linear Equations and Determinants . . . . . . . . . . . . . . . . 227
7.6 Determinant of a Linear Map . . . . . . . . . . . . . . . . . . . . . . . . . . 229
7.7 The Cayley–Hamilton Theorem . . . . . . . . . . . . . . . . . . . . . . . . . 230
7.8 Permanents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
7.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
7.10 Further Readings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
7.11 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
8 Gaussian Elimination, LU, Cholesky, Echelon Form 245
8.1 Motivating Example: Curve Interpolation . . . . . . . . . . . . . . . . . . . 245
8.2 Gaussian Elimination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
8.3 Elementary Matrices and Row Operations . . . . . . . . . . . . . . . . . . . 254
8.4 LU-Factorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
8.5 P A = LU Factorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
8.6 Proof of Theorem 8.5 ~ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
8.7 Dealing with Roundoff Errors; Pivoting Strategies . . . . . . . . . . . . . . . 276
8.8 Gaussian Elimination of Tridiagonal Matrices . . . . . . . . . . . . . . . . . 278
8.9 SPD Matrices and the Cholesky Decomposition . . . . . . . . . . . . . . . . 280
8.10 Reduced Row Echelon Form . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
8.11 RREF, Free Variables, Homogeneous Systems . . . . . . . . . . . . . . . . . 295
8.12 Uniqueness of RREF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
8.13 Solving Linear Systems Using RREF . . . . . . . . . . . . . . . . . . . . . . 300
CONTENTS 5
8.14 Elementary Matrices and Columns Operations . . . . . . . . . . . . . . . . 306
8.15 Transvections and Dilatations ~ . . . . . . . . . . . . . . . . . . . . . . . . 307
8.16 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
8.17 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314
9 Vector Norms and Matrix Norms 325
9.1 Normed Vector Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
9.2 Matrix Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
9.3 Subordinate Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
9.4 Inequalities Involving Subordinate Norms . . . . . . . . . . . . . . . . . . . 349
9.5 Condition Numbers of Matrices . . . . . . . . . . . . . . . . . . . . . . . . . 351
9.6 An Application of Norms: Inconsistent Linear Systems . . . . . . . . . . . . 360
9.7 Limits of Sequences and Series . . . . . . . . . . . . . . . . . . . . . . . . . 361
9.8 The Matrix Exponential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364
9.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367
9.10 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369
10 Iterative Methods for Solving Linear Systems 375
10.1 Convergence of Sequences of Vectors and Matrices . . . . . . . . . . . . . . 375
10.2 Convergence of Iterative Methods . . . . . . . . . . . . . . . . . . . . . . . . 378
10.3 Methods of Jacobi, Gauss–Seidel, and Relaxation . . . . . . . . . . . . . . . 380
10.4 Convergence of the Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . 388
10.5 Convergence Methods for Tridiagonal Matrices . . . . . . . . . . . . . . . . 391
10.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396
10.7 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
11 The Dual Space and Duality 401
11.1 The Dual Space E
∗ and Linear Forms . . . . . . . . . . . . . . . . . . . . . 401
11.2 Pairing and Duality Between E and E
∗
. . . . . . . . . . . . . . . . . . . . 408
11.3 The Duality Theorem and Some Consequences . . . . . . . . . . . . . . . . 413
11.4 The Bidual and Canonical Pairings . . . . . . . . . . . . . . . . . . . . . . . 419
11.5 Hyperplanes and Linear Forms . . . . . . . . . . . . . . . . . . . . . . . . . 421
11.6 Transpose of a Linear Map and of a Matrix . . . . . . . . . . . . . . . . . . 422
11.7 Properties of the Double Transpose . . . . . . . . . . . . . . . . . . . . . . . 429
11.8 The Four Fundamental Subspaces . . . . . . . . . . . . . . . . . . . . . . . 431
11.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 434
11.10 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
12 Euclidean Spaces 439
12.1 Inner Products, Euclidean Spaces . . . . . . . . . . . . . . . . . . . . . . . . 439
12.2 Orthogonality and Duality in Euclidean Spaces . . . . . . . . . . . . . . . . 448
12.3 Adjoint of a Linear Map . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 455
12.4 Existence and Construction of Orthonormal Bases . . . . . . . . . . . . . . 458
6 CONTENTS
12.5 Linear Isometries (Orthogonal Transformations) . . . . . . . . . . . . . . . . 465
12.6 The Orthogonal Group, Orthogonal Matrices . . . . . . . . . . . . . . . . . 468
12.7 The Rodrigues Formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470
12.8 QR-Decomposition for Invertible Matrices . . . . . . . . . . . . . . . . . . . 473
12.9 Some Applications of Euclidean Geometry . . . . . . . . . . . . . . . . . . . 478
12.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 479
12.11 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 481
13 QR-Decomposition for Arbitrary Matrices 493
13.1 Orthogonal Reflections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 493
13.2 QR-Decomposition Using Householder Matrices . . . . . . . . . . . . . . . . 498
13.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 508
13.4 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 508
14 Hermitian Spaces 515
14.1 Hermitian Spaces, Pre-Hilbert Spaces . . . . . . . . . . . . . . . . . . . . . 515
14.2 Orthogonality, Duality, Adjoint of a Linear Map . . . . . . . . . . . . . . . 524
14.3 Linear Isometries (Also Called Unitary Transformations) . . . . . . . . . . . 529
14.4 The Unitary Group, Unitary Matrices . . . . . . . . . . . . . . . . . . . . . 531
14.5 Hermitian Reflections and QR-Decomposition . . . . . . . . . . . . . . . . . 534
14.6 Orthogonal Projections and Involutions . . . . . . . . . . . . . . . . . . . . 539
14.7 Dual Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542
14.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 549
14.9 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 550
15 Eigenvectors and Eigenvalues 555
15.1 Eigenvectors and Eigenvalues of a Linear Map . . . . . . . . . . . . . . . . . 555
15.2 Reduction to Upper Triangular Form . . . . . . . . . . . . . . . . . . . . . . 563
15.3 Location of Eigenvalues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 567
15.4 Conditioning of Eigenvalue Problems . . . . . . . . . . . . . . . . . . . . . . 571
15.5 Eigenvalues of the Matrix Exponential . . . . . . . . . . . . . . . . . . . . . 573
15.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 575
15.7 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 576
16 Unit Quaternions and Rotations in SO(3) 587
16.1 The Group SU(2) and the Skew Field H of Quaternions . . . . . . . . . . . 587
16.2 Representation of Rotation in SO(3) By Quaternions in SU(2) . . . . . . . 589
16.3 Matrix Representation of the Rotation rq . . . . . . . . . . . . . . . . . . . 594
16.4 An Algorithm to Find a Quaternion Representing a Rotation . . . . . . . . 596
16.5 The Exponential Map exp: su(2) → SU(2) . . . . . . . . . . . . . . . . . . 599
16.6 Quaternion Interpolation ~ . . . . . . . . . . . . . . . . . . . . . . . . . . . 602
16.7 Nonexistence of a “Nice” Section from SO(3) to SU(2) . . . . . . . . . . . . 604
16.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 606
CONTENTS 7
16.9 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 607
17 Spectral Theorems 611
17.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 611
17.2 Normal Linear Maps: Eigenvalues and Eigenvectors . . . . . . . . . . . . . . 611
17.3 Spectral Theorem for Normal Linear Maps . . . . . . . . . . . . . . . . . . . 617
17.4 Self-Adjoint and Other Special Linear Maps . . . . . . . . . . . . . . . . . . 622
17.5 Normal and Other Special Matrices . . . . . . . . . . . . . . . . . . . . . . . 628
17.6 Rayleigh–Ritz Theorems and Eigenvalue Interlacing . . . . . . . . . . . . . 631
17.7 The Courant–Fischer Theorem; Perturbation Results . . . . . . . . . . . . . 636
17.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 639
17.9 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 640
18 Computing Eigenvalues and Eigenvectors 647
18.1 The Basic QR Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 649
18.2 Hessenberg Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 655
18.3 Making the QR Method More Efficient Using Shifts . . . . . . . . . . . . . 661
18.4 Krylov Subspaces; Arnoldi Iteration . . . . . . . . . . . . . . . . . . . . . . 666
18.5 GMRES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 670
18.6 The Hermitian Case; Lanczos Iteration . . . . . . . . . . . . . . . . . . . . . 671
18.7 Power Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 672
18.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 674
18.9 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 675
19 Introduction to The Finite Elements Method 677
19.1 A One-Dimensional Problem: Bending of a Beam . . . . . . . . . . . . . . . 677
19.2 A Two-Dimensional Problem: An Elastic Membrane . . . . . . . . . . . . . 688
19.3 Time-Dependent Boundary Problems . . . . . . . . . . . . . . . . . . . . . . 691
20 Graphs and Graph Laplacians; Basic Facts 699
20.1 Directed Graphs, Undirected Graphs, Weighted Graphs . . . . . . . . . . . 702
20.2 Laplacian Matrices of Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . 709
20.3 Normalized Laplacian Matrices of Graphs . . . . . . . . . . . . . . . . . . . 713
20.4 Graph Clustering Using Normalized Cuts . . . . . . . . . . . . . . . . . . . 717
20.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 719
20.6 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 720
21 Spectral Graph Drawing 723
21.1 Graph Drawing and Energy Minimization . . . . . . . . . . . . . . . . . . . 723
21.2 Examples of Graph Drawings . . . . . . . . . . . . . . . . . . . . . . . . . . 726
21.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 730
22 Singular Value Decomposition and Polar Form 733
8 CONTENTS
22.1 Properties of f
∗ ◦ f . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 733
22.2 Singular Value Decomposition for Square Matrices . . . . . . . . . . . . . . 739
22.3 Polar Form for Square Matrices . . . . . . . . . . . . . . . . . . . . . . . . . 743
22.4 Singular Value Decomposition for Rectangular Matrices . . . . . . . . . . . 745
22.5 Ky Fan Norms and Schatten Norms . . . . . . . . . . . . . . . . . . . . . . 749
22.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 750
22.7 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 750
23 Applications of SVD and Pseudo-Inverses 755
23.1 Least Squares Problems and the Pseudo-Inverse . . . . . . . . . . . . . . . . 755
23.2 Properties of the Pseudo-Inverse . . . . . . . . . . . . . . . . . . . . . . . . 762
23.3 Data Compression and SVD . . . . . . . . . . . . . . . . . . . . . . . . . . . 767
23.4 Principal Components Analysis (PCA) . . . . . . . . . . . . . . . . . . . . . 769
23.5 Best Affine Approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . 780
23.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 784
23.7 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 785
II Affine and Projective Geometry 789
24 Basics of Affine Geometry 791
24.1 Affine Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 791
24.2 Examples of Affine Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . 800
24.3 Chasles’s Identity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 801
24.4 Affine Combinations, Barycenters . . . . . . . . . . . . . . . . . . . . . . . . 802
24.5 Affine Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 807
24.6 Affine Independence and Affine Frames . . . . . . . . . . . . . . . . . . . . . 813
24.7 Affine Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 819
24.8 Affine Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 826
24.9 Affine Geometry: A Glimpse . . . . . . . . . . . . . . . . . . . . . . . . . . 828
24.10 Affine Hyperplanes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 832
24.11 Intersection of Affine Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . 834
25 Embedding an Affine Space in a Vector Space 837
25.1 The “Hat Construction,” or Homogenizing . . . . . . . . . . . . . . . . . . . 837
25.2 Affine Frames of E and Bases of Eˆ . . . . . . . . . . . . . . . . . . . . . . . 844
25.3 Another Construction of Eˆ . . . . . . . . . . . . . . . . . . . . . . . . . . . 847
25.4 Extending Affine Maps to Linear Maps . . . . . . . . . . . . . . . . . . . . . 850
26 Basics of Projective Geometry 855
26.1 Why Projective Spaces? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 855
26.2 Projective Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 860
26.3 Projective Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 865
CONTENTS 9
26.4 Projective Frames . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 868
26.5 Projective Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 882
26.6 Finding a Homography Between Two Projective Frames . . . . . . . . . . . 888
26.7 Affine Patches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 901
26.8 Projective Completion of an Affine Space . . . . . . . . . . . . . . . . . . . 904
26.9 Making Good Use of Hyperplanes at Infinity . . . . . . . . . . . . . . . . . 909
26.10 The Cross-Ratio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 912
26.11 Fixed Points of Homographies and Homologies . . . . . . . . . . . . . . . . 916
26.12 Duality in Projective Geometry . . . . . . . . . . . . . . . . . . . . . . . . . 930
26.13 Cross-Ratios of Hyperplanes . . . . . . . . . . . . . . . . . . . . . . . . . . . 934
26.14 Complexification of a Real Projective Space . . . . . . . . . . . . . . . . . . 936
26.15 Similarity Structures on a Projective Space . . . . . . . . . . . . . . . . . . 938
26.16 Some Applications of Projective Geometry . . . . . . . . . . . . . . . . . . . 947
III The Geometry of Bilinear Forms 953
27 The Cartan–Dieudonn´e Theorem 955
27.1 The Cartan–Dieudonn´e Theorem for Linear Isometries . . . . . . . . . . . . 955
27.2 Affine Isometries (Rigid Motions) . . . . . . . . . . . . . . . . . . . . . . . . 967
27.3 Fixed Points of Affine Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . 969
27.4 Affine Isometries and Fixed Points . . . . . . . . . . . . . . . . . . . . . . . 971
27.5 The Cartan–Dieudonn´e Theorem for Affine Isometries . . . . . . . . . . . . 977
28 Isometries of Hermitian Spaces 981
28.1 The Cartan–Dieudonn´e Theorem, Hermitian Case . . . . . . . . . . . . . . . 981
28.2 Affine Isometries (Rigid Motions) . . . . . . . . . . . . . . . . . . . . . . . . 990
29 The Geometry of Bilinear Forms; Witt’s Theorem 995
29.1 Bilinear Forms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 995
29.2 Sesquilinear Forms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1003
29.3 Orthogonality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1007
29.4 Adjoint of a Linear Map . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1012
29.5 Isometries Associated with Sesquilinear Forms . . . . . . . . . . . . . . . . . 1014
29.6 Totally Isotropic Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . 1018
29.7 Witt Decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1024
29.8 Symplectic Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1032
29.9 Orthogonal Groups and the Cartan–Dieudonn´e Theorem . . . . . . . . . . . 1036
29.10 Witt’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1043
10 CONTENTS
IV Algebra: PID’s, UFD’s, Noetherian Rings, Tensors,
Modules over a PID, Normal Forms 1049
30 Polynomials, Ideals and PID’s 1051
30.1 Multisets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1051
30.2 Polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1052
30.3 Euclidean Division of Polynomials . . . . . . . . . . . . . . . . . . . . . . . 1058
30.4 Ideals, PID’s, and Greatest Common Divisors . . . . . . . . . . . . . . . . . 1060
30.5 Factorization and Irreducible Factors in K[X] . . . . . . . . . . . . . . . . . 1068
30.6 Roots of Polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1072
30.7 Polynomial Interpolation (Lagrange, Newton, Hermite) . . . . . . . . . . . . 1079
31 Annihilating Polynomials; Primary Decomposition 1087
31.1 Annihilating Polynomials and the Minimal Polynomial . . . . . . . . . . . . 1089
31.2 Minimal Polynomials of Diagonalizable Linear Maps . . . . . . . . . . . . . 1091
31.3 Commuting Families of Linear Maps . . . . . . . . . . . . . . . . . . . . . . 1094
31.4 The Primary Decomposition Theorem . . . . . . . . . . . . . . . . . . . . . 1097
31.5 Jordan Decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1103
31.6 Nilpotent Linear Maps and Jordan Form . . . . . . . . . . . . . . . . . . . . 1106
31.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1112
31.8 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1113
32 UFD’s, Noetherian Rings, Hilbert’s Basis Theorem 1117
32.1 Unique Factorization Domains (Factorial Rings) . . . . . . . . . . . . . . . . 1117
32.2 The Chinese Remainder Theorem . . . . . . . . . . . . . . . . . . . . . . . . 1131
32.3 Noetherian Rings and Hilbert’s Basis Theorem . . . . . . . . . . . . . . . . 1137
32.4 Futher Readings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1141
33 Tensor Algebras 1143
33.1 Linear Algebra Preliminaries: Dual Spaces and Pairings . . . . . . . . . . . 1145
33.2 Tensors Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1150
33.3 Bases of Tensor Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1162
33.4 Some Useful Isomorphisms for Tensor Products . . . . . . . . . . . . . . . . 1163
33.5 Duality for Tensor Products . . . . . . . . . . . . . . . . . . . . . . . . . . . 1167
33.6 Tensor Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1173
33.7 Symmetric Tensor Powers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1180
33.8 Bases of Symmetric Powers . . . . . . . . . . . . . . . . . . . . . . . . . . . 1184
33.9 Some Useful Isomorphisms for Symmetric Powers . . . . . . . . . . . . . . . 1187
33.10 Duality for Symmetric Powers . . . . . . . . . . . . . . . . . . . . . . . . . . 1187
33.11 Symmetric Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1191
33.12 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1194
34 Exterior Tensor Powers and Exterior Algebras 1197
CONTENTS 11
34.1 Exterior Tensor Powers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1197
34.2 Bases of Exterior Powers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1202
34.3 Some Useful Isomorphisms for Exterior Powers . . . . . . . . . . . . . . . . 1205
34.4 Duality for Exterior Powers . . . . . . . . . . . . . . . . . . . . . . . . . . . 1205
34.5 Exterior Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1209
34.6 The Hodge ∗-Operator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1213
34.7 Left and Right Hooks ~ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1217
34.8 Testing Decomposability ~ . . . . . . . . . . . . . . . . . . . . . . . . . . . 1227
34.9 The Grassmann-Pl¨ucker’s Equations and Grassmannians ~ . . . . . . . . . 1230
34.10 Vector-Valued Alternating Forms . . . . . . . . . . . . . . . . . . . . . . . . 1233
34.11 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1237
35 Introduction to Modules; Modules over a PID 1239
35.1 Modules over a Commutative Ring . . . . . . . . . . . . . . . . . . . . . . . 1239
35.2 Finite Presentations of Modules . . . . . . . . . . . . . . . . . . . . . . . . . 1248
35.3 Tensor Products of Modules over a Commutative Ring . . . . . . . . . . . . 1254
35.4 Torsion Modules over a PID; Primary Decomposition . . . . . . . . . . . . . 1257
35.5 Finitely Generated Modules over a PID . . . . . . . . . . . . . . . . . . . . 1263
35.6 Extension of the Ring of Scalars . . . . . . . . . . . . . . . . . . . . . . . . 1279
36 Normal Forms; The Rational Canonical Form 1285
36.1 The Torsion Module Associated With An Endomorphism . . . . . . . . . . 1285
36.2 The Rational Canonical Form . . . . . . . . . . . . . . . . . . . . . . . . . . 1293
36.3 The Rational Canonical Form, Second Version . . . . . . . . . . . . . . . . . 1300
36.4 The Jordan Form Revisited . . . . . . . . . . . . . . . . . . . . . . . . . . . 1301
36.5 The Smith Normal Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1304
V Topology, Differential Calculus 1317
37 Topology 1319
37.1 Metric Spaces and Normed Vector Spaces . . . . . . . . . . . . . . . . . . . 1319
37.2 Topological Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1326
37.3 Continuous Functions, Limits . . . . . . . . . . . . . . . . . . . . . . . . . . 1335
37.4 Connected Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1343
37.5 Compact Sets and Locally Compact Spaces . . . . . . . . . . . . . . . . . . 1352
37.6 Second-Countable and Separable Spaces . . . . . . . . . . . . . . . . . . . . 1363
37.7 Sequential Compactness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1367
37.8 Complete Metric Spaces and Compactness . . . . . . . . . . . . . . . . . . . 1373
37.9 Completion of a Metric Space . . . . . . . . . . . . . . . . . . . . . . . . . . 1376
37.10 The Contraction Mapping Theorem . . . . . . . . . . . . . . . . . . . . . . 1383
37.11 Continuous Linear and Multilinear Maps . . . . . . . . . . . . . . . . . . . . 1387
37.12 Completion of a Normed Vector Space . . . . . . . . . . . . . . . . . . . . . 1394
12 CONTENTS
37.13 Normed Affine Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1397
37.14 Futher Readings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1397
38 A Detour On Fractals 1399
38.1 Iterated Function Systems and Fractals . . . . . . . . . . . . . . . . . . . . 1399
39 Differential Calculus 1407
39.1 Directional Derivatives, Total Derivatives . . . . . . . . . . . . . . . . . . . 1407
39.2 Properties of Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1416
39.3 Jacobian Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1421
39.4 The Implicit and The Inverse Function Theorems . . . . . . . . . . . . . . . 1429
39.5 Tangent Spaces and Differentials . . . . . . . . . . . . . . . . . . . . . . . . 1436
39.6 Second-Order and Higher-Order Derivatives . . . . . . . . . . . . . . . . . . 1438
39.7 Taylor’s formula, Fa`a di Bruno’s formula . . . . . . . . . . . . . . . . . . . . 1444
39.8 Vector Fields, Covariant Derivatives, Lie Brackets . . . . . . . . . . . . . . . 1449
39.9 Futher Readings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1451
39.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1451
39.11 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1452
VI Preliminaries for Optimization Theory 1455
40 Extrema of Real-Valued Functions 1457
40.1 Local Extrema and Lagrange Multipliers . . . . . . . . . . . . . . . . . . . . 1458
40.2 Using Second Derivatives to Find Extrema . . . . . . . . . . . . . . . . . . . 1470
40.3 Using Convexity to Find Extrema . . . . . . . . . . . . . . . . . . . . . . . 1473
40.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1483
40.5 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1484
41 Newton’s Method and Its Generalizations 1487
41.1 Newton’s Method for Real Functions of a Real Argument . . . . . . . . . . 1487
41.2 Generalizations of Newton’s Method . . . . . . . . . . . . . . . . . . . . . . 1489
41.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1498
41.4 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1498
42 Quadratic Optimization Problems 1507
42.1 Quadratic Optimization: The Positive Definite Case . . . . . . . . . . . . . 1507
42.2 Quadratic Optimization: The General Case . . . . . . . . . . . . . . . . . . 1517
42.3 Maximizing a Quadratic Function on the Unit Sphere . . . . . . . . . . . . 1522
42.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1527
42.5 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1528
43 Schur Complements and Applications 1529
CONTENTS 13
43.1 Schur Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1529
43.2 SPD Matrices and Schur Complements . . . . . . . . . . . . . . . . . . . . . 1532
43.3 SP Semidefinite Matrices and Schur Complements . . . . . . . . . . . . . . 1533
43.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1535
43.5 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1535
VII Linear Optimization 1537
44 Convex Sets, Cones, H-Polyhedra 1539
44.1 What is Linear Programming? . . . . . . . . . . . . . . . . . . . . . . . . . 1539
44.2 Affine Subsets, Convex Sets, Hyperplanes, Half-Spaces . . . . . . . . . . . . 1541
44.3 Cones, Polyhedral Cones, and H-Polyhedra . . . . . . . . . . . . . . . . . . 1544
44.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1549
44.5 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1550
45 Linear Programs 1551
45.1 Linear Programs, Feasible Solutions, Optimal Solutions . . . . . . . . . . . 1551
45.2 Basic Feasible Solutions and Vertices . . . . . . . . . . . . . . . . . . . . . . 1558
45.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1565
45.4 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1565
46 The Simplex Algorithm 1569
46.1 The Idea Behind the Simplex Algorithm . . . . . . . . . . . . . . . . . . . . 1569
46.2 The Simplex Algorithm in General . . . . . . . . . . . . . . . . . . . . . . . 1578
46.3 How to Perform a Pivoting Step Efficiently . . . . . . . . . . . . . . . . . . 1585
46.4 The Simplex Algorithm Using Tableaux . . . . . . . . . . . . . . . . . . . . 1589
46.5 Computational Efficiency of the Simplex Method . . . . . . . . . . . . . . . 1598
46.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1599
46.7 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1599
47 Linear Programming and Duality 1603
47.1 Variants of the Farkas Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . 1603
47.2 The Duality Theorem in Linear Programming . . . . . . . . . . . . . . . . . 1609
47.3 Complementary Slackness Conditions . . . . . . . . . . . . . . . . . . . . . 1617
47.4 Duality for Linear Programs in Standard Form . . . . . . . . . . . . . . . . 1618
47.5 The Dual Simplex Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 1621
47.6 The Primal-Dual Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 1628
47.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1638
47.8 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1638
14 CONTENTS
VIII NonLinear Optimization 1643
48 Basics of Hilbert Spaces 1645
48.1 The Projection Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1645
48.2 Duality and the Riesz Representation Theorem . . . . . . . . . . . . . . . . 1658
48.3 Farkas–Minkowski Lemma in Hilbert Spaces . . . . . . . . . . . . . . . . . . 1663
48.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1664
48.5 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1665
49 General Results of Optimization Theory 1667
49.1 Optimization Problems; Basic Terminology . . . . . . . . . . . . . . . . . . 1667
49.2 Existence of Solutions of an Optimization Problem . . . . . . . . . . . . . . 1671
49.3 Minima of Quadratic Functionals . . . . . . . . . . . . . . . . . . . . . . . . 1675
49.4 Elliptic Functionals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1682
49.5 Iterative Methods for Unconstrained Problems . . . . . . . . . . . . . . . . 1685
49.6 Gradient Descent Methods for Unconstrained Problems . . . . . . . . . . . 1688
49.7 Convergence of Gradient Descent with Variable Stepsize . . . . . . . . . . . 1695
49.8 Steepest Descent for an Arbitrary Norm . . . . . . . . . . . . . . . . . . . . 1699
49.9 Newton’s Method For Finding a Minimum . . . . . . . . . . . . . . . . . . . 1701
49.10 Conjugate Gradient Methods; Unconstrained Problems . . . . . . . . . . . . 1705
49.11 Gradient Projection for Constrained Optimization . . . . . . . . . . . . . . 1716
49.12 Penalty Methods for Constrained Optimization . . . . . . . . . . . . . . . . 1719
49.13 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1721
49.14 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1722
50 Introduction to Nonlinear Optimization 1727
50.1 The Cone of Feasible Directions . . . . . . . . . . . . . . . . . . . . . . . . . 1729
50.2 Active Constraints and Qualified Constraints . . . . . . . . . . . . . . . . . 1735
50.3 The Karush–Kuhn–Tucker Conditions . . . . . . . . . . . . . . . . . . . . . 1742
50.4 Equality Constrained Minimization . . . . . . . . . . . . . . . . . . . . . . . 1753
50.5 Hard Margin Support Vector Machine; Version I . . . . . . . . . . . . . . . 1758
50.6 Hard Margin Support Vector Machine; Version II . . . . . . . . . . . . . . . 1763
50.7 Lagrangian Duality and Saddle Points . . . . . . . . . . . . . . . . . . . . . 1771
50.8 Weak and Strong Duality . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1780
50.9 Handling Equality Constraints Explicitly . . . . . . . . . . . . . . . . . . . . 1788
50.10 Dual of the Hard Margin Support Vector Machine . . . . . . . . . . . . . . 1791
50.11 Conjugate Function and Legendre Dual Function . . . . . . . . . . . . . . . 1796
50.12 Some Techniques to Obtain a More Useful Dual Program . . . . . . . . . . 1806
50.13 Uzawa’s Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1810
50.14 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1816
50.15 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1817
51 Subgradients and Subdifferentials ~ 1819
CONTENTS 15
51.1 Extended Real-Valued Convex Functions . . . . . . . . . . . . . . . . . . . . 1821
51.2 Subgradients and Subdifferentials . . . . . . . . . . . . . . . . . . . . . . . . 1830
51.3 Basic Properties of Subgradients and Subdifferentials . . . . . . . . . . . . . 1842
51.4 Additional Properties of Subdifferentials . . . . . . . . . . . . . . . . . . . . 1848
51.5 The Minimum of a Proper Convex Function . . . . . . . . . . . . . . . . . . 1852
51.6 Generalization of the Lagrangian Framework . . . . . . . . . . . . . . . . . 1859
51.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1862
51.8 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1864
52 Dual Ascent Methods; ADMM 1865
52.1 Dual Ascent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1867
52.2 Augmented Lagrangians and the Method of Multipliers . . . . . . . . . . . . 1871
52.3 ADMM: Alternating Direction Method of Multipliers . . . . . . . . . . . . . 1876
52.4 Convergence of ADMM ~ . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1879
52.5 Stopping Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1888
52.6 Some Applications of ADMM . . . . . . . . . . . . . . . . . . . . . . . . . . 1889
52.7 Solving Hard Margin (SVMh2) Using ADMM . . . . . . . . . . . . . . . . . 1894
52.8 Applications of ADMM to ` 1
-Norm Problems . . . . . . . . . . . . . . . . . 1896
52.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1901
52.10 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1902
IX Applications to Machine Learning 1905
53 Positive Definite Kernels 1907
53.1 Feature Maps and Kernel Functions . . . . . . . . . . . . . . . . . . . . . . 1907
53.2 Basic Properties of Positive Definite Kernels . . . . . . . . . . . . . . . . . . 1914
53.3 Hilbert Space Representation of a Positive Kernel . . . . . . . . . . . . . . . 1920
53.4 Kernel PCA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1923
53.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1926
53.6 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1927
54 Soft Margin Support Vector Machines 1929
54.1 Soft Margin Support Vector Machines; (SVMs1) . . . . . . . . . . . . . . . . 1932
54.2 Solving SVM (SVMs1) Using ADMM . . . . . . . . . . . . . . . . . . . . . . 1947
54.3 Soft Margin Support Vector Machines; (SVMs2) . . . . . . . . . . . . . . . . 1948
54.4 Solving SVM (SVMs2) Using ADMM . . . . . . . . . . . . . . . . . . . . . . 1955
54.5 Soft Margin Support Vector Machines; (SVMs2
0 ) . . . . . . . . . . . . . . . 1956
54.6 Classification of the Data Points in Terms of ν (SVMs2
0 ) . . . . . . . . . . . 1967
54.7 Existence of Support Vectors for (SVMs2
0 ) . . . . . . . . . . . . . . . . . . . 1970
54.8 Solving SVM (SVMs2
0 ) Using ADMM . . . . . . . . . . . . . . . . . . . . . 1980
54.9 Soft Margin Support Vector Machines; (SVMs3) . . . . . . . . . . . . . . . . 1984
54.10 Classification of the Data Points in Terms of ν (SVMs3) . . . . . . . . . . . 1991
16 CONTENTS
54.11 Existence of Support Vectors for (SVMs3) . . . . . . . . . . . . . . . . . . . 1993
54.12 Solving SVM (SVMs3) Using ADMM . . . . . . . . . . . . . . . . . . . . . . 1995
54.13 Soft Margin SVM; (SVMs4) . . . . . . . . . . . . . . . . . . . . . . . . . . . 1999
54.14 Solving SVM (SVMs4) Using ADMM . . . . . . . . . . . . . . . . . . . . . . 2007
54.15 Soft Margin SVM; (SVMs5) . . . . . . . . . . . . . . . . . . . . . . . . . . . 2009
54.16 Solving SVM (SVMs5) Using ADMM . . . . . . . . . . . . . . . . . . . . . . 2013
54.17 Summary and Comparison of the SVM Methods . . . . . . . . . . . . . . . 2015
54.18 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2028
55 Ridge Regression, Lasso, Elastic Net 2033
55.1 Ridge Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2034
55.2 Ridge Regression; Learning an Affine Function . . . . . . . . . . . . . . . . 2037
55.3 Kernel Ridge Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2046
55.4 Lasso Regression (` 1
-Regularized Regression) . . . . . . . . . . . . . . . . . 2050
55.5 Lasso Regression; Learning an Affine Function . . . . . . . . . . . . . . . . . 2054
55.6 Elastic Net Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2060
55.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2066
55.8 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2066
56 ν-SV Regression 2069
56.1 ν-SV Regression; Derivation of the Dual . . . . . . . . . . . . . . . . . . . . 2069
56.2 Existence of Support Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . 2080
56.3 Solving ν-Regression Using ADMM . . . . . . . . . . . . . . . . . . . . . . . 2090
56.4 Kernel ν-SV Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2096
56.5 ν-Regression Version 2; Penalizing b . . . . . . . . . . . . . . . . . . . . . . 2099
56.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2106
56.7 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2107
X Appendices 2109
A Total Orthogonal Families in Hilbert Spaces 2111
A.1 Total Orthogonal Families, Fourier Coefficients . . . . . . . . . . . . . . . . 2111
A.2 The Hilbert Space ` 2
(K) and the Riesz–Fischer Theorem . . . . . . . . . . . 2120
A.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2129
A.4 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2130
B Matlab Programs 2131
B.1 Hard Margin (SVMh2) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2131
B.2 Soft Margin SVM (SVMs2
0 ) . . . . . . . . . . . . . . . . . . . . . . . . . . . 2135
B.3 Soft Margin SVM (SVMs3) . . . . . . . . . . . . . . . . . . . . . . . . . . . 2143
B.4 ν-SV Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2148
CONTENTS 17
C Zorn’s Lemma; Some Applications 2155
C.1 Statement of Zorn’s Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . 2155
C.2 Proof of the Existence of a Basis in a Vector Space . . . . . . . . . . . . . . 2156
C.3 Existence of Maximal Proper Ideals . . . . . . . . . . . . . . . . . . . . . . 2157
Bibliography 2159
Index 2171
18 CONTENTS
Chapter 1
Introduction
19
20 CHAPTER 1. INTRODUCTION
Chapter 2
Groups, Rings, and Fields
In the following four chapters, the basic algebraic structures (groups, rings, fields, vector
spaces) are reviewed, with a major emphasis on vector spaces. Basic notions of linear alge￾bra such as vector spaces, subspaces, linear combinations, linear independence, bases, quo￾tient spaces, linear maps, matrices, change of bases, direct sums, linear forms, dual spaces,
hyperplanes, transpose of a linear maps, are reviewed.
2.1 Groups, Subgroups, Cosets
The set R of real numbers has two operations +: R × R → R (addition) and ∗: R × R →
R (multiplication) satisfying properties that make R into an abelian group under +, and
R − {0} = R
∗
into an abelian group under ∗. Recall the definition of a group.
Definition 2.1. A group is a set G equipped with a binary operation ·: G × G → G that
associates an element a · b ∈ G to every pair of elements a, b ∈ G, and having the following
properties: · is associative, has an identity element e ∈ G, and every element in G is invertible
(w.r.t. ·). More explicitly, this means that the following equations hold for all a, b, c ∈ G:
(G1) a · (b · c) = (a · b) · c. (associativity);
(G2) a · e = e · a = a. (identity);
(G3) For every a ∈ G, there is some a
−1 ∈ G such that a · a
−1 = a
−1
· a = e. (inverse).
A group G is abelian (or commutative) if
a · b = b · a for all a, b ∈ G.
A set M together with an operation ·: M × M → M and an element e satisfying only
Conditions (G1) and (G2) is called a monoid. For example, the set N = {0, 1, . . . , n, . . .} of
natural numbers is a (commutative) monoid under addition. However, it is not a group.
Some examples of groups are given below.
21
22 CHAPTER 2. GROUPS, RINGS, AND FIELDS
Example 2.1.
1. The set Z = {. . . , −n, . . . , −1, 0, 1, . . . , n, . . .} of integers is an abelian group under
addition, with identity element 0. However, Z
∗ = Z − {0} is not a group under
multiplication.
2. The set Q of rational numbers (fractions p/q with p, q ∈ Z and q 6 = 0) is an abelian
group under addition, with identity element 0. The set Q∗ = Q− {0} is also an abelian
group under multiplication, with identity element 1.
3. Given any nonempty set S, the set of bijections f : S → S, also called permutations
of S, is a group under function composition (i.e., the multiplication of f and g is the
composition g ◦ f), with identity element the identity function idS. This group is not
abelian as soon as S has more than two elements. The permutation group of the set
S = {1, . . . , n} is often denoted Sn and called the symmetric group on n elements.
4. For any positive integer p ∈ N, define a relation on Z, denoted m ≡ n (mod p), as
follows:
m ≡ n (mod p) iff m − n = kp for some k ∈ Z.
The reader will easily check that this is an equivalence relation, and, moreover, it is
compatible with respect to addition and multiplication, which means that if m1 ≡ n1
(mod p) and m2 ≡ n2 (mod p), then m1 + m2 ≡ n1 + n2 (mod p) and m1m2 ≡ n1n2
(mod p). Consequently, we can define an addition operation and a multiplication
operation of the set of equivalence classes (mod p):
[m] + [n] = [m + n]
and
[m] · [n] = [mn].
The reader will easily check that addition of residue classes (mod p) induces an abelian
group structure with [0] as zero. This group is denoted Z/pZ.
5. The set of n×n invertible matrices with real (or complex) coefficients is a group under
matrix multiplication, with identity element the identity matrix In. This group is
called the general linear group and is usually denoted by GL(n, R) (or GL(n, C)).
6. The set of n × n invertible matrices A with real (or complex) coefficients such that
det(A) = 1 is a group under matrix multiplication, with identity element the identity
matrix In. This group is called the special linear group and is usually denoted by
SL(n, R) (or SL(n, C)).
7. The set of n × n matrices Q with real coefficients such that
QQ> = Q
> Q = In
2.1. GROUPS, SUBGROUPS, COSETS 23
is a group under matrix multiplication, with identity element the identity matrix In;
we have Q−1 = Q> . This group is called the orthogonal group and is usually denoted
by O(n).
8. The set of n × n invertible matrices Q with real coefficients such that
QQ> = Q
> Q = In and det(Q) = 1
is a group under matrix multiplication, with identity element the identity matrix In;
as in (6), we have Q−1 = Q> . This group is called the special orthogonal group or
rotation group and is usually denoted by SO(n).
The groups in (5)–(8) are nonabelian for n ≥ 2, except for SO(2) which is abelian (but O(2)
is not abelian).
It is customary to denote the operation of an abelian group G by +, in which case the
inverse a
−1 of an element a ∈ G is denoted by −a.
The identity element of a group is unique. In fact, we can prove a more general fact:
Proposition 2.1. For any binary operation ·: M ×M → M, if e
0 ∈ M is a left identity and
if e
00 ∈ M is a right identity, which means that
e
0 · a = a for all a ∈ M (G2l)
and
a · e
00 = a for all a ∈ M, (G2r)
then e
0 = e
00 .
Proof. If we let a = e
00 in equation (G2l), we get
e
0 · e
00 = e
00 ,
and if we let a = e
0 in equation (G2r), we get
e
0 · e
00 = e
0 ,
and thus
e
0 = e
0 · e
00 = e
00 ,
as claimed.
Proposition 2.1 implies that the identity element of a monoid is unique, and since every
group is a monoid, the identity element of a group is unique. Furthermore, every element in
a group has a unique inverse. This is a consequence of a slightly more general fact:
24 CHAPTER 2. GROUPS, RINGS, AND FIELDS
Proposition 2.2. In a monoid M with identity element e, if some element a ∈ M has some
left inverse a
0 ∈ M and some right inverse a
00 ∈ M, which means that
a
0 · a = e (G3l)
and
a · a
00 = e, (G3r)
then a
0 = a
00 .
Proof. Using (G3l) and the fact that e is an identity element, we have
(a
0 · a) · a
00 = e · a
00 = a
00 .
Similarly, Using (G3r) and the fact that e is an identity element, we have
a
0 · (a · a
00 ) = a
0 · e = a
0 .
However, since M is monoid, the operation · is associative, so
a
0 = a
0 · (a · a
00 ) = (a
0 · a) · a
00 = a
00 ,
as claimed.
Remark: Axioms (G2) and (G3) can be weakened a bit by requiring only (G2r) (the exis￾tence of a right identity) and (G3r) (the existence of a right inverse for every element) (or
(G2l) and (G3l)). It is a good exercise to prove that the group axioms (G2) and (G3) follow
from (G2r) and (G3r).
Another important property about inverse elements in monoids is stated below.
Proposition 2.3. In a monoid M with identity element e, if a and b are invertible elements
of M, where a
−1
is the inverse of a and b
−1
is the inverse of b, then ab is invertible and its
inverse is given by (ab)
−1 = b
−1a
−1
.
Proof. Using associativity and the fact that e is the identity element we have
(ab)(b
−1
a
−1
) = a(b(b
−1
a
−1
)) associativity
= a((bb−1
)a
−1
) associativity
= a(ea−1
) b
−1
is the inverse of b
= aa−1
e is the identity element
= e. a−1
is the inverse of a.
2.1. GROUPS, SUBGROUPS, COSETS 25
We also have
(b
−1
a
−1
)(ab) = b
−1
(a
−1
(ab)) associativity
= b
−1
((a
−1
a)b) associativity
= b
−1
(eb) a
−1
is the inverse of a
= b
−1
b e is the identity element
= e. b−1
is the inverse of b.
Therefore b
−1a
−1
is the inverse of ab.
Observe that the inverse of ba is a
−1
b
−1
. Proposition 2.3 implies that the set of invertible
elements of a monoid M is a group, also with identity element e.
Definition 2.2. If a group G has a finite number n of elements, we say that G is a group
of order n. If G is infinite, we say that G has infinite order . The order of a group is usually
denoted by |G| (if G is finite).
Given a group G, for any two subsets R, S ⊆ G, we let
RS = {r · s | r ∈ R, s ∈ S}.
In particular, for any g ∈ G, if R = {g}, we write
gS = {g · s | s ∈ S},
and similarly, if S = {g}, we write
Rg = {r · g | r ∈ R}.
From now on, we will drop the multiplication sign and write g1g2 for g1 · g2.
Definition 2.3. Let G be a group. For any g ∈ G, define Lg, the left translation by g, by
Lg(a) = ga, for all a ∈ G, and Rg, the right translation by g, by Rg(a) = ag, for all a ∈ G.
The following simple fact is often used.
Proposition 2.4. Given a group G, the translations Lg and Rg are bijections.
Proof. We show this for Lg, the proof for Rg being similar.
If Lg(a) = Lg(b), then ga = gb, and multiplying on the left by g
−1
, we get a = b, so Lg
injective. For any b ∈ G, we have Lg(g
−1
b) = gg−1
b = b, so Lg is surjective. Therefore, Lg
is bijective.
Definition 2.4. Given a group G, a subset H of G is a subgroup of G iff
(1) The identity element e of G also belongs to H (e ∈ H);
26 CHAPTER 2. GROUPS, RINGS, AND FIELDS
(2) For all h1, h2 ∈ H, we have h1h2 ∈ H;
(3) For all h ∈ H, we have h
−1 ∈ H.
The proof of the following proposition is left as an exercise.
Proposition 2.5. Given a group G, a subset H ⊆ G is a subgroup of G iff H is nonempty
and whenever h1, h2 ∈ H, then h1h
−
2
1 ∈ H.
If the group G is finite, then the following criterion can be used.
Proposition 2.6. Given a finite group G, a subset H ⊆ G is a subgroup of G iff
(1) e ∈ H;
(2) H is closed under multiplication.
Proof. We just have to prove that Condition (3) of Definition 2.4 holds. For any a ∈ H,
since the left translation La is bijective, its restriction to H is injective, and since H is finite,
it is also bijective. Since e ∈ H, there is a unique b ∈ H such that La(b) = ab = e. However,
if a
−1
is the inverse of a in G, we also have La(a
−1
) = aa−1 = e, and by injectivity of La, we
have a
−1 = b ∈ H.
Example 2.2.
1. For any integer n ∈ Z, the set
nZ = {nk | k ∈ Z}
is a subgroup of the group Z.
2. The set of matrices
GL+
(n, R) = {A ∈ GL(n, R) | det(A) > 0}
is a subgroup of the group GL(n, R).
3. The group SL(n, R) is a subgroup of the group GL(n, R).
4. The group O(n) is a subgroup of the group GL(n, R).
5. The group SO(n) is a subgroup of the group O(n), and a subgroup of the group
SL(n, R).
2.1. GROUPS, SUBGROUPS, COSETS 27
6. It is not hard to show that every 2 × 2 rotation matrix R ∈ SO(2) can be written as
R =

cos
sin θ
θ −
cos
sin
θ
θ

, with 0 ≤ θ < 2π.
Then SO(2) can be considered as a subgroup of SO(3) by viewing the matrix
R =

cos
sin θ
θ −
cos
sin
θ
θ

as the matrix
Q =


cos
sin θ
θ −
cos
sin
θ
θ 0
0
0 0 1

 .
7. The set of 2 × 2 upper-triangular matrices of the form

a b
0 c

a, b, c ∈ R, a, c 6 = 0
is a subgroup of the group GL(2, R).
8. The set V consisting of the four matrices

±
0
1 0
±1

is a subgroup of the group GL(2, R) called the Klein four-group.
Definition 2.5. If H is a subgroup of G and g ∈ G is any element, the sets of the form
gH are called left cosets of H in G and the sets of the form Hg are called right cosets of H
in G. The left cosets (resp. right cosets) of H induce an equivalence relation ∼ defined as
follows: For all g1, g2 ∈ G,
g1 ∼ g2 iff g1H = g2H
(resp. g1 ∼ g2 iff Hg1 = Hg2). Obviously, ∼ is an equivalence relation.
Now, we claim the following fact:
Proposition 2.7. Given a group G and any subgroup H of G, we have g1H = g2H iff
g
−1
2
g1H = H iff g2
−1
g1 ∈ H, for all g1, g2 ∈ G.
Proof. If we apply the bijection Lg
−1
2
to both g1H and g2H we get Lg
−1
2
(g1H) = g2
−1
g1H
and Lg
−1
2
(g2H) = H, so g1H = g2H iff g2
−1
g1H = H. If g2
−1
g1H = H, since 1 ∈ H, we get
g
−1
2
g1 ∈ H. Conversely, if g2
−1
g1 ∈ H, since H is a group, the left translation Lg2
−1
g1
is a
bijection of H, so g2
−1
g1H = H. Thus, g2
−1
g1H = H iff g2
−1
g1 ∈ H.
28 CHAPTER 2. GROUPS, RINGS, AND FIELDS
It follows that the equivalence class of an element g ∈ G is the coset gH (resp. Hg).
Since Lg is a bijection between H and gH, the cosets gH all have the same cardinality. The
map Lg−1 ◦ Rg is a bijection between the left coset gH and the right coset Hg, so they also
have the same cardinality. Since the distinct cosets gH form a partition of G, we obtain the
following fact:
Proposition 2.8. (Lagrange) For any finite group G and any subgroup H of G, the order
h of H divides the order n of G.
Definition 2.6. Given a finite group G and a subgroup H of G, if n = |G| and h = |H|,
then the ratio n/h is denoted by (G : H) and is called the index of H in G.
The index (G : H) is the number of left (and right) cosets of H in G. Proposition 2.8
can be stated as
|G| = (G : H)|H|.
The set of left cosets of H in G (which, in general, is not a group) is denoted G/H.
The “points” of G/H are obtained by “collapsing” all the elements in a coset into a single
element.
Example 2.3.
1. Let n be any positive integer, and consider the subgroup nZ of Z (under addition).
The coset of 0 is the set {0}, and the coset of any nonzero integer m ∈ Z is
m + nZ = {m + nk | k ∈ Z}.
By dividing m by n, we have m = nq + r for some unique r such that 0 ≤ r ≤ n − 1.
But then we see that r is the smallest positive element of the coset m + nZ. This
implies that there is a bijection betwen the cosets of the subgroup nZ of Z and the set
of residues {0, 1, . . . , n − 1} modulo n, or equivalently a bijection with Z/nZ.
2. The cosets of SL(n, R) in GL(n, R) are the sets of matrices
A SL(n, R) = {AB | B ∈ SL(n, R)}, A ∈ GL(n, R).
Since A is invertible, det(A) 6 = 0, and we can write A = (det(A))1/n((det(A))−1/nA)
if det(A) > 0 and A = (− det(A))1/n((− det(A))−1/nA) if det(A) < 0. But we have
(det(A))−1/nA ∈ SL(n, R) if det(A) > 0 and −(− det(A))−1/nA ∈ SL(n, R) if det(A) <
0, so the coset A SL(n, R) contains the matrix
(det(A))1/nIn if det(A) > 0, −(− det(A))1/nIn if det(A) < 0.
It follows that there is a bijection between the cosets of SL(n, R) in GL(n, R) and R.
2.1. GROUPS, SUBGROUPS, COSETS 29
3. The cosets of SO(n) in GL+
(n, R) are the sets of matrices
A SO(n) = {AQ | Q ∈ SO(n)}, A ∈ GL+
(n, R).
It can be shown (using the polar form for matrices) that there is a bijection between
the cosets of SO(n) in GL+
(n, R) and the set of n × n symmetric, positive, definite
matrices; these are the symmetric matrices whose eigenvalues are strictly positive.
4. The cosets of SO(2) in SO(3) are the sets of matrices
Q SO(2) = {QR | R ∈ SO(2)}, Q ∈ SO(3).
The group SO(3) moves the points on the sphere S
2
in R
3
, namely for any x ∈ S
2
,
x 7→ Qx for any rotation Q ∈ SO(3).
Here,
