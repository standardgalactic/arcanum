wi j (xi − xj )
2
for all x ∈ R
m.
Consequently, x
> Lx does not depend on the diagonal entries in W, and if wi j ≥ 0 for all
i, j ∈ {1, . . . , m}, then L is positive semidefinite.
Proof. We have
x
> Lx = x
> Dx − x
> W x
=
mX
i=1
dix
2
i −
mX
i,j=1
wi jxixj
=
1
2
 
mX
i=1
dix
2
i − 2
X
m
i,j=1
wi jxixj +
mX
i=1
dix
2
i
!
=
2
1
mX
i,j=1
wi j (xi − xj )
2
.
Obviously, the quantity on the right-hand side does not depend on the diagonal entries in
W, and if wi j ≥ 0 for all i, j, then this quantity is nonnegative.
Proposition 20.4 immediately implies the following facts: For any weighted graph G =
(V, W),
1. The eigenvalues 0 = λ1 ≤ λ2 ≤ . . . ≤ λm of L are real and nonnegative, and there is
an orthonormal basis of eigenvectors of L.
2. The smallest eigenvalue λ1 of L is equal to 0, and 1 is a corresponding eigenvector.
It turns out that the dimension of the nullspace of L (the eigenspace of 0) is equal to the
number of connected components of the underlying graph of G.
20.3. NORMALIZED LAPLACIAN MATRICES OF GRAPHS 713
Proposition 20.5. Let G = (V, W) be a weighted graph. The number c of connected com￾ponents K1, . . . , Kc of the underlying graph of G is equal to the dimension of the nullspace
of L, which is equal to the multiplicity of the eigenvalue 0. Furthermore, the nullspace of L
has a basis consisting of indicator vectors of the connected components of G, that is, vectors
(f1, . . . , fm) such that fj = 1 iff vj ∈ Ki and fj = 0 otherwise.
Proof. Since L = BB> for the incidence matrix B associated with any oriented graph
obtained from G, and since L and B> have the same nullspace, by Proposition 20.1, the
dimension of the nullspace of L is equal to the number c of connected components of G and
the indicator vectors of the connected components of G form a basis of Ker (L).
Proposition 20.5 implies that if the underlying graph of G is connected, then the second
eigenvalue λ2 of L is strictly positive.
Remarkably, the eigenvalue λ2 contains a lot of information about the graph G (assuming
that G = (V, E) is an undirected graph). This was first discovered by Fiedler in 1973, and for
this reason, λ2 is often referred to as the Fiedler number . For more on the properties of the
Fiedler number, see Godsil and Royle [77] (Chapter 13) and Chung [39]. More generally, the
spectrum (0, λ2, . . . , λm) of L contains a lot of information about the combinatorial structure
of the graph G. Leverage of this information is the object of spectral graph theory.
20.3 Normalized Laplacian Matrices of Graphs
It turns out that normalized variants of the graph Laplacian are needed, especially in appli￾cations to graph clustering. These variants make sense only if G has no isolated vertices.
Definition 20.18. Given a weighted graph G = (V, W), a vertex u ∈ V is isolated if it is
not incident to any other vertex. This means that every row of W contains some strictly
positive entry.
If G has no isolated vertices, then the degree matrix D contains positive entries, so it is
invertible and D−1/2 makes sense; namely
D
−1/2 = diag(d
−
1
1/2
, . . . , d−
m
1/2
),
and similarly for any real exponent α.
Definition 20.19. Given any weighted directed graph G = (V, W) with no isolated vertex
and with V = {v1, . . . , vm}, the (normalized) graph Laplacians Lsym and Lrw of G are defined
by
Lsym = D
−1/2LD−1/2 = I − D
−1/2W D−1/2
Lrw = D
−1L = I − D
−1W.
714 CHAPTER 20. GRAPHS AND GRAPH LAPLACIANS; BASIC FACTS
Observe that the Laplacian Lsym = D−1/2LD−1/2
is a symmetric matrix (because L and
D−1/2 are symmetric) and that
Lrw = D
−1/2LsymD
1/2
.
The reason for the notation Lrw is that this matrix is closely related to a random walk on
the graph G.
Example 20.1. As an example, the matrices Lsym and Lrw associated with the graph G1
are
Lsym =


−
−
1
0
0
.0000
.
.
3536 1
4082
−
−
0
0
.0000
.
.
3536
2887 1
−
−
0
0
.0000
.
.
4082 0 0
2887 −0.2887 −0.3536
−0.3333 0
0 −0.2887 −0.3333 1.0000 −0.4082
0 −0.3536 0 −0.4082 1.0000


and
Lrw =


−
−
1
0
0
.0000
.
.
2500 1
3333
−
−
0
0
.0000
.
.
5000
3333 1
−
−
0
0
.0000
.
.
5000 0 0
2500 −0.2500 −0.2500
−0.3333 0
0 −0.3333 −0.3333 1.0000 −0.3333
0 −0.5000 0 −0.5000 1.0000


.
Since the unnormalized Laplacian L can be written as L = BB> , where B is the incidence
matrix of any oriented graph obtained from the underlying graph of G = (V, W), if we let
Bsym = D
−1/2B,
we get
Lsym = BsymBsym
>.
In particular, for any singular decomposition Bsym = UΣV
> of Bsym (with U an m × m
orthogonal matrix, Σ a “diagonal” m×n matrix of singular values, and V an n×n orthogonal
matrix), the eigenvalues of Lsym are the squares of the top m singular values of Bsym, and
the vectors in U are orthonormal eigenvectors of Lsym with respect to these eigenvalues (the
squares of the top m diagonal entries of Σ). Computing the SVD of Bsym generally yields
more accurate results than diagonalizing Lsym, especially when Lsym has eigenvalues with
high multiplicity.
There are simple relationships between the eigenvalues and the eigenvectors of Lsym, and
Lrw. There is also a simple relationship with the generalized eigenvalue problem Lx = λDx.
Proposition 20.6. Let G = (V, W) be a weighted graph without isolated vertices. The graph
Laplacians, L, Lsym, and Lrw satisfy the following properties:
20.3. NORMALIZED LAPLACIAN MATRICES OF GRAPHS 715
(1) The matrix Lsym is symmetric and positive semidefinite. In fact,
x
> Lsymx =
1
2
mX
i,j=1
wi j 
xi
√
di
−
xj
p
dj
!
2
for all x ∈ R
m.
(2) The normalized graph Laplacians Lsym and Lrw have the same spectrum
(0 = ν1 ≤ ν2 ≤ . . . ≤ νm), and a vector u 6 = 0 is an eigenvector of Lrw for λ iff D1/2u
is an eigenvector of Lsym for λ.
(3) The graph Laplacians L and Lsym are symmetric and positive semidefinite.
(4) A vector u 6 = 0 is a solution of the generalized eigenvalue problem Lu = λDu iff D1/2u
is an eigenvector of Lsym for the eigenvalue λ iff u is an eigenvector of Lrw for the
eigenvalue λ.
(5) The graph Laplacians, L and Lrw have the same nullspace. For any vector u, we have
u ∈ Ker (L) iff D1/2u ∈ Ker (Lsym).
(6) The vector 1 is in the nullspace of Lrw, and D1/21 is in the nullspace of Lsym.
(7) For every eigenvalue νi of the normalized graph Laplacian Lsym, we have 0 ≤ νi ≤ 2.
Furthermore, νm = 2 iff the underlying graph of G contains a nontrivial connected
bipartite component.
(8) If m ≥ 2 and if the underlying graph of G is not a complete graph,1
then ν2 ≤ 1.
Furthermore the underlying graph of G is a complete graph iff ν2 = m
m
−1
.
(9) If m ≥ 2 and if the underlying graph of G is connected, then ν2 > 0.
(10) If m ≥ 2 and if the underlying graph of G has no isolated vertices, then νm ≥
m
m−1
.
Proof. (1) We have Lsym = D−1/2LD−1/2
, and D−1/2
is a symmetric invertible matrix (since
it is an invertible diagonal matrix). It is a well-known fact of linear algebra that if B is an
invertible matrix, then a matrix S is symmetric, positive semidefinite iff BSB> is symmetric,
positive semidefinite. Since L is symmetric, positive semidefinite, so is Lsym = D−1/2LD−1/2
.
The formula
x
> Lsymx =
1
2
mX
i,j=1
wi j 
xi
√
di
−
xj
p
dj
!
2
for all x ∈ R
m
follows immediately from Proposition 20.4 by replacing x by D−1/2x, and also shows that
Lsym is positive semidefinite.
(2) Since
Lrw = D
−1/2LsymD
1/2
,
1Recall that an undirected graph is complete if for any two distinct nodes u, v, there is an edge {u, v}.
716 CHAPTER 20. GRAPHS AND GRAPH LAPLACIANS; BASIC FACTS
the matrices Lsym and Lrw are similar, which implies that they have the same spectrum. In
fact, since D1/2
is invertible,
Lrwu = D
−1Lu = λu
iff
D
−1/2Lu = λD1/2u
iff
D
−1/2LD−1/2D
1/2u = LsymD
1/2u = λD1/2u,
which shows that a vector u 6 = 0 is an eigenvector of Lrw for λ iff D1/2u is an eigenvector of
Lsym for λ.
(3) We already know that L and Lsym are positive semidefinite.
(4) Since D−1/2
is invertible, we have
Lu = λDu
iff
D
−1/2Lu = λD1/2u
iff
D
−1/2LD−1/2D
1/2u = LsymD
1/2u = λD1/2u,
which shows that a vector u 6 = 0 is a solution of the generalized eigenvalue problem Lu = λDu
iff D1/2u is an eigenvector of Lsym for the eigenvalue λ. The second part of the statement
follows from (2).
(5) Since D−1
is invertible, we have Lu = 0 iff D−1Lu = Lrwu = 0. Similarly, since D−1/2
is invertible, we have Lu = 0 iff D−1/2LD−1/2D1/2u = 0 iff D1/2u ∈ Ker (Lsym).
(6) Since L1 = 0, we get Lrw1 = D−1L1 = 0. That D1/21 is in the nullspace of Lsym
follows from (2). Properties (7)–(10) are proven in Chung [39] (Chapter 1).
The eigenvalues the matrices Lsym and Lrw from Example 20.1 are
0, 7257, 1.1667, 1.5, 1.6076.
On the other hand, the eigenvalues of the unnormalized Laplacian for G1 are
0, 1.5858, 3, 4.4142, 5.
Remark: Observe that although the matrices Lsym and Lrw have the same spectrum, the
matrix Lrw is generally not symmetric, whereas Lsym is symmetric.
A version of Proposition 20.5 also holds for the graph Laplacians Lsym and Lrw. This fol￾lows easily from the fact that Proposition 20.1 applies to the underlying graph of a weighted
graph. The proof is left as an exercise.
20.4. GRAPH CLUSTERING USING NORMALIZED CUTS 717
Proposition 20.7. Let G = (V, W) be a weighted graph. The number c of connected com￾ponents K1, . . . , Kc of the underlying graph of G is equal to the dimension of the nullspace
of both Lsym and Lrw, which is equal to the multiplicity of the eigenvalue 0. Furthermore, the
nullspace of Lrw has a basis consisting of indicator vectors of the connected components of
G, that is, vectors (f1, . . . , fm) such that fj = 1 iff vj ∈ Ki and fj = 0 otherwise. For Lsym,
a basis of the nullpace is obtained by multiplying the above basis of the nullspace of Lrw by
D1/2
.
A particularly interesting application of graph Laplacians is graph clustering.
20.4 Graph Clustering Using Normalized Cuts
In order to explain this problem we need some definitions.
Definition 20.20. Given any subset of nodes A ⊆ V , we define the volume vol(A) of A as
the sum of the weights of all edges adjacent to nodes in A:
vol(A) = X
vi∈A
mX
j=1
wi j .
Given any two subsets A, B ⊆ V (not necessarily distinct), we define links(A, B) by
links(A, B) = X
vi∈A,vj∈B
wi j .
The quantity links(A, A) = links(A, A) (where A = V − A denotes the complement of A in
V ) measures how many links escape from A (and A). We define the cut of A as
cut(A) = links(A, A).
The notion of volume is illustrated in Figure 20.5 and the notions of cut is illustrated in
Figure 20.6.
Figure 20.5: Volume of a set of nodes.
718 CHAPTER 20. GRAPHS AND GRAPH LAPLACIANS; BASIC FACTS
Figure 20.6: A cut involving the set of nodes in the center and the nodes on the perimeter.
The above concepts play a crucial role in the theory of normalized cuts. This beautiful
and deeply original method first published in Shi and Malik [160], has now come to be a
“textbook chapter” of computer vision and machine learning. It was invented by Jianbo Shi
and Jitendra Malik and was the main topic of Shi’s dissertation. This method was extended
to K ≥ 3 clusters by Stella Yu in her dissertation [191] and is also the subject of Yu and Shi
[193].
Given a set of data, the goal of clustering is to partition the data into different groups
according to their similarities. When the data is given in terms of a similarity graph G,
where the weight wi j between two nodes vi and vj
is a measure of similarity of vi and vj
, the
problem can be stated as follows: Find a partition (A1, . . . , AK) of the set of nodes V into
different groups such that the edges between different groups have very low weight (which
indicates that the points in different clusters are dissimilar), and the edges within a group
have high weight (which indicates that points within the same cluster are similar).
The above graph clustering problem can be formalized as an optimization problem, using
the notion of cut mentioned earlier. If we want to partition V into K clusters, we can do so
by finding a partition (A1, . . . , AK) that minimizes the quantity
cut(A1, . . . , AK) = 1
2
X
K
i=1
cut(Ai) =
2
1 X
K
i=1
links(Ai
, Ai).
For K = 2, the mincut problem is a classical problem that can be solved efficiently, but in
practice, it does not yield satisfactory partitions. Indeed, in many cases, the mincut solution
separates one vertex from the rest of the graph. What we need is to design our cost function
in such a way that it keeps the subsets Ai “reasonably large” (reasonably balanced).
An example of a weighted graph and a partition of its nodes into two clusters is shown
in Figure 20.7.
20.5. SUMMARY 719
15
Encode Pairwise Relationships as a Weighted Graph
16
Cut the graph into two pieces 
Figure 20.7: A weighted graph and its partition into two clusters.
A way to get around this problem is to normalize the cuts by dividing by some measure
of each subset Ai
. A solution using the volume vol(Ai) of Ai (for K = 2) was proposed and
investigated in a seminal paper of Shi and Malik [160]. Subsequently, Yu (in her dissertation
[191]) and Yu and Shi [193] extended the method to K > 2 clusters. The idea is to minimize
the cost function
Ncut(A1, . . . , AK) =
K
X
i=1
links(Ai
, Ai)
vol(Ai)
=
K
X
i=1
cut(Ai)
vol(Ai)
.
The next step is to express our optimization problem in matrix form, and this can be
done in terms of Rayleigh ratios involving the graph Laplacian in the numerators. This
theory is very beautiful, but we do not have the space to present it here. The interested
reader is referred to Gallier [74].
20.5 Summary
The main concepts and results of this chapter are listed below:
• Directed graphs, undirected graphs.
• Incidence matrices, adjacency matrices.
• Weighted graphs.
• Degree matrix.
• Graph Laplacian (unnormalized).
720 CHAPTER 20. GRAPHS AND GRAPH LAPLACIANS; BASIC FACTS
• Normalized graph Laplacian.
• Spectral graph theory.
• Graph clustering using normalized cuts.
20.6 Problems
Problem 20.1. Find the unnormalized Laplacian of the graph representing a triangle and
of the graph representing a square.
Problem 20.2. Consider the complete graph Km on m ≥ 2 nodes.
(1) Prove that the normalized Laplacian Lsym of K is
Lsym =


−1/(m
1
− 1) 1
−1/(m − 1) . . .
. . .
−
−
1
1
/
/
(
(
m
m
−
−
1)
1)
−
−
1
1
/
/
(
(
m
m
−
−
1)
1)
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
−
−
1
1
/
/
(
(
m
m
−
−
1)
1)
−
−
1
1
/
/
(
(
m
m
−
−
1)
1)
. . .
. . .
−1/(m
1
− 1) 1
−1/(m − 1)


.
(2) Prove that the characteristic polynomial of Lsym is











λ − 1 1/(m − 1) . . . 1/(m − 1) 1/(m − 1)
1/(m − 1) λ − 1 . . . 1/(m − 1) 1/(m − 1)
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
1/(m − 1) 1/(m − 1) . . . λ − 1 1/(m − 1)
1/(m − 1) 1/(m − 1) . . . 1/(m − 1) λ − 1









 
= λ
 λ −
m
m
− 1

m−1
.
Hint. First subtract the second column from the first, factor λ − m/(m − 1), and then add
the first row to the second. Repeat this process. You will end up with the determinant




λ −
1/
1
(m
/(m
−
−
1)
1) 1
λ − 1




.
Problem 20.3. Consider the complete bipartite graph Km,n on m + n ≥ 3 nodes, with
edges between each of the first m ≥ 1 nodes to each of the last n ≥ 1 nodes. Prove that the
eigenvalues of the normalized Laplacian Lsym of Km,n are 0, 1 with multiplicity m + n − 2,
and 2.
Problem 20.4. Let G be a graph with a set of nodes V with m ≥ 2 elements, without
isolated nodes, and let Lsym = D−1/2LD−1/2 be its normalized Laplacian (with L its unnor￾malized Laplacian).
20.6. PROBLEMS 721
(1) For any y ∈ R
V
, consider the Rayleigh ratio
R =
y
> Lsym y
y
> y
.
Prove that if x = D−1/2
y, then
R =
x
> Lx
(D1/2x)
> D1/2x
=
X
u∼v
(x(u) − x(v))2
X
v
dvx(v)
2
.
(2) Prove that the second eigenvalue ν2 of Lsym is given by
ν2 = min
1> Dx=0,x6=0
X
u∼v
(x(u) − x(v))2
X
v
dvx(v)
2
.
(3) Prove that the largest eigenvalue νm of Lsym is given by
νm = max
x6=0
X
u∼v
(x(u) − x(v))2
X
v
dvx(v)
2
.
Problem 20.5. Let G be a graph with a set of nodes V with m ≥ 2 elements, without
isolated nodes. If 0 = ν1 ≤ ν1 ≤ . . . ≤ νm are the eigenvalues of Lsym, prove the following
properties:
(1) We have ν1 + ν2 + · · · + νm = m.
(2) We have ν2 ≤ m/(m − 1), with equality holding iff G = Km, the complete graph on m
nodes.
(3) We have νm ≥ m/(m − 1).
(4) If G is not a complete graph, then ν2 ≤ 1
Hint. If a and b are nonadjacent nodes, consider the function x given by
x(v) =



db if v = a
−da if v = b
0 if v 6 = a, b,
and use Problem 20.4(2).
722 CHAPTER 20. GRAPHS AND GRAPH LAPLACIANS; BASIC FACTS
(5) Prove that νm ≤ 2. Prove that νm = 2 iff the underlying graph of G contains a
nontrivial connected bipartite component.
Hint. Use Problem 20.4(3).
(6) Prove that if G is connected, then ν2 > 0.
Problem 20.6. Let G be a graph with a set of nodes V with m ≥ 2 elements, without
isolated nodes. Let vol(G) = P v∈V
dv and let
x =
P
v
dvx(v)
vol(G)
.
Prove that
ν2 = min
x6=0
X
u∼v
(x(u) − x(v))2
X
v
dv(x(v) − x)
2
.
Problem 20.7. Let G be a connected bipartite graph. Prove that if ν is an eigenvalue of
Lsym, then 2 − ν is also an eigenvalue of Lsym.
Problem 20.8. Prove Proposition 20.7.
Chapter 21
Spectral Graph Drawing
21.1 Graph Drawing and Energy Minimization
Let G = (V, E) be some undirected graph. It is often desirable to draw a graph, usually
in the plane but possibly in 3D, and it turns out that the graph Laplacian can be used to
design surprisingly good methods. Say |V | = m. The idea is to assign a point ρ(vi) in R
n
to the vertex vi ∈ V , for every vi ∈ V , and to draw a line segment between the points ρ(vi)
and ρ(vj ) iff there is an edge {vi
, vj}.
Definition 21.1. Let G = (V, E) be some undirected graph with m vertices. A graph
drawing is a function ρ: V → R
n
, for some n ≥ 1. The matrix of a graph drawing ρ (in R
n
)
is a m × n matrix R whose ith row consists of the row vector ρ(vi) corresponding to the
point representing vi
in R
n
.
For a graph drawing to be useful we want n ≤ m; in fact n should be much smaller than
m, typically n = 2 or n = 3.
Definition 21.2. A graph drawing is balanced iff the sum of the entries of every column of
the matrix of the graph drawing is zero, that is,
1
> R = 0.
If a graph drawing is not balanced, it can be made balanced by a suitable translation.
We may also assume that the columns of R are linearly independent, since any basis of the
column space also determines the drawing. Thus, from now on, we may assume that n ≤ m.
Remark: A graph drawing ρ: V → R
n
is not required to be injective, which may result in
degenerate drawings where distinct vertices are drawn as the same point. For this reason,
we prefer not to use the terminology graph embedding, which is often used in the literature.
This is because in differential geometry, an embedding always refers to an injective map.
The term graph immersion would be more appropriate.
723
724 CHAPTER 21. SPECTRAL GRAPH DRAWING
As explained in Godsil and Royle [77], we can imagine building a physical model of G
by connecting adjacent vertices (in R
n
) by identical springs. Then it is natural to consider
a representation to be better if it requires the springs to be less extended. We can formalize
this by defining the energy of a drawing R by
E(R) = X
{vi,vj}∈E
k
ρ(vi) − ρ(vj )k
2
,
where ρ(vi) is the ith row of R and k ρ(vi) − ρ(vj )k
2
is the square of the Euclidean length of
the line segment joining ρ(vi) and ρ(vj ).
Then, “good drawings” are drawings that minimize the energy function E. Of course, the
trivial representation corresponding to the zero matrix is optimum, so we need to impose
extra constraints to rule out the trivial solution.
We can consider the more general situation where the springs are not necessarily identical.
This can be modeled by a symmetric weight (or stiffness) matrix W = (wij ), with wij ≥ 0.
Then our energy function becomes
E(R) = X
{vi,vj}∈E
wij k ρ(vi) − ρ(vj )k
2
.
It turns out that this function can be expressed in terms of the Laplacian L = D − W. The
following proposition is shown in Godsil and Royle [77]. We give a slightly more direct proof.
Proposition 21.1. Let G = (V, W) be a weighted graph, with |V | = m and W an m × m
symmetric matrix, and let R be the matrix of a graph drawing ρ of G in R
n
(a m×n matrix).
If L = D − W is the unnormalized Laplacian matrix associated with W, then
E(R) = tr(R
> LR).
Proof. Since ρ(vi) is the ith row of R (and ρ(vj ) is the jth row of R), if we denote the kth
column of R by Rk
, using Proposition 20.4, we have
E(R) = X
{vi,vj}∈E
wij k ρ(vi) − ρ(vj )k
2
=
nX
k=1
X {vi,vj}∈E
wij (Rik − Rjk)
2
=
nX
k=1
1
2
X
m
i,j=1
wij (Rik − Rjk)
2
=
nX
k=1
(R
k
)
> LRk = tr(R
> LR),
as claimed.
21.1. GRAPH DRAWING AND ENERGY MINIMIZATION 725
Since the matrix R> LR is symmetric, it has real eigenvalues. Actually, since L is positive
semidefinite, so is R> LR. Then the trace of R> LR is equal to the sum of its positive
eigenvalues, and this is the energy E(R) of the graph drawing.
If R is the matrix of a graph drawing in R
n
, then for any n × n invertible matrix M, the
map that assigns ρ(vi)M to vi
is another graph drawing of G, and these two drawings convey
the same amount of information. From this point of view, a graph drawing is determined
by the column space of R. Therefore, it is reasonable to assume that the columns of R are
pairwise orthogonal and that they have unit length. Such a matrix satisfies the equation
R> R = I.
Definition 21.3. If the matrix R of a graph drawing satisfies the equation R> R = I, then
the corresponding drawing is called an orthogonal graph drawing.
This above condition also rules out trivial drawings. The following result tells us how to
find minimum energy orthogonal balanced graph drawings, provided the graph is connected.
Recall that
L1 = 0,
as we already observed.
Theorem 21.2. Let G = (V, W) be a weighted graph with |V | = m. If L = D − W is the
(unnormalized) Laplacian of G, and if the eigenvalues of L are 0 = λ1 < λ2 ≤ λ3 ≤ . . . ≤ λm,
then the minimal energy of any balanced orthogonal graph drawing of G in R
n
is equal to
λ2+· · ·+λn+1 (in particular, this implies that n < m). The m×n matrix R consisting of any
unit eigenvectors u2, . . . , un+1 associated with λ2 ≤ . . . ≤ λn+1 yields a balanced orthogonal
graph drawing of minimal energy; it satisfies the condition R> R = I.
Proof. We present the proof given in Godsil and Royle [77] (Section 13.4, Theorem 13.4.1).
The key point is that the sum of the n smallest eigenvalues of L is a lower bound for
tr(R> LR). This can be shown using a Rayleigh ratio argument; see Proposition 17.25
(the Poincar´e separation theorem). Then any n eigenvectors (u1, . . . , un) associated with
λ1, . . . , λn achieve this bound. Because the first eigenvalue of L is λ1 = 0 and because
we are assuming that λ2 > 0, we have u1 = 1/
√
m. Since the uj are pairwise orthogonal
for i = 2, . . . , n and since ui
is orthogonal to u1 = 1/
√
m, the entries in ui add up to 0.
Consequently, for any ` with 2 ≤ ` ≤ n, by deleting u1 and using (u2, . . . , u` ), we obtain a
balanced orthogonal graph drawing in R
`
−1 with the same energy as the orthogonal graph
drawing in R
` using (u1, u2, . . . , u` ). Conversely, from any balanced orthogonal drawing in
R
`
−1 using (u2, . . . , u` ), we obtain an orthogonal graph drawing in R
` using (u1, u2, . . . , u` )
with the same energy. Therefore, the minimum energy of a balanced orthogonal graph
drawing in R
n
is equal to the minimum energy of an orthogonal graph drawing in R
n+1, and
this minimum is λ2 + · · · + λn+1.
Since 1 spans the nullspace of L, using u1 (which belongs to Ker L) as one of the vectors
in R would have the effect that all points representing vertices of G would have the same
726 CHAPTER 21. SPECTRAL GRAPH DRAWING
first coordinate. This would mean that the drawing lives in a hyperplane in R
n
, which is
undesirable, especially when n = 2, where all vertices would be collinear. This is why we
omit the first eigenvector u1.
Observe that for any orthogonal n × n matrix Q, since
tr(R
> LR) = tr(Q
> R
> LRQ),
the matrix RQ also yields a minimum orthogonal graph drawing. This amounts to applying
the rigid motion Q> to the rows of R.
In summary, if λ2 > 0, an automatic method for drawing a graph in R
2
is this:
1. Compute the two smallest nonzero eigenvalues λ2 ≤ λ3 of the graph Laplacian L (it is
possible that λ3 = λ2 if λ2 is a multiple eigenvalue);
2. Compute two unit eigenvectors u2, u3 associated with λ2 and λ3, and let R = [u2 u3]
be the m × 2 matrix having u2 and u3 as columns.
3. Place vertex vi at the point whose coordinates is the ith row of R, that is, (Ri1, Ri2).
This method generally gives pleasing results, but beware that there is no guarantee that
distinct nodes are assigned distinct images since R can have identical rows. This does not
seem to happen often in practice.
21.2 Examples of Graph Drawings
We now give a number of examples using Matlab. Some of these are borrowed or adapted
from Spielman [163].
Example 1. Consider the graph with four nodes whose adjacency matrix is
A =


0 1 1 0
1 0 0 1
1 0 0 1
0 1 1 0

 .
We use the following program to compute u2 and u3:
A = [0 1 1 0; 1 0 0 1; 1 0 0 1; 0 1 1 0];
D = diag(sum(A));
L = D - A;
[v, e] = eigs(L);
gplot(A, v(:,[3 2]))
hold on;
gplot(A, v(:,[3 2]),’o’)
21.2. EXAMPLES OF GRAPH DRAWINGS 727
−0.8 −0.6 −0.4 −0.2 0 0.2 0.4 0.6 0.8 −0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
Figure 21.1: Drawing of the graph from Example 1.
The graph of Example 1 is shown in Figure 21.1. The function eigs(L) computes the
six largest eigenvalues of L in decreasing order, and corresponding eigenvectors. It turns out
that λ2 = λ3 = 2 is a double eigenvalue.
Example 2. Consider the graph G2 shown in Figure 20.3 given by the adjacency matrix
A =


0 1 1 0 0
1 0 1 1 1
1 1 0 1 0
0 1 1 0 1
0 1 0 1 0


.
We use the following program to compute u2 and u3:
A = [0 1 1 0 0; 1 0 1 1 1; 1 1 0 1 0; 0 1 1 0 1; 0 1 0 1 0];
D = diag(sum(A));
L = D - A;
[v, e] = eig(L);
gplot(A, v(:, [2 3]))
hold on
gplot(A, v(:, [2 3]),’o’)
The function eig(L) (with no s at the end) computes the eigenvalues of L in increasing
order. The result of drawing the graph is shown in Figure 21.2. Note that node v2 is assigned
to the point (0, 0), so the difference between this drawing and the drawing in Figure 20.3 is
that the drawing of Figure 21.2 is not convex.
Example 3. Consider the ring graph defined by the adjacency matrix A given in the Matlab
program shown below:
728 CHAPTER 21. SPECTRAL GRAPH DRAWING
−0.8 −0.6 −0.4 −0.2 0 0.2 0.4 0.6 0.8 −0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Figure 21.2: Drawing of the graph from Example 2.
A = diag(ones(1, 11),1);
A = A + A’;
A(1, 12) = 1; A(12, 1) = 1;
D = diag(sum(A));
L = D - A;
[v, e] = eig(L);
gplot(A, v(:, [2 3]))
hold on
gplot(A, v(:, [2 3]),’o’)
−0.5 −0.4 −0.3 −0.2 −0.1 0 0.1 0.2 0.3 0.4 0.5 −0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
Figure 21.3: Drawing of the graph from Example 3.
Observe that we get a very nice ring; see Figure 21.3. Again λ2 = 0.2679 is a double
eigenvalue (and so are the next pairs of eigenvalues, except the last, λ12 = 4).
21.2. EXAMPLES OF GRAPH DRAWINGS 729
Example 4. In this example adapted from Spielman, we generate 20 randomly chosen points
in the unit square, compute their Delaunay triangulation, then the adjacency matrix of the
corresponding graph, and finally draw the graph using the second and third eigenvalues of
the Laplacian.
A = zeros(20,20);
xy = rand(20, 2);
trigs = delaunay(xy(:,1), xy(:,2));
elemtrig = ones(3) - eye(3);
for i = 1:length(trigs),
A(trigs(i,:),trigs(i,:)) = elemtrig;
end
A = double(A >0);
gplot(A,xy)
D = diag(sum(A));
L = D - A;
[v, e] = eigs(L, 3, ’sm’);
figure(2)
gplot(A, v(:, [2 1]))
hold on
gplot(A, v(:, [2 1]),’o’)
