−→f (u),
−→f (v)i = ρh u, vi for all u, v ∈
−→E ,
946 CHAPTER 26. BASICS OF PROJECTIVE GEOMETRY
and we will be done.
Since dim(E) ≥ 2, pick v to be any nonzero vector in −→E such that u and v are linearly
independent, and let us evaluate h
−→f (u + v),
−→f (w)i for any w ∈
−→E . We have
h
−→f (u + v),
−→f (w)i = ϕu+v(w)
= ρ(u + v)h u + v, wi
= ρ(u + v)h u, wi + ρ(u + v)h v, wi
and
h
−→f (u + v),
−→f (w)i = h
−→f (u) + −→f (v),
−→f (w)i
= h
−→f (u),
−→f (w)i + h
−→f (v),
−→f (w)i
= ρ(u)h u, wi + ρ(v)h v, wi ,
so we get
h
(ρ(u + v) − ρ(u))u + (ρ(u + v) − ρ(v))v, wi = 0 for all w ∈
−→E ,
which implies that
(ρ(u + v) − ρ(u))u + (ρ(u + v) − ρ(v))v = 0.
Since u and v are linearly independent, we must have
ρ(u + v) = ρ(u) = ρ(v).
This proves that ρ(u) is a constant ρ independent of u, as claimed.
The converse is trivial.
Remark: Let f ∈ GA(E) be an affine similarity of ratio ρ. If either ρ 6 = 1 or ρ = 1 and
−→f ∈ O(E) does not admit the eigenvalue 1, then f has a unique fixed point.
Indeed, we have
−→f = ρ
−→g for some ρ > 0 and some linear isometry −→g ∈ O(E), so for
any origin a ∈ E, the point a + u is a fixed point of f iff
f(a + u) = a + u
iff
f(a) + −→f (u) = a + u
iff
ρ
−→g (u) = −−−→
f(a)a + u
iff
(
−→g − ρ
−1
id)(u) = ρ
−1−−−→
f(a)a.
26.16. SOME APPLICATIONS OF PROJECTIVE GEOMETRY 947
The linear map −→g − ρ
−1
id is singular iff ρ
−1
is an eigenvalue or −→g , and since −→g ∈ O(E) its
eigenvalues have modulus 1, so if ρ 6 = 1 or if ρ = 1 is not an eigenvalue of −→g , then −→g −ρ
−1
id
is invertible, and then there is a unique u ∈
−→E such that
(
−→g − ρ
−1
id)(u) = ρ
−1−−−→
f(a)a.
For more details on the use of absolute quadrics to obtain some very sophisticated results,
the reader should consult Berger [11, 12], Pedoe [136], Samuel [142], Coxeter [43], Sidler [161],
Tisseron [175], Lehmann and Bkouche [115], and, of course, Volume II of Veblen and Young
[184], which also explains how some non-Euclidean geometries are obtained by chosing the
absolute quadric in an appropriate fashion (after Cayley and Klein).
26.16 Some Applications of Projective Geometry
Projective geometry is definitely a jewel of pure mathematics and one of the major mathe￾matical achievements of the nineteenth century. It turns out to be a prerequisite for algebraic
geometry, but to our surprise (and pleasure), it also turns out to have applications in engi￾neering. In this short section we summarize some of these applications.
We first discuss applications of projective geometry to camera calibration, a crucial prob￾lem in computer vision. Our brief presentation follows quite closely Trucco and Verri [178]
(Chapter 2 and Chapter 6). One should also consult Faugeras [59], or Jain, Katsuri, and
Schunck [100].
The pinhole (or perspective) model of a camera is a typical example from computer vision
that can be explained very simply in terms of projective transformations. A pinhole camera
consists of a point O called the center or focus of projection, and a plane π (not containing
O) called the image plane. The distance f from the image plane π to the center O is called
the focal length. The line through O and perpendicular to π is called the optical axis, and
the point o, intersection of the optical axis with the image plane is called the principal point
or image center . The way the camera works is that a point P in 3D space is projected onto
the image plane (the film) to a point p via the central projection of center O.
It is assumed that an orthonormal frame Fc is attached to the camera, with its origin
at O and its z-axis parallel to the optical axis. Such a frame is called the camera reference
frame. With respect to the camera reference frame, it is very easy to write the equations
relating the coordinates (x, y) (omitting z = f) of the image p (in the image plane π) of a
point P of coordinates (X, Y, Z):
x = f
X
Z
, y = f
Y
Z
.
Typically, points in 3D space are defined by their coordinates not with respect to the camera
reference frame, but with respect to another frame Fw, called the world reference frame.
948 CHAPTER 26. BASICS OF PROJECTIVE GEOMETRY
However, for most computer vision algorithms, it is necessary to know the coordinates of a
point in 3D space with respect to the camera reference frame. Thus, it is necessary to know
the position and orientation of the camera with respect to the frame Fw. The position and
orientation of the camera are given by some affine transformation (R, T) mapping the frame
Fw to the frame Fc, where R is a rotation matrix and T is a translation vector. Furthermore,
the coordinates of an image point are typically known in terms of pixel coordinates, and it
is also necessary to transform the coordinates of an image point with respect to the camera
reference frame to pixel coordinates. In summary, it is necessary to know the transformation
that maps a point P in world coordinates (w.r.t. Fw) to pixel coordinates.
This transformation of world coordinates to pixel coordinates turns out to be a projective
transformation that depends on the extrinsic and the intrinsic parameters of the camera. The
extrinsic parameters of a camera are the location and orientation of the camera with respect
to the world reference frame Fw. It is given by an affine map (in fact, a rigid motion, see
Chapter 13, Section 27.2). The intrinsic parameters of a camera are the parameters needed
to link the pixel coordinates of an image point to the corresponding coordinates in the camera
reference frame. If Pw = (Xw, Yw, Zw) and Pc = (Xc, Yc, Zc) are the coordinates of the 3D
point P with respect to the frames Fw and Fc, respectively, we can write
Pc = R(Pw − T).
Neglecting distorsions possibly introduced by the optics, the correspondence between the
coordinates (x, y) of the image point with respect to Fc and the pixel coordinates (xim, yim)
is given by
x = −(xim − ox)sx,
y = −(yim − oy)sy,
where (ox, oy) are the pixel coordinates the principal point o and sx, sy are scaling parameters.
After some simple calculations, the upshot of all this is that the transformation between
the homogeneous coordinates (Xw, Yw, Zw, 1) of a 3D point and its homogeneous pixel coor￾dinates (x1, x2, x3) is given by


x
x
1
2
x3

 = M


Xw
Yw
Zw
1


where the matrix M, known as the projection matrix , is a 3 × 4 matrix depending on R, T,
ox, oy, f (the focal length), and sx, sy (for the derivation of this equation, see Trucco and
Verri [178], Chapter 2).
The problem of estimating the extrinsic and the instrinsic parameters of a camera is
known as the camera calibration problem. It is an important problem in computer vision.
26.16. SOME APPLICATIONS OF PROJECTIVE GEOMETRY 949
Now, using the equations
x = −(xim − ox)sx,
y = −(yim − oy)sy,
we get
xim = −
f
sx
Xc
Zc
+ ox,
yim = −
f
sy
Yc
Zc
+ oy,
relating the coordinates w.r.t. the camera reference frame to the pixel coordinates. This
suggests using the parameters fx = f/sx and fy = f/sy instead of the parameters f, sx, sy.
In fact, all we need are the parameters fx = f/sx and α = sy/sx, called the aspect ratio.
Without loss of generality, it can also be assumed that (ox, oy) are known. Then we have a
total of eight parameters.
One way of solving the calibration problem is to try estimating fx, α, the rotation matrix
R, and the translation vector T from N image points (xi
, yi), projections of N suitably
chosen world points (Xi
, Yi
, Zi), using the system of equations obtained from the projection
matrix. It turns out that if N ≥ 7 and the points are not coplanar, the rank of the system
is 7, and the system has a nontrivial solution (up to a scalar) that can be found using SVD
methods (see Chapter 22, Trucco and Verri [178], or Jain, Katsuri, and Schunck [100]).
Another method consists in estimating the whole projection matrix M, which depends on
11 parameters, and then extracting extrinsic and intrinsic parameters. Again, SVD methods
are used (see Trucco and Verri [178], and Faugeras [59]).
Cayley’s formula can also be used to solve the calibration cameras, as explained in
Faugeras [59]. Other problems in computer vision can be reduced to problems in projective
geometry (see Faugeras [59]).
In computer graphics, it is also necessary to convert the 3D world coordinates of a point
to a two-dimensional representation on a view plane. This is achieved by a so-called viewing
system using a projective transformation. For details on viewing systems see Watt [189] or
Foley, van Dam, Feiner, and Hughes [63].
Projective spaces are also the right framework to deal with rational curves and rational
surfaces. Indeed, in the projective framework it is easy to deal with vanishing denominators
and with “infinite” values of the parameter(s).
It is much less obvious that projective geometry has applications to efficient communi￾cation, error-correcting codes, and cryptography, as very nicely explained by Beutelspacher
and Rosenbaum [22]. We sketch these applications very briefly, referring our readers to [22]
for details. We begin with efficient communication. Suppose that eight students would like
to exchange information to do their homework economically. The idea is that each student
950 CHAPTER 26. BASICS OF PROJECTIVE GEOMETRY
solves part of the exercises and copies the rest from the others (which we do not recommend,
of course!). It is assumed that each student solves his part of the homework at home, and
that the solutions are communicated by phone. The problem is to minimize the number of
phone calls. An obvious but expensive method is for each student to call each of the other
seven students. A much better method is to imagine that the eight students are the vertices
of a cube, say with coordinates from {0, 1}
3
. There are three types of edges:
1. Those parallel to the z-axis, called type 1;
2. Those parallel to the y-axis, called type 2;
3. Those parallel to the x-axis, called type 3.
The communication can proceed in three rounds as follows: All nodes connected by type 1
edges exchange solutions; all nodes connected by type 2 edges exchange solutions; and finally
all nodes connected by type 3 edges exchange solutions.
It is easy to see that everybody has all the answers at the end of the three rounds.
Furthermore, each student is involved only in three calls (making a call or receiving it), and
the total number of calls is twelve.
In the general case, N nodes would like to exchange information in such a way that
eventually every node has all the information. A good way to to this is to construct certain
finite projective spaces, as explained in Beutelspacher and Rosenbaum [22]. We pick q to be
an integer (for instance, a prime number) such that there is a finite projective space of any
dimension over the finite field of order q. Then, we pick d such that
q
d−1 < N ≤ q
d
.
Since q is prime, there is a projective space P(Kd+1) of dimension d over the finite field
K of order q, and letting H be the hyperplane at infinity in P(Kd+1), we pick a frame
P1, . . . , Pd in H. It turns out that the affine space A = P(Kd+1) − H has q
d points. Then
the communication nodes can be identified with points in the affine space A. Assuming for
simplicity that N = q
d
, the algorithm proceeds in d rounds. During round i, each node
Q ∈ A sends the information it has received to all nodes in A on the line QPi
.
It can be shown that at the end of the d rounds, each node has the total information,
and that the total number of transactions is at most
(q − 1) logq
(N)N.
Other applications of projective spaces to communication systems with switches are de￾scribed in Chapter 2, Section 8, of Beutelspacher and Rosenbaum [22]. Applications to
error-correcting codes are described in Chapter 5 of the same book. Introducing even the
most elementary notions of coding theory would take too much space. Let us simply say
that the existence of certain types of good codes called linear [n, n − r]-codes with minimum
26.16. SOME APPLICATIONS OF PROJECTIVE GEOMETRY 951
distance d is equivalent to the existence of certain sets of points called (n, d − 1)-sets in
the finite projective space P({0, 1}
r
). For the sake of completeness, a set of n points in a
projective space is an (n, s)-set if s is the largest integer such that every subset of s points
is projectively independent. For example, an (n, 3)-set is a set of n points no three of which
are collinear, but at least four of them are coplanar.
Other applications of projective geometry to cryptography are given in Chapter 6 of
Beutelspacher and Rosenbaum [22].
952 CHAPTER 26. BASICS OF PROJECTIVE GEOMETRY
Part III
The Geometry of Bilinear Forms
953
Chapter 27
The Cartan–Dieudonn´e Theorem
In this chapter the structure of the orthogonal group is studied in more depth. In particular,
we prove that every isometry in O(n) is the composition of at most n reflections about
hyperplanes (for n ≥ 2, see Theorem 27.1). This important result is a special case of
the “Cartan–Dieudonn´e theorem” (Cartan [33], Dieudonn´e [50]). We also prove that every
rotation in SO(n) is the composition of at most n flips (for n ≥ 3).
Affine isometries are defined, and their fixed points are investigated. First, we charac￾terize the set of fixed points of an affine map. Then we show that the Cartan–Dieudonn´e
theorem can be generalized to affine isometries: Every rigid motion in Is(n) is the compo￾sition of at most n affine reflections if it has a fixed point, or else of at most n + 2 affine
reflections. We prove that every rigid motion in SE(n) is the composition of at most n affine
flips (for n ≥ 3).
27.1 The Cartan–Dieudonn´e Theorem for Linear
Isometries
The fact that the group O(n) of linear isometries is generated by the reflections is a special
case of a theorem known as the Cartan–Dieudonn´e theorem. Elie Cartan proved a version
of this theorem early in the twentieth century. A proof can be found in his book on spinors
[33], which appeared in 1937 (Chapter I, Section 10, pages 10–12). Cartan’s version applies
to nondegenerate quadratic forms over R or C. The theorem was generalized to quadratic
forms over arbitrary fields by Dieudonn´e [50]. One should also consult Emil Artin’s book
[6], which contains an in-depth study of the orthogonal group and another proof of the
Cartan–Dieudonn´e theorem.
Theorem 27.1. Let E be a Euclidean space of dimension n ≥ 1. Every isometry f ∈ O(E)
that is not the identity is the composition of at most n reflections. When n ≥ 2, the identity
is the composition of any reflection with itself.
955
956 CHAPTER 27. THE CARTAN–DIEUDONNE THEOREM ´
Proof. We proceed by induction on n. When n = 1, every isometry f ∈ O(E) is either the
identity or −id, but −id is a reflection about H = {0}. When n ≥ 2, we have id = s ◦ s
for every reflection s. Let us now consider the case where n ≥ 2 and f is not the identity.
There are two subcases.
Case 1. The map f admits 1 as an eigenvalue, i.e., there is some nonnull vector w such that
f(w) = w. In this case, let H be the hyperplane orthogonal to w, so that E = H ⊕ Rw. We
claim that f(H) ⊆ H. Indeed, if
v · w = 0
for any v ∈ H, since f is an isometry, we get
f(v) · f(w) = v · w = 0,
and since f(w) = w, we get
f(v) · w = f(v) · f(w) = 0,
and thus f(v) ∈ H. Furthermore, since f is not the identity, f is not the identity of H.
Since H has dimension n − 1, by the induction hypothesis applied to H, there are at most
k ≤ n − 1 reflections s1, . . . , sk about some hyperplanes H1, . . . , Hk in H, such that the
restriction of f to H is the composition sk ◦ · · · ◦ s1. Each si can be extended to a reflection
in E as follows: If H = Hi ⊕ Li (where Li = Hi
⊥, the orthogonal complement of Hi
in
H), L = Rw, and Fi = Hi ⊕ L, since H and L are orthogonal, Fi
is indeed a hyperplane,
E = Fi ⊕ Li = Hi ⊕ L ⊕ Li
, and for every u = h + λw ∈ H ⊕ L = E, since
si(h) = pHi
(h) − pLi
(h),
we can define si on E such that
si(h + λw) = pHi
(h) + λw − pLi
(h),
and since h ∈ H, w ∈ L, Fi = Hi ⊕ L, and H = Hi ⊕ Li
, we have
si(h + λw) = pFi
(h + λw) − pLi
(h + λw),
which defines a reflection about Fi = Hi ⊕ L. Now, since f is the identity on L = Rw, it is
immediately verified that f = sk ◦ · · · ◦ s1, with k ≤ n − 1. See Figure 27.1.
Case 2. The map f does not admit 1 as an eigenvalue, i.e., f(u) 6 = u for all u 6 = 0. Pick any
w 6 = 0 in E, and let H be the hyperplane orthogonal to f(w) − w. Since f is an isometry,
we have k f(w)k = k wk , and by Lemma 13.2, we know that s(w) = f(w), where s is the
reflection about H, and we claim that s ◦ f leaves w invariant. Indeed, since s
2 = id, we
have
s(f(w)) = s(s(w)) = w.
See Figure 27.2.
27.1. THE CARTAN–DIEUDONNE THEOREM FOR LINEAR ISOMETRIES ´ 957
w
L
Hi
Li
F
i
H s (h) i λw
λw
Figure 27.1: An illustration of how to extend the reflection si of Case 1 in Theorem 27.1 to
E. The result of this extended reflection is the bold green vector.
Since s
2 = id, we cannot have s◦f = id, since this would imply that f = s, where s is the
identity on H, contradicting the fact that f is not the identity on any vector. Thus, we are
back to Case 1. Thus, there are k ≤ n−1 hyperplane reflections such that s◦f = sk ◦· · · ◦s1,
from which we get
f = s ◦ sk ◦ · · · ◦ s1,
with at most k + 1 ≤ n reflections.
Remarks:
(1) A slightly different proof can be given. Either f is the identity, or there is some nonnull
vector u such that f(u) 6 = u. In the second case, proceed as in the second part of the
proof, to get back to the case where f admits 1 as an eigenvalue.
(2) Theorem 27.1 still holds if the inner product on E is replaced by a nondegenerate
symmetric bilinear form ϕ, but the proof is a lot harder; see Section 29.9.
(3) The proof of Theorem 27.1 shows more than stated. If 1 is an eigenvalue of f, for any
eigenvector w associated with 1 (i.e., f(w) = w, w 6 = 0), then f is the composition
of k ≤ n − 1 reflections about hyperplanes Fi such that Fi = Hi ⊕ L, where L is the
line Rw and the Hi are subspaces of dimension n − 2 all orthogonal to L (the Hi are
hyperplanes in H). This situation is illustrated in Figure 27.3.
If 1 is not an eigenvalue of f, then f is the composition of k ≤ n reflections about
hyperplanes H, F1, . . . , Fk−1, such that Fi = Hi ⊕ L, where L is a line intersecting H,
and the Hi are subspaces of dimension n−2 all orthogonal to L (the Hi are hyperplanes
in L
⊥). This situation is illustrated in Figure 27.4.
h + λw
-pL
(h
i
)
pHi
(h)
h
958 CHAPTER 27. THE CARTAN–DIEUDONNE THEOREM ´
w
H
Figure 27.2: The construction of the hyperplane H for Case 2 of Theorem 27.1.
w
H
Hi
Hj
F
j
L
w
u
s (u) i
s (u) s (u) j i
Figure 27.3: An isometry f as a composition of reflections, when 1 is an eigenvalue of f.
(4) It is natural to ask what is the minimal number of hyperplane reflections needed to
obtain an isometry f. This has to do with the dimension of the eigenspace Ker (f − id)
associated with the eigenvalue 1. We will prove later that every isometry is the com￾position of k hyperplane reflections, where
k = n − dim(Ker (f − id)),
and that this number is minimal (where n = dim(E)).
When n = 2, a reflection is a reflection about a line, and Theorem 27.1 shows that every
isometry in O(2) is either a reflection about a line or a rotation, and that every rotation is
the product of two reflections about some lines. In general, since det(s) = −1 for a reflection
s, when n ≥ 3 is odd, every rotation is the product of an even number less than or equal
f(w) - w
f(w)
27.1. THE CARTAN–DIEUDONNE THEOREM FOR LINEAR ISOMETRIES ´ 959
H
Hj
F
j
L
L
w
f(w)
Figure 27.4: An isometry f as a composition of reflections when 1 is not an eigenvalue of f.
Note that the pink plane H is perpendicular to f(w) − w.
to n − 1 of reflections, and when n is even, every improper orthogonal transformation is the
product of an odd number less than or equal to n − 1 of reflections.
In particular, for n = 3, every rotation is the product of two reflections about planes.
When n is odd, we can say more about improper isometries. Indeed, when n is odd, every
improper isometry admits the eigenvalue −1. This is because if E is a Euclidean space of
finite dimension and f : E → E is an isometry, because k f(u)k = k uk for every u ∈ E, if λ
is any eigenvalue of f and u is an eigenvector associated with λ, then
k
f(u)k = k λuk = |λ|kuk = k uk ,
which implies |λ| = 1, since u 6 = 0. Thus, the real eigenvalues of an isometry are either
+1 or −1. However, it is well known that polynomials of odd degree always have some
real root. As a consequence, the characteristic polynomial det(f − λid) of f has some real
root, which is either +1 or −1. Since f is an improper isometry, det(f) = −1, and since
det(f) is the product of the eigenvalues, the real roots cannot all be +1, and thus −1 is an
eigenvalue of f. Going back to the proof of Theorem 27.1, since −1 is an eigenvalue of f,
there is some nonnull eigenvector w such that f(w) = −w. Using the second part of the
proof, we see that the hyperplane H orthogonal to f(w) − w = −2w is in fact orthogonal
to w, and thus f is the product of k ≤ n reflections about hyperplanes H, F1, . . . , Fk−1
such that Fi = Hi ⊕ L, where L is a line orthogonal to H, and the Hi are hyperplanes in
H = L
⊥ orthogonal to L. However, k must be odd, and so k − 1 is even, and thus the
composition of the reflections about F1, . . . , Fk−1 is a rotation. Thus, when n is odd, an
improper isometry is the composition of a reflection about a hyperplane H with a rotation
consisting of reflections about hyperplanes F1, . . . , Fk−1 containing a line, L, orthogonal to
960 CHAPTER 27. THE CARTAN–DIEUDONNE THEOREM ´
H. In particular, when n = 3, every improper orthogonal transformation is the product of
a rotation with a reflection about a plane orthogonal to the axis of rotation.
Using Theorem 27.1, we can also give a rather simple proof of the classical fact that in a
Euclidean space of odd dimension, every rotation leaves some nonnull vector invariant, and
thus a line invariant.
If λ is an eigenvalue of f, then the following lemma shows that the orthogonal complement
Eλ(f)
⊥ of the eigenspace associated with λ is closed under f.
Proposition 27.2. Let E be a Euclidean space of finite dimension n, and let f : E → E be
an isometry. For any subspace F of E, if f(F) = F, then f(F
⊥) ⊆ F
⊥ and E = F ⊕ F
⊥.
Proof. We just have to prove that if w ∈ E is orthogonal to every u ∈ F, then f(w) is also
orthogonal to every u ∈ F. However, since f(F) = F, for every v ∈ F, there is some u ∈ F
such that f(u) = v, and we have
f(w) · v = f(w) · f(u) = w · u,
since f is an isometry. Since we assumed that w ∈ E is orthogonal to every u ∈ F, we have
w · u = 0,
and thus
f(w) · v = 0,
and this for every v ∈ F. Thus, f(F
⊥) ⊆ F
⊥. The fact that E = F ⊕ F
⊥ follows from
Lemma 12.11.
Lemma 27.2 is the starting point of the proof that every orthogonal matrix can be di￾agonalized over the field of complex numbers. Indeed, if λ is any eigenvalue of f, then
f(Eλ(f)) = Eλ(f), where Eλ(f) is the eigenspace associated with λ, and thus the orthogo￾nal Eλ(f)
⊥ is closed under f, and E = Eλ(f) ⊕ Eλ(f)
⊥. The problem over R is that there
may not be any real eigenvalues. However, when n is odd, the following lemma shows that
every rotation admits 1 as an eigenvalue (and similarly, when n is even, every improper
orthogonal transformation admits 1 as an eigenvalue).
Proposition 27.3. Let E be a Euclidean space.
(1) If E has odd dimension n = 2m + 1, then every rotation f admits 1 as an eigenvalue
and the eigenspace F of all eigenvectors left invariant under f has an odd dimension
2p + 1. Furthermore, there is an orthonormal basis of E, in which f is represented by
a matrix of the form

R2(m−p) 0
0 I2p+1
,
where R2(m−p)
is a rotation matrix that does not have 1 as an eigenvalue.
27.1. THE CARTAN–DIEUDONNE THEOREM FOR LINEAR ISOMETRIES ´ 961
(2) If E has even dimension n = 2m, then every improper orthogonal transformation f
admits 1 as an eigenvalue and the eigenspace F of all eigenvectors left invariant under
f has an odd dimension 2p + 1. Furthermore, there is an orthonormal basis of E, in
which f is represented by a matrix of the form

S2(m−p)−1 0
0 I2p+1
,
where S2(m−p)−1 is an improper orthogonal matrix that does not have 1 as an eigenvalue.
Proof. We prove only (1), the proof of (2) being similar. Since f is a rotation and n = 2m+1
is odd, by Theorem 27.1, f is the composition of an even number less than or equal to 2m
of reflections. From Lemma 24.15, recall the Grassmann relation
dim(M) + dim(N) = dim(M + N) + dim (M ∩ N),
where M and N are subspaces of E. Now, if M and N are hyperplanes, their dimension
is n − 1, and thus dim (M ∩ N) ≥ n − 2. Thus, if we intersect k ≤ n hyperplanes, we see
that the dimension of their intersection is at least n − k. Since each of the reflections is the
identity on the hyperplane defining it, and since there are at most 2m = n − 1 reflections,
their composition is the identity on a subspace of dimension at least 1. This proves that
1 is an eigenvalue of f. Let F be the eigenspace associated with 1, and assume that its
dimension is q. Let G = F
⊥ be the orthogonal of F. By Lemma 27.2, G is stable under f,
and E = F ⊕ G. Using Lemma 12.10, we can find an orthonormal basis of E consisting of
an orthonormal basis for G and orthonormal basis for F. In this basis, the matrix of f is of
the form

R2m+1−q 0
0 Iq

.
Thus, det(f) = det(R), and R must be a rotation, since f is a rotation and det(f) = 1.
Now, if f left some vector u 6 = 0 in G invariant, this vector would be an eigenvector for 1,
and we would have u ∈ F, the eigenspace associated with 1, which contradicts E = F ⊕ G.
Thus, by the first part of the proof, the dimension of G must be even, since otherwise, the
restriction of f to G would admit 1 as an eigenvalue. Consequently, q must be odd, and R
does not admit 1 as an eigenvalue. Letting q = 2p + 1, the lemma is established.
An example showing that Lemma 27.3 fails for n even is the following rotation matrix
(when n = 2):
R =

cos
sin θ
θ −
cos
sin
θ
θ

.
The above matrix does not have real eigenvalues for θ 6 = kπ.
It is easily shown that for n = 2, with respect to any chosen orthonormal basis (e1, e2),
every rotation is represented by a matrix of form
R =

cos
sin θ
θ −
cos
sin
θ
θ

962 CHAPTER 27. THE CARTAN–DIEUDONNE THEOREM ´
where θ ∈ [0, 2π[, and that every improper orthogonal transformation is represented by a
matrix of the form
S =

cos
sin θ
θ
−
sin
cos
θ
θ

.
In the first case, we call θ ∈ [0, 2π[ the measure of the angle of rotation of R w.r.t. the
orthonormal basis (e1, e2). In the second case, we have a reflection about a line, and it is
easy to determine what this line is. It is also easy to see that S is the composition of a
reflection about the x-axis with a rotation (of matrix R).

We refrained from calling θ “the angle of rotation,” because there are some subtleties
involved in defining rigorously the notion of angle of two vectors (or two lines). For
example, note that with respect to the “opposite basis” (e2, e1), the measure θ must be
changed to 2π − θ (or −θ if we consider the quotient set R/2π of the real numbers modulo
2π).
It is easily shown that the group SO(2) of rotations in the plane is abelian. First, recall
that every plane rotation is the product of two reflections (about lines), and that every
isometry in O(2) is either a reflection or a rotation. To alleviate the notation, we will omit
the composition operator ◦, and write rs instead of r ◦ s. Now, if r is a rotation and s is a
reflection, rs being in O(2) must be a reflection (since det(rs) = det(r) det(s) = −1), and
thus (rs)
2 = id, since a reflection is an involution, which implies that
srs = r
−1
.
Then, given two rotations r1 and r2, writing r1 as r1 = s2s1 for two reflections s1, s2, we have
r1r2r1
−1 = s2s1r2(s2s1)
−1 = s2s1r2s
−
1
1
s
−
2
1 = s2s1r2s1s2 = s2r2
−1
s2 = r2,
since srs = r
−1
for all reflections s and rotations r, and thus r1r2 = r2r1.
We can also perform the following calculation, using some elementary trigonometry:

cos
sin ϕ
ϕ
−
sin
cos
ϕ
ϕ
 
cos
sin ψ
ψ
−
sin
cos
ψ
ψ

=

cos(
sin(ϕ
ϕ
+
+
ψ
ψ
)
) sin(
− cos(
ϕ
ϕ
+
+
ψ
ψ
)
)

.
The above also shows that the inverse of a rotation matrix
R =

cos
sin θ
θ −
cos
sin
θ
θ

is obtained by changing θ to −θ (or 2π − θ). Incidentally, note that in writing a rotation r
as the product of two reflections r = s2s1, the first reflection s1 can be chosen arbitrarily,
since s
2
1 = id, r = (rs1)s1, and rs1 is a reflection.
For n = 3, the only two choices for p are p = 1, which corresponds to the identity, or
p = 0, in which case f is a rotation leaving a line invariant. This line D is called the axis of
27.1. THE CARTAN–DIEUDONNE THEOREM FOR LINEAR ISOMETRIES ´ 963
D
θ / 2
u
R (u)
Figure 27.5: 3D rotation as the composition of two reflections.
rotation. The rotation R behaves like a two-dimensional rotation around the axis of rotation.
Thus, the rotation R is the composition of two reflections about planes containing the axis
of rotation D and forming an angle θ/2. This is illustrated in Figure 27.5.
The measure of the angle of rotation θ can be determined through its cosine via the
formula
cos θ = u · R(u),
where u is any unit vector orthogonal to the direction of the axis of rotation. However, this
does not determine θ ∈ [0, 2π[ uniquely, since both θ and 2π − θ are possible candidates.
What is missing is an orientation of the plane (through the origin) orthogonal to the axis of
rotation.
In the orthonormal basis of the lemma, a rotation is represented by a matrix of the form
R =


cos
sin
0 0 1
θ
θ −
cos
sin
θ
θ 0
0

 .
Remark: For an arbitrary rotation matrix A, since a1 1 + a2 2 + a3 3 (the trace of A) is the
sum of the eigenvalues of A, and since these eigenvalues are cos θ + isin θ, cos θ − isin θ, and
1, for some θ ∈ [0, 2π[, we can compute cos θ from
1 + 2 cos θ = a1 1 + a2 2 + a3 3.
It is also possible to determine the axis of rotation (see the problems).
964 CHAPTER 27. THE CARTAN–DIEUDONNE THEOREM ´
An improper transformation is either a reflection about a plane or the product of three
reflections, or equivalently the product of a reflection about a plane with a rotation, and we
noted in the discussion following Theorem 27.1 that the axis of rotation is orthogonal to the
plane of the reflection. Thus, an improper transformation is represented by a matrix of the
form
S =


cos
sin
0 0
θ
θ −
cos
sin
θ
θ
−
0
0
1

 .
When n ≥ 3, the group of rotations SO(n) is not only generated by hyperplane reflections,
but also by flips (about subspaces of dimension n − 2). We will also see, in Section 27.2,
that every proper affine rigid motion can be expressed as the composition of at most n flips,
which is perhaps even more surprising! The proof of these results uses the following key
lemma.
Proposition 27.4. Given any Euclidean space E of dimension n ≥ 3, for any two reflections
h1 and h2 about some hyperplanes H1 and H2, there exist two flips f1 and f2 such that
h2 ◦ h1 = f2 ◦ f1.
Proof. If h1 = h2, it is obvious that
h1 ◦ h2 = h1 ◦ h1 = id = f1 ◦ f1
for any flip f1. If h1 6 = h2, then H1 ∩ H2 = F, where dim(F) = n − 2 (by the Grassmann
relation). We can pick an orthonormal basis (e1, . . . , en) of E such that (e1, . . . , en−2) is
an orthonormal basis of F. We can also extend (e1, . . . , en−2) to an orthonormal basis
(e1, . . . , en−2, u1, v1) of E, where (e1, . . . , en−2, u1) is an orthonormal basis of H1, in which
case
en−1 = cos θ1 u1 + sin θ1 v1,
en = sin θ1 u1 − cos θ1 v1,
for some θ1 ∈ [0, 2π]. See Figure 27.6
Since h1 is the identity on H1 and v1 is orthogonal to H1, it follows that h1(u1) = u1,
h1(v1) = −v1, and we get
h1(en−1) = cos θ1 u1 − sin θ1 v1,
h1(en) = sin θ1 u1 + cos θ1 v1.
After some simple calculations, we get
h1(en−1) = cos 2θ1 en−1 + sin 2θ1 en,
h1(en) = sin 2θ1 en−1 − cos 2θ1 en.
27.1. THE CARTAN–DIEUDONNE THEOREM FOR LINEAR ISOMETRIES ´ 965
e2
e2
e1 e1
e1
e3
e3
u1
u1
v1
v1
F
H
H1
2
Figure 27.6: An illustration of the hyperplanes H1, H2, their intersection F, and the two
orthonormal basis utilized in the proof of Proposition 27.4.
As a consequence, the matrix A1 of h1 over the basis (e1, . . . , en) is of the form
A1 =


In−2 0 0
0 cos 2θ1 sin 2θ1
0 sin 2θ1 − cos 2θ1

 .
Similarly, the matrix A2 of h2 over the basis (e1, . . . , en) is of the form
A2 =


In−2 0 0
0 cos 2θ2 sin 2θ2
0 sin 2θ2 − cos 2θ2

 .
Observe that both A1 and A2 have the eigenvalues −1 and +1 with multiplicity n − 1. The
trick is to observe that if we change the last entry in In−2 from +1 to −1 (which is possible
since n ≥ 3), we have the following product A2A1:


In−3 0 0 0
0 −1 0 0
0 0 sin 2
0 0 cos 2
θ
θ
2
2
−
sin 2
cos 2
θ2
θ2




In−3 0 0 0
0 −1 0 0
0 0 cos 2θ1 sin 2θ1
0 0 sin 2θ1 − cos 2θ1

 .
Now, the two matrices above are clearly orthogonal, and they have the eigenvalues −1, −1,
and +1 with multiplicity n−2, which implies that the corresponding isometries leave invariant
a subspace of dimension n − 2 and act as −id on its orthogonal complement (which has
dimension 2). This means that the above two matrices represent two flips f1 and f2 such
that h2 ◦ h1 = f2 ◦ f1. See Figure 27.7.
966 CHAPTER 27. THE CARTAN–DIEUDONNE THEOREM ´
e2
e1
e3
F
H1
h ( e2 1
h
1
( e3 )
)
e1
e3 ( e3 )
e2
e1
e3
F
h ( e2 1
1
( e3 )
)
h
θ
1
f
1
f
1( e
1 )
(i.)
(ii.)
(iii.)
Figure 27.7: The conversion of the hyperplane reflection h1 into the flip or 180◦
rotation
around the green axis in the e2e3-plane. The green axis corresponds to the restriction of the
eigenspace associated with eigenvalue 1.
Using Lemma 27.4 and the Cartan–Dieudonn´e theorem, we obtain the following charac￾terization of rotations when n ≥ 3.
Theorem 27.5. Let E be a Euclidean space of dimension n ≥ 3. Every rotation f ∈ SO(E)
is the composition of an even number of flips f = f2k ◦ · · · ◦ f1, where 2k ≤ n. Furthermore,
if u 6 = 0 is invariant under f (i.e., u ∈ Ker (f − id)), we can pick the last flip f2k such that
u ∈ F2
⊥
k
, where F2k is the subspace of dimension n − 2 determining f2k.
Proof. By Theorem 27.1, the rotation f can be expressed as an even number of hyperplane
reflections f = s2k ◦s2k−1 ◦· · ·◦s2 ◦s1, with 2k ≤ n. By Lemma 27.4, every composition of two
reflections s2i ◦ s2i−1 can be replaced by the composition of two flips f2i ◦ f2i−1 (1 ≤ i ≤ k),
which yields f = f2k ◦ · · · ◦ f1, where 2k ≤ n.
Assume that f(u) = u, with u 6 = 0. We have already made the remark that in the case
where 1 is an eigenvalue of f, the proof of Theorem 27.1 shows that the reflections si can
be chosen so that si(u) = u. In particular, if each reflection si
is a reflection about the
hyperplane Hi
, we have u ∈ H2k−1 ∩ H2k. Letting F = H2k−1 ∩ H2k, pick an orthonormal
basis (e1, . . . , en−3, en−2) of F, where
en−2 =
u
k
uk
.
27.2. AFFINE ISOMETRIES (RIGID MOTIONS) 967
The proof of Lemma 27.4 yields two flips f2k−1 and f2k such that
f2k(en−2) = −en−2 and s2k ◦ s2k−1 = f2k ◦ f2k−1,
since the (n − 2)th diagonal entry in both matrices is −1, which means that en−2 ∈ F2
⊥
k
,
where F2k is the subspace of dimension n − 2 determining f2k. Since u = k uk en−2, we also
have u ∈ F2
⊥
k
.
Remarks:
(1) It is easy to prove that if f is a rotation in SO(3) and if D is its axis and θ is its angle
of rotation, then f is the composition of two flips about lines D1 and D2 orthogonal
to D and making an angle θ/2.
(2) It is natural to ask what is the minimal number of flips needed to obtain a rotation f
(when n ≥ 3). As for arbitrary isometries, we will prove later that every rotation is
the composition of k flips, where
k = n − dim(Ker (f − id)),
and that this number is minimal (where n = dim(E)).
We now turn to affine isometries.
27.2 Affine Isometries (Rigid Motions)
In the remaining sections we study affine isometries. First, we characterize the set of fixed
points of an affine map. Using this characterization, we prove that every affine isometry f
can be written uniquely as
f = t ◦ g, with t ◦ g = g ◦ t,
where g is an isometry having a fixed point, and t is a translation by a vector τ such that
−→f (τ ) = τ , and with some additional nice properties (see Theorem 27.10). This is a gener￾alization of a classical result of Chasles about (proper) rigid motions in R
3
(screw motions).
We prove a generalization of the Cartan–Dieudonn´e theorem for the affine isometries: Every
isometry in Is(n) can be written as the composition of at most n affine reflections if it has a
fixed point, or else as the composition of at most n + 2 affine reflections. We also prove that
every rigid motion in SE(n) is the composition of at most n affine flips (for n ≥ 3). This is
somewhat surprising, in view of the previous theorem.
Definition 27.1. Given any two nontrivial Euclidean affine spaces E and F of the same
finite dimension n, a function f : E → F is an affine isometry (or rigid map) if it is an affine
map and
k
−−−−−→
f(a)f(b)k = k
−→abk ,
for all a, b ∈ E. When E = F, an affine isometry f : E → E is also called a rigid motion.
968 CHAPTER 27. THE CARTAN–DIEUDONNE THEOREM ´
Thus, an affine isometry is an affine map that preserves the distance. This is a rather
strong requirement. In fact, we will show that for any function f : E → F, the assumption
that
k −−−−−→
f(a)f(b)k = k
−→abk ,
for all a, b ∈ E, forces f to be an affine map.
Remark: Sometimes, an affine isometry is defined as a bijective affine isometry. When E
and F are of finite dimension, the definitions are equivalent.
The following simple lemma is left as an exercise.
Proposition 27.6. Given any two nontrivial Euclidean affine spaces E and F of the same
finite dimension n, an affine map f : E → F is an affine isometry iff its associated linear
map
−→f :
−→E →
−→F is an isometry. An affine isometry is a bijection.
Let us now consider affine isometries f : E → E. If −→f is a rotation, we call f a proper (or
direct) affine isometry, and if −→f is an improper linear isometry, we call f an improper (or
skew) affine isometry. It is easily shown that the set of affine isometries f : E → E forms a
group, and those for which −→f is a rotation is a subgroup. The group of affine isometries, or
rigid motions, is a subgroup of the affine group GA(E), denoted by Is(E) (or Is(n) when
E = E
n
). In Snapper and Troyer [162] the group of rigid motions is denoted by Mo(E).
Since we denote the group of affine bijections as GA(E), perhaps we should denote the
group of affine isometries by IA(E) (or EA(E)!). The subgroup of Is(E) consisting of the
direct rigid motions is also a subgroup of SA(E), and it is denoted by SE(E) (or SE(n),
when E = E
n
). The translations are the affine isometries f for which −→f = id, the identity
map on
−→E . The following lemma is the counterpart of Lemma 12.12 for isometries between
Euclidean vector spaces.
Proposition 27.7. Given any two nontrivial Euclidean affine spaces E and F of the same
finite dimension n, for every function f : E → F, the following properties are equivalent:
(1) f is an affine map and k
−−−−−→
f(a)f(b)k = k
−→abk , for all a, b ∈ E.
(2) k
−−−−−→
f(a)f(b)k = k
−→abk , for all a, b ∈ E.
Proof. Obviously, (1) implies (2). In order to prove that (2) implies (1), we proceed as
follows. First, we pick some arbitrary point Ω ∈ E. We define the map g :
−→E →
−→F such
that
g(u) =
−−−−−−−−−→
f(Ω)f(Ω + u)
for all u ∈ E. Since
f(Ω) + g(u) = f(Ω) + −−−−−−−−−→
f(Ω)f(Ω + u) = f(Ω + u)
27.3. FIXED POINTS OF AFFINE MAPS 969
for all u ∈
−→E , f will be affine if we can show that g is linear, and f will be an affine isometry
if we can show that g is a linear isometry.
Observe that
g(v) − g(u) =
−−−−−−−−−→
f(Ω)f(Ω + v) −
−−−−−−−−−→
f(Ω)f(Ω + u)
=
−−−−−−−−−−−−→
f(Ω + u)f(Ω + v).
Then, the hypothesis
k
−−−−−→
f(a)f(b)k = k
−→abk
for all a, b ∈ E, implies that
k
g(v) − g(u)k = k
−−−−−−−−−−−−→
f(Ω + u)f(Ω + v)k = k
−−−−−−−−−−→ (Ω + u)(Ω + v)k = k v − uk .
Thus, g preserves the distance. Also, by definition, we have
g(0) = 0.
Thus, we can apply Lemma 12.12, which shows that g is indeed a linear isometry, and thus
f is an affine isometry.
In order to understand the structure of affine isometries, it is important to investigate
the fixed points of an affine map.
27.3 Fixed Points of Affine Maps
