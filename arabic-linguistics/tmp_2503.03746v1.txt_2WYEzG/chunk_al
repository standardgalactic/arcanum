tion for mathematical reasoning.
arXiv preprint
arXiv:2406.10858.
Paul F Christiano, Jan Leike, Tom Brown, Miljan Mar-
tic, Shane Legg, and Dario Amodei. 2017. Deep
reinforcement learning from human preferences. Ad-
vances in neural information processing systems, 30.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Nakano, et al. 2021. Training verifiers to solve math
word problems. arXiv preprint arXiv:2110.14168.
Jacob Devlin. 2018. Bert: Pre-training of deep bidi-
rectional transformers for language understanding.
arXiv preprint arXiv:1810.04805.
Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and
Tushar Khot. 2022. Complexity-based prompting for
multi-step reasoning. In The Eleventh International
Conference on Learning Representations.
Leo Gao, John Schulman, and Jacob Hilton. 2023. Scal-
ing laws for reward model overoptimization. In In-
ternational Conference on Machine Learning, pages
10835–10866. PMLR.
Jiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan,
Xuehao Zhai, Chengjin Xu, Wei Li, Yinghan Shen,
Shengjie Ma, Honghao Liu, et al. 2024. A survey on
llm-as-a-judge. arXiv preprint arXiv:2411.15594.
Chaoqun He, Renjie Luo, Yuzhuo Bai, Shengding Hu,
Zhen Leng Thai, Junhao Shen, Jinyi Hu, Xu Han,
Yujie Huang, Yuxiang Zhang, et al. 2024. Olympiad-
bench: A challenging benchmark for promoting agi
with olympiad-level bilingual multimodal scientific
problems. arXiv preprint arXiv:2402.14008.
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul
Arora, Steven Basart, Eric Tang, Dawn Song, and Ja-
cob Steinhardt. 2021. Measuring mathematical prob-
lem solving with the math dataset. arXiv preprint
arXiv:2103.03874.
Jiwoo Hong, Noah Lee, and James Thorne. 2024. Orpo:
Monolithic preference optimization without refer-
ence model. In Proceedings of the 2024 Conference
on Empirical Methods in Natural Language Process-
ing, pages 11170–11189.
Aaron Hurst, Adam Lerer, Adam P Goucher, Adam
Perelman, Aditya Ramesh, Aidan Clark, AJ Os-
trow, Akila Welihinda, Alan Hayes, Alec Radford,
et al. 2024. Gpt-4o system card. arXiv preprint
arXiv:2410.21276.
Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richard-
son, Ahmed El-Kishky, Aiden Low, Alec Helyar,
Aleksander Madry, Alex Beutel, Alex Carney, et al.
2024.
Openai o1 system card.
arXiv preprint
arXiv:2412.16720.
Xin Lai, Zhuotao Tian, Yukang Chen, Senqiao Yang, Xi-
angru Peng, and Jiaya Jia. 2024. Step-dpo: Step-wise
preference optimization for long-chain reasoning of
llms. arXiv preprint arXiv:2406.18629.
Nathan Lambert, Valentina Pyatkin, Jacob Morrison,
LJ Miranda, Bill Yuchen Lin, Khyathi Chandu,
Nouha Dziri, Sachin Kumar, Tom Zick, Yejin Choi,
et al. 2024.
Rewardbench:
Evaluating reward
models for language modeling.
arXiv preprint
arXiv:2403.13787.
Jia LI, Edward Beeching,
Lewis Tunstall,
Ben
Lipkin, Roman Soletskyi, Shengyi Costa Huang,
Kashif Rasul, Longhui Yu, Albert Jiang, Ziju
Shen, Zihan Qin, Bin Dong, Li Zhou, Yann
9

Fleureau, Guillaume Lample, and Stanislas Polu.
2024. Numinamath. [https://huggingface.co/
AI-MO/NuminaMath-CoT](https://github.com/
project-numina/aimo-progress-prize/blob/
main/report/numina_dataset.pdf).
Junlong Li, Shichao Sun, Weizhe Yuan, Run-Ze Fan,
Hai Zhao, and Pengfei Liu. 2023.
Generative
judge for evaluating alignment.
arXiv preprint
arXiv:2310.05470.
Minpeng Liao, Wei Luo, Chengxi Li, Jing Wu, and
Kai Fan. 2024. Mario: Math reasoning with code
interpreter output–a reproducible pipeline.
arXiv
preprint arXiv:2401.08190.
Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri
Edwards, Bowen Baker, Teddy Lee, Jan Leike,
John Schulman, Ilya Sutskever, and Karl Cobbe.
2023.
Let’s verify step by step.
arXiv preprint
arXiv:2305.20050.
Yinhong Liu, Han Zhou, Zhijiang Guo, Ehsan Shareghi,
