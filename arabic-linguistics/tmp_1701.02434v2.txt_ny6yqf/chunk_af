A CONCEPTUAL INTRODUCTION TO HAMILTONIAN MONTE CARLO
13
Fig 8. Markov chains typically have trouble exploring regions of the typical set with large curvature (green).
Incomplete exploration biases Markov chain Monte Carlo estimators and spoils critical results such as
Central Limit Theorems.
of these estimators by using only those samples generated once the Markov chain has begun
to explore the typical set. Consequently, it is common practice to warm up the Markov chain
by throwing away those initial converging samples before computing Markov chain Monte
Carlo estimators. Warm-up can also be extended to allow for any degrees of freedom in the
Markov transition to be empirically optimized without biasing the subsequent estimators.
2.3 Pathological Behavior
Unfortunately, this idealized behavior requires that the Markov transition is compatible
with the structure of the target distribution. When the target distribution exhibits patho-
logical behavior, however, Markov transitions will have trouble exploring and Markov chain
Monte Carlo will fail.
Consider, for example, a target probability distribution where the typical set pinches
into a region of high curvature (Figure 8). Most Markov transitions are not able to resolve
these details and hence they cannot maneuver into these tight regions. The resulting Markov
chains simply ignore them, biasing subsequent Markov chain Monte Carlo estimators due
to the incomplete exploration. It is as if there are thin but deep cracks across a surface in
parameter space hiding a signiﬁcant amount of probability that the Markov chains pass
right over and miss entirely.
Because Markov chains have to recover the exact expectations asymptotically, they have
to somehow compensate for not being able to explore these regions. Typically the Markov
chain accomplishes this by getting stuck near the boundary of the pathological region: as
the chain hovers around the pathological region the estimators are drawn down almost
as if the Markov chain were exploring the pathological region. Eventually this causes the
estimators to overcorrect, inducing a bias in the opposite direction, at which point the
Markov chain escapes to explore the rest of the typical set (Figure 9).
Ultimately this behavior results in estimators that strongly oscillate around the true
expectations. Asymptotically the oscillations average out to give the true values, but that

14
BETANCOURT
q1
q2
Iteration
q2
 0
Iteration
|E[q2] −ˆq2|
(a)
q1
q2
Iteration
q2
 0
Iteration
|E[q2] −ˆq2|
(b)
q1
q2
Iteration
q2
 0
Iteration
|E[q2] −ˆq2|
(c)
Fig 9. In practice, pathological regions of the typical set usually cause Markov chains to get “stuck”. (a)
Initially the Markov chain explores well-behaved regions of the typical set, avoiding the pathological neighbor-
hood entirely and biasing Markov chain Monte Carlo estimators. (b) If the Markov chain is run long enough
then it will get stuck near the boundary of the pathological region, slowly correcting the Markov chain Monte
Carlo estimators. (c) Eventually the Markov chain escapes to explore the rest of the typical set. This process
repeats, causing the resulting estimators to oscillate around the true expectations and inducing strong biases
unless the chain is improbably stopped at exactly the right time.

A CONCEPTUAL INTRODUCTION TO HAMILTONIAN MONTE CARLO
15
balance is fragile. Terminating the Markov chain after only a ﬁnite time almost always
destroys this balance, and resulting estimators will suﬀer from substantial biases.
Whether or not features of the target distribution become pathological in a given appli-
cation of Markov chain Monte Carlo depends on how exactly the given Markov transition
interacts with those features. Some transitions are generically more robust to certain fea-
tures than others, and some can achieve robust performance by carefully tuning degrees of
freedom in the transition. Regardless, great care has to be taken to ensure that a Markov
transition is suﬃciently robust to be used in a given application.
Formally, the suﬃcient condition that guarantees the idealized behavior, most impor-
tantly a Central Limit Theorem for the Markov chain Monte Carlo estimators, is known
as geometric ergodicity (Roberts and Rosenthal, 2004). Unfortunately, geometric ergodic-
ity is extremely diﬃcult to verify theoretically for all but the simplest problems and we
must instead resort to empirical diagnostics. The most powerful of these is the split ˆR
statistic (Gelman et al., 2014), which quantiﬁes the variation of an ensemble of Markov
chains initialized from diﬀerent points in parameter space. The pathologies that frustrate
geometric ergodicity induce inconsistencies amongst the individual chains in the ensemble,
and hence large values of split ˆR. Consequently, when split ˆR is not near the nominal value
of 1, we should be suspicious of geometric ergodicity being satisﬁed and hence the practical
utility of any resulting estimators.
2.4 The Metropolis-Hastings Algorithm
Given a Markov transition that targets the desired distribution, Markov chain Monte
Carlo deﬁnes a generic strategy for quantifying the typical set. Constructing such a tran-
sition, however, is itself a nontrivial problem. Fortunately there are various procedures for
automatically constructing appropriate transitions for any given target distribution, with
the foremost amongst these the Metropolis-Hastings algorithm (Metropolis et al., 1953;
Hastings, 1970).
The Metropolis-Hastings algorithm is comprised of two steps: a proposal and a correc-
tion. The proposal is any stochastic perturbation of the initial state while the correction
rejects any proposals that stray too far away from the typical set of the target distribu-
tion. More formally, let Q(q′ | q) be the probability density deﬁning each proposal. The
probability of accepting a given proposal is then given by
a
