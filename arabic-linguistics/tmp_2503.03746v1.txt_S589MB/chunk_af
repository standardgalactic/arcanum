tionally, we choose OpenAI GPT-o1 (Jaech et al.,
2024) for our initialization data processing (§3.2).
Datasets
In our experiments, we mainly focus on
two capabilities of the model:
• Step-by-step Mathematical Reasoning: We
choose a subset of NuminaMath (LI et al.,
2024) for IFT data construction, whose so-
lutions have been formatted in a Chain of
Thought (CoT) manner. We extract a subset
of 28,889 samples and prompt GPT-o1 (Jaech
et al., 2024) to logically segment the solutions
into step-by-step format without altering any
original content. The corresponding prompt is
presented in Figure 3. And the instruction for-
mat for step-by-step long-thought reasoning
is presented in Figure 4.
• Step-wise LLM-as-a-Judge: As described in
the Section 3.2, we first filtrate some prefer-
ence pairs using the trained PRM. Then we
utilize GPT-o1 and get a total of 4,679 EFT
data with judgments and detailed explanations.
Finally we split the whole dataset into 4,167
samples as the training set and 500 samples
as the test set. The instruction format for step-
wise pairwise LLM-as-a-Judge is presented in
Figure 5, which is following the basic format
of Zheng et al. (2023).
And for mathematical task evaluation, fol-
lowing Yang et al. (2024b), we evaluate the
LLMs’ mathematical capabilities across some rep-
resentative benchmarks. We choose the widely
used benchmarks GSM8k (Cobbe et al., 2021)
and MATH (Hendrycks et al., 2021). We also
choose some complex and challenging competi-
tion benchmarks, including Gaokao2023En (Liao
et al., 2024), Olympiadbench (He et al., 2024),
AIME20242, and AMC20233.
Evaluation Metrics
We use accuracy as the eval-
uation metric for both the mathematical perfor-
mance and LLM-as-a-Judge quality. For accuracy
2https://huggingface.co/datasets/AI-MO/
aimo-validation-aime
3https://huggingface.co/datasets/AI-MO/
aimo-validation-amc
5

Model
GSM8k
MATH
Gaokao2023En
OlympiadBench
AIME2024
AMC2023
Avg.
GPT-4o
92.9
76.6
67.5
43.3
10.0
47.5
56.3
7B Base Model
M0
70.1
51.7
51.2
21.3
0.0
22.5
36.1
SRLM - M1
88.2
69.0
61.6
37.6
10.0
45.0
51.9
M2
87.6
69.4
63.9
37.2
3.3
40.0
50.2
M3
88.5
70.0
61.3
36.7
10.0
40.0
51.1
M4
88.3
70.2
