that can only regulate the overall length of the rea-
soning process using prompt words, ∆θ provides
finer granularity control. ∆θ is served in the exter-
nal parameter space. This allows for greater flexi-
bility in adjusting the reasoning trajectory. Specif-
ically, it facilitates the selective retention of long-
chain reasoning in certain thoughts while apply-
ing stronger compression to simpler reasoning seg-
ments. As a result, reductions in chain length can
be localized to specific portions of the inference
process rather than being uniformly applied across
the entire reasoning path. We remain the design of
this segment selection in future work.
3.2
Construct the MixChain Dataset
A crucial thing for the above process is the construc-
tion of the training dataset, especially the reason-
ing chain {ti}n
i=1. To have reasoning chains with
different lengths, previous approaches rely on mul-
tiple rounds of sampling, selecting reasoning paths
under different random seeds, or using some hand-
crafted way to remove parts of the answer (Chen
et al., 2024).
We introduce MixChain, a dataset inherently
generated by our method that contains reasoning
paths of varying lengths. This dataset is structured
such that each question is associated with multi-
ple reasoning paths, with lengths progressively de-
creasing from long to short. By simply adjusting
the parameter α, our approach avoids the need for
repeated sampling and achieves this diverse set of
reasoning paths. In contrast to multi-sampling tech-
niques, MixChain enables a more reliable and con-
sistent generation of shorter reasoning paths while
simultaneously capturing a spectrum of reasoning
lengths. To construct MixChain, we consider two
possible scenarios:
• If a well-annotated dataset with human-
labeled
solutions
is
available,
such
as
GSM8K
(Cobbe
et
al.,
2021b)
or
PRM800k (Lightman et al., 2024), it can
be leveraged to fine-tune the model for
generating shorter reasoning chains as a cold
start (θ1 →˜θ1 and θ2 →˜θ2 in Figure 2).
• In the absence of a dataset containing ex-
plicit reasoning paths, or when only final an-
swers are available without full explanations,
training solely on final answers is unlikely
to enable the model to generate reasoning
steps. To address this limitation, we propose
an alternative method for constructing Mix-
Chain. Specifically, we leverage an existing
base LLM (e.g., LLaMA-3.1-8B or Qwen-
32B-Instruct) as θ1 and use its corresponding
reasoning model (e.g., DeepSeek-R1-Distill-
Llama-8B or QwQ-Preview) to derive ∆θ.
4

The parameter update between these models
serves as a form of linear interpolation, en-
abling the transition from θ1 to θ2. This tran-
sition is then used to construct the dataset, as
illustrated in Figure 2, where the parameter
shift is represented by θ1 →θ2.
3.3
Improved Tuning for CoT-Valve
In this section, we present two enhanced variants
of CoT-Valve: one aimed at achieving improved
controllability and the other focused on optimizing
the compression ratio of the reasoning paths.
A More Precise CoT-Valve Paradigm: CoT-
Valve++.
In the previously proposed CoT-Valve
framework, the training process only constrained
∆θ to satisfy the final objective with α = 1. How-
ever, during inference, we expect all positions
along this direction to exhibit reasoning trajectories
of varying lengths. This leads to the inconsistency
between training and inference. With MixChain,
we can explicitly incorporate this requirement dur-
ing training by introducing an additional constraint,
ensuring that the model can adapt to reasoning
chains of different lengths across all positions in
this direction. For each training sample, in addition
to the question, answer, and solution, we have in-
troduced a normalized term β, which represents the
factor for the length of the reasoning path. Under
this dataset, our training objective is modified to
find a parameter update ∆θ′ such that it satisfies:
