Choi, and Xiang Ren. 2023. Are machine rationales
(not) useful to humans? measuring and improving
human utility of free-text rationales. arXiv preprint
arXiv:2305.07095.
Yu Kang, Xianghui Sun, Liangyu Chen, and Wei Zou.
2024. C3ot: Generating shorter chain-of-thought
without compromising effectiveness.
Preprint,
arXiv:2412.11664.
Levente Kocsis and Csaba Szepesvari. 2006. Bandit
based monte-carlo planning. In European Confer-
ence on Machine Learning.
Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harri-
son Edwards, Bowen Baker, Teddy Lee, Jan Leike,
John Schulman, Ilya Sutskever, and Karl Cobbe.
2024. Letâ€™s verify step by step. In The Twelfth Inter-
national Conference on Learning Representations.
9

Shih-Yang Liu, Chien-Yi Wang, Hongxu Yin, Pavlo
Molchanov, Yu-Chiang Frank Wang, Kwang-Ting
Cheng, and Min-Hung Chen. 2024a. Dora: Weight-
decomposed low-rank adaptation. In ICML.
Tengxiao Liu, Qipeng Guo, Xiangkun Hu, Cheng Ji-
ayang, Yue Zhang, Xipeng Qiu, and Zheng Zhang.
2024b. Can language models learn to skip steps?
In The Thirty-eighth Annual Conference on Neural
Information Processing Systems.
Haotian Luo, Li Shen, Haiying He, Yibo Wang, Shi-
wei Liu, Wei Li, Naiqiang Tan, Xiaochun Cao,
and Dacheng Tao. 2025a.
O1-pruner:
Length-
harmonizing fine-tuning for o1-like reasoning prun-
ing. arXiv preprint arXiv:2501.12570.
Liangchen Luo, Yinxiao Liu, Rosanne Liu, Samrat
Phatale, Meiqi Guo, Harsh Lara, Yunxuan Li, Lei
Shu, Lei Meng, Jiao Sun, and Abhinav Rastogi.
2025b. Improve mathematical reasoning in language
models with automated process supervision.
Nanye Ma, Shangyuan Tong, Haolin Jia, Hexiang Hu,
Yu-Chuan Su, Mingda Zhang, Xuan Yang, Yan-
dong Li, Tommi Jaakkola, Xuhui Jia, and Sain-
ing Xie. 2025. Inference-time scaling for diffusion
models beyond scaling denoising steps. Preprint,
arXiv:2501.09732.
Yu Meng, Mengzhou Xia, and Danqi Chen. 2024.
Simpo:
Simple preference optimization with a
reference-free reward. In Advances in Neural In-
formation Processing Systems (NeurIPS).
Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo
Aila, and Jan Kautz. 2016. Pruning convolutional
neural networks for resource efficient inference.
arXiv preprint arXiv:1611.06440.
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
Ouyang Long, Christina Kim, Christopher Hesse,
Shantanu Jain, Vineet Kosaraju, William Saunders,
Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen
Krueger, Kevin Button, Matthew Knight, Benjamin
Chess, and John Schulman. 2021. Webgpt: Browser-
assisted question-answering with human feedback.
ArXiv, abs/2112.09332.
Hao Shao, Shengju Qian, Han Xiao, Guanglu Song,
Zhuofan Zong, Letian Wang, Yu Liu, and Hongsheng
Li. 2024. Visual cot: Unleashing chain-of-thought
reasoning in multi-modal language models. Preprint,
arXiv:2403.16999.
Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez,
Dongwei Jiang, Manya Wadhwa, Prasann Singhal,
Xinyu Zhao, Xi Ye, Kyle Mahowald, and Greg Dur-
rett. 2024. To cot or not to cot? chain-of-thought
helps mainly on math and symbolic reasoning. arXiv
preprint arXiv:2409.12183.
Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-
Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan
Schalkwyk, Andrew M Dai, Anja Hauth, Katie
Millican, et al. 2023.
Gemini:
a family of
highly capable multimodal models. arXiv preprint
arXiv:2312.11805.
Kimi Team, Angang Du, Bofei Gao, Bowei Xing,
Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun
Xiao, Chenzhuang Du, Chonghua Liao, et al. 2025.
Kimi k1. 5: Scaling reinforcement learning with llms.
arXiv preprint arXiv:2501.12599.
Qwen Team. 2024a. Qwen2.5: A party of foundation
models.
Qwen Team. 2024b. Qwq: Reflect deeply on the bound-
aries of the unknown.
Jean-Francois Ton, Muhammad Faaiz Taufiq, and
Yang Liu. 2024. Understanding chain-of-thought
in llms through information theory.
Preprint,
arXiv:2411.11984.
Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai
Dai, Yifei Li, Deli Chen, Yu Wu, and Zhifang Sui.
2024. Math-shepherd: Verify and reinforce LLMs
step-by-step without human annotations. In Proceed-
