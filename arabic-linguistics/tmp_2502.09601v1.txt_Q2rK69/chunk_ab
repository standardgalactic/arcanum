to
the
market
with
€100.
He buys a roast for
€17 and vegetables
for €11. How much
money does he have
left?
1. John starts with €100. 2. He buys a roast for €17: €100 - €17 = €83 remaining
3. Then he buys vegetables for €11:\n
€83 - €11 = €72 remaining So, after his
purchases, John has €72 left.
John starts with €100. He makes two purchases: a roast for €17 and vegetables for
€11. To find out how much money he has left, we need to subtract the total
amount he spent from his initial amount. First, <Omitted>Yes, that seems correct.
John has €72 remaining.
Medium CoT
Short CoT
#Token: 85
#Token: 232
#Token: 449
Long CoT (QwQ-32B-Preview)
So John goes to the market with €100. That‘s his starting amount. Then he buys 
a roast for €17 and vegetables for €11. I need to find out how much money he 
has left after these purchases. Alright, first, I should figure out the total amount 
he spent. He bought a roast for €17 and vegetables for €11. So, the total 
expenditure is €17 plus €11. Let’s add those up. 17 plus 11 is 28. So, he spent a 
total of €28. Now, he started with €100, and he spent €28. <Omitted> Yes, that 
seems straightforward. I don’t think there‘s any trick here or additional steps I 
need to consider. So, the final answer is €72.
#Token: 833
Extrapolation to Unseen Length
CoT Valve
Long
Short
Figure 1: The reasoning model, after the length-compressible CoT tuning, can generate reasoning paths from long
to short, leveraging LoRA as a ‘Valve’. We show one example from our constructed dataset MixChain.
pable of generating both long and short reasoning
paths, rather than being restricted to a compressed
form. We offer a new way to control the length of
CoT, which we refer to as Length-Compressible
Chain-of-Thought Tuning.
A central component of the proposed method
is to identify an update direction in the parame-
ter space, which, by manipulating it, acts as in-
creasing or decreasing the length of CoT. Taking
a large step in this direction leads the model to
generate a short sequence, while a small step still
produces a long and complex reasoning trajectory.
We choose to incorporate this update direction by
LoRA (Hu et al., 2022), enabling it to function
as an additional branch that facilitates easy mod-
ulation of intensity while imposing minimal extra
parameters on the model. We explore methods
to identify this direction and demonstrate that it
offers superior controllability compared to prompt-
based approaches, which enables the generation of
short CoT that prompt-based methods are unable to
achieve. Besides, we observe that the direction can
be extrapolated, allowing the reasoning chains to
be extended beyond or shortened to lengths unseen
in the training set. Leveraging this compressibil-
ity, we construct a dataset that pairs long and short
reasoning chains for each question. This dataset is
then utilized in two ways: (1) to refine the direction
for more precise tuning, and (2) to progressively
compress the reasoning path.
We evaluate our method across different types
of models, ranging from a pre-trained LLM
with little reasoning ability, LLaMA-3.1-8B and
LLaMA-3.2-1.5B-Instruct (Dubey et al., 2024),
to post-trained reasoning models, QwQ-32B-
Preview (Team, 2024b), and distilled reasoning
models, DeepSeek-R1 (DeepSeek-AI, 2025). Our
results demonstrate that, with training for one time,
our approach enables a model to generate reasoning
paths of varying lengths, and we can achieve better
results than previous chain compression baselines.
Besides, our study highlights several interesting
findings: (1) Short reasoning paths can sometimes
outperform longer ones, underscoring the signifi-
cance of CoT-Valve in enhancing model efficiency.
(2) Not every reasoning chain, despite all leading
to the correct final answer, is conducive to model
optimization. Excessively long or short chains com-
plicate the distillation of CoT, posing challenges to
the model training.
In summary, our contributions are: (1) CoT-
Valve: Enables elastic control of length for CoT
within the parameter space, allowing a single model
to generate CoT from short to long. (2) MixChain
Dataset: A dataset with reasoning paths of varying
lengths for each question. (3) Improved Tuning &
Progressive Compression: Refines the direction-
tuning process based on MixChain and introduces
progressive compression for inference efficiency.
(4) Performance & Controllability: Achieves
controllable reasoning generation and state-of-the-
