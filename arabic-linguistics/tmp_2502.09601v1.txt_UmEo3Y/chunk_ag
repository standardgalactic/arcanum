CoT­Valve
CoT­Valve (Extrapolation)
CoT­Valve++
CoT­Valve++ (Extrapolation)
QwQ­32B­Preview
CoT­Valve+P
(a) GSM8K, QwQ-32B-Preview
200.0
300.0
400.0
500.0
600.0
700.0
#Token
46
48
50
52
54
56
58
Accuracy
Prompt
CoT­Valve ­ QwQ Distill
CoT­Valve ­ MixChain­Z ­ Solution 1 
LLaMA­3.2­1B­Instruct(0­shot) 
CoT­Valve+P ­ MixChain­Z
(b) GSM8K, Llama-3.2-1B-Instruct
2000.0
4000.0
6000.0
8000.0 10000.0 12000.0
#Token
0.10
0.15
0.20
0.25
0.30
0.35
0.40
0.45
0.50
Accuracy
Qwen2.5­32B­Instruct
Epoch 1
Epoch 2
Epoch 3
Epoch 4
Epoch 5
Epoch 6
CoT­Valve (Short­to­Long)
CoT­Valve (Long­to­Short)
MixChain ­ Solution 1
CoT­Valve (Long­to­Short) 
 MixChain ­ Solution 2
SFT Training Dynamics
(c) AIME, Qwen2.5-32B-I w/ LIMO
Figure 3: Token length and accuracy for different methods, datasets and reasoning models. Points connected by
curves in (a) and (b) represent results from one model.
Training and Evaluation.
For training the
model, we use LoRA (Hu et al., 2022) in most
of our experiments, except in the experiment for
LIMO on Qwen-2.5-32B-Instruct we use full pa-
rameter fine-tuning. We also show the results using
DoRA (Liu et al., 2024a) in the Appendix. The
hyper-parameters for each experiment are shown in
Appendix A. We select two math datasets to eval-
uate the performance, for one easy math dataset,
GSM8K (Cobbe et al., 2021b) and one hard math
dataset, AIME24.
4.2
Datasets
We find in our experiments that the quality of the
solution is important to the performance, even if all
the human-annotated solutions or synthesized so-
lutions reach the final answer. In our experiments,
we use the question from the train set of GSM8K,
the math split of PRM800K or the question from
LIMO, and we employ three types of datasets with
those questions in our experiments:
• Ground-truth Dataset: The dataset provides a
human-annotated or model-synthesized solu-
tion. We use this as the cold start.
• MixChain from cold-start (MixChain-C): Af-
ter taking the ground-truth dataset to train the
model, we can get the first model to generate
solutions from short to long. Then we use it
to generate the dataset.
• MixChain from zero-shot (MixChain-Z): We
employ CoT-Valve between a reasoning
model (θ2) and a base LLM (θ1) to generate
the solutions.
For each dataset, we filter out all the solutions with
incorrect answers. We show the statistics of the
dataset in Table 9 in the Appendix.
Method
Accuracy
#Token
ACU ↑
