19 Fédération Internationale des Échecs (World Chess Federation). 

human experts provided optional commentary about the merits and issues pertaining to each composition and 
this is provided in Appendix E.  
 
In general, the experts were of the opinion that the compositions they were given were of low quality or too 
easy. This is to be expected given the filter of just one composition convention (see section 4.2) and possibly 
because the automatic composer ‘reduces’ each problem to be as economical as possible (see Appendix A). 
Imposing all five composition conventions using CHESTHETICA would have taken far too long for our 
experimental purposes. One expert – the master solver and composer – suspected all the compositions were 
generated by computer but then went on to choose 16 instead of 15 that he thought were composed by a human. 
The female grandmaster selected 27 instead of just 15 whereas the FIDE master kept to the instructed 15. This 
alone suggests that the compositions generated, by expert opinion, were more human-like than to be expected; 
especially given that they were indeed all generated by computer using the DSNS approach. In fact, the experts 
did tend to have nicer things to say about the ones they thought were composed by a human (see Appendix E).  
 
The average expert score for the 90 compositions they evaluated were assessed based on the original three 
source sets (which the experts had no idea about), i.e. Comp3.5, TG1500p and TG2500p. An ANOVA test 
showed no statistically significant difference between the means (i.e. 0.847, 0.722 and 0.776, respectively). This 
was on a scale of 0.0 to 5.0. The result could have been due to the small sample sizes and the overall difficulty 
of the task in discerning between many compositions that may appear quite similar in quality, if not form as 
well. There was also no statistically significant (Pearson) correlation between any two of the human expert 
evaluations. This was not entirely unexpected as humans tend to factor in personal tastes and biases often 
without realizing it (Iqbal, 2014a). 
 
The same sets were tested using CHESTHETICA and an ANOVA test showed a statistically significant 
difference between the means (i.e. 2.678, 2.538 and 2.343, respectively): F (2, 87) = 6.154, p = 0.0032. So the 
human experts were unable to discern between the groups based on their average aesthetics ratings but the 
computer program seemed to think that Comp3.5, given this subset of 30 compositions, produced the highest 
quality chess problems compared to TG1500p and TG2500p, with the former doing better than the latter. This 
contradicts the means for these groups (i.e. 2.438, 2.449 and 2.137, respectively) shown in Tables 5 and 7 which 
had larger sample sizes because an ANOVA test showed the differences in means here to be significant as well: 
F (2, 214) = 12.358, p = 8.3E-06. Here, TG1500p is slightly better than Comp3.5, and TG2500p is the worst of 
the lot. 
 
The deciding factor, we thought, must reside in subtle form somewhere in the ‘undecided’ human expert 
aesthetic evaluations. Looking back at them, the suggestive answer was actually in their selections of the 
compositions thought to have been composed by a human (which also tended to receive the most favorable 
comments). Considering only the compositions where two or more experts agreed – classified in terms of the 
sources used to produce them – the experts’ selections tended to agree with CHESTHETICA’s assessment just 
mentioned. See Table 14.  
  
# 
Experts Agreed 
Source 
24 
2/3 
Comp3.5 
44 
2/3 
TG1500 + photo 
55 
2/3 
TG2500 + photo 
62 
2/3 
TG1500 + photo 
63 
2/3 
TG1500 + photo 
66 
2/3 
Comp3.5 
81 
3/3 
Comp3.5 
88 
2/3 
TG1500 + photo 
  
Table 14:  Expert agreement on the computer compositions thought to be human compositions. 
 
The final standings of the compositions thought to have been composed by a human when tallied in terms of the 
number of experts (in cases where the majority agreed) stood at: TG1500p (8), Comp3.5 (7), TG2500p (2). This 
correlates perfectly with the order of CHESTHETICA’s assessment of the mean aesthetics scores earlier using 
all available compositions for these sets, i.e. 2.449, 2.438 and 2.137, respectively. There was absolutely no way 
the experts could have known the compositions they were selecting favorably had come from these particular 
source sets. The rough probability of any two experts agreeing with each other that any particular composition 
was composed by a human = [[(15+16+27)/3]/90]2 x 100 = 4.61%. The rough probability of all three experts 
agreeing with each other on a particular composition is 0.99%. Figure 7 shows two of the DSNS-generated 

compositions the majority of experts agreed upon were composed by a human being. The solutions are in 
Appendix C. 
 
XABCDEFGHY 
8-+-+-sN-+( 
7+-+-+-tR-' 
6-+-+-mk-sN& 
5+-+Pzp-+-% 
4-+-+-+-+$ 
3+-+-+-+-# 
2-mK-+-+-+" 
1+-+-+-+-! 
xabcdefghy 
#63 
XABCDEFGHY 
8-+K+-+-+( 
7mk-+-sN-+-' 
6-+-+-+-+& 
5+L+-+-+-% 
