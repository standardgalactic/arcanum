DSNS: 
TG1600p1K 
Experience 
Table 
DSNS: 
TG1500p1K 
Experience 
Table 
Mean 
Aesthetics 
Score 
2.194 
2.218 
2.285 
2.257 
2.316 
2.240 
Mean 
Efficiency 
(cph) 
4.709 
4.119 
0.799 
0.993 
0.555 
0.667 
 
Table 15:  Comparison of the DSNS against the state-of-the-art ‘experience table’ approach. 
 
For no conventions, we used the TTEV test (see section 4.4) because the sample sizes were too large but for the 
rest we used the Mann-Whitney U test (two-tailed, 5% significance level) to compare the means, which is 
suitable if the sample sizes are smaller, i.e. typically below 200. There was no statistically significant difference 
between any of the three paired sets (in terms of both aesthetics and efficiency) except in the case of the mean 
aesthetics scores when applying three conventions (U-value = 7382.5, Z-score = -2.1385, n1 = 121, n2 = 144, P 
= 0.03236). This suggests that, under stricter composing conditions, the DSNS approach outperforms the 
experience table approach by producing compositions that, on average, rank higher aesthetically. Furthermore, 
the composing rate is still statistically equivalent. Under less strict composing conditions, there is no difference 
between the two approaches. Even then, it still leaves something to be said about the DSNS considering that the 
experience table approach uses tens of thousands of published compositions by human composers as a source 
whereas the DSNS uses sequences from games between weak players and the entirely unrelated domain of 
photographs of people.     

4.9 
Human vs. Computer Composition 
 
For the interested reader, in terms of mean aesthetics (as assesed by the aesthetics model and perceived by the 
majority of domain-competent human players), there was no statistically significant difference between the 69 
compositions created using the TG1500p DSNS approach (2.449) and 69 randomly-selected compositions by 
human experts from the The Meson Chess Problem Database (2.300) explained in section 4.3; TTEV test. There 
was, however, a statistically significant difference between the average number of variations where TG1500p 
had 44.2 variations on average and the Meson sample 143.1 on average; TTUV test: t(93) = 2.937, P = 0.00418 . 
Again, it is important to note that chess problems have various types (e.g. three-movers, endgame studies, 
constructs) and different requirements which go beyond the common ground of aesthetics assessed by the 
aesthetics model.  
 
For instance, compositions by humans tend to feature more variations by design and there is insufficient 
evidence that simply having more variations leads to improved aesthetics. Likewise, a complex yet award-
winning problem may be difficult for the majority of chess players to perceive as beautiful whereas an 
unexpected yet direct tactical checkmate (e.g. from a famous tournament game or construct) might be easier to 
fathom and more appealing to them. So the comparison between the TG1500p and Meson Database samples 
suggest that, on average, aesthetically, at least, the computer-generated compositions are comparable to (but not 
better than) those created by human experts. A growing collection of computer-generated chess problems 
composed using the DSNS approach is available online20 for interested readers. In addition to being appreciated 
aesthetically, they can also be used by players of all levels as puzzles to train and improve their game. 
Additionally, between 5 January and 19 February 2015, for instance, 1,263 three-movers were composed in total 
using anywhere between one and nine different instances of CHESTHETICA and no repetitions were detected.                 
 
 
5 
CONSOLIDATION OF RESULTS  
 
Bringing all of the experimental data of this research together, we present the following findings regarding the 
DSNS approach, including some extended findings. 
 
DSNS 
 
1. Computer processing power and memory do not have a significant effect on the composing efficiency. 
2. Given the use of just a single domain, the DSNS approach produces higher quality output compared to 
a completely random approach regardless of the quality of that DSNS source. 
3. Given the use of just a single domain, a higher quality source results in higher quality output. 
4. Given the use of just a single domain of high quality, combining with another unrelated domain has a 
negative effect on the quality of the output. 
5. Given the use of just a single domain of ‘moderate’ quality (e.g. TG2500) – considering all chess 
samples used – combining with another unrelated domain improves the quality of the output in some 
cases but has a negative effect in other cases. 
6. Given the use of just a single domain of low quality (preferably lowest quality, e.g. TG1500), 
combining with another unrelated domain improves the quality of the output in all cases. 
7. Given the use of just a single domain of low quality (i.e. TG1500), combining with actual photographs 
of people produces higher quality output than garbage photo data and not using photos at all. 
8. Given the use of just a single domain of high quality, using more objects or more attributes has a 
positive effect on the quality of the output. 
9. Given the use of just a single domain of low quality, using more objects or more attributes has no effect 
on the quality of the output. 
10. For TG1500p (low quality chess domain used in combination with photo domain), increasing the 
number of objects for both improves the quality of the output. Reducing the number of photos alone 
has a negative effect. Reducing the number of attributes of both has no effect. 
11. Overall, taking into account composing efficiency and quality using different machines, TG1500p 
outperforms Comp3.5. 
12. The DSNS also outperforms the present state-of-the-art composing approach (i.e. the ‘experience 
table’) in terms of average aesthetic quality of compositions generated under stricter composing 
