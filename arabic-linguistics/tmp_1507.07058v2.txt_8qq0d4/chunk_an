Table 11:  Mean aesthetics scores and variations for the compositions generated  
(two domains, variable objects). 
 
 
TG1500p 
300 games 
300 photos  
10 attributes 
TG1500p 
300 games 
300 photos  
5 attributes 
Aesthetics Score 
2.449 
2.355 
Variations 
44.2 
25 
 
Table 12:  Mean aesthetics scores and variations for the compositions generated 
(two domains, variable attributes). 
 
For TG1500p (300 games, 300 photos, 10 attributes) against TG1500p (150 games, 150 photos, 10 attributes), 
the difference between the mean aesthetics scores based on a TTEV test was statistically significant: t(153) = 
3.779, P = 0.0001. For TG1500p (300 games, 300 photos, 10 attributes) against TG1500p (150 games, 300 
photos, 10 attributes), the difference between the mean aesthetics scores based on the same test was not 
statistically significant. For TG1500p (300 games, 300 photos, 10 attributes) against TG1500p (300 games, 150 
photos, 10 attributes), the difference between the mean aesthetics scores based on the same test was statistically 

significant: t(204) = 2.219, P = 0.0276. So using more objects for both sources given these two source domains 
improves the quality of the compositions generated. This is consistent with the previous finding when using only 
a high quality chess source (Comp3.5, Table 9). However, for TG1500p sources, reducing just the number of 
games does not make a difference; but reducing the number of photos, interestingly, does. There were no 
differences of statistical significance across these four sets between the average number of variations based on 
an ANOVA test.      
 
For TG1500p (300 games, 300 photos, 10 attributes) against TG1500p (300 games, 300 photos, 5 attributes), the 
difference between the mean aesthetics scores based on a TTUV test was not statistically significant. This 
suggests that, given these two source domains, using more attributes makes no difference. This is somewhat 
consistent with the previous finding when using only a low quality chess source (TG1500, Table 10), in that an 
increase in the number of attributes used does not make a difference, regardless of the inclusion of photos as a 
source. There were no differences of statistical significance between the average number of variations based on 
a TTUV test. 
 
4.6 
The Fourth Experiment: Human Expert Assessment 
 
As explained in section 4.2, enlisting the help of human experts to evaluate aesthetics in this research would 
have its share of problems. Fatigue, imprecision and inconsistency are hallmarks of the human condition 
especially when it comes to typically subjective issues such as aesthetics. Nonetheless, if the amount of work 
required can be kept manageable and interesting for the experts, it is still useful to see what their evaluations 
might be like. So in the fourth experiment, we used the compositions generated using three approaches, i.e. 
TG1500p, TG2500 + photo (TG2500p for brevity) and Comp3.5 (see Tables 4 and 6). The following positions 
(see Table 13) were excluded from the compositions generated in all the sets because they are too simplistic and 
common to retain the attention of the human experts. K = King, Q = Queen, R = Rook, P = Pawn. A digit before 
the alphabet indicates the piece count. 
 
K, Q vs K 
K, Q vs K, P 
K, Q, P vs K 
K, Q, P vs K, P 
K, Q, R vs K 
K, Q, R vs K, P 
K, R vs K 
K, R vs K, P 
K, R, P vs K 
K, R, P vs K, P 
 
K, 2R vs K 
K, 2R vs K, P 
K, 2R, P vs K 
K, 2R, P vs K, P 
 
 
Table 13:  Composition types that were excluded for the benefit of the human experts. 
 
From the remainder, the top 30 from each set based on their aesthetics scores were chosen, and these randomly 
mixed together into a PGN (Portable Game Notation) file or database of 90 compositions. These DSNS-
generated compositions and their solutions are provided in Appendix C. All identifying information was also 
removed from each composition in the file so the human experts would not know which set they came from, or 
even if they were composed by a human or computer. For a balanced view of aesthetics in the game, the human 
experts chosen were co-authors Matej Guid (FIDE19 Master), Jana Krivec (Woman Grandmaster) and Vlaicu 
Crisan (International Master of Chess Solving and FIDE Master of Composition). Together they represent more 
or less the spectrum of expertise pertaining to the game of chess and where aesthetics in the game has been 
recognized, i.e. over the board and also in the domain of composing chess problems. They were considered 
sufficiently ‘domain competent’ with regard to the game. All the experts were completely unaware of the details 
of this fourth experiment until it was completed.  
 
The human experts were asked to rate the 90 compositions on a scale of 0.0 to 5.0 (one precision point) “based 
on their individual expertise and perception of beauty/aesthetics in the game”. This would also mean that some 
compositions would have to have the same rating based on human perception, which is acceptable. A larger 
scale of say, 0 to 10 was not used because this has already been attempted in previous research work related to 
the aesthetics model (Iqbal, 2008; Iqbal et al., 2012) and we wanted to try something different. Comments for 
each composition were optional. After rating the 90 compositions, the experts were asked to then choose 15 
from the 90 that were “most likely to have been composed by a human being”. The relevance of this second part 
will become evident later. The PGN file and Microsoft Excel evaluation sheet were e-mailed to the experts 
independently and they were asked to respond within two weeks. One expert took slightly longer due to other 
commitments. This is understandable given the complexity of having to (comparatively) rate 90 compositions 
on a discrete scale based on the subjective aspect of beauty. Their ratings are shown in Appendix D. Two of the 
                                                 
