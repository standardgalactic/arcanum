Notice that the first order term vanishes because ˆθ is a local optimum of log p(X | θ), and in the
second order term, −NJ(ˆθ) is the Hessian matrix of the likelihood function log p(X | θ) evaluated
10

at ˆθ. At the MLE, J(ˆθ) ⪰0, while in general the Hessian of the loss of a DNN evaluated at θ ̸= ˆθ
can have a negative spectrum [2, 61].
Through a change of variable ϕ :=
√
N(θ −ˆθ), the density of ϕ is p(ϕ) =
1
√
N p( ϕ
√
N + ˆθ) so
that
R
M p(ϕ)dϕ = 1. In the integration in eq. (10), the term −N
2 (θ −ˆθ)⊺J(ˆθ)(θ −ˆθ) has an
order of O(∥ϕ∥2). The cubic remainder term has an order of O(
1
√
N ∥ϕ∥3). If N is sufficiently
large, this remainder can be ignored. Therefore we can write
−log p(X) ≈−log p(X | ˆθ) −log Ep exp

−N
2 (θ −ˆθ)⊺J(ˆθ)(θ −ˆθ)

.
(11)
On the RHS, the first term measures the error of the model w.r.t. the observed data X. The
second term measures the model complexity. We have the following bound.
Proposition 3.
0 ≤−log Ep exp

−N
2 (θ −ˆθ)⊺J(ˆθ)(θ −ˆθ)

≤N
2 tr

J(ˆθ)

(µ(θ) −ˆθ)(µ(θ) −ˆθ)⊺+ cov(θ)

,
where µ(θ) and cov(θ) denote the mean and covariance matrix of the prior p(θ), respectively.
Therefore the complexity is always non-negative and its scale is bounded by the prior p(θ).
The model has low complexity when ˆθ is close to the mean of p(θ) and/or when the variance of
p(θ) is small.
Consider the prior p(θ) = κ(θ)/
R
M κ(θ)dθ, where κ(θ) > 0 is a positive measure on M so
that 0 <
R
M κ(θ)dθ < ∞. Based on the above approximation of −log p(X), we arrive at a
general formula
O := −log p(X | ˆθ) + log
Z
M
κ(θ)dθ
−log
Z
M
κ(θ) exp

−N
2 (θ −ˆθ)⊺J(ˆθ)(θ −ˆθ)

dθ,
(12)
where “O” stands for Occam’s razor. Compared with previous formulations of MDL [7, 59, 60],
eq. (12) relies on a quadratic approximation of the log-likelihood function and can be instantiated
based on different assumptions of κ(θ).
Informally, the term
R
M κ(θ)dθ gives the total capacity of models in M specified by the
improper prior κ(θ), up to constant scaling. For example, if κ(θ) is uniform on a subregion in
M, then
R
M κ(θ)dθ corresponds to the size of this region w.r.t. the base measure dθ. The term
R
M κ(θ) exp

−N
2 (θ −ˆθ)⊺J(ˆθ)(θ −ˆθ)

dθ gives the model capacity specified by the posterior
p(θ | X) ∝p(θ)p(X | θ) ∝κ(θ) exp

−N
2 (θ −ˆθ)⊺J(ˆθ)(θ −ˆθ)

.
It shrinks to zero when the
number N of observations increases. The last two terms in eq. (12) is the log-ratio between the
model capacity w.r.t. the prior and the capacity w.r.t. the posterior. A large log-ratio means
there are many distributions on M which have a relatively large value of κ(θ) but a small
value of κ(θ) exp

