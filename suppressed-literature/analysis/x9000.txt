figure out how to weaponize Facebook. (And yes, I know the phrase
“Buddhist monk” conjures something very different from “terrorist” for
most people, but members of the Buddhist majority in Myanmar have
persecuted Rohingya Muslims for decades.)
I get an email telling me the junta wants us to remove Wirathu’s posts
about this alleged rape. Because they’re causing real-world violence—riots
are ongoing, Buddhist mobs are attacking Muslim shops, people are dying
—the posts seem like a clear violation of our standards. But the content
operations team—which is based in Dublin—doesn’t want to take down the
posts. The case officer tells me she doesn’t think they violate our rules, but

she can’t find anyone who speaks Burmese, and Google Translate doesn’t
do Burmese, so she can’t say for sure.
I pull in someone more senior, and he reaches out to that same
contractor they’d hired a few months before—a Burmese guy based in
Dublin—to review the material. Five hours pass.
“How long do you think this will take?” I ask. There are riots in the
streets over this. I really need these posts to come down.
“Unfortunately no idea,” the senior guy responds. “He’s offline, I have
pinged him on FB and hope he sees it and gets back to me.”
“Do you have a contact phone number for him?” I write. “This is an
emergency.”
The senior guy calls him. The Burmese contractor is at a restaurant and
I’m told he’ll go home and “should have access to a PC in fifteen minutes.”
He’ll comb through the posts to try to see what is being said, and if we
would action it or not. Nearly two hours pass, and the senior guy confesses
that the contractor does not have his work laptop and he himself is on the
road but he’ll get to it when he gets home later. I feel both responsible and
completely impotent.
“When will you be in a position to do this? We really need to move
quickly,” I urge.
After receiving no response, I find a way to get other people to take
down the posts from California, but to do that we need the senior guy to
send the links that have been reported. Finally he does, the three posts are
removed, and four minutes later we get notification that Facebook was
unblocked in Myanmar, despite the fact that it’s 4:30 A.M. there.
This cannot be the system Facebook relies on when people are dying. If
posts are causing riots in the streets, we can’t be depending on some
random contractor in Ireland who’s out to dinner and can’t find his laptop.
Based on this and the experience over the last few months, I suggest to
both leadership and the content teams that we need to rethink how to handle
Myanmar, and figure out what we did wrong and how we fix it. This does
not go over well. The head of the content team emails that her people “did
exactly what they were supposed to do. This content, on its face, did not
violate our policies.… Those 3 posts contained factual reports and calls to

political action—not hate speech.” I point out that this doesn’t matter under
our own guidelines, which state clearly that we remove content “when we
perceive a genuine risk of physical harm, or a direct threat to public safety.”
Triggering real-world violence like riots violates our rules. They think they
can ignore this because it’s happening in Myanmar, but as with the elections
of despots, if Facebook can enable it in one place, the pattern will surely
repeat unless it is actively prevented. This gets me nowhere. The head of
content policy doesn’t want to do more training, and doesn’t see anything
wrong with how this was handled. In fact, they want to send a “quick note
reassuring the CO [content operations] folks that they did the right thing
here.” They tell leadership,
“To be clear on CO’s responsibilities here  … [the] team did exactly
what they were supposed to do. This content, on its face, did not violate our
policies.”
I disagree. At this point in 2014, Myanmar is too explosive—grappling
with hate speech, fake news, and mob violence, struggling to become a
democracy—for us to treat it like any other country. Millions in Myanmar
think of Facebook as the internet, and we have only one person who speaks
Burmese in Facebook’s operations team. That’s it. One person. Compared
with the hundreds for China. One man in Dublin, who isn’t even on staff, to
resolve all of the hate speech roiling Myanmar.
The note thanking the content operations team for how they handled this
gets sent anyway.
So even though the content operations team doesn’t want to figure out
what’s going on with reported content in Myanmar, at least my team and I
can try. Within weeks, we learn just how crudely Facebook is functioning in
Myanmar. For example, we’ve never posted our Community Standards in
Burmese, so it would be impossible for anyone to know what’s allowed and
what isn’t. Basic architecture of the site—the like button and most
importantly the reporting button that you’d use to alert Facebook to
problematic content—is not in Burmese (or shows up as corrupted
characters). And—biggest and most surprising of all—Facebook is
incompatible with the Burmese language. Facebook’s site could be
translated into Burmese at any point. It’s just … not a priority.

In addition to all this, Myanmar is one of the few countries that doesn’t
run on Unicode. This Unicode is the universal standard for encoding text on
computers. As a result, if you’re in Myanmar, you can type posts in
Facebook and read them as recognizable Burmese characters. But for
anyone outside Myanmar, the letters are just an unreadable jumble.
How do you moderate the content when you can’t read it? We go to the
head of internationalization at Facebook, who tells us that she and
engineering are very aware of this problem with Burmese, and it’s
eminently solvable. In fact, she’d tried to address it a year before this, but
nobody would listen. She just needs someone to prioritize it and assign
engineers. Myanmar is a huge potential market for Facebook, with over
sixty million people. A few weeks after the riot, I go to Elliot and Javi and
the head of content policy and others to plead my case. In the wake of the
riots, now we can see how deadly Facebook can be in Myanmar. We need to
do a better job monitoring hate speech on the platform. So we need
everything in Unicode. Nobody cares. I’m told, “I would love to prioritize
getting this done.… I just don’t think we can justify that given the other
things in our pipeline.” By contrast, there’s no problem spinning up huge
teams of expensive engineers to build a Facebook tool to facilitate Chinese
censorship.
This would become a consistent refrain whenever my team and I ask for
something for Myanmar.
Faced with the absurd situation that Facebook can’t actually post in
Burmese on its own platform, my team translates the Community Standards
and a tip sheet on how to report questionable content, and we print it as a
