the content we show not only responds to existing affinities but also
reinforces or shapes future affinities, potentially by clustering
people and cutting off some points from other points prematurely.…
We have been prematurely optimizing and we are driving towards a
local maxima and … what we have to do is relax the optimization a
bit. Take a hit on time spent and engagement and let things flow
with greater exploration.

Boz showed that Facebook’s senior management knew exactly what
Facebook was doing. Then he argued that Facebook should step back from
all this “optimizing and driving,” instead letting people have greater input
and more control over the content they see.
But nothing changed.
After the election, and with all the other problems coming to light, they
could’ve decided to genuinely clean things up. Instead they create some
window-dressing “fact checking partnerships” and, before long, some of the
main “partners,” Snopes and the Associated Press, pull out. “They’ve
essentially used us for crisis PR,” Brooke Binkowski, the former managing
editor of Snopes, tells the Guardian. “They’re not taking anything seriously.
They are more interested in making themselves look good and passing the
buck.… They clearly don’t care.” A different fact-checker who had long
worked for Facebook vents their frustration to the Guardian: “They are a
terrible company and, on a personal level, I don’t want to have anything to
do with them.”
Even the office feels different. One day there’s a commotion in the large
open space where the policy team works. I run over from my desk and see a
woman convulsing on the floor. She’s foaming at the mouth and her face is
bleeding. She must’ve hit something when she fell from her desk. And she’s
being completely ignored. She’s surrounded by desks and people at
computers and no one’s helping her. Everyone types busily on their
keyboards, pretending nothing is happening. She’s spasming violently,
bringing her dangerously close to mobile filing drawers with sharp metal
edges.
I and two members of the FFC who are both relatively new to the team
push aside the furniture and call 911 but can’t provide the basic information
the dispatcher needs. History of seizures? The woman’s age? Her name?
“Are you her manager?” I ask a woman at a nearby desk who seems to
be studiously concentrating on her computer, while a woman convulses in
pain at her feet.
“Yes. But I’m very busy,” she says brusquely.

“Are you serious? What’s her name? Does she have epilepsy? How can
we help her?”
The woman looks surprised. “She’s a contractor. I don’t have that sort of
information. Her contract’s coming to an end soon. I suggest you call HR.”
We do. They refer us to a company that manages contractors. The
representative for that company doesn’t pick up. The woman continues to
convulse.
This is not what it was like to work here when I began in 2011. There
was a boisterous, happy energy to the place. The idea that someone could
be in pain, writhing at your feet, and just be ignored, that was unthinkable.
The guys in the office could be obnoxious or fratty, but I never doubted that
they would’ve jumped in. They did have that much basic human decency.
But now everyone around me seems completely detached. Shut down.
Anxiously looking at their screens, eyes on the job. I don’t want that to
become who I am.

46
Myanmar
We’re not just treating each other badly in our own headquarters. We’re also
doing some real damage out in the world. And I’m failing when I try to get
the people in charge to care.
Take Myanmar. By now, it’s not that I expect anything good or
responsible from Facebook’s leadership. There was a time when I could
make that happen, but I know I can’t influence the things that matter now.
It’s hard for me to hold on to the difference between knowing when to
perservere and knowing when to quit. I keep telling myself I can do more to
change things inside than I can out. So I’m trying to work the rotten system
to achieve what little I can to make things better. In this case, I’m trying to
do something very simple. I want to hire a human rights expert to manage
Myanmar. But even this is not going well.
Myanmar exemplifies how damaging Facebook can be. But to
understand this and why I can’t hire someone to fix it we need to go back in
time. Since my visit to Myanmar four years ago, things have deteriorated
there. And Facebook has played a big role in this unraveling.
Myanmar is the one country where Mark’s dream for Internet.org kind
of came true. Since my time there in 2013, it went from having virtually no
internet to everyone on mobile, totally skipping desktops. And on mobile
phones, Facebook is the internet for nearly everyone. Facebook made deals
with the local telecoms to preload phones with Facebook, and in many
plans, time spent on Facebook wasn’t counted toward your minutes.

So in Myanmar, if you’re on the internet, you’re on Facebook, and
because of this, Myanmar demonstrates better than anywhere the havoc
Facebook can wreak when it’s truly ubiquitous. The best way I can describe
what’s happened there is a kind of lethal carelessness. At every turn, when
Facebook’s leaders see how Facebook is inflaming tensions and making an
unstable and frightening political situation much worse, they do … nothing.
We got our first real glimpse of how badly things can go in 2014, nearly
one year after I met with the junta. In April 2014 I and some others on the
policy team hear that there is virulent hate speech circulating in Myanmar.
Most of it is targeted at the country’s Muslim minority, the Rohingya. Mobs
are burning down mosques. We go to the content team that’s responsible for
removing hate speech and ask if there’s more we can do to address it, and
we’re told no. They’ve just hired a new Burmese contractor to manage this;
everything is fine. Facebook’s head of content policy says, “I can confirm
our Burmese rep has plenty of bandwidth.” We push for more details and
they provide a breakdown showing that they only have four or five reports
of hate speech in the queue, which is nothing.
A few months after this exchange with the content team, a riot is
triggered by a Facebook post and the junta blocks Facebook on July 4,
2014. The post claimed a Buddhist woman had been raped by a Muslim
man, a tea shop owner. Much later a UN report concludes that the story is
fabricated. But it went viral after it was shared by a Buddhist monk who’s
often described as the “Burmese Bin Laden,” Ashin Wirathu. Wirathu had
been jailed in the past for inciting religious hatred, and he was beginning to
