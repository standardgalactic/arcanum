handout. A leaflet. Like it’s the year 1776 and Thomas Paine has this great
commonsense idea about independence from Great Britain. That’s how
we’re going to get the word out. We go to the comms team to ask for their
help in getting this to people in Myanmar. We’re told no. “Myanmar isn’t a
priority country in SEA [Southeast Asia], which means we don’t have any
PR resources on the ground.”
And then, the kicker in June 2015: while trying to help groups and
activists report abusive content on Facebook, my team starts noticing that
users appear to be using unofficial Facebook apps that don’t offer a

reporting function. This is something that civil society had been trying to
tell us, but it seemed so preposterous that we didn’t believe them initially.
Then we learn that the official Facebook app is still unavailable for
download in Myanmar and, as a result, unofficial versions of the app get
shared through friends and at mobile shops. It seems impossible to report
the hate speech, racist posts, or content intended to trigger violence even if
they could solve the language and Unicode issues.
This explains why we’ve had a steady flow of complaints from the
junta, civil society, activists, and others all complaining about fake news,
hacked accounts, and racist, violent, threatening content on the site. They
said it’s impossible to report these posts, and in the few cases they managed
to get a report through, no one took action. They clicked on a button and
nothing happened. It also explains why the content team confidently
assured me throughout 2014 that users in Myanmar weren’t filing reports
about questionable content. Of course they weren’t filing reports. Of course
we took no action. Our users weren’t using apps capable of any of that.
As if that’s not troubling enough, a new problem emerges in May 2015.
By slowly piecing together the decisions being made by the now two
Burmese contractors who are doing all the content moderation in Dublin for
the content reports that manage to make it through all those issues, my team
and I start to suspect that one of them is allowing a lot of racist content onto
the site. He’s allowing a slur for Muslims that’s the equivalent of the N-
word—kalar—and defending its use, even in posts calling for people’s
blood. He’s removing more posts by civil society groups and peace activists
than government and anti-Muslim accounts. Worried he might be in cahoots
with the junta, we raise this with the content team, who tell us there’s
nothing to worry about.
We inform our bosses and plead with them to do something, anything,
to make the content team address it, but nothing comes of that. We ask them
to ban the word kalar, if they won’t deal with the moderator. They refuse.
(Years later, after untold harm, Facebook finally bans the slur.)
With few other options, my team sets up clandestine meetings with
nongovernmental organizations in Myanmar that track what’s posted on
Facebook, to gather information to make our arguments internally. It feels

weird and disloyal to collaborate with groups outside Facebook to solve an
issue within Facebook, but I don’t see what other choice we have. One of
the groups has been monitoring the posts and accounts Facebook takes
down, keeping records on big Excel spreadsheets, and it confirms that our
moderators are not removing racist and nationalist content that should come
down, and they’re taking down other content they shouldn’t.
We set up secret Facebook groups where civil society organizations can
communicate directly with us about whatever problems are not getting
addressed on the platform. They send us examples of posts where
government ministers spread hate speech and talk about how they’ll ensure
Muslims won’t be able to vote in the upcoming election. Or junta-backed
candidates encouraging their followers to burn a mosque to the ground.
This all heats up as Myanmar heads toward its first fully free, fully
contested election in decades, scheduled for November 2015, an election
where millions will be voting for the first time. A month before the election,
the civil society groups use the secret group to tell us that liberal candidates
opposing the junta have been removed from Facebook en masse. Their
accounts have been suspended in response to mass reports saying the
accounts are fake. Our platform is so dysfunctional in Burmese that there’s
no way to verify accounts. My team gets them reinstated.
At the same time, the junta starts to arrest civil society members for
their Facebook posts.
More than anything, it feels like we’re flying blind. This extremely
fragile country is heading into a contentious election while struggling with
hate speech, violence, and ethnic tension that Facebook appears to be
enabling. It’s like a newborn that needs extra care. In a country where most
people treat Facebook as though it is the internet, leadership have assigned
only two full-time Burmese staffers and it is unclear whether they are
employees or contractors (and two bonus contractors for the week of the
election), and they’re all based in Dublin, so not in the right time zone to
monitor all the posts. To properly cover the country as well as we cover,
say, Germany, we’d need hundreds of skilled moderators. And in China we
had promised four hundred initially, rising to over two thousand Facebook
employees. I know the size of the Myanmar staff is woefully inadequate, so

my team and I do what we can. On the cusp of the election, I divide up the
clock with a teammate in Australia so there’s always someone from our
team monitoring any reports to Facebook and our secret groups even in the
middle of the night, the fear of catastrophe ever present.
In the end, the election goes peacefully, with only rare and isolated
incidents of violence in the run-up. The National League for Democracy
sweeps into power in a landslide, driving out the junta. But as we head into
2016, it’s still unclear whether the military will respect the results and step
down.
After the election, the hate speech and fake news on Facebook continue,
worse than we’ve seen in any other country. The junta is supposedly
transitioning to democracy but that seems to be backsliding, and we
genuinely can’t tell where they stand on all this. Sometimes they ask to
collaborate to fight hate speech, but we don’t know if that’s sincere or if
they’re doing it as an underhanded way to crack down on their political
opponents. We’re in over our heads. We don’t understand the role Facebook
is playing in the country. And much of the platform still isn’t working as it
should in Myanmar. We need to get someone on the ground to figure it out
and start to work on solutions urgently, every day. Or at least that’s what I
think. The leadership of Facebook is utterly indifferent.
Then I think I’ve struck lucky. I’ve managed to find someone with
exactly the right expertise. And when I say “the right expertise,” I’m not
just referring to his extensive human rights experience. I’ve learned by this
point that hiring for a senior position at Facebook follows certain unspoken
rules. If you want someone to actually influence the policy and political
decisions that are ultimately made by Joel and Elliot, they’ll have a greater
