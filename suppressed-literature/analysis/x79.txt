attention. Other than moments that make the news, like when Mark went
for a smoggy jog through Tiananmen Square and posted about it.
I know Facebook’s advertising business in China is growing—even
while we’re blocked—because Chinese businesses are buying ads on
Facebook. It’s possible, through resellers, for them to target ads to people
outside China and to people who travel to China. In fact, China is
Facebook’s second-largest market, accounting for an estimated $5 billion of
revenue at this time and roughly 10 percent of Facebook’s total revenue,
trailing only the US. That’s while the company is banned. So I know China
matters a great deal to Facebook.

But as I take over the day-to-day running of Facebook’s China policy
from Joel, their strategy is so opaque, there’s no obvious place to find out
what’s happened so far. After a not terribly informative coffee with
Vaughan, I figure my only option is to sift through random documents to try
to understand the situation.
So I sit down to read.
In the three years since Mark sent out his email to top managers
declaring that getting into China was Facebook’s top priority, his desire to
make this happen has only grown, according to the documents.
To make it happen, Facebook’s put important people on the payroll,
including a former deputy secretary of the treasury, Bob Kimmitt, who’s
now the lead “independent” director on Facebook’s board. Mark gets advice
from Henry Kissinger and Hank Paulson.
I’m curious—why would China allow Facebook in? I soon find a set of
documents that sets out Facebook’s pitch. The first is titled “China—Our
Value Proposition.” It’s mostly the corporate feel-good “we’ll boost your
economy and help you prosper” bullshit. They promise to help China
increase its global influence and promote “the China dream,” support
innovation and job growth, and advertise Chinese products to people around
the world.
But the “key”offer is that Facebook will help China “promote safe and
secure social order.” And what does this mean? Surveillance. They point
out that on Facebook, the profiles represent real people with their real
names, and that “we adhere to local laws wherever we operate and develop
close relationships with law enforcement and governments.”
In the most benign reading of this, Facebook is saying: millions of your
citizens will post information about themselves publicly that you can view
and collect if you want. In the least benign reading—the way I read this—
Facebook is dangling the possibility that it’ll give China special access to
users’ data. Authoritarian states need information on everyone at every level
of society, and Facebook can provide a treasure trove.
That pitch signals Facebook’s intent to work hand-in-glove with the
CCP to help enforce its will on its people:

Facebook seeks to create an online environment that is civilized,
which is why we respect local laws as well as harmonious which is
why we remove offending content. We agree with Minister Lu Wei
when he said: “We must stick to the bottom line and exercise
governance in accordance with the law” and “Liberty means order.
The two are closely linked.… Liberty cannot exist without order.”
I can’t imagine Mark saying that to US citizens.
And who will do this surveillance on Facebook in China? Who’ll be
responsible for going through user posts and private messages looking for
each and every piece of content that the Chinese government wants
removed and expunging it? Does this include private messages between
Americans and Chinese citizens? Who will use Facebook’s technology to
search for faces at the government’s request? Who’ll turn those people in?
Be accountable to the CCP? Who gets their hands dirty? The stakes of this
are grim. Support for banned opinions can lead to harassment and arrest and
worse.
Facebook can take instructions from the Chinese government and do
this surveillance on its own users. Or a Chinese company can do it, in some
sort of joint venture with Facebook supplying the technology? I soon find a
document where our China team weighs the pros and cons of Facebook
doing this itself.
On the pro side, Facebook’s leadership believe they would have more
direct communication with the government, there’d be simpler coordination
since they wouldn’t have to deal with a business partner, and Facebook
would own more of the China operation. This is something that’s important
to Mark because he doesn’t want to give away equity or ownership for his
China operation if he can avoid it.
The con side is more complicated. They list several:
“Govt may be less forthcoming in its communication to us” [than
to a Chinese partner]

“increased human rights, media and public condemnation for
censorship and user data practices”
“Congress may demand visibility into content moderation
requirements” [in other words, US lawmakers might want to
know what’s on the blacklist of things the Chinese government
won’t allow on Facebook]
“More leverage for other Govts seeking similar treatment”
But the thing that gets me is where Facebook’s leadership states that one
of the “cons” of Facebook being the one who’s accountable for content
moderation is this:
“Facebook employees will be responsible for user data responses
that could lead to death, torture and incarceration.”
Which seems bad but somehow keeps getting worse. In the edit notes, I
see that Joel has edited out the part about death, torture, and incarceration
and replaced it in the final document, so instead it reads,
“Facebook employees will be responsible for directly responding
to requests for data from a government that does not respect
international standards for human rights.”
And yet, despite the fact that our employees would be responsible for
death, torture, and incarceration (however Joel might want to word it), the
consensus among Mark and the Facebook leaders was that this was what
they’d prefer:
We’d prefer more content/data control and communication with the
Govt over the limited protections we’d gain from being able to say
that our partner is responsible for taking down controversial content
and responding to Govt requests for user data.
Ugh.
I knew that Facebook’s leadership could be utterly indifferent to the
consequences of their decisions, but it never occurred to me that it would go

