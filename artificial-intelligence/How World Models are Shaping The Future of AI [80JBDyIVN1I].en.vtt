WEBVTT
Kind: captions
Language: en

00:00:03.184 --> 00:00:11.104
AI. In this episode, I speak with Tianmin Shu, a&nbsp;
rising figure in the AI research community soon to&nbsp;&nbsp;

00:00:11.104 --> 00:00:17.904
join Johns Hopkins University with an impressive&nbsp;
background that includes a postdoc at MIT and a&nbsp;&nbsp;

00:00:17.904 --> 00:00:25.664
PhD from UCLA. Tianmin works at the intersection&nbsp;
of AI and cognitive science with a particular&nbsp;&nbsp;

00:00:25.664 --> 00:00:32.904
focus on societal aspects of both human and&nbsp;
artificial intelligence. Our conversation revolved&nbsp;&nbsp;

00:00:32.904 --> 00:00:40.424
around the concept of world models, a term rooted&nbsp;
in developmental psychology and cognitive science&nbsp;&nbsp;

00:00:40.424 --> 00:00:48.504
and their integration into AI. Tianmin elaborated&nbsp;
on how these models coupled with large language&nbsp;&nbsp;

00:00:48.504 --> 00:00:56.064
models can enable the creation of agents capable&nbsp;
of interpreting and interacting with the world in&nbsp;&nbsp;

00:00:56.064 --> 00:01:03.064
human-like ways. He sheds light on his projects&nbsp;
involving world models for household environments&nbsp;&nbsp;

00:01:03.064 --> 00:01:09.464
and the potential of multimodal sensory data&nbsp;
in their training. The episode also delved&nbsp;&nbsp;

00:01:09.464 --> 00:01:16.704
into the challenges and future trajectories in AI,&nbsp;
especially in the realm of social learning, where&nbsp;&nbsp;

00:01:16.704 --> 00:01:24.824
AI models learn alongside of and from humans.&nbsp;
Tianmin discusses research driving the future of&nbsp;&nbsp;

00:01:24.824 --> 00:01:32.044
AI and human robot interaction. And I hope you&nbsp;
find our conversation as insightful as I did.

00:01:32.044 --> 00:01:39.304
CRAIG: At home and work, we all know one person&nbsp;
who is password challenged: sticky note reminders,&nbsp;&nbsp;

00:01:39.304 --> 00:01:46.224
emailing passwords, reusing passwords, using&nbsp;
the word ‘password’ as their password. Because&nbsp;&nbsp;

00:01:46.224 --> 00:01:52.779
data breaches affect everyone, you need&nbsp;
1Password. 1Password combines industry&nbsp;&nbsp;

00:01:52.779 --> 00:01:58.264
leading security with award winning designed&nbsp;
to bring private, secure and user friendly&nbsp;&nbsp;

00:01:58.264 --> 00:02:05.384
password management to everyone. Companies lose&nbsp;
hours every day just from employees forgetting&nbsp;&nbsp;

00:02:05.384 --> 00:02:12.464
and resetting passwords. A single data breach&nbsp;
costs millions of dollars. 1Password secures&nbsp;&nbsp;

00:02:12.464 --> 00:02:19.304
every sign in to save you time and money.&nbsp;
1Password lets you switch between iPhone,&nbsp;&nbsp;

00:02:19.304 --> 00:02:25.984
Android, Mac and PC with convenient features&nbsp;
like autofill for quick signups. All you have&nbsp;&nbsp;

00:02:25.984 --> 00:02:32.264
to remember is the one strong account password&nbsp;
that protects everything else - your logins,&nbsp;&nbsp;

00:02:32.264 --> 00:02:38.464
your credit cards, secure notes, or the&nbsp;
office Wi Fi password. 1Password generates&nbsp;&nbsp;

00:02:38.464 --> 00:02:44.784
as many strong unique passwords as you need&nbsp;
and securely stores them in an encrypted vault&nbsp;&nbsp;

00:02:44.784 --> 00:02:51.944
that only you have access to. I use 1Password&nbsp;
and you should too. 1Password’s award winning&nbsp;&nbsp;

00:02:51.944 --> 00:02:59.144
password manager is trusted by millions of&nbsp;
users and over 100,000 businesses from IBM&nbsp;&nbsp;

00:02:59.144 --> 00:03:06.264
to Slack. It beat out 40 other options to become&nbsp;
Wirecutters top pick for password managers. Plus,&nbsp;&nbsp;

00:03:06.264 --> 00:03:13.344
regular third party audits and the industry's&nbsp;
largest bug bounty keep 1Password at the forefront&nbsp;&nbsp;

00:03:13.344 --> 00:03:19.924
of security. Right now, my listeners get a&nbsp;
two week free trial at 1Password.com/eyeonai.

00:03:19.924 --> 00:03:29.864
CRAIG: So Why don't you start, Tianmin,&nbsp;
by introducing yourself and then I'll&nbsp;&nbsp;

00:03:29.864 --> 00:03:37.304
ask questions from there. Give a little of your&nbsp;
educational background. Yeah. And where you're&nbsp;&nbsp;

00:03:37.304 --> 00:03:42.464
working today and what you're working on.
TIANMIN: So I'm actually going to join&nbsp;&nbsp;

00:03:42.464 --> 00:03:48.064
Hopkins the CS department and also the Cognitive&nbsp;
Science department as an assistant professor.&nbsp;

00:03:48.064 --> 00:03:56.144
TIANMIN: But previously I did my postdoc at&nbsp;
MIT and before that I did my PhD at UCLA.&nbsp;&nbsp;

00:03:56.704 --> 00:04:03.864
I' working at the intersection between AI&nbsp;
and cognitive science. I think a lot about&nbsp;&nbsp;

00:04:03.864 --> 00:04:09.624
not only building artificial intelligence,&nbsp;
but also how human intelligence can inform&nbsp;&nbsp;

00:04:09.624 --> 00:04:15.784
us to build better AI. And I think that the&nbsp;
idea of building a world model that actually&nbsp;&nbsp;

00:04:15.784 --> 00:04:22.424
originally came from cognitive science and then&nbsp;
specifically I have a strong interest in the&nbsp;&nbsp;

00:04:22.424 --> 00:04:28.984
social aspect of AI and also human intelligence.
TIANMIN: How we can build human level kind of&nbsp;&nbsp;

00:04:28.984 --> 00:04:34.464
social intelligence so that we can allow&nbsp;
systems to understand humans and really&nbsp;&nbsp;

00:04:34.464 --> 00:04:39.104
cooperate with humans in the same way that we&nbsp;
can understand and cooperate with each other.&nbsp;&nbsp;

00:04:39.104 --> 00:04:47.824
And again, I think that's something&nbsp;
that's is very challenging right now.&nbsp;

00:04:47.824 --> 00:04:53.984
TIANMIN: And also it's not something that big&nbsp;
companies are working on. And I think it's also&nbsp;&nbsp;

00:04:53.984 --> 00:05:00.064
something that will really benefit from having a&nbsp;
world model. Both in the sense of understanding&nbsp;&nbsp;

00:05:00.064 --> 00:05:06.584
how humans understand the world and also how we&nbsp;
can understand humans that live in this world.&nbsp;

00:05:06.584 --> 00:05:11.904
CRAIG: Okay. Can we start first of&nbsp;
all, by talking about world models?&nbsp;

00:05:11.904 --> 00:05:20.304
CRAIG: I've had a few episodes on world models.&nbsp;
But maybe you can, when did the idea of world&nbsp;&nbsp;

00:05:20.304 --> 00:05:30.704
models emerge? I've been following Yann LeCun's&nbsp;
work, but I know it's much broader than that.&nbsp;&nbsp;

00:05:30.704 --> 00:05:38.864
When did that idea emerge and can you give us&nbsp;
just a very brief history of its development?&nbsp;

00:05:38.864 --> 00:05:45.304
TIANMIN: Just a to determine, I don't think&nbsp;
the history, I can tell. Probably not the&nbsp;&nbsp;

00:05:45.304 --> 00:05:49.544
full history. There's going to be some people&nbsp;
at some point talking about world models that&nbsp;&nbsp;

00:05:49.544 --> 00:05:54.544
I don't know about. But the kind of case I'm&nbsp;
familiar with is coming from developmental&nbsp;&nbsp;

00:05:54.544 --> 00:05:58.544
psychology and also cognitive science.
TIANMIN: So in developmental psychology there's&nbsp;&nbsp;

00:05:58.544 --> 00:06:06.904
this theory about core knowledge. So it's actually&nbsp;
a theory. Proposed by Liz Spelke, who is now a&nbsp;&nbsp;

00:06:06.904 --> 00:06:15.744
professor at Harvard. So she had this theory about&nbsp;
so since first, we have some core knowlege about&nbsp;&nbsp;

00:06:15.744 --> 00:06:22.464
the world and about other agents. that we can use&nbsp;
as a foundation for developing more sophisticated&nbsp;&nbsp;

00:06:22.464 --> 00:06:27.064
intelligence that we can develop later in life.
TIANMIN: And one of them is to understand the&nbsp;&nbsp;

00:06:27.064 --> 00:06:32.104
physical world. For example, we have some&nbsp;
physical common sense like object permanence,&nbsp;&nbsp;

00:06:32.104 --> 00:06:38.264
we understand supports if you put something&nbsp;
on a table, it won't fall. So this kind of&nbsp;&nbsp;

00:06:38.984 --> 00:06:46.984
basic kind of physical common sense allows us to&nbsp;
actually develop more sophisticated intelligence.&nbsp;

00:06:46.984 --> 00:06:51.384
TIANMIN: And we have acquired those&nbsp;
critical common sense very long,&nbsp;&nbsp;

00:06:51.384 --> 00:06:59.144
maybe even through evolution. Now it's unclear&nbsp;
that how much of it actually comes from evolution.&nbsp;&nbsp;

00:06:59.144 --> 00:07:08.264
How much of it comes from experiences living&nbsp;
life. Now there's also this idea about having&nbsp;&nbsp;

00:07:08.264 --> 00:07:14.984
an internal world model that can allow you&nbsp;
to simulate what could happen in the future.&nbsp;

00:07:14.984 --> 00:07:21.664
TIANMIN: And you can use that kind of simulation&nbsp;
to not only reason about future physical states,&nbsp;&nbsp;

00:07:21.664 --> 00:07:28.144
but also applying yourself better through this&nbsp;
kind of simulation. And that comes from a lot of&nbsp;&nbsp;

00:07:29.624 --> 00:07:38.384
work from my PhD, sorry, not PhD advisor postdoc&nbsp;
advisor, Josh Tenenbaum. He had this idea that&nbsp;&nbsp;

00:07:38.384 --> 00:07:44.504
human has this internal intuitive physics engine.&nbsp;
So we all know physics engine, which allows you to&nbsp;&nbsp;

00:07:44.504 --> 00:07:48.664
simulate what could happen in the physical world.
TIANMIN: Now human, in our minds,&nbsp;&nbsp;

00:07:48.664 --> 00:07:53.864
we can have an intuitive physics engine that&nbsp;
allows you to simulate what could happen in the&nbsp;&nbsp;

00:07:53.864 --> 00:07:58.504
physical world, just like how you can simulate&nbsp;
what could happen in a physical world using a&nbsp;&nbsp;

00:07:58.504 --> 00:08:06.544
game engine. Now using that, they show&nbsp;
that you can simulate physical events.&nbsp;

00:08:06.544 --> 00:08:10.224
TIANMIN: And use that kind of simulation&nbsp;
results, adding some kind of noise on top&nbsp;&nbsp;

00:08:10.224 --> 00:08:16.424
of that. And you can use that to approximate&nbsp;
how human judge physical events pretty well.&nbsp;&nbsp;

00:08:17.304 --> 00:08:22.264
They did experiments where they show a&nbsp;
tower of blocks, and they ask people to&nbsp;&nbsp;

00:08:22.264 --> 00:08:26.664
judge whether the block will fall or not.
TIANMIN: If they will fall which way&nbsp;&nbsp;

00:08:26.664 --> 00:08:32.584
they will fall to, right? And then it turns out&nbsp;
that if you actually simulate that using a game&nbsp;&nbsp;

00:08:32.584 --> 00:08:37.664
engine, you And as a little bit of noise on&nbsp;
top of that, because people have imperfect&nbsp;&nbsp;

00:08:37.664 --> 00:08:44.384
imperfect kind of simulation, right? Physical&nbsp;
simulation plus noise or some kind of uncertainty,&nbsp;&nbsp;

00:08:44.384 --> 00:08:50.184
that's approximately human judgment really well.
TIANMIN: And I think there's also recent kind of&nbsp;&nbsp;

00:08:50.184 --> 00:08:56.984
collaboration with a neuroscience at MIT Nancy&nbsp;
Kanwisher. They show that there's some kind&nbsp;&nbsp;

00:08:56.984 --> 00:09:04.664
of evidence in our brain that maybe our brain is&nbsp;
also using actually a game engine to simulate what&nbsp;&nbsp;

00:09:04.664 --> 00:09:08.704
could happen in in a physical world.
CRAIG: Yeah.&nbsp;

00:09:08.704 --> 00:09:17.664
CRAIG: And that engine to, to&nbsp;
simulate what's the computer code&nbsp;&nbsp;

00:09:17.664 --> 00:09:21.353
or algorithmic architecture behind that?
TIANMIN: Yeah. So if you if you want to&nbsp;&nbsp;

00:09:21.353 --> 00:09:21.447
write computer code there's there's this tools&nbsp;
called probabilistic programs. I don't know if&nbsp;&nbsp;

00:09:21.447 --> 00:09:24.144
you have heard about it. Probabilistic programs.
TIANMIN: I think one way to understand it is that&nbsp;&nbsp;

00:09:24.144 --> 00:09:32.024
you can generate you can write down codes to&nbsp;
describe a generative process. In this case,&nbsp;&nbsp;

00:09:32.024 --> 00:09:38.944
you can describe a generative process&nbsp;
as a world model. You assemble objects,&nbsp;&nbsp;

00:09:38.944 --> 00:09:47.784
you simulate force. And then the generative&nbsp;
model will tell you, after you apply this force,&nbsp;&nbsp;

00:09:47.784 --> 00:09:52.984
what will happen next. What will be the&nbsp;
state of these objects, you just simulate.&nbsp;

00:09:53.824 --> 00:09:58.904
TIANMIN: You can write down this generative&nbsp;
process as a program. And then when you run&nbsp;&nbsp;

00:09:58.904 --> 00:10:05.344
this program, you will sample this&nbsp;
sample foundation model. And it will&nbsp;&nbsp;

00:10:05.344 --> 00:10:08.624
tell you what's the distribution&nbsp;
of the, for example, in this case,&nbsp;&nbsp;

00:10:08.624 --> 00:10:14.504
what's the distribution of the future states&nbsp;
of these objects after you run the simulation.&nbsp;

00:10:14.504 --> 00:10:22.064
TIANMIN: So that allows you to, first of all,&nbsp;
simulate the generative model of the world. And&nbsp;&nbsp;

00:10:22.064 --> 00:10:29.224
second, it gives you a distribution. And what you&nbsp;
can do with this distribution is you can conduct&nbsp;&nbsp;

00:10:29.224 --> 00:10:47.824
probability inference. So say if you want to&nbsp;
predict where these objects will fall in the&nbsp;&nbsp;

00:10:47.824 --> 00:10:49.054
next few steps you can use that simulation, that&nbsp;
distribution to tell you what is the likelihood&nbsp;&nbsp;

00:10:49.054 --> 00:10:51.784
of these objects falling into this place.
TIANMIN: You can also use this simulation to do&nbsp;&nbsp;

00:10:51.784 --> 00:10:59.224
planning, for example, with uncertainty. I think&nbsp;
probably this object is going to fall this place,&nbsp;&nbsp;

00:10:59.224 --> 00:11:03.264
but maybe also in that place. Based on my&nbsp;
simulation, based on the distribution coming&nbsp;&nbsp;

00:11:03.264 --> 00:11:10.024
from the, this policy program now given this&nbsp;
uncertainty, how I can plan myself in order&nbsp;&nbsp;

00:11:10.024 --> 00:11:12.083
to maybe catch these objects.
CRAIG: I see. And that,&nbsp;&nbsp;

00:11:12.083 --> 00:11:12.984
that is, that is the world model?
TIANMIN: Yes. So in that that's like one,&nbsp;&nbsp;

00:11:12.984 --> 00:11:16.264
one implementation, right? You&nbsp;
use a physical simulation and&nbsp;&nbsp;

00:11:16.264 --> 00:11:21.024
that allows you to sample future states. And that&nbsp;&nbsp;

00:11:21.024 --> 00:11:27.144
can be implemented as a publish program.
CRAIG: I see. And then in your talk you were&nbsp;&nbsp;

00:11:27.144 --> 00:11:36.784
talking about combining world models and large&nbsp;
language models and the language model would&nbsp;&nbsp;

00:11:36.784 --> 00:11:45.584
provide the reasoning and the world model would&nbsp;
provide the the. predictions of future states,&nbsp;&nbsp;

00:11:45.584 --> 00:11:57.144
and then the language model would pick which&nbsp;
action to arrive at a future state. Is that right?&nbsp;

00:11:57.144 --> 00:12:03.224
TIANMIN: We explored or discussed different ways&nbsp;
in which people have tried to use language model&nbsp;&nbsp;

00:12:03.224 --> 00:12:10.704
to implement as like a word model. So the most&nbsp;
direct use is say, let's prompt the language&nbsp;&nbsp;

00:12:10.704 --> 00:12:16.904
model with the current state, the action,&nbsp;
and ask the model what could happen next.&nbsp;

00:12:16.904 --> 00:12:20.144
TIANMIN: So this is the basic idea of a&nbsp;
word model, right? You want to predict&nbsp;&nbsp;

00:12:20.144 --> 00:12:26.744
what will happen given the current state and given&nbsp;
your action. And then I think that the paper you&nbsp;&nbsp;

00:12:26.744 --> 00:12:33.584
mentioned is the reasoning as planning paper&nbsp;
the RaP paper. So the idea behind that is that&nbsp;&nbsp;

00:12:33.584 --> 00:12:39.304
why not we try to use a language model to do this.
TIANMIN: To imagine what could happen after taking&nbsp;&nbsp;

00:12:39.304 --> 00:12:46.704
an action at the current step. It works to a&nbsp;
certain extent. I think in some simple scenarios,&nbsp;&nbsp;

00:12:46.704 --> 00:12:52.664
it can work. I don't think at this point, the&nbsp;
model is robust enough to serve as a model on&nbsp;&nbsp;

00:12:52.664 --> 00:12:56.904
its own for more complicated scenarios.
CRAIG: Okay, and then this most recent&nbsp;&nbsp;

00:12:56.904 --> 00:13:05.444
paper and the the workshop at NeurIPS was about&nbsp;
combining the language model with a world model.&nbsp;

00:13:05.444 --> 00:13:10.984
CRAIG: So the world model predicts the future&nbsp;
states and the language model provides the&nbsp;&nbsp;

00:13:10.984 --> 00:13:17.704
reasoning. Did I understand that correctly?
TIANMIN: I don't think that's I guess the&nbsp;&nbsp;

00:13:17.704 --> 00:13:23.584
complete idea. The idea is that we want to&nbsp;
have expressible models and also express&nbsp;&nbsp;

00:13:23.584 --> 00:13:28.304
agent model that's built upon our model.
TIANMIN: And then using agent model and world&nbsp;&nbsp;

00:13:28.304 --> 00:13:34.464
model we can conduct model based reasoning.&nbsp;
Now we want to explore the idea that,&nbsp;&nbsp;

00:13:34.464 --> 00:13:39.864
how language model could be used as a back end&nbsp;
to implement a world model and an agent model.&nbsp;&nbsp;

00:13:39.864 --> 00:13:47.304
And of course like the RaP paper, there has been&nbsp;
effort that try to use language model directly as,&nbsp;&nbsp;

00:13:47.304 --> 00:13:52.704
for example, word model and agent models.
TIANMIN: That can work in certain scenarios,&nbsp;&nbsp;

00:13:52.704 --> 00:13:58.584
but not in more complex scenarios. Now we want&nbsp;
to explore, for example, how it can maybe enhance&nbsp;&nbsp;

00:13:58.584 --> 00:14:05.464
the agent model to serve as a better world&nbsp;
models and agent models. And second, we want&nbsp;&nbsp;

00:14:05.464 --> 00:14:11.504
to also explore ways in which we can not only&nbsp;
just use language, but also use other modalities,&nbsp;&nbsp;

00:14:11.504 --> 00:14:20.584
like the vision even like touch or audio to&nbsp;
to really build multi modal world models.&nbsp;

00:14:20.584 --> 00:14:26.384
TIANMIN: That's, so obviously that's&nbsp;
not going to be the kind of typical&nbsp;&nbsp;

00:14:26.384 --> 00:14:29.504
language model you see nowadays.
CRAIG: Yeah. So can you talk a&nbsp;&nbsp;

00:14:29.504 --> 00:14:37.664
little bit about that? How you introduce the&nbsp;
language model into this into this architecture&nbsp;&nbsp;

00:14:37.664 --> 00:14:43.824
with a world model in order to produce an agent?
TIANMIN: So I think I would say there are probably&nbsp;&nbsp;

00:14:43.824 --> 00:14:49.384
like two ways you can introduce this one way.
TIANMIN: That's that's not coming from my own&nbsp;&nbsp;

00:14:49.384 --> 00:14:55.664
work. That's from My, my colleagues&nbsp;
at MIT they introduced the idea that&nbsp;&nbsp;

00:14:55.664 --> 00:15:03.824
use language as interface to translate language&nbsp;
discussion about scenarios into a probabilistic&nbsp;&nbsp;

00:15:03.824 --> 00:15:08.324
program so that you can conduct probabilistic&nbsp;
inference using that probabilistic program.&nbsp;

00:15:08.324 --> 00:15:11.944
TIANMIN: And again, probabilistic programs&nbsp;
serve as a training model of the world. And&nbsp;&nbsp;

00:15:11.944 --> 00:15:19.464
also about other agents. This idea comes from&nbsp;
very classical idea in cognitive science called&nbsp;&nbsp;

00:15:19.464 --> 00:15:25.144
language of thought. We have our thoughts in&nbsp;
our minds, and we think about those thoughts&nbsp;&nbsp;

00:15:25.144 --> 00:15:27.904
in the form of language, right?
TIANMIN: We can also write down&nbsp;&nbsp;

00:15:27.904 --> 00:15:37.104
those thoughts and use, use our language to&nbsp;
communicate with others about our thoughts.&nbsp;&nbsp;

00:15:37.104 --> 00:15:43.824
Then if you do the reverse process, we are&nbsp;
given language about scenarios. And also a&nbsp;&nbsp;

00:15:43.824 --> 00:15:50.384
question about that scenarios, how you can&nbsp;
conduct reasoning using internal thoughts,&nbsp;&nbsp;

00:15:50.384 --> 00:15:55.424
not as directly as a language reasongin,&nbsp;
but you want to convert language into an&nbsp;&nbsp;

00:15:55.424 --> 00:16:01.704
internal thought and reason over that thought.
TIANMIN: For example, you can describe a language,&nbsp;&nbsp;

00:16:01.704 --> 00:16:10.504
you can use language to describe a physical&nbsp;
situation. I just told you yes. Maybe a tower&nbsp;&nbsp;

00:16:10.504 --> 00:16:16.584
of blocks on the table. On the bottom&nbsp;
you have a small block. In the middle I&nbsp;&nbsp;

00:16:16.584 --> 00:16:22.704
have a larger block. On top, you have an even&nbsp;
larger block. I can ask you, can you imagine&nbsp;&nbsp;

00:16:22.704 --> 00:16:29.224
how stable this tower of blocks can be, right?
TIANMIN: And I also describe a different scenario.&nbsp;&nbsp;

00:16:29.224 --> 00:16:35.784
On the bottom you have a very large block. On&nbsp;
the middle, you have a smaller kind of on top,&nbsp;&nbsp;

00:16:35.784 --> 00:16:42.104
you have a teeny tiny block. Then you can also&nbsp;
imagine what could happen next. Notice I have&nbsp;&nbsp;

00:16:42.104 --> 00:16:49.744
shown you a zero image about this, but you can&nbsp;
based on my language execution, try to understand&nbsp;&nbsp;

00:16:49.744 --> 00:16:54.584
what I'm trying to describe here, right?
TIANMIN: So how we can convert that language&nbsp;&nbsp;

00:16:54.584 --> 00:17:02.504
into something like a thought process that allows&nbsp;
us to simulate what could happen next. So I think&nbsp;&nbsp;

00:17:02.504 --> 00:17:08.664
what one so the colleagues at MIT, they come up&nbsp;
with this idea that you can use a language model&nbsp;&nbsp;

00:17:08.664 --> 00:17:16.304
to translate this standard distribution into&nbsp;
code. And so basically a probabilistic program&nbsp;&nbsp;

00:17:16.304 --> 00:17:22.464
that will basically become a physical simulation.
TIANMIN: So the scenario I told you, after the&nbsp;&nbsp;

00:17:22.464 --> 00:17:27.704
model, you'll get a code that allow to simulate&nbsp;
the physical situation, and you can simulate&nbsp;&nbsp;

00:17:27.704 --> 00:17:33.064
what could happen next. And that this again, allow&nbsp;
you to do model based kind of reasoning about the&nbsp;&nbsp;

00:17:33.064 --> 00:17:40.464
physical world. So I think that's very neat idea.&nbsp;
And it's also very good use of language model,&nbsp;&nbsp;

00:17:40.464 --> 00:17:45.264
because again, I don't think language model itself&nbsp;
has all the knowledge about the physical world,&nbsp;&nbsp;

00:17:45.264 --> 00:17:52.024
but language model is really good at writing code.
TIANMIN: And we all know that. But, and again,&nbsp;&nbsp;

00:17:52.024 --> 00:17:56.024
you can translate do this inverse process&nbsp;&nbsp;

00:17:56.024 --> 00:18:03.664
where you can convert language into a thought.
CRAIG: Yeah that's really interesting. And then&nbsp;&nbsp;

00:18:03.664 --> 00:18:13.704
how, and you guys have done this isn't theory.&nbsp;
You've built these models to work together.&nbsp;

00:18:13.704 --> 00:18:24.064
CRAIG: What is the agency layer. That's the&nbsp;
reasoning and the planning or decision making.&nbsp;&nbsp;

00:18:24.064 --> 00:18:35.504
Then how do you add the the agent on the model?
TIANMIN: Yeah so agent is model as a decision&nbsp;&nbsp;

00:18:35.504 --> 00:18:41.064
making process, basically in this framework&nbsp;
where you have your your world model,&nbsp;&nbsp;

00:18:41.064 --> 00:18:44.864
your internal world model that you&nbsp;
can use to simulate what could happen.&nbsp;

00:18:44.864 --> 00:18:49.864
TIANMIN: You have your own goal and goal has&nbsp;
a condition of the goal is you have a reward.&nbsp;&nbsp;

00:18:49.864 --> 00:18:54.344
So you really will try to help you to reach&nbsp;
the goal, but also in the process, minimize&nbsp;&nbsp;

00:18:54.344 --> 00:19:01.384
the cost. And then you have your belief about the&nbsp;
world because agents only has, an agent only has&nbsp;&nbsp;

00:19:01.384 --> 00:19:06.424
partial observation of the physical environments.
TIANMIN: You don't know everything. So you have a&nbsp;&nbsp;

00:19:06.424 --> 00:19:12.624
belief about what the actual physical state is.&nbsp;
So again, belief is like distribution of the&nbsp;&nbsp;

00:19:12.624 --> 00:19:22.264
physical states. Now, based on this, then you&nbsp;
can try to make a plan that can based on your,&nbsp;&nbsp;

00:19:22.264 --> 00:19:28.904
first of all, your belief about how the actual&nbsp;
physical states look like and then based,&nbsp;&nbsp;

00:19:28.904 --> 00:19:34.984
and then also try to maximize your rewards&nbsp;
that allow you to reach the goal after doing&nbsp;&nbsp;

00:19:34.984 --> 00:19:39.024
simulations about different kinds of plans.
CRAIG: Yeah, yeah. So I'm trying to&nbsp;&nbsp;

00:19:39.024 --> 00:19:46.144
think of it in. So that's an RL, a&nbsp;
reinforcement learning engine in effect.&nbsp;

00:19:46.144 --> 00:19:48.384
TIANMIN: That doesn't have to be&nbsp;
reinforcement learning, but that&nbsp;&nbsp;

00:19:48.384 --> 00:19:55.944
can be a model based planning. So the idea&nbsp;
about so the idea behind the model based&nbsp;&nbsp;

00:19:55.944 --> 00:20:01.704
reinforcement learning or model based planning&nbsp;
is that you don't need to do a lot of trial and&nbsp;&nbsp;

00:20:01.704 --> 00:20:05.944
error in actual physical environment.
TIANMIN: Okay. You can do so using a&nbsp;&nbsp;

00:20:05.944 --> 00:20:11.664
simulation. You can simulate beforehand what&nbsp;
could happen after taking different kind of&nbsp;&nbsp;

00:20:11.664 --> 00:20:18.664
actions. Then you can search for the best set of&nbsp;
actions that allow you to reach the goal without&nbsp;&nbsp;

00:20:18.664 --> 00:20:23.784
actually trying out in a real physical world.
CRAIG: At home and work, we all know one person&nbsp;&nbsp;

00:20:23.784 --> 00:20:31.344
who is password challenged: sticky note reminders,&nbsp;
emailing passwords, reusing passwords, using the&nbsp;&nbsp;

00:20:31.344 --> 00:20:38.784
word ‘password’ as their password. Because data&nbsp;
breaches affect everyone, you need 1Password.&nbsp;&nbsp;

00:20:39.344 --> 00:20:45.624
1Password combines industry leading security with&nbsp;
award winning designed to bring private, secure&nbsp;&nbsp;

00:20:45.624 --> 00:20:52.864
and user friendly password management to everyone.&nbsp;
Companies lose hours every day just from employees&nbsp;&nbsp;

00:20:52.864 --> 00:20:59.864
forgetting and resetting passwords. A single&nbsp;
data breach costs millions of dollars. 1Password&nbsp;&nbsp;

00:20:59.864 --> 00:21:07.944
secures every sign in to save you time and money.&nbsp;
1Password lets you switch between iPhone, Android,&nbsp;&nbsp;

00:21:07.944 --> 00:21:14.064
Mac and PC with convenient features like&nbsp;
autofill for quick signups. All you have&nbsp;&nbsp;

00:21:14.064 --> 00:21:20.344
to remember is the one strong account password&nbsp;
that protects everything else - your logins,&nbsp;&nbsp;

00:21:20.344 --> 00:21:26.504
your credit cards, secure notes, or the&nbsp;
office Wi Fi password. 1Password generates&nbsp;&nbsp;

00:21:26.504 --> 00:21:32.824
as many strong unique passwords as you need&nbsp;
and securely stores them in an encrypted vault&nbsp;&nbsp;

00:21:32.824 --> 00:21:39.984
that only you have access to. I use 1Password&nbsp;
and you should too. 1Password’s award winning&nbsp;&nbsp;

00:21:39.984 --> 00:21:47.264
password manager is trusted by millions of&nbsp;
users and over 100,000 businesses from IBM&nbsp;&nbsp;

00:21:47.264 --> 00:21:54.304
to Slack. It beat out 40 other options to become&nbsp;
Wirecutters top pick for password managers. Plus,&nbsp;&nbsp;

00:21:54.304 --> 00:22:01.424
regular third party audits and the industry's&nbsp;
largest bug bounty keep 1Password at the forefront&nbsp;&nbsp;

00:22:01.424 --> 00:22:09.344
of security. Right now, my listeners get a&nbsp;
two week free trial at 1Password.com/eyeonai.

00:22:09.344 --> 00:22:20.064
CRAIG: That last part sounds like a little bit&nbsp;
like AlphaGo where you you simulate various&nbsp;&nbsp;

00:22:20.064 --> 00:22:31.344
courses of action, and then you, you search for&nbsp;
the optimal solution and make that solution? Is&nbsp;&nbsp;

00:22:31.344 --> 00:22:40.204
it similar in in architecture to AlphaGo?&nbsp;
The AlphaGo it's not using a world model.&nbsp;

00:22:40.204 --> 00:22:46.984
TIANMIN: Okay. So what is the core component&nbsp;
of AlphaGo? It's the Monte Carlo Tree Search,&nbsp;&nbsp;

00:22:46.984 --> 00:22:51.864
right? So that's a planning algorithm.
TIANMIN: That, that is not RL, that is&nbsp;&nbsp;

00:22:51.864 --> 00:22:57.024
planning. And then, and the reason why you can&nbsp;
do planning in that case is that you know the&nbsp;&nbsp;

00:22:57.024 --> 00:23:04.104
rule of the game already, right? So you know&nbsp;
exactly this will be the next stage of the game&nbsp;&nbsp;

00:23:04.104 --> 00:23:10.424
after taking certain move, right? And that&nbsp;
allow you to do forward simulation. You can&nbsp;&nbsp;

00:23:10.424 --> 00:23:17.584
think ahead for many steps and get better&nbsp;
plans by doing this kind of imagination.&nbsp;

00:23:17.584 --> 00:23:23.864
TIANMIN: Now. You mentioned that there doesn't&nbsp;
seem to be a world model. There is a world model.&nbsp;&nbsp;

00:23:23.864 --> 00:23:28.624
The world model is very simple. It's just the&nbsp;
rules of the game. And then you know exactly&nbsp;&nbsp;

00:23:28.624 --> 00:23:35.464
what could happen next. Now the more, and&nbsp;
the, and I think MCTS for planning, obviously&nbsp;&nbsp;

00:23:35.464 --> 00:23:44.144
it's very intriguing because it's very general.
TIANMIN: In a sense that if you have a reward,&nbsp;&nbsp;

00:23:44.144 --> 00:23:51.344
you will have a model that allow you to do forward&nbsp;
simulation. In theory, you can do anything. If you&nbsp;&nbsp;

00:23:51.344 --> 00:23:56.744
do enough simulation, you can get pretty good&nbsp;
planning. And if you add a little bit learning,&nbsp;&nbsp;

00:23:56.744 --> 00:24:04.384
like AlphaGo, You can also make the search&nbsp;
even faster. Now the down, now the downside,&nbsp;&nbsp;

00:24:04.384 --> 00:24:08.944
the challenge is that in, in the real world,&nbsp;
you don't have that perfect word model.&nbsp;

00:24:09.544 --> 00:24:14.784
TIANMIN: But if you do build a world model&nbsp;
for certain domains, then you can plug&nbsp;&nbsp;

00:24:14.784 --> 00:24:19.504
in that world model to do Monte Carlo Tree&nbsp;
Search or any kind of model based planning.&nbsp;

00:24:19.504 --> 00:24:31.224
CRAIG: Yeah. How far have your implementations&nbsp;
of this gone? You've you've built a model with&nbsp;&nbsp;

00:24:31.224 --> 00:24:44.024
all these elements. Does it depend on Does&nbsp;
its efficacy depend on how large the model&nbsp;&nbsp;

00:24:44.024 --> 00:24:50.744
is as is the case with language models, that&nbsp;
the larger the model, the better performance,&nbsp;&nbsp;

00:24:50.744 --> 00:25:01.024
or is this more a matter of of just optimizing&nbsp;
hyper parameters and stuff like that?&nbsp;

00:25:01.024 --> 00:25:07.184
TIANMIN: You mean like building, actually learning&nbsp;
a world model that can be used for learning a&nbsp;&nbsp;

00:25:07.184 --> 00:25:12.864
world model that can be used for very broad&nbsp;
set of domains and not just specific domains.&nbsp;&nbsp;

00:25:12.864 --> 00:25:21.944
I think we are not remotely there yet. The reason&nbsp;
is, for example there's just so many different&nbsp;&nbsp;

00:25:21.944 --> 00:25:27.304
kind of thing you can model in the world, right?
TIANMIN: You have so many different objects and&nbsp;&nbsp;

00:25:27.304 --> 00:25:32.504
even if you think about one specific object, they&nbsp;
have so many different kind of properties you can&nbsp;&nbsp;

00:25:32.504 --> 00:25:41.864
try to model like the materials the textures the&nbsp;
weight of the objects. The shape and all these&nbsp;&nbsp;

00:25:41.864 --> 00:25:46.184
different kind of properties, right?
TIANMIN: And depending on your task,&nbsp;&nbsp;

00:25:46.184 --> 00:25:51.077
your mind needs to model the object in&nbsp;
different ways and to do this you need to&nbsp;&nbsp;

00:25:51.077 --> 00:25:58.944
find replications of the objects. For instance,&nbsp;
if you only want to say carry some box around,&nbsp;&nbsp;

00:25:58.944 --> 00:26:03.624
you'll probably only need to know the weight and&nbsp;
the rough shape of the box. You don't need to know&nbsp;&nbsp;

00:26:04.744 --> 00:26:09.744
very detailed kind of representation of the box.
TIANMIN: If you want to manipulate fluids,&nbsp;&nbsp;

00:26:09.744 --> 00:26:14.424
for example, I don't think shape and weight will&nbsp;
be enough. You need to actually model fluid as&nbsp;&nbsp;

00:26:14.424 --> 00:26:20.144
some kind of particles. And how the particles&nbsp;
or what flow interact with different kind of,&nbsp;&nbsp;

00:26:20.144 --> 00:26:26.504
with different kind of surfaces, right? If you&nbsp;
want to say how I can manipulate some kind of&nbsp;&nbsp;

00:26:26.504 --> 00:26:33.944
deformable objects, so say if you want to cut some&nbsp;
vegetables then you also need to know like how the&nbsp;&nbsp;

00:26:34.624 --> 00:26:42.104
vegetables will interact with the the knife.
TIANMIN: And then how they will maybe in some&nbsp;&nbsp;

00:26:42.104 --> 00:26:48.864
case, maybe a roll on the cutting board.&nbsp;
So you need to somehow hold it. So there's&nbsp;&nbsp;

00:26:48.864 --> 00:26:54.224
a different kind of representation for this.&nbsp;
If you only think about single objects. Now,&nbsp;&nbsp;

00:26:54.224 --> 00:27:00.544
if you think about wider case where you have&nbsp;
many different objects in the world that's not&nbsp;&nbsp;

00:27:00.544 --> 00:27:07.224
only having different kind of properties,&nbsp;
but also being also they are dynamic.&nbsp;

00:27:07.224 --> 00:27:12.224
TIANMIN: So the states are also&nbsp;
changed by the forces in nature,&nbsp;&nbsp;

00:27:12.224 --> 00:27:19.504
but also other people. So for example, objects&nbsp;
may be moved by another agent while you're not&nbsp;&nbsp;

00:27:19.504 --> 00:27:27.744
present. So now you need to also imagine where the&nbsp;
object could be. So world model will become very&nbsp;&nbsp;

00:27:27.744 --> 00:27:35.504
complex in the reward. Now how we can build that?
TIANMIN: I don't think there's a single answer&nbsp;&nbsp;

00:27:35.504 --> 00:27:44.104
yet. We have world models that can work pretty&nbsp;
well in certain domains. So I mentioned that for&nbsp;&nbsp;

00:27:44.104 --> 00:27:50.904
robot manipulation, for example, we can, learn to&nbsp;
how, learn how some kind of substance or methods,&nbsp;&nbsp;

00:27:50.904 --> 00:27:57.144
objects will change how their state will&nbsp;
change given certain actions of the robots.&nbsp;

00:27:57.144 --> 00:28:03.344
TIANMIN: And using that, you can try to manipulate&nbsp;
robots for certain tasks. I think you mentioned&nbsp;&nbsp;

00:28:03.344 --> 00:28:09.464
Gaia. So Gaia is another great example of&nbsp;
a domain specific kind of world model. Of&nbsp;&nbsp;

00:28:09.464 --> 00:28:15.384
course you can use that to maybe build self&nbsp;
driving cars, but you cannot use that for,&nbsp;&nbsp;

00:28:15.384 --> 00:28:20.424
say, objects manipulation for robots.
TIANMIN: We have other cases where,&nbsp;&nbsp;

00:28:20.424 --> 00:28:30.024
for example, you can learn a world model for Some&nbsp;
kind of abstract kind of knowledge. So there's&nbsp;&nbsp;

00:28:30.024 --> 00:28:36.904
some world model that's represented as a knowledge&nbsp;
graph. So say if I do this what will happen, say,&nbsp;&nbsp;

00:28:36.904 --> 00:28:42.464
if I want to take a flight, I need to buy a&nbsp;
ticket first. So some kind of abstract kind&nbsp;&nbsp;

00:28:42.464 --> 00:28:46.224
of common sense knowledge. Now you&nbsp;
can use that to do certain things.&nbsp;

00:28:46.224 --> 00:28:53.384
TIANMIN: So say like maybe help you to make a&nbsp;
plan for a vacation. But again, that's because&nbsp;&nbsp;

00:28:53.384 --> 00:28:58.304
it's representing it as like an abstract&nbsp;
knowledge. You cannot use that for physical&nbsp;&nbsp;

00:28:58.304 --> 00:29:06.664
manipulation. So I would say, I don't have a&nbsp;
great answer about say, building a single world&nbsp;&nbsp;

00:29:06.664 --> 00:29:12.304
model that can represent anything in the world.
TIANMIN: I also don't think At this moment it's&nbsp;&nbsp;

00:29:12.304 --> 00:29:17.304
the best strategy to try to build such&nbsp;
a model. It's probably better to say a&nbsp;&nbsp;

00:29:17.304 --> 00:29:25.544
world model that can do well in a range of&nbsp;
specific domains. That's, and also you can&nbsp;&nbsp;

00:29:25.544 --> 00:29:32.344
easily generalize that to similar domains and&nbsp;
fine tune it with a small set of data. But I&nbsp;&nbsp;

00:29:32.344 --> 00:29:38.784
don't think it's the best strategy yet to build&nbsp;
one single word model that can do everything.&nbsp;

00:29:38.784 --> 00:29:46.904
CRAIG: And the models that you've built&nbsp;
are are trained or tuned for what domains?&nbsp;

00:29:46.904 --> 00:29:54.744
TIANMIN: So specifically we've tried to&nbsp;
build word models for household domains,&nbsp;&nbsp;

00:29:54.744 --> 00:30:01.824
so we have built at MIT, in our group at MIT, we&nbsp;
built a household simulation called Visual Home.&nbsp;&nbsp;

00:30:01.824 --> 00:30:06.264
So we can build different kinds of apartments.
TIANMIN: You have different kinds of objects in&nbsp;&nbsp;

00:30:06.264 --> 00:30:10.504
an apartment you can interact with. You&nbsp;
can put many different kinds of agents,&nbsp;&nbsp;

00:30:10.504 --> 00:30:16.384
simulated agents in those environments that again,&nbsp;
you can interact with. So in those simulations, we&nbsp;&nbsp;

00:30:16.384 --> 00:30:23.184
can generate embodied experiences as training data&nbsp;
to fine tune this for example, language model or&nbsp;&nbsp;

00:30:23.184 --> 00:30:29.144
different or other type of model as a world model.
TIANMIN: So this is a very different from say&nbsp;&nbsp;

00:30:29.144 --> 00:30:34.704
training a language model on text. And hoping&nbsp;
you can get some knowledge about the words from&nbsp;&nbsp;

00:30:34.704 --> 00:30:40.864
those tasks. Because, again just intuitively&nbsp;
speaking, for humans to understand the words,&nbsp;&nbsp;

00:30:40.864 --> 00:30:45.364
I don't think you can just read books and you&nbsp;
can perfectly understand what could happen.&nbsp;

00:30:45.364 --> 00:30:50.624
TIANMIN: There, there are many details about&nbsp;
the world that won't be described in text. Say&nbsp;&nbsp;

00:30:50.624 --> 00:30:59.784
what happens if I push push this button of the&nbsp;
dishwasher? Or what happens if I open the cabinet&nbsp;&nbsp;

00:30:59.784 --> 00:31:05.784
door, put another object into the cabinet and&nbsp;
then go away a couple of days later, come back,&nbsp;&nbsp;

00:31:05.784 --> 00:31:09.944
how many objects will be there in the cabinet.
TIANMIN: Those kind of knowledge are very common&nbsp;&nbsp;

00:31:09.944 --> 00:31:16.304
to us, but you won't read it from books. But&nbsp;
again, those are common sense knowledge that&nbsp;&nbsp;

00:31:16.304 --> 00:31:24.464
even kids can have. But if you but the idea here&nbsp;
is that if you build embodied agents in those&nbsp;&nbsp;

00:31:24.464 --> 00:31:29.224
simulation environments, ask them to do different&nbsp;
kind of tasks, interact with different agents,&nbsp;&nbsp;

00:31:29.224 --> 00:31:31.588
or even just do random exploration,&nbsp;
you'll get these experiences, right?&nbsp;

00:31:31.588 --> 00:31:43.704
TIANMIN: You'll get say what will be So how many&nbsp;
objects will be in the cabinet after I did this&nbsp;&nbsp;

00:31:43.704 --> 00:31:49.464
sequence of actions? What will happen after I&nbsp;
push this button of the dishwasher? What happen&nbsp;&nbsp;

00:31:49.464 --> 00:31:55.784
if I say, we haven't done that yet, but let's say&nbsp;
what happen if I talk to someone and then I tell&nbsp;&nbsp;

00:31:55.784 --> 00:32:03.664
them that I'm pretty happy today let's hang out&nbsp;
maybe in the afternoon will be the response.&nbsp;

00:32:04.624 --> 00:32:09.784
TIANMIN: But if you can simulate all this and get&nbsp;
a lot of this experience data, then we can train&nbsp;&nbsp;

00:32:09.784 --> 00:32:15.611
a model that can really understand how the world&nbsp;
works or even how people will react to actions.&nbsp;

00:32:15.611 --> 00:32:23.864
CRAIG: Yeah. And for training in a specific&nbsp;
domain, is that done through video or still&nbsp;&nbsp;

00:32:23.864 --> 00:32:30.704
images or text or what is the data that you're&nbsp;
using to train, for example, a household.&nbsp;

00:32:30.704 --> 00:32:34.144
TIANMIN: Technically speaking, you can use&nbsp;
any kind of data that you can get from the&nbsp;&nbsp;

00:32:34.144 --> 00:32:40.904
environment. So we have the vision data for&nbsp;
sure. You can have the ground truth state&nbsp;&nbsp;

00:32:40.904 --> 00:32:47.104
of the objects. And agents, you can translate&nbsp;
those ground truth states into language. So say,&nbsp;&nbsp;

00:32:47.104 --> 00:32:54.544
how many objects are there inside these cabinets?
TIANMIN: You can also there's some simulation that&nbsp;&nbsp;

00:32:54.544 --> 00:33:01.944
allow you to also simulate audio. So you can say&nbsp;
if I drop this ball onto the ground what will be&nbsp;&nbsp;

00:33:01.944 --> 00:33:10.504
the sounds that I can get you can even simulate&nbsp;
touch in some systems. I think in the industry,&nbsp;&nbsp;

00:33:10.504 --> 00:33:18.064
actually in the same group at MIT, they had the&nbsp;
collaboration with, another group that works on&nbsp;&nbsp;

00:33:18.064 --> 00:33:27.344
multimodal sensory. So they have this nature paper&nbsp;
in recent years where they build this glove that&nbsp;&nbsp;

00:33:27.344 --> 00:33:33.824
can allow you to simulate allow you to get touch&nbsp;
sensory. So now imagine if you have some kind of&nbsp;&nbsp;

00:33:33.824 --> 00:33:39.824
VR set up where people can using this, using&nbsp;
the kind of graph interact with different kind&nbsp;&nbsp;

00:33:39.824 --> 00:33:46.384
of objects and can give you the kind of even the&nbsp;
touch sensors. Now you can use those different&nbsp;&nbsp;

00:33:46.384 --> 00:33:53.744
kind of multi modal sensory data to train your&nbsp;
world models. We haven't gone that far yet,&nbsp;&nbsp;

00:33:53.744 --> 00:34:00.504
I think. So the work I tell you about we are&nbsp;
using the ground truth state of the object and&nbsp;&nbsp;

00:34:00.504 --> 00:34:07.344
agents and then translate that into language.
TIANMIN: So we can more easily to train that,&nbsp;&nbsp;

00:34:07.344 --> 00:34:14.944
to understand the world. We have also done another&nbsp;
another part that we have done is, so again,&nbsp;&nbsp;

00:34:14.944 --> 00:34:23.784
we are using states that we can extract from the&nbsp;
images. Particularly to represent a state in the&nbsp;&nbsp;

00:34:23.784 --> 00:34:29.344
environment as a scene graph. So scene graph is&nbsp;
the structure representation about the world.&nbsp;

00:34:29.344 --> 00:34:34.624
TIANMIN: Each node is an object each edge&nbsp;
connecting two nodes representing the spatial&nbsp;&nbsp;

00:34:34.624 --> 00:34:39.224
relationship between two objects. So if you have&nbsp;
a cabinet, you have cabinet nodes. If a cup, you&nbsp;&nbsp;

00:34:39.224 --> 00:34:45.824
have a cup nodes. And then if the inside cabinet,&nbsp;
there will be a inside the edge connecting the cup&nbsp;&nbsp;

00:34:45.824 --> 00:34:54.664
and the cabinet. So this kind of representation&nbsp;
can be extracted from images but it's a pretty&nbsp;&nbsp;

00:34:54.664 --> 00:34:59.184
appealing kind of representation compared to&nbsp;
pixels because from pixel you don't get this&nbsp;&nbsp;

00:34:59.184 --> 00:35:04.984
semantic knowledge about the physical states.
TIANMIN: Now you can, you don't need to represent&nbsp;&nbsp;

00:35:04.984 --> 00:35:09.104
it into language, but you can just use&nbsp;
the symbolic representations of this&nbsp;&nbsp;

00:35:09.104 --> 00:35:15.704
scene graph as the world state, and again, you&nbsp;
can train that model on top of those symbolic&nbsp;&nbsp;

00:35:15.704 --> 00:35:24.544
representations to predict what will happen next.
CRAIG: Yeah. During that training process I&nbsp;&nbsp;

00:35:24.544 --> 00:35:35.264
spoke to somebody a year or so ago, who&nbsp;
was working on a training system that,&nbsp;&nbsp;

00:35:35.264 --> 00:35:44.384
that was hyper speed. So a hundred, I think it&nbsp;
was a million frames a second or some credible&nbsp;&nbsp;

00:35:44.384 --> 00:35:56.344
rate. Do you have to train in real time or can&nbsp;
you train at hyper speed? How long does a system&nbsp;&nbsp;

00:35:56.344 --> 00:36:01.904
need to absorb an image or frame a video?
TIANMIN: Yeah, so I think that depends&nbsp;&nbsp;

00:36:01.904 --> 00:36:07.424
on how data hungry your model is.
TIANMIN: And so say if you want to&nbsp;&nbsp;

00:36:07.424 --> 00:36:12.744
train model free RL, I think you mentioned this,&nbsp;
right? So usually for training model free RL,&nbsp;&nbsp;

00:36:12.744 --> 00:36:18.304
you want your system to be as fast as possible&nbsp;
because it is very data hungry. You have to try&nbsp;&nbsp;

00:36:18.304 --> 00:36:24.544
many different actions. just blindly, only just&nbsp;
blindly, so that you can get enough data to,&nbsp;&nbsp;

00:36:24.544 --> 00:36:30.904
or enough training signal to update your policy.
TIANMIN: If you haven't tried enough, you probably&nbsp;&nbsp;

00:36:30.904 --> 00:36:38.304
have, probably cannot even get any positive&nbsp;
reward at all in some very complex tasks. However,&nbsp;&nbsp;

00:36:38.304 --> 00:36:43.104
I think for training world models, on the&nbsp;
other hand I think the speed is actually&nbsp;&nbsp;

00:36:43.104 --> 00:36:50.904
not the biggest issue. You can just, that's&nbsp;
an algorithm, not algorithm even, just like&nbsp;&nbsp;

00:36:50.904 --> 00:36:55.664
any kind of embodied agent in the simulation.
TIANMIN: That is to explore, try different&nbsp;&nbsp;

00:36:55.664 --> 00:37:00.104
things in the environment for first a&nbsp;
period of time. You're going to get a&nbsp;&nbsp;

00:37:00.104 --> 00:37:05.784
lot of data already. Because again, it's&nbsp;
different from tuning our agents because&nbsp;&nbsp;

00:37:05.784 --> 00:37:10.824
our agent has the rule function that's defined&nbsp;
for a specific goal. You try a lot of things,&nbsp;&nbsp;

00:37:10.824 --> 00:37:17.424
you get a lot observation data, but now those&nbsp;
probably at the beginning are related to a task.&nbsp;

00:37:17.424 --> 00:37:23.224
TIANMIN: So you don't get any positive reward at&nbsp;
all. However for training world model you train on&nbsp;&nbsp;

00:37:23.224 --> 00:37:27.824
random things in the world, a lot of random&nbsp;
thing will happen. And those random things&nbsp;&nbsp;

00:37:27.824 --> 00:37:32.984
happening is actually all the useful training&nbsp;
signal for your world model, right? If I, if&nbsp;&nbsp;

00:37:32.984 --> 00:37:37.464
I. If I push something, something will be moved.
TIANMIN: If I push something down, something will&nbsp;&nbsp;

00:37:37.464 --> 00:37:42.824
be in a different location. If I walk from one&nbsp;
room to another room, I know my location will&nbsp;&nbsp;

00:37:42.824 --> 00:37:50.464
be changed. My observation also will change.&nbsp;
So that gives you many training signals you&nbsp;&nbsp;

00:37:50.464 --> 00:37:56.264
can use. So you don't need to, I think, compared&nbsp;
to at least model free RL agents, you don't need&nbsp;&nbsp;

00:37:56.264 --> 00:38:02.544
to try too many steps to get useful data.
CRAIG: Yeah. And so you've trained in a&nbsp;&nbsp;

00:38:02.544 --> 00:38:10.944
household environment for that domain&nbsp;
is this all in simulation or do you&nbsp;&nbsp;

00:38:11.824 --> 00:38:21.504
have you or is this outside of your area of&nbsp;
research? Have you tried controlling a robot&nbsp;&nbsp;

00:38:21.504 --> 00:38:28.504
with this kind of a world agent model?
TIANMIN: I guess part of my research&nbsp;&nbsp;

00:38:28.504 --> 00:38:32.144
is also in human robot interactions.
TIANMIN: So down the line, we do want&nbsp;&nbsp;

00:38:32.144 --> 00:38:38.544
to evaluate all these models in the real world.&nbsp;
Recently, I haven't done that yet, but there's&nbsp;&nbsp;

00:38:38.544 --> 00:38:42.944
there are other groups that have done that. So&nbsp;
there's, I think we actually mentioned this paper&nbsp;&nbsp;

00:38:42.944 --> 00:38:47.824
in our tutorial. So there's a very recent paper&nbsp;
from AI2, AI2 is the [Allen Institute for AI]&nbsp;&nbsp;

00:38:47.824 --> 00:38:52.864
AI Research Institute in Seattle.
TIANMIN: So they, they show that if&nbsp;&nbsp;

00:38:52.864 --> 00:38:58.704
you want to train a policy, a robot policy&nbsp;
for indoor environment kind of navigation,&nbsp;&nbsp;

00:38:58.704 --> 00:39:07.744
so say, try to find a TV remote for me&nbsp;
or try to train some policy to do simple,&nbsp;&nbsp;

00:39:07.744 --> 00:39:12.704
very simple object manipulation, say,&nbsp;
pick up one glass and give it to me.&nbsp;&nbsp;

00:39:13.424 --> 00:39:19.224
Now and they train this actually on raw pixels.
TIANMIN: So they don't actually turn on ground&nbsp;&nbsp;

00:39:19.224 --> 00:39:25.344
truth world state. So give them pixel that we can&nbsp;
see in front of you and then give the command,&nbsp;&nbsp;

00:39:25.344 --> 00:39:32.824
say find this object for me. You want the robot to&nbsp;
actually navigate and search through the apartment&nbsp;&nbsp;

00:39:32.824 --> 00:39:38.824
and find the object for you. Now, previously&nbsp;
people think Yes, could be a very big domain&nbsp;&nbsp;

00:39:38.824 --> 00:39:43.104
gap between simulation and the real world.
TIANMIN: In fact, I think many robotics&nbsp;&nbsp;

00:39:43.104 --> 00:39:49.224
researchers are actually against using simulation&nbsp;
precisely because they think no matter how good&nbsp;&nbsp;

00:39:49.224 --> 00:39:55.024
simulation is, they're not going to be real.&nbsp;
They're going to be a hundred percent real.&nbsp;&nbsp;

00:39:55.024 --> 00:39:59.264
And particularly if you think about the kind of&nbsp;
policy we want to build here, it's crazy, right?&nbsp;

00:39:59.264 --> 00:40:06.024
TIANMIN: It's actually low pixel inputs and they&nbsp;
are then mapped to some actions. Now the pixel&nbsp;&nbsp;

00:40:06.024 --> 00:40:10.784
rendering from simulation will be definitely&nbsp;
not going to be 100 percent real compared to&nbsp;&nbsp;

00:40:10.784 --> 00:40:16.144
real world images. However, they show that if&nbsp;
you have enough data, you actually do not need&nbsp;&nbsp;

00:40:16.144 --> 00:40:21.304
any kind of real world data to fine tune&nbsp;
the model you're training in simulation.&nbsp;

00:40:21.304 --> 00:40:27.184
TIANMIN: And they can deploy in real world&nbsp;
apartments, and that's the real physical robot&nbsp;&nbsp;

00:40:27.184 --> 00:40:34.824
to do the same kind of test. So I think that's&nbsp;
very promising because the quality of the current&nbsp;&nbsp;

00:40:34.824 --> 00:40:43.224
simulation is already very good. That, that's one.&nbsp;
And second, it allows to generate a lot of data,&nbsp;&nbsp;

00:40:43.224 --> 00:40:47.904
a lot of data you cannot get from the real world.
TIANMIN: And if you have enough data you can get&nbsp;&nbsp;

00:40:47.904 --> 00:40:54.624
very good policies out of it. And I think&nbsp;
it also presents maybe even the third kind&nbsp;&nbsp;

00:40:54.624 --> 00:41:00.344
of opportunities. So when you have a lot of&nbsp;
simulations you have household simulations,&nbsp;&nbsp;

00:41:00.344 --> 00:41:08.184
you have traffic simulations, you have those kind&nbsp;
of objects manipulation simulation for robots,&nbsp;&nbsp;

00:41:08.184 --> 00:41:13.084
you have fluid simulation, you have other kind&nbsp;
of physical fixed engine kind of simulation.&nbsp;

00:41:13.084 --> 00:41:16.344
TIANMIN: You have all these simulation&nbsp;
people have built. You have a model that&nbsp;&nbsp;

00:41:16.344 --> 00:41:23.264
can understand learn like general knowledge about&nbsp;
the world from all these different simulations,&nbsp;&nbsp;

00:41:23.264 --> 00:41:26.704
then those that have knowledge are very&nbsp;
useful for the real world. Even though like&nbsp;&nbsp;

00:41:26.704 --> 00:41:31.424
for individual simulation, they don't represent&nbsp;
the whole world, but if you can combine knowledge&nbsp;&nbsp;

00:41:31.424 --> 00:41:37.064
from different kinds of simulation together,&nbsp;
then you can have a, I guess like a forward&nbsp;&nbsp;

00:41:37.064 --> 00:41:42.304
picture about how the physical world works.
CRAIG: Yeah. And the this is all still in,&nbsp;&nbsp;

00:41:42.304 --> 00:41:50.704
in the research phase but how long do you think&nbsp;
before, this is one kind of agent. There are a&nbsp;&nbsp;

00:41:50.704 --> 00:41:59.104
lot of different strategies to build agents, but&nbsp;
how long do you, how promising do you think this&nbsp;&nbsp;

00:41:59.104 --> 00:42:10.064
method is as opposed to others? And how long do&nbsp;
you think before somebody puts, refines this and&nbsp;&nbsp;

00:42:10.064 --> 00:42:17.664
puts it into a product in the real world?
TIANMIN: I guess like you mentioned Gaia,&nbsp;&nbsp;

00:42:17.664 --> 00:42:23.224
so I don't know exactly how they are using&nbsp;
their simulation for their products. But they&nbsp;&nbsp;

00:42:23.224 --> 00:42:28.064
are startup companies. I don't think they're going&nbsp;
to build anything that's just purely for research&nbsp;&nbsp;

00:42:28.064 --> 00:42:36.864
that have no real value at all. And then I think&nbsp;
also we have things again I mentioned these indoor&nbsp;&nbsp;

00:42:36.864 --> 00:42:40.944
kind of robot navigation kind of tasks, right?
TIANMIN: Those are very useful right? If you&nbsp;&nbsp;

00:42:40.944 --> 00:42:46.664
want to build robots systems that can&nbsp;
help you to do household tasks the,&nbsp;&nbsp;

00:42:46.664 --> 00:42:51.224
one of the most fundamental tasks you're going&nbsp;
to ask a robot to do is to find objects you're&nbsp;&nbsp;

00:42:51.224 --> 00:42:55.864
going to need for whatever the thing you&nbsp;
want to do in the house. Now down the line,&nbsp;&nbsp;

00:42:55.864 --> 00:43:01.304
if you train robots to do more complex tasks&nbsp;
using similar kind of approach, I think will&nbsp;&nbsp;

00:43:01.304 --> 00:43:07.504
be a pretty compelling kind of product for you.
TIANMIN: And then that's definitely going to be&nbsp;&nbsp;

00:43:07.504 --> 00:43:13.904
more useful than Roomba. And I think that&nbsp;
announcing that could be very useful for&nbsp;&nbsp;

00:43:13.904 --> 00:43:19.424
is not just embodied agents, like robots&nbsp;
or self driving cars, but also just say,&nbsp;&nbsp;

00:43:19.424 --> 00:43:25.264
web agents. So think about works interface&nbsp;
or any kind of software interface.&nbsp;

00:43:25.264 --> 00:43:32.464
TIANMIN: As also a world model, like you can&nbsp;
try to figure out how does the interface work&nbsp;&nbsp;

00:43:32.464 --> 00:43:37.224
after you've taken some actions and you&nbsp;
can model it as a kind of virtual world&nbsp;&nbsp;

00:43:37.224 --> 00:43:43.184
model so to speak. Then if you can do that,&nbsp;
you can also build any kind of system agents&nbsp;&nbsp;

00:43:43.184 --> 00:43:51.304
for web interfaces for softwares Et cetera.
CRAIG: Yeah. And so do you think that within&nbsp;&nbsp;

00:43:51.304 --> 00:44:00.744
a year or two years or five years there'll be&nbsp;
whether or not they're embodied or virtual?&nbsp;&nbsp;

00:44:00.744 --> 00:44:11.144
There'll be, people will be working with agents&nbsp;
built on this architecture in various domains.&nbsp;

00:44:11.144 --> 00:44:17.104
TIANMIN: I am not good at predictions, but I&nbsp;
think, embodied agents are always very hard to&nbsp;&nbsp;

00:44:17.104 --> 00:44:22.864
build. Like for example, you would think one&nbsp;
of the most fundamental, most basic kind of&nbsp;&nbsp;

00:44:22.864 --> 00:44:30.104
task for robots, which is grasping an object.&nbsp;
I think some robotics actually ?? says that&nbsp;&nbsp;

00:44:30.104 --> 00:44:34.104
whenever you start to work on grasping,&nbsp;
you can have a whole career ahead of you.&nbsp;

00:44:34.104 --> 00:44:38.384
TIANMIN: It's just a really hard problem&nbsp;
right now. However, if you think about&nbsp;&nbsp;

00:44:38.384 --> 00:44:46.144
simplified tasks that doesn't require a lot&nbsp;
of very compact physical manipulation say,&nbsp;&nbsp;

00:44:46.144 --> 00:44:51.224
maybe like web interfaces or some kind of&nbsp;
virtual assistants that can help you to do&nbsp;&nbsp;

00:44:51.224 --> 00:44:58.144
some tasks. I think that could happen easily.
TIANMIN: I think there are already people&nbsp;&nbsp;

00:44:58.144 --> 00:45:05.344
building, trying to build such for that&nbsp;
as well. And I think also maybe even say,&nbsp;&nbsp;

00:45:05.344 --> 00:45:13.024
for embodied agents. For very not very,&nbsp;
but somewhat rigid environments. So say&nbsp;&nbsp;

00:45:14.744 --> 00:45:24.024
in I don't know warehouses or factories&nbsp;
again, they are already products like that,&nbsp;&nbsp;

00:45:24.024 --> 00:45:31.344
but I think with better AI models, you can&nbsp;
have more powerful kind of robot coworkers&nbsp;&nbsp;

00:45:32.184 --> 00:45:37.024
in those more rigid environments.
CRAIG: Yeah. But do you know of any&nbsp;&nbsp;

00:45:37.024 --> 00:45:42.264
commercial enterprise that's taking&nbsp;
your research and implementing it?&nbsp;

00:45:42.264 --> 00:45:46.944
TIANMIN: Right now, I don't think so.&nbsp;
I don't have that knowledge. Yeah.&nbsp;

00:45:46.944 --> 00:46:00.384
CRAIG: Yeah. It's fascinating research.&nbsp;
So I see you refer to it as LAW,&nbsp;

00:46:00.384 --> 00:46:04.624
TIANMIN: language model,&nbsp;
agent model, and world model.&nbsp;

00:46:04.624 --> 00:46:12.737
CRAIG: Yeah. I see that LAW. I don't&nbsp;
know if that's a term you use. Yeah.&nbsp;

00:46:12.737 --> 00:46:19.784
CRAIG: Okay. So what's next in your research?
TIANMIN: So like I said, building one models&nbsp;&nbsp;

00:46:19.784 --> 00:46:27.104
and also agent models. I think that's very&nbsp;
fascinating direction for me. And also for&nbsp;&nbsp;

00:46:27.104 --> 00:46:32.104
many people now, and hopefully what people&nbsp;
are finding fascinating and work on that.&nbsp;

00:46:32.104 --> 00:46:37.384
TIANMIN: But I think another thing, and I'm really&nbsp;
interested in is social learning, which was also&nbsp;&nbsp;

00:46:37.384 --> 00:46:43.504
talked a little bit about in the tutorial. So you&nbsp;
have a model that can learn on its own, but think&nbsp;&nbsp;

00:46:43.504 --> 00:46:49.584
about humans actually learn a lot of things. with&nbsp;
each other or from other people, right? And we can&nbsp;&nbsp;

00:46:49.584 --> 00:46:55.344
also teach knowledge we learn to other people.
TIANMIN: So how we can actually build models&nbsp;&nbsp;

00:46:55.344 --> 00:46:59.704
that can, or agents, that can also&nbsp;
learn with humans, learn for humans,&nbsp;&nbsp;

00:46:59.704 --> 00:47:05.024
or learn from humans. I think that's another&nbsp;
kind of direction I really want to work on.

