WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.000
Thomas: 0:00
Tech professionals,&nbsp;&nbsp;

00:00:01.000 --> 00:00:05.240
they're trying to figure out how do I apply AI,&nbsp;
and one of the muscles they have to build is,&nbsp;&nbsp;

00:00:05.240 --> 00:00:10.680
how do you evaluate this plethora of tools&nbsp;
that have come out of the woodwork? And just&nbsp;&nbsp;

00:00:10.680 --> 00:00:13.480
talking to different folks, that&nbsp;
is, again, a skill that you have&nbsp;&nbsp;

00:00:13.480 --> 00:00:18.120
to mature so you can kind of poke through&nbsp;
and say, okay, that tool looks really cool,&nbsp;&nbsp;

00:00:18.120 --> 00:00:21.840
but it's not going to scale for us, not going&nbsp;
to be practical. This tool over here, much more&nbsp;&nbsp;

00:00:21.840 --> 00:00:27.869
practical. So that's still early days, but it&nbsp;
is pretty amazing how rapidly it's maturing.

00:00:27.869 --> 00:00:29.520
Craig: 0:27
Hi, I'm Craig Smith,&nbsp;&nbsp;

00:00:29.520 --> 00:00:35.320
and this is Eye on AI. In this episode,&nbsp;
I speak with Thomas Lah, the Executive&nbsp;&nbsp;

00:00:35.320 --> 00:00:44.200
Director for the Technology and Services Industry&nbsp;
Association, TSIA. While you assume tech companies&nbsp;&nbsp;

00:00:44.200 --> 00:00:50.960
offering AI-powered products are way ahead of&nbsp;
everybody else in using AI in their operations,&nbsp;&nbsp;

00:00:50.960 --> 00:00:56.800
it turns out they're having as much trouble&nbsp;
as non-tech companies. Thomas delves into how&nbsp;&nbsp;

00:00:56.800 --> 00:01:04.240
AI is transforming internal processes such&nbsp;
as content development, support services,&nbsp;&nbsp;

00:01:04.240 --> 00:01:11.440
and field services, and discusses the challenges&nbsp;
and opportunities tech companies face in&nbsp;&nbsp;

00:01:11.440 --> 00:01:19.068
integrating AI into their workloads. I hope you&nbsp;
find the conversation as informative as I did.

00:01:19.068 --> 00:01:20.040
Craig: 1:19
AI might be the&nbsp;&nbsp;

00:01:20.040 --> 00:01:26.000
most important new computer technology ever.&nbsp;
It's storming every industry, and literally&nbsp;&nbsp;

00:01:26.000 --> 00:01:31.360
billions of dollars are being invested. So,&nbsp;
buckle up. The problem is that AI needs a&nbsp;&nbsp;

00:01:31.360 --> 00:01:37.880
lot of speed and processing power. So how do you&nbsp;
compete without costs spiraling out of control?&nbsp;&nbsp;

00:01:37.880 --> 00:01:44.040
It's time to upgrade to the next generation&nbsp;
of the cloud, Oracle Cloud Infrastructure,&nbsp;&nbsp;

00:01:44.040 --> 00:01:51.720
or OCI. OCI is a single platform for your&nbsp;
infrastructure, database, application development,&nbsp;&nbsp;

00:01:51.720 --> 00:01:59.560
and AI needs. OCI has four to eight times the&nbsp;
bandwidth of other clouds, offers one consistent&nbsp;&nbsp;

00:01:59.560 --> 00:02:06.440
price instead of variable regional pricing, and&nbsp;
of course, nobody does data better than Oracle.&nbsp;&nbsp;

00:02:06.440 --> 00:02:13.800
So now you can train your AI models at twice the&nbsp;
speed and less than half the cost of other clouds.&nbsp;&nbsp;

00:02:13.800 --> 00:02:20.560
If you want to do more and spend less, like&nbsp;
Uber, 8x8, and Databricks Mosaic, take a free&nbsp;&nbsp;

00:02:20.560 --> 00:02:30.989
test drive of OCI at oracle.com/eyeonai.&nbsp;
That's E-Y-E-O-N-A-I, all run together.

00:02:30.989 --> 00:02:34.108
Craig: 2:31
So, Thomas, go ahead. Can you introduce yourself?

00:02:34.108 --> 00:02:34.720
Thomas: 2:34
Yeah, absolutely. So,&nbsp;&nbsp;

00:02:34.720 --> 00:02:39.040
I am Thomas Lah. I serve as the executive&nbsp;
director for the Technology and Services&nbsp;&nbsp;

00:02:39.040 --> 00:02:42.960
Industry Association. We are a for-profit&nbsp;
research institute. We've been around almost&nbsp;&nbsp;

00:02:42.960 --> 00:02:49.000
20 years. We focus on technology business&nbsp;
models. We get companies basically under NDA,&nbsp;&nbsp;

00:02:49.000 --> 00:02:53.709
and we do a lot of benchmarking and&nbsp;
research on their operating models.

00:02:53.709 --> 00:02:54.760
Craig: 2:53
Yeah, and you're talking&nbsp;&nbsp;

00:02:54.760 --> 00:03:02.428
about companies that are using technology or&nbsp;
companies that are providing tech infrastructure?

00:03:02.428 --> 00:03:04.680
Thomas: 3:01
Companies that are providing basically&nbsp;&nbsp;

00:03:04.680 --> 00:03:09.640
enterprise technology. So, if you think about a&nbsp;
Microsoft, if you think about a Cisco, a Dell,&nbsp;&nbsp;

00:03:09.640 --> 00:03:15.160
all those companies are members, Salesforce.&nbsp;
And what's also interesting in that is more&nbsp;&nbsp;

00:03:15.160 --> 00:03:21.960
of older companies, think of somebody like a John&nbsp;
Deere, as they start to get into AI and software,&nbsp;&nbsp;

00:03:21.960 --> 00:03:28.840
Rockwell Automation, Siemens, all those companies&nbsp;
now are members of TSIA. And again, our lens is,&nbsp;&nbsp;

00:03:28.840 --> 00:03:33.920
if you're providing hardware or software,&nbsp;
what is the operating model around that?&nbsp;&nbsp;

00:03:33.920 --> 00:03:38.789
How you monetize, selling product versus&nbsp;
services, all that kind of fun stuff.

00:03:38.789 --> 00:03:40.720
Craig: 3:38
Yeah. And so, do you guys&nbsp;&nbsp;

00:03:40.720 --> 00:03:48.188
operate as kind of a consulting company or just&nbsp;
as a place to exchange information among members?

00:03:48.188 --> 00:03:49.400
Thomas: 3:47
Yeah, it's a great question. So,&nbsp;&nbsp;

00:03:49.400 --> 00:03:54.760
our model is to do operational&nbsp;
research, play that, you know,&nbsp;&nbsp;

00:03:54.760 --> 00:03:58.520
those insights back to members to help them&nbsp;
implement the best practices, optimize their&nbsp;&nbsp;

00:03:58.520 --> 00:04:04.720
performance metrics. We do light advisory work.&nbsp;
We very deliberately do not get into, you know,&nbsp;&nbsp;

00:04:04.720 --> 00:04:08.560
big, heavy consulting. That's not our model.&nbsp;
We want to have a one-to-many, get people to&nbsp;&nbsp;

00:04:08.560 --> 00:04:15.000
answers as quickly as possible, and quite frankly,&nbsp;
avoid some of the exploratory consulting you have&nbsp;&nbsp;

00:04:15.000 --> 00:04:18.040
to do to get to a right answer. We're like,&nbsp;
hey, we already know the right answer. We've,&nbsp;&nbsp;

00:04:18.040 --> 00:04:22.149
you know, we've talked to tons of companies&nbsp;
on this. Here's what you should be pursuing.

00:04:22.149 --> 00:04:23.200
Craig: 4:21
Yeah,&nbsp;&nbsp;

00:04:23.200 --> 00:04:27.348
and what's your background?&nbsp;
How long have you been at TSIA?

00:04:27.348 --> 00:04:28.560
Thomas: 4:27
Yeah, yeah. So,&nbsp;&nbsp;

00:04:28.560 --> 00:04:33.960
I was at Silicon Valley, a company called&nbsp;
Silicon Graphics, where I worked for about&nbsp;&nbsp;

00:04:33.960 --> 00:04:38.440
eight years within their service organization.&nbsp;
So, I really kind of learned directly what it&nbsp;&nbsp;

00:04:38.440 --> 00:04:42.800
meant to build services when you're also&nbsp;
providing, you know, technology and the&nbsp;&nbsp;

00:04:42.800 --> 00:04:46.520
good and the bad and the ugly of that. And that&nbsp;
inspired me to write a book. And since then, I've&nbsp;&nbsp;

00:04:46.520 --> 00:04:51.709
written seven books on technology business models&nbsp;
and have been doing research on it ever since.

00:04:51.709 --> 00:04:54.240
Craig: 4:52
Yeah, and a lot&nbsp;&nbsp;

00:04:54.240 --> 00:05:02.080
of tech companies are both builders and service&nbsp;
providers these days. I mean, as a matter of fact,&nbsp;&nbsp;

00:05:02.080 --> 00:05:08.308
I'm not sure if I can think of one that&nbsp;
is not. Is that an accurate perception?

00:05:08.308 --> 00:05:10.560
Thomas: 5:07
Yeah, I mean, the big transformation&nbsp;&nbsp;

00:05:10.560 --> 00:05:17.000
that has occurred with enterprise technology&nbsp;
companies over the last decade or so, and,&nbsp;&nbsp;

00:05:17.000 --> 00:05:21.720
you know, you can pick on a Cisco, you can pick&nbsp;
on a Microsoft. These companies, their preferred&nbsp;&nbsp;

00:05:21.720 --> 00:05:27.600
model is to create great technology, whether&nbsp;
it's a piece of hardware, a piece of software;&nbsp;&nbsp;

00:05:27.600 --> 00:05:32.440
launch it into the world, have, you know,&nbsp;
partners worried about implementing it and helping&nbsp;&nbsp;

00:05:32.440 --> 00:05:38.920
customers, you know, optimize it, et cetera. They&nbsp;
want to focus on creating the core technology.&nbsp;&nbsp;

00:05:38.920 --> 00:05:43.240
What's happened over the years is, especially&nbsp;
when you're dealing with complex enterprises,&nbsp;&nbsp;

00:05:43.240 --> 00:05:48.600
is that these customers want to make sure they're&nbsp;
really adopting and getting the business value&nbsp;&nbsp;

00:05:48.600 --> 00:05:53.880
from the technology. So, the services component&nbsp;
has become important in terms of really making&nbsp;&nbsp;

00:05:53.880 --> 00:05:58.800
sure that customers can adopt, get the value&nbsp;
realization. So, all those companies have support&nbsp;&nbsp;

00:05:58.800 --> 00:06:02.960
services. They have education services. They have&nbsp;
some level of consulting. They have work that&nbsp;&nbsp;

00:06:02.960 --> 00:06:09.468
they do to enable partners. So, it's definitely&nbsp;
more of a blended model than it has ever been.

00:06:09.468 --> 00:06:14.040
Craig: 6:09
Yeah, and I would guess that AI and generative AI&nbsp;&nbsp;

00:06:14.040 --> 00:06:22.640
in particular is sort of like a bull in the China&nbsp;
shop of TSIA because literally every tech company,&nbsp;&nbsp;

00:06:22.640 --> 00:06:30.708
every technology services company is trying to&nbsp;
rewrite their product from an GenAI perspective.

00:06:30.708 --> 00:06:33.720
Thomas: 6:30
Well, there's sort of two&nbsp;&nbsp;

00:06:33.720 --> 00:06:39.720
lenses on this when you think about AI within&nbsp;
the tech industry. So, one lens is if, again,&nbsp;&nbsp;

00:06:39.720 --> 00:06:46.280
if I'm at Microsoft, if I'm a ServiceNow, if I'm&nbsp;
a Salesforce, they all want to basically have AI&nbsp;&nbsp;

00:06:46.280 --> 00:06:51.360
capabilities that they're implementing into their&nbsp;
products and promoting out into the world, right,&nbsp;&nbsp;

00:06:51.360 --> 00:06:56.400
and placing their bets there. And so that's one&nbsp;
thing that everybody's, you know, working to do&nbsp;&nbsp;

00:06:56.400 --> 00:07:04.160
and scrambling to do. We're actually focused on&nbsp;
the other lens, which is, how is AI changing the&nbsp;&nbsp;

00:07:04.160 --> 00:07:09.400
way they are operating internally? Everything from&nbsp;
how they develop the products to okay, now we're&nbsp;&nbsp;

00:07:09.400 --> 00:07:15.000
going to, you know, service the products, educate&nbsp;
customers— all those workflows, how are they&nbsp;&nbsp;

00:07:15.000 --> 00:07:21.520
being impacted right now, by the potential of AI?&nbsp;
Because, you know, we think there, we don't think,&nbsp;&nbsp;

00:07:21.520 --> 00:07:27.680
we know there's a massive there there already.&nbsp;
And you use the term “bull in the China shop”,&nbsp;&nbsp;

00:07:27.680 --> 00:07:33.280
it's exactly what's going on. Everyone's like,&nbsp;
whoa, this is really, you know, a game changer.&nbsp;&nbsp;

00:07:33.280 --> 00:07:38.600
And so that's what we are really laser focused&nbsp;
on; is helping people understand where the most&nbsp;&nbsp;

00:07:38.600 --> 00:07:43.400
compelling use cases are, separate the hype&nbsp;
from the reality, all that kind of fun stuff&nbsp;&nbsp;

00:07:43.400 --> 00:07:48.989
is this really, becomes something that is going&nbsp;
to just be ubiquitous within operating models.

00:07:48.989 --> 00:07:49.880
Craig: 7:48
And it's going, it's going&nbsp;&nbsp;

00:07:49.880 --> 00:07:58.480
to get even more disruptive or confusing. I've&nbsp;
been talking to people about agents, you know,&nbsp;&nbsp;

00:07:58.480 --> 00:08:08.080
AI agents, AI models that can take actions in,&nbsp;
even in the physical world, I would guess that&nbsp;&nbsp;

00:08:08.080 --> 00:08:14.389
all tech companies are crawling through their&nbsp;
operations to see where that can be applied.

00:08:14.389 --> 00:08:17.520
Craig: 8:14
So, your members&nbsp;&nbsp;

00:08:17.520 --> 00:08:27.280
are focused on getting their technology into&nbsp;
the hands of enterprise and having enterprise&nbsp;&nbsp;

00:08:27.280 --> 00:08:33.760
adopt their technology. But at the same time,&nbsp;
there's this foundational technology that's&nbsp;&nbsp;

00:08:33.760 --> 00:08:39.680
appearing and your members have to figure&nbsp;
out how to integrate that into their own&nbsp;&nbsp;

00:08:39.680 --> 00:08:46.800
operations. And how do you go about advising&nbsp;
on that? Or how are people thinking about that?

00:08:46.800 --> 00:08:50.400
Thomas: 8:49
Yeah, so, this is the way that&nbsp;&nbsp;

00:08:50.400 --> 00:08:57.560
we've approached this for our member companies.&nbsp;
So, you know, I'm sure you're familiar with the&nbsp;&nbsp;

00:08:57.560 --> 00:09:02.160
AI framework, talks about AI capabilities&nbsp;
that are below the water line, you know,&nbsp;&nbsp;

00:09:02.160 --> 00:09:06.720
they've become very common at the waterline&nbsp;
versus they're way up on the mountain still,&nbsp;&nbsp;

00:09:06.720 --> 00:09:11.840
right. And so, I think one of the first things&nbsp;
that people are struggling with, leadership teams,&nbsp;&nbsp;

00:09:11.840 --> 00:09:17.840
is, you know, understanding that landscape, what&nbsp;
is really mature? What are the use cases that are&nbsp;&nbsp;

00:09:17.840 --> 00:09:24.000
right here, versus stuff that really is futures.&nbsp;
And so, we tracked that— we continue to track,&nbsp;&nbsp;

00:09:24.000 --> 00:09:29.360
we did our first cut last year. And we think&nbsp;
about AI capabilities below the waterline&nbsp;&nbsp;

00:09:29.360 --> 00:09:35.240
all the way up to way above, across seven&nbsp;
different areas, areas like customer success,&nbsp;&nbsp;

00:09:35.240 --> 00:09:40.560
areas like support, are people using support&nbsp;
agents, areas like education services, etc. So,&nbsp;&nbsp;

00:09:41.360 --> 00:09:47.000
we take snapshots for the members. And it was&nbsp;
amazing, the first snapshot we did last year,&nbsp;&nbsp;

00:09:48.040 --> 00:09:54.800
we identified, the research team identified over&nbsp;
70 use cases, they were already out there, right,&nbsp;&nbsp;

00:09:54.800 --> 00:09:59.600
across these areas. And then what we've been doing&nbsp;
is just clicking into those use cases in more&nbsp;&nbsp;

00:09:59.600 --> 00:10:05.440
detail to understand, you know, what's working and&nbsp;
what's not. And so, I'll just give you some very&nbsp;&nbsp;

00:10:05.440 --> 00:10:12.640
practical real-world examples, right, we've been&nbsp;
identifying with the past couple of months. So,&nbsp;&nbsp;

00:10:12.640 --> 00:10:18.720
this concept of copilots, right, so Microsoft&nbsp;
has a copilot. Well, the real there there for&nbsp;&nbsp;

00:10:18.720 --> 00:10:24.840
enterprise cases is where people, you know,&nbsp;
enterprises make that unique to them. So, Nokia&nbsp;&nbsp;

00:10:24.840 --> 00:10:31.200
has a copilot targeted at telecom engineers. So,&nbsp;
it's very specific to their language, helps with&nbsp;&nbsp;

00:10:31.200 --> 00:10:38.560
support. Dell has the same thing for support. Open&nbsp;
Text is a member that's done just incredible work&nbsp;&nbsp;

00:10:38.560 --> 00:10:43.880
on leveraging AI to generate educational service&nbsp;
content. And one of the biggest issues these tech&nbsp;&nbsp;

00:10:43.880 --> 00:10:50.360
companies have is, you know, technology can be&nbsp;
complex, members don't adopt all the features,&nbsp;&nbsp;

00:10:50.360 --> 00:10:55.200
right? There's, there's too much. And so, if you&nbsp;
can do a much better job of building education&nbsp;&nbsp;

00:10:55.200 --> 00:10:59.960
materials that are, you know, more persona&nbsp;
driven, more customized, local language, all&nbsp;&nbsp;

00:10:59.960 --> 00:11:06.800
that fun stuff. So that's another example. So, we&nbsp;
we are just finding use case after use case that&nbsp;&nbsp;

00:11:06.800 --> 00:11:15.908
there is real ROI there, real impact already and&nbsp;
so that's, you know, what we're super focused on.

00:11:15.908 --> 00:11:18.680
Craig: 11:16
Yeah, and you mentioned copilot,&nbsp;&nbsp;

00:11:21.280 --> 00:11:29.800
I would guess that there's no bias within TSIA&nbsp;
toward one company's tech or another but there&nbsp;&nbsp;

00:11:29.800 --> 00:11:40.240
is CodeWhisperer and some others. How do&nbsp;
you— do you do you make an effort to talk&nbsp;&nbsp;

00:11:40.240 --> 00:11:51.467
generically about these things or do some tools&nbsp;
become so dominant that you're you're talking—

00:11:51.467 --> 00:11:53.680
Thomas: 11:51
Yeah, yeah, and we are we're, because we&nbsp;&nbsp;

00:11:53.680 --> 00:11:59.800
have pretty much all the the tool providers on the&nbsp;
platform, we're agnostic. What we do for members&nbsp;&nbsp;

00:11:59.800 --> 00:12:06.480
when we're doing these case studies is, we will&nbsp;
ask them, you know, what tools, AI tools are you&nbsp;&nbsp;

00:12:06.480 --> 00:12:12.240
leveraging? Is it off the shelf, are you taking&nbsp;
something open source and modifying? And then we&nbsp;&nbsp;

00:12:12.240 --> 00:12:16.560
will play that back to folks so they can start&nbsp;
to see the pattern recognition. And it's still,&nbsp;&nbsp;

00:12:16.560 --> 00:12:23.200
it's interesting, it's still, early days. A lot&nbsp;
of the tools are immature. I think one of the&nbsp;&nbsp;

00:12:23.200 --> 00:12:29.960
interesting things we're finding for, you know,&nbsp;
enterprise companies, for tech professionals,&nbsp;&nbsp;

00:12:29.960 --> 00:12:34.600
they're trying to figure out how do I apply AI.&nbsp;
And one of the muscles they have to build is,&nbsp;&nbsp;

00:12:34.600 --> 00:12:42.080
how do you evaluate this plethora of tools&nbsp;
that have come out of the woodwork? And just&nbsp;&nbsp;

00:12:42.080 --> 00:12:46.560
talking to different folks, that is, again a&nbsp;
skill that you have to mature so you can kind&nbsp;&nbsp;

00:12:46.560 --> 00:12:51.360
of poke through and say, okay that tool looks&nbsp;
really cool but it's not going to scale for us,&nbsp;&nbsp;

00:12:51.360 --> 00:12:55.360
not going to be practical, this tool over here,&nbsp;
much more practical. So that's still early,&nbsp;&nbsp;

00:12:55.360 --> 00:13:01.680
early days but it is pretty amazing how rapidly&nbsp;
it's maturing, and I'll just pick on this area&nbsp;&nbsp;

00:13:01.680 --> 00:13:05.840
of education services. This case study, I was&nbsp;
talking to the woman that runs education services&nbsp;&nbsp;

00:13:05.840 --> 00:13:10.440
at OpenText and then they started this journey&nbsp;
of how they're going to leverage AI for content&nbsp;&nbsp;

00:13:10.440 --> 00:13:13.880
development. It was probably about, I don't know,&nbsp;
a year and a half, two years ago she said they&nbsp;&nbsp;

00:13:13.880 --> 00:13:19.760
started. And they were literally, like, just&nbsp;
beta testing a tool with their Canadian base,&nbsp;&nbsp;

00:13:19.760 --> 00:13:24.600
with a Canadian-based company and really almost&nbsp;
like co-developing the capabilities of that tool&nbsp;&nbsp;

00:13:24.600 --> 00:13:32.200
with them. Today, she said, you know, what we&nbsp;
were doing with them co-developing two years ago,&nbsp;&nbsp;

00:13:32.200 --> 00:13:37.000
that is now just all off-the-shelf capability&nbsp;
that another education service, you know,&nbsp;&nbsp;

00:13:37.000 --> 00:13:44.188
organization can just onboard immediately and take&nbsp;
off running. So, it is maturing rapidly for sure.

00:13:44.188 --> 00:13:45.680
Craig: 13:44
Yeah, and that's kind of a cautionary&nbsp;&nbsp;

00:13:45.680 --> 00:13:52.440
tale. I mean, I talk to not necessarily tech&nbsp;
enterprises, but enterprises about developing,&nbsp;&nbsp;

00:13:52.440 --> 00:14:01.080
about adopting AI and you know it's C-suite&nbsp;
executives are kind of a deer in the headlights&nbsp;&nbsp;

00:14:01.080 --> 00:14:09.280
because there's, in any category there are a dozen&nbsp;
offerings and you don't want to invest in training&nbsp;&nbsp;

00:14:09.280 --> 00:14:17.360
up people and buying the tech and everything and&nbsp;
find out that you bet on the losing horse. So,&nbsp;&nbsp;

00:14:17.360 --> 00:14:22.520
a lot of people are waiting. Is the same thing&nbsp;
happening in the tech services industry?
 &nbsp;

00:14:23.640 --> 00:14:24.400
Thomas: 14:22
Well, I think there's&nbsp;&nbsp;

00:14:24.400 --> 00:14:31.000
a couple different flavors of this, right? So, if&nbsp;
you're a company that has your own AI capability&nbsp;&nbsp;

00:14:31.000 --> 00:14:35.280
that you're already investing in heavily, if&nbsp;
you pick a Microsoft, you pick a ServiceNow,&nbsp;&nbsp;

00:14:35.280 --> 00:14:39.840
then those organizations are aggressively&nbsp;
applying that for internal use cases. Right,&nbsp;&nbsp;

00:14:39.840 --> 00:14:43.800
they don't have to blink. They know that they're&nbsp;
committed to that and they're getting the benefits&nbsp;&nbsp;

00:14:43.800 --> 00:14:48.960
that they can. So, I think that's one use case.&nbsp;
I think the other use cases are some of the tools&nbsp;&nbsp;

00:14:48.960 --> 00:14:54.800
that are already proving to be mature. They're out&nbsp;
there and so I think people can jump on those. And&nbsp;&nbsp;

00:14:54.800 --> 00:15:00.400
there's a third use case, which is you're right,&nbsp;
there's still, maybe that particular area of AI&nbsp;&nbsp;

00:15:00.400 --> 00:15:02.040
is still maturing.
 
Thomas: 15:02&nbsp;

00:15:02.040 --> 00:15:06.080
My cautionary tale, though, to these executive&nbsp;
teams, because I agree with what you're saying.&nbsp;&nbsp;

00:15:06.080 --> 00:15:12.920
I think when you go in and you speak to, you know,&nbsp;
the more senior, the bigger this gap is. I mean,&nbsp;&nbsp;

00:15:12.920 --> 00:15:18.680
these people have really zero experience with AI&nbsp;
because it is new, right. So, think about being&nbsp;&nbsp;

00:15:18.680 --> 00:15:22.800
an executive your whole life. You know, you're&nbsp;
building a business, you know it works, and this&nbsp;&nbsp;

00:15:22.800 --> 00:15:28.360
whole new thing comes along and you're trying to&nbsp;
figure out okay, what does that really mean to my&nbsp;&nbsp;

00:15:28.360 --> 00:15:33.440
company? And I have no experience and I’m looking&nbsp;
left and right and no of us have any experience.&nbsp;&nbsp;

00:15:33.440 --> 00:15:42.840
So, the common reaction I’m seeing is this sort of&nbsp;
mañana strategy- let me just take a deep breath,&nbsp;&nbsp;

00:15:42.840 --> 00:15:48.400
you know, let’s wait until everybody else figures&nbsp;
out the tools and then we'll kind of jump on it.&nbsp;&nbsp;

00:15:48.400 --> 00:15:52.760
And I understand and appreciate the caution.
 
Thomas: 15:52&nbsp;

00:15:52.760 --> 00:15:59.960
But my greater concern is I don't think that these&nbsp;
executive teams are internalizing how massively&nbsp;&nbsp;

00:15:59.960 --> 00:16:05.000
disruptive this is going to be to their operating&nbsp;
models. And my concern is if they're not starting&nbsp;&nbsp;

00:16:05.000 --> 00:16:10.760
to lean in now and saying, hey, we got to start&nbsp;
understanding some of the use cases, we've got to&nbsp;&nbsp;

00:16:10.760 --> 00:16:16.640
start piloting some of the more proven use cases,&nbsp;
we've got to start getting basically experience&nbsp;&nbsp;

00:16:16.640 --> 00:16:23.080
with what it means to use AI and change. If we're&nbsp;
not doing any of that right now, every month,&nbsp;&nbsp;

00:16:23.080 --> 00:16:29.640
every quarter that goes by, there's a bigger gap&nbsp;
between your operating costs and somebody who's&nbsp;&nbsp;

00:16:29.640 --> 00:16:35.600
figured this out. And again, I think it's going&nbsp;
to move fast. And so, pick a horizon. In two,&nbsp;&nbsp;

00:16:35.600 --> 00:16:42.520
three years you could wake up and say my&nbsp;
cost structure is 20, 30, 40% higher than&nbsp;&nbsp;

00:16:42.520 --> 00:16:48.068
my competitors because I had this wait and see&nbsp;
mentality and I think there's a real risk there.
 &nbsp;

00:16:48.068 --> 00:16:49.320
Craig: 16:48
Yeah, although there's also&nbsp;&nbsp;

00:16:49.320 --> 00:16:57.065
kind of an art to timing. I mean that example&nbsp;
you gave of the education company spending—
 &nbsp;

00:16:57.065 --> 00:16:58.040
Thomas: 16:57
A year and a half, two years,&nbsp;&nbsp;

00:16:58.040 --> 00:16:59.720
yeah, working on it, yeah.
 
Craig: 16:59&nbsp;

00:16:59.720 --> 00:17:05.320
There's a big cost associated with that and if by&nbsp;
the time you're through those two years, you've&nbsp;&nbsp;

00:17:05.320 --> 00:17:10.920
committed to this technology, suddenly there are&nbsp;
all these other off-the-shelf solutions. Your&nbsp;&nbsp;

00:17:10.920 --> 00:17:16.227
competitors can pick up and be right where you&nbsp;
are without having invested that time and money.
 &nbsp;

00:17:16.227 --> 00:17:19.200
Thomas: 17:16
Well, and I think, but if you think about, so,&nbsp;&nbsp;

00:17:19.200 --> 00:17:24.920
let's think about the components of implementing&nbsp;
an AI solution, right? So, one of them is clearly&nbsp;&nbsp;

00:17:24.920 --> 00:17:30.200
just, what am I going to spend on a core piece of&nbsp;
software or technology? The other components are&nbsp;&nbsp;

00:17:30.200 --> 00:17:37.200
understanding, you know, how my professionals,&nbsp;
how my employees are going to work differently,&nbsp;&nbsp;

00:17:37.200 --> 00:17:41.787
and there's a curve on that, right? So, let's&nbsp;
keep just stay on this education thread.
 &nbsp;

00:17:41.787 --> 00:17:44.200
Thomas: 17:42
So, one of the big advantages&nbsp;&nbsp;

00:17:44.200 --> 00:17:51.120
of AI and education is around content development&nbsp;
and how you can use AI. So if you're, let's say,&nbsp;&nbsp;

00:17:51.120 --> 00:17:55.880
you, have a team of content developers who are&nbsp;
professionals, have been doing this for a while,&nbsp;&nbsp;

00:17:55.880 --> 00:18:00.320
they're very good at it, but they have a certain&nbsp;
way of developing content that they've been doing&nbsp;&nbsp;

00:18:00.320 --> 00:18:04.360
for years and years and years, and you don't just&nbsp;
snap your fingers and say, well, here's this new&nbsp;&nbsp;

00:18:04.360 --> 00:18:10.960
tool and voila, you've changed your workflow&nbsp;
and you're proficient- there's a curve there,&nbsp;&nbsp;

00:18:10.960 --> 00:18:16.760
right? So, again, my nervousness is if you're&nbsp;
not building any experience with what it means&nbsp;&nbsp;

00:18:16.760 --> 00:18:21.880
to integrate AI into your workflows and you're&nbsp;
waiting, waiting, waiting to place the safest&nbsp;&nbsp;

00:18:21.880 --> 00:18:29.320
bet possible on the technology; there's still a&nbsp;
gap there which I think is a little concerning.
 &nbsp;

00:18:29.320 --> 00:18:34.520
Craig: 18:30
Yeah, you would assume that technology services&nbsp;&nbsp;

00:18:34.520 --> 00:18:39.000
companies are quicker on the uptake than not.
 
Thomas: 18:39&nbsp;

00:18:39.000 --> 00:18:44.680
I spent a lot of time briefing these executive&nbsp;
teams on the state of technology business models,&nbsp;&nbsp;

00:18:44.680 --> 00:18:49.200
right. What's driving profitability, where we&nbsp;
see headwinds, what are-. And in every one of&nbsp;&nbsp;

00:18:49.200 --> 00:18:55.280
these briefings for the past 12 months, I&nbsp;
put this topic of AI on the table. Right,&nbsp;&nbsp;

00:18:55.280 --> 00:19:00.160
and we do a lot of survey work in this. So, you&nbsp;
ask questions like, do you have a senior executive&nbsp;&nbsp;

00:19:00.160 --> 00:19:07.520
assigned to AI, your AI strategy? Do you have a&nbsp;
clear budget? Do you have processes to share best&nbsp;&nbsp;

00:19:07.520 --> 00:19:11.960
practices of implementing AI across departments?&nbsp;
So, you can test on these types of practices.
 &nbsp;

00:19:11.960 --> 00:19:16.960
Thomas: 19:11
And you know tech, I think, has&nbsp;&nbsp;

00:19:16.960 --> 00:19:21.400
the same challenges that almost any industry does&nbsp;
on this right now. Again, it's such a new thing.&nbsp;&nbsp;

00:19:21.400 --> 00:19:28.240
They're not sure how to organize around it, they&nbsp;
have data problems like everybody has internally.&nbsp;&nbsp;

00:19:28.240 --> 00:19:33.880
Just because they’re tech doesn't mean that&nbsp;
their data is clean, and so there's sort of this&nbsp;&nbsp;

00:19:33.880 --> 00:19:39.080
paradox. When you read something in the business&nbsp;
press, if you look at the industries that are&nbsp;&nbsp;

00:19:39.080 --> 00:19:43.880
always shown to be the most aggressive with AI,&nbsp;
it's technology companies and, I think, financial&nbsp;&nbsp;

00:19:43.880 --> 00:19:48.920
services comes up pretty high there and then you&nbsp;
go from there, right. So, they're probably doing&nbsp;&nbsp;

00:19:48.920 --> 00:19:54.360
a better job than a lot of industries. But I think&nbsp;
there's this misnomer that just because they're,&nbsp;&nbsp;

00:19:54.360 --> 00:19:59.880
you know, you’re tech company, that you're just&nbsp;
you're totally on this thing and you got it. I&nbsp;&nbsp;

00:19:59.880 --> 00:20:05.680
am not seeing that. I think that there's a lot of&nbsp;
executive teams that are still just as flat-footed&nbsp;&nbsp;

00:20:05.680 --> 00:20:09.600
as any retail executive or other industry.
 
Craig: 20:09&nbsp;

00:20:09.600 --> 00:20:16.160
Yeah, and what percentage of just off the cuff,&nbsp;
not a hard data point, but what percentage would&nbsp;&nbsp;

00:20:16.160 --> 00:20:28.640
you say of your membership are, if not AI native,&nbsp;
have been in the AI space for 10 years or so.
 &nbsp;

00:20:28.640 --> 00:20:31.120
Thomas: 20:29
Yeah, that's a fantastic question.&nbsp;&nbsp;

00:20:31.840 --> 00:20:37.200
Here's the lens we use on that, so, we think of&nbsp;
a spectrum of tech companies right now that goes&nbsp;&nbsp;

00:20:37.200 --> 00:20:43.400
from being what we call AI advantaged, and so,&nbsp;
what are the attributes there? They probably have&nbsp;&nbsp;

00:20:43.400 --> 00:20:52.240
AI products they're monetizing, they're using&nbsp;
AI internally, so they're pretty savvy. And the&nbsp;&nbsp;

00:20:52.240 --> 00:20:57.920
opposite end of that spectrum is what we call&nbsp;
severe AI laggers. They have no AI offerings,&nbsp;&nbsp;

00:20:57.920 --> 00:21:02.640
they're not using AI internally, they're not well&nbsp;
positioned to leverage it because they don't have&nbsp;&nbsp;

00:21:02.640 --> 00:21:03.880
good data, et cetera, et cetera.
 
Thomas: 21:03&nbsp;

00:21:03.880 --> 00:21:09.040
So, here's this spectrum and right now it's&nbsp;
sort of almost like this classic bell curve&nbsp;&nbsp;

00:21:09.040 --> 00:21:13.840
of life. You have about 10 to 14% of the tech&nbsp;
companies we look at that really, I would say&nbsp;&nbsp;

00:21:13.840 --> 00:21:22.200
are AI advantaged, but on the opposite end you&nbsp;
have 10, 15% that are severely disadvantaged, and&nbsp;&nbsp;

00:21:22.200 --> 00:21:28.760
then you have the folks in the middle. So, it is&nbsp;
almost like this classic bell curve of life. But&nbsp;&nbsp;

00:21:28.760 --> 00:21:35.800
again, I think my observation, looking at these&nbsp;
companies operate, these AI-advantaged companies,&nbsp;&nbsp;

00:21:35.800 --> 00:21:40.480
to me this is like the internet on steroids.&nbsp;
When the internet came out, and companies that&nbsp;&nbsp;

00:21:40.480 --> 00:21:46.480
were able to jump on that fast created some real&nbsp;
advantage. This AI thing is going to move faster&nbsp;&nbsp;

00:21:46.480 --> 00:21:50.520
than that and the advantages that get created are&nbsp;
even going to be more massive. So, if you're down&nbsp;&nbsp;

00:21:50.520 --> 00:21:56.280
here and you again are severely disadvantaged, not&nbsp;
well positioned to really even leverage AI in your&nbsp;&nbsp;

00:21:56.280 --> 00:21:59.280
operating model, that is going to be a problem.
 
Craig: 21:59&nbsp;

00:21:59.280 --> 00:22:05.840
You were talking about the different, looking at&nbsp;
the different places in the operations where AI&nbsp;&nbsp;

00:22:05.840 --> 00:22:15.987
could be applied to immediate ROI, do you have a&nbsp;
distribution there that, you should start with-?
 &nbsp;

00:22:15.987 --> 00:22:18.440
Thomas: 22:16
I'll give you two responses to that and&nbsp;&nbsp;

00:22:18.440 --> 00:22:25.280
what we see in the data. So, one response is if&nbsp;
we just think about different activities within a&nbsp;&nbsp;

00:22:25.280 --> 00:22:31.120
tech company, where are the folks that are leaning&nbsp;
in? Where we see the use cases that are mature and&nbsp;&nbsp;

00:22:31.120 --> 00:22:35.800
you could, definitely should be leveraging right&nbsp;
now, the classic is support services. Everything&nbsp;&nbsp;

00:22:35.800 --> 00:22:39.360
from, you're talking about agents, but just&nbsp;
helping with self-support all the way to more&nbsp;&nbsp;

00:22:39.360 --> 00:22:44.120
predictive support. I mean, basically they're&nbsp;
using AI to prevent things from even happening,&nbsp;&nbsp;

00:22:44.120 --> 00:22:51.280
right, outages, et cetera. So that is becoming&nbsp;
very mature. I would say that field services,&nbsp;&nbsp;

00:22:51.280 --> 00:22:56.720
using AI so you don't have to deploy hardware&nbsp;
and equipment onsite, that's a big use case,&nbsp;&nbsp;

00:22:56.720 --> 00:23:01.640
education services, as I mentioned, for content&nbsp;
development. That's a big use case. And then you&nbsp;&nbsp;

00:23:01.640 --> 00:23:07.720
start to see a fall off. So, if you look at the&nbsp;
area of customer success, which is very popular,&nbsp;&nbsp;

00:23:07.720 --> 00:23:13.520
how to help customers adopt, customer success&nbsp;
organizations are kind of lagging on applying&nbsp;&nbsp;

00:23:13.520 --> 00:23:20.240
AI. There's good use cases, they're just lagging.&nbsp;
And then, when you come to the revenue generation&nbsp;&nbsp;

00:23:20.240 --> 00:23:25.000
side, so if you think about any technology&nbsp;
company, you have to sell and market your&nbsp;&nbsp;

00:23:25.000 --> 00:23:31.360
products and there are absolutely use cases&nbsp;
for AI to help you do that more effectively&nbsp;&nbsp;

00:23:31.360 --> 00:23:36.240
and what we're seeing is sales and marketing&nbsp;
organizations are severe laggers right now in&nbsp;&nbsp;

00:23:36.240 --> 00:23:41.800
using AI. And again, there are some that are. But&nbsp;
I'm just saying in general, right, you say, hey,&nbsp;&nbsp;

00:23:41.800 --> 00:23:47.680
how are you using AI to do renewal management,&nbsp;
or your forecasting, or to better understand&nbsp;&nbsp;

00:23:47.680 --> 00:23:55.747
opportunities? Still, sales organizations are&nbsp;
typically not technology forward organizations.
 &nbsp;

00:23:55.747 --> 00:23:56.520
Thomas: 23:55
But I will tell you,&nbsp;&nbsp;

00:23:56.520 --> 00:24:03.560
the other view on this, like, where are the use&nbsp;
cases? I think that the companies that get an ROI,&nbsp;&nbsp;

00:24:03.560 --> 00:24:11.480
proven ROI, you focus on workflows, actually, that&nbsp;
you understand really well that you have really&nbsp;&nbsp;

00:24:11.480 --> 00:24:15.920
solid performance metrics on, again, content&nbsp;
development. An education service organization&nbsp;&nbsp;

00:24:15.920 --> 00:24:20.360
can tell you, hey, to generate an hour of&nbsp;
training materials, it takes make up a number,&nbsp;&nbsp;

00:24:20.360 --> 00:24:27.560
10 hours of labor. If I apply AI to that, I&nbsp;
can see exactly where I'm reducing. Same with,&nbsp;&nbsp;

00:24:27.560 --> 00:24:33.320
how much time does a support engineer spend on&nbsp;
a call? How many times do I deploy equipment,&nbsp;&nbsp;

00:24:33.320 --> 00:24:39.520
replacement hardware that I didn't need to? Those&nbsp;
are all clear performance KPIs where you can put&nbsp;&nbsp;

00:24:39.520 --> 00:24:41.960
AI to it, and you can see the benefits.
 
Thomas: 24:42&nbsp;

00:24:41.960 --> 00:24:46.400
That's a winning attribute as opposed to, and it's&nbsp;
interesting there's just an article in the Wall&nbsp;&nbsp;

00:24:46.400 --> 00:24:50.640
Street Journal. It was about Microsoft's co-pilot,&nbsp;
and they were saying, well, we're paying whatever,&nbsp;&nbsp;

00:24:50.640 --> 00:24:56.260
$30 a month, we're not sure if there's benefit&nbsp;
and we've got to— but I read that and I'm like,&nbsp;&nbsp;

00:24:56.260 --> 00:25:00.760
well, but what's the use case? I mean just giving&nbsp;
employees co-pilot and throwing it out there and&nbsp;&nbsp;

00:25:00.760 --> 00:25:05.440
paying for it and then going, well, I don't know&nbsp;
if there's an ROI— because you haven't defined&nbsp;&nbsp;

00:25:05.440 --> 00:25:10.960
what you expect to get out of that. So, that's&nbsp;
where you really do see ROI is when people are&nbsp;&nbsp;

00:25:10.960 --> 00:25:14.880
crystal clear on what they're trying to optimize.
 
Craig: 25:14&nbsp;

00:25:14.880 --> 00:25:22.480
Yeah, you mentioned a few times now the education&nbsp;
content generation. Are you talking about&nbsp;&nbsp;

00:25:22.480 --> 00:25:31.027
companies that are creating training programs&nbsp;
for other companies, or are you talking about?
 &nbsp;

00:25:31.027 --> 00:25:32.440
Thomas: 25:31
Their own, yea, their&nbsp;&nbsp;

00:25:32.440 --> 00:25:37.400
internal. So if you think about this challenge,&nbsp;
there's something we wrote about years ago and&nbsp;&nbsp;

00:25:37.400 --> 00:25:43.120
we called it the Consumption Gap, and it was a&nbsp;
book called Complexity Avalanche and our argument&nbsp;&nbsp;

00:25:43.120 --> 00:25:49.680
was that enterprise tech companies just keep&nbsp;
throwing out all of this feature functionality,&nbsp;&nbsp;

00:25:49.680 --> 00:25:54.240
wave after wave, and the gap between what&nbsp;
enterprise customers, enterprise customers can&nbsp;&nbsp;

00:25:54.240 --> 00:26:00.920
actually consume and apply, it just gets bigger&nbsp;
and bigger. So that's always a challenge for the&nbsp;&nbsp;

00:26:00.920 --> 00:26:06.800
education, internal education folks, is getting&nbsp;
the materials. What's effective education? Again,&nbsp;&nbsp;

00:26:06.800 --> 00:26:13.720
is it targeted toward different user types and&nbsp;
personas? And so, using AI to create personalized&nbsp;&nbsp;

00:26:13.720 --> 00:26:19.560
content at scale is amazing, and I know you&nbsp;
had the Khan Academy founder on talking—
 &nbsp;

00:26:19.560 --> 00:26:22.120
Thomas: 26:21
It’s that thought right,&nbsp;&nbsp;

00:26:22.120 --> 00:26:27.880
is, how does AI really change and make it easier&nbsp;
for people to consume? And I'll give you just&nbsp;&nbsp;

00:26:27.880 --> 00:26:32.120
simple examples. The biggest challenge with these&nbsp;
education service departments is keeping their&nbsp;&nbsp;

00:26:32.120 --> 00:26:37.840
content up to date with new releases. So, if it&nbsp;
takes me all these man hours to do this every&nbsp;&nbsp;

00:26:37.840 --> 00:26:43.600
time, I'm always falling behind. If I can use&nbsp;
AI to compress that and get fresh releases out&nbsp;&nbsp;

00:26:43.600 --> 00:26:51.200
there in a super timely manner, it's a game&nbsp;
changer for them. So, its just one example,&nbsp;&nbsp;

00:26:52.600 --> 00:26:59.320
it speaks to not only saving real cost but&nbsp;
creating a better customer experience as well.

00:26:59.320 --> 00:27:03.120
Craig: 27:02
Yeah, and do you guys,&nbsp;&nbsp;

00:27:03.120 --> 00:27:10.680
as an organization provide training, any kind&nbsp;
of training? I mean, it seems like that would be&nbsp;&nbsp;

00:27:10.680 --> 00:27:18.240
a perfect use case where you say, look, you have&nbsp;
this tool, Copilot, you have a, depending on your,&nbsp;&nbsp;

00:27:18.240 --> 00:27:24.480
but these are tech companies, you have all&nbsp;
these developers. How do you get it applied?
 &nbsp;

00:27:24.480 --> 00:27:26.680
Thomas: 27:24
So, our use case on this and it's a&nbsp;&nbsp;

00:27:26.680 --> 00:27:30.880
great question. So, if you think about a company&nbsp;
that creates research, right, so we go out, we&nbsp;&nbsp;

00:27:30.880 --> 00:27:36.960
study things and what you typically do you create&nbsp;
papers on that; research artifacts that people can&nbsp;&nbsp;

00:27:36.960 --> 00:27:40.960
consume, and then we will also, we will workshop&nbsp;
around that. So, if somebody goes well, hey,&nbsp;&nbsp;

00:27:40.960 --> 00:27:44.280
I read the paper, but I want my team to really&nbsp;
get this framework or really understand these&nbsp;&nbsp;

00:27:44.280 --> 00:27:49.600
lessons learned, can you have somebody deliver?&nbsp;
It's like a stand and deliver. So those are our&nbsp;&nbsp;

00:27:49.600 --> 00:27:55.600
two traditional ways to basically impart our&nbsp;
insights on the audience. There's no doubt that&nbsp;&nbsp;

00:27:55.600 --> 00:28:02.960
AI is going to allow us to just take that content&nbsp;
engine and again put it on steroids and create&nbsp;&nbsp;

00:28:02.960 --> 00:28:08.040
way more nuanced versions of it. So you come in,&nbsp;
Craig, and understanding your background and what&nbsp;&nbsp;

00:28:08.040 --> 00:28:15.720
your role is at the company, et cetera, we can now&nbsp;
put our content in formats to spoon feed you meet&nbsp;&nbsp;

00:28:15.720 --> 00:28:20.920
you where you're at, instead of saying here's the&nbsp;
one paper we wrote for a bunch of people on this&nbsp;&nbsp;

00:28:20.920 --> 00:28:23.200
topic. So that's the journey we're on right now.
 
Thomas: 28:23&nbsp;

00:28:23.200 --> 00:28:29.840
The other really cool thing about this in terms&nbsp;
of imparting knowledge is still, even for us,&nbsp;&nbsp;

00:28:29.840 --> 00:28:35.280
we write papers which are, you know, in a sense,&nbsp;
very structured content, but we have tons of&nbsp;&nbsp;

00:28:35.280 --> 00:28:41.240
unstructured content from from webinars, from,&nbsp;
you know, powerpoint presentations, from you know,&nbsp;&nbsp;

00:28:41.240 --> 00:28:46.000
notes from our research researchers. We, you&nbsp;
know, from interactions with our members,&nbsp;&nbsp;

00:28:46.000 --> 00:28:51.880
which you can start to bring in and&nbsp;
feed to create structured experiences.

00:28:51.880 --> 00:28:53.680
Thomas: 28:53
We actually just released a&nbsp;&nbsp;

00:28:53.680 --> 00:29:01.120
new digital platform for our members which starts&nbsp;
with what we call AI-enabled search so much more&nbsp;&nbsp;

00:29:01.120 --> 00:29:05.520
than traditional search being able to serve up&nbsp;
the right content, again for where you are. And&nbsp;&nbsp;

00:29:05.520 --> 00:29:10.040
then we're on the journey of now, how do we take&nbsp;
it, how do we ingest all this unstructured content&nbsp;&nbsp;

00:29:10.040 --> 00:29:17.680
and start to put it out in different ways? So, if&nbsp;
you do research and advisory or consulting and you&nbsp;&nbsp;

00:29:17.680 --> 00:29:23.520
think you're going to do a traditional brain on&nbsp;
a stick model five years from now, you're kidding&nbsp;&nbsp;

00:29:23.520 --> 00:29:30.360
yourself. And it's amazing because again, this&nbsp;
thing is moving so fast. Look at what's happening&nbsp;&nbsp;

00:29:30.360 --> 00:29:35.000
to the traditional consulting firms, like the&nbsp;
McKinsey's of the world. They're already reshaping&nbsp;&nbsp;

00:29:35.000 --> 00:29:39.840
their workforce. They're already downsizing&nbsp;
because this brain on a stick; I just get a bunch&nbsp;&nbsp;

00:29:39.840 --> 00:29:44.600
of smart people to come out and just brute force&nbsp;
you through these learnings or whatever. That's&nbsp;&nbsp;

00:29:44.600 --> 00:29:46.760
not going to be the winning model.
 
Craig: 29:47&nbsp;

00:29:46.760 --> 00:29:52.600
Well, let me ask the obvious question. How much AI&nbsp;
do you guys use in your operation? Do you struggle&nbsp;&nbsp;

00:29:52.600 --> 00:29:55.200
with the same thing?
 
Thomas: 29:55&nbsp;

00:29:55.200 --> 00:30:00.560
Yeah, well, I always say we are a mirror or&nbsp;
reflection of our members. We look, you know,&nbsp;&nbsp;

00:30:00.560 --> 00:30:05.000
like the challenges they have with AI, the&nbsp;
challenges we have. You got to pick the right&nbsp;&nbsp;

00:30:05.000 --> 00:30:10.520
tools. You're comment about maturity, we've&nbsp;
been working with a lot of, we do writing,&nbsp;&nbsp;

00:30:10.520 --> 00:30:16.480
so one of the first applications that we've&nbsp;
leaned into is how you can leverage AI to&nbsp;&nbsp;

00:30:16.480 --> 00:30:20.640
make your researchers more productive, and those&nbsp;
tools have been fluid and we've settled on some&nbsp;&nbsp;

00:30:21.560 --> 00:30:28.440
tools right now, literally within the past month.&nbsp;
So, we're on the same journey everybody else is,&nbsp;&nbsp;

00:30:28.440 --> 00:30:30.120
but I'll give you some examples here.
 
Thomas: 30:31&nbsp;

00:30:30.120 --> 00:30:37.440
Again, we are very committed and internalized&nbsp;
the fact that AI is going to change our operating&nbsp;&nbsp;

00:30:37.440 --> 00:30:41.560
model and every employee in the company whether&nbsp;
you're a customer success manager, we have those,&nbsp;&nbsp;

00:30:41.560 --> 00:30:45.640
whether you're a researcher, whether you're a&nbsp;
salesperson, whether you're a marketing person,&nbsp;&nbsp;

00:30:45.640 --> 00:30:52.680
that you just have got to lean into that reality&nbsp;
and we're going to figure out as fast as we can
 &nbsp;

00:30:52.680 --> 00:30:56.240
Thomas: 30:52
what that means. And so, we have, you&nbsp;&nbsp;

00:30:56.240 --> 00:31:00.600
know, in general we call it an AI task force, and&nbsp;
it's made up of people from different departments&nbsp;&nbsp;

00:31:00.600 --> 00:31:05.720
and they are meeting constantly to be checking&nbsp;
this landscape out. What are the tools out&nbsp;&nbsp;

00:31:05.720 --> 00:31:10.920
there? What do we think the top use cases are for&nbsp;
the company? Prioritize that and then just keep&nbsp;&nbsp;

00:31:10.920 --> 00:31:17.880
chipping at those, and that doesn't sound overly&nbsp;
complex, but I can tell you that is several steps&nbsp;&nbsp;

00:31:17.880 --> 00:31:23.960
ahead of many tech companies out there, right?&nbsp;
They haven't had that internalization that this is&nbsp;&nbsp;

00:31:23.960 --> 00:31:29.000
gonna change everybody's workflow. So, what does&nbsp;
that mean to how we operate? They're still, again,&nbsp;&nbsp;

00:31:29.000 --> 00:31:34.720
not sure. Let's wait for the tools, and so I think&nbsp;
again, our guidance to the members is you just,&nbsp;&nbsp;

00:31:34.720 --> 00:31:42.080
you have to get serious about this now and get&nbsp;
experience and insights now and it will mature.&nbsp;&nbsp;

00:31:42.080 --> 00:31:48.000
But as it matures, you're going to be ready to&nbsp;
go, as opposed to, you know, trying to just jump&nbsp;&nbsp;

00:31:48.000 --> 00:31:50.440
on down the road.
 
Craig: 31:51&nbsp;

00:31:50.440 --> 00:31:57.240
Yeah, and this task force this is something that,&nbsp;
as a journalist, you know, I don’t quite know how&nbsp;&nbsp;

00:31:57.240 --> 00:32:07.360
to handle. Do you have some researchers on the&nbsp;
staff of that task force that are literally,&nbsp;&nbsp;

00:32:07.360 --> 00:32:16.000
that trial every model or every product in a&nbsp;
category and write an assessment of it, or? 
 &nbsp;

00:32:16.000 --> 00:32:19.080
Thomas: 32:17
Yeah, you know, it is a team sport,&nbsp;&nbsp;

00:32:19.080 --> 00:32:23.680
and this is what I'm observing. Again, we're we're&nbsp;
learning like everybody else. It's not like we,&nbsp;&nbsp;

00:32:23.680 --> 00:32:28.360
you know, two years ago, can say that, okay,&nbsp;
you know, we're really adapted AI and we know&nbsp;&nbsp;

00:32:28.360 --> 00:32:32.760
all the tools and we know all the use cases. We&nbsp;
are learning every week. But if you look at the&nbsp;&nbsp;

00:32:32.760 --> 00:32:39.080
way we're approaching it and I think this is a&nbsp;
good practice for companies, is cross-functional.&nbsp;&nbsp;

00:32:39.080 --> 00:32:43.320
You got to get people who are practitioners&nbsp;
in your different areas to come and say gosh,&nbsp;&nbsp;

00:32:43.320 --> 00:32:49.440
what do I, I need to understand what again, what&nbsp;
AI could mean to me, to my customer success peers,&nbsp;&nbsp;

00:32:49.440 --> 00:32:52.960
what it could mean to my sales peers, what it&nbsp;
could mean to our researchers. So, you need&nbsp;&nbsp;

00:32:52.960 --> 00:32:57.347
representation, number one; from different&nbsp;
departments that would actually be users.
 &nbsp;

00:32:57.347 --> 00:32:58.400
Thomas: 32:57
You can't just go off in&nbsp;&nbsp;

00:32:58.400 --> 00:33:04.880
an ivory tower and have people technically say&nbsp;
this is really cool and throw it over, but you&nbsp;&nbsp;

00:33:04.880 --> 00:33:10.160
have to have the right technical talent in play.&nbsp;
So, we obviously have IT people that are on that,&nbsp;&nbsp;

00:33:10.160 --> 00:33:14.640
and we are blessed. We have a killer, what&nbsp;
we call our A team, which is an analytics,&nbsp;&nbsp;

00:33:14.640 --> 00:33:20.160
data and software team, and they are the technical&nbsp;
experts on, you're talking about, what are some of&nbsp;&nbsp;

00:33:20.160 --> 00:33:23.960
the tools? What do we see as strengths and&nbsp;
weaknesses? Because if you don't have that&nbsp;&nbsp;

00:33:23.960 --> 00:33:29.240
technical muscle and you just have practitioners&nbsp;
who use, they don't know the right questions to&nbsp;&nbsp;

00:33:29.240 --> 00:33:34.880
ask on that side. So, you got to bring them&nbsp;
together and so I think one of the struggles&nbsp;&nbsp;

00:33:34.880 --> 00:33:42.630
out there for sure for companies is they don't yet&nbsp;
have that technical muscle when it comes to AI.
 &nbsp;

00:33:42.630 --> 00:33:44.280
Thomas: 33:43
You have strong IT people,&nbsp;&nbsp;

00:33:44.280 --> 00:33:50.240
you can have strong product people, but they may&nbsp;
not have real expertise yet in AI, and that's what&nbsp;&nbsp;

00:33:50.240 --> 00:33:55.440
companies have got to ramp up. I think it's one&nbsp;
of those things where, because obviously there's&nbsp;&nbsp;

00:33:55.440 --> 00:34:00.280
a lot of consulting firms that can help with that&nbsp;
and they can augment your internal staff but I&nbsp;&nbsp;

00:34:00.280 --> 00:34:05.400
would not outsource that completely in sense to&nbsp;
say look, I'll just let consulting firm A come in&nbsp;&nbsp;

00:34:05.400 --> 00:34:09.560
and tell me what the answers are technically.&nbsp;
I think, just like with your IT departments,&nbsp;&nbsp;

00:34:10.600 --> 00:34:15.840
no matter if you have a lot of partners involved&nbsp;
with your IT, you still have to have some level of&nbsp;&nbsp;

00:34:15.840 --> 00:34:19.640
internal expertise to help guide you there.
 
Craig: 34:19&nbsp;

00:34:19.640 --> 00:34:25.760
Yeah, do you have a sense, as you're going&nbsp;
through this or watching other people go&nbsp;&nbsp;

00:34:25.760 --> 00:34:31.560
through this and I know that the answer will be&nbsp;
variable depending on what part of the operations&nbsp;&nbsp;

00:34:31.560 --> 00:34:37.680
or what thing you're trying to automate but how&nbsp;
long does that process take? Because the market&nbsp;&nbsp;

00:34:37.680 --> 00:34:45.360
is moving so fast. So, you have a task force. On&nbsp;
that task force is a head of sales and you know,&nbsp;&nbsp;

00:34:45.360 --> 00:34:50.560
it surprised me what you said about sales being&nbsp;
laggards, because two or three years ago now,&nbsp;&nbsp;

00:34:50.560 --> 00:35:00.720
I had on the podcast a company called&nbsp;
Akkio. And they have a no-code platform,&nbsp;&nbsp;

00:35:00.720 --> 00:35:11.240
and their biggest use case is ranking leads&nbsp;
because the sales team can't call every lead. So,&nbsp;&nbsp;

00:35:11.240 --> 00:35:13.480
they have this predictive model.
 
Craig: 35:13&nbsp;

00:35:13.480 --> 00:35:20.120
It's a pretty standard model, frankly, but you&nbsp;
drop in all your sales lead data from you know&nbsp;&nbsp;

00:35:20.120 --> 00:35:27.800
before and the outcomes that you got off of those,&nbsp;
and then the model figures out whatever patterns&nbsp;&nbsp;

00:35:27.800 --> 00:35:35.920
there are in the data that makes somebody a lead&nbsp;
worthy spending time on. And then when you get a&nbsp;&nbsp;

00:35:35.920 --> 00:35:40.600
batch of leads in, you run them through the model.&nbsp;
It ranks them and you know who to focus on. So,&nbsp;&nbsp;

00:35:40.600 --> 00:35:47.760
the sales guy is there and says, yeah, we need&nbsp;
to automate this. There are a dozen probably much&nbsp;&nbsp;

00:35:47.760 --> 00:35:54.720
more than that tools out there or companies that&nbsp;
offer that kind of a product. Someone's got to go&nbsp;&nbsp;

00:35:54.720 --> 00:36:03.240
through all of those tools and figure out features&nbsp;
and cost and whatnot. On something like that,&nbsp;&nbsp;

00:36:03.240 --> 00:36:11.880
is that assuming you have buy-in, you're not&nbsp;
fighting political battles? Is that a six-month&nbsp;&nbsp;

00:36:11.880 --> 00:36:14.440
process? Is that a three-week process?
 
Thomas: 36:14&nbsp;

00:36:14.440 --> 00:36:22.280
Yeah, this is a great question and I want to&nbsp;
click into the sales conversation directly to&nbsp;&nbsp;

00:36:22.280 --> 00:36:26.080
kind of put some light on that, so you understand&nbsp;
why we're seeing that. But let's just talk first&nbsp;&nbsp;

00:36:26.080 --> 00:36:31.560
of all the general case. So, your department,&nbsp;
whether you're in sales, or your education,&nbsp;&nbsp;

00:36:31.560 --> 00:36:35.840
support, whatever and you're going to go&nbsp;
through this journey where you say, hey,&nbsp;&nbsp;

00:36:35.840 --> 00:36:42.640
we want to leverage AI more effectively and&nbsp;
in these case studies where I am interviewing&nbsp;&nbsp;

00:36:42.640 --> 00:36:46.907
companies around successful deployment,&nbsp;
right, they went through this journey.
 &nbsp;

00:36:46.907 --> 00:36:49.600
Thomas: 36:47
One of the things we ask is how long did this&nbsp;&nbsp;

00:36:49.600 --> 00:36:56.520
take, when you started to explore tools to get to&nbsp;
the place? And right now, the common answer is two&nbsp;&nbsp;

00:36:56.520 --> 00:37:03.160
to three years. Two to three years, okay, but that&nbsp;
is going to start doing this [shorten], okay. Now,&nbsp;&nbsp;

00:37:03.160 --> 00:37:07.560
when you click into that and you start saying,&nbsp;
oh, wow, gosh, two to three years, yeah,&nbsp;&nbsp;

00:37:07.560 --> 00:37:14.960
we had to start chipping on this a while ago. What&nbsp;
creates that type of timeline? Well, first of all,&nbsp;&nbsp;

00:37:14.960 --> 00:37:20.120
when you were on this earlier, the tools were&nbsp;
more immature two, three years ago. So, the lot&nbsp;&nbsp;

00:37:20.120 --> 00:37:24.840
around just, can I get the tools in beta? Can I&nbsp;
get them to work? That's going to compress, okay,&nbsp;&nbsp;

00:37:24.840 --> 00:37:32.680
so that one's definitely going to get shorter. My&nbsp;
next problem, my data. My data is a mess. AI is a&nbsp;&nbsp;

00:37:32.680 --> 00:37:41.880
data-driven engine here, and so a lot of time you&nbsp;
have to get through getting your data in order.&nbsp;&nbsp;

00:37:41.880 --> 00:37:44.960
Okay, so that, I think, is also going to get&nbsp;
easier. I think there's going to be tools there&nbsp;&nbsp;

00:37:44.960 --> 00:37:52.160
that will help people, so that will compress over&nbsp;
time. The next click over, though and again this&nbsp;&nbsp;

00:37:52.160 --> 00:37:57.440
is one where people underestimate is, maybe now&nbsp;
I have a great tool, I've got my data in order,&nbsp;&nbsp;

00:37:58.480 --> 00:38:04.360
I now can apply this to the workflow; but I am&nbsp;
underestimating the change management with my&nbsp;&nbsp;

00:38:04.360 --> 00:38:12.520
employees, and that can end up creating oh gosh,&nbsp;
this was not like two weeks and they were adept.&nbsp;&nbsp;

00:38:12.520 --> 00:38:16.640
I had to get some early adopters. I had to learn&nbsp;
what was working, what wasn't working. I had to&nbsp;&nbsp;

00:38:16.640 --> 00:38:23.360
go back. So, again, and I think what companies&nbsp;
need to do is learn what are the best practices to&nbsp;&nbsp;

00:38:23.360 --> 00:38:28.000
change my workflows with AI, and again, the sooner&nbsp;
you get battle scars on that, the better. So,&nbsp;&nbsp;

00:38:28.000 --> 00:38:33.120
you put all that together, and that's why you end&nbsp;
up with two or three years. Now let's take that&nbsp;&nbsp;

00:38:33.120 --> 00:38:35.040
and apply it to sales.
 
Thomas: 38:35&nbsp;

00:38:35.040 --> 00:38:39.040
The challenge with sales, the last book we wrote&nbsp;
it was called Digital Hesitation. We had a chapter&nbsp;&nbsp;

00:38:39.040 --> 00:38:45.040
called Data-Driven Sales, and our argument was&nbsp;
that sales organizations need to wake up every&nbsp;&nbsp;

00:38:45.040 --> 00:38:51.160
morning and do exactly what you just said, which&nbsp;
is I'm a salesperson, I look at my screen and&nbsp;&nbsp;

00:38:51.160 --> 00:38:58.520
the data should be my guide in terms of who I call&nbsp;
and what I sell to them. The data analytics should&nbsp;&nbsp;

00:38:58.520 --> 00:39:02.200
be my guide, and that data should be getting&nbsp;
better and better. The analytics is getting&nbsp;&nbsp;

00:39:02.200 --> 00:39:03.480
better and better.
 
Thomas: 39:03&nbsp;

00:39:03.480 --> 00:39:10.640
The problem that we see in the industry is that's&nbsp;
not how sales organizations want to operate.&nbsp;&nbsp;

00:39:10.640 --> 00:39:15.840
That's just not their DNA. They're not data driven&nbsp;
historically. They get up and they say, well,&nbsp;&nbsp;

00:39:15.840 --> 00:39:19.200
look, I'm going to call, you know, to call Craig,&nbsp;
because I was talking to him last week and I&nbsp;&nbsp;

00:39:19.200 --> 00:39:26.040
really think he's ready to buy this, and so that's&nbsp;
my gut and he was giving me all the right signals,&nbsp;&nbsp;

00:39:26.040 --> 00:39:32.560
right? Well, the data says Craig is like way early&nbsp;
in the sales cycle and you should be talking to&nbsp;&nbsp;

00:39:32.560 --> 00:39:37.960
Susie over here because she is really ready.&nbsp;
Well, I'll get to Susie next week, and so that&nbsp;&nbsp;

00:39:37.960 --> 00:39:44.800
is a huge shift in mentality. But it's going to&nbsp;
come because the tools, you know, like the tool&nbsp;&nbsp;

00:39:44.800 --> 00:39:48.840
you were describing, I'm not familiar with that&nbsp;
one, but I'm familiar with other ones. There's,&nbsp;&nbsp;

00:39:48.840 --> 00:39:53.200
there there, right, they're getting really good.&nbsp;
We just had to get the change management piece&nbsp;&nbsp;

00:39:53.200 --> 00:40:00.428
of it, that last leg, that last mile, to&nbsp;
get workers to be adept with these tools.
 &nbsp;

00:40:00.428 --> 00:40:01.440
Craig: 40:01
Yeah, and the other&nbsp;&nbsp;

00:40:01.440 --> 00:40:10.720
question was— so two years, two, three years,&nbsp;
and that's getting shorter. But it's an ongoing&nbsp;&nbsp;

00:40:10.720 --> 00:40:19.200
process because in each of these categories there&nbsp;
are new products coming out or new features to&nbsp;&nbsp;

00:40:19.200 --> 00:40:26.920
products that may be you passed over because&nbsp;
the one you settled on had features, but maybe&nbsp;&nbsp;

00:40:26.920 --> 00:40:32.640
that product now surpasses the one you settled on&nbsp;
because its features are better. I mean, do you&nbsp;&nbsp;

00:40:32.640 --> 00:40:42.227
have, do you advise people to have someone who's&nbsp;
sort of on this continuous learning treadmill?
 &nbsp;

00:40:42.227 --> 00:40:43.680
Thomas: 40:42
Yeah, I mean, you know,&nbsp;&nbsp;

00:40:43.680 --> 00:40:49.560
the concept of agile, right with development&nbsp;
and just the fact that you are constantly,&nbsp;&nbsp;

00:40:49.560 --> 00:40:53.960
it's not the old waterfall days where it's like,&nbsp;
we have a project, boom, boom, boom, bam, we're&nbsp;&nbsp;

00:40:53.960 --> 00:40:59.160
done. We're probably, don't have to go look at&nbsp;
that for however many you know quarters or years&nbsp;&nbsp;

00:40:59.160 --> 00:41:06.627
or whatever, because we did that. It's going to be&nbsp;
this never-ending opportunity for optimization.
 &nbsp;

00:41:06.627 --> 00:41:09.560
Thomas: 41:06
I think that that is going to be the reality,&nbsp;&nbsp;

00:41:09.560 --> 00:41:14.600
my hope and I don't know if this is going to be&nbsp;
true and I test in these case studies as people&nbsp;&nbsp;

00:41:14.600 --> 00:41:23.880
are rolling out technologies but I would assert&nbsp;
that historically, enterprise software has been&nbsp;&nbsp;

00:41:23.880 --> 00:41:29.960
very complex and very onerous to implement and&nbsp;
to get your business value from. That's just a&nbsp;&nbsp;

00:41:29.960 --> 00:41:37.560
reality and we've had in play for decades now. But&nbsp;
if you're a company, and B2C, it's a lot easier,&nbsp;&nbsp;

00:41:37.560 --> 00:41:43.560
but B2B is still oh my God, I got to buy this&nbsp;
tool, I got to build this configuration, and so&nbsp;&nbsp;

00:41:43.560 --> 00:41:49.360
it's expensive, time consuming to get the business&nbsp;
value. I am hoping, with this next generation of&nbsp;&nbsp;

00:41:49.360 --> 00:41:55.760
AI enabled capabilities, that they're going&nbsp;
to be actually easier to implement and adopt,&nbsp;&nbsp;

00:41:55.760 --> 00:42:01.960
and that's TBD. We don't know yet, but I think&nbsp;
it's going to make a faster life cycle there.&nbsp;&nbsp;

00:42:01.960 --> 00:42:07.320
I can get tools. I can get a new feature. Once&nbsp;
I get good at this and leveraging these kinds&nbsp;&nbsp;

00:42:07.320 --> 00:42:12.440
of capabilities, I can do it faster than I&nbsp;
used to in the old world. But we'll see.
 &nbsp;

00:42:12.440 --> 00:42:14.120
Craig: 42:13
I'm interested in&nbsp;&nbsp;

00:42:14.120 --> 00:42:23.040
what's happening with AI agents, both virtual&nbsp;
and embodied because there's just, even in the&nbsp;&nbsp;

00:42:23.040 --> 00:42:33.640
last month, a ton of new research coming out&nbsp;
of DeepMind or Amazon, different people. Is&nbsp;&nbsp;

00:42:33.640 --> 00:42:43.760
that something that because again, that's going&nbsp;
to change the game altogether from just simply&nbsp;&nbsp;

00:42:43.760 --> 00:42:53.267
GenAI tools? Are you guys trying to stay on top&nbsp;
of that, or how do you advise your members?
 &nbsp;

00:42:53.267 --> 00:42:54.080
Thomas: 42:53
Yeah so, what's interesting&nbsp;&nbsp;

00:42:54.080 --> 00:43:00.760
with agents and you know, the two use cases there&nbsp;
well, there's multiple, but I mean two classic for&nbsp;&nbsp;

00:43:00.760 --> 00:43:05.440
a tech company would be the support I've got a&nbsp;
technical issue, I have an agent there to help&nbsp;&nbsp;

00:43:05.440 --> 00:43:10.720
me or customer success, I'm trying to do something&nbsp;
I haven't done before with your technology, can I&nbsp;&nbsp;

00:43:10.720 --> 00:43:15.640
have an intelligent agent there to help? It's&nbsp;
interesting because, again, these case studies&nbsp;&nbsp;

00:43:15.640 --> 00:43:21.720
that I'm looking at right now and I have not done&nbsp;
a deep dive on agents and how they're changing;&nbsp;&nbsp;

00:43:21.720 --> 00:43:27.440
the earlier generation of this was sort of&nbsp;
these classic chatbots and stuff which helped&nbsp;&nbsp;

00:43:27.440 --> 00:43:33.920
in certain scenarios but in general were probably&nbsp;
not very satisfactory for the end user, right? So,&nbsp;&nbsp;

00:43:33.920 --> 00:43:38.467
this is definitely changing that game and saying,&nbsp;
look, this is going to be way more intelligent.
 &nbsp;

00:43:38.467 --> 00:43:40.960
Thomas: 43:38
What I'm seeing is sort of the middle ground,&nbsp;&nbsp;

00:43:40.960 --> 00:43:47.680
is this co-pilot approach, where companies&nbsp;
are again building co-pilots that are specific&nbsp;&nbsp;

00:43:47.680 --> 00:43:56.520
to their products, their world, tuned to that&nbsp;
language, and building these co-pilots initially&nbsp;&nbsp;

00:43:56.520 --> 00:44:01.720
internally to help their own technical engineers&nbsp;
solve things much faster, and then they're saying,&nbsp;&nbsp;

00:44:01.720 --> 00:44:08.560
well, wait a minute, let's let our end customers&nbsp;
have access to that and basically augment their&nbsp;&nbsp;

00:44:08.560 --> 00:44:14.440
ability to completely self-serve. So that is&nbsp;
already a winning play for sure, and I've done&nbsp;&nbsp;

00:44:14.440 --> 00:44:19.920
several case studies on that. And then the&nbsp;
agents, I think, is the next version of that.

00:44:19.920 --> 00:44:20.800
Thomas: 44:19
So, it's really&nbsp;&nbsp;

00:44:20.800 --> 00:44:26.240
interesting that that term has sort of been&nbsp;
you know, people have grabbed onto that term&nbsp;&nbsp;

00:44:26.240 --> 00:44:32.320
to describe the experience of saying I've got a&nbsp;
co-pilot that is going to ride alongside you and&nbsp;&nbsp;

00:44:32.320 --> 00:44:39.200
help you do whatever it is. And so, again, Nokia&nbsp;
has put a lot into this for telecom engineers,&nbsp;&nbsp;

00:44:39.200 --> 00:44:44.680
specifically tuned to those use cases and&nbsp;
starting with their internal engineers,&nbsp;&nbsp;

00:44:44.680 --> 00:44:49.800
and now it's out there for their customers to&nbsp;
leverage as well and you know, again, it can be&nbsp;&nbsp;

00:44:49.800 --> 00:44:53.360
a game changer for the productivity of both sides&nbsp;
of that right, for their own engineers and for&nbsp;&nbsp;

00:44:53.360 --> 00:45:00.188
their customers. So, there's definitely, that's&nbsp;
already, you know a proven use case for sure.
 &nbsp;

00:45:00.188 --> 00:45:01.200
Craig: 45:00
Yeah, well, agents&nbsp;&nbsp;

00:45:01.200 --> 00:45:07.800
I'm really really excited about, because some&nbsp;
of the stuff that's coming out of OpenAI and—

00:45:07.800 --> 00:45:08.840
Thomas: 45:08
Well, it's mind-boggling,&nbsp;&nbsp;

00:45:08.840 --> 00:45:12.788
mind-boggling what it could potentially&nbsp;
be doing for us, I mean, it really is.
 &nbsp;

00:45:12.788 --> 00:45:14.480
Craig: 45:12
You know you mentioned when&nbsp;&nbsp;

00:45:14.480 --> 00:45:21.760
I was saying what's the sort of timeframe for&nbsp;
implementing, that companies, when they first&nbsp;&nbsp;

00:45:21.760 --> 00:45:29.520
address automating with AI some part of their&nbsp;
business, that they've got to centralize the data,&nbsp;&nbsp;

00:45:29.520 --> 00:45:38.200
they've got to rationalize the data. Does that&nbsp;
have to be done for every separate use case or&nbsp;&nbsp;

00:45:38.200 --> 00:45:45.040
is that something that companies need to be doing&nbsp;
right now, understanding that data is going to&nbsp;&nbsp;

00:45:45.040 --> 00:45:51.960
drive their business regardless of the business&nbsp;
they're in? So they need to centralize the data,&nbsp;&nbsp;

00:45:51.960 --> 00:45:58.107
rationalize the data, clean the data, regardless&nbsp;
of how it's going to be used at this point?
 &nbsp;

00:45:58.107 --> 00:46:00.320
Thomas: 45:57
Yeah, no, this is a great topic and the one thing&nbsp;&nbsp;

00:46:00.320 --> 00:46:04.560
I'll tell your listeners, because I'm sure you&nbsp;
have people from a lot of different backgrounds,&nbsp;&nbsp;

00:46:04.560 --> 00:46:11.680
industries, and you think of technology companies&nbsp;
that sell technology to help people manage their&nbsp;&nbsp;

00:46:11.680 --> 00:46:16.920
data and you say, gosh, those folks have to have&nbsp;
the best, their data house has got to be in order,&nbsp;&nbsp;

00:46:16.920 --> 00:46:22.320
and it's just, it's not true. They’re as messed up&nbsp;
as everybody else is on this topic and you know,&nbsp;&nbsp;

00:46:22.320 --> 00:46:29.640
it's just, it's the reality. So, everybody has&nbsp;
this problem and what drives it is sort of these&nbsp;&nbsp;

00:46:29.640 --> 00:46:35.800
organizational fiefdoms, right. So, sales wants&nbsp;
their data, marketing wants their data, service&nbsp;&nbsp;

00:46:35.800 --> 00:46:40.600
people want their data, and so everyone's got&nbsp;
their version of the truth, et cetera, and it has&nbsp;&nbsp;

00:46:40.600 --> 00:46:45.520
created all these silos. And now these AI tools&nbsp;
come along, and you say, well, look, to really get&nbsp;&nbsp;

00:46:45.520 --> 00:46:50.720
the bang for the buck, I need a holistic view of&nbsp;
what the heck my customer's doing. I can't just be&nbsp;&nbsp;

00:46:50.720 --> 00:46:53.680
like; I only have the sales view of it.
 
Thomas: 46:53&nbsp;

00:46:53.680 --> 00:47:00.480
So, it's forcing this issue where people have to&nbsp;
say there's really one source of truth, one gold&nbsp;&nbsp;

00:47:00.480 --> 00:47:06.160
standard. And so that pressure is there now and&nbsp;
there is going to be a lot of work that has to&nbsp;&nbsp;

00:47:06.160 --> 00:47:12.360
be done to break these silos down. The winning&nbsp;
move that we see when we test on practices, and&nbsp;&nbsp;

00:47:12.360 --> 00:47:19.560
this is about 47% of the companies that we survey&nbsp;
now, they have a centralized data analytics team.&nbsp;&nbsp;

00:47:19.560 --> 00:47:26.040
That is the first step. So before you even crush,&nbsp;
get everything together in one lake or whatever&nbsp;&nbsp;

00:47:26.040 --> 00:47:30.920
you're doing there is, you basically say, look,&nbsp;
we're going to have a team. They own the source&nbsp;&nbsp;

00:47:30.920 --> 00:47:35.480
of truth and in the short term they're going to&nbsp;
be having to deal with a lot of different silos&nbsp;&nbsp;

00:47:35.480 --> 00:47:41.160
to bring in what is going on with the customer or&nbsp;
whatever's going on with the product but that we&nbsp;&nbsp;

00:47:41.160 --> 00:47:46.240
all agree that we go to them and that if the data&nbsp;
is not right there, we keep pushing on that until&nbsp;&nbsp;

00:47:46.240 --> 00:47:50.560
they've got the right view of the of the world.&nbsp;
And then, behind the scenes, we're cleaning up the&nbsp;&nbsp;

00:47:50.560 --> 00:47:54.640
data. We're starting to break down the physical&nbsp;
silos, if you will, between organizations or&nbsp;&nbsp;

00:47:54.640 --> 00:47:56.080
applications or whatever.
 
Thomas: 47:56&nbsp;

00:47:56.080 --> 00:48:03.440
So, I think that's the journey. But to get a&nbsp;
team that owns again the source of truth for&nbsp;&nbsp;

00:48:03.440 --> 00:48:09.680
the company on the data, I think is a winning move&nbsp;
to start that journey. But what you're pushing on,&nbsp;&nbsp;

00:48:09.680 --> 00:48:14.840
it's got to happen because you can't get these&nbsp;
tools to really sing, to get the full potential&nbsp;&nbsp;

00:48:14.840 --> 00:48:20.588
from the AI if your data is the classic garbage&nbsp;
in, garbage out. That's more true than ever.
 &nbsp;

00:48:20.588 --> 00:48:21.640
Craig: 48:20
Right, but that's&nbsp;&nbsp;

00:48:21.640 --> 00:48:26.587
a process that can start long before you&nbsp;
decide what tool you're going to settle on? 
 &nbsp;

00:48:26.587 --> 00:48:27.600
Thomas: 48:27
Yeah, absolutely.

00:48:27.600 --> 00:48:28.560
Craig: 48:28
So that would&nbsp;&nbsp;

00:48:28.560 --> 00:48:31.307
be kind of a first step in everything.

00:48:31.307 --> 00:48:33.920
Thomas: 48:31
Yeah, absolutely. And just think about&nbsp;&nbsp;

00:48:33.920 --> 00:48:39.560
that culturally. So that this really lands with&nbsp;
the audience, right? What are we saying here? Oh,&nbsp;&nbsp;

00:48:39.560 --> 00:48:42.480
yeah, well, we have an analytics team. We have&nbsp;
an analytics team. Okay, that's fine, but what&nbsp;&nbsp;

00:48:42.480 --> 00:48:50.880
I'm saying is okay, I'm in sales and what I am now&nbsp;
agreeing to is that that team, that central team,&nbsp;&nbsp;

00:48:50.880 --> 00:48:56.360
owns the source of truth of what's going on with&nbsp;
sales, that my data feeds into there and they say&nbsp;&nbsp;

00:48:56.360 --> 00:49:01.160
look, this is what's going on with forecast,&nbsp;
or pipeline, or whatever, close rates. And I&nbsp;&nbsp;

00:49:01.160 --> 00:49:06.960
am seeding that ground. I'm not holding my data&nbsp;
and source of truth and everything here. That,&nbsp;&nbsp;

00:49:06.960 --> 00:49:12.040
culturally, you can start to force that issue&nbsp;
before you solve all the technical issues.
 &nbsp;

00:49:12.040 --> 00:49:15.880
Craig: 49:12
And on that point, but across the board, and&nbsp;&nbsp;

00:49:15.880 --> 00:49:25.600
you know, to the point of evaluating and adopting&nbsp;
tools on something like data management, that's&nbsp;&nbsp;

00:49:25.600 --> 00:49:36.320
a specialization like the Wealth of Nations.&nbsp;
Shouldn’t a company be just an orchestrator and&nbsp;&nbsp;

00:49:36.320 --> 00:49:43.400
all of the stuff you want to centralize, clean&nbsp;
your data? You bring in a specialized company&nbsp;&nbsp;

00:49:43.400 --> 00:49:51.120
to do that. Not that you don't have somebody on&nbsp;
your team writing herd and understanding what's&nbsp;&nbsp;

00:49:51.120 --> 00:49:59.880
going on, if it's optimizing sales. Rather&nbsp;
than have your team trying to figure out,&nbsp;&nbsp;

00:49:59.880 --> 00:50:05.947
you bring in an expert who can say you know, I see&nbsp;
the problem, this is what you should be doing.
 &nbsp;

00:50:05.947 --> 00:50:08.160
Thomas: 50:05
Yeah, I mean, it's a great question. You know the&nbsp;&nbsp;

00:50:08.160 --> 00:50:15.680
classic, am I going to try to build this myself or&nbsp;
buy the expertise? I mean I don't have strong data&nbsp;&nbsp;

00:50:15.680 --> 00:50:22.680
or point of view on that. I will say that, you&nbsp;
know, in general, I think there's tons of awesome&nbsp;&nbsp;

00:50:22.680 --> 00:50:26.000
expertise that's out there that can help you on&nbsp;
that journey. I don't think there's any doubt&nbsp;&nbsp;

00:50:26.000 --> 00:50:31.640
about that and there's, technology is going to&nbsp;
help you on that journey. And I think that, again,&nbsp;&nbsp;

00:50:31.640 --> 00:50:35.620
what I'll just emphasize is two things on that&nbsp;
and what you started with, you know the concept&nbsp;&nbsp;

00:50:35.620 --> 00:50:41.600
that you need more centralized data, et cetera.&nbsp;
It is another one of these internalizations that&nbsp;&nbsp;

00:50:41.600 --> 00:50:49.240
companies and executive teams have to have the&nbsp;
wherewithal to execute. So, they're saying gosh,&nbsp;&nbsp;

00:50:49.960 --> 00:50:54.480
if we're going to leverage this AI in our&nbsp;
workflows, we got to get our data house in&nbsp;&nbsp;

00:50:54.480 --> 00:50:59.000
order. So that means that we have to be committed,&nbsp;
probably ultimately, to centralizing, which means&nbsp;&nbsp;

00:50:59.000 --> 00:51:04.200
we may need expertise. We got to invest in this&nbsp;
and culturally, we are all going to have to agree&nbsp;&nbsp;

00:51:04.200 --> 00:51:06.640
that we don't have our own sources of truth.
 
Thomas: 51:06&nbsp;

00:51:06.640 --> 00:51:10.320
And that second one, I'm telling you,&nbsp;
is harder, probably, than the first one,&nbsp;&nbsp;

00:51:10.320 --> 00:51:14.520
even though everyone's focused on the first&nbsp;
one. It's a technical problem. It's both,&nbsp;&nbsp;

00:51:14.520 --> 00:51:21.520
cultural and technical. You know, is there&nbsp;
a lot of hype on AI? Absolutely, but it is&nbsp;&nbsp;

00:51:21.520 --> 00:51:27.960
already impacting business models. This is not a&nbsp;
mañana wait, and I'll just give you a data point.&nbsp;&nbsp;

00:51:27.960 --> 00:51:32.080
I was doing some research on headcount analysis.&nbsp;
There was an article in the Wall Street Journal&nbsp;&nbsp;

00:51:32.080 --> 00:51:39.040
around the fact that AI is already starting to eat&nbsp;
through headcount. And there's no doubt, and I'll&nbsp;&nbsp;

00:51:39.040 --> 00:51:45.520
give you an example, if you look at Microsoft,&nbsp;
Amazon, Salesforce, these are all companies that&nbsp;&nbsp;

00:51:45.520 --> 00:51:50.640
have more revenue under management than they did&nbsp;
two years ago and they all have less employees,&nbsp;&nbsp;

00:51:50.640 --> 00:51:52.880
and that is not an anomaly. 
 
Craig: 51:57&nbsp;

00:51:52.880 --> 00:51:58.920
AI might be the most important new computer&nbsp;
technology ever. It's storming every industry&nbsp;&nbsp;

00:51:58.920 --> 00:52:04.120
and literally billions of dollars are being&nbsp;
invested, so buckle up. The problem is that&nbsp;&nbsp;

00:52:04.120 --> 00:52:10.400
AI needs a lot of speed and processing power.&nbsp;
So how do you compete without costs spiraling&nbsp;&nbsp;

00:52:10.400 --> 00:52:16.120
out of control? It's time to upgrade to&nbsp;
the next generation of the cloud Oracle&nbsp;&nbsp;

00:52:16.120 --> 00:52:23.760
Cloud Infrastructure, or OCI. OCI is a single&nbsp;
platform for your infrastructure, database,&nbsp;&nbsp;

00:52:23.760 --> 00:52:31.840
application development, and AI needs. OCI has&nbsp;
four to eight times the bandwidth of other clouds,&nbsp;&nbsp;

00:52:31.840 --> 00:52:38.520
offers one consistent price instead of variable&nbsp;
regional pricing. And, of course, nobody does data&nbsp;&nbsp;

00:52:38.520 --> 00:52:45.520
better than Oracle. So now you can train your AI&nbsp;
models at twice the speed and less than half the&nbsp;&nbsp;

00:52:45.520 --> 00:52:53.600
cost of other clouds. If you want to do more and&nbsp;
spend less, like Uber, 8x8, and Databricks Mosaic,&nbsp;&nbsp;

00:52:53.600 --> 00:53:04.880
take a free test drive of OCI at oraclecom/eyeonat&nbsp;
that's E-Y-E-O-N-A-I all run together.&nbsp;

00:53:04.880 --> 00:53:09.960
That's it for today's episode. I want to&nbsp;
thank Thomas for his time. If you want&nbsp;&nbsp;

00:53:09.960 --> 00:53:20.040
to read a transcript of today's conversation,&nbsp;
you can find one on our website at eye-on.ai.&nbsp;&nbsp;

00:53:20.040 --> 00:53:27.480
Remember the singularity may not be near, but AI&nbsp;
is fast changing our worlds, so pay attention.

