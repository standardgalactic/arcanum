WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:20.720
Craig: Hi, I'm Craig Smith, and this is Eye on&nbsp;
AI. This week, I talk to Oriol Vinyals, who leads&nbsp;&nbsp;

00:00:20.720 --> 00:00:27.680
DeepMind’s deep learning team, about AlphaCode,&nbsp;
his group’s code-writing language model,&nbsp;&nbsp;

00:00:28.480 --> 00:00:34.960
and DeepMind’s winding road toward&nbsp;
artificial general intelligence.&nbsp;

00:00:36.080 --> 00:00:43.200
Before we begin, I want to mention&nbsp;
our sponsor, ClearML, a collaborative&nbsp;&nbsp;

00:00:43.200 --> 00:00:46.450
open source MLOps solution. They're sponsoring&nbsp;
the podcast. They offer an end-to-end system for&nbsp;&nbsp;

00:00:46.450 --> 00:00:50.160
building and deploying machine-learning&nbsp;
models. Check them out at clear.ml.&nbsp;&nbsp;

00:00:51.120 --> 00:00:57.040
Tell them Eye on AI sent you.
Craig: Meanwhile, I hope you find the&nbsp;&nbsp;

00:00:57.040 --> 00:01:17.600
conversation with Oriol as interesting as I did.
Craig: Okay. So, Oriol I have to ask you a couple&nbsp;&nbsp;

00:01:17.600 --> 00:01:24.160
of things: one, what's the significance&nbsp;
of the big black bear behind you, and two,&nbsp;&nbsp;

00:01:25.200 --> 00:01:34.080
I'm curious about the meaning of your first name.
Oriol: Right? The bear behind me actually traveled&nbsp;&nbsp;

00:01:34.080 --> 00:01:40.720
all the way back from California, where I did my&nbsp;
PhD at UC Berkeley, which has as a mascot a bear.&nbsp;

00:01:40.720 --> 00:01:45.920
Oriol: And then it's a good question about&nbsp;
the Oriol name. It's a Catalan name. I'm&nbsp;&nbsp;

00:01:45.920 --> 00:01:52.800
from Barcelona originally, and I believe it&nbsp;
doesn't have any translation to Spanish. It's&nbsp;&nbsp;

00:01:57.520 --> 00:02:02.800
a compound name, which is Joseph-Oriol.
Oriol: But again, it's a very local name&nbsp;&nbsp;

00:02:02.800 --> 00:02:04.400
from Barcelona.
Craig: Okay.&nbsp;&nbsp;

00:02:04.400 --> 00:02:10.800
And I know you've given your background many times&nbsp;
before, but that's generally how I like to start.&nbsp;&nbsp;

00:02:11.840 --> 00:02:15.120
So, you are a Spanish by birth.
Oriol: Yes.&nbsp;

00:02:15.120 --> 00:02:20.640
Craig: Can you talk a little bit about your&nbsp;
education and then how you got to DeepMind?&nbsp;

00:02:20.640 --> 00:02:27.680
Oriol: Yeah, certainly. So, I did my undergraduate&nbsp;
degree in Barcelona where I'm from, then moved to&nbsp;&nbsp;

00:02:27.680 --> 00:02:35.840
the US where I lived for probably 10 years. I did&nbsp;
my masters at UC San Diego, so, in California,&nbsp;&nbsp;

00:02:37.200 --> 00:02:42.000
and then moved to do my PhD in a bit&nbsp;
more northern California in Berkeley,&nbsp;&nbsp;

00:02:42.000 --> 00:02:49.360
where I did the PhD starting in 2009.
Oriol: It was a very interesting time because&nbsp;&nbsp;

00:02:49.360 --> 00:02:55.120
machine learning was definitely not as popular,&nbsp;
deep learning certainly wasn't very popular. So,&nbsp;&nbsp;

00:02:55.680 --> 00:02:59.760
it was a unique experience to be in a&nbsp;
university environment but discovering a&nbsp;&nbsp;

00:02:59.760 --> 00:03:05.520
lot of what was going on in the field. And&nbsp;
there were only a very few people that I&nbsp;&nbsp;

00:03:05.520 --> 00:03:13.040
was able to hang out with at the university.
Oriol: But luckily, I did a few internships&nbsp;&nbsp;

00:03:13.040 --> 00:03:21.440
also doing my PhD, many of which were at Microsoft&nbsp;
Research in Redmond in Washington state. And that&nbsp;&nbsp;

00:03:21.440 --> 00:03:27.440
is where I met also a lot of students from Geoff&nbsp;
Hinton's lab, where it sparked my interest in deep&nbsp;&nbsp;

00:03:27.440 --> 00:03:35.040
learning, which I then exported to Berkeley.
Oriol: And then in 2013, I finished my PhD.&nbsp;&nbsp;

00:03:35.600 --> 00:03:43.360
I did my very last internship at Google in Google&nbsp;
Brain. It was a fun time because Geoff Hinton&nbsp;&nbsp;

00:03:43.360 --> 00:03:49.680
was an intern himself as well, actually, at the&nbsp;
time. We had both internships at the same time.&nbsp;&nbsp;

00:03:50.320 --> 00:03:57.600
And then after graduating, I joined Google Brain,&nbsp;
which was very small compared to what it is now.&nbsp;&nbsp;

00:03:58.160 --> 00:04:03.920
I worked there for a few years and&nbsp;
then moved to DeepMind in 2016,&nbsp;&nbsp;

00:04:03.920 --> 00:04:10.160
back in London, back in Europe where I'm from.
Craig: Yeah. Yeah. You were an intern at Microsoft&nbsp;&nbsp;

00:04:11.440 --> 00:04:20.000
the same time as Ilya Sutskever, is that right?
Oriol: Yes. Yes, many of my friends I met through&nbsp;&nbsp;

00:04:20.000 --> 00:04:27.280
Microsoft Research internships, including Ilya&nbsp;
Sutskever, Alex Krzyzewski, George Dahl, and many&nbsp;&nbsp;

00:04:27.280 --> 00:04:32.000
of these folks and then you would obviously hang&nbsp;
out in conferences in the very small workshops&nbsp;&nbsp;

00:04:32.000 --> 00:04:37.600
that we held in deep learning at the time.
Oriol: And yeah, many friendships started through&nbsp;&nbsp;

00:04:37.600 --> 00:04:42.160
internships and of course at school as well.
Craig: Yeah, it's remarkable. I just had&nbsp;&nbsp;

00:04:42.800 --> 00:04:49.840
Andrew Ng on the podcast and he talked about&nbsp;
those days when Geoff Hinton was his intern. Yeah.&nbsp;&nbsp;

00:04:52.400 --> 00:04:59.120
My conversation is a little less technical&nbsp;
than many of those that you've had.&nbsp;

00:05:04.960 --> 00:05:23.600
Craig: I'd like to start with AlphaCode and I'm&nbsp;
particularly interested in AlphaCode because&nbsp;&nbsp;

00:05:23.600 --> 00:05:27.520
I'm not a coder. And I've&nbsp;
talked to a lot of people about&nbsp;&nbsp;

00:05:29.200 --> 00:05:32.640
no code and low code platforms that are emerging.&nbsp;

00:05:33.920 --> 00:05:41.760
Craig: I'm wondering where that's going.&nbsp;
And I hear a lot of skepticism about,&nbsp;&nbsp;

00:05:41.760 --> 00:05:50.480
applications of things like AlphaCode because&nbsp;
of the limitations and the actual complexity of&nbsp;&nbsp;

00:05:50.480 --> 00:05:58.480
useful code. And then I'd also like to hear&nbsp;
a little bit about DeepMind’s work on large&nbsp;&nbsp;

00:05:58.480 --> 00:06:08.880
language models, which are the rage right now.
Craig: And whether there's a relationship between&nbsp;&nbsp;

00:06:09.600 --> 00:06:15.600
RETRO, I believe is DeepMind's large language&nbsp;
model, and AlphaCode. And then where does the&nbsp;&nbsp;

00:06:15.600 --> 00:06:27.520
research go from there? So, if you can just talk,&nbsp;
I won't interrupt very much, about how AlphaCode&nbsp;&nbsp;

00:06:27.520 --> 00:06:37.520
started. What is the purpose of that research?
Craig: What are the likely applications, if any&nbsp;&nbsp;

00:06:37.520 --> 00:06:44.160
of the AlphaCode model and how it&nbsp;
relates to large language models&nbsp;&nbsp;

00:06:44.160 --> 00:06:49.440
and then where does it go from there?
Oriol: Great. Yeah, I'm happy to talk&nbsp;&nbsp;

00:06:49.440 --> 00:06:55.680
you through a bit of a few of these projects&nbsp;
that you might be learning from our blog and&nbsp;&nbsp;

00:06:56.400 --> 00:07:01.840
the news that comes up from the lab.
Oriol: So AlphaCode in particular,&nbsp;&nbsp;

00:07:02.560 --> 00:07:08.000
If I have to trace its inception, it starts&nbsp;
actually doing another project that we ran&nbsp;&nbsp;

00:07:08.000 --> 00:07:14.080
a couple of years ago called AlphaStar, where&nbsp;
we were building an agent to play a video game,&nbsp;&nbsp;

00:07:14.080 --> 00:07:19.840
StarCraft, that I actually am very passionate&nbsp;
about. And the fact of the matter is we've been&nbsp;&nbsp;

00:07:19.840 --> 00:07:26.640
using a lot of these sort of benchmarks that&nbsp;
humans found interesting through many years,&nbsp;&nbsp;

00:07:27.200 --> 00:07:32.160
as a sort of benchmarks themselves as well for&nbsp;
our agents and the technology we developed.&nbsp;

00:07:32.160 --> 00:07:38.480
Oriol: So, one of the sorts of trajectories&nbsp;
you can trace back if you look at DeepMind's&nbsp;&nbsp;

00:07:38.480 --> 00:07:46.640
history and certainly many of the successes in&nbsp;
the field is to see which benchmarks exist and&nbsp;&nbsp;

00:07:46.640 --> 00:07:53.120
what's the performance improvements over&nbsp;
those. Obviously, DeepMind started perhaps&nbsp;&nbsp;

00:07:53.120 --> 00:07:59.120
most notoriously with Atari playing Atari games.
Oriol: And then StarCraft was perhaps the last&nbsp;&nbsp;

00:07:59.120 --> 00:08:06.000
game, which was a step up in complexity. And&nbsp;
Go was maybe an intermediate between those two.&nbsp;&nbsp;

00:08:06.000 --> 00:08:11.440
So AlphaGo being another very famous of course&nbsp;
project that the world learned about a few years&nbsp;&nbsp;

00:08:11.440 --> 00:08:20.320
ago. So AlphaCode, in a way from a techniques&nbsp;
perspective actually borrowed a lot of past&nbsp;&nbsp;

00:08:20.320 --> 00:08:25.200
research and that's actually one, maybe one&nbsp;
meta point I would like to make very early that&nbsp;&nbsp;

00:08:25.920 --> 00:08:30.720
I'm leading the deep learning team.
Oriol: So deep learning, I find it quite useful&nbsp;&nbsp;

00:08:30.720 --> 00:08:37.600
to see it as a toolbox, right? So, the toolbox is&nbsp;
ever expanding. There's new research, new papers&nbsp;&nbsp;

00:08:37.600 --> 00:08:43.440
come out, people share code, share insights,&nbsp;
and you're adding this tool now to your toolbox.&nbsp;&nbsp;

00:08:43.440 --> 00:08:49.440
And then anytime there's a hard challenge out&nbsp;
there, what's happened now, the revolution, so&nbsp;&nbsp;

00:08:49.440 --> 00:08:55.920
to speak, in deep learning is that you can go and&nbsp;
seek in the toolbox and find patterns, find past&nbsp;&nbsp;

00:08:55.920 --> 00:09:01.040
problems you've solved, things that were useful.
Oriol: Take them out of this toolbox and then&nbsp;&nbsp;

00:09:01.040 --> 00:09:06.240
reapply them to a new domain. So&nbsp;
AlphaCode, in fact, borrows a lot&nbsp;&nbsp;

00:09:06.240 --> 00:09:12.720
of the things we learned doing AlphaStar&nbsp;
because it uses, in fact, it connects also&nbsp;&nbsp;

00:09:12.720 --> 00:09:19.360
with language models because it first learns what&nbsp;
code looks like. Coding is no less than a sequence&nbsp;&nbsp;

00:09:19.360 --> 00:09:25.840
of words that happen to conform a program.
Oriol: So that sort of same principle applies to&nbsp;&nbsp;

00:09:25.840 --> 00:09:30.640
coding, and it applies to the game of StarCraft&nbsp;
as well because playing a game is no less than&nbsp;&nbsp;

00:09:30.640 --> 00:09:38.960
issuing a sequence of instructions that look a&nbsp;
bit like code, actually, move this piece up on&nbsp;&nbsp;

00:09:38.960 --> 00:09:48.320
the board here, et cetera, et cetera. At the time&nbsp;
we were doing AlphaStar, coding seemed like a very&nbsp;&nbsp;

00:09:48.320 --> 00:09:53.920
interesting challenge. And when you look at a&nbsp;
domain like coding or programming in general,&nbsp;&nbsp;

00:09:53.920 --> 00:09:58.480
one of the things you want to do, is there&nbsp;
any existing benchmark in that domain&nbsp;&nbsp;

00:09:59.280 --> 00:10:05.120
that will serve the purpose of, can we do this&nbsp;
with the current tools we have in the toolbox?&nbsp;

00:10:05.120 --> 00:10:10.080
Oriol: If yes. Then it's useful to know.&nbsp;
If not, maybe we'll invent new tools&nbsp;&nbsp;

00:10:10.080 --> 00:10:17.280
to be added for further projects that go beyond&nbsp;
what we do towards AGI. So, with that in mind,&nbsp;&nbsp;

00:10:19.120 --> 00:10:24.400
looking at coding in particular, there are&nbsp;
a few things you could imagine doing with an&nbsp;&nbsp;

00:10:24.400 --> 00:10:30.320
AI to enhance software engineering, but we&nbsp;
went perhaps the more traditional route we&nbsp;&nbsp;

00:10:30.320 --> 00:10:37.440
had been doing with games, like Atari, Go and&nbsp;
StarCraft, which is look at the very serious&nbsp;&nbsp;

00:10:37.440 --> 00:10:45.280
competition that has not been designed for AIs&nbsp;
to compete in, take that platform, hopefully a&nbsp;&nbsp;

00:10:45.280 --> 00:10:56.400
popular one where humans really have expanded and&nbsp;
try to exhaust all the skills that humanity that&nbsp;&nbsp;

00:10:56.400 --> 00:11:02.480
programmers have developed and then participate&nbsp;
in it to see where we are in this benchmark.&nbsp;

00:11:02.480 --> 00:11:07.600
Oriol: And that's where we thought about&nbsp;
a coding contest or coding competition as&nbsp;&nbsp;

00:11:07.600 --> 00:11:13.120
the platform to do such a challenge, which&nbsp;
is fairly unique and fairly different than&nbsp;&nbsp;

00:11:13.120 --> 00:11:19.520
perhaps other work that regards more about&nbsp;
completion of code or trying to assist&nbsp;&nbsp;

00:11:20.240 --> 00:11:24.240
coding in some sort of, oh, I don't&nbsp;
know about this language or this API,&nbsp;&nbsp;

00:11:24.240 --> 00:11:31.440
and then you have a smart way to access that.
Oriol: Instead of doing that, what we did is code&nbsp;&nbsp;

00:11:31.440 --> 00:11:37.680
competitions, which in a nutshell can be described&nbsp;
as, there is a problem statement. It's almost like&nbsp;&nbsp;

00:11:39.440 --> 00:11:44.160
an exam that you would do at school. So,&nbsp;
there's some sort of story that tells you about,&nbsp;&nbsp;

00:11:45.280 --> 00:11:50.960
explains what an algorithm should&nbsp;
be doing in words, in plain words.&nbsp;

00:11:50.960 --> 00:11:58.480
Oriol: So, it's natural language at the input.&nbsp;
And then humans usually take this description.&nbsp;&nbsp;

00:11:58.480 --> 00:12:04.080
This description contains a few examples, right?&nbsp;
Oh, like for example, if the input to this program&nbsp;&nbsp;

00:12:04.080 --> 00:12:12.160
you're about to write is this, the output should&nbsp;
be that. And then from this description humans&nbsp;&nbsp;

00:12:12.160 --> 00:12:17.920
basically put a few hours trial and error, right?
Oriol: They code, they code some Python, C++,&nbsp;&nbsp;

00:12:18.480 --> 00:12:23.920
or whatever popular language they choose&nbsp;
to. They code the solution. Then they&nbsp;&nbsp;

00:12:23.920 --> 00:12:28.880
submit it to a web server that then has&nbsp;
some secret tests that would evaluate, hey,&nbsp;&nbsp;

00:12:28.880 --> 00:12:34.240
is this program fast enough, importantly, and&nbsp;
also, correct. So, we thought that's great.&nbsp;

00:12:34.240 --> 00:12:39.360
Oriol: There's actually tens of thousands&nbsp;
of participants in weekly competitions.&nbsp;&nbsp;

00:12:39.360 --> 00:12:45.600
People that take these competitions very&nbsp;
seriously, by extremely clever coders. So,&nbsp;&nbsp;

00:12:45.600 --> 00:12:51.680
we took these as the sort of benchmark and the&nbsp;
result was that we achieved median performance,&nbsp;&nbsp;

00:12:51.680 --> 00:12:58.880
meaning average human that competes in this.&nbsp;
So that's a bit what happened in AlphaCode in&nbsp;&nbsp;

00:12:58.880 --> 00:13:04.080
terms of the result and a bit of background.
Craig: Yeah, AlphaCode uses the transformer&nbsp;&nbsp;

00:13:04.080 --> 00:13:14.240
algorithm as the core. Does it draw at&nbsp;
all on RETRO, on a large language model?&nbsp;

00:13:14.240 --> 00:13:17.840
Oriol: Yeah. So, this is a good question.
Oriol: So first of all,&nbsp;&nbsp;

00:13:19.040 --> 00:13:26.960
actually AlphaStar, AlphaFold, AlphaCode and all&nbsp;
the large language model work you're seeing from&nbsp;&nbsp;

00:13:26.960 --> 00:13:32.240
DeepMind and obviously from many other labs, use&nbsp;
transformers, which is one of these tools that we&nbsp;&nbsp;

00:13:32.240 --> 00:13:39.680
added in the toolbox in 2017. It's a very powerful&nbsp;
neural network that allows you to model sequences.&nbsp;

00:13:39.680 --> 00:13:44.640
Oriol: Basically, you input the sequence and the&nbsp;
transformer does a transformation - it's actually&nbsp;&nbsp;

00:13:44.640 --> 00:13:51.760
a good name - on top of it to then predict&nbsp;
either, whether the sequence is, I don't know,&nbsp;&nbsp;

00:13:51.760 --> 00:13:57.760
a positive or a negative sentence in natural&nbsp;
language processing, or what's the 3D coordinate&nbsp;&nbsp;

00:13:57.760 --> 00:14:03.920
of a protein or an atom in the protein or, in&nbsp;
the coding case or language case in general,&nbsp;&nbsp;

00:14:03.920 --> 00:14:11.040
it predicts what's the next level that proceeds&nbsp;
the code. So, it indeed uses transformers.&nbsp;&nbsp;

00:14:11.040 --> 00:14:17.520
Retro is actually a particular language model&nbsp;
that uses an extra, an additional idea. So,&nbsp;&nbsp;

00:14:17.520 --> 00:14:25.120
it expands a transformer with a large memory&nbsp;
bank. Basically, you're trying to predict the&nbsp;&nbsp;

00:14:25.120 --> 00:14:29.280
next word. So, you're seeing a few letters,&nbsp;
maybe of a program you're trying to predict.&nbsp;

00:14:29.280 --> 00:14:34.800
Oriol: What's the next letter that you should&nbsp;
write to make this program, correct? But then&nbsp;&nbsp;

00:14:34.800 --> 00:14:41.840
critically it indexes a large dataset of&nbsp;
lines, like trillions of documents to retrieve&nbsp;&nbsp;

00:14:41.840 --> 00:14:47.360
relevant information. And this is another tool&nbsp;
in the toolbox, in fact, the retrieval process&nbsp;&nbsp;

00:14:47.920 --> 00:14:54.960
that enables models to become as good as bigger&nbsp;
models, but at much less parameter count.&nbsp;

00:14:54.960 --> 00:15:00.320
Oriol: In the coding example, we actually tried&nbsp;
some of these ideas because it's very natural&nbsp;&nbsp;

00:15:00.320 --> 00:15:05.840
to think, hey, when you're coding something,&nbsp;
you actually retrieve, you search for similar&nbsp;&nbsp;

00:15:05.840 --> 00:15:10.960
algorithms or try to inform yourself about&nbsp;
what the code might look like. And in fact,&nbsp;&nbsp;

00:15:10.960 --> 00:15:17.440
in these competitions, that's very commonly done.
Oriol: But, in actuality, we found this to not be&nbsp;&nbsp;

00:15:17.440 --> 00:15:25.680
so useful for AlphaCode in particular. But then&nbsp;
the Retro paper showed its capabilities on just&nbsp;&nbsp;

00:15:25.680 --> 00:15:30.480
regular language models. And in our large&nbsp;
language models research, this is an active&nbsp;&nbsp;

00:15:30.480 --> 00:15:37.600
area to expand this toolbox, to make it more&nbsp;
useful, to essentially supercharge transformers&nbsp;&nbsp;

00:15:37.600 --> 00:15:42.800
to access this memory bank a bit like us.
Oriol: We are supercharged by Google search.&nbsp;&nbsp;

00:15:43.600 --> 00:15:47.040
When we're looking for information, we&nbsp;
don't remember everything, right? So,&nbsp;&nbsp;

00:15:47.600 --> 00:15:53.760
this idea behind RETRO is actually more a new tool&nbsp;
that's still a work in progress. We published,&nbsp;&nbsp;

00:15:53.760 --> 00:15:57.120
of course, a paper. There's&nbsp;
some activity in research. But&nbsp;&nbsp;

00:15:57.680 --> 00:16:03.120
in AlphaCode, in particular, it didn't help.
Oriol: So, we just use the plain transformer.&nbsp;

00:16:03.840 --> 00:16:08.240
Craig: I see. So AlphaCode&nbsp;
itself is a large language model.&nbsp;

00:16:08.240 --> 00:16:16.000
Oriol: So how did we create AlphaCode?&nbsp;
The step and maybe that's where most&nbsp;&nbsp;

00:16:16.000 --> 00:16:20.720
of the inspiration came from, was AlphaStar.&nbsp;
We thought about the same process as we&nbsp;&nbsp;

00:16:20.720 --> 00:16:25.680
created for these agents that played the game.
Oriol: The first step is imitating humans,&nbsp;&nbsp;

00:16:25.680 --> 00:16:32.000
right? So large language models, take&nbsp;
a large data set of language sequences,&nbsp;&nbsp;

00:16:32.000 --> 00:16:37.600
and try to imitate the statistics of what&nbsp;
will come next after each letter or word,&nbsp;&nbsp;

00:16:38.480 --> 00:16:43.200
train a big model, and then that's what you're&nbsp;
seeing these days in large language models. The&nbsp;&nbsp;

00:16:43.200 --> 00:16:48.240
way that we did AlphaStar was actually the same.
Oriol: We had sequences of actions, these actions&nbsp;&nbsp;

00:16:48.240 --> 00:16:53.840
that I mentioned, move this unit here, move&nbsp;
these unit there. We trained a large transformer,&nbsp;&nbsp;

00:16:53.840 --> 00:17:00.720
an LSTM model - it’s a different recurrent neural&nbsp;
network that is also very popular – to imitate&nbsp;&nbsp;

00:17:01.280 --> 00:17:06.000
human actions, but human actions, human&nbsp;
words that are in some data set. They're&nbsp;&nbsp;

00:17:06.000 --> 00:17:10.560
essentially the same or mapped to one another.
Oriol: So, in AlphaCode, the first step,&nbsp;&nbsp;

00:17:10.560 --> 00:17:17.280
like in AlphaStar, was to pre-train an agent that&nbsp;
was able to imitate human moves. In this case,&nbsp;&nbsp;

00:17:17.280 --> 00:17:23.760
of course, this is a very language centric task.&nbsp;
We took GitHub, which is a massive repository of&nbsp;&nbsp;

00:17:23.760 --> 00:17:28.160
human code, and then we said, hey,&nbsp;
let's start from pre-training on this&nbsp;&nbsp;

00:17:28.160 --> 00:17:34.240
large amount of data, so that we have a&nbsp;
first transformer model that is able to&nbsp;&nbsp;

00:17:34.240 --> 00:17:37.840
produce code that looks reasonable.
Oriol: And this is actually a key&nbsp;&nbsp;

00:17:37.840 --> 00:17:43.040
ingredient of maybe all of these&nbsp;
tools that could potentially help&nbsp;&nbsp;

00:17:43.040 --> 00:17:48.320
software engineers to auto-complete but be much&nbsp;
more than auto-complete. So that's the first step&nbsp;&nbsp;

00:17:48.320 --> 00:17:54.960
of AlphaCode. But now the crucial step, there's&nbsp;
two extra sort of algorithmic things you do. Once&nbsp;&nbsp;

00:17:54.960 --> 00:18:00.800
you have this pre-trained amount of knowledge,&nbsp;
this is mostly knowing how to continue programs,&nbsp;&nbsp;

00:18:00.800 --> 00:18:06.000
but it does not know about this particular&nbsp;
format, which is, I'll give you a long language&nbsp;&nbsp;

00:18:06.000 --> 00:18:10.880
description of the algorithm you should be doing.
Oriol: And then please just generate code that&nbsp;&nbsp;

00:18:10.880 --> 00:18:16.240
is correct. Period. There's no ambiguity&nbsp;
in the metrics, which is very important.&nbsp;&nbsp;

00:18:16.240 --> 00:18:20.640
And probably when you talked to Pushmeet&nbsp;
actually about AlphaFold and many other examples,&nbsp;&nbsp;

00:18:20.640 --> 00:18:24.800
having a good metric and a good benchmark&nbsp;
is critical to assess advancements.&nbsp;&nbsp;

00:18:25.600 --> 00:18:32.800
So, similar to there, we collected all the data&nbsp;
that exists in these platforms, in these websites&nbsp;&nbsp;

00:18:32.800 --> 00:18:37.360
that people have been competing in for many years.
Oriol: So, we'd actually talked to the creator of&nbsp;&nbsp;

00:18:37.360 --> 00:18:43.520
one of these platforms. And this person was&nbsp;
very excited actually to see what an AI could&nbsp;&nbsp;

00:18:43.520 --> 00:18:48.000
do. They really thought it would be impossible&nbsp;
to do anything reasonable, which is always a&nbsp;&nbsp;

00:18:48.000 --> 00:18:55.600
good sign when you work on these projects. And we&nbsp;
collected, let's say 15,000 examples. It's not a&nbsp;&nbsp;

00:18:55.600 --> 00:19:00.080
large amount of data in machine learning, right?
Oriol: 15,000 is actually smaller than MNIST,&nbsp;&nbsp;

00:19:00.080 --> 00:19:06.080
right? This very popular data set that sparked&nbsp;
some of the early work on convolutional neural&nbsp;&nbsp;

00:19:06.080 --> 00:19:11.120
networks. So, we created this specialized&nbsp;
data set of input-output examples,&nbsp;&nbsp;

00:19:12.080 --> 00:19:18.000
15,000 of them, which contained the language&nbsp;
description. And then the code that could be&nbsp;&nbsp;

00:19:18.560 --> 00:19:24.560
tens or hundreds of lines of code that implement&nbsp;
a solution to that particular problem from past&nbsp;&nbsp;

00:19:25.360 --> 00:19:31.920
competitions, right? Then we took these massive&nbsp;
language model that we pre-train, we fine tune it,&nbsp;&nbsp;

00:19:31.920 --> 00:19:37.520
which is actually a very common tool again, in the&nbsp;
toolbox. If you will, this is a common practice,&nbsp;&nbsp;

00:19:37.520 --> 00:19:43.920
you will do with neural nets. We fine tune it, to&nbsp;
be good at this particular setting, so to speak.&nbsp;

00:19:43.920 --> 00:19:50.080
Oriol: Although honestly, I was skeptical and&nbsp;
surprised to see that with such small amount of&nbsp;&nbsp;

00:19:50.080 --> 00:19:56.800
data, we were able to indeed steer this model,&nbsp;
this transformer model to now become not very&nbsp;&nbsp;

00:19:56.800 --> 00:20:02.080
good at, but it started to be reasonable&nbsp;
at solving some of the easiest problems.&nbsp;&nbsp;

00:20:02.720 --> 00:20:08.240
And once you see something promising, that is&nbsp;
when you start iterating, you start developing&nbsp;&nbsp;

00:20:08.240 --> 00:20:16.400
new sort of components, new tools, new algorithmic&nbsp;
insights. And basically, we started from solving&nbsp;&nbsp;

00:20:17.040 --> 00:20:22.960
maybe 2% of the problem, the test set we&nbsp;
had collected from this website through&nbsp;&nbsp;

00:20:22.960 --> 00:20:29.360
many innovations, to the 34% or so, a solve rate&nbsp;
that made us believe this might be at human level.&nbsp;&nbsp;

00:20:30.320 --> 00:20:35.920
At which point we took that neural network and&nbsp;
actually placed it in the web server competition.&nbsp;

00:20:35.920 --> 00:20:40.160
Oriol: After a competition was held, we&nbsp;
entered, and we then measured ourselves.&nbsp;&nbsp;

00:20:40.960 --> 00:20:45.440
So, the last, very step though, that&nbsp;
was needed besides some innovation,&nbsp;&nbsp;

00:20:45.440 --> 00:20:50.800
some techniques that are perhaps very deep in&nbsp;
the toolbox, not so generic yet, but we might&nbsp;&nbsp;

00:20:50.800 --> 00:20:56.560
be using them in further projects, of course,&nbsp;
was the idea that came from actually AlphaGo,&nbsp;&nbsp;

00:20:56.560 --> 00:21:03.280
which is the idea of search. You have this&nbsp;
natural description, natural language description.&nbsp;&nbsp;

00:21:03.920 --> 00:21:10.480
You can generate one program, but you can generate&nbsp;
10 programs or 50 or a hundred or a thousand. And&nbsp;&nbsp;

00:21:10.480 --> 00:21:17.360
then the question is to find a program that looks&nbsp;
promising enough that you will bother to go to the&nbsp;&nbsp;

00:21:17.360 --> 00:21:22.400
web server and submit it. We don't, we didn't want&nbsp;
to submit millions of programs to the web server.&nbsp;

00:21:22.400 --> 00:21:27.120
Oriol: We actually thought 10 attempts is&nbsp;
maybe the max that we will attempt to at most,&nbsp;&nbsp;

00:21:27.120 --> 00:21:31.920
since that felt reasonable and talking to the&nbsp;
creator of the website also thought that seems&nbsp;&nbsp;

00:21:31.920 --> 00:21:38.880
reasonable as well. So, we created many different&nbsp;
program possibilities by essentially sampling the&nbsp;&nbsp;

00:21:38.880 --> 00:21:46.640
language model almost let's say a million times.
Oriol: And then we developed something very&nbsp;&nbsp;

00:21:46.640 --> 00:21:52.400
similar to what the value functions&nbsp;
do in, for instance, AlphaGo, which is&nbsp;&nbsp;

00:21:53.280 --> 00:21:58.800
what is the programs we should be picking out&nbsp;
of these millions of programs that we should&nbsp;&nbsp;

00:21:58.800 --> 00:22:04.720
submit. So, then we developed a few techniques to&nbsp;
filter down all these programs, that some of them&nbsp;&nbsp;

00:22:04.720 --> 00:22:09.120
didn't compile, but some of them did compile&nbsp;
and some of them pass the test we knew about,&nbsp;&nbsp;

00:22:09.120 --> 00:22:12.800
but we didn't know if they were correct.
Oriol: So, we filtered them down&nbsp;&nbsp;

00:22:13.360 --> 00:22:20.080
to 10 at most. And then we submitted to the server&nbsp;
and the results we got, I think impressed really&nbsp;&nbsp;

00:22:20.080 --> 00:22:24.320
like many people that probably have quite&nbsp;
a lot of knowledge about machine learning&nbsp;&nbsp;

00:22:24.880 --> 00:22:29.760
and then this programming contest. But at the&nbsp;
same time, I think what's cool about this is,&nbsp;&nbsp;

00:22:29.760 --> 00:22:36.800
it's human level, but it's not at the top&nbsp;
level. And there is still a long gap and&nbsp;&nbsp;

00:22:36.800 --> 00:22:42.720
a long way to go. In a way, this is almost the&nbsp;
beginning where we have a very good benchmark.&nbsp;&nbsp;

00:22:42.720 --> 00:22:48.320
We think this benchmark tests reasoning,&nbsp;
problem-solving abilities, et cetera. And&nbsp;&nbsp;

00:22:48.320 --> 00:22:54.160
the transformer is a great tool, but maybe&nbsp;
we need better tools or enhancing tools&nbsp;&nbsp;

00:22:54.160 --> 00:22:59.120
to then climb this ladder or leaderboard.
Oriol: That is one of the many that exist&nbsp;&nbsp;

00:22:59.120 --> 00:23:03.360
of course, in the machine learning community.
Craig: Yeah. Yeah. I have a couple of&nbsp;&nbsp;

00:23:03.360 --> 00:23:11.280
questions. The pre-training on GitHub&nbsp;
that's an unsupervised task, right?&nbsp;

00:23:12.320 --> 00:23:18.160
Oriol: Yes. There is a potential debate what&nbsp;
unsupervised means. So, I want to maybe just&nbsp;&nbsp;

00:23:18.160 --> 00:23:27.200
maybe explain. So, typically it is unsupervised in&nbsp;
the sense that this is a dataset that exists. And&nbsp;&nbsp;

00:23:27.200 --> 00:23:32.880
you just take, let's say a large collection of&nbsp;
programs that were written for whatever purposes.&nbsp;&nbsp;

00:23:32.880 --> 00:23:39.200
And you just learn a system that will predict&nbsp;
what is the next word or token or character.&nbsp;&nbsp;

00:23:40.000 --> 00:23:45.440
And in that sense, it is unsupervised because we&nbsp;
didn't label this data set, we didn't do any extra&nbsp;&nbsp;

00:23:45.440 --> 00:23:51.760
work on it. But in a way it might be supervised&nbsp;
because this is, someone wrote that code and&nbsp;&nbsp;

00:23:51.760 --> 00:23:58.880
it's not random programs, right? These programs&nbsp;
were not randomly generated. But I would say,&nbsp;&nbsp;

00:23:58.880 --> 00:24:04.800
yeah, this is an unsupervised pre-training step&nbsp;
that most language models undertake these days.&nbsp;

00:24:04.800 --> 00:24:12.320
Craig: But the second step of then&nbsp;
training on the competition set&nbsp;&nbsp;

00:24:13.040 --> 00:24:22.000
that's in effect a labeled data set because you&nbsp;
have scores for how well the different programs&nbsp;&nbsp;

00:24:22.000 --> 00:24:25.920
performed and that sort of thing.
Oriol: Yeah. So, the second step,&nbsp;&nbsp;

00:24:25.920 --> 00:24:32.480
maybe the best sort of parallel to trace&nbsp;
here is with that of machine translation.&nbsp;

00:24:32.480 --> 00:24:38.560
Oriol: So, imagine we know we can get&nbsp;
a lot of English text on the internet.&nbsp;&nbsp;

00:24:38.560 --> 00:24:43.600
We can get a lot of Spanish texts as well. So&nbsp;
that would be what we did in pre-training. We&nbsp;&nbsp;

00:24:43.600 --> 00:24:49.520
got a lot of Python and C++ texts, and we just&nbsp;
trained the model on that. But then we needed to&nbsp;&nbsp;

00:24:49.520 --> 00:24:57.040
know how to translate, and it is a very good way&nbsp;
to put it, actually. How to translate this natural&nbsp;&nbsp;

00:24:57.040 --> 00:25:03.520
language description high-level description,&nbsp;
translate that to an algorithmic solution in&nbsp;&nbsp;

00:25:03.520 --> 00:25:09.760
Python or C++, the two languages we focused on for&nbsp;
no reason then other than that, they are popular.&nbsp;

00:25:09.760 --> 00:25:13.840
Oriol: So, the second data set needs&nbsp;
to be paired, right? This needs to have&nbsp;&nbsp;

00:25:14.480 --> 00:25:19.840
on the one hand, the description, and the other&nbsp;
hand, you have the solution for that description&nbsp;&nbsp;

00:25:19.840 --> 00:25:25.280
that someone brought with other intents. So&nbsp;
maybe that of course constitutes what we would&nbsp;&nbsp;

00:25:25.280 --> 00:25:31.120
call supervised sequence-to-sequence learning,&nbsp;
which is actually a project that I worked on with&nbsp;&nbsp;

00:25:31.840 --> 00:25:36.720
folks at Google Brain a long time ago for&nbsp;
machine translation initially, but which has been&nbsp;&nbsp;

00:25:36.720 --> 00:25:42.080
applied to many other sorts of domains, right?
Oriol: You can translate English to Spanish.&nbsp;&nbsp;

00:25:42.080 --> 00:25:46.800
You can translate an image to text. You can&nbsp;
translate the text to an image. You can translate&nbsp;&nbsp;

00:25:46.800 --> 00:25:51.520
a specification of a problem to the code&nbsp;
that solves it, right. And that's maybe&nbsp;&nbsp;

00:25:51.520 --> 00:25:58.720
the easiest way to see it parallel to that.
Craig: Yeah. So, the purpose of AlphaStar&nbsp;&nbsp;

00:25:58.720 --> 00:26:02.800
isn't to create an agent that&nbsp;
can beat everybody at StarCraft.&nbsp;&nbsp;

00:26:03.600 --> 00:26:11.040
It's a research effort to advance the science.&nbsp;
And is that the same case with AlphaCode or in&nbsp;&nbsp;

00:26:11.040 --> 00:26:19.200
AlphaCode's case is the end goal more specific&nbsp;
that you really want to create an agent&nbsp;&nbsp;

00:26:19.760 --> 00:26:25.520
that can code from natural language?
Oriol: So that's a great question. I think there's&nbsp;&nbsp;

00:26:25.520 --> 00:26:33.520
always the tension. When I think, this is actually&nbsp;
a very nice portrayal deep learning. We care about&nbsp;&nbsp;

00:26:33.520 --> 00:26:38.080
the toolbox, right? So, if you think of, oh, I'm&nbsp;
a deep learning researcher, I'm leading the deep&nbsp;&nbsp;

00:26:38.080 --> 00:26:45.280
learning team. What is our goal? Our goal is to&nbsp;
expand with more powerful tools so that any new&nbsp;&nbsp;

00:26:45.280 --> 00:26:50.960
problem, any new domain, any new fields, right?&nbsp;
Like biology, like we went pretty far from machine&nbsp;&nbsp;

00:26:50.960 --> 00:26:57.840
learning and there is more to come that we can&nbsp;
have the powerful tools that will be needed for&nbsp;&nbsp;

00:26:57.840 --> 00:27:04.800
very specific domains that have very hard problems&nbsp;
to be solved. So, from a deep learning and perhaps&nbsp;&nbsp;

00:27:04.800 --> 00:27:10.400
zooming out from a solving AGI standpoint, which&nbsp;
is ultimately what we're after at DeepMind,&nbsp;&nbsp;

00:27:11.680 --> 00:27:17.600
absolutely the view of, these are benchmarks.
Oriol: We get a lot of good information from&nbsp;&nbsp;

00:27:17.600 --> 00:27:24.160
them. We can generate new tools to advance, to&nbsp;
go to the next steps. That view is perfectly&nbsp;&nbsp;

00:27:24.160 --> 00:27:30.560
fine. And in fact, many of these projects,&nbsp;
I would say, have these characteristics as&nbsp;&nbsp;

00:27:30.560 --> 00:27:38.160
benchmarks that some of them might be solved and&nbsp;
we might revisit or not. And in the coding case,&nbsp;&nbsp;

00:27:38.800 --> 00:27:44.320
now going to your second point, since there&nbsp;
seems to be something fundamentally difficult&nbsp;&nbsp;

00:27:44.320 --> 00:27:52.800
about this, it's not over, we now are at the&nbsp;
beginning in a way of discovering how this&nbsp;&nbsp;

00:27:52.800 --> 00:27:59.760
wonderful sort of benchmark that humans created&nbsp;
that challenges them intellectually, et cetera.&nbsp;

00:27:59.760 --> 00:28:05.680
Oriol: How will these push the boundaries of the&nbsp;
techniques, but always the eye in deep learning is&nbsp;&nbsp;

00:28:05.680 --> 00:28:13.040
these techniques will be applied to other fields&nbsp;
and domains. And so, this connection with all the,&nbsp;&nbsp;

00:28:13.040 --> 00:28:18.240
you can almost connect, if you look at all the&nbsp;
many projects and work that goes at DeepMind,&nbsp;&nbsp;

00:28:18.240 --> 00:28:22.880
of course from the inside it is perhaps&nbsp;
easier, but it is quite natural to start&nbsp;&nbsp;

00:28:22.880 --> 00:28:27.600
seeing how these projects connect to one another.
Oriol: They connect with the techniques. They also&nbsp;&nbsp;

00:28:27.600 --> 00:28:33.440
connect wonderfully with the teams that are behind&nbsp;
these projects. There's a lot to be said about, of&nbsp;&nbsp;

00:28:33.440 --> 00:28:39.040
course, the researchers behind it. You're seeing&nbsp;
maybe a few of them, you get to talk to a few&nbsp;&nbsp;

00:28:39.040 --> 00:28:45.120
of them, but it is also interesting to understand&nbsp;
that these teams that go behind one of these hard&nbsp;&nbsp;

00:28:45.120 --> 00:28:52.320
goals, then will proceed to either keep iterating&nbsp;
over in this case, the coding one. Maybe some&nbsp;&nbsp;

00:28:52.320 --> 00:28:56.560
people will move on to other projects and so on.
Oriol: And this is actually how&nbsp;&nbsp;

00:28:56.560 --> 00:29:00.000
I think the field has advanced in a&nbsp;
way that perhaps it's a bit invisible&nbsp;&nbsp;

00:29:00.640 --> 00:29:06.400
to those who might not be as in as we are.
Craig: Yeah. Yeah, of course. Every time&nbsp;&nbsp;

00:29:06.400 --> 00:29:09.280
you work on a project, you carry the knowledge&nbsp;&nbsp;

00:29:11.200 --> 00:29:15.760
to your next project. A lot of that&nbsp;
knowledge is not written down in papers.&nbsp;

00:29:15.760 --> 00:29:21.280
Oriol: Absolutely, yeah.
Craig: But again, with AlphaCode,&nbsp;&nbsp;

00:29:21.280 --> 00:29:29.920
because I'm not a coder and I'm fascinated&nbsp;
by no code solutions and low code solutions,&nbsp;&nbsp;

00:29:31.840 --> 00:29:38.720
do you think there's a possibility that AlphaCode&nbsp;
could progress to the point where it could write&nbsp;&nbsp;

00:29:39.360 --> 00:29:43.200
more complex programs?
Oriol: Yeah, absolutely. So&nbsp;&nbsp;

00:29:43.200 --> 00:29:48.400
now going a bit deeper into coding as a&nbsp;
very interesting, very meta domain, right?&nbsp;

00:29:48.400 --> 00:29:54.080
Oriol: You have to, we're coding to generate&nbsp;
these tools. These tools in the box are actually&nbsp;&nbsp;

00:29:54.080 --> 00:29:59.280
pieces of code and so on. So, it's actually&nbsp;
a very dear domain to us researchers&nbsp;&nbsp;

00:30:00.160 --> 00:30:04.560
in machine learning. So, there is&nbsp;
quite a lot of excitement of course,&nbsp;&nbsp;

00:30:04.560 --> 00:30:10.560
about beyond the benchmark for towards AGI.
Oriol: Could this be just something that people&nbsp;&nbsp;

00:30:10.560 --> 00:30:16.640
find useful? Absolutely. But we are talking to,&nbsp;
there's obviously a lot, also a lot of teams&nbsp;&nbsp;

00:30:18.080 --> 00:30:22.800
across Google that are working on&nbsp;
similar projects. And you might&nbsp;&nbsp;

00:30:22.800 --> 00:30:26.800
have seen also other research. That's the&nbsp;
beautiful part of the community, right?&nbsp;&nbsp;

00:30:27.360 --> 00:30:34.160
So, I think we are exploring right the power,&nbsp;
how these techniques, maybe not the actual agent,&nbsp;&nbsp;

00:30:34.160 --> 00:30:39.120
not AlphaCode, if we call AlphaCode the set&nbsp;
of weights in the neural network, but how can&nbsp;&nbsp;

00:30:39.120 --> 00:30:45.440
we now take some of the techniques and apply them&nbsp;
in a setting that maybe it's more about making&nbsp;&nbsp;

00:30:46.080 --> 00:30:51.680
software engineers more productive, et cetera.
Oriol: And I think from what I can see, there's&nbsp;&nbsp;

00:30:51.680 --> 00:30:57.760
a very real possibility of a transformation.&nbsp;
It's probably going to be slower than some people&nbsp;&nbsp;

00:30:57.760 --> 00:31:07.440
think, but that's fine, on how we do and produce&nbsp;
code. Will the limit of as maybe writing down the&nbsp;&nbsp;

00:31:07.440 --> 00:31:12.960
problem like these competitions have that you want&nbsp;
to generate some sort of program that you just&nbsp;&nbsp;

00:31:12.960 --> 00:31:17.600
write it in natural language, no coding required?
Oriol: And then the solution comes out at the&nbsp;&nbsp;

00:31:17.600 --> 00:31:24.560
other end. Perhaps, AlphaCode clearly does that&nbsp;
with something that felt quite difficult, or it&nbsp;&nbsp;

00:31:24.560 --> 00:31:31.760
actually was impossible just a couple of years&nbsp;
ago. So, could these go beyond the setting, which&nbsp;&nbsp;

00:31:31.760 --> 00:31:37.920
is code competitions? This is a narrow domain in&nbsp;
a way. It's just specific kinds of algorithms.&nbsp;

00:31:37.920 --> 00:31:44.080
Oriol: They're very hard, but they're just short&nbsp;
programs. Can we go from here to a more end to end&nbsp;&nbsp;

00:31:44.080 --> 00:31:50.000
approach? I believe so. The question is, are&nbsp;
we going to focus on it? And I think for us,&nbsp;&nbsp;

00:31:50.000 --> 00:31:55.920
the main mission is always AGI. But of course&nbsp;
we are lucky to have many partners and many,&nbsp;&nbsp;

00:31:56.560 --> 00:31:59.840
that's how the field works.
Oriol: Really, actually, maybe,&nbsp;&nbsp;

00:31:59.840 --> 00:32:06.080
you could see this advance clearly will unlock&nbsp;
this. And the publication process is actually&nbsp;&nbsp;

00:32:06.080 --> 00:32:11.600
enabling others to also explore possibilities&nbsp;
of this kind of domain. So as a researcher&nbsp;&nbsp;

00:32:13.040 --> 00:32:18.480
and me personally, you always are balancing how&nbsp;
deep are you going to go into these domain vs&nbsp;&nbsp;

00:32:18.480 --> 00:32:21.280
well, I am a deep learning&nbsp;
researcher. The tools are there,&nbsp;&nbsp;

00:32:22.080 --> 00:32:27.280
go ahead. Use them. And that's also wonderful&nbsp;
when that happens, which obviously has happened&nbsp;&nbsp;

00:32:27.280 --> 00:32:31.600
as well, many times in our field.
Craig: Yup. And on this toolbox,&nbsp;&nbsp;

00:32:31.600 --> 00:32:39.600
you've been out talking about quite a bit.&nbsp;
Does DeepMind have a platform that researchers&nbsp;&nbsp;

00:32:39.600 --> 00:32:47.280
or practitioners or developers can use?
Oriol: Yeah. So, the toolbox, as I've been&nbsp;&nbsp;

00:32:47.280 --> 00:32:55.200
referring to is clearly a sort of very virtual&nbsp;
toolbox of ideas, right? Like the transformer&nbsp;&nbsp;

00:32:55.200 --> 00:33:04.000
model, knowledge distillation, LSTM, convolutional&nbsp;
networks. So, it's a toolbox of ideas. And then&nbsp;&nbsp;

00:33:04.000 --> 00:33:11.680
from the idea to the actual implementation there&nbsp;
is indeed a lot of tools, actual tools that you&nbsp;&nbsp;

00:33:11.680 --> 00:33:18.320
would call them in software engineering to then&nbsp;
develop and almost like it's like a puzzle to&nbsp;&nbsp;

00:33:18.320 --> 00:33:24.400
work on a new application, to crack a new&nbsp;
benchmark, to go to like I know physics and try&nbsp;&nbsp;

00:33:24.400 --> 00:33:29.680
to make a change there. There's a lot of very cool&nbsp;
things happening where people in different fields&nbsp;&nbsp;

00:33:30.480 --> 00:33:34.480
because the tools are not only the&nbsp;
toolbox of ideas, but the tools&nbsp;&nbsp;

00:33:34.480 --> 00:33:38.960
actually to run them are fairly developed.
Oriol: They can go ahead and try them. And it's&nbsp;&nbsp;

00:33:38.960 --> 00:33:46.800
amazing to see how other fields are embracing this&nbsp;
approach and basically getting it. So academic&nbsp;&nbsp;

00:33:46.800 --> 00:33:54.960
labs like ours in industry and in universities,&nbsp;
they're part of some ecosystem of like software,&nbsp;&nbsp;

00:33:54.960 --> 00:34:00.480
which actually, if I think about why.
Oriol: What has happened? Why is this&nbsp;&nbsp;

00:34:00.480 --> 00:34:06.800
so popular? Why in 2009, deep learning&nbsp;
wasn't as popular as now? Software,&nbsp;&nbsp;

00:34:06.800 --> 00:34:15.120
and the actual open sourcing of platforms. That's&nbsp;
been a key in the community. So indeed, there's&nbsp;&nbsp;

00:34:15.120 --> 00:34:21.040
obviously a few choices depending on what you&nbsp;
want to do as a practitioner and as a researcher,&nbsp;&nbsp;

00:34:21.040 --> 00:34:27.520
but you can certainly map instantiations or,&nbsp;
realizations of the virtual tools to then,&nbsp;&nbsp;

00:34:28.080 --> 00:34:33.760
any of the platforms that are very popular.
Oriol: Now, there is obviously PyTorch,&nbsp;&nbsp;

00:34:33.760 --> 00:34:42.960
TensorFlow, JAX and the ones to come. As we say in&nbsp;
the field, if in five years we are using the same&nbsp;&nbsp;

00:34:42.960 --> 00:34:47.840
tools as in software tools, something is wrong&nbsp;
because the field is advancing so fast that&nbsp;&nbsp;

00:34:48.400 --> 00:34:54.960
when you create these open-source libraries that&nbsp;
are used, the research takes over and there's&nbsp;&nbsp;

00:34:54.960 --> 00:35:00.480
something unexpected that you did not account for.&nbsp;
And sometimes you need to start from scratch and&nbsp;&nbsp;

00:35:00.480 --> 00:35:08.080
have a new framework and a new platform.
Craig: Yeah. So, you're not personally, you're not&nbsp;&nbsp;

00:35:08.880 --> 00:35:19.200
drilling down into the possibilities of AlphaCode&nbsp;
as a particular domain. Where is your research&nbsp;&nbsp;

00:35:19.200 --> 00:35:26.000
going next or are you still working on AlphaCode.
Oriol: Yeah, that's a good question. Obviously,&nbsp;&nbsp;

00:35:26.720 --> 00:35:28.400
we are still working on AlphaCode.&nbsp;&nbsp;

00:35:30.320 --> 00:35:34.880
We have in the deep learning team&nbsp;
and obviously DeepMind in general,&nbsp;&nbsp;

00:35:34.880 --> 00:35:39.520
we have quite a few projects. So AlphaCode,&nbsp;
usually when you see a publication, sometimes it's&nbsp;&nbsp;

00:35:41.040 --> 00:35:47.520
a milestone that we hit, or a checkpoint.
Oriol: But, we keep working on it. As part of&nbsp;&nbsp;

00:35:47.520 --> 00:35:53.280
the many projects that I oversee personally&nbsp;
as the leader of the deep learning team.&nbsp;&nbsp;

00:35:54.880 --> 00:36:02.400
I've been, from a personal standpoint, I've&nbsp;
been very actually if I look at, when I&nbsp;&nbsp;

00:36:02.400 --> 00:36:11.280
joined DeepMind in 2016, one of the things that I&nbsp;
immediately catch upon was this idea, at the time&nbsp;&nbsp;

00:36:11.280 --> 00:36:18.320
maybe the popular name was meta-learning, which is&nbsp;
the idea that you can learn to learn so to speak,&nbsp;&nbsp;

00:36:18.320 --> 00:36:24.800
right? Traditionally, in supervised learning, you&nbsp;
take some data set, you train a neural network,&nbsp;&nbsp;

00:36:24.800 --> 00:36:30.640
and that neural network does something useful&nbsp;
like translating, transcribing speech, or&nbsp;&nbsp;

00:36:30.640 --> 00:36:38.400
writing code. But this idea of meta learning that&nbsp;
you can teach a model, something new was happening&nbsp;&nbsp;

00:36:38.400 --> 00:36:45.040
at the time through a very simplistic view of this&nbsp;
approach, which, at the time we obviously imagined&nbsp;&nbsp;

00:36:45.040 --> 00:36:48.720
that this is still a very valid benchmark, right?
Oriol: That we were working on still&nbsp;&nbsp;

00:36:48.720 --> 00:36:54.240
to advance the toolbox. But ImageNet was,&nbsp;
oh, there's a closed data set, thousands&nbsp;&nbsp;

00:36:55.200 --> 00:37:00.880
of categories of objects. And there you go you&nbsp;
need to be more accurate in the next generation&nbsp;&nbsp;

00:37:00.880 --> 00:37:05.840
of neural networks. But what happened&nbsp;
at the time is we took ImageNet, and we&nbsp;&nbsp;

00:37:06.400 --> 00:37:12.240
invented a new task, which was, when I test your&nbsp;
model, I'm not going to ask you from an image,&nbsp;&nbsp;

00:37:12.240 --> 00:37:17.120
can you classify it onto one of the thousand&nbsp;
objects. Instead, I'm going to give you a few&nbsp;&nbsp;

00:37:17.120 --> 00:37:21.520
input-output examples that you've never&nbsp;
seen, right? New categories of objects.&nbsp;&nbsp;

00:37:21.520 --> 00:37:26.480
And then you need to create a system that&nbsp;
is able to observe this information very&nbsp;&nbsp;

00:37:26.480 --> 00:37:31.280
quickly with very little data, right?
Oriol: One example per category, perhaps,&nbsp;&nbsp;

00:37:31.280 --> 00:37:36.480
and do well at that. And that was happening at&nbsp;
the time through image classification. We call&nbsp;&nbsp;

00:37:36.480 --> 00:37:42.400
this few shot learning and then feed forward,&nbsp;
it turns out that these large language models&nbsp;&nbsp;

00:37:42.960 --> 00:37:47.760
are excellent at future learning and&nbsp;
at learning sort of things that you can&nbsp;&nbsp;

00:37:47.760 --> 00:37:52.640
induce at test time, so to speak, right?
Oriol: So, these models are trained to be&nbsp;&nbsp;

00:37:53.520 --> 00:37:59.040
good at predicting these unsupervised data of&nbsp;
all the texts on the internet or all the code&nbsp;&nbsp;

00:37:59.040 --> 00:38:06.320
on GitHub. But then there is a lot of research&nbsp;
to be done in my opinion, but a lot of exciting&nbsp;&nbsp;

00:38:06.320 --> 00:38:13.120
opportunities for teaching this model something&nbsp;
new, but not learning, fine tuning is one&nbsp;&nbsp;

00:38:13.120 --> 00:38:19.360
approach that is not the most elegant perhaps.
Oriol: So, I think what I'm now focusing more&nbsp;&nbsp;

00:38:19.360 --> 00:38:24.240
on is these capabilities of meta-learning as&nbsp;
we called them back in the day. But now you&nbsp;&nbsp;

00:38:24.240 --> 00:38:29.920
could call this few-shot learning or this ability&nbsp;
that you can literally have a model that you can&nbsp;&nbsp;

00:38:30.880 --> 00:38:35.520
instruct, so to speak, just say, hey,&nbsp;
here is an image of these objects.&nbsp;

00:38:35.520 --> 00:38:39.440
Oriol: Here is another image of these other&nbsp;
objects. Can you now play this game with&nbsp;&nbsp;

00:38:39.440 --> 00:38:46.880
me? And it's a transformation of how we are&nbsp;
testing models in machine learning that has&nbsp;&nbsp;

00:38:46.880 --> 00:38:52.080
been ongoing for a long time. Of course,&nbsp;
like this the field always has newer&nbsp;&nbsp;

00:38:52.080 --> 00:38:57.520
benchmarks and words for describing things.
Oriol: But right now, AlphaCode is perhaps&nbsp;&nbsp;

00:38:57.520 --> 00:39:04.080
an instantiation of that in very particular&nbsp;
ways, but I'm very excited about some of the&nbsp;&nbsp;

00:39:04.080 --> 00:39:10.240
recent work also that the team has been doing&nbsp;
on this particular aspect where it's not only&nbsp;&nbsp;

00:39:10.240 --> 00:39:15.680
about language, but about vision, which links very&nbsp;
nicely back to this idea of, hey, can we classify&nbsp;&nbsp;

00:39:16.640 --> 00:39:19.760
these two objects from one another?
Oriol: We could at the time, but it&nbsp;&nbsp;

00:39:19.760 --> 00:39:27.040
was a very cumbersome way to do so. Now, we&nbsp;
can literally not only classify but teach&nbsp;&nbsp;

00:39:27.040 --> 00:39:33.440
almost any computer vision tasks to models by&nbsp;
basically showing, hey, these emails, tell me&nbsp;&nbsp;

00:39:33.440 --> 00:39:39.600
something about it. You can ask it more and so on.&nbsp;
And in part of our large language models research,&nbsp;&nbsp;

00:39:39.600 --> 00:39:46.160
the latest actually release which was just&nbsp;
released a few days ago was this model Flamingo,&nbsp;&nbsp;

00:39:46.160 --> 00:39:51.120
which is a visual language model,&nbsp;
that knows a lot about language,&nbsp;&nbsp;

00:39:51.120 --> 00:39:57.360
but actually is grounded in images.
Oriol: And I think that sort of link that comes&nbsp;&nbsp;

00:39:57.360 --> 00:40:02.160
from when I joined DeepMind to say, wow, that's&nbsp;
amazing. I wanted to learn about reinforcement&nbsp;&nbsp;

00:40:02.160 --> 00:40:09.920
learning. So naturally I went into projects like&nbsp;
AlphaStar and AlphaCode to now just say wait a&nbsp;&nbsp;

00:40:09.920 --> 00:40:14.800
second this is something super exciting.
Oriol: So that's one of the&nbsp;&nbsp;

00:40:14.800 --> 00:40:20.800
kinds of focuses that I'm switching my sort&nbsp;
of research attention towards for sure. Yeah.&nbsp;

00:40:20.800 --> 00:40:27.440
Craig: Can you talk a little bit; you mentioned&nbsp;
a few times already AGI and DeepMind is&nbsp;&nbsp;

00:40:27.440 --> 00:40:33.360
famous for having that as an ultimate goal.
Craig: Is there a roadmap? And you mentioned&nbsp;&nbsp;

00:40:34.720 --> 00:40:48.480
guideposts or milestones. Do you guys sit down and&nbsp;
have an overall roadmap that may get dimmer the&nbsp;&nbsp;

00:40:49.520 --> 00:40:55.200
further you get in the future of how all of these&nbsp;
things are contributing and how you expect them&nbsp;&nbsp;

00:40:56.000 --> 00:40:58.480
to converge some day?
Oriol: Yeah, absolutely.&nbsp;

00:40:58.480 --> 00:41:06.720
Oriol: The roadmap toward a sort of AI&nbsp;
that would be general that would be able to&nbsp;&nbsp;

00:41:06.720 --> 00:41:12.480
learn with you the way I actually just described&nbsp;
it. That's very much in discussions, of course,&nbsp;&nbsp;

00:41:12.480 --> 00:41:17.200
at DeepMind and in the community, that&nbsp;
is, how to get there. What are the right&nbsp;&nbsp;

00:41:17.200 --> 00:41:20.720
benchmarks? And all that entails.
Oriol: I think this is basically&nbsp;&nbsp;

00:41:22.800 --> 00:41:29.280
probably the main topic of discussion in the main&nbsp;
machine learning conferences, to some extent, and&nbsp;&nbsp;

00:41:29.280 --> 00:41:36.080
certainly at DeepMind since that's our mission.&nbsp;
We were doing these projects with a lot of, with&nbsp;&nbsp;

00:41:36.080 --> 00:41:43.440
the mindset that's where we're going. So that's&nbsp;
why perhaps it was useful to depict this level of&nbsp;&nbsp;

00:41:43.440 --> 00:41:50.320
difficulty of perhaps single domains, right?
Oriol: Like from Atari, to chess to Go,&nbsp;&nbsp;

00:41:50.320 --> 00:41:54.960
to StarCraft, right? That's a thread that&nbsp;
doesn't happen randomly. This is something that&nbsp;&nbsp;

00:41:55.840 --> 00:42:02.000
you can see where we're going. In fact, I did&nbsp;
work on StarCraft back in my Berkeley days&nbsp;&nbsp;

00:42:02.560 --> 00:42:08.480
which is a fun fact. And at the time I remember&nbsp;
the mindset we were not ready to do StarCraft.&nbsp;

00:42:08.480 --> 00:42:13.440
Oriol: We were working on Atari in this end-to-end&nbsp;
fashion, like machine learning fashion. So&nbsp;&nbsp;

00:42:13.440 --> 00:42:20.800
clearly you can see, especially externally, which&nbsp;
is obviously the things that you see more visibly,&nbsp;&nbsp;

00:42:21.440 --> 00:42:25.600
you can certainly depict these little&nbsp;
roads that are increasing in difficulty&nbsp;&nbsp;

00:42:25.600 --> 00:42:30.000
and impressiveness towards AGI.
Oriol: And then of course, where to go next is&nbsp;&nbsp;

00:42:30.000 --> 00:42:38.240
the question. I remember someone, when I joined&nbsp;
my PhD, they said 90% of your PhD is the question&nbsp;&nbsp;

00:42:38.240 --> 00:42:44.080
you're asking. So, it is a very hard question&nbsp;
to find what is the next thing on the road that&nbsp;&nbsp;

00:42:44.080 --> 00:42:50.960
will provide progress and signal towards that.
Oriol: So indeed, we talk a lot about it, but&nbsp;&nbsp;

00:42:51.520 --> 00:42:56.880
what you're seeing is hopefully, it's something&nbsp;
that will make sense when we look back. And it's&nbsp;&nbsp;

00:42:56.880 --> 00:43:02.160
actually quite a useful exercise to actually,&nbsp;
for me to be talking to you because sometimes you&nbsp;&nbsp;

00:43:02.160 --> 00:43:07.680
on the fly, you might not realize it as&nbsp;
easily until you connect the dots and say,&nbsp;&nbsp;

00:43:07.680 --> 00:43:12.480
of course we were seeking this, for&nbsp;
instance, learning ability of the models.&nbsp;

00:43:12.480 --> 00:43:18.160
Oriol: And now maybe the timing wasn't quite&nbsp;
ready there. Now it is. We're focusing on that&nbsp;&nbsp;

00:43:18.160 --> 00:43:24.560
as a key capability of intelligence. So, I&nbsp;
would say, yes, we definitely roadmap what&nbsp;&nbsp;

00:43:24.560 --> 00:43:31.120
it might be like to reach the goal of a&nbsp;
truly intelligent system like AGI would be.&nbsp;

00:43:31.120 --> 00:43:37.440
Craig: Yeah. And that kind of intelligence&nbsp;
system would be multimodal. It would have vision,&nbsp;&nbsp;

00:43:39.200 --> 00:43:51.520
language, agency - you'd be able to take actions.&nbsp;
So, the game trajectory and that's the agency&nbsp;&nbsp;

00:43:51.520 --> 00:44:00.880
trajectory, and AlphaCode is the language&nbsp;
trajectory. Is that the way to think of it?&nbsp;&nbsp;

00:44:00.880 --> 00:44:06.880
And then eventually these threads will intertwine.
Oriol: Yeah. I'm quite impressed&nbsp;&nbsp;

00:44:06.880 --> 00:44:10.000
with the way you put it.
Oriol: I think that's actually a very nice&nbsp;&nbsp;

00:44:11.520 --> 00:44:18.720
description of what an AGI to me personally, would&nbsp;
look like. There, there would be arguments to be&nbsp;&nbsp;

00:44:18.720 --> 00:44:25.920
said that perhaps language is all you need, but&nbsp;
there could be arguments to say, we don't need&nbsp;&nbsp;

00:44:25.920 --> 00:44:33.520
language, right? But from looking back at my&nbsp;
own research kind of passions, these clearly&nbsp;&nbsp;

00:44:34.240 --> 00:44:41.280
is tracing by nicely what it might be like you&nbsp;
said, like multimodality vision and language,&nbsp;&nbsp;

00:44:41.280 --> 00:44:47.840
and then capacity to take actions that feels&nbsp;
like baking ingredients. And indeed, you can see&nbsp;&nbsp;

00:44:48.560 --> 00:44:53.160
how we advance the toolbox on these&nbsp;
ingredients when we work on these.&nbsp;

00:44:53.160 --> 00:44:59.680
Oriol: So that's why, by the way, why do we&nbsp;
work on ImagNet? Because it enhances the visual&nbsp;&nbsp;

00:44:59.680 --> 00:45:05.920
capabilities of whatever ultimate models may&nbsp;
come up in the future. It's still a very valid&nbsp;&nbsp;

00:45:05.920 --> 00:45:13.280
benchmark to test those abilities in a very nicely&nbsp;
controlled environment. They are very well thought&nbsp;&nbsp;

00:45:13.280 --> 00:45:21.040
out benchmarks and linking back to AlphaCode,&nbsp;
probably the reasoning abilities required.&nbsp;&nbsp;

00:45:21.680 --> 00:45:26.720
They're still primitive, but the way we advance&nbsp;
them in part will be, hey, how are we doing&nbsp;&nbsp;

00:45:26.720 --> 00:45:32.240
on these benchmarks? And that may stick for years,&nbsp;
depending of course, on the rate of progress.&nbsp;

00:45:32.240 --> 00:45:39.360
Craig: Yeah. You're focused largely throughout&nbsp;
your career on sequence-to-sequence learning.&nbsp;&nbsp;

00:45:40.960 --> 00:45:49.200
And there's been a lot of talk at OpenAI at&nbsp;
Qinghua University and some other institutes about&nbsp;&nbsp;

00:45:51.120 --> 00:46:00.560
developing these systems for video. Being able to&nbsp;
describe something and have an AI system produce&nbsp;&nbsp;

00:46:00.560 --> 00:46:07.680
video in the way that Dall-E produces an image.&nbsp;
Are you working on video at all in that way?&nbsp;

00:46:07.680 --> 00:46:16.720
Oriol: Yeah, so personally I haven't worked on&nbsp;
video other than the new model that is Flamingo,&nbsp;&nbsp;

00:46:16.720 --> 00:46:23.120
which you could think of as a language model. It&nbsp;
has a particular way to understand special words&nbsp;&nbsp;

00:46:23.120 --> 00:46:29.680
that are either images or videos actually. So, we&nbsp;
added, basically we enhance the capacity of the&nbsp;&nbsp;

00:46:29.680 --> 00:46:38.840
amazing language models with some borrowings from&nbsp;
ImageNet and vision to have them be doing both.&nbsp;

00:46:38.840 --> 00:46:44.480
Oriol: Like you can input a video or an image as&nbsp;
part of what you're talking about with the model.&nbsp;&nbsp;

00:46:44.480 --> 00:46:52.880
So that's maybe very recent and it included video&nbsp;
as inputs. And as outputs, there is definitely&nbsp;&nbsp;

00:46:52.880 --> 00:47:00.160
lots of work to be done. It's one of the, I&nbsp;
remember talking to one of the professors at&nbsp;&nbsp;

00:47:00.160 --> 00:47:06.560
Berkeley who is a very well-known computer vision&nbsp;
researcher about the idea of the generating.&nbsp;

00:47:06.560 --> 00:47:11.920
Oriol: You only truly understand the world. If you&nbsp;
can take a still image and maybe generate a video&nbsp;&nbsp;

00:47:11.920 --> 00:47:17.440
from it. So, I've been always fascinated&nbsp;
by this. I very lightly touched upon this&nbsp;&nbsp;

00:47:17.440 --> 00:47:21.840
topic back when we were in the very early&nbsp;
days of sequence-to-sequence learning. So,&nbsp;&nbsp;

00:47:21.840 --> 00:47:27.920
we had one, one of the benchmarks we were doing&nbsp;
what's called moving MNIST, which is boringly&nbsp;&nbsp;

00:47:28.640 --> 00:47:35.760
MNIST digits that moves around - it's a&nbsp;
benchmark for video prediction or generation.&nbsp;&nbsp;

00:47:35.760 --> 00:47:39.840
That was a few years ago.
Oriol: But from the recent past&nbsp;&nbsp;

00:47:40.880 --> 00:47:45.520
at DeepMind, actually not me personally,&nbsp;
but there's been work that had very&nbsp;&nbsp;

00:47:45.520 --> 00:47:49.840
nice follow-up work, in fact, connecting&nbsp;
nicely to the science part of our mission,&nbsp;&nbsp;

00:47:49.840 --> 00:47:57.280
which is to advance science with AGI. So, we had&nbsp;
a model that was called, it's called video GANs.&nbsp;

00:47:57.280 --> 00:48:03.520
Oriol: So GANs from the generative adversarial&nbsp;
networks and boringly, like the name is just&nbsp;&nbsp;

00:48:03.520 --> 00:48:10.000
applied to videos and it was a fairly good model.&nbsp;
There's a paper out there with samples. It's,&nbsp;&nbsp;

00:48:10.000 --> 00:48:13.600
I don't know if it's three years old or&nbsp;
something the paper now, and I'm sure there's&nbsp;&nbsp;

00:48:13.600 --> 00:48:19.920
many more advances beyond. But again, connecting&nbsp;
these dots, this model that generated videos,&nbsp;&nbsp;

00:48:19.920 --> 00:48:28.240
like I don’t know, short videos, clips, were the&nbsp;
technique behind the weather prediction efforts.&nbsp;&nbsp;

00:48:28.240 --> 00:48:35.760
Because the recent paper that came from,&nbsp;
many people, including some folks in my team&nbsp;&nbsp;

00:48:37.440 --> 00:48:41.680
thought predicting how the clouds move over&nbsp;
time. That's a video prediction problem.&nbsp;

00:48:41.680 --> 00:48:48.240
Oriol: So, they use that technique and some&nbsp;
enhancements for that problem. Indeed, videos&nbsp;&nbsp;

00:48:48.240 --> 00:48:55.040
is definitely part of actually in this case, a&nbsp;
solution to predicting weather. Very exciting&nbsp;&nbsp;

00:48:55.040 --> 00:49:01.040
things to do in that domain. I actually, in my&nbsp;
opinion. But yeah, personally I think there's&nbsp;&nbsp;

00:49:01.040 --> 00:49:04.960
a lot to do and it seems very exciting.
Oriol: The idea of taking a picture and&nbsp;&nbsp;

00:49:04.960 --> 00:49:08.320
animating it. So, we'll see maybe&nbsp;
in the future, we'll see some of&nbsp;&nbsp;

00:49:08.320 --> 00:49:13.600
that research happening as well in the group.
Craig: This has really been fascinating. I hope&nbsp;&nbsp;

00:49:13.600 --> 00:49:20.000
I have the opportunity to talk again. I'd love to&nbsp;
meet you. I'll be going to conferences again soon.&nbsp;&nbsp;

00:49:22.720 --> 00:49:26.160
So, thanks Oriol. I appreciate it.
Oriol: Yeah. It was my pleasure. As&nbsp;&nbsp;

00:49:26.160 --> 00:49:32.400
I said it's quite useful, even for oneself&nbsp;
to just be looking back a bit more like&nbsp;&nbsp;

00:49:33.200 --> 00:49:37.840
casually, and as you said, not from the&nbsp;
most technical perspective, but also&nbsp;&nbsp;

00:49:37.840 --> 00:49:41.520
like on why do we do the projects we do.
Oriol: Thanks. Thanks, likewise, for your&nbsp;&nbsp;

00:49:41.520 --> 00:49:53.360
excellent questions and your time.
Craig:&nbsp;&nbsp;

00:49:53.360 --> 00:50:00.240
That's it for this week's episode. I want to&nbsp;
thank Oriol for his time. I also want to thank&nbsp;&nbsp;

00:50:00.240 --> 00:50:07.600
ClearML for their support. Take&nbsp;
a look at what they have to&nbsp;&nbsp;

00:50:08.320 --> 00:50:19.280
offer at clear.ml.
Craig:&nbsp;&nbsp;

00:50:19.280 --> 00:50:26.960
And remember, the singularity may not be&nbsp;
near, but AI is about to change your world.&nbsp;&nbsp;

00:50:27.600 --> 00:50:48.640
So, pay attention.
&nbsp;

