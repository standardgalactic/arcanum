WEBVTT
Kind: captions
Language: en

00:00:00.199 --> 00:02:20.580
My name is Andre Van Schaik.

00:02:20.580 --> 00:02:25.220
I'm the director of the International Centre
for Neuromorphic Systems at Western Sydney

00:02:25.220 --> 00:02:26.740
University.

00:02:26.740 --> 00:02:33.510
I've been in neuromorphic engineering almost
since the beginning since, the early 90s,

00:02:33.510 --> 00:02:34.790
very early 90s.

00:02:34.790 --> 00:02:38.260
So it's getting on to thirty five years now.

00:02:38.260 --> 00:02:43.080
And let's begin by explaining what neuromorphic
computing is.

00:02:43.080 --> 00:02:50.860
I mean, I know that it's a different architecture
that's meant to mimic the brain, I know that

00:02:50.860 --> 00:03:04.040
the artificial neurons in a neuromorphic computer
fire on action potentials and spike in the

00:03:04.040 --> 00:03:07.700
way that biological neurons do.

00:03:07.700 --> 00:03:15.510
But can you sort of break down, before we
talk about DeepSouth, the computer that you

00:03:15.510 --> 00:03:24.730
guys are building, how the basic differences
between Von Neumann architecture and neuromorphic

00:03:24.730 --> 00:03:31.811
computing architecture, and specifically maybe
start with action potentials and spikes, as

00:03:31.811 --> 00:03:38.569
opposed to weights and what happens in an
artificial neural network?

00:03:38.569 --> 00:03:43.569
Yeah, so to get back to neuromorphic computing,
or actually neuromorphic engineering, to start

00:03:43.569 --> 00:03:49.720
with that, we're taking inspiration from neural
systems in biology, and try and implement

00:03:49.720 --> 00:03:52.069
that in technology.

00:03:52.069 --> 00:03:57.319
That means we also need to understand neural
technology and biology to take that inspiration

00:03:57.319 --> 00:03:58.319
from it.

00:03:58.319 --> 00:04:04.110
And there are sort of two main branches to
neuromorphic engineering, one is neuromorphic,

00:04:04.110 --> 00:04:09.690
sensing, taking inspiration of the senses
that we have and how biology senses information

00:04:09.690 --> 00:04:10.709
around in the world.

00:04:10.709 --> 00:04:15.430
And then neuromorphic computing is largely
around how do we then process that information

00:04:15.430 --> 00:04:24.330
from such sensors like brains do in humans,
but also in dragon flies and mosquitoes.

00:04:24.330 --> 00:04:31.030
Neural computation then uses neurons, neurons
in biology indeed send action potentials to

00:04:31.030 --> 00:04:40.000
each other, they connect their axons onto
dendrites of other neurons, with synapses,

00:04:40.000 --> 00:04:42.870
and the synapses typically have some strengths.

00:04:42.870 --> 00:04:46.539
And those strengths can be modified through
learning rules.

00:04:46.539 --> 00:04:53.590
So that is similar to weights in neural networks
but the spikes are the means of communication.

00:04:53.590 --> 00:04:59.450
And they lead then to pulses on the postsynaptic
neuron over a certain weight, depending on

00:04:59.450 --> 00:05:00.870
the weight of the synaps.

00:05:00.870 --> 00:05:07.800
In this architecture of a brain, all neurons
operate in parallel, they don't operate on

00:05:07.800 --> 00:05:09.300
a common clock.

00:05:09.300 --> 00:05:13.000
So it's asynchronous communication.

00:05:13.000 --> 00:05:15.979
It's pulse based communication.

00:05:15.979 --> 00:05:23.720
And that the memory that these systems have,
is effectively in the synaptic strength, at

00:05:23.720 --> 00:05:28.210
least that's what we currently understand
from how our brain works.

00:05:28.210 --> 00:05:33.120
And that's quite different from a Von Neumann
machine, where memory is a separate thing

00:05:33.120 --> 00:05:39.820
to compute, and you're forever shuffling things
back and forth from memory to the compute

00:05:39.820 --> 00:05:44.610
block, and then write the result back to memory,
and then do the next operation in a sequential

00:05:44.610 --> 00:05:45.610
fashion.

00:05:45.610 --> 00:05:46.610
Yep.

00:05:46.610 --> 00:05:52.660
And also on the clock in Von Neumann architecture
and with the artificial neural networks, there

00:05:52.660 --> 00:06:01.870
is input information and there's calculation
at the neuron level.

00:06:01.870 --> 00:06:08.410
And then the result or the output of that
neuron is passed on to another neuron according

00:06:08.410 --> 00:06:12.900
to the clock when the transistor resets, right.

00:06:12.900 --> 00:06:19.160
And there has been work on building spiking
neural networks.

00:06:19.160 --> 00:06:22.530
I know IBM has this TrueNorth chip.

00:06:22.530 --> 00:06:30.630
So can you talk about how a chip like TrueNorth
works differently than a CPU or GPU processor?

00:06:30.630 --> 00:06:38.229
Yeah, so the chips like TrueNorth, and that
we've called this system DeepSouth, slightly

00:06:38.229 --> 00:06:45.270
in reference to TrueNorth because we're down
under when we're very far south in the world.

00:06:45.270 --> 00:06:52.630
TrueNorth was sort of the first large scale
neuromorphic system that was doing spiking

00:06:52.630 --> 00:06:53.630
neurons.

00:06:53.630 --> 00:07:00.510
This was part of a US DARPA funded project
called Synaps that IBM did.

00:07:00.510 --> 00:07:05.020
That started a good decade ago now, that they
did that.

00:07:05.020 --> 00:07:10.819
That has been followed up by a few that have
been doing that in most recent years it's

00:07:10.819 --> 00:07:16.050
been Intel during their Loihi platform, which
is similar in goals.

00:07:16.050 --> 00:07:17.949
It's a different design.

00:07:17.949 --> 00:07:25.330
I don't know the actual ins and outs of TrueNorth
or Loihi, in terms of what actual architecture

00:07:25.330 --> 00:07:26.639
they have on it.

00:07:26.639 --> 00:07:33.210
But they are all aiming at emulating neurons
that communicate with action potentials, so

00:07:33.210 --> 00:07:39.360
spiking neural networks, and implementing
those, and running those.

00:07:39.360 --> 00:07:41.360
DeepSouth is a system like that too.

00:07:41.360 --> 00:07:49.169
We're emulating how a brain works on the electrical
level by how it communicates with pulses and

00:07:49.169 --> 00:07:52.340
how does communication with that.

00:07:52.340 --> 00:08:01.419
Some of these systems that have been designed,
they have attempted to be fully asynchronous,

00:08:01.419 --> 00:08:06.070
just like the brain is and not gonna do it
on a common clock.

00:08:06.070 --> 00:08:11.250
And that is quite difficult actually, to get
to work properly.

00:08:11.250 --> 00:08:17.259
So most of these systems, they will still
have a clock, DeepSouth, for example, it's

00:08:17.259 --> 00:08:24.020
built out of FPGAs (Field Programmable Gate
Arrays) that's reconfigurable hardware that

00:08:24.020 --> 00:08:27.229
operates on a clock.

00:08:27.229 --> 00:08:33.260
And so our system is not asynchronous in that
sense.

00:08:33.260 --> 00:08:42.300
And the point of the clock in a current chip
architecture is the calculation is done all

00:08:42.300 --> 00:08:48.110
at the same time across the transistors, across
the chips, it's not right?

00:08:48.110 --> 00:08:56.350
It is, and the other point of the clock for
us is that DeepSouth has almost 100 FPGA boards

00:08:56.350 --> 00:08:57.350
in it.

00:08:57.350 --> 00:09:03.580
And we can do up to almost 100 billion neurons
that we can simulate with that, in real time.

00:09:03.580 --> 00:09:10.279
But that doesn't mean that every 100 billion
neuron has its separate implementation in

00:09:10.279 --> 00:09:13.100
the hardware in order to get to these numbers.

00:09:13.100 --> 00:09:16.680
We have to use the fact that silicon is much
faster than biology.

00:09:16.680 --> 00:09:23.120
So we have one block compute, say 128 neurons,
one after the other in a sequential fashion.

00:09:23.120 --> 00:09:27.990
And again, that clock is needed to schedule
that basically.

00:09:27.990 --> 00:09:29.100
Yeah.

00:09:29.100 --> 00:09:37.399
But the point of spiking, asynchronous spiking
neurons in the brain is that they only spike

00:09:37.399 --> 00:09:46.100
when the action potential is reached, when
they have enough stimulus to send a signal.

00:09:46.100 --> 00:09:52.029
And in a neural network, an artificial neural
network they all update at the same time,

00:09:52.029 --> 00:09:53.820
according to the clock.

00:09:53.820 --> 00:09:55.459
Am I misunderstanding that?

00:09:55.459 --> 00:09:57.700
No, that is correct and that's a good point.

00:09:57.700 --> 00:10:06.440
So we do make use of that sparsity of signals
that you see in biology where you only communicate

00:10:06.440 --> 00:10:09.490
when you have a spike, so when a neuron has
passed a threshold.

00:10:09.490 --> 00:10:15.120
Obviously, the neuron itself is still updating,
even if it hasn't spiked based on its inputs

00:10:15.120 --> 00:10:19.790
until it reaches this threshold, though, other
neurons wouldn't know about that.

00:10:19.790 --> 00:10:21.730
And that gets used in this system too.

00:10:21.730 --> 00:10:27.790
So while the neuron internal updates are done
on the clock, only those neurons that spike

00:10:27.790 --> 00:10:31.220
will actually communicate with the other neurons
in the network.

00:10:31.220 --> 00:10:39.040
Right, and then an artificial neural network,
regardless of the input, the strength or relevance

00:10:39.040 --> 00:10:46.360
of the input to an artificial neuron, it will
communicate onward.

00:10:46.360 --> 00:10:50.490
It's just a matter of how strong a signal
is?

00:10:50.490 --> 00:10:56.339
Yeah, in a artificial neural network like
current deep neural networks and convolutional

00:10:56.339 --> 00:11:01.430
neural networks, all the values from all the
neurons are passed on to the next layer right,

00:11:01.430 --> 00:11:03.300
and processed by the weights including zeros.

00:11:03.300 --> 00:11:04.300
Yeah.

00:11:04.300 --> 00:11:10.399
And is that why artificial neural networks
consume so much energy and why neuromorphic

00:11:10.399 --> 00:11:14.050
computing consumes so little energy?

00:11:14.050 --> 00:11:18.480
Yes, partly, at least it is not making use
of the sparsity.

00:11:18.480 --> 00:11:21.089
So all the operations have to be done.

00:11:21.089 --> 00:11:28.860
Another part that is expensive is this constant
shuffling of data from memory, to the compute

00:11:28.860 --> 00:11:31.940
and then back to, to memory.

00:11:31.940 --> 00:11:35.110
With the FPGAs, we can't totally avoid that,
either.

00:11:35.110 --> 00:11:40.950
But we have, in our system, quite a lot of
local memory, high bandwidth memory integrated

00:11:40.950 --> 00:11:48.170
with the FPGA nearby, which reduces some of
the energy costs of moving the data.

00:11:48.170 --> 00:11:53.300
Because again, where, as I mentioned, where
one block will calculate multiple neurons,

00:11:53.300 --> 00:11:57.600
one after the other in scheme, that's called
time multiplexing.

00:11:57.600 --> 00:12:02.910
And in order to do that, you need to store
the internal state of each neuron back in

00:12:02.910 --> 00:12:07.820
local memory when you're updating the next
one, and then writing that result back to

00:12:07.820 --> 00:12:09.050
local memory as well.

00:12:09.050 --> 00:12:11.200
So, we still have some of that.

00:12:11.200 --> 00:12:17.000
We try and keep it as much local and distributed
across all the FPGAs.

00:12:17.000 --> 00:12:20.370
And each of the FPGA blocks will have its
own memory.

00:12:20.370 --> 00:12:26.710
Yeah, can you just give us a thumbnail on
what an FPGA is?

00:12:26.710 --> 00:12:27.710
Sure.

00:12:27.710 --> 00:12:34.920
So an FPGA is a Field-Programmable Gate Array,
it's a digital platform that can be programmed

00:12:34.920 --> 00:12:36.740
a bit like a CPU.

00:12:36.740 --> 00:12:42.209
But by programming it, you're actually setting
hardware switches, and basically changing

00:12:42.209 --> 00:12:47.589
how one block on the hardware is routed to
the next block and how things are connected

00:12:47.589 --> 00:12:49.110
to do a certain operation.

00:12:49.110 --> 00:12:52.649
So you're really configuring the hardware.

00:12:52.649 --> 00:12:56.480
And you can do that multiple times, which
is why this is also called reconfigurable

00:12:56.480 --> 00:12:57.540
hardware.

00:12:57.540 --> 00:13:01.980
And so once you've programmed it, you actually
have a hardware circuit that sits there that

00:13:01.980 --> 00:13:07.430
does the calculation that you have programmed
whereas on a CPU, when you program it, the

00:13:07.430 --> 00:13:09.060
hardware has stayed the same.

00:13:09.060 --> 00:13:12.540
You've got your CPU that's doing the calculations.

00:13:12.540 --> 00:13:17.889
And it is looking at what instructions it
now needs to do from instruction memory, computing

00:13:17.889 --> 00:13:22.839
these instructions one after the other, but
with exactly the same hardware that hasn't

00:13:22.839 --> 00:13:25.529
been changed no matter what program you're
sticking.

00:13:25.529 --> 00:13:39.170
And in that reprogramming, is that dynamic,
depending on the sensory input that that the

00:13:39.170 --> 00:13:46.380
FPGAs are receiving, or is that something
that's physically reprogrammed by a technician?

00:13:46.380 --> 00:13:49.550
So that's something that's physically done.

00:13:49.550 --> 00:13:57.870
So we try not to change the configuration
of the hardware for the various models that

00:13:57.870 --> 00:14:00.130
DeepSouth might simulate.

00:14:00.130 --> 00:14:04.820
So the user will specify an architecture of
their spiking neural network that they will

00:14:04.820 --> 00:14:05.820
want to run on it.

00:14:05.820 --> 00:14:11.220
It runs on the same hardware, we don't have
to reprogram the hardware for that.

00:14:11.220 --> 00:14:15.850
We've configured it already to simulate the
neurons, and the synapses, and the connections

00:14:15.850 --> 00:14:19.589
and those things are available.

00:14:19.589 --> 00:14:27.000
And users would simply have a software description
of their network architecture that they want.

00:14:27.000 --> 00:14:32.300
And that then gets sent to the memory of the
devices.

00:14:32.300 --> 00:14:36.519
And that can run on that hardware without
having to reprogram the hardware.

00:14:36.519 --> 00:14:42.389
Where the reconfigurability does come in is
if we want to add other features to it, new

00:14:42.389 --> 00:14:46.470
Learning rules, different neuron models, things
like that.

00:14:46.470 --> 00:14:49.800
We can still add those after we've built this
machine.

00:14:49.800 --> 00:14:56.170
And that's a big difference going back to
say TrueNorth or Intel Loihi, those are chips

00:14:56.170 --> 00:15:00.100
that are custom made and what's on them is
what's on them.

00:15:00.100 --> 00:15:06.920
And you can’t add things to that without
doing a whole chip design and fabrication.

00:15:06.920 --> 00:15:08.550
And that's expensive and slow.

00:15:08.550 --> 00:15:15.280
If we look at Intel Loihi, to go from Loihi
1 to Loihi 2 that came out two years ago,

00:15:15.280 --> 00:15:17.500
I think there was a six year cycle.

00:15:17.500 --> 00:15:23.040
And so doing updates and adding a learning
rule to that, that's not quick.

00:15:23.040 --> 00:15:25.720
Whereas for us with this hardware, we can
do that.

00:15:25.720 --> 00:15:27.430
Yeah, that's that’s fascinating.

00:15:27.430 --> 00:15:35.630
The network works among neurons can reconfigure
themselves dynamically, right?

00:15:35.630 --> 00:15:38.500
I mean they're not fixed?

00:15:38.500 --> 00:15:39.540
Yeah.

00:15:39.540 --> 00:15:44.920
And we tend to simulate that by changing the
weights of connection.

00:15:44.920 --> 00:15:51.899
So weights can go all the way to zero, which
effectively means the connection has disappeared,

00:15:51.899 --> 00:15:52.899
and can grow.

00:15:52.899 --> 00:15:55.240
And connections can start as well.

00:15:55.240 --> 00:16:03.410
Typically, I've seen networks defined where
the connectivity is defined by the user.

00:16:03.410 --> 00:16:08.139
It might be a probabilistic definition and
saying, from this group of neurons, that group

00:16:08.139 --> 00:16:14.290
of neurons, there's a 20% probability of a
connection from one neuron to the other, or

00:16:14.290 --> 00:16:18.720
something like that, rather than saying, oh,
yeah, this one goes exactly to this one, this

00:16:18.720 --> 00:16:20.519
one goes exactly to this one.

00:16:20.519 --> 00:16:25.240
But that does tend to be static in most simulations
at the moment.

00:16:25.240 --> 00:16:32.720
And that is, because adding this flexibility
of reconfiguring all the connectivity, indeed

00:16:32.720 --> 00:16:35.600
makes the simulations even harder.

00:16:35.600 --> 00:16:42.120
It is something we can support on this machine,
though.

00:16:42.120 --> 00:16:43.500
Where are you with DeepSouth?

00:16:43.500 --> 00:16:49.100
Is it is it finished and in the testing phase,
are you still building.

00:16:49.100 --> 00:16:57.210
We're building it and actually physically,
over the last few days, we've had the hardware

00:16:57.210 --> 00:16:59.090
put in the racks.

00:16:59.090 --> 00:17:02.910
And that's still ongoing, and it's being connected.

00:17:02.910 --> 00:17:10.490
It should be connected up in the next few
weeks, all fully connected.

00:17:10.490 --> 00:17:12.390
And then we can run some tests.

00:17:12.390 --> 00:17:17.980
We're now looking to launch it in the beginning
of June.

00:17:17.980 --> 00:17:25.410
Part of that delay is, I'm going to travel
for the next seven weeks and I want to be

00:17:25.410 --> 00:17:28.700
there when we launched the machine.

00:17:28.700 --> 00:17:29.700
Yeah.

00:17:29.700 --> 00:17:30.880
And what will you launch it on?

00:17:30.880 --> 00:17:34.690
What sort of computation are you going to
ask it to do?

00:17:34.690 --> 00:17:35.690
Yeah, very sort of classical demonstration.

00:17:35.690 --> 00:17:38.990
It is what is called Balanced Excitation-inhibition
Networks.

00:17:38.990 --> 00:17:46.001
It's the sort of traditional setup in spiking
neural networks where it's based on what we

00:17:46.001 --> 00:17:53.520
see in cortex, in the human brain, where we
have about 80% excitatory neurons, so neurons

00:17:53.520 --> 00:17:59.870
that excite other neurons and 20% inhibitory
neurons, neurons that inhibit or reduce the

00:17:59.870 --> 00:18:02.060
excitation of other neurons.

00:18:02.060 --> 00:18:09.059
And those are connected in networks that keep
the excitation and inhibition balanced.

00:18:09.059 --> 00:18:13.860
That's why they're called Balance Excitation-inhibition
Networks, and keep the activity level of the

00:18:13.860 --> 00:18:15.570
brain within a reasonable amount.

00:18:15.570 --> 00:18:22.130
If you just had excitatory neurons, then the
excitation could easily run away and you end

00:18:22.130 --> 00:18:24.890
up with everything spiking all the time.

00:18:24.890 --> 00:18:29.580
And obviously, if neurons were just inhibiting
each other, nothing would ever happen, so

00:18:29.580 --> 00:18:31.220
it's that balance there.

00:18:31.220 --> 00:18:39.500
That in itself is not a useful computation
but it is a easy demonstration for us to show

00:18:39.500 --> 00:18:45.830
that everything works; that all the neurons
are computing as they should, that we're able

00:18:45.830 --> 00:18:51.231
to achieve the balanced excitation and inhibition
with a very large population, that we can

00:18:51.231 --> 00:18:57.440
run that in real, time that all the populations
can communicate to each other as needed and

00:18:57.440 --> 00:18:58.440
so on.

00:18:58.440 --> 00:19:03.690
So it's a good functionality test, but it's
not doing anything intelligent basically.

00:19:03.690 --> 00:19:05.520
Yeah.

00:19:05.520 --> 00:19:13.430
Given that this is based on the biological
structures of the brain and that artificial

00:19:13.430 --> 00:19:22.740
neural networks that run on Von Neumann architecture
are mimicking the neural activity of the brain,

00:19:22.740 --> 00:19:33.340
do you expect them to run neural network architectures
on the neuromorphic computer on DeepSouth?

00:19:33.340 --> 00:19:40.650
We can support running artificial neural network
type architectures on the machine.

00:19:40.650 --> 00:19:47.780
It is not the initial plan to do that but
we specifically want this to run spiking neural

00:19:47.780 --> 00:19:48.780
networks.

00:19:48.780 --> 00:19:54.090
The reason for this is that artificial neural
networks, the convolutional neural networks

00:19:54.090 --> 00:20:01.220
that underpin current machine learning and
AI, they run very well on GPUs, Graphical

00:20:01.220 --> 00:20:05.200
Processing Units, and we can do that now.

00:20:05.200 --> 00:20:10.860
Pretty large networks, it still takes a fair
amount to train them, but then once they're

00:20:10.860 --> 00:20:16.500
trained we can execute them in a reasonable
amount of time or pretty quickly.

00:20:16.500 --> 00:20:17.840
And they run well on that.

00:20:17.840 --> 00:20:24.900
And that was, effectively a revolution or
an evolution, because the GPU is was more

00:20:24.900 --> 00:20:27.390
of an evolution and a revolution, I think.

00:20:27.390 --> 00:20:35.080
That really helped machine learning and artificial
neural networks to get to the power that they

00:20:35.080 --> 00:20:39.690
needed, and get to the size that they needed
to be able to do the things that they can

00:20:39.690 --> 00:20:40.690
do now.

00:20:40.690 --> 00:20:47.830
I'm sort of hoping that with DeepSouth, which
is aiming to be able to run spiking neural

00:20:47.830 --> 00:20:54.909
networks efficiently and lives networks efficiently,
that we can do the same thing for spiking

00:20:54.909 --> 00:20:55.909
neural networks.

00:20:55.909 --> 00:21:00.039
Because spiking neural networks don't run
well on GPUs, or on CPUs.

00:21:00.039 --> 00:21:03.360
They're very slow to simulate.

00:21:03.360 --> 00:21:08.840
And that means that researchers that have
been trying to understand spiking neural networks

00:21:08.840 --> 00:21:14.480
at scale, they've always had to simulate small
models, toy models, basically.

00:21:14.480 --> 00:21:22.890
And that's a problem because like, if you
look at, say a neuron in the cortex, it can

00:21:22.890 --> 00:21:27.570
have 10,000 inputs, one neuron, from other
neurons.

00:21:27.570 --> 00:21:32.010
And if you’re only simulating a network
with 1000 neurons in it, because that's what

00:21:32.010 --> 00:21:35.360
you can simulate on the computer, how do you
get 10,000 inputs?

00:21:35.360 --> 00:21:39.950
And you can go, well, I'll just do 100 inputs
instead, and make each input 100 times stronger

00:21:39.950 --> 00:21:44.220
so they get the same total input strength
but you can imagine that if you get spikes

00:21:44.220 --> 00:21:49.080
that are 100 times stronger, one spike in
just means one spike out.

00:21:49.080 --> 00:21:52.130
And the dynamics of the computation gets totally
different.

00:21:52.130 --> 00:21:54.540
So you can't play that trick very well.

00:21:54.540 --> 00:22:01.700
So we really hope that this will enable researchers
worldwide, ultimately, in first instance,

00:22:01.700 --> 00:22:06.549
we have to get this up and running for us,
but it will be available for other people

00:22:06.549 --> 00:22:11.450
to use, and they can create accounts on it,
and there'll be cloud service effectively.

00:22:11.450 --> 00:22:19.340
And the other important point about DeepSouth
is that it's non custom hardware, it's commercial

00:22:19.340 --> 00:22:20.679
hardware.

00:22:20.679 --> 00:22:27.039
So you can just buy the components and build
one yourself and use the configuration that

00:22:27.039 --> 00:22:33.929
we've designed for the FPGAs, configure it
the same, and you have a copy of the machine.

00:22:33.929 --> 00:22:38.230
And again, that's not so easy, when you use
custom made chips.

00:22:38.230 --> 00:22:44.720
Often, there's only a limited volume of those
chips around and only one machine is built.

00:22:44.720 --> 00:22:48.490
And that's what people have, maybe get remote
access to.

00:22:48.490 --> 00:22:53.520
Here FPGAs is a commercial business, you know,
these companies, they make them, they improve

00:22:53.520 --> 00:22:57.919
them, they sell millions of them, they will
continue to do that, people can buy this stuff.

00:22:57.919 --> 00:22:58.919
Yeah.

00:22:58.919 --> 00:23:03.230
Do you need new algorithms to run on this
machine?

00:23:03.230 --> 00:23:06.260
On spiking neural networks?

00:23:06.260 --> 00:23:07.900
Or are they transferable?

00:23:07.900 --> 00:23:15.130
You know, the transformer algorithm, for example,
it's done so much in generative AI.

00:23:15.130 --> 00:23:21.620
Will you be able to run that algorithm on
a neuromorphic computer, on DeepSouth?

00:23:21.620 --> 00:23:29.570
So there are spiking versions of, say, a transformer
architecture that have been created.

00:23:29.570 --> 00:23:34.570
So they can be trained, and they can be made,
and we could run them.

00:23:34.570 --> 00:23:40.860
The thing is taking a transformer from an
artificial neural network and making it spiking

00:23:40.860 --> 00:23:45.300
tends to work almost as good as the non spiking
version.

00:23:45.300 --> 00:23:49.850
But there's not much point in making this
the spiking version other than to say, see,

00:23:49.850 --> 00:23:51.779
I've made it spike.

00:23:51.779 --> 00:23:56.630
Our brain doesn't exactly do to transformer
implementations, I believe.

00:23:56.630 --> 00:24:04.460
I believe there are indeed other architectures
that are going to really unlock the advantages

00:24:04.460 --> 00:24:07.250
of spiking neural networks.

00:24:07.250 --> 00:24:10.100
And those are the ones that are yet to be
discovered.

00:24:10.100 --> 00:24:17.830
And I think we need to discover them by trying
things at scale with the spiking Neural Networks,

00:24:17.830 --> 00:24:22.820
just like the transformer architecture for
artificial neural networks was only discovered

00:24:22.820 --> 00:24:27.539
once we could make really large, artificial
neural networks.

00:24:27.539 --> 00:24:32.860
Back in the 80s and 90s, when we were doing
three layer artificial neural networks, there

00:24:32.860 --> 00:24:38.419
was no transformer architecture to be found,
because it just wasn't possible to make them.

00:24:38.419 --> 00:24:48.190
Yeah, although the power consumption of the
big transformer models is so enormous.

00:24:48.190 --> 00:24:54.321
They would be a lot cheaper to run in spiking
neural network on a neuromorphic computer

00:24:54.321 --> 00:24:56.029
when they?

00:24:56.029 --> 00:25:01.640
That's the hope, yeah, so this system that
we're building, it's not extremely low power.

00:25:01.640 --> 00:25:09.450
It's about 40 kilowatts, maximum power, the
system, which is about the building air conditioning

00:25:09.450 --> 00:25:12.529
of a medium sized building or something like
that.

00:25:12.529 --> 00:25:18.789
It's not a power that you see for data centers
where it's megawatts.

00:25:18.789 --> 00:25:23.730
It's not portable power either, it's somewhere
in between.

00:25:23.730 --> 00:25:28.909
But that can be improved once we know what
we want to do with it; then if you really

00:25:28.909 --> 00:25:34.250
want to go to low power, then you will have
to go and build some custom chips to really

00:25:34.250 --> 00:25:36.279
get to the low power.

00:25:36.279 --> 00:25:42.809
But my view on that is we still don't quite
know what architectures we need, what type

00:25:42.809 --> 00:25:47.260
of features we need from the neurons, what
type of learning rules we're going to need

00:25:47.260 --> 00:25:48.440
exactly.

00:25:48.440 --> 00:25:53.230
So let's explore that on this machine that
is flexible first and once we've figured that

00:25:53.230 --> 00:25:57.159
out, then we can start making some chips that
make it really low power.

00:25:57.159 --> 00:26:01.600
And who were you talking to in the research
community?

00:26:01.600 --> 00:26:08.700
You know, I started this podcast after meeting
Geoff Hinton, and he's been on a few times.

00:26:08.700 --> 00:26:18.070
And he talked about spiking neural networks
and his ambition is not so much to create

00:26:18.070 --> 00:26:23.560
AGI, but to understand how the brain works.

00:26:23.560 --> 00:26:28.840
The last time I spoke to him, he was working
on forward networks.

00:26:28.840 --> 00:26:30.850
Is that what he called them?

00:26:30.850 --> 00:26:39.169
He was looking for an algorithm that could
work in the brain because he didn't believe

00:26:39.169 --> 00:26:42.390
that backpropagation could work in the brain.

00:26:42.390 --> 00:26:52.100
Are you talking to people like Jeff that could
use this computer to explore some of their

00:26:52.100 --> 00:26:53.850
ideas?

00:26:53.850 --> 00:26:56.460
Not yet, at least not yet broadly.

00:26:56.460 --> 00:27:03.670
We have, as part of the application for funding
that we did to get this system built, we have

00:27:03.670 --> 00:27:13.170
a team of about, at the top of my head 13
researchers largely in Australia, because

00:27:13.170 --> 00:27:17.970
this is Australian funding, but not not exclusively.

00:27:17.970 --> 00:27:24.640
So one of the people we have as part of the
team is Emerson Neftci.

00:27:24.640 --> 00:27:31.230
He’s in Aachen, in Jülich, where there's
a big supercomputer center.

00:27:31.230 --> 00:27:40.670
And he is one of the researchers that started
Surrogate Gradient approach that is used to

00:27:40.670 --> 00:27:44.039
do the back propagation with spiking neural
networks.

00:27:44.039 --> 00:27:52.110
Because the issue is spiking neural networks
and error back propagation is, an artificial

00:27:52.110 --> 00:27:59.390
neural network should past the arrow back
through the gradients of the activation function.

00:27:59.390 --> 00:28:03.820
But in the spiking neural network, it's a
discontinuous activation function because

00:28:03.820 --> 00:28:06.020
it either spikes or not.

00:28:06.020 --> 00:28:08.850
So you don't have a gradient that you can
pass things through.

00:28:08.850 --> 00:28:13.470
So you have to come up with surrogate gradients
in order to do that.

00:28:13.470 --> 00:28:16.580
And so that's one of the approaches.

00:28:16.580 --> 00:28:24.350
But I would agree with Jeff, that I don't
think the brain is doing backpropagation that

00:28:24.350 --> 00:28:31.880
way and there’s other architectures and
learning mechanisms with local learning that

00:28:31.880 --> 00:28:35.510
need to be used in order to train such networks.

00:28:35.510 --> 00:28:41.299
Yeah, can you talk a little bit about the
number of connections in DeepSouth?

00:28:41.299 --> 00:28:52.960
We've speced this system to effectively have
the same number of neurons as a human brain,

00:28:52.960 --> 00:28:58.340
with the same number of average inputs per
neuron as the human brain, running that at

00:28:58.340 --> 00:29:04.980
the same number of spikes processed per second
as the human brain.

00:29:04.980 --> 00:29:11.710
The number of synaptic operations per second,
so that's a spike arriving at a synaps activating

00:29:11.710 --> 00:29:19.409
the neuron; the postsynaptic neuron, is in
the order of 220 trillion per second.

00:29:19.409 --> 00:29:24.730
And that is what this machine can do.

00:29:24.730 --> 00:29:30.929
Obviously, they're very simplified neural
models, they don't have the full 3D structure

00:29:30.929 --> 00:29:33.779
that biological neurons have.

00:29:33.779 --> 00:29:38.510
They’re digital neurons, because we still
store the states in memory.

00:29:38.510 --> 00:29:46.580
The precision of that is limited to eight
bits only because we can't have the precision

00:29:46.580 --> 00:29:50.740
too high or we would need to store too much
in memory, for instance.

00:29:50.740 --> 00:29:59.140
So, it's a simplified human brain-scale spiking
neural network simulator but it is the first

00:29:59.140 --> 00:30:01.890
time we achieved this, I think in the world.

00:30:01.890 --> 00:30:04.100
Yeah, that's really remarkable.

00:30:04.100 --> 00:30:06.409
And what did you say?

00:30:06.409 --> 00:30:07.409
40 kilowatts?

00:30:07.409 --> 00:30:09.110
Is that what you said?

00:30:09.110 --> 00:30:11.630
Yeah, 40 kilowatts power usage.

00:30:11.630 --> 00:30:14.620
As opposed to what, 20 watts in the brain?

00:30:14.620 --> 00:30:17.929
As opposed to 20 watts in the brain, yeah.

00:30:17.929 --> 00:30:21.510
But compared to, I don't know, what GPT four
is…

00:30:21.510 --> 00:30:25.760
ANDRE 36:45
Yeah, I don’t know either but you hear the

00:30:25.760 --> 00:30:32.880
stories, it's the power consumption of New
York City for a certain extended time just

00:30:32.880 --> 00:30:34.610
to train a network like that.

00:30:34.610 --> 00:30:41.220
CRAIG 36:57
Yeah, and is this an open source architecture?

00:30:41.220 --> 00:30:49.340
You were saying that people can then build
these wherever they want, at a reasonable

00:30:49.340 --> 00:30:50.340
cost?

00:30:50.340 --> 00:30:52.669
ANDRE 37:14
Yes, that's the plan.

00:30:52.669 --> 00:30:58.850
So obviously, this year, we will launch it,
then we will develop stuff for it internally

00:30:58.850 --> 00:31:03.490
in the lab and make sure everything works
and for the remainder of this year.

00:31:03.490 --> 00:31:09.340
Then it will be opened up to the researchers
that are part of the team and we're working

00:31:09.340 --> 00:31:13.910
with, directly but that are remote at all
the universities around the world.

00:31:13.910 --> 00:31:19.370
And then we'll grow that community and open
it up to other people and at that point in

00:31:19.370 --> 00:31:27.230
time too, our design will be made open source
available so that people can copy the machine.

00:31:27.230 --> 00:31:29.309
And they don't have to do it.

00:31:29.309 --> 00:31:37.390
So for us, it's three data center racks, it's
twenty four server computers with four FPGA

00:31:37.390 --> 00:31:41.260
boards in them.

00:31:41.260 --> 00:31:47.220
And that's an expensive machine, but you could
scale it down to just use one FPGA and obviously

00:31:47.220 --> 00:31:54.889
much smaller neural networks, or two, or eight;
or if somebody is interested and has a lot

00:31:54.889 --> 00:31:59.889
of money to burn on this, they can make a
superhuman brain basically with it, or at

00:31:59.889 --> 00:32:04.650
least superhuman brain scale, I should say,
because I don't know whether it's a full brain

00:32:04.650 --> 00:32:05.650
yet.

00:32:05.650 --> 00:32:10.809
CRAIG 38:30
Yeah, at current prices for FPGA boards, what

00:32:10.809 --> 00:32:13.370
would it cost for somebody to build?

00:32:13.370 --> 00:32:21.500
I mean, obviously they're benefiting from
all your time and effort, but to replicate

00:32:21.500 --> 00:32:27.130
this, what's the ballpark for building one
of these machines now, once it's open source?

00:32:27.130 --> 00:32:33.220
ANDRE 38:51
Probably around 2 million US in terms of hardware?

00:32:33.220 --> 00:32:34.390
Yeah.

00:32:34.390 --> 00:32:38.649
So it's not cheap but its not way out there
either.

00:32:38.649 --> 00:32:45.240
CRAIG 39:05
Yeah, I mean, it's within reach of a lot of

00:32:45.240 --> 00:32:46.240
companies.

00:32:46.240 --> 00:32:53.909
And the algorithmic, the software research,
how far along is that?

00:32:53.909 --> 00:33:05.159
How far does it need to go for your computer
to be useful or doing some amazing things?

00:33:05.159 --> 00:33:09.240
ANDRE 39:35
Yeah, I would like to say, “Oh, we're ready

00:33:09.240 --> 00:33:10.840
to go there.”

00:33:10.840 --> 00:33:15.919
but actually, I think we have a long way to
go there.

00:33:15.919 --> 00:33:22.779
My first goal with this machine is to better
understand how the brain does computation

00:33:22.779 --> 00:33:26.679
with its electrical pulses.

00:33:26.679 --> 00:33:31.590
We know some of the principles but we haven't
been able to study this at any large scale

00:33:31.590 --> 00:33:35.830
yet simply because we haven't been able to
simulate it.

00:33:35.830 --> 00:33:41.649
And you can look at real brains but there
you can't observe everything you might want

00:33:41.649 --> 00:33:46.400
to observe; plus, you don't have full control
over what is going on either.

00:33:46.400 --> 00:33:53.120
So there's a lot to be discovered still around
what works and what doesn't work.

00:33:53.120 --> 00:34:00.380
And once we have that, then we can start applying
that to tasks, basically make AI.

00:34:00.380 --> 00:34:06.860
That's how I think of machine learning, right,
you're learning to do tasks.

00:34:06.860 --> 00:34:13.839
And once we know some of the principles, then
we can start working on doing tasks with the

00:34:13.839 --> 00:34:14.839
machine.

00:34:14.839 --> 00:34:18.560
But we first have to still discover the principles
that work really well.

00:34:18.560 --> 00:34:20.470
And that's going to be a big research effort.

00:34:20.470 --> 00:34:24.330
CRAIG 40:51
And this is mimicking.

00:34:24.330 --> 00:34:33.909
When you say brain scale, it's the neocortex,
or does it you know, include the thalamus

00:34:33.909 --> 00:34:39.090
and the hippocampus and all the other structures
in a human brain?

00:34:39.090 --> 00:34:43.359
ANDRE 41:10
So the numbers I used before and used to spec

00:34:43.359 --> 00:34:48.919
this system for it includes all the neurons
in the brain, including cerebellum, which

00:34:48.919 --> 00:34:52.980
is actually has more neurons in it than the
cortex, for instance.

00:34:52.980 --> 00:34:59.640
Now, what the user ends up doing with these
neurons depends on what model they define.

00:34:59.640 --> 00:35:09.070
So the model can be defined to specifically
have thalamus, or superior colliculus, or

00:35:09.070 --> 00:35:14.750
cochlear nucleus if you want to do audio processing,
or all those parts in it as well, or cerebellum

00:35:14.750 --> 00:35:18.050
say you want to do some motor processing.

00:35:18.050 --> 00:35:25.870
Because it is a cloud system effectively still,
in server racks, it's not ideally suited to

00:35:25.870 --> 00:35:33.420
do robotic motor processing and control loops,
because the latency would become an issue.

00:35:33.420 --> 00:35:36.060
Is your background in neuroscience?

00:35:36.060 --> 00:35:41.020
What was your educational background preceding
this project?

00:35:41.020 --> 00:35:45.250
ANDRE 42:36
So my background was in integrated circuit

00:35:45.250 --> 00:35:50.710
design, my education and first job.

00:35:50.710 --> 00:35:55.829
But in neuromorphic engineering, almost from
the beginning.

00:35:55.829 --> 00:36:05.830
My final year, undergraduate thesis was around
making electronic micro electronic circuits

00:36:05.830 --> 00:36:08.900
for artificial neural networks.

00:36:08.900 --> 00:36:13.319
And that was in 1990.

00:36:13.319 --> 00:36:24.340
And so it's always been integrated circuit
design, forward neural inspired hardware.

00:36:24.340 --> 00:36:33.000
And so the education in neuroscience has been
effectively self educated over the years and,

00:36:33.000 --> 00:36:40.950
you know, attending a lot of talks, and conferences,
and things like that on it.

00:36:40.950 --> 00:36:46.849
And then this system, there's not really integrated
circuit design that we're doing for it.

00:36:46.849 --> 00:36:54.480
As I said, we would only want to do that once
we know what needs to be on there.

00:36:54.480 --> 00:36:59.540
And instead, we're using this digital hardware
that is available.

00:36:59.540 --> 00:37:05.040
That is not my personal area of expertise
but we have people in the group like Mark

00:37:05.040 --> 00:37:12.240
Wang, who is an expert in how to write the
code to configure these systems.

00:37:12.240 --> 00:37:18.540
CRAIG 44:07
Now, do you talk to people like Jeff Lichtman

00:37:18.540 --> 00:37:21.500
at Harvard who's mapping the brain?

00:37:21.500 --> 00:37:32.170
I saw an earlier interview with you in which
you were showing a brainbow image that I think

00:37:32.170 --> 00:37:34.090
came from his lab.

00:37:34.090 --> 00:37:41.710
ANDRE 44:30
So we're not in direct contact with that lab.

00:37:41.710 --> 00:37:50.320
We do talk to various people from neuroscience
over time.

00:37:50.320 --> 00:37:59.060
We have in the neuromorphic engineering community,
we have two main workshops every year annually,

00:37:59.060 --> 00:38:04.730
ones in Telluride, Colorado, a terrible place
to be- Not!

00:38:04.730 --> 00:38:08.790
It's very, a very beautiful town.

00:38:08.790 --> 00:38:17.410
And then the other is in Cappadocia, which
is in Sardinia, in Italy, on the beach, also

00:38:17.410 --> 00:38:20.430
a very nice place to be.

00:38:20.430 --> 00:38:22.830
And those two workshops, they're multi week.

00:38:22.830 --> 00:38:27.810
So Telluride is three weeks, and Cappadocia
a two week one.

00:38:27.810 --> 00:38:33.510
And there we combine talks from people with
an engineering background and have talks from

00:38:33.510 --> 00:38:36.579
people with a neuroscience background.

00:38:36.579 --> 00:38:39.960
And that's been going on now for a long time.

00:38:39.960 --> 00:38:45.320
I think Telluride workshop started in 1994
and it's still going, so it's been running

00:38:45.320 --> 00:38:46.990
for a long time.

00:38:46.990 --> 00:38:54.730
Cappadocia has now been running for maybe
15 years or so as well.

00:38:54.730 --> 00:39:02.150
And so that's where we get annual interactions
with various between the various teams basically,

00:39:02.150 --> 00:39:03.460
in the various groups.

00:39:03.460 --> 00:39:08.760
CRAIG 45:58
Yeah, and the ambition beyond understanding

00:39:08.760 --> 00:39:19.619
how the brain works by building this, presumably
is to be able to solve problems that we're

00:39:19.619 --> 00:39:25.770
not able to solve today, with, with the more
powerful computers.

00:39:25.770 --> 00:39:32.990
Is that right or are you really more focused
on just understanding brain structures and

00:39:32.990 --> 00:39:33.990
brain activity?

00:39:33.990 --> 00:39:39.750
ANDRE 46:30
The latter, I would say, first instance, I'm

00:39:39.750 --> 00:39:45.109
interested in understanding the brain, I believe
that if we do that, we will also find better

00:39:45.109 --> 00:39:50.820
ways to do artificial intelligence or machine
learning tasks.

00:39:50.820 --> 00:39:58.240
But that's the secondary goal that would come
after we make progress in better understanding

00:39:58.240 --> 00:39:59.240
the brain.

00:39:59.240 --> 00:40:04.340
CRAIG 46:55
Yeah, and what sort of timeline in understanding

00:40:04.340 --> 00:40:07.160
the brain are you looking out?

00:40:07.160 --> 00:40:10.430
I mean, you're still a young guy?

00:40:10.430 --> 00:40:18.290
Are you hoping that within the next 10 or
20 years, we will have figured out how the

00:40:18.290 --> 00:40:23.380
brain operates at a much deeper level than
we understand today?

00:40:23.380 --> 00:40:27.839
ANDRE 47:20
I'm definitely hoping that when.

00:40:27.839 --> 00:40:39.079
Whether we achieve that also depends on unknown
progress in research and in studying the brain,

00:40:39.079 --> 00:40:40.079
right.

00:40:40.079 --> 00:40:45.230
It's like we’re making this machine available
and it gives us possibilities to do these

00:40:45.230 --> 00:40:47.430
simulations and study that.

00:40:47.430 --> 00:40:48.990
How quickly will that pay off?

00:40:48.990 --> 00:40:51.660
It's very difficult to predict.

00:40:51.660 --> 00:40:56.490
The other thing that's difficult to predict
is, how popular will this be?

00:40:56.490 --> 00:41:06.050
How many researchers will end up using this
or a machine like this that might be a machine

00:41:06.050 --> 00:41:11.790
inspired by hours built by somebody else somewhere
else, but also with hardware that people can

00:41:11.790 --> 00:41:14.319
buy and replicate, and so on.

00:41:14.319 --> 00:41:18.890
I find that very difficult to see how that
will go.

00:41:18.890 --> 00:41:26.270
I would hope it'll be very popular and lots
of people want to use it, and copy it, and

00:41:26.270 --> 00:41:29.930
make their own versions, and make improvements
on that.

00:41:29.930 --> 00:41:34.420
And that really locks up potential to do these
studies.

00:41:34.420 --> 00:41:43.210
That should then, hopefully lead to much quicker
advances in understanding how brains compute

00:41:43.210 --> 00:41:44.210
with spikes.

00:41:44.210 --> 00:41:49.610
CRAIG 48:40
Yeah, is there much interest from the artificial

00:41:49.610 --> 00:41:52.380
intelligence research community?

00:41:52.380 --> 00:41:56.590
ANDRE 48:48
Not yet, but we haven't really pitched it

00:41:56.590 --> 00:41:59.119
to them yet either.

00:41:59.119 --> 00:42:07.170
I've only announced it at a conference that
we organized here in Australia last December,

00:42:07.170 --> 00:42:09.220
the Neural Engineering conference.

00:42:09.220 --> 00:42:17.680
I've since done a podcast here and there and
some news articles on this.

00:42:17.680 --> 00:42:26.710
Once we've built it and we've launched it,
then we will get it all working nicely, and

00:42:26.710 --> 00:42:30.839
we can talk about it more, because then I'm
more comfortable that it's all working as

00:42:30.839 --> 00:42:32.530
it should as well.

00:42:32.530 --> 00:42:40.109
And then once we're ready, then we will start
talking more widely about it and trying to

00:42:40.109 --> 00:42:44.630
attract users effectively for this type of
machine.

00:42:44.630 --> 00:42:46.829
CRAIG 49:40
Yeah.

00:42:46.829 --> 00:42:49.030
Well, it's fascinating.

00:42:49.030 --> 00:42:55.579
As you can tell, I'm coming from a position
of ignorance.

00:42:55.579 --> 00:43:01.930
Are there things that I haven't asked about
that listeners would want to know?

00:43:01.930 --> 00:43:08.270
ANDRE 49:57
I think we've covered the main points about

00:43:08.270 --> 00:43:13.069
what we're trying to do here quite well.

00:43:13.069 --> 00:43:20.059
That is, trying to understand the electrical
computation in the brain, having hardware

00:43:20.059 --> 00:43:25.680
that makes it possible to do this at scale
for researchers worldwide, using hardware

00:43:25.680 --> 00:43:32.329
that is commercially available so people can
make copies, and using hardware that is flexible

00:43:32.329 --> 00:43:37.020
so that we can add other features to it as
we discover that we need them.

00:43:37.020 --> 00:43:42.310
CRAIG 50:33
Yeah, I mean, it would be remarkable even

00:43:42.310 --> 00:43:51.080
if it's not your ambition, if you can replicate
the success of GPUs and transformer algorithms,

00:43:51.080 --> 00:43:58.260
for example, because the whole GPU bottleneck
is severe.

00:43:58.260 --> 00:44:07.390
ANDRE 50:57
Yeah, and that would indeed be fantastic if

00:44:07.390 --> 00:45:20.550
we could 

00:45:20.550 --> 00:46:01.720
do that.

