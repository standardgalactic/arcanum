WEBVTT
Kind: captions
Language: en

00:00:41.160 --> 00:02:52.560
DANNY 0:30
I did my undergrad at UC Berkeley in computer&nbsp;&nbsp;

00:02:52.560 --> 00:02:59.680
science. At the time I was very interested&nbsp;
in computer security. So after graduation,&nbsp;&nbsp;

00:02:59.680 --> 00:03:06.760
I worked at Google and Robinhood where I was doing&nbsp;
machine learning fraud detection. Then around the&nbsp;&nbsp;

00:03:06.760 --> 00:03:14.800
time that GPT-3 came out, I thought it was a big&nbsp;
turning point for AI, as a lot of people did,&nbsp;&nbsp;

00:03:14.800 --> 00:03:20.600
both from an advancement standpoint and also&nbsp;
just as a what are the implications for broader&nbsp;&nbsp;

00:03:20.600 --> 00:03:29.960
society, for the labor force, just from a safety&nbsp;
perspective. So I felt compelled to go back to&nbsp;&nbsp;

00:03:29.960 --> 00:03:37.320
school and do work in this space. I started&nbsp;
working with Jacob Steinhardt at UC Berkeley&nbsp;&nbsp;

00:03:37.320 --> 00:03:44.640
and was really interested in understanding how&nbsp;
models work. We know that models work very well,&nbsp;&nbsp;

00:03:44.640 --> 00:03:50.720
we know neural networks are strong but we&nbsp;
don't necessarily know how they work. So this&nbsp;&nbsp;

00:03:50.720 --> 00:03:56.360
is a problem that really gripped me because these&nbsp;
things are deployed in high-stakes situations but&nbsp;&nbsp;

00:03:56.360 --> 00:04:03.840
we have no idea what the underlying algorithm that&nbsp;
they're implementing is- to make decisions and do&nbsp;&nbsp;

00:04:03.840 --> 00:04:11.120
various tasks. So this is one area of research&nbsp;
that I was very interested in. Then recently&nbsp;&nbsp;

00:04:11.120 --> 00:04:19.440
we've done work on automated forecasting with&nbsp;
AI. So this is forecasting future geopolitical&nbsp;&nbsp;

00:04:19.440 --> 00:04:31.960
events with AI systems. We believe that this has&nbsp;
implications for AI safety and also implications&nbsp;&nbsp;

00:04:31.960 --> 00:04:37.920
for the broader public- how they could potentially&nbsp;
use this technology if it were to work. So you&nbsp;&nbsp;

00:04:37.920 --> 00:04:44.800
can imagine that if we had a system that could&nbsp;
forecast future events better than humans, we&nbsp;&nbsp;

00:04:44.800 --> 00:04:52.000
would be able to understand the results of taking&nbsp;
certain actions and making certain decisions. And&nbsp;&nbsp;

00:04:52.000 --> 00:04:59.040
if we can understand those things, we could make&nbsp;
better-informed decisions on what actions to take.&nbsp;&nbsp;

00:05:00.280 --> 00:05:06.840
Currently, we have forecasters that are humans&nbsp;
that forecast different events. The really good&nbsp;&nbsp;

00:05:06.840 --> 00:05:13.720
ones are called Superforecasters. The thing with&nbsp;
superforecasters is that there's not a lot of them&nbsp;&nbsp;

00:05:13.720 --> 00:05:20.320
and they're expensive. So you can have a machine&nbsp;
that could forecast at the level of humans;&nbsp;&nbsp;

00:05:20.320 --> 00:05:26.320
this would be very valuable because you could&nbsp;
distribute this technology widely and people&nbsp;&nbsp;

00:05:26.320 --> 00:05:35.840
could use this to make more informed decisions.&nbsp;
Also, you can imagine as AI gets really advanced-&nbsp;&nbsp;

00:05:35.840 --> 00:05:45.400
using AI to forecast AI itself, meaning using AI&nbsp;
to forecast when AI will be able to do a certain&nbsp;&nbsp;

00:05:45.400 --> 00:05:51.240
thing or when it will get to this level of&nbsp;
capability is really important so we can&nbsp;&nbsp;

00:05:51.240 --> 00:05:57.920
understand, [What is the world going to look like&nbsp;
in two years?] These were the two things that got&nbsp;&nbsp;

00:05:57.920 --> 00:06:04.668
us interested in using AI for forecasting&nbsp;
and that's what I've been up to recently.

00:06:04.668 --> 00:06:05.720
CRAIG 3:47
Yeah. So tell&nbsp;&nbsp;

00:06:05.720 --> 00:06:11.520
me about the system that you've built and&nbsp;
the paper that you wrote. I guess start&nbsp;&nbsp;

00:06:11.520 --> 00:06:20.200
with the prediction markets, which I wasn't&nbsp;
really aware of, and how those function,&nbsp;&nbsp;

00:06:20.960 --> 00:06:32.480
also how the super forecasters function. Are&nbsp;
they doing deep research around an event?

00:06:32.480 --> 00:06:35.600
DANNY 4:20
Absolutely. I guess the thing I'll start with&nbsp;&nbsp;

00:06:35.600 --> 00:06:41.320
is some context which is, the thing we're doing&nbsp;
is referred to as judgemental forecasting versus&nbsp;&nbsp;

00:06:41.320 --> 00:06:48.640
time series forecasting. Time series forecasting&nbsp;
typically excels when data is abundant and when&nbsp;&nbsp;

00:06:48.640 --> 00:06:53.920
it doesn't change much, so it's under minimal&nbsp;
distributional shift. And here, in this field, you&nbsp;&nbsp;

00:06:53.920 --> 00:06:59.680
take tools from time series modeling. So you can&nbsp;
imagine if you want to forecast the weather, you&nbsp;&nbsp;

00:06:59.680 --> 00:07:04.920
just collect a lot of data that you have currently&nbsp;
in the environment and use some time series&nbsp;&nbsp;

00:07:04.920 --> 00:07:10.200
modeling to make a forecast about the weather.&nbsp;
Judgemental forecasting, on the other hand, is&nbsp;&nbsp;

00:07:10.200 --> 00:07:17.000
where people assign probabilities to future events&nbsp;
based off historical data, their intuition, their&nbsp;&nbsp;

00:07:17.000 --> 00:07:22.760
firm estimates, and their domain knowledge. It's&nbsp;
very much intuition-based, it's very much just&nbsp;&nbsp;

00:07:22.760 --> 00:07:28.920
thinking about; What are the possible outcomes?&nbsp;
What are the factors that I should consider? What&nbsp;&nbsp;

00:07:28.920 --> 00:07:33.120
are the probabilities of the different factors?&nbsp;
So we are interested in the field of judgemental&nbsp;&nbsp;

00:07:33.120 --> 00:07:39.560
forecasting. Okay, to study this you can take a&nbsp;
look at prediction markets. Prediction markets&nbsp;&nbsp;

00:07:39.560 --> 00:07:45.480
are essentially these platforms where people put&nbsp;
probabilities on different events happening. So&nbsp;&nbsp;

00:07:45.480 --> 00:07:49.960
anybody can go on to these prediction platforms,&nbsp;
take a look at a question that interests them,&nbsp;&nbsp;

00:07:49.960 --> 00:07:54.840
like who's going to win the next US election,&nbsp;
and they can put a probability on each candidate,&nbsp;&nbsp;

00:07:54.840 --> 00:08:00.920
and you have many people doing this. Based off&nbsp;
what people think, this will determine what the&nbsp;&nbsp;

00:08:00.920 --> 00:08:07.000
platform or prediction market thinks is the true&nbsp;
probability of this event. So if you have like&nbsp;&nbsp;

00:08:07.000 --> 00:08:14.000
500 people putting a probability on Trump or&nbsp;
Biden or some other candidate winning and you&nbsp;&nbsp;

00:08:14.000 --> 00:08:19.720
aggregate all this information of what all these&nbsp;
different people think; the prediction market puts&nbsp;&nbsp;

00:08:19.720 --> 00:08:29.600
a probability on the event. So one natural concern&nbsp;
is, [Well, some humans are probably better at&nbsp;&nbsp;

00:08:29.600 --> 00:08:36.240
forecasting than others. So why should the&nbsp;
platform consider everyone's probability?] And the&nbsp;&nbsp;

00:08:36.240 --> 00:08:43.520
thing that these platforms do is weigh people's&nbsp;
probabilities based off their past performance.&nbsp;&nbsp;

00:08:43.520 --> 00:08:50.160
So if you've been on these platforms for a long&nbsp;
time and you've done very well at predicting the&nbsp;&nbsp;

00:08:50.160 --> 00:08:54.560
future, then the platform puts a lot of weight on&nbsp;
your probability because you've done a good job&nbsp;&nbsp;

00:08:54.560 --> 00:09:00.120
in the past so they have reason to believe you'll&nbsp;
do a good job in the future. Another interesting&nbsp;&nbsp;

00:09:00.120 --> 00:09:06.080
thing I'll say about these prediction markets is&nbsp;
that if you take a look at the aggregate forecast&nbsp;&nbsp;

00:09:06.080 --> 00:09:13.160
of forecasters, so you take a look at what&nbsp;
the prediction market says is the probability,&nbsp;&nbsp;

00:09:13.720 --> 00:09:20.600
which it is based off of the individual&nbsp;
forecasters; this probability is usually&nbsp;&nbsp;

00:09:20.600 --> 00:09:30.520
more accurate than the probability reported by the&nbsp;
expert forecasters. The reason why this happens&nbsp;&nbsp;

00:09:30.520 --> 00:09:38.320
is because every individual has their own biases,&nbsp;
they base their forecasts off the information that&nbsp;&nbsp;

00:09:38.320 --> 00:09:45.240
they find compelling, and when you average the&nbsp;
probabilities across many different individuals,&nbsp;&nbsp;

00:09:45.240 --> 00:09:50.600
you're sort of getting all the different pieces of&nbsp;
information that each individual is considering.&nbsp;&nbsp;

00:09:50.600 --> 00:09:56.160
You're also sort of averaging out this bias factor&nbsp;
that each individual has. This is referred to as&nbsp;&nbsp;

00:09:56.160 --> 00:10:03.320
like the wisdom of the crowd. And that's why&nbsp;
prediction markets are a very valuable tool and&nbsp;&nbsp;

00:10:03.320 --> 00:10:10.920
are very successful. It's because by taking what&nbsp;
everyone thinks and averaging them in some way,&nbsp;&nbsp;

00:10:10.920 --> 00:10:17.720
you can get a more accurate forecast than you&nbsp;
would have. So that's basically the field of&nbsp;&nbsp;

00:10:17.720 --> 00:10:22.680
judgmental forecasting and this is sort of the&nbsp;
state of prediction markets. I guess I'll also&nbsp;&nbsp;

00:10:22.680 --> 00:10:29.480
add that prediction markets have been around&nbsp;
for a bit but there's been a lot more excitement&nbsp;&nbsp;

00:10:29.480 --> 00:10:36.040
about them recently. So just a lot more&nbsp;
user participation. This has almost become a&nbsp;&nbsp;

00:10:36.040 --> 00:10:44.360
trend or fad, where people go on these prediction&nbsp;
markets and just start submitting probabilities&nbsp;&nbsp;

00:10:44.360 --> 00:10:50.760
for different things. People will even propose&nbsp;
their own questions. So there has been a lot of&nbsp;&nbsp;

00:10:50.760 --> 00:10:58.840
excitement in this space and a lot of attention&nbsp;
which I think is a good thing for this field.

00:10:58.840 --> 00:11:00.240
CRAIG 8:47&nbsp;

00:11:01.080 --> 00:11:12.640
Let me just ask before we go on from that.&nbsp;
What's the accuracy? Is there an aggregate&nbsp;&nbsp;

00:11:12.640 --> 00:11:19.600
accuracy for the different platforms? I&nbsp;
would imagine that when you break that down&nbsp;&nbsp;

00:11:19.600 --> 00:11:29.240
to different domains, they're more accurate&nbsp;
in some domains and others. Then, if they are&nbsp;&nbsp;

00:11:30.320 --> 00:11:41.120
70% or above accurate, are people using them&nbsp;
to gamble? That seems like an obvious use case.

00:11:41.120 --> 00:11:44.960
DANNY 9:28
So these prediction markets&nbsp;&nbsp;

00:11:44.960 --> 00:11:50.680
don't actually use real money. That's important&nbsp;
to say. You're not actually going on and placing&nbsp;&nbsp;

00:11:50.680 --> 00:11:56.240
a real bet- although that would probably increase&nbsp;
the accuracy of some of these questions because&nbsp;&nbsp;

00:11:56.240 --> 00:12:02.440
if you're actually using real money, maybe people&nbsp;
are more incentivized to really think through the&nbsp;&nbsp;

00:12:02.440 --> 00:12:14.720
question. People do rely on the prediction markets&nbsp;
for making their own decisions. People do use the&nbsp;&nbsp;

00:12:14.720 --> 00:12:22.800
wisdom of the crowd to actually incorporate into&nbsp;
their life when considering different things,&nbsp;&nbsp;

00:12:22.800 --> 00:12:29.360
whether it's to take on this major in&nbsp;
college; like, people who are entering&nbsp;&nbsp;

00:12:29.360 --> 00:12:33.480
college right now are trying to understand,&nbsp;
[Okay, if I go into this field of medicine,&nbsp;&nbsp;

00:12:33.480 --> 00:12:39.720
will it just be completely automated by AI in two&nbsp;
years?] So I think there are people who really,&nbsp;&nbsp;

00:12:41.240 --> 00:12:47.800
take information from these prediction markets&nbsp;
and use it practically. As far as betting goes,&nbsp;&nbsp;

00:12:47.800 --> 00:12:52.880
there's lots of questions on sports on these&nbsp;
platforms. I wouldn't be surprised if people&nbsp;&nbsp;

00:12:52.880 --> 00:12:59.440
do use them to make sports bets but I would be&nbsp;
surprised if anyone has used them successfully&nbsp;&nbsp;

00:12:59.440 --> 00:13:06.360
to make money. I think that's because, when&nbsp;
you think about the things that we can bet on,&nbsp;&nbsp;

00:13:06.360 --> 00:13:13.680
like sports events or maybe elections, these&nbsp;
things are extremely hard to predict and very&nbsp;&nbsp;

00:13:13.680 --> 00:13:19.280
chaotic. So even if you get a more accurate&nbsp;
probability from the crowd, which you will,&nbsp;&nbsp;

00:13:19.280 --> 00:13:25.120
there's just a level of noise that you&nbsp;
can't really beat, which still allows&nbsp;&nbsp;

00:13:28.040 --> 00:13:33.787
basically the house to win almost every time.&nbsp;
So that's the current state, to answer that.

00:13:33.787 --> 00:13:34.320
CRAIG 11:20
Yeah, but&nbsp;&nbsp;

00:13:35.040 --> 00:13:43.640
what's the reliability or the&nbsp;
success rate of these platforms?

00:13:43.640 --> 00:13:45.800
DANNY 11:29
Oh, right. So up&nbsp;&nbsp;

00:13:45.800 --> 00:13:55.080
until 2022– so I can give you some stats on&nbsp;
some of these platforms. So an earlier paper&nbsp;&nbsp;

00:13:55.080 --> 00:14:02.960
by Andy Zhao and colleagues looked at three&nbsp;
platforms, Meticulous, Good Judgment Open,&nbsp;&nbsp;

00:14:02.960 --> 00:14:11.720
and CSET Foretell, which are three prediction&nbsp;
markets. Across all questions, the crowd got,&nbsp;&nbsp;

00:14:11.720 --> 00:14:20.160
I believe, an accuracy of 92%. But, if you look&nbsp;
at the same exact platforms in the last two years,&nbsp;&nbsp;

00:14:20.160 --> 00:14:27.320
which is what we studied, their accuracy falls to&nbsp;
77%. This isn't to say that they're getting worse,&nbsp;&nbsp;

00:14:27.320 --> 00:14:34.000
this is just to say that the types of questions&nbsp;
that they're forecasting are getting more and&nbsp;&nbsp;

00:14:34.000 --> 00:14:48.440
more difficult. Maybe one thing that's helpful&nbsp;
as a statistic is, these prediction markets,&nbsp;&nbsp;

00:14:48.440 --> 00:14:54.120
if you were to compare them, let's say you were&nbsp;
to do a competition with individual forecasters&nbsp;&nbsp;

00:14:54.120 --> 00:15:01.520
that really have a lot of experience, are very&nbsp;
smart, and are have known to be accurate- these&nbsp;&nbsp;

00:15:01.520 --> 00:15:08.320
prediction markets, on average, tend to be&nbsp;
even better than them. So the accuracy will&nbsp;&nbsp;

00:15:08.320 --> 00:15:13.280
completely just depend on the difficulty of the&nbsp;
questions you're considering. But as far as,&nbsp;&nbsp;

00:15:13.280 --> 00:15:16.480
[How powerful are these markets?] I would&nbsp;
say that they're quite strong and I think&nbsp;&nbsp;

00:15:16.480 --> 00:15:21.027
that they will only continue to get more&nbsp;
strong as you get increased participation.

00:15:21.027 --> 00:15:24.840
CRAIG 13:07
Yeah, before, again, we go into&nbsp;&nbsp;

00:15:24.840 --> 00:15:33.560
your paper and your system, just aggregating the&nbsp;
predictions of the prediction market seems that it&nbsp;&nbsp;

00:15:33.560 --> 00:15:39.360
would be one step towards a stronger prediction.&nbsp;
If you have, I don't know how many there are,&nbsp;&nbsp;

00:15:39.360 --> 00:15:49.080
5 or 10 markets, probably the questions are&nbsp;
phrased slightly differently and that would create&nbsp;&nbsp;

00:15:50.400 --> 00:16:01.147
some noise. Can you boost the predictions simply&nbsp;
by aggregating the prediction markets themselves?

00:16:01.147 --> 00:16:03.120
DANNY 13:46
Yeah, absolutely. I mean, sort&nbsp;&nbsp;

00:16:03.120 --> 00:16:10.400
of one of the key takeaways from the forecasting&nbsp;
literature is, the more sources of information&nbsp;&nbsp;

00:16:10.400 --> 00:16:15.640
you have, the more signals you have, the better&nbsp;
your forecast is. So there is there are actually&nbsp;&nbsp;

00:16:15.640 --> 00:16:19.360
currently platforms- I can't remember the name of&nbsp;
the one I'm thinking of, but there is a current&nbsp;&nbsp;

00:16:19.360 --> 00:16:25.480
platform that simply aggregates that prediction&nbsp;
from all the prediction markets for a particular&nbsp;&nbsp;

00:16:25.480 --> 00:16:31.560
question. So this is done in practice. And I think&nbsp;
one thing that you pointed out is you have to be&nbsp;&nbsp;

00:16:31.560 --> 00:16:36.280
careful because the questions might have different&nbsp;
wordings on different platforms, which would&nbsp;&nbsp;

00:16:36.280 --> 00:16:43.160
create different probabilities for the event. Or,&nbsp;
they might have different resolution criteria. So&nbsp;&nbsp;

00:16:44.920 --> 00:16:50.440
two platforms will have the same question but&nbsp;
maybe one platform will say, this will resolve&nbsp;&nbsp;

00:16:50.440 --> 00:16:56.800
as ‘Yes’ under this criteria. Then, another&nbsp;
platform will say, this will resolve is yes under&nbsp;&nbsp;

00:16:56.800 --> 00:17:03.720
this criteria. For example, let's say the question&nbsp;
is, will the Starship launch be successful? People&nbsp;&nbsp;

00:17:03.720 --> 00:17:09.880
have different criteria for what successful is and&nbsp;
one platform, might outline certain criteria for&nbsp;&nbsp;

00:17:09.880 --> 00:17:15.360
successful launch and the other one will have&nbsp;
different criteria. So yeah, you just have to&nbsp;&nbsp;

00:17:15.360 --> 00:17:21.587
be careful with respect to that but overall this&nbsp;
would be a very intuitive and natural thing to do.

00:17:21.587 --> 00:17:22.400
CRAIG 15:08
Yeah,&nbsp;&nbsp;

00:17:23.840 --> 00:17:30.907
let's talk about what you have been&nbsp;
doing with large foundation models.

00:17:30.907 --> 00:17:32.040
DANNY 15:17
Cool. Yeah,&nbsp;&nbsp;

00:17:32.040 --> 00:17:37.400
recently our group at UC Berkeley, with&nbsp;
Fred Zahn, Yuhan Chen, and Jacob Steinhardt,&nbsp;&nbsp;

00:17:37.400 --> 00:17:47.560
we released a paper showing that an end-to-end&nbsp;
language model system can forecast future events&nbsp;&nbsp;

00:17:48.840 --> 00:17:53.960
almost at the level of human crowd aggregates,&nbsp;
almost at the level of these prediction markets.&nbsp;&nbsp;

00:17:53.960 --> 00:18:00.840
In some specific settings, they're actually&nbsp;
better than the prediction markets. So yeah,&nbsp;&nbsp;

00:18:03.320 --> 00:18:08.520
we could start with the dataset collection and&nbsp;
I could tell you about what the task is, the&nbsp;&nbsp;

00:18:08.520 --> 00:18:13.789
motivation for it, and why we set it up this way.&nbsp;
Then I could tell you how our system performs.

00:18:13.789 --> 00:18:14.480
CRAIG 16:00
Yeah.

00:18:14.480 --> 00:18:17.480
DANNY 16:01
So on the data collection front,&nbsp;&nbsp;

00:18:17.480 --> 00:18:23.800
there's all these prediction markets in the&nbsp;
wild. Most of them have API's or it's easy&nbsp;&nbsp;

00:18:23.800 --> 00:18:31.400
to scrape the data online, and they allow you&nbsp;
to do this. You could scrape the questions,&nbsp;&nbsp;

00:18:31.400 --> 00:18:38.960
you can scrape what the crowd thinks at different&nbsp;
dates. The crowd prediction is constantly changing&nbsp;&nbsp;

00:18:38.960 --> 00:18:43.920
over time as new information is accrued. It's not&nbsp;
like there's a question they asked the crowd once&nbsp;&nbsp;

00:18:43.920 --> 00:18:50.560
and they use that as a probability. They ask the&nbsp;
crowd across questions, open date and close date.&nbsp;&nbsp;

00:18:50.560 --> 00:18:54.720
So the question might be open for six months&nbsp;
or something and the crowd prediction changes;&nbsp;&nbsp;

00:18:54.720 --> 00:19:02.240
so you can get all this data. Given that you have&nbsp;
these questions and this data, you can ask an&nbsp;&nbsp;

00:19:02.240 --> 00:19:08.000
AI system like language model what it thinks the&nbsp;
probability of this event happening is and you can&nbsp;&nbsp;

00:19:08.000 --> 00:19:15.120
compare it to what the crowd thinks. Eventually,&nbsp;
at some point the question is resolved,&nbsp;&nbsp;

00:19:15.120 --> 00:19:20.640
the outcome happens. And you can sort of compute&nbsp;
the accuracy across many different questions over&nbsp;&nbsp;

00:19:20.640 --> 00:19:28.240
time and see how accurate your system is. So&nbsp;
this is the setup. We thought that language&nbsp;&nbsp;

00:19:28.240 --> 00:19:38.440
models would be a really good place to start&nbsp;
with getting superhuman machine forecasting.&nbsp;&nbsp;

00:19:38.440 --> 00:19:43.680
We thought language models was a good place to&nbsp;
start for a couple different reasons. The first&nbsp;&nbsp;

00:19:43.680 --> 00:19:52.920
is that for human forecasting, typically expert&nbsp;
forecasters or people who do this as a profession,&nbsp;&nbsp;

00:19:52.920 --> 00:19:58.160
forecast in specific domains. So if you want&nbsp;
really good forecasts about the environment,&nbsp;&nbsp;

00:19:58.160 --> 00:20:02.480
there are certain people who are really good&nbsp;
at this. But this limits you because you have&nbsp;&nbsp;

00:20:02.480 --> 00:20:08.880
to rely on experts and some questions call upon&nbsp;
introduce interdisciplinary thinking, which isn't&nbsp;&nbsp;

00:20:08.880 --> 00:20:15.160
always trivial to think about. So language models&nbsp;
are trained on web-scale data. So they're endowed&nbsp;&nbsp;

00:20:15.160 --> 00:20:23.080
with mass cross-domain knowledge so they don't&nbsp;
succumb to this limitation. Furthermore, they can&nbsp;&nbsp;

00:20:23.080 --> 00:20:31.080
parse and produce texts extremely rapidly. They're&nbsp;
timely, you can invoke them at any point in time&nbsp;&nbsp;

00:20:31.080 --> 00:20:41.920
during the day or at any point in time during your&nbsp;
decision process. Lastly, they can be trained in a&nbsp;&nbsp;

00:20:41.920 --> 00:20:49.680
way that humans can't. Language models as they&nbsp;
currently stand are trained on some very large&nbsp;&nbsp;

00:20:49.680 --> 00:20:56.200
data set and then deployed and then used. But once&nbsp;
they're deployed, they're not getting updated or&nbsp;&nbsp;

00:20:56.200 --> 00:21:02.640
retrained with recent knowledge. I think good&nbsp;
evidence for this is if you go to ChatGPT, you&nbsp;&nbsp;

00:21:02.640 --> 00:21:09.920
ask it who won the last NBA Finals; it won't be&nbsp;
able to tell you because it was trained up until&nbsp;&nbsp;

00:21:09.920 --> 00:21:18.720
2021. Once it was released, it wasn't trained&nbsp;
again. So why is this useful and interesting?&nbsp;&nbsp;

00:21:18.720 --> 00:21:24.920
It is because I can ask a language model about&nbsp;
events that have already been resolved or have&nbsp;&nbsp;

00:21:24.920 --> 00:21:31.520
already happened and see what its prediction&nbsp;
is and compare that to the crowd prediction.&nbsp;&nbsp;

00:21:32.360 --> 00:21:38.560
In addition, if I let it look at information&nbsp;
that was only available up until some date,&nbsp;&nbsp;

00:21:38.560 --> 00:21:45.080
I can sort of simulate forecasting. So today,&nbsp;
if I were to forecast the state of the election,&nbsp;&nbsp;

00:21:45.080 --> 00:21:51.120
who I think is going to win the US election,&nbsp;
I'd go online and I have information available&nbsp;&nbsp;

00:21:51.120 --> 00:21:57.160
up until today, March 8, and tomorrow I’d have&nbsp;
information available up until March 9. So you&nbsp;&nbsp;

00:21:57.160 --> 00:22:03.360
could retroactively go to these models and just&nbsp;
give them information up to some date and then&nbsp;&nbsp;

00:22:03.360 --> 00:22:11.240
have them make a prediction. This will effectively&nbsp;
be like, what would this model have said if it was&nbsp;&nbsp;

00:22:11.240 --> 00:22:19.680
really forecasting on this date? So you can set&nbsp;
up this method of evaluation and method to train&nbsp;&nbsp;

00:22:19.680 --> 00:22:27.120
these models on information that has already been&nbsp;
resolved in a way that's automatic and effective.&nbsp;&nbsp;

00:22:30.160 --> 00:22:36.960
One method you could even consider is having a&nbsp;
language model that was deployed with data up&nbsp;&nbsp;

00:22:36.960 --> 00:22:44.240
until 2023 to sort of teach and guide a model that&nbsp;
was trained only up until 2021. The point here is&nbsp;&nbsp;

00:22:44.240 --> 00:22:51.120
that the 2023 model would have so much information&nbsp;
about things that have happened that it could have&nbsp;&nbsp;

00:22:51.120 --> 00:22:56.120
the earlier language model make predictions,&nbsp;
it could help you correct its predictions, and&nbsp;&nbsp;

00:22:59.000 --> 00:23:03.000
it could help it learn where its mistakes are, how&nbsp;
it could have made a better prediction and improve&nbsp;&nbsp;

00:23:03.000 --> 00:23:08.920
accordingly. So you can have this completely&nbsp;
automatic training between two systems where&nbsp;&nbsp;

00:23:08.920 --> 00:23:15.480
there's literally no human involved. So we thought&nbsp;
that this would make language models a really good&nbsp;&nbsp;

00:23:15.480 --> 00:23:22.680
place to start for forecasting. Interestingly,&nbsp;
this idea has been proposed and tried in the&nbsp;&nbsp;

00:23:22.680 --> 00:23:32.000
past. We're not the first people to come up with&nbsp;
this idea or try it. In a study that was released&nbsp;&nbsp;

00:23:32.000 --> 00:23:43.040
in 2022 by Andy Zhao and his collaborators showed&nbsp;
that their system achieved an accuracy around 65%,&nbsp;&nbsp;

00:23:43.040 --> 00:23:51.280
whereas the crowd accuracy was 92%. So their&nbsp;
system was a lot worse than the crowd. But&nbsp;&nbsp;

00:23:51.280 --> 00:24:00.440
as language models have become more capable over&nbsp;
the past two years, we thought to try this again,&nbsp;&nbsp;

00:24:00.440 --> 00:24:09.720
potentially sourcing even better information and&nbsp;
training this system in more advanced ways. What&nbsp;&nbsp;

00:24:09.720 --> 00:24:19.320
we observe is that the model has gotten more&nbsp;
accurate. Our accuracy was 71% versus the crowd&nbsp;&nbsp;

00:24:19.320 --> 00:24:28.600
accuracy of 77%. What we hope to show here is&nbsp;
that language models are a good place to train&nbsp;&nbsp;

00:24:28.600 --> 00:24:34.120
machines to forecast. We believe this gap will&nbsp;
only become more narrow over time and eventually&nbsp;&nbsp;

00:24:34.120 --> 00:24:41.360
machines will become better. If this is the case,&nbsp;
we hope that this technology is distributed across&nbsp;&nbsp;

00:24:41.360 --> 00:24:45.440
organizations and people so that they can&nbsp;
use it to make more informed decisions.

00:24:45.440 --> 00:24:49.280
CRAIG 22:31
Yeah, and the data-&nbsp;&nbsp;

00:24:49.280 --> 00:24:58.480
let's say you want to predict a sports team, not&nbsp;
that I'm particularly interested in gambling,&nbsp;&nbsp;

00:24:58.480 --> 00:25:09.440
but you have the Super Bowl and there's– are&nbsp;
you relying on the information encoded in the&nbsp;&nbsp;

00:25:09.440 --> 00:25:20.400
weights of the models? Or are you supplying the&nbsp;
models with reams of data on individual players,&nbsp;&nbsp;

00:25:20.400 --> 00:25:31.307
on historical outcomes? What kind of data are&nbsp;
you providing and how do you collect that data?

00:25:31.307 --> 00:25:33.120
DANNY 23:17
Yeah, great question. I'll&nbsp;&nbsp;

00:25:33.120 --> 00:25:37.200
answer that question and then also talk a little&nbsp;
bit about how our system was trained since that'll&nbsp;&nbsp;

00:25:37.200 --> 00:25:44.640
give insight on what sort of data the model is&nbsp;
privy to. So at test time, when we're actually&nbsp;&nbsp;

00:25:44.640 --> 00:25:51.800
having the model make forecasts, what we do is&nbsp;
we give it access to essentially the internet;&nbsp;&nbsp;

00:25:52.920 --> 00:25:56.280
up until some date, of course, because we&nbsp;
don't want it to have information after a&nbsp;&nbsp;

00:25:56.280 --> 00:26:03.840
date. And what it has access to is– what we let&nbsp;
the system do is decide what it wants to search&nbsp;&nbsp;

00:26:03.840 --> 00:26:10.360
on the internet. For forecasting let's say&nbsp;
the Super Bowl, the system will say, [Okay,&nbsp;&nbsp;

00:26:10.360 --> 00:26:14.320
I want to see what experts are saying. I want&nbsp;
to see who's currently injured. I want to see&nbsp;&nbsp;

00:26:14.320 --> 00:26:17.840
what the weather is going to be like for&nbsp;
the game.] So the system itself will come&nbsp;&nbsp;

00:26:17.840 --> 00:26:22.440
up with everything that it wants, what types&nbsp;
of information it'll want to see. Then we go&nbsp;&nbsp;

00:26:22.440 --> 00:26:28.240
and grab that information. Then the system&nbsp;
looks through, let's say 300 articles and&nbsp;&nbsp;

00:26:28.920 --> 00:26:34.040
it determines which ones are relevant and which&nbsp;
ones are irrelevant. So when you go try to look&nbsp;&nbsp;

00:26:34.040 --> 00:26:38.720
at the answer to a question on Google, you might&nbsp;
have to look through a few articles before you&nbsp;&nbsp;

00:26:38.720 --> 00:26:42.960
actually get the answer to your question.&nbsp;
The system does the same thing. We grab a&nbsp;&nbsp;

00:26:42.960 --> 00:26:48.680
bunch of articles and we decide which ones are&nbsp;
most relevant to the questions it was asking.

00:26:48.680 --> 00:26:51.160
CRAIG 24:35
Let me just stop you; when&nbsp;&nbsp;

00:26:51.160 --> 00:26:58.840
you say grab the articles, are you talking&nbsp;
about physically downloading content and then&nbsp;&nbsp;

00:26:58.840 --> 00:27:07.467
uploading it to the model? Are you talking about&nbsp;
copying URLs into the model? How does that happen?

00:27:07.467 --> 00:27:08.520
DANNY 24:54
Yeah, so we grabbed&nbsp;&nbsp;

00:27:08.520 --> 00:27:12.800
the content of the article, and the way we&nbsp;
do this is we use news API's. So there's a&nbsp;&nbsp;

00:27:12.800 --> 00:27:17.960
bunch of news API's out there. Google News is&nbsp;
one we use. Another one, there's this startup&nbsp;&nbsp;

00:27:17.960 --> 00:27:23.480
called NewsCatcher which we think sources&nbsp;
excellent information; I expect them to do&nbsp;&nbsp;

00:27:23.480 --> 00:27:32.960
very well. And they provide the body content of&nbsp;
an article. So we load this into a data structure,&nbsp;&nbsp;

00:27:32.960 --> 00:27:40.360
all the content in each individual article. Then&nbsp;
we have the model go through each article and&nbsp;&nbsp;

00:27:40.360 --> 00:27:46.200
look through the article end to end and see if&nbsp;
the information is relevant. This is step one.

00:27:46.200 --> 00:27:47.320
CRAIG 25:33
And let me stop you&nbsp;&nbsp;

00:27:47.320 --> 00:28:00.587
there. Are you putting the content into a vector&nbsp;
database? Or, are you uploading PDFs to the model?

00:28:00.587 --> 00:28:03.360
DANNY 25:49
So we're feeding it into its&nbsp;&nbsp;

00:28:03.360 --> 00:28:11.240
context. So just how you go on some web app and&nbsp;
prompt a language model, a way that we typically&nbsp;&nbsp;

00:28:11.240 --> 00:28:18.160
do as just common users; this is exactly how&nbsp;
it's being done. We're not embedding the article&nbsp;&nbsp;

00:28:18.160 --> 00:28:23.200
in a special way or encoding it in a special&nbsp;
way. We're just giving the plain text to the&nbsp;&nbsp;

00:28:23.200 --> 00:28:28.120
model within its context and then asking it some&nbsp;
questions like, [Do you think this is relevant&nbsp;&nbsp;

00:28:29.760 --> 00:28:34.108
given what you wanted to&nbsp;
know?] Does that make sense?

00:28:34.108 --> 00:28:34.709
CRAIG 26:20
Yeah

00:28:34.709 --> 00:28:41.760
DANNY 26:21
Cool. Once the system determines which articles it&nbsp;&nbsp;

00:28:41.760 --> 00:28:47.600
finds relevant, the next step is to summarize this&nbsp;
information. Why do we summarize this information?&nbsp;&nbsp;

00:28:47.600 --> 00:28:52.520
It's kind of for the reason you just said;&nbsp;
so we're giving this information to the model&nbsp;&nbsp;

00:28:52.520 --> 00:28:58.680
within its context window, which might be 16,000&nbsp;
tokens or 32,000 tokens. We have a limited space&nbsp;&nbsp;

00:28:58.680 --> 00:29:04.800
to work with. So we take like the 30 most relevant&nbsp;
articles and we summarize them to condense the&nbsp;&nbsp;

00:29:04.800 --> 00:29:10.000
information. Then we give it to a final language&nbsp;
model and say, [Okay, these are all the retrieved&nbsp;&nbsp;

00:29:10.000 --> 00:29:16.680
articles based off the questions that you ask,&nbsp;
based off what you found was relevant. Finally,&nbsp;&nbsp;

00:29:16.680 --> 00:29:21.920
apply these forecasting methods to make a&nbsp;
forecast.] These forecasting methods could be&nbsp;&nbsp;

00:29:21.920 --> 00:29:29.440
like, what do you think the reliability of each&nbsp;
information is? For each piece of information,&nbsp;&nbsp;

00:29:29.440 --> 00:29:37.880
how much weight do you put on this for affecting&nbsp;
the outcome? And, what is the historical base rate&nbsp;&nbsp;

00:29:37.880 --> 00:29:42.240
of this event happening? That's another thing you&nbsp;
might consider. So it just applies all these tools&nbsp;&nbsp;

00:29:42.240 --> 00:29:47.147
from forecasting and then makes a prediction.&nbsp;
So that's how the system works in deployment.

00:29:47.147 --> 00:29:47.800
CRAIG 27:35
I've been talking&nbsp;&nbsp;

00:29:47.800 --> 00:29:57.600
to a journalist researcher and a data&nbsp;
scientist about doing something similar,&nbsp;&nbsp;

00:29:58.160 --> 00:30:09.720
gathering information around a news event and&nbsp;
seeing if a large language model or an ensemble&nbsp;&nbsp;

00:30:09.720 --> 00:30:23.400
of models could determine the probability of&nbsp;
truth of any particular narrative around that&nbsp;&nbsp;

00:30:23.400 --> 00:30:38.360
event. The point is that there are narratives&nbsp;
that are not adopted by the dominant narrative,&nbsp;&nbsp;

00:30:38.360 --> 00:30:46.960
there are sub narratives that are excluded. You&nbsp;
can think of a million examples in a conflict;&nbsp;&nbsp;

00:30:46.960 --> 00:30:58.120
there's eyewitness accounts on Twitter/social&nbsp;
media that don't necessarily get picked up because&nbsp;&nbsp;

00:30:58.120 --> 00:31:08.680
they're considered too anecdotal or too biased&nbsp;
or whatever. In the same way, in this prediction,&nbsp;&nbsp;

00:31:08.680 --> 00:31:18.440
as you add data, presumably the prediction&nbsp;
will change. If you're using the news sources,&nbsp;&nbsp;

00:31:19.200 --> 00:31:32.120
that's one source of information; but if you use&nbsp;
something noisier like Twitter or– I don't know,&nbsp;&nbsp;

00:31:32.120 --> 00:31:39.560
I’m not young enough to be using social media&nbsp;
that much, but whatever platform is active on a&nbsp;&nbsp;

00:31:39.560 --> 00:31:47.987
question, you may get a different prediction.&nbsp;
So have you guys taken that into account?

00:31:47.987 --> 00:31:49.680
DANNY 29:46
I think thinking about&nbsp;&nbsp;

00:31:49.680 --> 00:31:57.920
what sources of information tend to provide more&nbsp;
reliable data is very important for forecasting.&nbsp;&nbsp;

00:31:57.920 --> 00:32:03.440
We let the language models sort of learn on it’s&nbsp;
own what information it finds to be effective to&nbsp;&nbsp;

00:32:03.440 --> 00:32:10.440
rely on. One interesting thing is, one way&nbsp;
you can measure the truthfulness of data&nbsp;&nbsp;

00:32:10.440 --> 00:32:16.360
is how well it can be used to predict future&nbsp;
events, for example. So if you find that all&nbsp;&nbsp;

00:32:16.360 --> 00:32:22.520
the information you source from a certain news&nbsp;
outlet is always really helpful for improving&nbsp;&nbsp;

00:32:22.520 --> 00:32:29.789
the accuracy of your predictions, this is&nbsp;
a good proxy for the truth of information.

00:32:29.789 --> 00:32:30.400
CRAIG 30:28
Yeah.

00:32:30.400 --> 00:32:31.400
DANNY 30:28
One follow-up&nbsp;&nbsp;

00:32:31.400 --> 00:32:35.640
that I've gotten from people along the&nbsp;
same lines of what you just said is&nbsp;&nbsp;

00:32:36.880 --> 00:32:43.880
using this for epistemic. So one thing you&nbsp;
could ask is, given this language model,&nbsp;&nbsp;

00:32:43.880 --> 00:32:49.360
I can source information from all these articles&nbsp;
and sort of reason about this information;&nbsp;&nbsp;

00:32:51.080 --> 00:32:55.520
how many people's minds can be changed using this&nbsp;
language model? I get this language model to like&nbsp;&nbsp;

00:32:55.520 --> 00:33:01.320
1000 people, asking them some controversial&nbsp;
question and the language model can pull&nbsp;&nbsp;

00:33:01.320 --> 00:33:07.840
information from different news sources. One&nbsp;
question you could ask is, how many people's&nbsp;&nbsp;

00:33:07.840 --> 00:33:18.680
minds can I change on a certain topic? As far&nbsp;
as measuring the truthfulness of information,&nbsp;&nbsp;

00:33:18.680 --> 00:33:24.800
I think forecasting is a good starting point for&nbsp;
this because if you rely on information that's&nbsp;&nbsp;

00:33:24.800 --> 00:33:31.440
always leading you to make inaccurate forecasts&nbsp;
of future events, you could sort of determine&nbsp;&nbsp;

00:33:31.440 --> 00:33:37.760
that it's not very accurate. During training of&nbsp;
our system, you could probably hypothesize that&nbsp;&nbsp;

00:33:37.760 --> 00:33:45.760
the model did learn which sources to rely more&nbsp;
on and which sources not to rely more on. And&nbsp;&nbsp;

00:33:45.760 --> 00:33:50.920
you don't have to train explicitly to do this.&nbsp;
It will implicitly learn to do this because it's&nbsp;&nbsp;

00:33:50.920 --> 00:33:56.027
trained to make accurate predictions and better&nbsp;
information will give you accurate predictions.

00:33:56.027 --> 00:34:00.160
CRAIG 31:53
Yeah. So you're relying solely&nbsp;&nbsp;

00:34:00.840 --> 00:34:08.067
on generative models? I mean, this sounds like&nbsp;
a perfect use case for reinforcement learning.

00:34:08.067 --> 00:34:10.240
DANNY 32:06
So I think reinforcement learning&nbsp;&nbsp;

00:34:10.240 --> 00:34:16.640
has a lot of potential applications here to&nbsp;
make this model stronger. Currently, we're using&nbsp;&nbsp;

00:34:16.640 --> 00:34:25.080
auto-regressive language models. So generative&nbsp;
models and we're having the models rely on their&nbsp;&nbsp;

00:34:25.080 --> 00:34:31.240
pre-trained knowledge, anything it knows about,&nbsp;
the context or the specifics about the thing we're&nbsp;&nbsp;

00:34:31.240 --> 00:34:37.760
asking about as well as pulled knowledge. But you&nbsp;
could, for example, let's say you had access to a&nbsp;&nbsp;

00:34:37.760 --> 00:34:45.560
lot of humans; you could have the model generate&nbsp;
four forecasts for an event. It'll just generate&nbsp;&nbsp;

00:34:45.560 --> 00:34:54.160
four different types of forecasts and you can have&nbsp;
a human who's maybe good at forecasting, rate each&nbsp;&nbsp;

00:34:54.160 --> 00:34:59.960
forecast across different criteria, or you can&nbsp;
have even the model do this itself. Then you&nbsp;&nbsp;

00:34:59.960 --> 00:35:07.040
could use some form of reinforcement learning to&nbsp;
reinforce the criteria that was most effective. We&nbsp;&nbsp;

00:35:07.040 --> 00:35:13.080
think that our work is preliminary. And we imagine&nbsp;
that there is going to be a lot of work done in&nbsp;&nbsp;

00:35:13.080 --> 00:35:22.520
this space after, sort of, the release of our&nbsp;
work. Forecasting is hard, predicting the future&nbsp;&nbsp;

00:35:22.520 --> 00:35:29.720
is a very hard thing to do. So I don't think folks&nbsp;
have been bullish on AI being able to do this. But&nbsp;&nbsp;

00:35:29.720 --> 00:35:36.160
I think giving the advancements and training&nbsp;
algorithms, which you alluded to, and just the&nbsp;&nbsp;

00:35:36.160 --> 00:35:42.827
capabilities and the size of these models, I think&nbsp;
this will become very possible in the near future.

00:35:42.827 --> 00:35:46.520
CRAIG 33:44
Yeah. Can&nbsp;&nbsp;

00:35:46.520 --> 00:35:54.320
you just, at the 40,000-foot&nbsp;
level, give us the architecture?

00:35:54.320 --> 00:35:56.480
DANNY 33:56
Definitely. So I'll&nbsp;&nbsp;

00:35:56.480 --> 00:36:01.480
tell you the architecture at a high level and I'll&nbsp;
tell you at a high level how it was trained since&nbsp;&nbsp;

00:36:01.480 --> 00:36:12.360
I think it's interesting. I sort of was talking&nbsp;
about this earlier but the first step, which is&nbsp;&nbsp;

00:36:12.360 --> 00:36:17.720
really important in judgmental forecasting, is,&nbsp;
What are the different things you would need to&nbsp;&nbsp;

00:36:17.720 --> 00:36:24.360
consider? If you're forecasting an election, it's&nbsp;
one thing to just look at what the polls say. But&nbsp;&nbsp;

00:36:24.360 --> 00:36:29.440
there's a lot of different factors that go into&nbsp;
it, that make an accurate prediction. Maybe you&nbsp;&nbsp;

00:36:29.440 --> 00:36:33.600
want to look at what the campaign finances&nbsp;
are, you want to look at recent scandals,&nbsp;&nbsp;

00:36:33.600 --> 00:36:37.720
you want to look at the state of the economy, what&nbsp;
are different geopolitical events around the world&nbsp;&nbsp;

00:36:37.720 --> 00:36:43.880
and what are these candidates thoughts on it.&nbsp;
So the first step is to get a model to be able&nbsp;&nbsp;

00:36:43.880 --> 00:36:51.840
to really think about which considerations&nbsp;
are important. And this is all generative;&nbsp;&nbsp;

00:36:51.840 --> 00:36:57.080
so you give the question and information&nbsp;
about the question to a model and you say,&nbsp;&nbsp;

00:36:57.760 --> 00:37:02.800
[generate the sub-questions that you have.]&nbsp;
Then you take these sub-questions and you&nbsp;&nbsp;

00:37:02.800 --> 00:37:07.760
just go to some news API like Google News or&nbsp;
NewsCatcher, which I said, and you look up&nbsp;&nbsp;

00:37:07.760 --> 00:37:12.240
articles that hopefully have information about&nbsp;
the sub-questions. Then once you get articles,&nbsp;&nbsp;

00:37:12.240 --> 00:37:19.360
there's going to be some articles that are just&nbsp;
not relevant based off noise in these API's and&nbsp;&nbsp;

00:37:19.360 --> 00:37:23.600
the fact that these search engines are not&nbsp;
perfect. So you really want to get the best&nbsp;&nbsp;

00:37:23.600 --> 00:37:31.400
information. Then you want to condense it into&nbsp;
the context window of a model. This has to be&nbsp;&nbsp;

00:37:31.400 --> 00:37:35.640
done because models have a fixed context&nbsp;
window that you can't see past certainly.

00:37:35.640 --> 00:37:39.280
CRAIG 35:37
So up till that point, is this all automated?

00:37:39.280 --> 00:37:40.269
DANNY 35:42
Yes

00:37:40.269 --> 00:37:40.880
CRAIG 35:43
So you put&nbsp;&nbsp;

00:37:40.880 --> 00:37:50.187
in the question, the model makes the API&nbsp;
call, gets in, and it all comes in? Okay.

00:37:50.187 --> 00:37:52.720
DANNY 35:51
Yeah. So it's completely automated,&nbsp;&nbsp;

00:37:52.720 --> 00:37:58.960
its automated end to end. It takes a question&nbsp;
and every step that I just described is a step&nbsp;&nbsp;

00:37:58.960 --> 00:38:09.400
that it does completely on its own. Then it gets&nbsp;
this large list of summarized articles with each&nbsp;&nbsp;

00:38:09.400 --> 00:38:15.280
article potentially having information about each&nbsp;
sub-question. I think this on its own is a pretty&nbsp;&nbsp;

00:38:15.280 --> 00:38:21.840
interesting tool. You can imagine if a journalist&nbsp;
is doing research on some topic or someone's&nbsp;&nbsp;

00:38:21.840 --> 00:38:31.200
doing a literature review about some research&nbsp;
thing, having this is pretty helpful. So just&nbsp;&nbsp;

00:38:31.200 --> 00:38:36.200
as a sidestep, there's other organizations&nbsp;
like the Forecasting Research Institute,&nbsp;&nbsp;

00:38:36.200 --> 00:38:40.720
which have done some studies on using language&nbsp;
models to actually help human forecasters. They've&nbsp;&nbsp;

00:38:40.720 --> 00:38:48.040
shown that by giving them access to these language&nbsp;
models, forecasters are much more accurate. They&nbsp;&nbsp;

00:38:48.040 --> 00:38:54.840
don't even have to be used in isolation, I guess&nbsp;
is my point. To go back to the architecture; once&nbsp;&nbsp;

00:38:54.840 --> 00:39:01.760
you have all the information, which is obviously&nbsp;
most of the piece of the forecasting problem, you&nbsp;&nbsp;

00:39:01.760 --> 00:39:11.720
have to make considerations about the information&nbsp;
and then finally, a prediction. In our paper,&nbsp;&nbsp;

00:39:11.720 --> 00:39:19.440
we focused on training a language model to make&nbsp;
accurate predictions given information. So the way&nbsp;&nbsp;

00:39:19.440 --> 00:39:26.640
we did this is you take a lot of questions, a lot&nbsp;
of forecasting questions from these platforms and&nbsp;&nbsp;

00:39:26.640 --> 00:39:31.320
you have the language model make predictions for&nbsp;
each one of these questions. For each prediction&nbsp;&nbsp;

00:39:31.320 --> 00:39:37.840
it's going to give you a reasoning, basically the&nbsp;
reasoning will sort of describe its step-by-step&nbsp;&nbsp;

00:39:37.840 --> 00:39:42.120
thinking and then this reasoning will lead to&nbsp;
some final probability. So it's going to be like,&nbsp;&nbsp;

00:39:42.120 --> 00:39:49.520
let's say half a page of text where it gives&nbsp;
sort of a description of what it's thinking&nbsp;&nbsp;

00:39:49.520 --> 00:39:53.000
about. And then at the end of the text, it's&nbsp;
going to have a number indicating what it&nbsp;&nbsp;

00:39:53.000 --> 00:39:57.520
thinks the probability is of the event.&nbsp;
So you do this on a lot of questions,&nbsp;&nbsp;

00:39:57.520 --> 00:40:03.040
then you take the questions where the&nbsp;
model predicted the event accurately,&nbsp;&nbsp;

00:40:03.040 --> 00:40:08.760
and then you go back to the system and you train&nbsp;
it on these predictions because these are the&nbsp;&nbsp;

00:40:08.760 --> 00:40:11.880
accurate ones. So you basically go back to it and&nbsp;
you say, [These are the accurate ones I want you&nbsp;&nbsp;

00:40:11.880 --> 00:40:16.280
to learn to do, I want you to learn to do this&nbsp;
more often.] And you can just keep repeating&nbsp;&nbsp;

00:40:16.280 --> 00:40:21.080
this process. So if you had access to a lot of&nbsp;
compute, which we didn't, and a lot of data,&nbsp;&nbsp;

00:40:21.080 --> 00:40:27.320
you can imagine just doing this repeatedly and&nbsp;
getting something that's very, very strong.

00:40:27.320 --> 00:40:34.240
CRAIG 38:31
Okay. So it spits out at the end,&nbsp;&nbsp;

00:40:34.240 --> 00:40:52.560
a probability. Then you go back and if you're&nbsp;
doing this with a cut-off date of- February 29&nbsp;&nbsp;

00:40:53.280 --> 00:41:05.040
and the event resolves on the first of March,&nbsp;
you could run the prediction on the model based&nbsp;&nbsp;

00:41:05.040 --> 00:41:12.800
on information up until February 29, have a&nbsp;
prediction, and then see on the first whether&nbsp;&nbsp;

00:41:12.800 --> 00:41:25.200
or not that prediction was accurate. You were&nbsp;
saying earlier, I think 71% compared to the&nbsp;&nbsp;

00:41:25.200 --> 00:41:34.667
prediction market’s 77%, where have you gotten and&nbsp;
with the level of compute that you have available?

00:41:34.667 --> 00:41:35.640
DANNY 39:37
Yeah. What you&nbsp;&nbsp;

00:41:35.640 --> 00:41:43.520
described is I think a really good summary of our&nbsp;
process. We wait till the question resolves and if&nbsp;&nbsp;

00:41:43.520 --> 00:41:52.960
the model made an accurate prediction, which&nbsp;
basically means it gave a reasoning that was&nbsp;&nbsp;

00:41:52.960 --> 00:41:58.200
effective at predicting the event, we collect&nbsp;
this reasoning and then we train the model on&nbsp;&nbsp;

00:41:58.200 --> 00:42:05.320
these reasonings because we found them to be&nbsp;
effective for making correct predictions. As&nbsp;&nbsp;

00:42:05.320 --> 00:42:11.920
far as where our performance stands; one thing I&nbsp;
will say about our system that I haven't said yet&nbsp;&nbsp;

00:42:11.920 --> 00:42:18.920
is that it's very good at forecasting events that&nbsp;
are more uncertain. We found that it's actually&nbsp;&nbsp;

00:42:18.920 --> 00:42:27.280
better than the prediction market. So if you take&nbsp;
questions where the prediction markets put the&nbsp;&nbsp;

00:42:27.280 --> 00:42:34.260
probability between .3 and .7, somewhere in&nbsp;
that interval, it could be .4, it could be .6,&nbsp;&nbsp;

00:42:34.260 --> 00:42:38.880
5, but somewhere in the interval, .3 and&nbsp;
.7; if you just look at those questions,&nbsp;&nbsp;

00:42:38.880 --> 00:42:47.160
our system forecasts them at a level better&nbsp;
than the crowd aggregate. The reason why this is&nbsp;&nbsp;

00:42:47.160 --> 00:42:57.240
probably happening is because– so the model that&nbsp;
we train, which is GPT-4, was trained using our&nbsp;&nbsp;

00:42:57.240 --> 00:43:06.280
RLHF, which basically made it so that it doesn't&nbsp;
output predictions that are extremely confident.&nbsp;&nbsp;

00:43:06.280 --> 00:43:13.400
So the model is hedging, even when the evidence&nbsp;
is extremely clear. So let's say the crowd puts a&nbsp;&nbsp;

00:43:13.400 --> 00:43:20.800
probability of it raining tomorrow at 95%, I don't&nbsp;
know; the model won't want to tell you 95% or 96%&nbsp;&nbsp;

00:43:20.800 --> 00:43:25.160
because it doesn't want to give you probabilities&nbsp;
that are extremely certain because it doesn't want&nbsp;&nbsp;

00:43:25.160 --> 00:43:31.040
to be wrong and then be punished, punished&nbsp;
for that or something. But for these events,&nbsp;&nbsp;

00:43:31.040 --> 00:43:36.160
where the probability is more uncertain between&nbsp;
.3 and .7, you just look at these questions,&nbsp;&nbsp;

00:43:36.160 --> 00:43:42.840
our accuracy is better than better than the&nbsp;
crowd accuracy. Then on all the questions,&nbsp;&nbsp;

00:43:42.840 --> 00:43:51.640
yeah, we got 71%. The overall performance&nbsp;
is 77%. That gap is certainly smaller than&nbsp;&nbsp;

00:43:51.640 --> 00:44:00.200
the previous gap of 65% versus 92% but I think&nbsp;
there's still some ways to go. I think getting&nbsp;&nbsp;

00:44:00.200 --> 00:44:05.480
to the point that we did is easier than getting&nbsp;
to the next point which is at the level of human&nbsp;&nbsp;

00:44:05.480 --> 00:44:09.800
forecasters or even better. I think this&nbsp;
is going to be increasingly challenging&nbsp;&nbsp;

00:44:09.800 --> 00:44:15.587
and it's going to require better information,&nbsp;
more compute, and potentially better models.

00:44:15.587 --> 00:44:17.040
CRAIG 42:17
Yeah. And just on that,&nbsp;&nbsp;

00:44:17.040 --> 00:44:22.520
on doing better on highly uncertain questions,&nbsp;&nbsp;

00:44:22.520 --> 00:44:30.627
that could also just reflect how poor the&nbsp;
human forecasters are on those questions right?

00:44:30.627 --> 00:44:31.520
DANNY 42:31
That's true.

00:44:31.520 --> 00:44:42.440
CRAIG 42:34
I mean, because I don't know what the percentage&nbsp;&nbsp;

00:44:42.440 --> 00:44:50.669
accuracy you would have on that kind of a question&nbsp;
but if the crowd was between– what did you say?

00:44:50.669 --> 00:44:52.229
DANNY 42:52
.3 and .7

00:44:52.229 --> 00:44:54.440
CRAIG 42:54
.3 and .7 and the&nbsp;&nbsp;

00:44:54.440 --> 00:45:03.480
model beats the crowd and it's .4, youre still&nbsp;
a long way from having a useful prediction.

00:45:03.480 --> 00:45:06.000
DANNY 43:05
That is true. I&nbsp;&nbsp;

00:45:06.000 --> 00:45:12.360
think that's a fair point. I would say that&nbsp;
my intuition is that it's not necessarily&nbsp;&nbsp;

00:45:12.360 --> 00:45:18.760
the case that the crowd is not as good at&nbsp;
forecasting these questions; I think these&nbsp;&nbsp;

00:45:18.760 --> 00:45:24.320
are just questions with higher uncertainty. So&nbsp;
if you're trying to predict the last Super Bowl,&nbsp;&nbsp;

00:45:24.320 --> 00:45:29.280
it's going to be somewhere within that interval.&nbsp;
You're not going to say, 49ers- 95%. This would be&nbsp;&nbsp;

00:45:29.280 --> 00:45:39.320
a bad prediction. But it is to say that with&nbsp;
these marginal differences in probability,&nbsp;&nbsp;

00:45:39.320 --> 00:45:43.920
our system is reporting something that is a bit&nbsp;
more accurate, on average, since we're considering&nbsp;&nbsp;

00:45:43.920 --> 00:45:50.507
over 1000 questions and over 3000 forecasts,&nbsp;
etc. So it's not purely just noise I would say.

00:45:50.507 --> 00:45:56.920
CRAIG 43:52
Yeah. Let me ask you something about just standard&nbsp;&nbsp;

00:45:58.320 --> 00:46:04.200
supervised learning, which now&nbsp;
sounds like old-fashioned AI.

00:46:04.200 --> 00:46:06.349
DANNY 44:06
Yeah.

00:46:06.349 --> 00:46:07.320
CRAIG 43:52
A couple of years&nbsp;&nbsp;

00:46:07.320 --> 00:46:20.520
ago I got to know a no-code company called&nbsp;
Akio, who I'm a great fan of. You can load&nbsp;&nbsp;

00:46:20.520 --> 00:46:30.920
in your data- at that time, now they work&nbsp;
with less structured data, but, you know,&nbsp;&nbsp;

00:46:30.920 --> 00:46:43.920
your tabular data. I used it as an experiment&nbsp;
for an article I wrote on horse racing. What&nbsp;&nbsp;

00:46:43.920 --> 00:46:56.920
they were focused on was sorting lead generation&nbsp;
leads for sales teams. So you have 10,000 leads,&nbsp;&nbsp;

00:46:56.920 --> 00:47:02.200
you don't know where to spend your time, you&nbsp;
can't call 10,000 people; so you train the&nbsp;&nbsp;

00:47:02.200 --> 00:47:12.520
model based on past leads and as many columns of&nbsp;
attributes, or I guess you got on parameters, as&nbsp;&nbsp;

00:47:12.520 --> 00:47:26.840
you can find on each lead for which you know the&nbsp;
ultimate outcome. Then the model learns to predict&nbsp;&nbsp;

00:47:28.040 --> 00:47:34.080
relatively accurately which leads are likely to&nbsp;
convert to sales. Then when you get a bunch of&nbsp;&nbsp;

00:47:34.080 --> 00:47:40.040
new leads in, you put it through the system, it&nbsp;
ranks them according to their probability. So I&nbsp;&nbsp;

00:47:40.040 --> 00:47:49.000
was using horse racing data for which there is&nbsp;
a lot. I can't remember how many columns we had&nbsp;&nbsp;

00:47:49.000 --> 00:47:57.840
but we would we loaded it all in and the last&nbsp;
column is– first of all, we trained it on past&nbsp;&nbsp;

00:47:57.840 --> 00:48:12.120
races. Then we loaded all these columns in with–&nbsp;
it was a classification algorithm; is this gonna&nbsp;&nbsp;

00:48:12.120 --> 00:48:21.640
win or not win, this horse? Then you would rank&nbsp;
the probabilities and it did an excellent job of&nbsp;&nbsp;

00:48:21.640 --> 00:48:34.520
predicting race time odds. We would do this&nbsp;
a day before. That was pretty amazing. Every&nbsp;&nbsp;

00:48:34.520 --> 00:48:47.080
now and then it would predict a win for a long&nbsp;
shot. I was betting, I think it was $2 bets,&nbsp;&nbsp;

00:48:47.080 --> 00:48:57.840
on the top– I can't remember how I sorted, but to&nbsp;
see how I did and I did pretty well; except that&nbsp;&nbsp;

00:48:57.840 --> 00:49:06.080
if you're betting on the favorites, the favorites&nbsp;
aren't always going to win so over time you lose&nbsp;&nbsp;

00:49:06.080 --> 00:49:14.080
money. But if you bet only on the long shots,&nbsp;
because they paid so much more, you don't have&nbsp;&nbsp;

00:49:14.080 --> 00:49:20.040
to hit many of those correctly to make money.&nbsp;
Then I lost my data source; I've always wanted&nbsp;&nbsp;

00:49:20.040 --> 00:49:28.667
to go back to it. But something like that could&nbsp;
be another data point for your system, right?

00:49:28.667 --> 00:49:29.280
DANNY 47:31
Definitely. I&nbsp;&nbsp;

00:49:29.280 --> 00:49:36.160
think what you're alluding to is that there is&nbsp;
so many different places in life where there's&nbsp;&nbsp;

00:49:36.160 --> 00:49:42.160
prediction involved. This means that there is&nbsp;
so much data. Let's just take horse racing;&nbsp;&nbsp;

00:49:42.160 --> 00:49:46.000
this could have been part of the thing we&nbsp;
trained our model to do. And you can imagine&nbsp;&nbsp;

00:49:46.000 --> 00:49:50.280
that if you get really good at predicting horse&nbsp;
racing, that probably gives you some skill on&nbsp;&nbsp;

00:49:50.280 --> 00:49:58.680
predicting other sports events. Another use case&nbsp;
that’s sort of similar to what you just said is,&nbsp;&nbsp;

00:49:58.680 --> 00:50:05.520
imagine you take every company that ever tried&nbsp;
to launch some product and you take the ones&nbsp;&nbsp;

00:50:05.520 --> 00:50:09.400
that failed and the one that succeeded and you&nbsp;
train the model to classify whether it's going&nbsp;&nbsp;

00:50:09.400 --> 00:50:13.600
to succeed or fail based on like every single&nbsp;
company that has ever tried to go public or do&nbsp;&nbsp;

00:50:13.600 --> 00:50:19.280
something. And you could try asking the model&nbsp;
about a new idea with your business plan and&nbsp;&nbsp;

00:50:19.280 --> 00:50:24.560
seeing what it thinks the probability of success&nbsp;
is. This is just another way to teach the model&nbsp;&nbsp;

00:50:24.560 --> 00:50:28.880
how to forecast this type of event which I&nbsp;
imagine would allow it to gain skills that&nbsp;&nbsp;

00:50:28.880 --> 00:50:36.280
are useful for other types of forecasting. This&nbsp;
is why I think that using AI and language models&nbsp;&nbsp;

00:50:36.280 --> 00:50:44.560
in particular to learn how to forecast is– we're&nbsp;
in a current position to do this in a way that we&nbsp;&nbsp;

00:50:44.560 --> 00:50:49.320
haven't been able to previously with the amount of&nbsp;
data and compute available. I think could really&nbsp;&nbsp;

00:50:49.320 --> 00:50:56.640
revolutionize technology and how we humans even&nbsp;
make decisions and assess things across the board.

00:50:56.640 --> 00:51:01.560
CRAIG 49:06
Yeah. So where do you go from&nbsp;&nbsp;

00:51:01.560 --> 00:51:10.600
here? You're over 70% against the forecasting&nbsp;
platforms and superforecasters. Is that right?&nbsp;

00:51:12.960 --> 00:51:18.880
What are you going to do with this? This is a&nbsp;
research project. Are you taking it further,&nbsp;&nbsp;

00:51:18.880 --> 00:51:26.560
marshaling more compute, more data?&nbsp;
Adding reinforcement learning or a&nbsp;&nbsp;

00:51:27.160 --> 00:51:35.387
supervised learning classifier is another&nbsp;
data point. What's the next step for you guys?

00:51:35.387 --> 00:51:38.480
DANNY 49:44
Yeah. So my prediction&nbsp;&nbsp;

00:51:38.480 --> 00:51:46.120
is that some large company, maybe OpenAI is– I'm&nbsp;
actually already familiar with a large company&nbsp;&nbsp;

00:51:46.120 --> 00:51:52.800
that has contacted me that is really interested in&nbsp;
this work and want to put a lot of resources into&nbsp;&nbsp;

00:51:52.800 --> 00:52:00.160
it. So I think there is going to be at least one&nbsp;
large company or organization that tries to push&nbsp;&nbsp;

00:52:00.160 --> 00:52:10.800
this to the superhuman level. I think my main&nbsp;
hope is that this technology happens. I think&nbsp;&nbsp;

00:52:10.800 --> 00:52:17.560
it has a positive consequence for the future.&nbsp;
If I didn't think that other people were going&nbsp;&nbsp;

00:52:17.560 --> 00:52:26.107
to work on this I would probably do it myself.&nbsp;
That's where I think this project is headed.

00:52:26.107 --> 00:52:29.800
CRAIG 50:35
Yeah. And how&nbsp;&nbsp;

00:52:30.360 --> 00:52:38.800
these predictions could be used, if you had&nbsp;
a high degree of accuracy in predictions&nbsp;&nbsp;

00:52:38.800 --> 00:52:48.267
you could modify behavior and there could&nbsp;
be sort of a self-reinforcing loop there.

00:52:48.267 --> 00:52:49.520
DANNY 50:58
Exactly. I think&nbsp;&nbsp;

00:52:49.520 --> 00:52:53.320
there's some equilibrium that you'll find&nbsp;
once everyone has perfect information.

