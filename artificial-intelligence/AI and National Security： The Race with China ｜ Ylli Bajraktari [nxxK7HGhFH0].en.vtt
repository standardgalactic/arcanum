WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.400
Ylli: 0:00.
In terms of US versus China,&nbsp;&nbsp;

00:00:02.400 --> 00:00:08.640
did they have a centrally pushed policy to invest&nbsp;
and get ahead in AI? Yes, they did. It's a public&nbsp;&nbsp;

00:00:08.640 --> 00:00:12.680
strategy that they had. Where they're organized&nbsp;
for that competition. Yes, they were just because&nbsp;&nbsp;

00:00:12.680 --> 00:00:17.400
they have a different political system. They can&nbsp;
drive their private sector in this competition&nbsp;&nbsp;

00:00:17.400 --> 00:00:22.160
because there's a similar fusion that they have.&nbsp;
Did they put enormous resources behind this? They&nbsp;&nbsp;

00:00:22.160 --> 00:00:28.680
did. Did they appoint national AI champions to&nbsp;
serve as the companies that will propagate and&nbsp;&nbsp;

00:00:28.680 --> 00:00:35.840
advance the CCP agenda globally? Yes, they did. We&nbsp;
all know that, and so I think in some aspects, the&nbsp;&nbsp;

00:00:35.840 --> 00:00:41.680
pre GenAI period, they were moving fast. We have&nbsp;
to get ourselves organized, we have to finance&nbsp;&nbsp;

00:00:41.680 --> 00:00:46.949
ourselves, put enough resources. I think CHIPS Act&nbsp;
is one of the elements I think towards that end.

00:00:46.949 --> 00:00:48.880
Craig: 0:46
Hi, my name is Craig Smith,&nbsp;&nbsp;

00:00:48.880 --> 00:00:56.000
and this is Eye on AI. In this episode, I sit down&nbsp;
with Ylli Bajraktari, executive Director of the&nbsp;&nbsp;

00:00:56.000 --> 00:01:02.800
Special Competitive Studies Project, which is a&nbsp;
follow-on organization to the National Security&nbsp;&nbsp;

00:01:02.800 --> 00:01:12.000
Commission on AI focused on maintaining the US&nbsp;
lead in AI. Ylli provides invaluable insights&nbsp;&nbsp;

00:01:12.000 --> 00:01:19.040
into the current state of the AI race between the&nbsp;
US and China, discussing the implications of the&nbsp;&nbsp;

00:01:19.040 --> 00:01:27.800
latest advancements in generative AI. He also&nbsp;
sheds light on the so-called Offset-X strategy,&nbsp;&nbsp;

00:01:27.800 --> 00:01:35.000
the National Plan for Microelectronics and the&nbsp;
upcoming Special Competitive Studies Project AI&nbsp;&nbsp;

00:01:35.000 --> 00:01:43.320
Expo in Washington DC in May. Join us for an&nbsp;
in-depth look at the critical role AI plays&nbsp;&nbsp;

00:01:43.320 --> 00:01:51.709
in shaping our national security. I hope you&nbsp;
find the conversation as important as I did.

00:01:51.709 --> 00:01:53.600
Craig: 1:52
Hi, good tech solves&nbsp;&nbsp;

00:01:53.600 --> 00:01:59.360
problems that you've thought about. Great tech&nbsp;
solves problems that you haven't even thought of.&nbsp;&nbsp;

00:01:59.360 --> 00:02:05.640
What can the commerce platform trusted by millions&nbsp;
of merchants do for you? It's time for Shopify,&nbsp;&nbsp;

00:02:05.640 --> 00:02:11.840
the commerce platform revolutionizing millions&nbsp;
of businesses worldwide. Whether you're a garage&nbsp;&nbsp;

00:02:11.840 --> 00:02:18.960
entrepreneur or IPO ready, Shopify is the only&nbsp;
tool you need to start, run, and grow your&nbsp;&nbsp;

00:02:18.960 --> 00:02:24.720
business without the struggle. Shopify puts&nbsp;
you in control of every sales channel. So,&nbsp;&nbsp;

00:02:24.720 --> 00:02:31.160
whether you're selling satin sheets from Shopify's&nbsp;
in-person point of sale system or offering organic&nbsp;&nbsp;

00:02:31.160 --> 00:02:38.760
olive oil on Shopify's all-in-one e-commerce&nbsp;
platform, you're covered. Shopify powers 10% of&nbsp;&nbsp;

00:02:38.760 --> 00:02:47.200
all e-commerce in the United States and Shopify's&nbsp;
truly a global force, powering Allbirds, Rothy's,&nbsp;&nbsp;

00:02:47.200 --> 00:02:55.040
and Brooklyn and millions of other entrepreneurs&nbsp;
of every size across over 170 countries. Plus,&nbsp;&nbsp;

00:02:55.040 --> 00:03:02.269
Shopify's award-winning help is there to&nbsp;
support your success every step of the way.

00:03:02.269 --> 00:03:04.560
Craig: 3:02
Sign up for a $1 per&nbsp;&nbsp;

00:03:04.560 --> 00:03:17.480
month trial period at shopify.com/eyeonai, that's&nbsp;
shopify S-H-O-P-I-F-Y dot com slash eye on ai,&nbsp;&nbsp;

00:03:17.480 --> 00:03:26.160
that's E-Y-E-O-N-A-I all run together.&nbsp;
So, sign up for a $1 a month trial period&nbsp;&nbsp;

00:03:26.160 --> 00:03:37.200
at shopify.com/eyeonai, that's shopify&nbsp;
S-H-O-P-I-F-Y dot com slash eye on ai,&nbsp;&nbsp;

00:03:37.200 --> 00:03:46.309
that's E-Y-E-O-N-A-I all lowercase, all run&nbsp;
together. They support us, so let's support them.

00:03:46.309 --> 00:03:47.440
Craig: 3:06
I'm here at the special&nbsp;&nbsp;

00:03:47.440 --> 00:03:54.840
competitive studies project with Ylli Bajraktari.&nbsp;
It's a follow-on organization from the National&nbsp;&nbsp;

00:03:54.840 --> 00:04:04.560
Security Commission on AI, which Ylli was also the&nbsp;
executive director of. Ylli, maybe we can start&nbsp;&nbsp;

00:04:04.560 --> 00:04:13.840
just by explaining the project, how it originated,&nbsp;
I know the story of the Rockefeller project with&nbsp;&nbsp;

00:04:13.840 --> 00:04:18.539
Kissinger, but if you could give that and then&nbsp;
we'll start talking about what you guys do.

00:04:18.539 --> 00:04:20.520
Ylli: 4:18
Absolutely and thanks for hosting us on&nbsp;&nbsp;

00:04:20.520 --> 00:04:26.280
your podcast. I mean, as I've told you many, many&nbsp;
times, we are big fans of your podcast. I mean,&nbsp;&nbsp;

00:04:26.280 --> 00:04:32.040
you're one of the first supporters of our work&nbsp;
with NSCAI and we had an amazing series with you,&nbsp;&nbsp;

00:04:32.040 --> 00:04:36.280
so truly appreciate it. And it's a unique&nbsp;
podcast, just so you know, as I told you before,&nbsp;&nbsp;

00:04:36.280 --> 00:04:40.880
because it's more specialized about AI and&nbsp;
you have incredible guests. So it's an honor&nbsp;&nbsp;

00:04:40.880 --> 00:04:47.840
to be on your show. The origins of the Special&nbsp;
Competitive Studies Project, or the SCSP, really&nbsp;&nbsp;

00:04:47.840 --> 00:04:54.640
go back towards the end of the commissions work.&nbsp;
At that point Eric was writing a book with Dr.&nbsp;&nbsp;

00:04:54.640 --> 00:05:00.680
Kissinger on the age of AI and Dr. Kissinger spoke&nbsp;
fondly about a project he led in the 50s called&nbsp;&nbsp;

00:05:00.680 --> 00:05:07.960
Special Studies Project. I didn't know much about&nbsp;
the Special Studies Project. It's you know 1950s,&nbsp;&nbsp;

00:05:07.960 --> 00:05:13.640
not much you can find online. But, as you noted,&nbsp;
Rockefeller Brothers Fund back in the 50s thought&nbsp;&nbsp;

00:05:13.640 --> 00:05:18.680
that we are at the turning point in the history&nbsp;
in which you know we're facing a competitor in&nbsp;&nbsp;

00:05:18.680 --> 00:05:23.840
Soviet Union. Obviously, the word competition&nbsp;
and competitor was not used back in the 50s,&nbsp;&nbsp;

00:05:23.840 --> 00:05:32.080
more like adversary and so they thought that we&nbsp;
still have not created a framework or a vision for&nbsp;&nbsp;

00:05:32.080 --> 00:05:36.440
how we should address that competition. I mean,&nbsp;
and this was a battle of systems when you look at,&nbsp;&nbsp;

00:05:36.440 --> 00:05:41.600
in the 50s, it was a communist system versus a&nbsp;
democratic system, and I think the outcome was&nbsp;&nbsp;

00:05:41.600 --> 00:05:45.400
still unpredictable. Who's going to win at that&nbsp;
point? So I think Rockefeller Brothers Fund funded&nbsp;&nbsp;

00:05:45.400 --> 00:05:50.760
a project that Dr. Kissinger led called Special&nbsp;
Studies Project, and over the course of three&nbsp;&nbsp;

00:05:50.760 --> 00:05:55.960
years they brought some of the most thoughtful&nbsp;
leaders we had in the 50s from private sector,&nbsp;&nbsp;

00:05:55.960 --> 00:06:00.560
academia, and government to think about&nbsp;
how do we get ourselves organized first,&nbsp;&nbsp;

00:06:00.560 --> 00:06:05.880
how do we get our society organized, how do we&nbsp;
build our military to face such a competitor,&nbsp;&nbsp;

00:06:05.880 --> 00:06:10.200
and then, how do we bring our allies and partners&nbsp;
around the world to believe in the system values&nbsp;&nbsp;

00:06:10.200 --> 00:06:15.960
that we were projecting versus what the Soviet&nbsp;
Union was projecting. And so, Dr. Kissinger&nbsp;&nbsp;

00:06:16.720 --> 00:06:25.160
late Dr. Kissinger now, in the summer of 2021,&nbsp;
talked to Eric about relaunching that initiative.

00:06:25.160 --> 00:06:26.400
Ylli: 6:25
I had initial conversation&nbsp;&nbsp;

00:06:26.400 --> 00:06:36.280
with Eric about this and when you think about it&nbsp;
in 2021, same with the establishing of NSCAI we&nbsp;&nbsp;

00:06:36.280 --> 00:06:41.920
were really at the crossroad of the beginning&nbsp;
of this AI revolution, but also a changing&nbsp;&nbsp;

00:06:41.920 --> 00:06:49.480
geopolitical world order. And so I thought we&nbsp;
were positioned in a really unique place to&nbsp;&nbsp;

00:06:49.480 --> 00:06:56.320
create a Special Competitive Studies Project. I&nbsp;
added competitive in the title because I called&nbsp;&nbsp;

00:06:57.720 --> 00:07:03.240
my old boss and mentor, Bob Work and I said, hey,&nbsp;
I'm thinking about launching this project. Eric is&nbsp;&nbsp;

00:07:03.240 --> 00:07:08.470
really interested. Would you join? First&nbsp;
of all, what do think about the project?

00:07:08.470 --> 00:07:09.160
Ylli: 7:08
And he said you've got&nbsp;&nbsp;

00:07:09.160 --> 00:07:14.080
to add competition in the title because we're in&nbsp;
competition with China, and in competition with&nbsp;&nbsp;

00:07:14.080 --> 00:07:18.880
China, you either win or lose, and you're familiar&nbsp;
with Bob Work. You hosted him numerous times on&nbsp;&nbsp;

00:07:18.880 --> 00:07:23.920
your show. He's a really thoughtful leader when&nbsp;
it comes to grand strategy, China competition,&nbsp;&nbsp;

00:07:23.920 --> 00:07:30.360
and AI. And so obviously I listened to him, and&nbsp;
we added C in our title to make it a little bit&nbsp;&nbsp;

00:07:30.360 --> 00:07:35.600
different from the project in the 50s. And&nbsp;
so, with that in mind, we created SCSP.

00:07:35.600 --> 00:07:36.920
Ylli: 7:41
Initially,&nbsp;&nbsp;

00:07:36.920 --> 00:07:41.920
the conversations with Eric were that&nbsp;
we were focused on a three-year project,&nbsp;&nbsp;

00:07:41.920 --> 00:07:49.240
just because in my mind and I think in Eric's&nbsp;
mind, is, if we are here in March of 25, 26,&nbsp;&nbsp;

00:07:49.240 --> 00:07:54.550
and we're still talking about the same topics that&nbsp;
you and I have talked many times on your podcast.

00:07:54.550 --> 00:07:58.240
Ylli: 7:54
I think we might be risking of falling&nbsp;&nbsp;

00:07:58.240 --> 00:08:05.920
behind China. Now, you see also a convergence of&nbsp;
what we call the axes of disruptors China, Russia,&nbsp;&nbsp;

00:08:05.920 --> 00:08:12.960
Iran, and North Korea against the democratic&nbsp;
block, and I think the challenge in 25, 20,&nbsp;&nbsp;

00:08:12.960 --> 00:08:20.000
30 timeframe is much, much higher of a&nbsp;
conflict that could come between these&nbsp;&nbsp;

00:08:20.000 --> 00:08:25.240
two systems of thoughts, of political systems,&nbsp;
and beliefs, and so I think SCSP could play a&nbsp;&nbsp;

00:08:25.240 --> 00:08:30.240
vital role there in terms of, like, how do we&nbsp;
get ourself organized, how do we, you know,&nbsp;&nbsp;

00:08:30.240 --> 00:08:36.520
increase awareness of what's going on and play a&nbsp;
role like they did in the 50s, in which, you know,&nbsp;&nbsp;

00:08:36.520 --> 00:08:41.280
when they published their book, which sold&nbsp;
400,000 copies and it's really difficult to&nbsp;&nbsp;

00:08:41.280 --> 00:08:48.360
find it called Prospect for America, you know&nbsp;
they educated and informed American citizens,&nbsp;&nbsp;

00:08:48.360 --> 00:08:54.120
obviously, of what we were facing against in&nbsp;
terms of Soviet Union challenge, and I think&nbsp;&nbsp;

00:08:54.120 --> 00:08:59.800
that then got ourselves organized from the 50s&nbsp;
to the end of the Cold War, where we ultimately&nbsp;&nbsp;

00:08:59.800 --> 00:09:06.229
won. And so that's sort of like the origins of&nbsp;
SCSP Greg, but happy to answer any questions.

00:09:06.229 --> 00:09:07.400
Craig: 9:08
Yeah, and you’ve&nbsp;&nbsp;

00:09:07.400 --> 00:09:16.000
come out with a series of reports, and my&nbsp;
understanding is your audience is really the&nbsp;&nbsp;

00:09:16.000 --> 00:09:21.440
legislative branch and the executive branch,&nbsp;
right? You’re trying to influence policy,&nbsp;&nbsp;

00:09:21.440 --> 00:09:31.280
and I know shortly after the end of the National&nbsp;
Security Commission there was the CHIPS Act,&nbsp;&nbsp;

00:09:31.280 --> 00:09:37.200
which I don't know the inner workings,&nbsp;
but it sounded like it came right out of&nbsp;&nbsp;

00:09:37.200 --> 00:09:44.790
the NSCAI's final report. So, can you talk&nbsp;
about how that pipeline gets implemented?

00:09:44.790 --> 00:09:45.920
Ylli: 9:44
Yeah. So, first of all,&nbsp;&nbsp;

00:09:46.560 --> 00:09:53.360
let me talk about the NSCI. When you go back in&nbsp;
2018, when I think the legislation got passed for&nbsp;&nbsp;

00:09:53.360 --> 00:10:01.240
the creation of NSCI, I think you know, in 2018,&nbsp;
the issue of AI and the geopolitical competition&nbsp;&nbsp;

00:10:01.240 --> 00:10:08.680
was not on everyone's mind probably, um, and&nbsp;
so I think what I give congress credit to is,&nbsp;&nbsp;

00:10:08.680 --> 00:10:13.440
um, they were getting signals a, from&nbsp;
private sector, that there's a powerful&nbsp;&nbsp;

00:10:13.440 --> 00:10:18.520
technology coming that you have covered for such&nbsp;
a long time, and that, b China, our competitor,&nbsp;&nbsp;

00:10:18.520 --> 00:10:24.920
our main competitor uh, really is putting all&nbsp;
the resources, all sort of like the energy,&nbsp;&nbsp;

00:10:24.920 --> 00:10:29.600
behind this technology, because at that time,&nbsp;
they came up with this strategy that they&nbsp;&nbsp;

00:10:29.600 --> 00:10:34.200
wanted to be the global AI power by 2030. And&nbsp;
so, I think, with these two factors in mind,&nbsp;&nbsp;

00:10:34.200 --> 00:10:40.560
congress created the commission. I also think it's&nbsp;
the first time that, in absence of our federal&nbsp;&nbsp;

00:10:40.560 --> 00:10:47.320
government having a clear strategy on a specific&nbsp;
technology, congress stepped in to fill that void,&nbsp;&nbsp;

00:10:47.320 --> 00:10:53.080
and I think they do this with commissions, as&nbsp;
you know, occasionally and so I think we stepped&nbsp;&nbsp;

00:10:53.080 --> 00:10:59.240
into a space in which was number one, highly&nbsp;
bipartisan. You know the CHIPS Act, but like,&nbsp;&nbsp;

00:10:59.760 --> 00:11:05.360
when you put technology competition in China,&nbsp;
there's a huge bipartisan support in Congress&nbsp;&nbsp;

00:11:05.360 --> 00:11:11.920
because I think there's a wide recognition that&nbsp;
failure to, uh, stay behind in this technology&nbsp;&nbsp;

00:11:11.920 --> 00:11:16.400
could have consequential impact for our&nbsp;
society and our economy and ultimately,&nbsp;&nbsp;

00:11:16.400 --> 00:11:23.720
national security, and so I think the NSCI really&nbsp;
moved into that space. We were lucky and fortunate&nbsp;&nbsp;

00:11:23.720 --> 00:11:30.920
that Congress appointed 15 individuals with&nbsp;
a huge difference in their background. That,&nbsp;&nbsp;

00:11:30.920 --> 00:11:36.880
I think, benefited us as a staff at that point,&nbsp;
but also when we were going around departments and&nbsp;&nbsp;

00:11:36.880 --> 00:11:43.360
agencies and looking at what they were doing with&nbsp;
AI and what do they need to do more. I think these&nbsp;&nbsp;

00:11:43.360 --> 00:11:48.640
individuals really stepped forward to serve the&nbsp;
country. I don't think that gets much credited in&nbsp;&nbsp;

00:11:48.640 --> 00:11:53.280
today's environment, to be honest with you, but&nbsp;
having some of the top technology leaders, some&nbsp;&nbsp;

00:11:53.280 --> 00:11:58.040
of the top academic leaders and some of the top&nbsp;
former government officials looking at what can&nbsp;&nbsp;

00:11:58.040 --> 00:12:04.189
we do more for our country in this competition,&nbsp;
I think that would deserve much bigger praise.

00:12:04.189 --> 00:12:05.840
Ylli: 12:06
In terms of the audience&nbsp;&nbsp;

00:12:05.840 --> 00:12:11.640
our job with NSCI was pretty straightforward.&nbsp;
We had to provide Congress with recommendations&nbsp;&nbsp;

00:12:11.640 --> 00:12:15.680
on how do we maintain global AI leadership&nbsp;
for national security purposes and I'd like&nbsp;&nbsp;

00:12:15.680 --> 00:12:21.760
to underscore the national security piece here&nbsp;
because the commission was not. What can we do&nbsp;&nbsp;

00:12:21.760 --> 00:12:26.960
with AI in terms of our education and our society&nbsp;
and our healthcare. You know, the commission was&nbsp;&nbsp;

00:12:26.960 --> 00:12:31.360
tasked by the armed services community on&nbsp;
the Hill, so the number one customer were&nbsp;&nbsp;

00:12:31.360 --> 00:12:37.149
the armed services agencies and the intelligence&nbsp;
community, and so we had a really narrow focus.

00:12:37.149 --> 00:12:38.120
Ylli: 12:37
What we tried to do with&nbsp;&nbsp;

00:12:38.120 --> 00:12:45.160
SCSP from the beginning, Craig, is that we take&nbsp;
more of a whole of nation approach, and so we have&nbsp;&nbsp;

00:12:45.160 --> 00:12:50.680
a team that is focused on the economic impact of&nbsp;
AI. We have a team that is focused on, you know,&nbsp;&nbsp;

00:12:50.680 --> 00:12:56.600
what are the next generation of technologies that&nbsp;
we have to stay ahead. We cover the impact on&nbsp;&nbsp;

00:12:56.600 --> 00:13:04.080
education, impact on workforce, some of the topics&nbsp;
that were not included during the NSCI work,&nbsp;&nbsp;

00:13:04.080 --> 00:13:12.840
in terms of audience. You're right, obviously,&nbsp;
Congress is a major piece of who we try to inform.

00:13:12.840 --> 00:13:14.360
Ylli: 13:13
We also work with all&nbsp;&nbsp;

00:13:14.360 --> 00:13:20.960
the departments and agencies in Washington and,&nbsp;
more broadly, with governors and state levels and&nbsp;&nbsp;

00:13:20.960 --> 00:13:25.640
anybody else, because, as I said, we try to take&nbsp;
a different approach with SCSP, like more of a&nbsp;&nbsp;

00:13:25.640 --> 00:13:31.840
whole of nation. If you and I believe that AI is a&nbsp;
transformative technology or once in a generation&nbsp;&nbsp;

00:13:31.840 --> 00:13:37.680
technology, then I think this is more than just&nbsp;
a national security challenge or opportunity we&nbsp;&nbsp;

00:13:37.680 --> 00:13:45.160
have. We have to take a more of a holistic, whole&nbsp;
of nation transformation approach to this. And so,&nbsp;&nbsp;

00:13:45.160 --> 00:13:49.080
with SCSP, we take more of that approach. We&nbsp;
spend a lot of time, you know, at the state,&nbsp;&nbsp;

00:13:49.080 --> 00:13:55.240
local level. We spend much more time with allies&nbsp;
and partners. And so we try to like, we try to&nbsp;&nbsp;

00:13:55.240 --> 00:13:59.800
analyze, like, what are some of the implications&nbsp;
and what are some of the huge opportunities AI&nbsp;&nbsp;

00:13:59.800 --> 00:14:05.268
will have for across, you know, domains from&nbsp;
economy and society and national security.

00:14:05.268 --> 00:14:07.120
Craig: 14:05
Right, let's talk about some&nbsp;&nbsp;

00:14:07.120 --> 00:14:14.240
of the specific reports and recommendations.&nbsp;
You came out with this Offset-X strategy,&nbsp;&nbsp;

00:14:14.240 --> 00:14:23.597
which is sort of a reference to the Third Offset&nbsp;
strategy under Ash Carter, I think it was.

00:14:23.597 --> 00:14:23.621
Ylli: 14:24
And Bob Work.

00:14:23.621 --> 00:14:23.829
Craig: 14:24
What's that?

00:14:23.829 --> 00:14:24.840
Ylli: 14:25
And Bob Work

00:14:24.840 --> 00:14:26.840
Craig: 14:26
I'm sorry. Yeah,&nbsp;&nbsp;

00:14:26.840 --> 00:14:34.440
Bob was kind of the driver and that's as&nbsp;
you just said, you're really focused on&nbsp;&nbsp;

00:14:34.440 --> 00:14:43.960
the competition with China. I'm curious you guys&nbsp;
look at China closely, you track it. There has&nbsp;&nbsp;

00:14:43.960 --> 00:14:53.640
been a debate about how advanced China is. There&nbsp;
was this Australian think tank that came out and&nbsp;&nbsp;

00:14:53.640 --> 00:15:00.000
said China's ahead in, I don't remember 33 of&nbsp;
47 categories or something. I'm sure you know&nbsp;&nbsp;

00:15:00.000 --> 00:15:10.640
Jeffrey Ding at George Washington here in DC. His&nbsp;
argument is that you can't look at those top-line&nbsp;&nbsp;

00:15:10.640 --> 00:15:17.800
numbers. You have to look at, you know, which&nbsp;
are patents and papers and funding. You have&nbsp;&nbsp;

00:15:17.800 --> 00:15:24.560
to look at the diffusion, as he calls it, of&nbsp;
AI into the economy and that if you look at,&nbsp;&nbsp;

00:15:24.560 --> 00:15:33.320
through that lens, the US remains far ahead&nbsp;
of China. And he argues that there's a certain&nbsp;&nbsp;

00:15:33.320 --> 00:15:42.269
amount of hype around the China threat in order&nbsp;
to get policy passed. So, you guys look at this?

00:15:42.269 --> 00:15:45.120
Ylli: 15:42
Yeah, absolutely. So,&nbsp;&nbsp;

00:15:45.120 --> 00:15:48.680
you raised a lot of questions there. You started&nbsp;
with Offset-X which I can come back later if you&nbsp;&nbsp;

00:15:48.680 --> 00:15:56.480
want, Craig but in terms of US versus China,&nbsp;
so we have looked into this for a while now&nbsp;&nbsp;

00:15:56.480 --> 00:16:01.680
and there's a pre GenAI period probably&nbsp;
and there's, I think, post-gen AI period,&nbsp;&nbsp;

00:16:01.680 --> 00:16:06.200
which I think people sometimes, as you&nbsp;
know, mix both, what AI and Gen AI is.

00:16:06.200 --> 00:16:08.640
Ylli: 16:07
The first interim report we published&nbsp;&nbsp;

00:16:08.640 --> 00:16:15.320
with NSCI, which was a requirement from Congress,&nbsp;
we came up explicitly saying that you know we are&nbsp;&nbsp;

00:16:15.320 --> 00:16:21.320
ahead by maybe two years, but they're catching up&nbsp;
fast. And so, I think that was our first judgment&nbsp;&nbsp;

00:16:21.320 --> 00:16:26.880
that we made with NSCI, and I think our thinking&nbsp;
there was similar to what you mentioned, Jeff Ding&nbsp;&nbsp;

00:16:26.880 --> 00:16:33.400
and everybody else talking about. It's not just&nbsp;
the level of investment, it's the application,&nbsp;&nbsp;

00:16:33.400 --> 00:16:39.640
adoption, people, hardware. There are numerous&nbsp;
factors you can compare here and sometimes,&nbsp;&nbsp;

00:16:39.640 --> 00:16:44.800
as you know, this is not like an apples-to-apples&nbsp;
analysis just because they have a different&nbsp;&nbsp;

00:16:44.800 --> 00:16:52.120
system, and we have a different system. But when&nbsp;
you look at it, on just some high-level themes,&nbsp;&nbsp;

00:16:54.000 --> 00:17:00.720
did they have a centrally pushed policy&nbsp;
to invest and get ahead in AI? Yes,&nbsp;&nbsp;

00:17:00.720 --> 00:17:06.400
they did. It's a public strategy that they&nbsp;
had where they organized for that competition&nbsp;&nbsp;

00:17:13.080 --> 00:17:14.541
competition? Yes, they were. Just because they&nbsp;
have a different political system, they can drive&nbsp;&nbsp;

00:17:14.541 --> 00:17:17.600
their private sector in this competition because&nbsp;
there's a similar fusion that they have. Did they&nbsp;&nbsp;

00:17:17.600 --> 00:17:23.880
put enormous resources behind this? They did.&nbsp;
Did they appoint national AI champions to serve&nbsp;&nbsp;

00:17:23.880 --> 00:17:30.829
as the companies that will propagate and advance?&nbsp;
Or, like the CCP agenda, globally? Yes, they did.

00:17:30.829 --> 00:17:32.360
Ylli: 17:30
We all know that I mean,&nbsp;&nbsp;

00:17:32.360 --> 00:17:38.720
and so I think in some aspects, the pre-gen AI&nbsp;
period. They were moving fast, and I think that&nbsp;&nbsp;

00:17:38.720 --> 00:17:43.880
was the concern that led Congress to create&nbsp;
NSCI, because all the signals coming out of&nbsp;&nbsp;

00:17:43.880 --> 00:17:51.160
Beijing were that they have taken this technology&nbsp;
so seriously. And I didn't mention data, I didn't&nbsp;&nbsp;

00:17:51.160 --> 00:17:56.800
mention the application that we have seen against&nbsp;
the minority population. They have done the use&nbsp;&nbsp;

00:17:56.800 --> 00:18:03.120
of surveillance cameras and all those things. So,&nbsp;
all these, like small tactical elements, when you&nbsp;&nbsp;

00:18:03.120 --> 00:18:07.749
add them at the strategic level, was a source of&nbsp;
concern for our country I think, so that's one.

00:18:07.749 --> 00:18:08.440
Ylli: 18:07
The second thing I&nbsp;&nbsp;

00:18:08.440 --> 00:18:16.720
would argue is um, um is that, as you know, this&nbsp;
is a dual-purpose technology. So, I think like,&nbsp;&nbsp;

00:18:16.720 --> 00:18:23.320
you cannot in isolation say oh, let them get ahead&nbsp;
in AI because we are leading in other elements of&nbsp;&nbsp;

00:18:23.320 --> 00:18:32.600
the technology competition. I believe, because AI&nbsp;
is more akin to a general-purpose technology. You&nbsp;&nbsp;

00:18:32.600 --> 00:18:38.800
cannot have your main competitor, who also&nbsp;
is a completely different political system,&nbsp;&nbsp;

00:18:38.800 --> 00:18:46.040
get ahead in that space, and so that's&nbsp;
why I think the concern was in 18, 19,&nbsp;&nbsp;

00:18:46.040 --> 00:18:51.040
and 20, is that, with those elements in mind&nbsp;
and those signals coming out of Beijing,&nbsp;&nbsp;

00:18:51.040 --> 00:18:55.320
we have to get ourselves organized, we have&nbsp;
to finance ourselves, put enough resources.&nbsp;&nbsp;

00:18:55.320 --> 00:19:00.029
I think CHIPS Act is one of the elements, I&nbsp;
think, towards that end. So that's one thing.

00:19:00.029 --> 00:19:01.040
Ylli: 19:00
Post GenAI,&nbsp;&nbsp;

00:19:01.040 --> 00:19:06.440
I think it's a little bit different conversation.&nbsp;
First, because most of the, I think, best models&nbsp;&nbsp;

00:19:06.440 --> 00:19:12.680
came out of US companies' number one. So, there's&nbsp;
an advantage there that I think we have. Secondly&nbsp;&nbsp;

00:19:12.680 --> 00:19:19.000
is that a lot of these models, as you know, need a&nbsp;
lot of data to be trained, and the internet is 60%&nbsp;&nbsp;

00:19:19.000 --> 00:19:25.480
in English and I think it's 2% to 5% in Mandarin,&nbsp;
if I'm not mistaken, and so the training of these&nbsp;&nbsp;

00:19:25.480 --> 00:19:30.200
models requires a lot of data in your native&nbsp;
language, and I think that's what probably holds&nbsp;&nbsp;

00:19:30.200 --> 00:19:38.800
China back in some elements. Third is, we placed&nbsp;
a lot of controls on cutting-edge chips, which I&nbsp;&nbsp;

00:19:38.800 --> 00:19:46.560
think makes Chinese companies really difficult&nbsp;
to get to these models without having access to&nbsp;&nbsp;

00:19:46.560 --> 00:19:52.349
these cutting-edge chips, and you're familiar with&nbsp;
the export controls we placed on high-end chips.

00:19:52.349 --> 00:19:55.360
Ylli: 19:52
And then the last element here is that we live in&nbsp;&nbsp;

00:19:55.360 --> 00:20:01.520
a democracy. You can easily prompt these models to&nbsp;
say something about you or me, or political system&nbsp;&nbsp;

00:20:01.520 --> 00:20:06.720
or political leadership, and they'll do it so long&nbsp;
you know you're not offending somebody or you're&nbsp;&nbsp;

00:20:06.720 --> 00:20:12.400
not seeking to use it for malign purposes. As you&nbsp;
know, you can't do this in China, and I think that&nbsp;&nbsp;

00:20:12.400 --> 00:20:20.040
will hold China back in, probably, these models,&nbsp;
because they'll probably have to place much more&nbsp;&nbsp;

00:20:20.680 --> 00:20:26.680
or heavier control on the models, and these models&nbsp;
get better and better by using them, as you know.&nbsp;&nbsp;

00:20:26.680 --> 00:20:32.000
So, I think Gen AI gives you a different picture.&nbsp;
Will this stop China? I don't think so because,&nbsp;&nbsp;

00:20:32.000 --> 00:20:36.160
as you know, they understand that this is a&nbsp;
critical technology. Are they going to seek&nbsp;&nbsp;

00:20:36.160 --> 00:20:44.800
a different architecture, to go after different&nbsp;
AI models and take a pass on Gen AI competition?&nbsp;&nbsp;

00:20:44.800 --> 00:20:49.360
Probably, because I think there are multiple&nbsp;
ways here to get to the next generation of AI&nbsp;&nbsp;

00:20:49.360 --> 00:20:57.520
models. But I think right now, with these models&nbsp;
being released from primarily US companies,&nbsp;&nbsp;

00:20:57.520 --> 00:21:05.400
you can make, I think, a serious bet that we&nbsp;
are definitely ahead in two to three years time.

00:21:05.400 --> 00:21:08.560
Craig: 21:05
Yeah, and on the GenAI,&nbsp;&nbsp;

00:21:08.560 --> 00:21:15.080
it’s interesting, the idea that they’ll&nbsp;
maybe will take a pass on that, but already&nbsp;&nbsp;

00:21:15.080 --> 00:21:21.489
the technology of the research is moving beyond&nbsp;
large language models into multimodal models, …

00:21:21.489 --> 00:21:21.508
Ylli: 21:21
Exactly.

00:21:21.508 --> 00:21:23.869
Craig: 21:03
combinations of LLMs and—

00:21:23.869 --> 00:21:25.108
Ylli: 21:24
Video and audio.

00:21:25.108 --> 00:21:26.680
Craig: 21:25
Yeah, language, I mean&nbsp;&nbsp;

00:21:26.680 --> 00:21:34.720
large visual models. DeepMind has some amazing&nbsp;
work out and OpenAI just came out with Sora,&nbsp;&nbsp;

00:21:34.720 --> 00:21:44.709
which people look at as, kind of entertainment,&nbsp;
but there is the kernel of AGI in there.

00:21:44.709 --> 00:21:45.600
Ylli: 21:04
Yea

00:21:45.600 --> 00:21:48.240
Craig: 21:47
So, things are moving so fast.&nbsp;&nbsp;

00:21:48.240 --> 00:21:56.320
How do you guys keep up with that? How do you keep&nbsp;
Congress and the executive branch and work with&nbsp;&nbsp;

00:21:56.320 --> 00:22:02.549
them to keep them at the leading edge, because&nbsp;
governments everywhere are notoriously slow?

00:22:02.549 --> 00:22:08.840
Ylli: 22:02
Yeah Well, I mean, I think the release of ChatGPT&nbsp;&nbsp;

00:22:08.840 --> 00:22:16.040
really gave us a new momentum. And then you know&nbsp;
this I mean, all of a sudden, you know, everybody&nbsp;&nbsp;

00:22:16.040 --> 00:22:25.680
started to talk about AI. People are using these&nbsp;
models now and we're facing probably a phase which&nbsp;&nbsp;

00:22:25.680 --> 00:22:30.520
I think in the next three years we're going to&nbsp;
live in, this co-piloting phase, where you know&nbsp;&nbsp;

00:22:30.520 --> 00:22:37.200
everything we do is with these models. So, I think&nbsp;
the conversation has changed dramatically, Greg,&nbsp;&nbsp;

00:22:37.200 --> 00:22:44.920
as you know, from like 2019 and 20, because now AI&nbsp;
has become mainstream and so, to a certain degree,&nbsp;&nbsp;

00:22:44.920 --> 00:22:51.360
this is no longer a difficult space to explain&nbsp;
to people what it means. Because I think,&nbsp;&nbsp;

00:22:51.360 --> 00:22:57.880
if you look at just the, in the last four months,&nbsp;
what has happened in this space? You have the&nbsp;&nbsp;

00:22:57.880 --> 00:23:02.680
White House releasing the White House executive&nbsp;
order on AI. It's probably one of the longest&nbsp;&nbsp;

00:23:02.680 --> 00:23:10.480
EOs you have ever seen, and I think that is a&nbsp;
demonstration of how seriously the White House has&nbsp;&nbsp;

00:23:10.480 --> 00:23:16.160
taken this technology. I can never recall I cannot&nbsp;
recall a technology that we have released such&nbsp;&nbsp;

00:23:16.160 --> 00:23:23.440
a deep and thorough executive order to all the&nbsp;
departments and agencies. So that's one. You have&nbsp;&nbsp;

00:23:23.440 --> 00:23:30.880
a massive effort on the congressional side, led&nbsp;
by four senators Senator Schumer, senator Young,&nbsp;&nbsp;

00:23:30.880 --> 00:23:36.720
senator Heinrich and Senator Rounds that have&nbsp;
organized hearings after hearings, called the&nbsp;&nbsp;

00:23:36.720 --> 00:23:43.360
AI Insight Forum, in educating members of Congress&nbsp;
and Senate about AI from all aspects of our lives.&nbsp;&nbsp;

00:23:43.360 --> 00:23:48.040
You had civil rights leaders, you have technology&nbsp;
leaders, you had national security leaders really&nbsp;&nbsp;

00:23:48.040 --> 00:23:55.320
coming in front of senators explaining the&nbsp;
implications of Gen AI for our country. On&nbsp;&nbsp;

00:23:55.320 --> 00:24:01.480
our allies and partners side, you have the EU AI&nbsp;
Act that was passed a month ago or two months ago,&nbsp;&nbsp;

00:24:01.480 --> 00:24:07.720
so just in the last four months you have this&nbsp;
enormous activity on the policy side of trying&nbsp;&nbsp;

00:24:07.720 --> 00:24:13.720
to get ahead on a technology that is moving so&nbsp;
fast, as you know, and so we will always face&nbsp;&nbsp;

00:24:13.720 --> 00:24:18.360
that challenge, like how do you stay ahead on a&nbsp;
technology that constantly changes? New models&nbsp;&nbsp;

00:24:18.360 --> 00:24:26.640
are released and then you have the open-source&nbsp;
path, you have the proprietary models path,&nbsp;&nbsp;

00:24:26.640 --> 00:24:35.120
but I think, from the awareness perspective,&nbsp;
I think everybody's aware this is moving and&nbsp;&nbsp;

00:24:35.120 --> 00:24:41.109
there are efforts to understand how do we stay&nbsp;
ahead, how do you get organized to stay ahead.

00:24:41.109 --> 00:24:42.080
Ylli: 24:41
Because I think,&nbsp;&nbsp;

00:24:42.080 --> 00:24:47.640
if you look at our government institutions,&nbsp;
they are built after World War II with the&nbsp;&nbsp;

00:24:47.640 --> 00:24:54.360
1947 Act. So, I usually use the example of&nbsp;
Department of Commerce. If you look at our,&nbsp;&nbsp;

00:24:54.880 --> 00:25:00.120
key elements of our competition with China&nbsp;
reside within Department of Commerce, but that&nbsp;&nbsp;

00:25:00.120 --> 00:25:05.720
Department of Commerce was built for the Cold War&nbsp;
competition, and now we're in this techno-economic&nbsp;&nbsp;

00:25:05.720 --> 00:25:11.749
competition with China. So, do we have to reform&nbsp;
institutions? Do you need to create new ones?

00:25:11.749 --> 00:25:13.400
Ylli: 25:11
After 9-11,&nbsp;&nbsp;

00:25:13.400 --> 00:25:18.760
we created a range of institutions. We use the&nbsp;
example that even at the White House, you need&nbsp;&nbsp;

00:25:18.760 --> 00:25:26.880
a different constellation of um councils, uh,&nbsp;
to go after the technology competition. I think&nbsp;&nbsp;

00:25:26.880 --> 00:25:31.120
I used this example in the past, but after World&nbsp;
War II, we created the National Security Council&nbsp;&nbsp;

00:25:31.120 --> 00:25:36.400
of the White House because security was the&nbsp;
predominant domain of competition between us and&nbsp;&nbsp;

00:25:36.400 --> 00:25:42.840
Soviet Union. After the cold war ended, we created&nbsp;
the National Economic Council because the economy&nbsp;&nbsp;

00:25:42.840 --> 00:25:48.960
became you know, as part of that globalizing&nbsp;
you know, discourse the key component of the&nbsp;&nbsp;

00:25:48.960 --> 00:25:56.480
World Order. And then, after 9-11, we created a&nbsp;
Domestic Policy Council to focus on, you know,&nbsp;&nbsp;

00:25:56.480 --> 00:26:02.189
issues related to terrorism, counterterrorism,&nbsp;
you know, our presence in Middle East and whatnot.

00:26:02.189 --> 00:26:03.320
Ylli: 26:07
So, are we now&nbsp;&nbsp;

00:26:03.320 --> 00:26:08.560
in a new era? I believe so. Are we organized&nbsp;
for this era? Not yet. All the departments and&nbsp;&nbsp;

00:26:08.560 --> 00:26:16.120
agencies as you know, Craig, are moving, but&nbsp;
usually our government moves when something&nbsp;&nbsp;

00:26:16.120 --> 00:26:21.600
bad happens and requires us to wake up. I think&nbsp;
9-11 was that wake-up call and we created DNI,&nbsp;&nbsp;

00:26:21.600 --> 00:26:28.560
and we created all these other agencies and&nbsp;
offices. I think AI has that momentum for us&nbsp;&nbsp;

00:26:28.560 --> 00:26:34.360
to relook or reorganize for the AI era and I think&nbsp;
we were at the beginning, as you know, of the AI&nbsp;&nbsp;

00:26:34.360 --> 00:26:39.480
era because it will have huge implications for&nbsp;
the education and workforce and government and&nbsp;&nbsp;

00:26:39.480 --> 00:26:44.560
everything else. So, I think that is when I&nbsp;
think we step in as SCSP, because we have the&nbsp;&nbsp;

00:26:44.560 --> 00:26:51.560
luxury to think outside. We're also surrounded by&nbsp;
technologies, academics, private sector leaders&nbsp;&nbsp;

00:26:51.560 --> 00:26:57.960
who think a lot in this space, and so then what&nbsp;
we do is we take all these conversations and we&nbsp;&nbsp;

00:26:57.960 --> 00:27:03.388
put it in a format to help our government&nbsp;
move forward on all these conversations.

00:27:03.388 --> 00:27:04.720
Craig: 27:04
Yeah, there's&nbsp;&nbsp;

00:27:04.720 --> 00:27:09.800
so much to talk about. Can you give&nbsp;
us a quick overview of the Offset-X&nbsp;&nbsp;

00:27:09.800 --> 00:27:15.149
strategy? And then I want to talk about&nbsp;
the action plan for microelectronics.

00:27:15.149 --> 00:27:17.600
Ylli: 27:15
No problem. So Offset-X,&nbsp;&nbsp;

00:27:19.480 --> 00:27:24.280
one of our lines of effort here, is focused on&nbsp;
the implications of AI and all these, emerging&nbsp;&nbsp;

00:27:24.280 --> 00:27:32.400
tech for the military and the future of warfare,&nbsp;
and so you mentioned Third Offset. I was really&nbsp;&nbsp;

00:27:32.400 --> 00:27:39.000
fortunate to work for Bob Work, and a lot of&nbsp;
things that Bob Work was trying to push through,&nbsp;&nbsp;

00:27:39.000 --> 00:27:46.000
uh, inside the Department of Defense really was&nbsp;
um, early identification that the the warfare&nbsp;&nbsp;

00:27:46.000 --> 00:27:51.560
is changing. And so, I'm talking about 2014,&nbsp;
15, and 16 when I think he started talking&nbsp;&nbsp;

00:27:51.560 --> 00:27:58.520
about the implications of technology and AI, the&nbsp;
future warfare, china really trying to get ahead,&nbsp;&nbsp;

00:27:58.520 --> 00:28:05.200
us losing sort of like the military supremacy and&nbsp;
whatnot. And so, what we tried to do with Offset-X&nbsp;&nbsp;

00:28:05.200 --> 00:28:09.480
is really looking at, you know, what are some&nbsp;
of the key technologies that are happening right&nbsp;&nbsp;

00:28:09.480 --> 00:28:16.880
now that could give us an edge on the battle&nbsp;
space. We also looked at what's happening in&nbsp;&nbsp;

00:28:16.880 --> 00:28:23.280
Ukraine now. So, with those two elements in mind,&nbsp;
we thought that the future of warfare really will&nbsp;&nbsp;

00:28:23.280 --> 00:28:28.480
be characterized by three primary factors.&nbsp;
Number one is we will move into the space,&nbsp;&nbsp;

00:28:28.480 --> 00:28:35.320
and you can see this in Ukraine and elsewhere&nbsp;
of many network distributed platforms. These are&nbsp;&nbsp;

00:28:35.320 --> 00:28:42.000
small. You can think of drones, you can think of&nbsp;
uncrewed systems, but the future of battlefield,&nbsp;&nbsp;

00:28:42.000 --> 00:28:51.720
as you see it in Ukraine, is that of drones,&nbsp;
first-person view drones, many highly networked,&nbsp;&nbsp;

00:28:51.720 --> 00:28:57.080
communicating with each other, communicating&nbsp;
with humans in sort of like deployment and&nbsp;&nbsp;

00:28:57.080 --> 00:29:01.109
execution of the mission, and so that&nbsp;
is one of the elements of the Offset-X.

00:29:01.109 --> 00:29:02.000
Ylli: 29:01
The second element&nbsp;&nbsp;

00:29:02.000 --> 00:29:10.600
is software supremacy. When you look at what we&nbsp;
have as a country, a comparative advantage over&nbsp;&nbsp;

00:29:10.600 --> 00:29:17.240
probably our main competitors is that we have&nbsp;
some of the top leading software companies, and&nbsp;&nbsp;

00:29:17.240 --> 00:29:24.320
software is changing everywhere. It has changed&nbsp;
how we work, how we receive information, and it's&nbsp;&nbsp;

00:29:24.320 --> 00:29:30.520
changing the warfare. And so how do we and, you&nbsp;
know, our department is really notorious in terms&nbsp;&nbsp;

00:29:30.520 --> 00:29:36.360
of buying software and updating it regularly so&nbsp;
how do we stay and how do we make the Department&nbsp;&nbsp;

00:29:36.360 --> 00:29:42.640
of Defense a software-oriented department for the&nbsp;
future warfare. If you look at what's happening&nbsp;&nbsp;

00:29:42.640 --> 00:29:48.760
again in Ukraine, in Middle East and elsewhere is&nbsp;
that you know, if you have cutting edge software,&nbsp;&nbsp;

00:29:48.760 --> 00:29:54.240
it will give you you know information advantage.&nbsp;
It will give you situational advantage,&nbsp;&nbsp;

00:29:54.240 --> 00:29:59.640
it will allow you to defend against information&nbsp;
operations that the enemy is pushing towards you,&nbsp;&nbsp;

00:29:59.640 --> 00:30:04.480
but also you can launch information operation&nbsp;
against your adversary. So, staying ahead in&nbsp;&nbsp;

00:30:04.480 --> 00:30:09.549
the software space was the second element we&nbsp;
thought the Offset-X should be focused on.

00:30:09.549 --> 00:30:10.640
Ylli: 30:09
And the third element was&nbsp;&nbsp;

00:30:10.640 --> 00:30:16.200
really the human machine teaming. Human machine&nbsp;
teaming because if you look at all these systems,&nbsp;&nbsp;

00:30:16.760 --> 00:30:23.360
there's a degree of human control and there's a&nbsp;
degree that then these systems will complement&nbsp;&nbsp;

00:30:23.360 --> 00:30:27.960
human advantages. And so, I think as we&nbsp;
move into the future of battle space,&nbsp;&nbsp;

00:30:28.480 --> 00:30:34.880
we will have human machine teaming in how we&nbsp;
do intelligence analysis, in terms of how we do&nbsp;&nbsp;

00:30:34.880 --> 00:30:42.560
military operations and in terms of how we get&nbsp;
situational awareness and whatnot. So, I think&nbsp;&nbsp;

00:30:42.560 --> 00:30:49.120
training humans in using better these capabilities&nbsp;
will allow us to have an edge over our adversary.

00:30:49.120 --> 00:30:50.320
Ylli: 30:49
I think our military&nbsp;&nbsp;

00:30:50.320 --> 00:30:56.920
is always ahead when it comes to the traditional&nbsp;
training, but I think the situation is changing,&nbsp;&nbsp;

00:30:56.920 --> 00:31:02.960
that if the drones have proven to be so&nbsp;
successful in the battle space of Ukraine,&nbsp;&nbsp;

00:31:02.960 --> 00:31:08.960
you know, I believe that we should have&nbsp;
a drone unit in every other services&nbsp;&nbsp;

00:31:08.960 --> 00:31:14.800
that people are trained on how to use these&nbsp;
drones. Because in, Bob Work has the saying&nbsp;&nbsp;

00:31:14.800 --> 00:31:20.360
that every military technology revolution that&nbsp;
has happened, especially in the military space,&nbsp;&nbsp;

00:31:20.360 --> 00:31:31.560
has allowed us to focus on precise attacks and&nbsp;
the execution of the mission. That in itself has&nbsp;&nbsp;

00:31:31.560 --> 00:31:37.640
limited and diminished the collateral damage,&nbsp;
because the attacks have been more precise,&nbsp;&nbsp;

00:31:37.640 --> 00:31:43.320
more targeted, and I think you know this&nbsp;
new wave of technologies will allow us to&nbsp;&nbsp;

00:31:43.320 --> 00:31:50.960
enter faster into that space by having AI-enabled&nbsp;
systems that are like human, that have meaningful&nbsp;&nbsp;

00:31:50.960 --> 00:31:57.188
human control and they're deployed for, you&nbsp;
know, all aspects of the military operations.

00:31:57.188 --> 00:31:59.320
Craig: 31:57
Yeah, there are a couple of things in the&nbsp;&nbsp;

00:31:59.320 --> 00:32:09.160
Offset-X strategy that struck me. One, you talk&nbsp;
about, with regard to drones, counter-autonomy&nbsp;&nbsp;

00:32:09.160 --> 00:32:21.680
capabilities. The US has been pretty clear to&nbsp;
date that they don't endorse lethal autonomous&nbsp;&nbsp;

00:32:21.680 --> 00:32:31.920
weapon systems, but it's a little bit like&nbsp;
refining uranium. It's the same technology,&nbsp;&nbsp;

00:32:31.920 --> 00:32:38.960
you just go a little bit further and it's&nbsp;
autonomous. What does that mean? Anti-autonomy?

00:32:38.960 --> 00:32:41.108
Ylli: 32:40
Counter autonomy

00:32:41.108 --> 00:32:42.949
Craig: 31:57
Yeah, counter autonomy, I'm sorry.

00:32:42.949 --> 00:32:44.840
Ylli: 32:43
So there are two things, and I&nbsp;&nbsp;

00:32:44.840 --> 00:32:55.160
think we've talked about lethal autonomous weapon&nbsp;
systems. Chapter 4 of the NSCI really covered the&nbsp;&nbsp;

00:32:55.160 --> 00:32:59.400
lethal autonomous weapon systems and I think we&nbsp;
came up with some conclusions. Number one was that&nbsp;&nbsp;

00:32:59.400 --> 00:33:04.320
the department is really well positioned to build&nbsp;
and deploy these systems, and I think we came to&nbsp;&nbsp;

00:33:04.320 --> 00:33:09.040
that conclusion because the commissioners that&nbsp;
came from, as I said, private sector academia,&nbsp;&nbsp;

00:33:09.040 --> 00:33:16.440
and former government were exposed to briefings&nbsp;
and policies and procedures that the department&nbsp;&nbsp;

00:33:16.440 --> 00:33:22.760
has in place before it builds, tests, and&nbsp;
evaluates and deploys these capabilities, because&nbsp;&nbsp;

00:33:22.760 --> 00:33:30.480
I think you have to separate fact from fiction&nbsp;
sometimes in this conversation. I think we were&nbsp;&nbsp;

00:33:30.480 --> 00:33:36.080
heavily influenced by a number of movies in this&nbsp;
space, but the reality is a little bit different.

00:33:36.080 --> 00:33:40.240
Ylli: 33:41
When you look at the first memo the&nbsp;&nbsp;

00:33:40.240 --> 00:33:46.240
department under Secretary Austin issued when it&nbsp;
came to AI, it was on the responsible and ethical&nbsp;&nbsp;

00:33:46.240 --> 00:33:51.640
use of artificial intelligence, and I think the&nbsp;
leadership of the Pentagon wanted to demonstrate&nbsp;&nbsp;

00:33:51.640 --> 00:33:56.549
that they take this technology seriously like&nbsp;
every other technology they have used in the past.

00:33:56.549 --> 00:33:59.240
Ylli: 33:56
There are certain procedures and certain rules&nbsp;&nbsp;

00:33:59.240 --> 00:34:04.720
in which they have, before they test, they take,&nbsp;
they test, evaluate and then they deploy these&nbsp;&nbsp;

00:34:04.720 --> 00:34:10.600
capabilities. So that's one. The second aspect&nbsp;
of this is that there's a political declaration&nbsp;&nbsp;

00:34:10.600 --> 00:34:19.040
the State Department has issued and I think you&nbsp;
have dozens of countries that have signed into&nbsp;&nbsp;

00:34:19.040 --> 00:34:24.400
that political declaration that no matter how the&nbsp;
future warfare changes because of these systems,&nbsp;&nbsp;

00:34:24.400 --> 00:34:28.880
I think we should make sure that these systems are&nbsp;
built and deployed in a responsible and ethical&nbsp;&nbsp;

00:34:28.880 --> 00:34:33.600
way. Obviously, I don't think up to now China or&nbsp;
Russia have signed that political declaration.&nbsp;&nbsp;

00:34:33.600 --> 00:34:39.760
I don't expect that because, as you know, we have&nbsp;
never seen anything coming out of Russia or China&nbsp;&nbsp;

00:34:39.760 --> 00:34:43.680
in terms of how they plan, how they build&nbsp;
and how they're going to use these systems&nbsp;&nbsp;

00:34:43.680 --> 00:34:48.680
and they've used them. I mean, we all know Russia&nbsp;
has used autonomous systems in Syria. They failed,&nbsp;&nbsp;

00:34:48.680 --> 00:34:55.200
but still, nevertheless. It's not that, I think&nbsp;
they, follow some kind of policy procedures&nbsp;&nbsp;

00:34:55.200 --> 00:35:00.640
like we would in those circumstances. The&nbsp;
second aspect to your question was about—

00:35:00.640 --> 00:35:04.549
Craig: 35:01
Well, when you say develop counter autonomy, —

00:35:04.549 --> 00:35:05.720
Ylli: 35:04
Yeah, counter-autonomy,&nbsp;&nbsp;

00:35:05.720 --> 00:35:14.560
so the counter-autonomy is a different space here,&nbsp;
because we're entering a phase in which you have a&nbsp;&nbsp;

00:35:14.560 --> 00:35:23.000
lot of these systems being deployed autonomously&nbsp;
and obviously every autonomous system will have&nbsp;&nbsp;

00:35:23.000 --> 00:35:30.269
a counter autonomous systems that seeks to,&nbsp;
you know, block it, shut it down, and whatnot.

00:35:30.269 --> 00:35:32.040
Ylli: 35:30
And so are we&nbsp;&nbsp;

00:35:32.040 --> 00:35:38.600
positioned even for that space, where a lot of&nbsp;
these systems will be systems against systems&nbsp;&nbsp;

00:35:38.600 --> 00:35:46.400
over the air in the battle space. And so how do&nbsp;
you make these systems resilient, cyber proof&nbsp;&nbsp;

00:35:46.400 --> 00:35:52.000
that your adversary cannot take it over and turn&nbsp;
it against you? So, I think that is another area&nbsp;&nbsp;

00:35:52.000 --> 00:35:57.880
that will probably evolve in an accelerated way&nbsp;
in the next three to five years because as you&nbsp;&nbsp;

00:35:57.880 --> 00:36:03.320
can see from the Ukraine battle space, a lot of&nbsp;
these systems are becoming autonomous. I mean,&nbsp;&nbsp;

00:36:03.320 --> 00:36:08.920
one of the articles we published was that the&nbsp;
Ukraine airspace is dominated by autonomous&nbsp;&nbsp;

00:36:08.920 --> 00:36:15.720
systems small drones or medium-sized drones of&nbsp;
both sides and so in that environment, you know,&nbsp;&nbsp;

00:36:15.720 --> 00:36:21.760
how do you build these systems that you can&nbsp;
ensure that they are proof of cyber attack,&nbsp;&nbsp;

00:36:21.760 --> 00:36:25.440
that your adversary cannot hack them and&nbsp;
turn them against you. So that is the counter&nbsp;&nbsp;

00:36:25.440 --> 00:36:33.868
autonomy piece that I think will enter into the&nbsp;
battle space policy in the next couple of years.

00:36:33.868 --> 00:36:35.000
Craig: 36:33
Okay, yeah,&nbsp;&nbsp;

00:36:35.000 --> 00:36:40.280
that's interesting. I thought more that counter&nbsp;
autonomy were systems, because if the US is not&nbsp;&nbsp;

00:36:40.280 --> 00:36:48.040
using autonomous weapons and the adversary is, you&nbsp;
at least need a way to counter their autonomous&nbsp;&nbsp;

00:36:48.040 --> 00:36:57.240
weapons, because it becomes asymmetrical very&nbsp;
quickly. The other thing in the Offset-X, you talk&nbsp;&nbsp;

00:36:57.240 --> 00:37:07.160
about disrupting adversary's communications and&nbsp;
I assume because the Offset-X is really looking&nbsp;&nbsp;

00:37:07.880 --> 00:37:19.840
at China you now have Russia reportedly planning&nbsp;
to field anti-satellite weapons in outer space,&nbsp;&nbsp;

00:37:19.840 --> 00:37:26.903
which would devastate our ability to&nbsp;
communicate. So, yeah, can you talk about that?

00:37:26.903 --> 00:37:27.920
Ylli: 37:26
Yeah, no, absolutely,&nbsp;&nbsp;

00:37:27.920 --> 00:37:33.920
look, if you look at the importance of space&nbsp;
that has grown over the last couple of years,&nbsp;&nbsp;

00:37:33.920 --> 00:37:41.560
both in terms of where our adversary has invested,&nbsp;
deployed and tested capabilities, but also if&nbsp;&nbsp;

00:37:41.560 --> 00:37:48.080
you look at the private sector on our side and&nbsp;
how much you know the space has proliferated,&nbsp;&nbsp;

00:37:48.080 --> 00:37:53.640
both in terms of launches, in terms of satellite&nbsp;
constellations, and then you know reliance on&nbsp;&nbsp;

00:37:53.640 --> 00:37:59.680
Starlink, for example, in Ukraine, that tells&nbsp;
you a lot of how space is a key component now&nbsp;&nbsp;

00:37:59.680 --> 00:38:06.120
of the battle space and the warfare. I think&nbsp;
some of the analysis that we have probably&nbsp;&nbsp;

00:38:06.120 --> 00:38:13.560
published is you know, I think the first move&nbsp;
by the Russian military against the Ukrainian&nbsp;&nbsp;

00:38:13.560 --> 00:38:18.520
military was to try to shut down their, I think,&nbsp;
satellites. And so, this goes back to, like&nbsp;&nbsp;

00:38:18.520 --> 00:38:25.600
you know, because space gives you information,&nbsp;
awareness, communication, command, and control,&nbsp;&nbsp;

00:38:25.600 --> 00:38:32.948
and so space is a critical component of how we're&nbsp;
organized now for the future of the warfare.

00:38:32.948 --> 00:38:34.640
Craig: 38:32
You talk about,&nbsp;&nbsp;

00:38:34.640 --> 00:38:43.000
on the national plan for microelectronics, you&nbsp;
talk about addressing the threat of China's&nbsp;&nbsp;

00:38:43.000 --> 00:38:50.840
massive build out of legacy chips, and there's&nbsp;
some other really interesting things in there-&nbsp;&nbsp;

00:38:50.840 --> 00:38:57.040
this innovator visa category, which I'm all&nbsp;
for. On the Chinese chips though, there's&nbsp;&nbsp;

00:38:57.040 --> 00:39:04.440
been a big debate about whether the export&nbsp;
controls haven't created a bigger problem.

00:39:04.440 --> 00:39:06.520
Ylli: 39:04
Yeah, first of all,&nbsp;&nbsp;

00:39:06.520 --> 00:39:11.440
I think the export control really aimed to what&nbsp;
I think the National Security advisor said,&nbsp;&nbsp;

00:39:11.440 --> 00:39:18.080
you know, high fence, small garden approach. The&nbsp;
export controls were designed, I think, in a way,&nbsp;&nbsp;

00:39:18.080 --> 00:39:23.840
and targeted to prevent China from having&nbsp;
access to the cutting-edge semiconductors.&nbsp;&nbsp;

00:39:23.840 --> 00:39:27.680
Not all semiconductors, but the cutting-edge&nbsp;
semiconductors. So that's one thing, because&nbsp;&nbsp;

00:39:27.680 --> 00:39:36.560
I think, as you know, these are the semiconductors&nbsp;
that allow you to get to these high-end AI models.&nbsp;&nbsp;

00:39:36.560 --> 00:39:43.800
So that's one. I don't think that has prevented&nbsp;
China from investing on all other aspects of&nbsp;&nbsp;

00:39:43.800 --> 00:39:52.920
semiconductor industry, nor, I think, it has&nbsp;
prevented China from trying to circumvent&nbsp;&nbsp;

00:39:52.920 --> 00:40:01.000
export controls by getting access to, you know,&nbsp;
clouds in third countries or buying a new design&nbsp;&nbsp;

00:40:01.000 --> 00:40:09.440
of a similar chip from certain companies.&nbsp;
So, I think the issue of export controls,&nbsp;&nbsp;

00:40:09.440 --> 00:40:15.760
I think it did have an effect I mentioned&nbsp;
earlier, look at the general AI models where&nbsp;&nbsp;

00:40:15.760 --> 00:40:21.240
are our companies versus the Chinese companies?&nbsp;
So that's one. Secondly is, these export controls&nbsp;&nbsp;

00:40:21.240 --> 00:40:30.589
have been in place since October 2022. So usually,&nbsp;
you know, these effects will not be immediate.

00:40:30.589 --> 00:40:31.600
Ylli: 40:30
You have to think&nbsp;&nbsp;

00:40:31.600 --> 00:40:37.560
about it in terms of three to five years&nbsp;
and how much I think that has an effect&nbsp;&nbsp;

00:40:37.560 --> 00:40:45.200
on the Chinese access to these capabilities&nbsp;
and I think, as I think the White House has&nbsp;&nbsp;

00:40:45.200 --> 00:40:53.189
said many, many times, these were not&nbsp;
intended to slow China down forever.

00:40:53.189 --> 00:40:54.000
Ylli: 40:53
They were intended&nbsp;&nbsp;

00:40:54.000 --> 00:41:00.480
to give us a competing edge, a window&nbsp;
that we stay the leading technology,&nbsp;&nbsp;

00:41:01.200 --> 00:41:04.960
and while we did the protect side of the&nbsp;
export controls, we also did the promote.&nbsp;&nbsp;

00:41:04.960 --> 00:41:12.000
We have invested through the CHIPS Act $52&nbsp;
billion on domestic fabs, and then companies&nbsp;&nbsp;

00:41:12.000 --> 00:41:18.360
have also came on top of that to announce their&nbsp;
investments here, and so I think not only you&nbsp;&nbsp;

00:41:18.360 --> 00:41:23.680
have to slow them down, you continuously have&nbsp;
to evolve in this space. Secretary Raimondo&nbsp;&nbsp;

00:41:23.680 --> 00:41:28.520
said yesterday that maybe we might need&nbsp;
another CHIPS Act, and I think the demand,&nbsp;&nbsp;

00:41:28.520 --> 00:41:34.880
as you can see from what's happening right now&nbsp;
with the CHIPS worldwide, is so big that I could&nbsp;&nbsp;

00:41:34.880 --> 00:41:39.360
probably foresee another CHIPS Act in the next,&nbsp;
because I think the first CHIP Act was like just&nbsp;&nbsp;

00:41:39.360 --> 00:41:45.868
trying to catch up and I think staying ahead in&nbsp;
this space will probably require more investment.

00:41:45.868 --> 00:41:47.840
Craig: 41:45
Yeah, I guess what&nbsp;&nbsp;

00:41:47.840 --> 00:41:54.760
I'm referring to is it's also spurred&nbsp;
China to have a national plan to become&nbsp;&nbsp;

00:41:54.760 --> 00:42:03.200
independent in high-end semiconductors you&nbsp;
know everything from lithography on and that's&nbsp;&nbsp;

00:42:03.200 --> 00:42:08.909
not necessarily a good thing if they're&nbsp;
no longer dependent on Western supplies.

00:42:08.909 --> 00:42:10.920
Ylli: 42:08
No, and I understand that argument,&nbsp;&nbsp;

00:42:10.920 --> 00:42:16.720
Craig I would argue that China would have done&nbsp;
that anyway, because I think, if you look at&nbsp;&nbsp;

00:42:16.720 --> 00:42:27.840
the China policy made in China 2025, which is also&nbsp;
known as the dual circulation policy is they have&nbsp;&nbsp;

00:42:27.840 --> 00:42:37.000
a strategy in place and this is a public document&nbsp;
that they want to be independent from the world&nbsp;&nbsp;

00:42:37.000 --> 00:42:42.200
supply chain, but they want the rest of the world&nbsp;
to be dependent on their supply chain, and so I&nbsp;&nbsp;

00:42:42.200 --> 00:42:49.669
think they would pursue the semiconductor path of&nbsp;
independence, regardless of our export controls,

00:42:49.669 --> 00:42:50.640
Ylli: 42:49
just because they&nbsp;&nbsp;

00:42:50.640 --> 00:42:55.240
look at what's happening in Ukraine, with&nbsp;
us sanctioning Russia and their access to&nbsp;&nbsp;

00:42:55.240 --> 00:43:03.000
semiconductors and I think the technology aspect&nbsp;
or their national security approach is it,&nbsp;&nbsp;

00:43:03.000 --> 00:43:09.640
shouldn't serve as a weak point in whatever&nbsp;
they decide to do around Taiwan, wherever the&nbsp;&nbsp;

00:43:09.640 --> 00:43:14.720
global ambitions are in South/Southeast Asia,&nbsp;
and so I don't think they would have let the&nbsp;&nbsp;

00:43:14.720 --> 00:43:22.200
technology piece be their weak point in pursuing&nbsp;
their regional and global goals. So, I think,&nbsp;&nbsp;

00:43:22.200 --> 00:43:28.760
bottom line, as I said, I think they would have&nbsp;
pursued the path towards semiconductor design,&nbsp;&nbsp;

00:43:28.760 --> 00:43:33.280
fabrication and production independent of our&nbsp;
export controls. I think we have managed to&nbsp;&nbsp;

00:43:33.280 --> 00:43:37.988
slow them down and I think this will have&nbsp;
implications for the next couple of years.

00:43:37.988 --> 00:43:38.800
Craig: 43:38
Can you talk a little&nbsp;&nbsp;

00:43:38.800 --> 00:43:44.469
bit about the National Semiconductor&nbsp;
Technology Center, that proposal?

00:43:44.469 --> 00:43:46.960
Ylli: 43:44
And so, the National Center was part of our&nbsp;&nbsp;

00:43:46.960 --> 00:43:52.760
recommendation with NSCI, because what we argued&nbsp;
in an NSEI report is not only do we need resources&nbsp;&nbsp;

00:43:52.760 --> 00:43:58.069
to catch up and build some of these manufacturing&nbsp;
capabilities back to the United States.

00:43:58.069 --> 00:43:59.240
Ylli: 43:58
You need a center&nbsp;&nbsp;

00:43:59.240 --> 00:44:03.360
that brings together probably our government&nbsp;
labs, university labs to look at what's the&nbsp;&nbsp;

00:44:03.360 --> 00:44:09.800
next generation of semiconductors we have to look&nbsp;
after. If you think about it, we're getting close&nbsp;&nbsp;

00:44:09.800 --> 00:44:14.760
to the end of the nanometer or the Moore's&nbsp;
law, and so there are different paths now&nbsp;&nbsp;

00:44:14.760 --> 00:44:20.440
that you can take in terms of how is the future of&nbsp;
semiconductor going to look like? And I think we&nbsp;&nbsp;

00:44:20.440 --> 00:44:25.680
need a center like that. We need a center that the&nbsp;
only job and the only objective is to look at what&nbsp;&nbsp;

00:44:25.680 --> 00:44:31.000
does the post-Moore’s law world look like in terms&nbsp;
of semiconductors. I think, with the right actors,&nbsp;&nbsp;

00:44:31.000 --> 00:44:37.160
with the right leadership and I think Secretary&nbsp;
Raimondo has been a force of nature in this space.&nbsp;&nbsp;

00:44:37.160 --> 00:44:41.560
That center should focus on really coming&nbsp;
out with a couple of options that we should&nbsp;&nbsp;

00:44:41.560 --> 00:44:51.068
have as a country, as a government, in pursuing&nbsp;
the next three, ten years of this technology.

00:44:51.068 --> 00:44:52.000
Craig: 44:51
Okay, can you&nbsp;&nbsp;

00:44:52.000 --> 00:44:54.509
talk about this expo that's coming up in May.

00:44:54.509 --> 00:44:57.200
Ylli: 44:54
Yeah, so the expo is probably&nbsp;&nbsp;

00:44:57.200 --> 00:45:04.160
a unique gathering in DC. It's a classic AI expo&nbsp;
in a sense that nobody has ever organized this in&nbsp;&nbsp;

00:45:04.160 --> 00:45:09.920
Washington. You have AI expos around the world,&nbsp;
you have the CES in Vegas, but in Washington&nbsp;&nbsp;

00:45:09.920 --> 00:45:15.160
nobody has ever brought together the technology&nbsp;
companies small, medium-sized and large companies&nbsp;&nbsp;

00:45:15.160 --> 00:45:22.360
with government agencies, with academic labs in&nbsp;
one place where they can showcase technology. So&nbsp;&nbsp;

00:45:22.360 --> 00:45:27.520
this is not just a conversation, this is not just&nbsp;
releasing another policy document. This is really&nbsp;&nbsp;

00:45:27.520 --> 00:45:33.400
bringing together in one place people to see&nbsp;
demos of these technologies, to have conversation&nbsp;&nbsp;

00:45:33.400 --> 00:45:39.280
around these technologies, to exchange business&nbsp;
cards, because our government desperately needs&nbsp;&nbsp;

00:45:39.280 --> 00:45:44.360
to modernize when it comes to these technologies.&nbsp;
There's an enormous capacity in private sector to&nbsp;&nbsp;

00:45:44.360 --> 00:45:49.200
offer these technologies to government. So this&nbsp;
will be a unique place, over the course of two&nbsp;&nbsp;

00:45:49.200 --> 00:45:55.200
days at our convention center, may 7th and 8th,&nbsp;
for all these stakeholders to come together, talk,&nbsp;&nbsp;

00:45:55.200 --> 00:45:59.908
engage and really deepen their relationship&nbsp;
when it comes to AI and emerging tech.

00:45:59.908 --> 00:46:00.480
Craig: 46:02
Yeah, how much&nbsp;&nbsp;

00:46:00.480 --> 00:46:02.749
of that will be focused on national security?

00:46:02.749 --> 00:46:04.000
Ylli: 46:02
A fraction, Greg,&nbsp;&nbsp;

00:46:04.000 --> 00:46:09.800
because what we have said is, you know, there are&nbsp;
probably 19 departments and agencies in Washington&nbsp;&nbsp;

00:46:09.800 --> 00:46:16.680
DC, and so I think what we want to focus on is&nbsp;
there's certain elements of the conversation and&nbsp;&nbsp;

00:46:16.680 --> 00:46:20.200
companies that are tailored for Department&nbsp;
of Defense and the intelligence community,&nbsp;&nbsp;

00:46:20.200 --> 00:46:26.280
but I believe we can provide a useful service&nbsp;
here for health and human services, FEMA,&nbsp;&nbsp;

00:46:26.280 --> 00:46:31.360
because, as you know, these models can do&nbsp;
an incredible predictions of hurricanes,&nbsp;&nbsp;

00:46:31.360 --> 00:46:38.680
weather forecasting. So by bringing not just DOD&nbsp;
and IC related companies, but other companies&nbsp;&nbsp;

00:46:38.680 --> 00:46:44.720
that have services and have technologies&nbsp;
in this space, I think we would really do a&nbsp;&nbsp;

00:46:44.720 --> 00:46:52.748
huge service to other non-DOD and non-IC related&nbsp;
departments and agencies in DC with the AI Expo.

00:46:52.748 --> 00:46:54.400
Craig: 46:52
Okay, great well,&nbsp;&nbsp;

00:46:54.400 --> 00:47:00.200
I'll be there, and I appreciate the&nbsp;
time. I know you've got a tight schedule.

00:47:00.200 --> 00:47:01.680
Ylli: 47:01
Thanks for having me,&nbsp;&nbsp;

00:47:01.680 --> 00:47:05.228
Craig. It's always a pleasure&nbsp;
and I’ll see you on May 7th!

00:47:05.228 --> 00:47:07.160
Craig: 47:06
Hi, good tech solves&nbsp;&nbsp;

00:47:07.160 --> 00:47:12.920
problems that you've thought about. Great tech&nbsp;
solves problems that you haven't even thought of.&nbsp;&nbsp;

00:47:12.920 --> 00:47:19.120
What can the commerce platform trusted by millions&nbsp;
of merchants do for you? It's time for Shopify,&nbsp;&nbsp;

00:47:19.120 --> 00:47:25.320
the commerce platform revolutionizing millions&nbsp;
of businesses worldwide. Whether you're a garage&nbsp;&nbsp;

00:47:25.320 --> 00:47:32.240
entrepreneur or IPO ready, Shopify is the&nbsp;
only tool you need to start, run and grow&nbsp;&nbsp;

00:47:32.240 --> 00:47:38.200
your business without the struggle. Shopify&nbsp;
puts you in control of every sales channel. So,&nbsp;&nbsp;

00:47:38.200 --> 00:47:44.640
whether you're selling satin sheets from Shopify's&nbsp;
in-person point of sale system or offering organic&nbsp;&nbsp;

00:47:44.640 --> 00:47:52.240
olive oil on Shopify's all-in-one e-commerce&nbsp;
platform, you're covered. Shopify powers 10% of&nbsp;&nbsp;

00:47:52.240 --> 00:48:00.680
all e-commerce in the United States and Shopify's&nbsp;
a truly global force powering Allbirds, Rothy’s,&nbsp;&nbsp;

00:48:00.680 --> 00:48:08.520
and Brooklyn and millions of other entrepreneurs&nbsp;
of every size across over 170 countries. Plus,&nbsp;&nbsp;

00:48:08.520 --> 00:48:15.748
Shopify’s award-winning help is there to&nbsp;
support your success every step of the way.

00:48:15.748 --> 00:48:19.880
Craig: 48:15
Sign up for a $1 per month trial period at&nbsp;&nbsp;

00:48:19.880 --> 00:48:33.920
shopify.com/eyeonai, that's shopify S-H-O-P-I-F-Y&nbsp;
dot com slash eye on ai, that's E-Y-E-O-N-A-I all&nbsp;&nbsp;

00:48:33.920 --> 00:48:45.262
run together. So, sign up for a $1 a month trial&nbsp;
period at shopify.com/eyeonai, that’s shopify&nbsp;&nbsp;

00:48:45.262 --> 00:48:56.720
S-H-O-P-I-F-Y dot com slash eye on ai, that's&nbsp;
E-Y-E-O-N-A-I all lowercase, all run together.&nbsp;&nbsp;

00:48:57.240 --> 00:49:02.920
They support us, so let's support them. That's&nbsp;
it for this episode. I want to thank Ylli for&nbsp;&nbsp;

00:49:02.920 --> 00:49:10.200
his time. If you're in the Washington DC area in&nbsp;
May, be sure to check out the special Competitive&nbsp;&nbsp;

00:49:10.200 --> 00:49:17.680
Studies Project's AI Expo. I'll be there and&nbsp;
if you see me, say hello. In the meantime,&nbsp;&nbsp;

00:49:17.680 --> 00:49:26.160
remember the singularity may not be near, but&nbsp;
AI is changing your world, so pay attention.

