WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.020
SINA
When you think about machine learning or AI using&nbsp;&nbsp;

00:00:04.020 --> 00:00:10.740
databases, one of the most obvious questions is
what's in those databases? And do we want to&nbsp;&nbsp;

00:00:10.740 --> 00:00:14.700
expose that to in the context&nbsp;
of our cyber unaffiliated&nbsp;

00:00:14.700 --> 00:00:18.240
nodes in this context to machine&nbsp;
learning, you can use encryption,&nbsp;&nbsp;

00:00:19.020 --> 00:00:22.860
to make data unavailable to the
general public that may try to&nbsp;&nbsp;

00:00:22.860 --> 00:00:26.640
look at that data. But at the same&nbsp;
time, if you put it on something like&nbsp;

00:00:26.640 --> 00:00:32.700
Aleo, you can prove things about&nbsp;
that data that are true or false,&nbsp;&nbsp;

00:00:32.700 --> 00:00:38.640
or that fall within certain parameters.
And leverage that data without actually giving&nbsp;&nbsp;

00:00:38.640 --> 00:00:40.462
away identifying information.
CRAIG&nbsp;

00:00:40.462 --> 00:00:40.716
Data privacy continues to be a&nbsp;
challenge for companies deploying AI,&nbsp;&nbsp;

00:00:40.717 --> 00:00:41.038
particularly the privacy of training
data, which constitutes some of the most valuable&nbsp;&nbsp;

00:00:41.037 --> 00:00:41.317
IP for companies as algorithms and compute
become increasingly commoditized.&nbsp;

00:00:41.318 --> 00:00:42.060
CRAIG
This week,&nbsp;&nbsp;

00:00:42.060 --> 00:00:52.440
I talk with Sina Kian, chief operating officer of&nbsp;
Aleo, a platform for building private blockchain&nbsp;

00:00:52.440 --> 00:00:58.020
based applications. Aleo&nbsp;
supports zero knowledge proofs,&nbsp;&nbsp;

00:00:58.020 --> 00:01:06.000
a powerful tool to verify the correctness of a
computation without revealing the input data,&nbsp;&nbsp;

00:01:06.000 --> 00:01:10.500
or the computation itself.&nbsp;
This makes Aleo particularly&nbsp;

00:01:10.500 --> 00:01:14.400
useful in machine learning,&nbsp;
where sensitive data such as&nbsp;&nbsp;

00:01:14.400 --> 00:01:22.440
medical records or financial information needs
to be kept private but has tremendous potential&nbsp;&nbsp;

00:01:22.440 --> 00:01:26.580
for training AI systems.
CRAIG&nbsp;

00:01:26.580 --> 00:01:34.380
Before we begin, I want to mention our sponsor&nbsp;
NetSuite, Oracle's cloud-based enterprise resource&nbsp;

00:01:34.380 --> 00:01:40.860
planning software to help any business&nbsp;
manage their financials operations and&nbsp;&nbsp;

00:01:40.860 --> 00:01:44.160
customer relationships
in a single platform.&nbsp;&nbsp;

00:01:44.760 --> 00:01:51.480
For the first time in NetSuite 22 years&nbsp;
as the number one cloud financial system,&nbsp;

00:01:51.480 --> 00:01:57.900
you can defer payment on a full&nbsp;
implementation for six months;&nbsp;&nbsp;

00:01:58.500 --> 00:02:07.140
no payment, no interest for six months
for a full implementation of Oracle's NetSuite.&nbsp;&nbsp;

00:02:08.100 --> 00:02:12.300
To take advantage of this&nbsp;
unprecedented financing offer,&nbsp;

00:02:12.900 --> 00:02:25.380
go to www.netsuite.com/eyeonai.&nbsp;
That's EYEONAI all run together.&nbsp;

00:02:25.380 --> 00:02:27.546
Now here’s Sina.
CRAIG&nbsp;

00:02:27.546 --> 00:02:30.720
Let’s talk about Aleo. I've had a&nbsp;
little bit of a look, but why don't&nbsp;&nbsp;

00:02:30.720 --> 00:02:34.980
we start by having you introduce
yourself and then introduce Aleo.&nbsp;&nbsp;

00:02:35.820 --> 00:02:38.430
And then I'll get into some questions.
SINA&nbsp;

00:02:38.430 --> 00:02:43.320
Okay, great. So, my name is Sina&nbsp;
Kian. I'm General Counsel and COO&nbsp;&nbsp;

00:02:43.320 --> 00:02:48.480
here at Aleo. I graduated from
law school, after law school,&nbsp;&nbsp;

00:02:48.480 --> 00:02:52.500
I clerked on the DC circuit for two&nbsp;
years and then the Supreme Court for&nbsp;

00:02:52.500 --> 00:02:57.420
Chief Justice Roberts. I practice law&nbsp;
at a firm called Wilmer Hale here in DC&nbsp;&nbsp;

00:02:58.680 --> 00:03:01.800
for a couple of years. Then
I changed gears, actually&nbsp;&nbsp;

00:03:01.800 --> 00:03:06.420
went into the finance world, worked at&nbsp;
Blackstone for about four years. And&nbsp;

00:03:06.420 --> 00:03:10.860
during that time, in an investment&nbsp;
capacity, I got very interested in&nbsp;&nbsp;

00:03:10.860 --> 00:03:16.800
the technology behind blockchain
generally and I met the folks over&nbsp;&nbsp;

00:03:16.800 --> 00:03:19.440
here at Aleo and got very interested&nbsp;
in what they're doing. I joined&nbsp;

00:03:19.440 --> 00:03:26.280
initially as VP of strategy and have since been&nbsp;
promoted to COO and General Counsel. So happy to&nbsp;

00:03:26.280 --> 00:03:27.329
talk about Aleo itself.
1&nbsp;

00:03:27.329 --> 00:03:30.060
Transcribed by https://otter.ai
As background, I was also an advisor&nbsp;&nbsp;

00:03:30.060 --> 00:03:33.240
to the Privacy and Civil Liberties&nbsp;
Oversight Board, so long been&nbsp;

00:03:33.240 --> 00:03:36.540
very interested in issues&nbsp;
around privacy and how they work&nbsp;&nbsp;

00:03:37.800 --> 00:03:42.960
consistent with sort of national security and
other public policy goals that we have. So&nbsp;&nbsp;

00:03:42.960 --> 00:03:46.740
Aleo. If you take a step back,&nbsp;
if you think about blockchains,&nbsp;

00:03:46.740 --> 00:03:53.040
generally, if the internet allowed&nbsp;
unaffiliated notes, which is to&nbsp;&nbsp;

00:03:53.040 --> 00:03:59.700
say computers, phone phones, other
nodes like that, to communicate with&nbsp;&nbsp;

00:03:59.700 --> 00:04:03.300
each other, even though they're&nbsp;
unaffiliated, and have no reason&nbsp;

00:04:03.300 --> 00:04:07.800
to trust each other, blockchain sort&nbsp;
of took that a step further and allow&nbsp;&nbsp;

00:04:07.800 --> 00:04:12.600
those unaffiliated nodes to
cooperate on a task and&nbsp;&nbsp;

00:04:12.600 --> 00:04:18.000
specifically on updating a ledger.
Now, the mechanism by which they&nbsp;&nbsp;

00:04:18.000 --> 00:04:22.020
did that is basically yelling the&nbsp;
answer out loud, which is one node&nbsp;

00:04:22.020 --> 00:04:26.760
will say, hey, Craig sent Sina one&nbsp;
Bitcoin or one ether, one, whatever,&nbsp;&nbsp;

00:04:26.760 --> 00:04:32.160
and all the other nodes write it
down. And so that's how they update&nbsp;&nbsp;

00:04:32.160 --> 00:04:37.320
the ledger in terms of like data.&nbsp;
Now, if you and I crack started&nbsp;

00:04:37.320 --> 00:04:44.640
talking about what are use cases for ledgers, we'd&nbsp;
start talking about, obviously, the financial use&nbsp;

00:04:44.640 --> 00:04:48.600
cases, bank accounts, that sort of&nbsp;
thing. Maybe your real estate titles,&nbsp;&nbsp;

00:04:48.600 --> 00:04:52.920
we start talking about healthcare
records, you know, vaccine records,&nbsp;&nbsp;

00:04:52.920 --> 00:04:58.560
maybe voting databases. And for&nbsp;
almost all those use cases, if not&nbsp;

00:04:58.560 --> 00:05:02.940
all of them, you want some level of&nbsp;
data confidentiality and privacy.&nbsp;&nbsp;

00:05:04.260 --> 00:05:07.380
Which is to say you don't want to
yell the answer to the entire&nbsp;&nbsp;

00:05:07.380 --> 00:05:10.980
world of unaffiliated nodes that you&nbsp;
don't know and maybe don't have great&nbsp;

00:05:10.980 --> 00:05:15.120
reason to trust. And so, what we're&nbsp;
doing at Aleo is we're allowing the&nbsp;&nbsp;

00:05:15.120 --> 00:05:19.200
same thing to happen. But for the
answers to be encrypted, which is&nbsp;&nbsp;

00:05:19.200 --> 00:05:24.180
to say we yell encrypted answers&nbsp;
out loud. And you can still verify&nbsp;

00:05:24.180 --> 00:05:29.280
that everything being said is true, you just don't&nbsp;
know what the actual content is, as a completely&nbsp;

00:05:29.280 --> 00:05:35.640
unaffiliated node as a user as a program, you may.&nbsp;
But in terms of what you broadcast to the entire&nbsp;

00:05:35.640 --> 00:05:40.800
world that's encrypted. And that&nbsp;
unlocks a lot more use cases. So,&nbsp;&nbsp;

00:05:40.800 --> 00:05:42.900
we're very excited about that. So
that's very long answer.&nbsp;&nbsp;

00:05:43.680 --> 00:05:45.420
To help explain what we're doing.
CRAIG&nbsp;

00:05:45.420 --> 00:05:50.040
Yeah, yeah. Well, that's interesting.&nbsp;
And you're specifically targeting&nbsp;&nbsp;

00:05:50.640 --> 00:05:53.280
machine learning solutions. Is that&nbsp;

00:05:53.280 --> 00:05:53.940
right?
SINA&nbsp;

00:05:53.940 --> 00:05:57.420
The overlap between what we're doing&nbsp;
and machine learning, machine learning&nbsp;&nbsp;

00:05:57.420 --> 00:06:00.900
and AI is really, really
interesting. Because there&nbsp;&nbsp;

00:06:00.900 --> 00:06:05.160
are a couple of there are a couple of&nbsp;
interfaces here. The first is training&nbsp;

00:06:05.160 --> 00:06:12.420
data. When you think about machine learning or AI&nbsp;
using databases, one of the most obvious questions&nbsp;

00:06:12.420 --> 00:06:18.600
is what's in those databases? And&nbsp;
do we want to expose that to in&nbsp;&nbsp;

00:06:18.600 --> 00:06:21.060
the context of something about an
affiliated nodes in this context&nbsp;&nbsp;

00:06:21.060 --> 00:06:25.920
to machine learning. And so, one&nbsp;
technique that you could use is&nbsp;

00:06:25.920 --> 00:06:28.320
something called homomorphic&nbsp;
encryption. Another one is&nbsp;&nbsp;

00:06:28.320 --> 00:06:33.660
federated learning. Another one isn't actually
exactly what we're doing, which is using a kind of&nbsp;&nbsp;

00:06:33.660 --> 00:06:40.980
cryptography called zero knowledge proofs to prove
information from data without actually revealing&nbsp;&nbsp;

00:06:40.980 --> 00:06:45.840
the underlying data, which would allow machine
learning to train without necessarily having&nbsp;&nbsp;

00:06:45.840 --> 00:06:50.820
exposure to the kinds of data&nbsp;
we don't want, machines we&nbsp;

00:06:50.820 --> 00:06:55.980
don't quite understand yet to have access to.
CRAIG&nbsp;

00:06:55.980 --> 00:07:03.420
Well, just to slow down a little bit. So,&nbsp;
I'm familiar with homomorphic encryption.&nbsp;&nbsp;

00:07:03.960 --> 00:07:06.900
And I'm, I'm familiar
with federated learning.&nbsp;&nbsp;

00:07:08.760 --> 00:07:11.902
How is this different from either of those.
2&nbsp;

00:07:11.902 --> 00:07:12.720
Transcribed by https://otter.ai
SINA&nbsp;

00:07:12.720 --> 00:07:18.240
So, zero knowledge proof is&nbsp;
basically an application of&nbsp;&nbsp;

00:07:18.240 --> 00:07:26.280
cryptography that allows a user to prove
something about a set of facts without&nbsp;&nbsp;

00:07:26.280 --> 00:07:33.000
actually sharing that underlying&nbsp;
set of facts. So, it's a particular&nbsp;

00:07:33.000 --> 00:07:37.920
and as a statement has three features. First,&nbsp;
the proof has to be complete. Meaning if someone&nbsp;

00:07:37.920 --> 00:07:43.440
provides the proof, we know with certainty that&nbsp;
the underlying statement being proven as true. The&nbsp;

00:07:43.440 --> 00:07:49.260
second is, it must be impossible for someone to&nbsp;
provide a zero-knowledge proof of a particular&nbsp;

00:07:49.260 --> 00:07:52.740
statement if that statement&nbsp;
is false. And then finally,&nbsp;&nbsp;

00:07:52.740 --> 00:07:56.580
and this is the key one that distinguishes it from
some of the other techniques we're talking about,&nbsp;&nbsp;

00:07:56.580 --> 00:08:02.160
is the proof must be zero knowledge, meaning the
proof must not reveal anything about the&nbsp;&nbsp;

00:08:02.160 --> 00:08:06.720
statement other than the fact&nbsp;
that the statement is true. And&nbsp;

00:08:06.720 --> 00:08:11.760
so homomorphic encryption overlaps with that very&nbsp;
significantly, but it's its own distinct field.&nbsp;

00:08:11.760 --> 00:08:17.220
CRAIG
And in a in a in a&nbsp;&nbsp;

00:08:18.540 --> 00:08:24.780
machine learning training scenario, how&nbsp;
does that work? I mean, federated learning,&nbsp;

00:08:24.780 --> 00:08:33.060
you're sending the model&nbsp;
out to different data pools,&nbsp;&nbsp;

00:08:33.840 --> 00:08:44.220
that various owners have, and you’re training and
then coming back and updating models so that that&nbsp;&nbsp;

00:08:44.220 --> 00:08:52.320
data never has to leave the possession of the
owner. And the only thing that&nbsp;&nbsp;

00:08:52.920 --> 00:09:04.860
that goes back are the weights from&nbsp;
the training exercise. In this case,&nbsp;

00:09:05.760 --> 00:09:14.100
where is the model? If you're training a model.&nbsp;
And where's the data? And, yeah, how does it work?&nbsp;

00:09:14.100 --> 00:09:16.020
SINA
Okay, let's take&nbsp;&nbsp;

00:09:16.020 --> 00:09:21.780
a very simple example. Imagine that we are&nbsp;
looking at certain kinds of health data. And&nbsp;

00:09:21.780 --> 00:09:26.160
we want to know, if the health&nbsp;
data shows correlate, or there's&nbsp;&nbsp;

00:09:26.160 --> 00:09:31.860
something we can learn about it based
on age, which is people under 21. They&nbsp;&nbsp;

00:09:31.860 --> 00:09:35.100
have certain traits over 21, they&nbsp;
have certain traits over 65, do&nbsp;

00:09:35.100 --> 00:09:46.740
they have certain traits. And in that context, you&nbsp;
could actually look at, so I can hear baby in the&nbsp;

00:09:46.740 --> 00:09:47.820
background.
CRAIG&nbsp;

00:09:47.820 --> 00:09:49.020
That's okay, that's okay.
SINA&nbsp;

00:09:49.800 --> 00:09:53.340
So, in that context, you can&nbsp;
actually look at the health&nbsp;&nbsp;

00:09:53.340 --> 00:09:56.700
traits you care about and get proofs about the&nbsp;

00:09:56.700 --> 00:10:02.820
age of the person without actually&nbsp;
knowing anything else about the&nbsp;&nbsp;

00:10:02.820 --> 00:10:06.240
person. So, if you imagine a human
doing it, they may pull out files,&nbsp;&nbsp;

00:10:06.240 --> 00:10:11.400
they may see, for example, things like&nbsp;
the race, the name, the ethnicity,&nbsp;

00:10:12.000 --> 00:10:16.200
gender, and they may allow that to&nbsp;
affect their thinking. But in a,&nbsp;&nbsp;

00:10:16.200 --> 00:10:19.440
if you're having like a machine learning
context, where the only thing you want&nbsp;&nbsp;

00:10:19.440 --> 00:10:24.780
to do is isolate, sort of a scan&nbsp;
result and the date of birth, then&nbsp;

00:10:24.780 --> 00:10:28.260
you can actually have it only&nbsp;
prove that okay, here are the&nbsp;&nbsp;

00:10:28.260 --> 00:10:32.460
people who are over 21. And here's what's
happening and is there a correlation or&nbsp;&nbsp;

00:10:32.460 --> 00:10:35.400
is there not without actually&nbsp;
ever having to look at anything&nbsp;

00:10:35.400 --> 00:10:38.880
else? And so, in a way, you can&nbsp;
sort of think of it as helping&nbsp;&nbsp;

00:10:38.880 --> 00:10:45.720
to blind the learning, so that it doesn't
consider factors we don't want it to consider.&nbsp;

00:10:45.720 --> 00:10:50.340
CRAIG
Yeah. And the data in that case resides,&nbsp;&nbsp;

00:10:50.340 --> 00:10:52.491
say in our hospital database.
SINA&nbsp;

00:10:52.491 --> 00:10:53.400
3
Transcribed by https://otter.ai&nbsp;

00:10:53.400 --> 00:10:57.360
Well, so if you're talking about&nbsp;
a blockchain, you can actually put&nbsp;&nbsp;

00:10:57.360 --> 00:11:01.800
it literally on a blockchain and then it
can be it can be leveraged by hospitals,&nbsp;&nbsp;

00:11:01.800 --> 00:11:05.160
insurance companies, anything&nbsp;
except they won't actually have&nbsp;

00:11:05.160 --> 00:11:08.280
access to the personal underlying&nbsp;
information. So, it's a matter of how&nbsp;&nbsp;

00:11:08.280 --> 00:11:11.700
you structure the data. You can
have it the traditionally sort&nbsp;&nbsp;

00:11:11.700 --> 00:11:15.180
of be on a database where it's like&nbsp;
managed. In that case, you don't need a&nbsp;

00:11:15.180 --> 00:11:19.080
blockchain to accomplish anything that I'm talking&nbsp;
about at all. You can leverage something like zero&nbsp;

00:11:19.080 --> 00:11:21.660
knowledge proofs without a&nbsp;
blockchain. Or you can look at&nbsp;&nbsp;

00:11:21.660 --> 00:11:26.340
a world where you put it on a blockchain, it's
completely encrypted, which means that it's, no&nbsp;&nbsp;

00:11:26.340 --> 00:11:30.120
one can go to the blockchain and see your personal
information or this health risks are these&nbsp;&nbsp;

00:11:30.120 --> 00:11:34.560
health records. But you can't,&nbsp;
if you opt in, provide proofs of&nbsp;

00:11:34.560 --> 00:11:38.080
certain characteristics about&nbsp;
it, so that it can be studied. As&nbsp;&nbsp;

00:11:38.820 --> 00:11:44.280
a way of allowing your users to have a lot
more sovereignty over their data,&nbsp;&nbsp;

00:11:44.280 --> 00:11:48.600
what can you post, how can it be&nbsp;
exposed, and then you can, you can&nbsp;

00:11:48.600 --> 00:11:52.800
combine that with machine&nbsp;
learning to be more precise&nbsp;&nbsp;

00:11:52.800 --> 00:11:56.100
about what you're studying, and what you're
looking at, when you're looking at data sets,&nbsp;&nbsp;

00:11:56.100 --> 00:11:59.280
as opposed to allowing machine&nbsp;
learning to just go at it,&nbsp;

00:11:59.280 --> 00:12:05.280
come back with whatever it may come back with.&nbsp;
Because what we know already, is the data sets&nbsp;

00:12:05.280 --> 00:12:11.760
aren't totally neutral, they reflect human biases.&nbsp;
And we may allow, we may allow or permit machine&nbsp;

00:12:11.760 --> 00:12:15.780
learning algorithms to adopt&nbsp;
those human biases without&nbsp;&nbsp;

00:12:15.780 --> 00:12:20.160
even understanding that we're doing that. So,
this allows us to adopt more safeguards against&nbsp;&nbsp;

00:12:20.160 --> 00:12:21.030
something like that.
SINA&nbsp;

00:12:21.030 --> 00:12:28.800
Think of it as using encryption to obscure what&nbsp;
you're putting onto a database the same way your&nbsp;

00:12:28.800 --> 00:12:32.460
passwords are obscured. Same&nbsp;
way, all sorts of sensitive&nbsp;&nbsp;

00:12:32.460 --> 00:12:35.460
information is obscure, like your credit card
information, when you send it to the internet,&nbsp;&nbsp;

00:12:35.460 --> 00:12:38.340
you're not sending your literal&nbsp;
credit card information. It’s&nbsp;

00:12:38.340 --> 00:12:42.480
hashes so that if your data packet&nbsp;
is intercepted along the way,&nbsp;&nbsp;

00:12:42.480 --> 00:12:47.040
people don't actually have your credit
card number. So similarly, you can use encryption,&nbsp;&nbsp;

00:12:47.820 --> 00:12:51.300
to make data unavailable&nbsp;
to the general public that&nbsp;

00:12:51.300 --> 00:12:55.920
may try to look at that data.&nbsp;
But at the same time, if you&nbsp;&nbsp;

00:12:55.920 --> 00:13:02.820
put it on something like a Leo, you can prove
things about that data that are true or false,&nbsp;&nbsp;

00:13:02.820 --> 00:13:07.140
or that fall within certain&nbsp;
parameters. And leverage that&nbsp;

00:13:07.140 --> 00:13:12.300
data without actually giving away&nbsp;
identifying information. And you&nbsp;&nbsp;

00:13:12.300 --> 00:13:15.840
can tailor the parameters of that
however you like. It's totally&nbsp;&nbsp;

00:13:15.840 --> 00:13:20.940
an open design space. And so, this is&nbsp;
very new, it's very, very, very early.&nbsp;

00:13:22.200 --> 00:13:27.540
And it's kind of ripe for creative thinking, given&nbsp;
that you have this tool that allows you to upload&nbsp;

00:13:27.540 --> 00:13:31.980
information, protect that information&nbsp;
such that as with encryption,&nbsp;&nbsp;

00:13:32.700 --> 00:13:37.680
and yet be able to draw inferences
from it and understand facts and&nbsp;&nbsp;

00:13:37.680 --> 00:13:39.720
correlations from it.
SINA&nbsp;

00:13:39.720 --> 00:13:43.320
How do you best leverage this?&nbsp;
One of the interesting things? So,&nbsp;&nbsp;

00:13:43.320 --> 00:13:46.140
there are two things going on here.
There's the machine learning aspect, and there's&nbsp;&nbsp;

00:13:46.140 --> 00:13:52.320
a blockchain aspect. What's interesting about the
blockchain aspect is how it allows you to&nbsp;&nbsp;

00:13:52.320 --> 00:13:55.860
leverage something that doesn't&nbsp;
have to live on one platform.&nbsp;

00:13:56.520 --> 00:14:01.440
So, it's not just one hospital doing&nbsp;
this. Every hospital can put their&nbsp;&nbsp;

00:14:01.440 --> 00:14:05.940
data together in something like this.
And they can all benefit from all of&nbsp;&nbsp;

00:14:06.480 --> 00:14:12.060
the data that they're cumulatively&nbsp;
providing, without having to reveal&nbsp;

00:14:12.060 --> 00:14:16.200
anything about their patients the world without&nbsp;
having to compromise their patients privacy&nbsp;&nbsp;

00:14:16.800 --> 00:14:18.300
and getting
in with getting&nbsp;&nbsp;

00:14:18.300 --> 00:14:23.820
their patients consensus. And they can allow&nbsp;
their patients to retain ongoing sovereignty&nbsp;

00:14:23.820 --> 00:14:27.060
over this, which is the withdrawal&nbsp;
to do whatever they want to own their&nbsp;&nbsp;

00:14:27.060 --> 00:14:32.280
data. And so, thinking about
how a system like that enables&nbsp;&nbsp;

00:14:32.280 --> 00:14:37.200
better forms of machine learning, I&nbsp;
think is just a totally ripe design&nbsp;

00:14:37.200 --> 00:14:42.120
space not only for products just fill us&nbsp;
perfectly at the computer science level,&nbsp;&nbsp;

00:14:42.120 --> 00:14:44.580
at the at the level of
theory,&nbsp;&nbsp;

00:14:45.360 --> 00:14:50.640
and that level of like actual practice. It's&nbsp;
just totally new. And I think it's very,&nbsp;&nbsp;

00:14:50.640 --> 00:14:51.749
very exciting. That's
4&nbsp;

00:14:51.749 --> 00:14:55.020
Transcribed by https://otter.ai
just on the training part. There's&nbsp;&nbsp;

00:14:55.020 --> 00:15:01.140
a lot more that helps with effort&nbsp;
hinted at this with actually like the&nbsp;

00:15:01.140 --> 00:15:07.680
output, how you can help control&nbsp;
what factors are being looked at.&nbsp;

00:15:07.680 --> 00:15:08.700
SINA
And&nbsp;&nbsp;

00:15:08.700 --> 00:15:14.160
also, so take one of the products we're working&nbsp;
on that we think is a good use case for our&nbsp;

00:15:14.160 --> 00:15:19.260
blockchain, which is digital identity.&nbsp;
We allow through this product,&nbsp;&nbsp;

00:15:20.520 --> 00:15:24.540
folks to be able to upload facts about
their digital identity can be their&nbsp;&nbsp;

00:15:24.540 --> 00:15:28.800
passport and scan your passport&nbsp;
onto a blockchain. And then you can&nbsp;

00:15:28.800 --> 00:15:34.800
leverage that passport going forward&nbsp;
across platforms completely agnostic&nbsp;&nbsp;

00:15:34.800 --> 00:15:37.500
to the platform, which is say,
right now we all take for granted&nbsp;&nbsp;

00:15:37.500 --> 00:15:40.260
the status quo, if you go to Amazon,&nbsp;
you give them your information,&nbsp;

00:15:40.260 --> 00:15:43.740
you go to Walmart, you give them your information,&nbsp;
you go to some random website, you give them&nbsp;

00:15:43.740 --> 00:15:48.300
your information, but you could&nbsp;
actually just have passport grade,&nbsp;&nbsp;

00:15:48.300 --> 00:15:53.340
digital identification, that you leverage
at each of these websites without actually having&nbsp;&nbsp;

00:15:53.340 --> 00:15:57.000
to reveal much more about yourself, depending on
the website, depending on the nature of&nbsp;&nbsp;

00:15:57.000 --> 00:16:00.420
your relationship with that.&nbsp;
Now, combine that with what's&nbsp;

00:16:01.080 --> 00:16:05.760
going on in something like machine learning,&nbsp;
it doesn't have to just be your passport,&nbsp;&nbsp;

00:16:05.760 --> 00:16:07.140
it could be your
vaccine records,&nbsp;&nbsp;

00:16:07.140 --> 00:16:14.640
it could be anything. And then you can allow&nbsp;
machine learning to, to you can allow a&nbsp;

00:16:14.640 --> 00:16:19.680
more competitive machine learning landscape, which&nbsp;
is to say you can take that same data to multiple&nbsp;

00:16:19.680 --> 00:16:23.820
different algorithms and allow&nbsp;
them all to train and try to come&nbsp;&nbsp;

00:16:23.820 --> 00:16:29.340
up with something from it. As opposed to
having the data live on just Google or&nbsp;&nbsp;

00:16:29.340 --> 00:16:32.820
just Microsoft, we're one company,&nbsp;
we're all sort of relying on one&nbsp;

00:16:32.820 --> 00:16:35.760
company to do its best, but&nbsp;
that, and it's a much more&nbsp;&nbsp;

00:16:35.760 --> 00:16:40.440
open-source view of the world. It's a much more
competitive view of the world. You know, one of&nbsp;&nbsp;

00:16:40.440 --> 00:16:44.880
the troubling things when you look at AI is how
singular, it seems to feel, you know,&nbsp;&nbsp;

00:16:44.880 --> 00:16:49.980
one or two, or just a handful of&nbsp;
companies potentially can own the&nbsp;

00:16:49.980 --> 00:16:56.100
space because of their access to data. But if you&nbsp;
can open up that data in a way that is privacy&nbsp;

00:16:56.100 --> 00:17:00.900
preserving for the people who whose&nbsp;
data it is, then you can allow a&nbsp;&nbsp;

00:17:00.900 --> 00:17:04.260
lot more competition. And if you
sort of believe classical theory,&nbsp;&nbsp;

00:17:04.260 --> 00:17:09.540
competition is going to result in&nbsp;
better innovation, better products, and&nbsp;

00:17:09.540 --> 00:17:13.500
more responsiveness to the to the policy&nbsp;
concerns that many have raised around AI.&nbsp;

00:17:15.120 --> 00:17:18.180
CRAIG
Are you familiar with Oasis Labs?&nbsp;

00:17:18.180 --> 00:17:21.120
SINA
I've heard of them. Yeah. Yeah.&nbsp;

00:17:21.120 --> 00:17:25.200
CRAIG
Because it sounds similar. They have&nbsp;&nbsp;

00:17:25.800 --> 00:17:35.100
a combination of secure hardware and cryptography,
cryptographic techniques to allow&nbsp;&nbsp;

00:17:37.740 --> 00:17:44.580
privacy preserving computation on&nbsp;
the blockchain. But they have kind&nbsp;

00:17:44.580 --> 00:17:51.540
of a blend of, of strategies.&nbsp;
So, from for Aleo’s users,&nbsp;&nbsp;

00:17:55.560 --> 00:18:01.620
all of this happens through a web interface or
through an API. And&nbsp;&nbsp;

00:18:03.720 --> 00:18:09.180
does. Yeah, explain how it works.
SINA&nbsp;

00:18:09.180 --> 00:18:15.120
We're building an open-source protocol that we're&nbsp;
hoping to launch later this year. When this open-&nbsp;

00:18:15.120 --> 00:18:19.800
source protocol launches, are&nbsp;
our audience for that it's&nbsp;&nbsp;

00:18:19.800 --> 00:18:24.420
actually developers, it's people who build the
applications we're talking about. We're not, for&nbsp;&nbsp;

00:18:24.420 --> 00:18:30.960
example, building a healthcare application at the
moment. But I believe as people learn about&nbsp;&nbsp;

00:18:30.960 --> 00:18:33.660
what we're building, they'll&nbsp;
start to see the potential for&nbsp;

00:18:33.660 --> 00:18:38.100
things, the things that we're talking about,&nbsp;
which is okay, you can leverage this open&nbsp;&nbsp;

00:18:38.100 --> 00:18:38.909
source blockchain,
5&nbsp;

00:18:38.909 --> 00:18:40.380
Transcribed by https://otter.ai
and you can build an application&nbsp;&nbsp;

00:18:40.380 --> 00:18:45.360
on top of it, that uses that, for&nbsp;
example, funnels certain kinds of data,&nbsp;

00:18:45.360 --> 00:18:49.680
puts it on the blockchain in&nbsp;
a highly secure way, and then&nbsp;&nbsp;

00:18:49.680 --> 00:18:54.360
allows it to be leveraged going forward. And
one of the reasons I came up with healthcare is&nbsp;&nbsp;

00:18:55.080 --> 00:18:59.160
everyone kind of intuitively understands there's
something wrong with the way healthcare records&nbsp;&nbsp;

00:18:59.160 --> 00:19:04.380
work. You have your primary care physician, when
you're younger, maybe you move maybe they retire,&nbsp;&nbsp;

00:19:04.380 --> 00:19:07.080
it's very hard to get your&nbsp;
records. A lot of people&nbsp;

00:19:07.080 --> 00:19:09.660
don't know if they were vaccinated&nbsp;
when they were vaccinated,&nbsp;&nbsp;

00:19:09.660 --> 00:19:15.720
what they're vaccinated against. In that
environment to actually get together, okay, who is&nbsp;&nbsp;

00:19:15.720 --> 00:19:24.480
everyone who's had a screen for colon cancer? You
know, what are accuracy rates? Who's doing it&nbsp;&nbsp;

00:19:24.480 --> 00:19:30.300
better? It's very hard, but because the data is so
fragmented, and one of the reasons it's good for&nbsp;&nbsp;

00:19:30.300 --> 00:19:34.140
the data to be fragmented is because it's privacy
preserving, if at all, the doctor just said,&nbsp;&nbsp;

00:19:34.140 --> 00:19:36.780
Hey, everyone, here's the scan&nbsp;
for my latest patient, then then&nbsp;

00:19:36.780 --> 00:19:40.440
your information would be sort of&nbsp;
revealed to the whole world So that&nbsp;&nbsp;

00:19:40.440 --> 00:19:44.880
that's not an attractive sort of way
of creating machine learning,&nbsp;&nbsp;

00:19:44.880 --> 00:19:49.920
enabling that data. But what I'm talking&nbsp;
about, if there are developers out&nbsp;

00:19:49.920 --> 00:19:54.720
there listening to this, and they're thinking, Oh,&nbsp;
that's my wheelhouse. They're our audience because&nbsp;

00:19:54.720 --> 00:20:00.840
they should be building experimenting with how to&nbsp;
do this. And when I say this, I mean, create an&nbsp;

00:20:00.840 --> 00:20:04.500
application that allows you to&nbsp;
upload this specific kind of data,&nbsp;&nbsp;

00:20:04.500 --> 00:20:10.740
or any kind of health data allows you to
leverage it, and, and gives you the&nbsp;&nbsp;

00:20:10.740 --> 00:20:15.000
benefit of access to the data&nbsp;
without actually compromising any&nbsp;

00:20:15.000 --> 00:20:21.240
individual's personal information.
SINA&nbsp;

00:20:21.240 --> 00:20:24.600
In our laws aren't completely foreign&nbsp;
to this. Our census law, for example,&nbsp;&nbsp;

00:20:24.600 --> 00:20:29.820
allows the Census Bureau to
analyze data and to publish&nbsp;&nbsp;

00:20:29.820 --> 00:20:35.520
reports on that data, so long as it's&nbsp;
functionally anonymizing, which is to&nbsp;

00:20:35.520 --> 00:20:41.220
say, the nature of the publication&nbsp;
doesn't give away, it's not too so&nbsp;&nbsp;

00:20:41.220 --> 00:20:44.700
specific that it would give away who
it's talking about. Right. So,&nbsp;&nbsp;

00:20:44.700 --> 00:20:48.900
collecting data and preserving its&nbsp;
privacy while benefiting from it is not&nbsp;

00:20:48.900 --> 00:20:54.240
foreign to us. This is just a totally new&nbsp;
tool that I think is going to be really&nbsp;&nbsp;

00:20:54.240 --> 00:20:56.820
enhancing for the for the AI
and machine learning space.&nbsp;

00:20:56.820 --> 00:20:59.760
CRAIG
Yeah. And it's open source. So,&nbsp;&nbsp;

00:21:03.120 --> 00:21:11.880
the business plan for Aleo is to open&nbsp;
source it, get it widely adopted,&nbsp;

00:21:11.880 --> 00:21:20.340
and then offer sort of expert services&nbsp;
or consulting on specific applications.&nbsp;

00:21:20.340 --> 00:21:21.660
SINA
Exactly. Right. Yeah.&nbsp;

00:21:21.660 --> 00:21:23.160
CRAIG
Yeah. Who's&nbsp;&nbsp;

00:21:23.160 --> 00:21:27.960
the competition? I mean, are there other&nbsp;
open-source projects like this? I know, this has&nbsp;

00:21:27.960 --> 00:21:37.980
been an active space. I mentioned Oasis Labs.&nbsp;
I've had Dawn Song, who's the Berkeley professor&nbsp;

00:21:37.980 --> 00:21:47.940
behind it on the podcast. But I, frankly, haven't&nbsp;
looked at any of this for a long time. Is there a&nbsp;

00:21:47.940 --> 00:21:48.780
competition?
SINA&nbsp;

00:21:48.780 --> 00:21:53.400
I first of all, I think I would do terrible&nbsp;
injustice to all the really talented&nbsp;&nbsp;

00:21:53.400 --> 00:21:56.460
people out there working on this
from one angle or another. So,&nbsp;&nbsp;

00:21:56.460 --> 00:22:00.480
I would be reluctant sort of have a&nbsp;
list right now I don't think of it as a&nbsp;

00:22:00.480 --> 00:22:05.460
competitive space. What do I mean by that? I&nbsp;
sort of think of it as an innovative space where&nbsp;

00:22:05.460 --> 00:22:09.960
everyone's trying to build out what the&nbsp;
technology can enable at an infrastructure&nbsp;&nbsp;

00:22:09.960 --> 00:22:11.849
level. And then what's
6&nbsp;

00:22:11.849 --> 00:22:13.980
Transcribed by https://otter.ai
enabled on top of that is really,&nbsp;&nbsp;

00:22:13.980 --> 00:22:17.340
really incredible. And then that&nbsp;
sort of when competition kicks in. So&nbsp;

00:22:17.340 --> 00:22:19.500
now when I see other people&nbsp;
working in this space, I sort&nbsp;&nbsp;

00:22:19.500 --> 00:22:24.780
of view them as really important in a sense of
partners, because they're doing R&amp;D, they're doing&nbsp;&nbsp;

00:22:24.780 --> 00:22:29.640
the marketing. And the reality is like, there are
computer scientists, very smart computer science,&nbsp;&nbsp;

00:22:29.640 --> 00:22:35.100
like Dan Boneh over at Stanford, who know this
inside and out. But the world of developers,&nbsp;&nbsp;

00:22:35.760 --> 00:22:39.840
they're still they're still&nbsp;
learning about this. And so anyone&nbsp;

00:22:39.840 --> 00:22:44.220
kind of introducing these tools to&nbsp;
the world explaining these are tools&nbsp;&nbsp;

00:22:44.220 --> 00:22:47.580
you can use, I view as sort of a
partner, it's just too early to&nbsp;&nbsp;

00:22:47.580 --> 00:22:51.300
think of it sort of being like, who are&nbsp;
the competitors, you know, around the&nbsp;

00:22:51.300 --> 00:22:56.400
internet and the 1980s, like you could&nbsp;
conceptualize of competitors, but just a&nbsp;&nbsp;

00:22:56.400 --> 00:22:58.320
little too early to think of
the space that way.&nbsp;

00:22:59.220 --> 00:23:08.040
CRAIG
What is ZK ML? I see on your, on your website.&nbsp;

00:23:08.040 --> 00:23:09.540
SINA
Yes, this z k&nbsp;&nbsp;

00:23:09.540 --> 00:23:14.760
in our space is a common way of saying zero&nbsp;
knowledge, zero knowledge proof. So, this is&nbsp;

00:23:14.760 --> 00:23:17.040
your knowledge of machine&nbsp;
learning, which is a machine&nbsp;&nbsp;

00:23:17.040 --> 00:23:25.440
learning based on an algorithm that does not
have access to the underlying data can only&nbsp;&nbsp;

00:23:25.440 --> 00:23:27.660
draw inferences from it.
CRAIG&nbsp;

00:23:27.660 --> 00:23:34.260
Yeah. So where are you in the project right&nbsp;
now you say that it has not been launched&nbsp;&nbsp;

00:23:34.260 --> 00:23:36.060
are? Yeah, yeah,
SINA&nbsp;

00:23:36.060 --> 00:23:40.140
We're in the midst of our testnet&nbsp;
three. And so, we just opened up&nbsp;&nbsp;

00:23:40.140 --> 00:23:44.100
the ability to deploy applications. And
we've had many hundreds of applications&nbsp;&nbsp;

00:23:44.100 --> 00:23:48.840
deployed on our testnet. So far,&nbsp;
it's working really well. The&nbsp;

00:23:48.840 --> 00:23:52.620
point of our testnet is to identify&nbsp;
bugs to invite an open-source&nbsp;&nbsp;

00:23:52.620 --> 00:24:00.540
community to sort of begin the project of
making this a global open-source project as&nbsp;&nbsp;

00:24:00.540 --> 00:24:04.800
opposed to something that we own are particularly
important for.&nbsp;&nbsp;

00:24:05.820 --> 00:24:12.240
Because as you said, we'd like to pivot to&nbsp;
applications and enabling use cases on top of&nbsp;

00:24:12.240 --> 00:24:12.900
it.
CRAIG&nbsp;

00:24:12.900 --> 00:24:22.860
Yeah. And the is how wide is&nbsp;
or how large is your developer&nbsp;&nbsp;

00:24:23.640 --> 00:24:27.780
base right now, people that are
participating?&nbsp;

00:24:27.780 --> 00:24:29.100
SINA
Yeah, it's,&nbsp;&nbsp;

00:24:29.100 --> 00:24:33.000
you know, there are lots of different ways to&nbsp;
measure it. There's like the programs that are&nbsp;

00:24:33.000 --> 00:24:38.880
being deployed. There are the nodes that are&nbsp;
being run so many 1000s. Right now, what I find&nbsp;

00:24:38.880 --> 00:24:43.320
heartening is that At, there's a&nbsp;
very enthusiastic core group of&nbsp;&nbsp;

00:24:43.320 --> 00:24:49.260
folks thinking about zero knowledge on
our testnet on other in other projects,&nbsp;&nbsp;

00:24:49.260 --> 00:24:54.180
and that group seems to be getting&nbsp;
larger, and the contributors&nbsp;

00:24:54.180 --> 00:25:01.260
are increasing in what feels to be exponential&nbsp;
with exponential numbers. So, we're sort of very&nbsp;

00:25:01.260 --> 00:25:05.760
heartened by all the trends we're seeing there.&nbsp;
And then the number of people who are not computer&nbsp;

00:25:05.760 --> 00:25:09.240
scientists who are familiar with&nbsp;
zero knowledge proofs is increasing,&nbsp;&nbsp;

00:25:09.240 --> 00:25:14.160
the Treasury Department released
a report referencing them,&nbsp;&nbsp;

00:25:14.160 --> 00:25:18.120
the Office of Science and Technology&nbsp;
Policy at the White House is, is getting&nbsp;

00:25:18.120 --> 00:25:23.220
familiar with this technology. So, the&nbsp;
audience for this is growing really,&nbsp;&nbsp;

00:25:23.220 --> 00:25:24.749
really fast. And we're, we're
7&nbsp;

00:25:24.749 --> 00:25:26.580
Transcribed by https://otter.ai
very excited about that. And&nbsp;&nbsp;

00:25:26.580 --> 00:25:31.020
I think the machine is time for the&nbsp;
machine learning world to recognize the&nbsp;

00:25:31.020 --> 00:25:33.600
Venn diagram overlap here,&nbsp;
because it's very interesting.&nbsp;

00:25:33.600 --> 00:25:38.040
SINA
I mean, let me give you another way that this can&nbsp;&nbsp;

00:25:38.040 --> 00:25:47.160
be leveraged that I think intersects with machine
learning and, and the user experience online. So&nbsp;&nbsp;

00:25:47.160 --> 00:25:53.280
right now, if you go to Amazon or Walmart from the
United States, it through your IP address&nbsp;&nbsp;

00:25:53.280 --> 00:25:56.160
roughly knows not only you’re&nbsp;
in the United States, but like&nbsp;

00:25:56.160 --> 00:25:58.980
maybe what city you're in. And&nbsp;
maybe even more specific than that,&nbsp;&nbsp;

00:25:58.980 --> 00:26:02.160
and you don't think too much about
it. But the products that it shows you&nbsp;&nbsp;

00:26:02.160 --> 00:26:05.940
are a function of that. So, what's&nbsp;
available to you, given where you&nbsp;

00:26:05.940 --> 00:26:07.980
are. And if you went to France,&nbsp;
you have a slightly different&nbsp;&nbsp;

00:26:07.980 --> 00:26:10.680
experience. And if you went to another
country, maybe you have a very different&nbsp;&nbsp;

00:26:10.680 --> 00:26:14.400
experience or no experience at&nbsp;
all. So that's the sad theater&nbsp;

00:26:14.400 --> 00:26:16.380
currently.
SINA&nbsp;

00:26:17.340 --> 00:26:22.920
And by extension, any machine learning model on&nbsp;
top of that, understands where you are, and gives&nbsp;

00:26:22.920 --> 00:26:29.220
you an experience that's somewhat tailored&nbsp;
to that. We can also build it, so that let's&nbsp;&nbsp;

00:26:29.220 --> 00:26:31.260
just take the digital
identity concept.&nbsp;&nbsp;

00:26:32.340 --> 00:26:38.040
Amazon or Walmart, or the next website&nbsp;
would know that you're under 12, or under&nbsp;

00:26:38.040 --> 00:26:45.240
18, or over 21. And you wouldn't think too much&nbsp;
about it. But what's available changes, because&nbsp;

00:26:45.240 --> 00:26:49.200
alcohol on the website is certain&nbsp;
adult content on the website,&nbsp;&nbsp;

00:26:49.200 --> 00:26:53.340
or dangerous things on the website, you
know, things that 12-year-old shouldn't be playing&nbsp;&nbsp;

00:26:53.340 --> 00:26:59.940
with on the website. And as a result of machine,
machine learning that's built on top of that&nbsp;&nbsp;

00:26:59.940 --> 00:27:03.360
could also be leveraging that&nbsp;
information. Again, without&nbsp;

00:27:03.360 --> 00:27:08.880
knowing name, date of birth, anything&nbsp;
specific to the individual, just that,&nbsp;&nbsp;

00:27:08.880 --> 00:27:12.360
hey, it's maybe certain things
are age appropriate,&nbsp;&nbsp;

00:27:12.360 --> 00:27:17.640
maybe we don't want machine learning for&nbsp;
children of a certain age. Or maybe if&nbsp;

00:27:17.640 --> 00:27:21.240
we do want it, we want to tailor it a certain way&nbsp;
we have certain public policy goals that matter.&nbsp;

00:27:21.240 --> 00:27:23.340
SINA
So having&nbsp;&nbsp;

00:27:23.340 --> 00:27:27.780
credentials like this that can be leveraged and&nbsp;
that the entire internet would be responsive to&nbsp;

00:27:28.860 --> 00:27:33.480
has the trickle-down effect of&nbsp;
any sort of any sort of what&nbsp;&nbsp;

00:27:33.480 --> 00:27:38.220
I'll probably call machine learning on top of
that, sort of watching the user experience, seeing&nbsp;&nbsp;

00:27:38.220 --> 00:27:46.800
how the user interacts, would be sensitive to that
particular criterion. And so, you can imagine when&nbsp;&nbsp;

00:27:46.800 --> 00:27:52.560
you're thinking about TikTok or social media, this
could be very important, especially to parents.&nbsp;

00:27:54.120 --> 00:27:59.580
CRAIG
Yeah, it's, so that application relies on&nbsp;&nbsp;

00:28:00.660 --> 00:28:08.340
kind of the passport idea, the&nbsp;
ID, the ID, for an individual that&nbsp;

00:28:08.340 --> 00:28:18.300
then is accessed by whoever wants to access&nbsp;
that individual. I mean, how would that work?&nbsp;

00:28:18.300 --> 00:28:20.160
SINA
Yeah, so like,&nbsp;&nbsp;

00:28:20.160 --> 00:28:23.340
think about how it currently works, which is&nbsp;
you go to buy wine or website, they ask you&nbsp;

00:28:23.340 --> 00:28:25.920
are you 21, you click yes, that's the end of the,&nbsp;&nbsp;

00:28:25.920 --> 00:28:29.340
you know, at the end of the&nbsp;
questioning, which probably&nbsp;

00:28:29.340 --> 00:28:34.560
good enough security for wine, we probably don't&nbsp;
have an epidemic of minors ordering wine on&nbsp;

00:28:34.560 --> 00:28:39.960
websites, but where you have greater concerns,&nbsp;
maybe you want something more than just data that&nbsp;

00:28:39.960 --> 00:28:43.260
the individual can arbitrarily&nbsp;
input. You know, they know they&nbsp;&nbsp;

00:28:43.260 --> 00:28:46.860
just need to pick something that says
they're over 18 or 21. We'll just&nbsp;&nbsp;

00:28:46.860 --> 00:28:51.360
pick it. And so, you can have a lot of&nbsp;
fake identities. I mean, this applies&nbsp;

00:28:51.360 --> 00:28:55.560
in so many contexts. By the way, Craig, if you&nbsp;
look over at like ticket sales, something like&nbsp;&nbsp;

00:28:55.560 --> 00:28:57.389
40% of ticket
8&nbsp;

00:28:57.389 --> 00:28:59.820
Transcribed by https://otter.ai
sales are sold to bots. So put&nbsp;&nbsp;

00:28:59.820 --> 00:29:03.360
aside a human lying about itself. It's&nbsp;
just like, something that's trained to&nbsp;

00:29:03.360 --> 00:29:10.560
lie to the actual, to the actual&nbsp;
merchants, you can replace that with&nbsp;&nbsp;

00:29:10.560 --> 00:29:14.760
something where you have to get
passport grade identification,&nbsp;&nbsp;

00:29:14.760 --> 00:29:18.360
which can’t be faked, digitally&nbsp;
signed by the US government can be&nbsp;

00:29:18.360 --> 00:29:20.700
authenticated against the US government database.&nbsp;&nbsp;

00:29:21.300 --> 00:29:28.500
And that would be the identifying credential. And
so, the ability of a child to suggest or over&nbsp;&nbsp;

00:29:28.500 --> 00:29:32.820
21 or the ability of someone to&nbsp;
suggest their US citizen when&nbsp;

00:29:32.820 --> 00:29:38.100
in fact they're, you know, a North&nbsp;
Korean citizen. I think it limits&nbsp;&nbsp;

00:29:38.100 --> 00:29:42.720
that very significantly because as you're
talking about passport grade security,&nbsp;&nbsp;

00:29:42.720 --> 00:29:45.720
where some of these websites just&nbsp;
have, you know, click through&nbsp;

00:29:45.720 --> 00:29:47.400
your 21.
CRAIG&nbsp;

00:29:47.400 --> 00:29:57.720
And to develop that. And that that there would&nbsp;
be a key or something that someone would use&nbsp;

00:29:57.720 --> 00:29:59.160
SINA
maybe a combination&nbsp;&nbsp;

00:29:59.160 --> 00:30:05.220
of a private key, which is specifically the&nbsp;
individual. And LiveScan, which is to say&nbsp;

00:30:05.220 --> 00:30:08.940
something to so if I had&nbsp;
your private key, you know,&nbsp;&nbsp;

00:30:08.940 --> 00:30:13.860
the LiveScan would show actually, it's not Craig,
even though he has Craig's private key. And in the&nbsp;&nbsp;

00:30:13.860 --> 00:30:18.180
case of parents, you can imagine introducing multi
party computation or other things,&nbsp;&nbsp;

00:30:18.180 --> 00:30:23.160
so that maybe there even two or&nbsp;
three keys are necessary for login,&nbsp;

00:30:23.160 --> 00:30:25.440
it's just a matter of how you&nbsp;
again, it's open design space,&nbsp;&nbsp;

00:30:25.440 --> 00:30:31.440
it's how you want to design it. But this is
introducing the ability to have one,&nbsp;&nbsp;

00:30:31.440 --> 00:30:35.820
digital identification that is&nbsp;
passed per grade across all of these&nbsp;

00:30:35.820 --> 00:30:39.360
websites, as opposed to you go to TikTok,&nbsp;
you share your passport information&nbsp;&nbsp;

00:30:39.360 --> 00:30:41.160
with them, you go to,
you know, Instagram,&nbsp;&nbsp;

00:30:41.160 --> 00:30:45.120
you share your password, sharing your&nbsp;
passport information with everyone. And&nbsp;

00:30:45.120 --> 00:30:49.860
by the way, none of these websites really want&nbsp;
to be responsible for collecting that kind of&nbsp;&nbsp;

00:30:49.860 --> 00:30:50.700
information.
Right.&nbsp;

00:30:50.700 --> 00:30:52.260
SINA
Now, on the other side of it,&nbsp;&nbsp;

00:30:52.260 --> 00:30:56.580
what's I think particularly interesting&nbsp;
for policymakers and for and for a lot&nbsp;

00:30:56.580 --> 00:30:59.820
of parents out there is that once&nbsp;
you introduce technology like this,&nbsp;&nbsp;

00:31:01.560 --> 00:31:06.000
the excuse for, for example, a
website that has like adult&nbsp;&nbsp;

00:31:06.000 --> 00:31:10.200
content to not be screening out minors&nbsp;
goes down very, very significantly,&nbsp;

00:31:10.200 --> 00:31:13.200
they can't say, oh, we didn't&nbsp;
know they tricked us, it's,&nbsp;&nbsp;

00:31:13.200 --> 00:31:21.000
you have a way to figure this out. Right. And that
also applies to anyone collecting data, which is&nbsp;&nbsp;

00:31:21.000 --> 00:31:25.980
to say their excuse for holding your data in this
honeypot that hackers find very attractive&nbsp;&nbsp;

00:31:25.980 --> 00:31:29.580
goes down. Once you introduce&nbsp;
technology like this, that's no&nbsp;

00:31:29.580 --> 00:31:33.480
longer necessary. Now let's go over to&nbsp;
like AI what we're specifically talking&nbsp;&nbsp;

00:31:33.480 --> 00:31:35.820
about. Right now, when we
talk about data privacy,&nbsp;&nbsp;

00:31:35.820 --> 00:31:40.260
it's typically sort of privacy policy, you&nbsp;
know, long scroll down thing about what&nbsp;

00:31:40.260 --> 00:31:42.660
they're going to do with your&nbsp;
data that many people don't read&nbsp;&nbsp;

00:31:42.660 --> 00:31:46.500
the click through, they move on. But you
can start introducing data minimization,&nbsp;&nbsp;

00:31:46.500 --> 00:31:50.820
again, not foreign to the Census&nbsp;
Bureau. And it's just a concept&nbsp;

00:31:50.820 --> 00:31:57.900
that says, you have to use a reasonably available&nbsp;
technologies to minimize your, your what you're&nbsp;

00:31:57.900 --> 00:32:01.020
doing with people's privacy,&nbsp;
right. And in many contexts,&nbsp;&nbsp;

00:32:01.020 --> 00:32:03.900
I think that's going to be very attractive, it's
going to be attractive from a product design&nbsp;&nbsp;

00:32:03.900 --> 00:32:06.780
perspective, which is to say&nbsp;
you even if policymaker said&nbsp;

00:32:06.780 --> 00:32:12.360
nothing about it, users may have preferences.&nbsp;
But from the perspective of policymakers who,&nbsp;&nbsp;

00:32:13.200 --> 00:32:13.800
you know,&nbsp;

00:32:13.800 --> 00:32:19.440
in at least western values, we&nbsp;
care a lot about people's privacy,&nbsp;&nbsp;

00:32:19.440 --> 00:32:23.520
what that means for their dignity. And
so, we are not going to have like our&nbsp;&nbsp;

00:32:23.520 --> 00:32:26.280
government go and collect everyone's&nbsp;
data and like, feed it into&nbsp;

00:32:26.280 --> 00:32:30.720
some sort of machine learning exercise. We were&nbsp;
maybe other countries would do that, but we&nbsp;

00:32:30.720 --> 00:32:33.540
wouldn't. Now, this is a very&nbsp;
interesting way of saying, okay,&nbsp;&nbsp;

00:32:33.540 --> 00:32:37.320
well, we can continue with the machine
learning, we can actually pioneer this&nbsp;&nbsp;

00:32:37.320 --> 00:32:41.040
technology, but we don't have to&nbsp;
invade people's privacy to do it.&nbsp;

00:32:42.480 --> 00:32:43.770
9
Transcribed by https://otter.ai&nbsp;

00:32:43.770 --> 00:32:46.020
CRAIG
What is it going to take for,&nbsp;&nbsp;

00:32:46.560 --> 00:32:48.960
for widespread adoption,&nbsp;&nbsp;

00:32:49.800 --> 00:32:56.880
which is always the case with these things? I
mean, I've, I've listened to so many&nbsp;&nbsp;

00:32:59.040 --> 00:33:07.860
ideas or proposals that sound great,&nbsp;
but until you reach the tipping&nbsp;

00:33:07.860 --> 00:33:17.820
point where it's widespread, and generally&nbsp;
accepted, it remains kind of a niche.&nbsp;

00:33:17.820 --> 00:33:19.020
SINA
Yeah, I think that's&nbsp;&nbsp;

00:33:19.020 --> 00:33:22.500
completely right. And there's a difference&nbsp;
between having theoretical conversations&nbsp;

00:33:22.500 --> 00:33:28.020
and comprehend, and actual solutions&nbsp;
that are adopted in practice. If you&nbsp;&nbsp;

00:33:28.020 --> 00:33:29.940
look at zero knowledge,
proof, there were invented&nbsp;&nbsp;

00:33:29.940 --> 00:33:35.520
as a concept in the 1980s, five, six&nbsp;
years ago, the time it took to do one&nbsp;

00:33:35.520 --> 00:33:40.980
transaction for zero knowledge proof orders of&nbsp;
magnitude slower than today. That's a result of&nbsp;

00:33:40.980 --> 00:33:44.580
investment in R&amp;D that's happening&nbsp;
in the United States and happening&nbsp;&nbsp;

00:33:44.580 --> 00:33:48.240
globally. And that time is going
down. And it's scaling better and&nbsp;&nbsp;

00:33:48.240 --> 00:33:52.080
better and better and faster. And&nbsp;
what happens with these systems is&nbsp;

00:33:54.660 --> 00:33:57.660
as we get better at doing it on&nbsp;
the software side, we can actually&nbsp;&nbsp;

00:33:57.660 --> 00:34:01.500
specialize hardware to do it faster and
faster and optimized at the hardware&nbsp;&nbsp;

00:34:01.500 --> 00:34:04.500
side. And that's what that's the&nbsp;
transition from having something&nbsp;

00:34:04.500 --> 00:34:08.040
like a CPU to the GPU to even&nbsp;
in certain circumstances,&nbsp;&nbsp;

00:34:08.040 --> 00:34:14.040
an application specific integrated circuit, which
does one thing but does it very, very fast and&nbsp;&nbsp;

00:34:14.040 --> 00:34:15.030
optimized, right.
SINA&nbsp;

00:34:15.030 --> 00:34:20.940
So that starts to make this practical&nbsp;
for large scale uses, like whether&nbsp;&nbsp;

00:34:20.940 --> 00:34:25.020
it's credit card data, or health
records, that kind of thing. So,&nbsp;&nbsp;

00:34:25.020 --> 00:34:28.920
we're getting closer and closer to&nbsp;
technologically of being there. So, if&nbsp;

00:34:28.920 --> 00:34:31.920
you think about the internet, when&nbsp;
it first starts and it sort of dial&nbsp;&nbsp;

00:34:31.920 --> 00:34:36.000
up and it's very, very slow, and we
could talk about video streaming in&nbsp;&nbsp;

00:34:36.000 --> 00:34:40.800
that in that in those days, but it's&nbsp;
you have to get faster and the way&nbsp;

00:34:40.800 --> 00:34:43.140
it gets faster is more investment. And&nbsp;
the way to get more investment is to get&nbsp;&nbsp;

00:34:43.140 --> 00:34:47.040
more excited about what
it's actually capable of.&nbsp;&nbsp;

00:34:47.040 --> 00:34:51.180
So, I think what to answer your question,&nbsp;
what it takes is more people learning&nbsp;

00:34:51.180 --> 00:34:55.080
about the potential here, more people&nbsp;
experimenting in the design space,&nbsp;&nbsp;

00:34:55.860 --> 00:34:58.740
support from the government
in terms of R&amp;D, and around&nbsp;&nbsp;

00:34:58.740 --> 00:35:03.240
privacy enhancing technologies as&nbsp;
a way to enhance how we do AI, AI&nbsp;

00:35:03.240 --> 00:35:07.800
and machine learning. And just&nbsp;
more experimentation, as I said,&nbsp;&nbsp;

00:35:09.060 --> 00:35:13.560
that will, if this design space proves
itself out, and I think it will,&nbsp;&nbsp;

00:35:15.000 --> 00:35:19.740
encourage more investment, and you'll&nbsp;
see it scale better and faster.&nbsp;

00:35:19.740 --> 00:35:22.140
SINA
So, from my perspective, when people talk about&nbsp;&nbsp;

00:35:23.100 --> 00:35:30.000
something like blockchain, we've long been in that
like 1970s, to 1980s era for the Internet,&nbsp;&nbsp;

00:35:30.000 --> 00:35:33.600
which is the concepts have been&nbsp;
introduced. There's this new&nbsp;

00:35:33.600 --> 00:35:38.040
and interesting thing we can do.&nbsp;
But it's not quite practical yet.&nbsp;&nbsp;

00:35:38.040 --> 00:35:42.780
And we're getting closer. And the only
distinction between in my mind between&nbsp;&nbsp;

00:35:42.780 --> 00:35:46.500
the timeline for the Internet and&nbsp;
the timeline for something like&nbsp;

00:35:46.500 --> 00:35:51.600
blockchain technology is open-source systems tend&nbsp;
to have a lot more eyes on them, and they tend to&nbsp;

00:35:51.600 --> 00:35:54.720
move a little bit faster, right.&nbsp;
So, it's not a small group of&nbsp;&nbsp;

00:35:54.720 --> 00:36:00.900
resources are doing it anyone can open up the
coins code or the next projects code and learn&nbsp;&nbsp;

00:36:00.900 --> 00:36:03.520
from it and build on it.
CRAIG&nbsp;

00:36:04.200 --> 00:36:11.640
Yeah. Has the government expressed interest in&nbsp;
this? Or are you working with any government&nbsp;

00:36:11.640 --> 00:36:17.520
agencies to include them in the open-source&nbsp;&nbsp;

00:36:18.120 --> 00:36:18.738
project?
SINA&nbsp;

00:36:18.738 --> 00:36:19.500
10
Transcribed by https://otter.ai&nbsp;

00:36:19.500 --> 00:36:23.040
Yeah, so the White House Office&nbsp;
of Science and Technology&nbsp;&nbsp;

00:36:23.040 --> 00:36:28.440
Policy invited comment letters earlier this
year on privacy enhancing technologies generally.&nbsp;&nbsp;

00:36:29.520 --> 00:36:36.180
We issued a comment letter in response to that.
There's a lot of interest on the Hill in terms of&nbsp;&nbsp;

00:36:36.180 --> 00:36:39.480
privacy enhancing technologies,&nbsp;
especially as it relates to&nbsp;

00:36:39.480 --> 00:36:43.380
machine learning. There's a lot of&nbsp;
interest around digital identity,&nbsp;&nbsp;

00:36:43.380 --> 00:36:47.700
I think people understand that we can
do identity better, we can do it in a&nbsp;&nbsp;

00:36:47.700 --> 00:36:52.260
way that increases compliance that&nbsp;
increases reliability and also&nbsp;

00:36:52.260 --> 00:36:56.100
increases privacy, which is kind of&nbsp;
an interesting combination. Usually,&nbsp;&nbsp;

00:36:56.100 --> 00:36:59.880
those concepts are seen as in
tension as it relates to blockchain.&nbsp;&nbsp;

00:36:59.880 --> 00:37:03.060
Generally, I think we've been a&nbsp;
little bit tripped up on threshold&nbsp;

00:37:03.060 --> 00:37:06.120
questions about, you know,&nbsp;
whether a particular token&nbsp;&nbsp;

00:37:06.120 --> 00:37:10.920
is a security or not a security, there are these
open regulatory questions that I have confidence&nbsp;&nbsp;

00:37:10.920 --> 00:37:13.740
will resolve over time.
SINA&nbsp;

00:37:14.520 --> 00:37:20.940
And I think, especially as it relates&nbsp;
to crypto, there's been a lot of&nbsp;&nbsp;

00:37:22.680 --> 00:37:27.480
focus on the asset itself, because it's
invited this speculative, like&nbsp;&nbsp;

00:37:27.480 --> 00:37:30.540
speculative frenzy around the value&nbsp;
of something, everyone's heard some&nbsp;

00:37:30.540 --> 00:37:34.860
story about how somebody got very rich&nbsp;
off of a Bitcoin or the, you know,&nbsp;&nbsp;

00:37:34.860 --> 00:37:37.740
Dogecoin, or the next thing.
And so, a lot of the social&nbsp;&nbsp;

00:37:37.740 --> 00:37:41.760
commentary has been around those asset&nbsp;
values. But one of the insights that&nbsp;

00:37:41.760 --> 00:37:46.680
we had is, if you look at Bitcoin,&nbsp;
for example, it's not just a ledger,&nbsp;&nbsp;

00:37:46.680 --> 00:37:50.820
for Bitcoin, it's a ledger for identity,
each one of those public addresses&nbsp;&nbsp;

00:37:50.820 --> 00:37:55.020
is an implied identity. Now, it's&nbsp;
transparent, which means once they&nbsp;

00:37:55.020 --> 00:37:58.500
once anyone figures out, you know,&nbsp;
that it's your address, don't know,&nbsp;&nbsp;

00:37:58.500 --> 00:38:01.440
your whole transaction history is
not really workable for a lot of&nbsp;&nbsp;

00:38:01.440 --> 00:38:05.040
the ledger uses we've talked about. But&nbsp;
if you add a little bit of privacy to&nbsp;

00:38:05.040 --> 00:38:08.940
that, you can actually add a lot&nbsp;
of meat to what the identity holds,&nbsp;&nbsp;

00:38:09.720 --> 00:38:13.320
and what it says and how it can be
leveraged. And so those are the&nbsp;&nbsp;

00:38:13.320 --> 00:38:18.060
insights, I think that will take this&nbsp;
technology to the next level. And I&nbsp;

00:38:18.060 --> 00:38:20.640
think everyone's very interested&nbsp;
in that. And they should be.&nbsp;

00:38:20.640 --> 00:38:26.160
CRAIG
how does this project intersect with the web 3.0?&nbsp;&nbsp;

00:38:27.780 --> 00:38:28.500
Or web three?
SINA&nbsp;

00:38:28.500 --> 00:38:36.780
Yeah. If I if I understand the term web&nbsp;
three, charitably, I think what it's&nbsp;&nbsp;

00:38:36.780 --> 00:38:43.380
getting at is the ability for nodes,
i.e., computers on the internet,&nbsp;&nbsp;

00:38:43.380 --> 00:38:49.320
to hold and transfer digital assets.&nbsp;
In the past, when we think about that,&nbsp;

00:38:49.320 --> 00:38:53.160
we sort of had this copy paste problem&nbsp;
that's required an intermediary&nbsp;&nbsp;

00:38:53.160 --> 00:38:57.180
which just say, take music. If I
have a song, and I sell you the song,&nbsp;&nbsp;

00:38:57.180 --> 00:39:01.110
I can just copy paste it locally&nbsp;
and sell you the song. And so there&nbsp;

00:39:01.110 --> 00:39:05.820
now there's two of them, and then the&nbsp;
value of the music plummets because&nbsp;&nbsp;

00:39:05.820 --> 00:39:11.760
there's infinite supply. And
one of the things that Bitcoin&nbsp;&nbsp;

00:39:11.760 --> 00:39:19.200
did is actually come up with a way to&nbsp;
enforce scarcity without requiring an&nbsp;

00:39:19.200 --> 00:39:22.260
intermediary, kind of to own&nbsp;
all of that, because once you&nbsp;&nbsp;

00:39:22.260 --> 00:39:26.760
introduce an intermediary to own all that, if
you take, for example, health records, they become&nbsp;&nbsp;

00:39:26.760 --> 00:39:31.800
a very powerful, almost monopoly. That is the
owner of records that you don't want them&nbsp;&nbsp;

00:39:31.800 --> 00:39:37.980
necessarily to write. So insofar&nbsp;
as web three references the&nbsp;

00:39:37.980 --> 00:39:44.160
ability of like nodes, to own assets&nbsp;
transfer assets, were very much&nbsp;&nbsp;

00:39:44.160 --> 00:39:49.080
sort of within that definition, in that
this would be a decentralized open-source&nbsp;&nbsp;

00:39:49.080 --> 00:39:55.860
project that allows hospitals&nbsp;
or anyone to build on top of it&nbsp;

00:39:55.860 --> 00:40:03.000
something where credentials and assets can be&nbsp;
moved around and leveraged without necessarily&nbsp;

00:40:03.000 --> 00:40:05.520
needing any particular intermediary.
CRAIG&nbsp;

00:40:07.680 --> 00:40:12.900
So, let's presume that this&nbsp;
becomes widely adopted.&nbsp;&nbsp;

00:40:15.060 --> 00:40:23.160
From a consumers point of view for the ID, what
would I have to do to get my&nbsp;&nbsp;

00:40:24.060 --> 00:40:29.301
ID key and then use it on various websites?&nbsp;

00:40:29.301 --> 00:40:29.334
11
Transcribed by https://otter.ai&nbsp;

00:40:29.334 --> 00:40:30.600
SINA
Yeah, so,&nbsp;&nbsp;

00:40:31.140 --> 00:40:38.700
if this is adopted, the consumer could use their&nbsp;
phone to scan their passport. Your passport&nbsp;

00:40:38.700 --> 00:40:43.740
has a chip that allows it to be to be&nbsp;
scanned, so you can scan and upload&nbsp;&nbsp;

00:40:43.740 --> 00:40:48.240
all your information onto one
for like, let's just say there's&nbsp;&nbsp;

00:40:48.240 --> 00:40:53.760
a project emerging. It's called like&nbsp;
Aleo ID. You can upload it through Aleo&nbsp;

00:40:53.760 --> 00:41:01.140
ID, and then that project Aleo ID would have&nbsp;
to go to, you know, the ecommerce websites, the&nbsp;

00:41:02.760 --> 00:41:09.120
wherever and have them integrate so that&nbsp;
when the user shows up to the website,&nbsp;&nbsp;

00:41:11.280 --> 00:41:15.900
that underlying ID is
leveraged, for example,&nbsp;&nbsp;

00:41:15.900 --> 00:41:19.560
to make sure that content is age appropriate.
CRAIG&nbsp;

00:41:19.560 --> 00:41:25.980
So that would require the open-source&nbsp;
project and I presume there's a&nbsp;&nbsp;

00:41:25.980 --> 00:41:31.440
there's a foundation in addition
to the private company, is that right?&nbsp;

00:41:31.440 --> 00:41:32.400
SINA
Yeah, yeah,&nbsp;&nbsp;

00:41:32.400 --> 00:41:38.580
so imagine there's the open-source project,&nbsp;
that's just the layer that exists, then a team&nbsp;

00:41:38.580 --> 00:41:42.060
would come a company would come, it&nbsp;
could be for profit, it could be just,&nbsp;&nbsp;

00:41:42.060 --> 00:41:44.220
it could be do nonprofit could
be the government.&nbsp;&nbsp;

00:41:45.480 --> 00:41:50.640
And they would build an interface that&nbsp;
allows people to say, okay, we're going to&nbsp;

00:41:50.640 --> 00:41:56.040
scan our passports onto the blockchain.&nbsp;
And then that company would go to&nbsp;&nbsp;

00:41:57.120 --> 00:42:01.560
whoever, Amazon or a
gaming company, right,&nbsp;&nbsp;

00:42:01.560 --> 00:42:04.260
these are the gaming companies and&nbsp;
say, okay, the amount of bloodshed or&nbsp;

00:42:04.260 --> 00:42:07.920
violence or whatever should&nbsp;
be limited for this age group,&nbsp;&nbsp;

00:42:07.920 --> 00:42:14.160
or certain games can't be downloaded by this
age group. And so when you go to that website the&nbsp;&nbsp;

00:42:14.160 --> 00:42:18.360
same way, for example, you have single sign on
with like Google or anything, or just you can&nbsp;&nbsp;

00:42:18.360 --> 00:42:21.360
even do it as like a the way&nbsp;
IP addresses work, which is,&nbsp;

00:42:21.360 --> 00:42:28.020
the user doesn't need to experience anything, you&nbsp;
can just go to the website, leverage that those&nbsp;

00:42:28.020 --> 00:42:31.320
credentials, and then get the&nbsp;
appropriate experience based&nbsp;&nbsp;

00:42:31.320 --> 00:42:35.100
on his credentials without ever touching the
website, again, hey, I'm Craig, I'm this age,&nbsp;&nbsp;

00:42:35.100 --> 00:42:40.680
or, Hey, I'm Sina, you know,&nbsp;
this gender, or this country of&nbsp;

00:42:40.680 --> 00:42:44.340
origin, the other things that&nbsp;
are on your passport. So, like,&nbsp;&nbsp;

00:42:44.340 --> 00:42:49.560
just to take us like a simple analogy, sort of
visualize what this looks like, in the real world,&nbsp;&nbsp;

00:42:50.700 --> 00:42:53.460
you go to an event, and&nbsp;
you're on the you're on the&nbsp;

00:42:53.460 --> 00:42:57.420
guest list, and they give you a&nbsp;
wristband, and the wristband indicates,&nbsp;&nbsp;

00:42:57.420 --> 00:43:00.600
for example, you're over 21, and
you're on the, on the guest list.&nbsp;&nbsp;

00:43:00.600 --> 00:43:05.880
The bartender never asked for your&nbsp;
ID in that context, they just know&nbsp;

00:43:05.880 --> 00:43:09.660
from your wristband that&nbsp;
you belong there, and that&nbsp;&nbsp;

00:43:09.660 --> 00:43:15.660
you're over 21, without the wristband, you would
show the bartender who you don't know, your name,&nbsp;&nbsp;

00:43:15.660 --> 00:43:23.040
your address, your date of birth, the issuance,
issuing state of your ID, all this all this&nbsp;&nbsp;

00:43:23.040 --> 00:43:25.920
information has nothing to do&nbsp;
with you getting a drink at an&nbsp;

00:43:25.920 --> 00:43:29.880
event. And so, this is kind&nbsp;
of like a digital wristband,&nbsp;&nbsp;

00:43:29.880 --> 00:43:37.920
where when you show up, the experience is
tailored based on who you are without actually&nbsp;&nbsp;

00:43:37.920 --> 00:43:40.800
having to reveal who you are to your counterparty.
CRAIG&nbsp;

00:43:40.800 --> 00:43:49.380
Right. And the and when you say you show up in the&nbsp;
physical case, you're wearing a wristband, in this&nbsp;

00:43:49.380 --> 00:43:58.380
case, it's this key that represents&nbsp;
your identity on the blockchain,&nbsp;&nbsp;

00:43:59.100 --> 00:44:04.680
you would enter that when you're
registering with the website, or would that be&nbsp;&nbsp;

00:44:04.680 --> 00:44:07.680
tied to your I don't know your IP address?
SINA&nbsp;

00:44:07.680 --> 00:44:10.980
Three are a couple of ways to do this.&nbsp;
I mean, it could be tied to your actual&nbsp;&nbsp;

00:44:10.980 --> 00:44:12.840
particular device. So, you
sign into your device,&nbsp;&nbsp;

00:44:12.840 --> 00:44:17.040
right with your with your face scan, and&nbsp;
it could automatically leverage those&nbsp;

00:44:17.040 --> 00:44:21.420
credentials. It could be on a per website&nbsp;
basis, the way you do Google single sign on.&nbsp;&nbsp;

00:44:22.440 --> 00:44:22.949
There are a lot of
12&nbsp;

00:44:22.949 --> 00:44:24.660
Transcribed by https://otter.ai
them again, it's very early as to&nbsp;&nbsp;

00:44:24.660 --> 00:44:29.100
I think it's too early to predict what&nbsp;
the winning product looks like. But&nbsp;

00:44:29.100 --> 00:44:32.640
from the user's experience, I would&nbsp;
hope that product is seamless.&nbsp;&nbsp;

00:44:32.640 --> 00:44:35.340
I would hope it protects their
privacy, and I hope that it would&nbsp;&nbsp;

00:44:35.340 --> 00:44:41.160
help them have an experience online&nbsp;
that's appropriate. especially for&nbsp;

00:44:41.160 --> 00:44:44.100
their age, you know, look, again,&nbsp;
nine-year-olds on the internet,&nbsp;&nbsp;

00:44:44.100 --> 00:44:48.780
different experience and 40-year-olds
on the internet. And I think those are&nbsp;&nbsp;

00:44:48.780 --> 00:44:51.900
things that we can build in reliably&nbsp;
now. And the old excuses about&nbsp;

00:44:51.900 --> 00:44:56.580
well, it's impossible to verify age, or it's&nbsp;
prohibitive to those I think are going to&nbsp;&nbsp;

00:44:56.580 --> 00:44:57.360
fade away.
SINA&nbsp;

00:44:57.360 --> 00:45:01.440
And I also hope that what it&nbsp;
means is, the days of us giving&nbsp;&nbsp;

00:45:01.440 --> 00:45:06.300
away our addresses and our dates of birth
and other personal information to hundreds&nbsp;&nbsp;

00:45:06.300 --> 00:45:11.880
of websites, none of which exists because they're
particularly good at security, they're ecommerce,&nbsp;&nbsp;

00:45:11.880 --> 00:45:14.220
they have different missions, their mission is not
security,&nbsp;&nbsp;

00:45:15.600 --> 00:45:22.020
and exposing ourselves in these centralized honey&nbsp;
pots all across the internet, just to have an&nbsp;

00:45:22.020 --> 00:45:27.060
internet experience, I hope that we can&nbsp;
look back soon. And see that for what it is,&nbsp;&nbsp;

00:45:27.060 --> 00:45:28.920
which is a security
nightmare&nbsp;&nbsp;

00:45:29.940 --> 00:45:34.920
that compromises the user experience in totally&nbsp;
unacceptable ways. I mean, when is the last&nbsp;

00:45:34.920 --> 00:45:40.680
time anyone even had an emotional response to&nbsp;
a major hack? We've had OPM hacked we've had&nbsp;

00:45:41.460 --> 00:45:47.580
those who keep our credit scores hacked, you know,&nbsp;
that says, as much data as you could possibly&nbsp;

00:45:47.580 --> 00:45:52.500
want from the perspective of a hacker,&nbsp;
and much of this is needlessly kept.&nbsp;

00:45:52.500 --> 00:45:57.480
CRAIG
Yeah, yeah. And then from the point of view of&nbsp;&nbsp;

00:45:58.560 --> 00:46:03.600
like a hospital that has a lot&nbsp;
of data that wants to make it&nbsp;

00:46:03.600 --> 00:46:09.120
available to a machine-to-machine&nbsp;
learning, training exercise.&nbsp;&nbsp;

00:46:10.500 --> 00:46:16.380
They would, there would be some,&nbsp;

00:46:16.380 --> 00:46:17.760
SINA
You can&nbsp;&nbsp;

00:46:17.760 --> 00:46:22.680
build a mechanism that allows you to do that.&nbsp;
And what I really like about this is that the&nbsp;

00:46:22.680 --> 00:46:30.300
mechanism can be agnostic to the machine learning&nbsp;
counterparty, right now, we sort of built a system&nbsp;

00:46:30.300 --> 00:46:37.380
that rewards monopolistic or oligopolistic and&nbsp;
says that they can go, and they can go and do the&nbsp;

00:46:37.380 --> 00:46:42.600
paperwork of collecting the data. And then&nbsp;
they're the only ones who have a stab at this.&nbsp;&nbsp;

00:46:43.140 --> 00:46:45.360
But all of us
know intuitively,&nbsp;&nbsp;

00:46:46.080 --> 00:46:52.260
if you stipulate the patient data is protected,&nbsp;
it's better to have 10, 20, 30 companies&nbsp;

00:46:52.260 --> 00:46:58.200
competing to do this better. Right. And&nbsp;
we, we can more enable that as we learn&nbsp;&nbsp;

00:46:58.200 --> 00:47:01.620
to play with encryption
as a design tool.&nbsp;&nbsp;

00:47:01.620 --> 00:47:05.640
So that we can actually invite competition&nbsp;
into machine learning instead of taking for&nbsp;

00:47:05.640 --> 00:47:12.000
granted as many do now that the biggest&nbsp;
companies are inherently already the winners.&nbsp;

00:47:12.000 --> 00:47:13.800
CRAIG
Now, the what's&nbsp;&nbsp;

00:47:13.800 --> 00:47:20.760
the next step for you guys that I mean, if&nbsp;
presumably, you say there's a foundation and&nbsp;

00:47:20.760 --> 00:47:27.660
then the company. I mean if people want to&nbsp;
explore this, certainly, they can go to aleo.org.&nbsp;&nbsp;

00:47:32.160 --> 00:47:36.420
But I would
guess there is a whole GitHub&nbsp;&nbsp;

00:47:39.540 --> 00:47:45.060
page or repository or something&nbsp;
where people can get involved in the&nbsp;

00:47:45.060 --> 00:47:46.230
open-source project,
SINA&nbsp;

00:47:46.230 --> 00:47:49.380
Open source, there's GitHub,&nbsp;
there's a GitHub repo.&nbsp;&nbsp;

00:47:50.400 --> 00:47:54.120
We are testing that is currently live, they can
actually go and deploy applications, you can&nbsp;&nbsp;

00:47:54.120 --> 00:47:58.200
simple, very simple&nbsp;
applications, or we welcome more&nbsp;

00:47:58.200 --> 00:48:04.620
complex applications. Just to sort of learn how&nbsp;
this works. We have a language called Leo, which&nbsp;

00:48:04.620 --> 00:48:11.520
abstracts away a lot of the hard cryptography and&nbsp;
makes it accessible to developers more generally.&nbsp;

00:48:11.520 --> 00:48:19.500
They can experiment with Leo. Learn to use&nbsp;
that. We welcome feedback. We welcome any&nbsp;&nbsp;

00:48:19.500 --> 00:48:20.549
sort of any
13&nbsp;

00:48:20.549 --> 00:48:21.600
Transcribed by https://otter.ai
sort of feedback, whether it's,&nbsp;&nbsp;

00:48:21.600 --> 00:48:26.100
we're looking for bugs, we have a bug&nbsp;
bounty, but we also, what makes it&nbsp;

00:48:26.100 --> 00:48:28.080
better from a developer's perspective.
SINA&nbsp;

00:48:28.080 --> 00:48:34.020
Because the next steps, our priorities&nbsp;
are to take this from the realm of&nbsp;&nbsp;

00:48:34.020 --> 00:48:36.600
computer science and make it
available in the realm of&nbsp;&nbsp;

00:48:36.600 --> 00:48:40.920
engineering and developers and people&nbsp;
who are just typical coders, right?&nbsp;

00:48:40.920 --> 00:48:49.020
Because then once you open up that audience,&nbsp;
it can go outside of my theorizing about what's&nbsp;

00:48:49.020 --> 00:48:54.900
interesting, and they can actually put rubber to&nbsp;
the road and figure out what works from a product&nbsp;

00:48:54.900 --> 00:48:58.440
perspective. And I think when it really&nbsp;
gets interesting is when you start&nbsp;&nbsp;

00:48:58.440 --> 00:49:01.620
having product managers think
about who are our end users,&nbsp;&nbsp;

00:49:01.620 --> 00:49:05.280
what is the best experience for them?&nbsp;
What facilities distribution, the&nbsp;

00:49:05.280 --> 00:49:10.020
questions that make this a practical&nbsp;
reality, as opposed to a very neat&nbsp;&nbsp;

00:49:10.020 --> 00:49:13.860
computer science breakthrough
that's theoretically interesting.&nbsp;

00:49:14.880 --> 00:49:16.020
CRAIG
You know,&nbsp;&nbsp;

00:49:16.020 --> 00:49:25.320
as I said, I've talked to people about this over&nbsp;
the last five years, similar kinds of things.&nbsp;&nbsp;

00:49:27.840 --> 00:49:29.940
Do
you do have a sense&nbsp;&nbsp;

00:49:31.380 --> 00:49:38.820
it's a little bit like autonomous vehicles?&nbsp;
We've been talking about it for a long&nbsp;

00:49:38.820 --> 00:49:46.740
time, and we're still waiting. Do you have&nbsp;
a sense when this, whether it's Aleo’s&nbsp;&nbsp;

00:49:47.640 --> 00:49:51.960
solution or Oasis Labs
solution or somebody else's&nbsp;&nbsp;

00:49:51.960 --> 00:49:58.980
solution? How long it will be before&nbsp;
we're actually using this stuff in our&nbsp;

00:49:58.980 --> 00:50:00.150
daily lives?
SINA&nbsp;

00:50:00.150 --> 00:50:05.460
Yeah, look, I think it's up to the&nbsp;
open-source community who work on this,&nbsp;&nbsp;

00:50:05.460 --> 00:50:09.720
it's up to us, it's up to all the
other projects that are working on this,&nbsp;&nbsp;

00:50:10.380 --> 00:50:14.640
to make this more like the internet&nbsp;
in the early 1990s, than the&nbsp;

00:50:14.640 --> 00:50:21.180
internet in the late 1970s. Which is to say,&nbsp;
educate people, show them the tools, show them the&nbsp;

00:50:21.180 --> 00:50:26.400
possibilities, publish blog posts, thinking about&nbsp;
different solutions. You know, we had one of our&nbsp;

00:50:27.540 --> 00:50:30.420
computer scientists, Ian Myers,&nbsp;
published a paper on identity,&nbsp;&nbsp;

00:50:30.420 --> 00:50:35.580
we took that paper and used it to build
out a proof of concept around the digital&nbsp;&nbsp;

00:50:35.580 --> 00:50:40.740
identity product, which is looking&nbsp;
really attractive already. So,&nbsp;

00:50:40.740 --> 00:50:45.540
in some sense, these products are I&nbsp;
think, you know, on a 12-to-18-month&nbsp;&nbsp;

00:50:45.540 --> 00:50:49.920
timeline in terms of like being
practically available. Now,&nbsp;&nbsp;

00:50:49.920 --> 00:50:53.460
whether teams execute on 12-to-18-month&nbsp;
timeline is a different question.&nbsp;

00:50:53.460 --> 00:50:58.500
But I think something like&nbsp;
digital identity is currently&nbsp;&nbsp;

00:50:59.640 --> 00:51:05.460
plausible, and is very, very interesting. And it's
something that should be, I think,&nbsp;&nbsp;

00:51:05.460 --> 00:51:09.420
a very high priority for governments&nbsp;
in particular, because it's a really&nbsp;

00:51:09.420 --> 00:51:14.280
attractive way of making the mess&nbsp;
of the internet in terms of like,&nbsp;&nbsp;

00:51:14.280 --> 00:51:18.660
hackers, all the stuff, we've been
talking about the data that's available privacy,&nbsp;&nbsp;

00:51:18.660 --> 00:51:22.320
a lot less messy and a lot more user friendly.
SINA&nbsp;

00:51:23.040 --> 00:51:28.440
The more complicated things that we've discussed,&nbsp;
which is making healthcare data broadly available&nbsp;

00:51:28.440 --> 00:51:32.460
to multiple teams of scientists,&nbsp;
you know, the issue, there is no&nbsp;&nbsp;

00:51:32.460 --> 00:51:36.240
less a technological issue, as is the
case with electronic health records,&nbsp;&nbsp;

00:51:36.240 --> 00:51:40.620
and more, getting the institutions&nbsp;
that are currently incumbents and&nbsp;

00:51:40.620 --> 00:51:45.240
how they own data and how they monetize data.&nbsp;
Sometimes the incentives aren't perfectly aligned&nbsp;

00:51:45.240 --> 00:51:48.900
there. And that could be a longer&nbsp;
process. So, there's the technology,&nbsp;&nbsp;

00:51:48.900 --> 00:51:53.820
which is like closing in on, on
availability. And from here on out,&nbsp;&nbsp;

00:51:53.820 --> 00:51:57.960
I think the main thing is educating&nbsp;
people and increasing its ability to&nbsp;

00:51:57.960 --> 00:52:00.780
scale. And then there's just&nbsp;
sort of the real-world dynamics&nbsp;&nbsp;

00:52:00.780 --> 00:52:05.760
of what's an easier place to disrupt? Where
are there incumbents who are going to be very&nbsp;&nbsp;

00:52:05.760 --> 00:52:07.914
resistant? That sort of thing.
14&nbsp;

00:52:07.914 --> 00:52:08.940
Transcribed by https://otter.ai
CRAIG&nbsp;

00:52:08.940 --> 00:52:14.700
Yeah. Are you talking to any of&nbsp;
the big social media platforms?&nbsp;&nbsp;

00:52:16.260 --> 00:52:27.600
You know, one of my pet peeves is, is
Twitter because of the enormous amount of sort of&nbsp;&nbsp;

00:52:27.600 --> 00:52:35.700
toxic speech that goes on there. And you know, I
wish Elon Musk would require people to register&nbsp;&nbsp;

00:52:36.540 --> 00:52:40.920
their Twitter accounts under&nbsp;
their own names. I think it&nbsp;

00:52:40.920 --> 00:52:46.920
would, it would, you know, you would see&nbsp;
a lot of that toxic speech disappear.&nbsp;

00:52:46.920 --> 00:52:48.960
SINA
It's a great point. I mean,&nbsp;&nbsp;

00:52:49.620 --> 00:52:53.700
it's amazing the extent to which the&nbsp;
social media experience has disappointed&nbsp;

00:52:53.700 --> 00:52:57.960
many, many people. And it's also&nbsp;
amazing the extent to which not&nbsp;&nbsp;

00:52:57.960 --> 00:53:02.760
having control and sovereignty over
our data has been used against us.&nbsp;&nbsp;

00:53:02.760 --> 00:53:09.600
If you mentioned in 2010, for&nbsp;
example, that social media would&nbsp;

00:53:09.600 --> 00:53:13.980
result in data leakage such&nbsp;
that foreign adversaries can&nbsp;&nbsp;

00:53:13.980 --> 00:53:20.460
use that data and leverage it to make us mad
at our neighbors and US yelling about more things,&nbsp;&nbsp;

00:53:22.020 --> 00:53:27.480
and the blood pressure of our country to go up. It
just would have seemed a little bit implausible.&nbsp;&nbsp;

00:53:27.480 --> 00:53:31.860
How would they do that? Why would we respond that
way? It seems a little silly. And yet,&nbsp;&nbsp;

00:53:31.860 --> 00:53:35.520
that's sort of what's happened.&nbsp;
Our data has been rather than like&nbsp;

00:53:35.520 --> 00:53:40.860
something we own, it's been turned&nbsp;
against us. The on the pro side,&nbsp;&nbsp;

00:53:40.860 --> 00:53:44.580
it's like maybe the advertisements
you see are a little bit more relevant. And on the&nbsp;&nbsp;

00:53:44.580 --> 00:53:49.620
con side, you know, the country is more divided,
because they're spiraling with like plots,&nbsp;&nbsp;

00:53:49.620 --> 00:53:52.140
and they don't know they're&nbsp;
interacting with bots, and there's a&nbsp;

00:53:52.140 --> 00:53:56.640
lot less accountability. So, I think it's&nbsp;
a really, really wise thing to point out.&nbsp;

00:53:56.640 --> 00:53:58.080
SINA
And from&nbsp;&nbsp;

00:53:58.080 --> 00:54:03.540
our perspective, it would be very attractive to&nbsp;
start leveraging things like identity in a privacy&nbsp;

00:54:03.540 --> 00:54:05.940
preserving way that authenticate&nbsp;
what's happening. I mean,&nbsp;&nbsp;

00:54:05.940 --> 00:54:11.640
one of the things credit we didn't talk about,
it's a near term risk of what people broadly&nbsp;&nbsp;

00:54:11.640 --> 00:54:15.480
call AI is the ability to fake&nbsp;
content. We're all familiar with&nbsp;

00:54:15.480 --> 00:54:17.580
faking an identity in the sense&nbsp;
that like, there are all these&nbsp;&nbsp;

00:54:17.580 --> 00:54:22.740
bots that are clearly not humans. But there's
also increasingly where we know what we understand&nbsp;&nbsp;

00:54:22.740 --> 00:54:28.920
in fake news, but fake quotes, fake audio files.
Over time, there’s going to be fake visuals,&nbsp;&nbsp;

00:54:28.920 --> 00:54:35.460
fake video, and the ability to&nbsp;
authenticate data content by&nbsp;

00:54:35.460 --> 00:54:40.140
linking it back to users without&nbsp;
exposing the privacy of those&nbsp;&nbsp;

00:54:40.140 --> 00:54:45.180
users is a very attractive proposition.
Because you can say, okay, well, you know, that&nbsp;&nbsp;

00:54:45.180 --> 00:54:49.500
actually did not come from the phone they're
suggesting it came from. And we don't need&nbsp;&nbsp;

00:54:49.500 --> 00:54:52.440
to actually reveal anyone's&nbsp;
data, we just know that it's a&nbsp;

00:54:52.440 --> 00:54:56.880
non-authenticated image, and therefore highly,&nbsp;
much more structured, much more suspect.&nbsp;&nbsp;

00:54:58.380 --> 00:55:00.300
So I think
not just social&nbsp;&nbsp;

00:55:00.300 --> 00:55:05.880
media, but the ability to authenticate in a&nbsp;
courtroom, actual content, like did the person&nbsp;

00:55:05.880 --> 00:55:13.200
say that. You may know as well as I would if you&nbsp;
go and look for, like videos that are faking what&nbsp;

00:55:13.200 --> 00:55:19.680
politicians are saying you're getting increasingly&nbsp;
persuasive looking and sounding stuff, and so&nbsp;

00:55:19.680 --> 00:55:25.620
authenticating while preserving privacy, highly&nbsp;
attractive, particularly in context of social&nbsp;&nbsp;

00:55:25.620 --> 00:55:26.760
media.
CRAIG&nbsp;

00:55:26.760 --> 00:55:35.040
Yeah, but are there conversations going on with&nbsp;
any of those social media platforms about this&nbsp;

00:55:35.040 --> 00:55:35.880
technology?
SINA&nbsp;

00:55:35.880 --> 00:55:38.640
No, we haven't had direct&nbsp;
conversations. But I think that&nbsp;&nbsp;

00:55:38.640 --> 00:55:43.620
would be really attractive. Our focus over the
past two or three years has been completely on the&nbsp;&nbsp;

00:55:43.620 --> 00:55:49.200
computer science and converting it into sort of an
engineering reality. But now's the time,&nbsp;&nbsp;

00:55:49.200 --> 00:55:53.100
you know, and I think we'd be&nbsp;
very interested in talking to Elon&nbsp;

00:55:53.100 --> 00:55:58.380
over at Twitter, or any of these platforms&nbsp;
about integrating this to provide their,&nbsp;&nbsp;

00:55:58.380 --> 00:55:59.549
their use of better
15&nbsp;

00:55:59.549 --> 00:56:01.440
Transcribed by https://otter.ai
experience. I mean, there's just&nbsp;&nbsp;

00:56:01.440 --> 00:56:05.640
no way they're monetizing data.&nbsp;
And that is their business model in&nbsp;

00:56:05.640 --> 00:56:08.520
many ways. But there are things&nbsp;
happening on social media,&nbsp;&nbsp;

00:56:08.520 --> 00:56:12.780
that is not the intent of the owners of
these social media platforms, and that they would&nbsp;&nbsp;

00:56:12.780 --> 00:56:16.920
acknowledge as bad and they don't know, they don't
know what to do with it. And they're not&nbsp;&nbsp;

00:56:16.920 --> 00:56:19.860
particularly incentivized to know&nbsp;
what to do with it. So, we'd be&nbsp;

00:56:19.860 --> 00:56:22.470
very happy to talk about solutions on that front.
CRAIG&nbsp;

00:56:22.470 --> 00:56:27.780
Okay, so that's it for this week.&nbsp;
I want to thank Sina for his time.&nbsp;&nbsp;

00:56:28.800 --> 00:56:34.200
And I'd like you again to consider
visiting netsuite.com/eyeonai&nbsp;&nbsp;

00:56:37.380 --> 00:56:43.560
if you're interested in a full&nbsp;
implementation of Oracle's software with no&nbsp;

00:56:43.560 --> 00:56:47.220
down payment, and no interest for six months.&nbsp;&nbsp;

00:56:48.780 --> 00:56:53.760
As always, you can find a&nbsp;
transcript of this episode on&nbsp;

00:56:53.760 --> 00:57:03.240
our website, eye-on.ai. I find that&nbsp;
you see a lot of things and understand&nbsp;&nbsp;

00:57:03.240 --> 00:57:10.200
things reading a transcript that
you miss with purely audio or visual.&nbsp;

00:57:11.100 --> 00:57:20.760
And remember, the singularity may not be near,&nbsp;
but AI is changing your world. So, pay attention

