WEBVTT
Kind: captions
Language: en

00:04:35.280 --> 00:04:38.120
Well, can you introduce yourself? Tell us about&nbsp;&nbsp;

00:04:38.120 --> 00:04:43.080
how you got to lightning AI? And then&nbsp;
we'll talk about lightning studio.

00:04:43.080 --> 00:04:47.760
Yeah, so I'm William Falcon. I'm the creator&nbsp;
of PyTorch Lightning and founder of lightning&nbsp;&nbsp;

00:04:47.760 --> 00:04:53.880
AI. I come to AI from Research, right, like&nbsp;
most of us do. But before that I actually was&nbsp;&nbsp;

00:04:53.880 --> 00:04:59.320
in the US military. So I spent about six years&nbsp;
going through Navy SEAL training in San Diego;&nbsp;&nbsp;

00:05:01.040 --> 00:05:05.480
during that I got injured. The Navy&nbsp;
gives you a few options at that point,&nbsp;&nbsp;

00:05:06.400 --> 00:05:10.800
the option to continue and finish was not one&nbsp;
of the options they gave me. As an officer,&nbsp;&nbsp;

00:05:10.800 --> 00:05:15.200
I only get one chance to train so that&nbsp;
was unfortunate. But then, you know,&nbsp;&nbsp;

00:05:15.200 --> 00:05:19.080
they gave me the option to become an Intel&nbsp;
officer, or leave and try something else,&nbsp;&nbsp;

00:05:19.080 --> 00:05:26.400
so I left. I was considering things like the CIA&nbsp;
and other special operations, and then just kind&nbsp;&nbsp;

00:05:26.400 --> 00:05:30.520
of found my way. It was kind of the time when&nbsp;
iPhones were coming out and iPhone apps. So I&nbsp;&nbsp;

00:05:30.520 --> 00:05:36.280
started building, just started coding, coding&nbsp;
apps, and eventually find my way into computer&nbsp;&nbsp;

00:05:36.280 --> 00:05:41.920
science and math at Columbia. Don't ask me how but&nbsp;
ended up doing my undergrad at Columbia University&nbsp;&nbsp;

00:05:41.920 --> 00:05:49.200
in New York. And then there, I learned that you&nbsp;
could major computer science, right, and so I did.

00:05:50.600 --> 00:05:52.740
Did you know a guy named Chris Wiggins?

00:05:52.740 --> 00:05:52.795
Yeah, I do. He was at the&nbsp;
New York Times I want to say.

00:05:52.795 --> 00:05:52.840
I was at The New York Times. Yeah, and Chris.

00:05:52.840 --> 00:06:00.080
Yeah, so I know Chris, from the Center for Data&nbsp;
Science, I think as far as I'm from. Yeah, and so&nbsp;&nbsp;

00:06:00.080 --> 00:06:04.800
right around the time I got to Columbia it was&nbsp;
like 2013, which is when deep learning had just&nbsp;&nbsp;

00:06:04.800 --> 00:06:08.400
taken off, like the year before that I had no&nbsp;
idea what it was, right. But I show up to one&nbsp;&nbsp;

00:06:08.400 --> 00:06:13.560
of my classes and, and there's this Professor&nbsp;
Tony Jebara, right, who ran Netflix and stuff&nbsp;&nbsp;

00:06:13.560 --> 00:06:17.040
for a while, on the deep learning side. And&nbsp;
he's teaching the neural networks and I'm like,&nbsp;&nbsp;

00:06:17.040 --> 00:06:22.320
I don't know what any of this is. And, one of the&nbsp;
demos he gives us, MNIST from Yann down at NYU,&nbsp;&nbsp;

00:06:22.320 --> 00:06:28.280
right down the street. At the time it had&nbsp;
little carousel music and I was like, okay, I&nbsp;&nbsp;

00:06:28.280 --> 00:06:32.480
don't really know how that's useful, right? But it&nbsp;
was interesting. And so I started learning about&nbsp;&nbsp;

00:06:32.480 --> 00:06:36.960
it. A long story short, about two, three years&nbsp;
later, I ended up doing research in computational&nbsp;&nbsp;

00:06:36.960 --> 00:06:46.960
neuroscience and in 20, like, 16, 17, I want to&nbsp;
say I went to NeurIPS in Montreal, back then it&nbsp;&nbsp;

00:06:46.960 --> 00:06:53.320
was like a few 100 people. So I discovered the&nbsp;
deep learning community and somehow ended up,&nbsp;&nbsp;

00:06:53.320 --> 00:06:58.560
kind of going into that. I had taken up a job at&nbsp;
Goldman during that time. So I told my manager,&nbsp;&nbsp;

00:06:58.560 --> 00:07:01.840
hey, I wanna I want to do deep learning on the&nbsp;
trading floor and they were like, no, and I was&nbsp;&nbsp;

00:07:01.840 --> 00:07:06.840
like, fine, I'll leave. That's how I went back&nbsp;
to school, and just did research. And then at&nbsp;&nbsp;

00:07:06.840 --> 00:07:10.960
that time, I started building like internal&nbsp;
software for myself to be able to move faster&nbsp;&nbsp;

00:07:10.960 --> 00:07:15.040
through it. That's why I eventually open sourced&nbsp;
which is known as PyTorch Lightning today, right.&nbsp;&nbsp;

00:07:15.040 --> 00:07:21.960
So it started super, super early. And I ended up&nbsp;
doing my PhD down at NYU with Yann LeCun and then&nbsp;&nbsp;

00:07:21.960 --> 00:07:27.280
Kyunghyun Cho as well. Then about three, four&nbsp;
years into it, I dropped out to start Lightning&nbsp;&nbsp;

00:07:27.280 --> 00:07:32.320
AI. PyTorch Lightning took off. I was at Facebook&nbsp;
AI research at the time. And then you know,&nbsp;&nbsp;

00:07:32.320 --> 00:07:36.200
1000s of companies were pinging me, they're using&nbsp;
it, they're trying to put models in production.&nbsp;&nbsp;

00:07:36.200 --> 00:07:41.720
This is like late 2019, early 2020. And, you know,&nbsp;
they were super encouraging. And they basically&nbsp;&nbsp;

00:07:41.720 --> 00:07:45.640
were like, hey, like, you should probably pursue&nbsp;
this and see how it goes, and, you know, we'll&nbsp;&nbsp;

00:07:45.640 --> 00:07:50.400
support you. And they have been very supportive.&nbsp;
So I left Facebook, and have been focused on&nbsp;&nbsp;

00:07:50.400 --> 00:07:58.560
Lightning since then. At the time, we were trying&nbsp;
to figure out how to remove a lot of this overhead&nbsp;&nbsp;

00:07:58.560 --> 00:08:03.000
that you need to know to do deep learning,&nbsp;
right. Back then you had to implement your&nbsp;&nbsp;

00:08:03.000 --> 00:08:07.960
own gradients and all these different things. So&nbsp;
PyTorch for Meta, solved a lot of these problems,&nbsp;&nbsp;

00:08:07.960 --> 00:08:12.280
and then Lightning solved the scaling problem.&nbsp;
But then you start to know Kubernetes, and Docker,&nbsp;&nbsp;

00:08:12.280 --> 00:08:17.440
and Cloud and a million other technologies. So I&nbsp;
started trying to figure out, how do you do that?&nbsp;&nbsp;

00:08:17.440 --> 00:08:23.880
How do you it really felt like MS DOS or like a&nbsp;
Blackberry before an iPhone, super clunky. So I&nbsp;&nbsp;

00:08:23.880 --> 00:08:27.840
was like, well, what is the iPhone experience?&nbsp;
What does that look like? And so it took us&nbsp;&nbsp;

00:08:27.840 --> 00:08:33.880
about three years to figure it out. We tried many&nbsp;
things. Ultimately, we landed on Studios, which we&nbsp;&nbsp;

00:08:33.880 --> 00:08:40.960
launched. It's been in industry, behind the scenes&nbsp;
for about a year, being used by enterprises. But&nbsp;&nbsp;

00:08:40.960 --> 00:08:45.280
we made it public a few months ago. I actually&nbsp;
do think that Studios achieves that iPhone&nbsp;&nbsp;

00:08:45.280 --> 00:08:51.360
leap. It is super usable. If you go to Twitter&nbsp;
today, on LinkedIn, and social media, you hear&nbsp;&nbsp;

00:08:51.360 --> 00:08:55.720
people talking about it, like “revolutionary”,&nbsp;
“it's the next thing”. That's what we wanted&nbsp;&nbsp;

00:08:55.720 --> 00:08:59.840
and that's what Lightning taught us. We want&nbsp;
you to get that 10x experience on something.

00:08:59.840 --> 00:09:06.000
Yeah, let's go back. Explain what Pytorch&nbsp;
Lightning does sort of in layman's terms.

00:09:06.000 --> 00:09:13.920
Yeah. So PyTorch is a library built by Meta,&nbsp;
right, or Facebook AI at the time. And,&nbsp;&nbsp;

00:09:14.640 --> 00:09:19.600
what they saw is the ability to do computational&nbsp;
graphs, right. When a model learns, you have&nbsp;&nbsp;

00:09:19.600 --> 00:09:22.600
to compute gradients, and you have to update&nbsp;
those gradients. So it's like, how to express a&nbsp;&nbsp;

00:09:22.600 --> 00:09:26.800
math function and program in essence, right?&nbsp;
They give you the raw tools to do that. So,&nbsp;&nbsp;

00:09:26.800 --> 00:09:30.960
it'd be me like giving you a bunch of tools to&nbsp;
build a car, like, here's a wheel, here's this,&nbsp;&nbsp;

00:09:30.960 --> 00:09:34.440
here's an engine, but then you still have to&nbsp;
build your own car. So people come up with ways&nbsp;&nbsp;

00:09:34.440 --> 00:09:38.160
of building their own cars. And they'll kind of&nbsp;
look and feel the same, but they're not standard.&nbsp;&nbsp;

00:09:38.160 --> 00:09:42.000
Some people put like four wheels, five wheels,&nbsp;
three wheels, they put them in different places.&nbsp;&nbsp;

00:09:42.000 --> 00:09:45.600
PyTorch Lightning came in as an interface,&nbsp;
like a front end for that, that says, No,&nbsp;&nbsp;

00:09:45.600 --> 00:09:48.880
here's how you do it. Here are the standards, you&nbsp;
put wheels here, you put this here, you do this&nbsp;&nbsp;

00:09:48.880 --> 00:09:53.480
here, and it structures your code. It's not an&nbsp;
abstraction. It's really just structuring the code&nbsp;&nbsp;

00:09:53.480 --> 00:09:59.480
and organizing it for you. Then from that, you're&nbsp;
able to scale and that came out of many years of&nbsp;&nbsp;

00:09:59.480 --> 00:10:05.120
research. The big deal that this unblocked was&nbsp;
the ability to train across 1000s of machines,&nbsp;&nbsp;

00:10:05.120 --> 00:10:10.120
right? In 2019, that wasn't happening at Facebook.&nbsp;
It was like me and two other teams who were doing&nbsp;&nbsp;

00:10:10.120 --> 00:10:14.040
this, right. I was an intern at the time and the&nbsp;
other teams were like professional engineers,&nbsp;&nbsp;

00:10:14.040 --> 00:10:20.200
like ten of them, right, doing these things. And,&nbsp;
I got a lot of their help to building lightning&nbsp;&nbsp;

00:10:20.200 --> 00:10:25.840
into what it is today, putting all their knowledge&nbsp;
into the programs. So that's how I came out. So in&nbsp;&nbsp;

00:10:26.440 --> 00:10:30.960
2020, when I left Facebook, I think the paper we&nbsp;
published a year after, we trained that on like,&nbsp;&nbsp;

00:10:30.960 --> 00:10:36.080
one or 2000 GPUs, right. And that was in 2020.&nbsp;
Today, people are starting to learn how to do&nbsp;&nbsp;

00:10:36.080 --> 00:10:39.800
that but we've been doing that for a long&nbsp;
time. So it gives you that scaling ability,&nbsp;&nbsp;

00:10:39.800 --> 00:10:45.600
right? So if we're use, like, web frameworks,&nbsp;
we basically say like, PyTorch is JavaScript&nbsp;&nbsp;

00:10:45.600 --> 00:10:49.458
and PyTorch Lightning is React, like you&nbsp;
wouldn't build your own React library.

00:10:49.458 --> 00:10:54.680
Right. Yeah, and then once that product had&nbsp;
traction, you started looking around and&nbsp;&nbsp;

00:10:54.680 --> 00:11:05.800
seeing all the other tools and frameworks that&nbsp;
you need to work with, with PyTorch Lightning,&nbsp;&nbsp;

00:11:05.800 --> 00:11:10.440
and you eventually brought it all&nbsp;
under one umbrella, in that studio?

00:11:10.440 --> 00:11:16.440
Exactly. So just like in Web, right— I mean,&nbsp;
actually I’d argue that even AI is a lot harder&nbsp;&nbsp;

00:11:16.440 --> 00:11:21.920
because you have so many moving parts; but PyTorch&nbsp;
Lightning just one piece, but you needed so many&nbsp;&nbsp;

00:11:21.920 --> 00:11:26.840
things. So lightning was the first thing to&nbsp;
integrate other tools. We were like the first&nbsp;&nbsp;

00:11:26.840 --> 00:11:31.760
ones to integrate, like, the ability to train&nbsp;
on different hardware. So before lightning,&nbsp;&nbsp;

00:11:31.760 --> 00:11:35.840
you didn't really code your stuff, and then go&nbsp;
to GPUs, and then go to TPUs, today you do that,&nbsp;&nbsp;

00:11:35.840 --> 00:11:40.080
right? That's something that we pioneered in&nbsp;
Lightning. So we started integrating different&nbsp;&nbsp;

00:11:40.080 --> 00:11:44.800
accelerators which is super valuable today because&nbsp;
there's not enough GPUs to go around. So you kind&nbsp;&nbsp;

00:11:44.800 --> 00:11:50.680
of have to be able to try other hardware. Then we&nbsp;
also brought in things like experiment managers,&nbsp;&nbsp;

00:11:50.680 --> 00:11:54.520
like TensorBoard, Neptune, Weights and&nbsp;
Biases, Comet, all that stuff, right,&nbsp;&nbsp;

00:11:54.520 --> 00:11:57.920
integrated into the system. So it started growing&nbsp;
into kind of like an operating system in essence,&nbsp;&nbsp;

00:11:57.920 --> 00:12:02.360
right, that connected a lot of things together.&nbsp;
And that was kind of the premise behind a lot&nbsp;&nbsp;

00:12:02.360 --> 00:12:06.600
of what we did. In Studio, we basically took&nbsp;
that farther and we just said, okay, and now&nbsp;&nbsp;

00:12:06.600 --> 00:12:12.000
we're gonna bring in your cloud infrastructure&nbsp;
as well and then all your teams, your developers,&nbsp;&nbsp;

00:12:12.000 --> 00:12:15.400
your data scientists, your machine learning&nbsp;
engineers, your designers, everyone can work&nbsp;&nbsp;

00:12:15.400 --> 00:12:22.480
on a single thing together from the browser&nbsp;
but the infrastructure is at scale, right.

00:12:24.240 --> 00:12:33.640
Last time we spoke, I had just spoken to Versel,&nbsp;
which has a services or a platform where you&nbsp;&nbsp;

00:12:33.640 --> 00:12:44.200
can build a model and then access different&nbsp;
foundation models. It's kind of like the bedrock&nbsp;&nbsp;

00:12:44.200 --> 00:12:54.160
at Amazon. But maybe more versatile and with more&nbsp;
options, and I saw Versel is in lightning studio&nbsp;&nbsp;

00:12:54.160 --> 00:13:03.880
as one of the tools or platforms that you can&nbsp;
access. It's a little confusing to me. You keep&nbsp;&nbsp;

00:13:03.880 --> 00:13:13.160
on getting these umbrellas that then give you&nbsp;
access to things further down, further upstream&nbsp;&nbsp;

00:13:13.160 --> 00:13:22.200
I guess. Can you talk about this as, sort of,&nbsp;
hierarchy of platforms, or models, or umbrellas?

00:13:22.200 --> 00:13:26.880
Yeah, so I'm not super familiar with how Versel&nbsp;
works but for what I know, it's mostly about web&nbsp;&nbsp;

00:13:26.880 --> 00:13:32.080
development and deploying web apps, right,&nbsp;
like that kind of thing. That's not really&nbsp;&nbsp;

00:13:32.080 --> 00:13:36.840
the focus of Lightning, right. So what you saw&nbsp;
in lightning is the ability to deploy web apps,&nbsp;&nbsp;

00:13:36.840 --> 00:13:41.320
you can deploy React, you can deploy Angular, Next&nbsp;
etc. But that's not really the focus, right. The&nbsp;&nbsp;

00:13:41.320 --> 00:13:46.000
focus of Lightning is, how do you deploy models&nbsp;
at scale? How do you how do you train models?&nbsp;&nbsp;

00:13:46.000 --> 00:13:51.400
How do you fine tune them? How do you take 10&nbsp;
terabytes of data and do distributed processing&nbsp;&nbsp;

00:13:51.400 --> 00:13:57.200
on it? So it's really more about the scale. What&nbsp;
separates Lightning is this ability to take your&nbsp;&nbsp;

00:13:57.200 --> 00:14:01.640
studio and scale it to 1000 machines instantly,&nbsp;
right? That's not something that a website ever&nbsp;&nbsp;

00:14:01.640 --> 00:14:05.920
needs. A website is happy to work on a single&nbsp;
machine and maybe scale a little bit, but like,&nbsp;&nbsp;

00:14:05.920 --> 00:14:12.200
not at the scale that you need for deep learning.&nbsp;
So it's a fundamentally different thing. Yeah,&nbsp;&nbsp;

00:14:12.200 --> 00:14:15.520
I think that all tools have their place, for&nbsp;
sure. And we’re always happy to integrate with&nbsp;&nbsp;

00:14:15.520 --> 00:14:21.440
things. But definitely the main thing that&nbsp;
we're going after is the scalable workloads,&nbsp;&nbsp;

00:14:21.440 --> 00:14:25.560
the machine learning kind of side of it, and like&nbsp;
through that people do have to make web apps,&nbsp;&nbsp;

00:14:25.560 --> 00:14:28.200
and they have to make websites. So we give&nbsp;
them the ability to do that pretty easily&nbsp;&nbsp;

00:14:28.200 --> 00:14:32.680
as well. But you know, our customers make&nbsp;
tools all the time that don’t just use one.

00:14:32.680 --> 00:14:38.040
Yeah. And when you seem to build models, you're&nbsp;
talking about any machine learning model,&nbsp;&nbsp;

00:14:38.040 --> 00:14:41.720
are you talking about foundation&nbsp;
models, or generative models?

00:14:41.720 --> 00:14:46.640
So PyTorch came out before foundation models were&nbsp;
a thing, before Gennai was a thing, before any of&nbsp;&nbsp;

00:14:46.640 --> 00:14:51.800
this, right. So PyTorch Lightning— In fact, one&nbsp;
of the foundation models to built an AI is built&nbsp;&nbsp;

00:14:51.800 --> 00:14:57.640
using PyTorch Lightning, right. So from the very&nbsp;
beginning, we've been at the epicenter of GenAI.&nbsp;&nbsp;

00:14:57.640 --> 00:15:03.200
So to answer your question, you know, our tools&nbsp;
scale from the simplest models, like literally&nbsp;&nbsp;

00:15:03.200 --> 00:15:08.720
tiny, tiny models to foundation models on 1000s of&nbsp;
GPUs, you know, over the years to our frameworks,&nbsp;&nbsp;

00:15:08.720 --> 00:15:14.200
and our tools have stood the test of time. And we&nbsp;
know that they actually do work for pretty much&nbsp;&nbsp;

00:15:14.200 --> 00:15:19.160
any type of model today, right. And we didn't&nbsp;
actually know that in 2021, when Lightning came&nbsp;&nbsp;

00:15:19.160 --> 00:15:26.000
out first, right. So that's been true, but yeah,&nbsp;
it's really any type of model. And I think we&nbsp;&nbsp;

00:15:26.000 --> 00:15:30.840
definitely do like Gen AI and foundation models&nbsp;
better. And when I say build, that's a good,&nbsp;&nbsp;

00:15:30.840 --> 00:15:34.400
that's a good point. I don't literally mean, you&nbsp;
have to build the model. Most people just grab a&nbsp;&nbsp;

00:15:34.400 --> 00:15:40.200
model from open source, right? I don't mean that.&nbsp;
For researchers like, fair, you're doing your PhD,&nbsp;&nbsp;

00:15:40.200 --> 00:15:44.720
like, sometimes I do mean that, and we do that.&nbsp;
But really, the majority of people are fine tuning&nbsp;&nbsp;

00:15:44.720 --> 00:15:47.960
models, they grab something, they drop it, they&nbsp;
put some data on or they fine tune it for a few&nbsp;&nbsp;

00:15:47.960 --> 00:15:52.560
hours. That's great. That's exactly one of the&nbsp;
bread and butters that we do on the platform.

00:15:52.560 --> 00:15:58.920
Does Studio then allow you to do&nbsp;
things like connect to vector database,&nbsp;&nbsp;

00:16:00.120 --> 00:16:06.520
you know, and implement RAG and all of&nbsp;
those things that people are doing today?

00:16:06.520 --> 00:16:11.880
Yeah, so we have like a public&nbsp;
collection of studios that we put out,&nbsp;&nbsp;

00:16:11.880 --> 00:16:16.920
kind of like a gallery or like a library of&nbsp;
these, these are templates, right? In fact,&nbsp;&nbsp;

00:16:16.920 --> 00:16:23.280
just yesterday we put out a RAG one. So that one,&nbsp;
you can grab a whole data set, do RAG with it,&nbsp;&nbsp;

00:16:23.280 --> 00:16:27.360
and there's like a UI, you can query it as well.&nbsp;
You can integrate an open source database or&nbsp;&nbsp;

00:16:27.360 --> 00:16:31.680
your personal databases as well. And these things&nbsp;
come up a lot, like you know, pretty much anytime&nbsp;&nbsp;

00:16:31.680 --> 00:16:35.640
there's a use case someone's like, Oh, can you do&nbsp;
this or that? Usually either we do it or someone&nbsp;&nbsp;

00:16:35.640 --> 00:16:39.440
in the community will put it together in a few&nbsp;
days. But the platform is very extensible, right?&nbsp;&nbsp;

00:16:39.440 --> 00:16:46.440
It's kind of like having a car and asking if you&nbsp;
can drive to Texas or the supermarket, like, yes!

00:16:46.440 --> 00:16:49.000
This is open source, it's not right.

00:16:49.000 --> 00:16:53.080
So a lot of our frameworks are open source, the&nbsp;
platform itself is not but a lot of the pieces of&nbsp;&nbsp;

00:16:53.080 --> 00:16:57.120
the platform are open source, right. But the code&nbsp;
that we give you, the templates are open source,&nbsp;&nbsp;

00:16:57.960 --> 00:17:00.560
ike that RAG template, that code&nbsp;
is free in there. You can use it,&nbsp;&nbsp;

00:17:00.560 --> 00:17:03.600
you can take it off Lightning if you want,&nbsp;
right, but it already works out of the box.

00:17:03.600 --> 00:17:10.360
Yeah, are there other things in the market&nbsp;
that have approached this and you've&nbsp;&nbsp;

00:17:10.360 --> 00:17:19.080
gone, sort of one layer higher or broader?&nbsp;
That people may know or could relate to?

00:17:19.080 --> 00:17:27.840
So, remember when the iPhone came out, most&nbsp;
things looked like blackberries and Palm Pilots,&nbsp;&nbsp;

00:17:27.840 --> 00:17:31.320
most things that were out there at the time,&nbsp;
Razor phones, right, like that kind of thing.&nbsp;&nbsp;

00:17:31.320 --> 00:17:35.720
That's what that middle of the market looks like&nbsp;
today. And that's because people were kind of&nbsp;&nbsp;

00:17:35.720 --> 00:17:39.800
trying to do the same thing, just slightly&nbsp;
better, different ways, right? We said, No,&nbsp;&nbsp;

00:17:39.800 --> 00:17:43.640
we're not going to do that. In fact, we like&nbsp;
stoped— like, I don't really care what other&nbsp;&nbsp;

00:17:43.640 --> 00:17:47.680
people are working on in general, like we don't&nbsp;
follow what what the markets doing. We just talk&nbsp;&nbsp;

00:17:47.680 --> 00:17:51.600
to our users, hear what they want to do. And&nbsp;
we solve it our own way, kind of like Apple,&nbsp;&nbsp;

00:17:51.600 --> 00:17:56.240
you know, they'll solve it their way however they&nbsp;
want to do it. And, and no, so we really rethought&nbsp;&nbsp;

00:17:56.240 --> 00:18:00.200
the problem from the ground up. And so we said,&nbsp;
like, it's got to be fundamentally different,&nbsp;&nbsp;

00:18:00.200 --> 00:18:05.160
right? And pretty much every single tool in the&nbsp;
world today forces you to code on your laptop,&nbsp;&nbsp;

00:18:05.160 --> 00:18:09.520
on your local machine and then you submit to&nbsp;
the cloud. And that's a paradigm that they've&nbsp;&nbsp;

00:18:09.520 --> 00:18:13.760
all adopted, we got rid of that paradigm, we&nbsp;
don't let you do that. We just let you code on&nbsp;&nbsp;

00:18:13.760 --> 00:18:19.840
the cloud and it stays on the cloud, right? You&nbsp;
can still connect your local IDE and code, so it&nbsp;&nbsp;

00:18:19.840 --> 00:18:24.520
still has the local experience, but everything's&nbsp;
on the cloud. And that's a very, very different&nbsp;&nbsp;

00:18:24.520 --> 00:18:28.880
paradigm. No one else is doing that. And when we&nbsp;
started doing that, people thought it was crazy,&nbsp;&nbsp;

00:18:28.880 --> 00:18:34.880
right? Kind of like when Apple took keyboards&nbsp;
off phones, they thought it was crazy, right?

00:18:34.880 --> 00:18:42.280
Yeah, I would imagine, though, that there are&nbsp;
latency issues if you're working in the cloud.&nbsp;&nbsp;

00:18:42.280 --> 00:18:53.640
I just— this is way before machine learning,&nbsp;
but I used to have to do the— or, expenses at&nbsp;&nbsp;

00:18:53.640 --> 00:19:00.600
the New York Times, you were working on a&nbsp;
remote platform. So everything you input,&nbsp;&nbsp;

00:19:00.600 --> 00:19:05.480
there would be like, a little&nbsp;
incredibly irritating delay,&nbsp;&nbsp;

00:19:05.480 --> 00:19:11.080
and then, that sort of thing. So how&nbsp;
do you overcome the latency issue?

00:19:11.080 --> 00:19:15.360
We’ve spent a lot of time making that go&nbsp;
away, right. And that's why I also said,&nbsp;&nbsp;

00:19:15.360 --> 00:19:21.280
you can also code from your laptop, so there's&nbsp;
zero latency. When you connect your local VS code,&nbsp;&nbsp;

00:19:21.280 --> 00:19:25.680
your IDE, it's exactly the same experience. You&nbsp;
know, the market has gone through this many times,&nbsp;&nbsp;

00:19:25.680 --> 00:19:29.880
and I've been in the other side, too.&nbsp;
I've been skeptical about things,&nbsp;&nbsp;

00:19:29.880 --> 00:19:33.645
right. But, have you ever tried&nbsp;
Figma for example, for designing?

00:19:33.645 --> 00:19:33.664
What’s it called?

00:19:33.664 --> 00:19:33.684
So Figma, to design?

00:19:33.684 --> 00:19:33.711
Yeah, I’ve never used it.

00:19:33.711 --> 00:19:38.840
Yeah, so Figma is like a browser design&nbsp;
tool, right. It competes with Photoshop,&nbsp;&nbsp;

00:19:38.840 --> 00:19:42.760
and those kinds of tools, right?&nbsp;
Now, when Figma came out, you know,&nbsp;&nbsp;

00:19:42.760 --> 00:19:46.720
you ask any designer, and they're gonna be like,&nbsp;
Wait, like design on the browser? Why? Like,&nbsp;&nbsp;

00:19:46.720 --> 00:19:51.440
it's not powerful enough, I have my Photoshop&nbsp;
on my laptop, right? Adobe bought figma for&nbsp;&nbsp;

00:19:51.440 --> 00:19:57.520
$20 billion. Why? Right? Because that is the&nbsp;
future, and most things are moving that way,&nbsp;&nbsp;

00:19:57.520 --> 00:20:01.880
you just have to be very good about how you do&nbsp;
it. And our team has spent a lot of time trying&nbsp;&nbsp;

00:20:01.880 --> 00:20:05.880
to solve these issues. And I think we've landed&nbsp;
there, now it's gonna get better. 100%, right,&nbsp;&nbsp;

00:20:05.880 --> 00:20:09.760
the first iPhone and the current iPhone are very&nbsp;
different. But we have to take the industry and&nbsp;&nbsp;

00:20:09.760 --> 00:20:13.280
leap forward that way. And we have to say&nbsp;
it can be done. And we're going all in on&nbsp;&nbsp;

00:20:13.280 --> 00:20:17.760
it because we believe it is the future. And most&nbsp;
people are, I would say about three years behind&nbsp;&nbsp;

00:20:17.760 --> 00:20:22.840
now because of that, right? But we have a lot of&nbsp;
knowledge on how to keep improving things as well.

00:20:22.840 --> 00:20:35.520
Yeah, and then you integrate all of the, like&nbsp;
copilot or I mean, GitHub Copilot, or Codex,&nbsp;&nbsp;

00:20:35.520 --> 00:20:46.040
or all these other tools that people use while&nbsp;
they're coding. So you're building by coding&nbsp;&nbsp;

00:20:46.040 --> 00:20:57.040
or you're building by putting together&nbsp;
different elements that are pre written?

00:20:57.040 --> 00:21:03.480
Yeah, exactly, an iPhone has iPhone apps,&nbsp;
right? And you need apps to do your work,&nbsp;&nbsp;

00:21:03.480 --> 00:21:08.960
right? You need a way to write, you need a way&nbsp;
to send emails, calculator, flashlight, etc. When&nbsp;&nbsp;

00:21:08.960 --> 00:21:13.360
you're developing AI, you need apps, right? So&nbsp;
to us everything is an app. So you want to train&nbsp;&nbsp;

00:21:13.360 --> 00:21:16.880
a model, there's an app for that, you want to&nbsp;
fine tune the model, there's an app for that,&nbsp;&nbsp;

00:21:16.880 --> 00:21:21.640
you want to deploy a model, there's a fun app for&nbsp;
that, you want to do RAG, there's an app for that,&nbsp;&nbsp;

00:21:21.640 --> 00:21:26.680
right? So every one of these things has an app&nbsp;
embedded in it. Depending on what you're doing,&nbsp;&nbsp;

00:21:26.680 --> 00:21:29.560
it may be a full code experience. So&nbsp;
like all you want to do is code and&nbsp;&nbsp;

00:21:29.560 --> 00:21:33.280
develop there’s literally an IDE to do&nbsp;
that. But if you don't want to do that,&nbsp;&nbsp;

00:21:33.280 --> 00:21:38.280
there might be another UI. Some of these&nbsp;
embedding things, there's no code. You’re&nbsp;&nbsp;

00:21:38.280 --> 00:21:43.840
just like watching plots and dots on the screen,&nbsp;
right? It's kind of like no code. So, just like&nbsp;&nbsp;

00:21:43.840 --> 00:21:48.480
your Mac, sometimes you write into an app, and&nbsp;
sometimes you don't, you click into it, right?

00:21:48.480 --> 00:21:51.400
So once you have this built, the studio built,&nbsp;&nbsp;

00:21:51.400 --> 00:21:58.520
and it's got PyTorch Lightning and&nbsp;
all of these other apps, are you&nbsp;&nbsp;

00:21:59.960 --> 00:22:08.560
continuing?— I guess the the unique thing is that&nbsp;
this is all being done in the cloud, or at least&nbsp;&nbsp;

00:22:08.560 --> 00:22:17.960
if you're doing it locally, it's uploading&nbsp;
to the cloud. I mean, then you have all these&nbsp;&nbsp;

00:22:17.960 --> 00:22:25.840
apps that you can use, but what are the other&nbsp;
features of Lightning Studio that are not covered&nbsp;&nbsp;

00:22:25.840 --> 00:22:34.080
by an app? Or is it really an orchestration&nbsp;
layer to like, manage all these different tools?

00:22:34.080 --> 00:22:39.760
So there are features that are not apps,&nbsp;
specifically, right? So the first thing is like,&nbsp;&nbsp;

00:22:39.760 --> 00:22:44.960
you can create one studio for every task. So&nbsp;
you know, let's say you want to train a model,&nbsp;&nbsp;

00:22:44.960 --> 00:22:49.440
you'll create a studio just to do that. And then&nbsp;
you'll create another studio, maybe to do RAG,&nbsp;&nbsp;

00:22:49.440 --> 00:22:54.400
and then you'll create another studio maybe to&nbsp;
do, I don't know, fine tuning, and another studio&nbsp;&nbsp;

00:22:54.400 --> 00:22:59.760
to serve. You can have infinite of these. In&nbsp;
essence, what you're doing is you're taking your&nbsp;&nbsp;

00:22:59.760 --> 00:23:03.800
laptop— imagine if anytime you want to start a new&nbsp;
project, you could just have a brand new laptop,&nbsp;&nbsp;

00:23:03.800 --> 00:23:07.360
that's what you have, right? And you can store&nbsp;
that laptop, and then when you want to work on&nbsp;&nbsp;

00:23:07.360 --> 00:23:12.320
that you just open the laptop, and it's ready to&nbsp;
go. So that's kind of the first thing, I think&nbsp;&nbsp;

00:23:12.320 --> 00:23:17.400
it's the most useful. I program in probably three&nbsp;
or four things, you know, front end, back end,&nbsp;&nbsp;

00:23:17.400 --> 00:23:22.840
machine learning, data science, different times.&nbsp;
When I want to context switch, I just go turn&nbsp;&nbsp;

00:23:22.840 --> 00:23:27.800
on that studio and I'm there. I don't have to&nbsp;
set anything up. So it's a lot faster. That's,&nbsp;&nbsp;

00:23:27.800 --> 00:23:32.840
I think, probably one of the biggest features&nbsp;
for everyone. Things just work out of the box,&nbsp;&nbsp;

00:23:32.840 --> 00:23:36.480
then I can share that with you. So&nbsp;
let's say you today, you're like, Hey,&nbsp;&nbsp;

00:23:36.480 --> 00:23:39.640
how did you find him that model? Can you share&nbsp;
that with me also? Sure, duplicate my studio,&nbsp;&nbsp;

00:23:39.640 --> 00:23:43.040
and you literally take a carbon copy&nbsp;
of my laptop, and it's done, right? So,&nbsp;&nbsp;

00:23:43.720 --> 00:23:47.960
the community creates these and they share these.&nbsp;
You asked me about the RAG, we didn't create the&nbsp;&nbsp;

00:23:47.960 --> 00:23:53.040
RAG someone else did. And now you can go take&nbsp;
their RAG up and deploy yourself in five seconds,&nbsp;&nbsp;

00:23:53.040 --> 00:23:58.880
right? And you had to do zero work, the RAG&nbsp;
studio. So that's one, you have the ability&nbsp;&nbsp;

00:23:58.880 --> 00:24:03.080
to work together. So like, let's say you and I&nbsp;
are coding and maybe you're learning to code,&nbsp;&nbsp;

00:24:03.080 --> 00:24:07.600
you send me a link, just like in Google Docs, and&nbsp;
I go and type with you and we just code together,&nbsp;&nbsp;

00:24:07.600 --> 00:24:12.800
right? So I can teach people how to code, I can&nbsp;
help junior engineers onboard easier, a lot of&nbsp;&nbsp;

00:24:12.800 --> 00:24:18.440
things we can do there. You have the ability&nbsp;
to measure cost in real time. So you can say,&nbsp;&nbsp;

00:24:18.440 --> 00:24:21.920
I don't want to spend more than $100 on this&nbsp;
thing. And you put a budget of 100. And we&nbsp;&nbsp;

00:24:21.920 --> 00:24:27.440
will measure the cloud costs to a second. Ask&nbsp;
any person in an enterprise today, any company,&nbsp;&nbsp;

00:24:27.440 --> 00:24:31.520
how much they spend on anything machine learning,&nbsp;
they can tell you. You ask us? I can say, yes,&nbsp;&nbsp;

00:24:31.520 --> 00:24:39.240
on that thing we spend $50,000, $271, that's it.&nbsp;
No question asked, right. It's all there. And then&nbsp;&nbsp;

00:24:39.240 --> 00:24:43.000
there's a bunch of team management stuff, like&nbsp;
who can see what when, or what levels of the org,&nbsp;&nbsp;

00:24:43.000 --> 00:24:48.240
who was an admin, who isn't, what data can they&nbsp;
see, what can they not see, right? The ability to&nbsp;&nbsp;

00:24:48.240 --> 00:24:53.400
connect to different data sources like Snowflake&nbsp;
and Databricks data, and then bring in data from&nbsp;&nbsp;

00:24:53.400 --> 00:24:58.920
S3, upload your own data, right? So all of that&nbsp;
gets ingested. So yeah, Lightning, in essence,&nbsp;&nbsp;

00:24:58.920 --> 00:25:03.640
is kind of like an operating system. It just&nbsp;
becomes the center that everything kind of comes&nbsp;&nbsp;

00:25:03.640 --> 00:25:08.380
together. And then you can create studios that&nbsp;
are specialized to specific tasks that you need.

00:25:08.380 --> 00:25:13.520
Yeah, and you were saying that without&nbsp;
Lightning studio, people would have to&nbsp;&nbsp;

00:25:13.520 --> 00:25:20.680
set all this up themselves. Can you walk&nbsp;
me through a use case, to build something,&nbsp;&nbsp;

00:25:20.680 --> 00:25:26.960
and the steps that you would take, and then&nbsp;
how that is different with Lightning Studio?

00:25:26.960 --> 00:25:32.520
Yeah, so let's say mixed trail, I think is one of&nbsp;
the best models out there, came out, and this is&nbsp;&nbsp;

00:25:32.520 --> 00:25:38.360
the mixture of experts. And let's say you want to&nbsp;
deploy that model, right? And for you to do that&nbsp;&nbsp;

00:25:38.360 --> 00:25:43.760
you could have an option. You can either go to one&nbsp;
of these API companies and then hit a button and&nbsp;&nbsp;

00:25:43.760 --> 00:25:49.920
then they'll deploy it for you. But you are kind&nbsp;
of subject to them. What if they go down? Like,&nbsp;&nbsp;

00:25:49.920 --> 00:25:55.080
OpenAI goes down all the time, right? So what&nbsp;
happens? Is your app going to stop working?&nbsp;&nbsp;

00:25:55.080 --> 00:25:59.920
Your service is done, right. So do you really want&nbsp;
to give that up? I don't, I'm not sure, right. So&nbsp;&nbsp;

00:25:59.920 --> 00:26:04.520
that's your first option. Second option is you go&nbsp;
find the code in open source and then you download&nbsp;&nbsp;

00:26:04.520 --> 00:26:09.000
it to your laptop and then you like set it up&nbsp;
and try to get it to work, then you try to find&nbsp;&nbsp;

00:26:09.000 --> 00:26:13.200
a cloud machine somewhere, and then you go to that&nbsp;
cloud machine and you got to set it all up again,&nbsp;&nbsp;

00:26:13.200 --> 00:26:17.440
and then maybe it doesn't work. And you spend like&nbsp;
a week or two doing this. It's extremely hard,&nbsp;&nbsp;

00:26:17.440 --> 00:26:22.600
right? On Lightning, you go to Studios, there's&nbsp;
the gallery there with all the templates,&nbsp;&nbsp;

00:26:22.600 --> 00:26:28.000
you find the MOE template, you click on it,&nbsp;
you press duplicate, takes about 35 seconds,&nbsp;&nbsp;

00:26:28.000 --> 00:26:31.360
it's up and running, and the model’s already&nbsp;
deployed and everything there, and you have the&nbsp;&nbsp;

00:26:31.360 --> 00:26:36.160
code fully. So, you can delete the code if you&nbsp;
want. But it's fully transparent to you. So you&nbsp;&nbsp;

00:26:36.160 --> 00:26:41.240
have full control over it. You can hack it, or you&nbsp;
can leave it alone and leave it how it is, right.

00:30:00.600 --> 00:30:07.640
Yeah, and you said that there's been a very strong&nbsp;
response, how big is that? Well, first of all,&nbsp;&nbsp;

00:30:07.640 --> 00:30:09.080
how do you charge? Is there a freemium layer? And&nbsp;
then you pay for different services, or features?

00:30:09.080 --> 00:30:13.280
Yeah, so we have four different tiers. So there's&nbsp;
a free tier, so everyone, when they sign up,&nbsp;&nbsp;

00:30:13.280 --> 00:30:17.880
they get a free tier, they automatically can&nbsp;
run a studio for free anytime of the day, right,&nbsp;&nbsp;

00:30:17.880 --> 00:30:24.000
CPU studio. They literally could code on the cloud&nbsp;
all day long. They can make infinite studios and&nbsp;&nbsp;

00:30:24.000 --> 00:30:28.160
they can only run one at a time. So if you want&nbsp;
to run multiple, then you're going to use credits,&nbsp;&nbsp;

00:30:28.160 --> 00:30:33.280
right? So you have to buy credits. You pay as you&nbsp;
go as you need them. We also give you 15 credits,&nbsp;&nbsp;

00:30:33.280 --> 00:30:38.920
right. But 15 credits means you can basically&nbsp;
run about 22 GPU hours per month, which is a lot,&nbsp;&nbsp;

00:30:38.920 --> 00:30:44.080
right? Like, I don't think most people need that.&nbsp;
So you have the 15 free credits. So in essence,&nbsp;&nbsp;

00:30:44.080 --> 00:30:47.400
you're gonna get one free running Studio&nbsp;
and 22 GPU hours every month that you can&nbsp;&nbsp;

00:30:47.400 --> 00:30:51.640
use for free. And then when you need more&nbsp;
advanced features, or you need more hours,&nbsp;&nbsp;

00:30:51.640 --> 00:30:55.480
you buy more credits or you upgrade to the&nbsp;
different tiers, right. If you're a company,&nbsp;&nbsp;

00:30:55.480 --> 00:31:00.200
there's stuff around security and the way that you&nbsp;
work with people that are in the different tiers,&nbsp;&nbsp;

00:31:00.200 --> 00:31:04.360
as well. What we wanted to do is get back to&nbsp;
the open source community. I do think that&nbsp;&nbsp;

00:31:04.360 --> 00:31:08.600
there's a big accessibility problem. I'm from&nbsp;
South America, right. And if you tell me that&nbsp;&nbsp;

00:31:08.600 --> 00:31:13.280
I can get a GPU in Venezuela, like, it's not&nbsp;
going to happen but I can through Lightning.&nbsp;&nbsp;

00:31:13.280 --> 00:31:17.640
And so now you've allowed people in developing&nbsp;
countries to like, participate in this as well&nbsp;&nbsp;

00:31:17.640 --> 00:31:23.400
and do something, which is cool. And, and then&nbsp;
after that, you have the ability to integrate&nbsp;&nbsp;

00:31:23.400 --> 00:31:28.720
all the open source stuff as well, right.&nbsp;
So it's, I think, the best of both worlds.

00:31:29.360 --> 00:31:37.800
Yeah, and how big is the community&nbsp;
now, including freemium users?

00:31:37.800 --> 00:31:42.040
So the PyTorch Lightning community is about&nbsp;
1 to 2 million people across the world,&nbsp;&nbsp;

00:31:42.040 --> 00:31:45.480
that's on the open source side as well.&nbsp;
So the platform just became public like,&nbsp;&nbsp;

00:31:45.480 --> 00:31:50.120
two months ago and we already have about 50,000&nbsp;
people on there, right. So it's growing extremely&nbsp;&nbsp;

00:31:50.120 --> 00:31:57.480
fast. Some people might end up in a waitlist if&nbsp;
we can't verify you, for whatever reason. So we're&nbsp;&nbsp;

00:31:57.480 --> 00:32:02.080
trying to get people off the waitlist as much&nbsp;
as we can. I think probably about 20 or 30,000&nbsp;&nbsp;

00:32:02.080 --> 00:32:06.080
of them are still on the waitlist. So we have&nbsp;
to go through and like, do that. But you know,&nbsp;&nbsp;

00:32:06.080 --> 00:32:11.320
we're moving as fast as we can. And we're a little&nbsp;
overwhelmed at the moment but overall it's been&nbsp;&nbsp;

00:32:11.320 --> 00:32:16.160
really, really positive and overwhelming, right?&nbsp;
It's kind of what we saw when we first launched&nbsp;&nbsp;

00:32:16.160 --> 00:32:21.080
PyTorch Lightning in the very beginning, it&nbsp;
just went viral on its own. Because, you know,&nbsp;&nbsp;

00:32:21.080 --> 00:32:27.000
people appreciate good design, they appreciate&nbsp;
usability, especially in a world where like,&nbsp;&nbsp;

00:32:27.000 --> 00:32:30.760
you know, I mean, when I came into AI and I saw&nbsp;
the way that people were working, I was like,&nbsp;&nbsp;

00:32:30.760 --> 00:32:36.240
How? It just really bothered me and, like, I hate&nbsp;
using clunky things, right. And so I just wanted&nbsp;&nbsp;

00:32:36.240 --> 00:32:40.640
to make something that was extremely easy for the&nbsp;
world to use so that they could focus on science,&nbsp;&nbsp;

00:32:40.640 --> 00:32:44.240
they could focus on the models, they could&nbsp;
focus on the business problem, instead of&nbsp;&nbsp;

00:32:44.240 --> 00:32:50.200
like learning Kubernetes, and Docker, and this&nbsp;
and that, right? Even most hardcore engineers,&nbsp;&nbsp;

00:32:50.200 --> 00:32:54.520
when they get on they're like, Oh, my God, thank&nbsp;
God! Like yes, it was intellectually curious to&nbsp;&nbsp;

00:32:54.520 --> 00:33:01.080
know these things but it really was so annoying&nbsp;
for years that I don't want to deal with it.

00:33:01.080 --> 00:33:10.000
Yeah, you mentioned Weights &amp; Biases, I had a&nbsp;
conversation with the Weights &amp; Biases guys and&nbsp;&nbsp;

00:33:10.000 --> 00:33:16.520
that's, that's on the platform. They do things&nbsp;
like monitoring. A lot of the ML ops stuff,&nbsp;&nbsp;

00:33:16.520 --> 00:33:24.720
which now is becoming LLM ops, and maybe&nbsp;
it'll be LMM ops at some point. Do you&nbsp;&nbsp;

00:33:24.720 --> 00:33:31.680
do any of that? Version Control monitoring&nbsp;
after deployment, things like that, or again,&nbsp;&nbsp;

00:33:34.040 --> 00:33:40.800
you're letting people like Weights and&nbsp;
Biases. do that through the Studio?

00:33:40.800 --> 00:33:45.600
Yeah, so they're apps, right, they’re partnered&nbsp;
with us. So, we don't provide that capability. We&nbsp;&nbsp;

00:33:45.600 --> 00:33:50.120
provide a few apps that do those things. So on&nbsp;
the platform, people use TensorBoard, which is&nbsp;&nbsp;

00:33:50.120 --> 00:33:54.760
open source. They do use Weights &amp; Biases. What&nbsp;
else did they use? They use things like Comet,&nbsp;&nbsp;

00:33:54.760 --> 00:33:59.920
they use MLflow. But yeah, those are all&nbsp;
integrated and people can use them out of the box.

00:33:59.920 --> 00:34:05.120
Yeah, so last time we spoke it&nbsp;
seemed that you were about to&nbsp;&nbsp;

00:34:05.120 --> 00:34:10.920
release something new on the platform, or&nbsp;
am I mistaken? I talk to so many people.

00:34:10.920 --> 00:34:14.600
Yeah, I mean, we've released a&nbsp;
lot of stuff already. I mean,&nbsp;&nbsp;

00:34:14.600 --> 00:34:16.800
we have many cool things that are&nbsp;
coming in the next few months for&nbsp;&nbsp;

00:34:16.800 --> 00:34:21.240
sure but right now people are just&nbsp;
getting started to even try Studios.

00:34:21.240 --> 00:34:23.480
Right, and how big is your team?

00:34:23.480 --> 00:34:27.320
Yeah, very small. So about 40 people,&nbsp;
right, which is cool. Remember,&nbsp;&nbsp;

00:34:27.320 --> 00:34:31.240
I grew up in special operations, right?&nbsp;
SEAL teams are very small. You have very,&nbsp;&nbsp;

00:34:31.240 --> 00:34:34.880
very talented people who just really&nbsp;
worked together well and internally,&nbsp;&nbsp;

00:34:34.880 --> 00:34:38.160
the company structure is how the SEAL teams are&nbsp;
structured actually, because that's kind of the&nbsp;&nbsp;

00:34:38.160 --> 00:34:44.440
management style that I know. So everyone moves&nbsp;
aggressively fast. Everyone is a team player,&nbsp;&nbsp;

00:34:44.440 --> 00:34:49.200
very collaborative. And we hire the best people&nbsp;
in the world. We love to train them and, you know,&nbsp;&nbsp;

00:34:49.200 --> 00:34:53.720
I think one thing that I do is teach them how&nbsp;
to work really, really well as a team, right,&nbsp;&nbsp;

00:34:53.720 --> 00:34:57.360
which is something that I thought was crazy&nbsp;
how the civilian world doesn't really have&nbsp;&nbsp;

00:34:57.360 --> 00:35:02.680
that. There's a lot of individuals working on a&nbsp;
team, but not an actual team working together.

00:35:02.680 --> 00:35:06.680
Yeah, that's interesting.Generative&nbsp;
AI and world models are coming on,&nbsp;&nbsp;

00:35:08.600 --> 00:35:15.520
this space is moving very quickly.&nbsp;
How do you keep the studio relevant&nbsp;&nbsp;

00:35:15.520 --> 00:35:23.240
as the research moves, and then&nbsp;
that research becomes adopted?

00:35:23.240 --> 00:35:27.520
Well, remember, that was the goal of the&nbsp;
Studio, is to build an integration platform,&nbsp;&nbsp;

00:35:27.520 --> 00:35:32.640
right? So inherently, it is designed to do that.&nbsp;
So actually, if you don't use Studio, you probably&nbsp;&nbsp;

00:35:32.640 --> 00:35:39.080
will fall behind. I'll give you an example. Just&nbsp;
this week, there were two models released, there&nbsp;&nbsp;

00:35:39.080 --> 00:35:43.680
was one from Alan AI, and there was another one,&nbsp;
right, he Facebook one, the Code LLaMA. On the&nbsp;&nbsp;

00:35:43.680 --> 00:35:47.560
day that the Code LLaMA model was released,&nbsp;
within an hour or two, we had a studio out,&nbsp;&nbsp;

00:35:47.560 --> 00:35:52.000
a template already ready to go with it. Then&nbsp;
when the other one was released from Alan AI,&nbsp;&nbsp;

00:35:52.000 --> 00:35:57.320
within an hour or two, we had another one out.&nbsp;
So like, we can get you that latest AI stuff,&nbsp;&nbsp;

00:35:57.320 --> 00:36:03.600
literally within a day, like worst case scenario,&nbsp;
no matter what it is, RAG, you know, new database,&nbsp;&nbsp;

00:36:03.600 --> 00:36:07.800
something crazy comes out, we can always integrate&nbsp;
it, because it is built for integrations first,&nbsp;&nbsp;

00:36:07.800 --> 00:36:12.440
at the end of the day. And that's that that's&nbsp;
the fundamental problem that most platforms have,&nbsp;&nbsp;

00:36:12.440 --> 00:36:16.600
is their point solutions. They just do&nbsp;
the one thing. They're like, a calculator,&nbsp;&nbsp;

00:36:16.600 --> 00:36:19.560
and then when a flashlight comes out,&nbsp;
they're trying to stick a flashlight&nbsp;&nbsp;

00:36:19.560 --> 00:36:22.160
in a calculator and you're like,&nbsp;
No, it doesn't really work, right?

00:36:22.160 --> 00:36:27.680
Yeah, actually, that's interesting,&nbsp;
because it also gives people a&nbsp;&nbsp;

00:36:27.680 --> 00:36:34.800
central source of knowledge. So, they&nbsp;
don't have to be reading about every new&nbsp;&nbsp;

00:36:34.800 --> 00:36:43.960
tool or new technique that comes out, it'll&nbsp;
appear in Lightning Studio. Is that right?

00:36:43.960 --> 00:36:44.800
Yes

00:36:44.800 --> 00:36:47.800
And I would imagine there's documentation,&nbsp;&nbsp;

00:36:47.800 --> 00:36:54.680
or tutorials, or something to help people&nbsp;
understand when something new appears?

00:36:54.680 --> 00:36:59.320
Yes, and we'll do the work to; vet something&nbsp;
is real or not, most of us are researchers,&nbsp;&nbsp;

00:36:59.880 --> 00:37:03.200
most of us come from academia,&nbsp;
like, you know, PhDs and that's&nbsp;&nbsp;

00:37:03.200 --> 00:37:07.320
something we have related. So we can pretty&nbsp;
quickly know when something's hype or not,&nbsp;&nbsp;

00:37:07.320 --> 00:37:11.600
and we will vet things. We'll experiment with&nbsp;
everything but we’ll decide what actually&nbsp;&nbsp;

00:37:11.600 --> 00:37:16.470
sticks around or not. So, you know, you can&nbsp;
kind of defer that work to us as a company.

00:37:16.470 --> 00:37:24.840
Yeah, and you also are in a position to see what&nbsp;
people are using the platform for. Does that give&nbsp;&nbsp;

00:37:24.840 --> 00:37:32.960
you visibility into where the markets going,&nbsp;
what's popular? What's hot? That sort of thing?

00:37:32.960 --> 00:37:36.040
Yeah, I mean, look, we obviously don't look&nbsp;
at people's code or anything like that,&nbsp;&nbsp;

00:37:36.040 --> 00:37:40.880
right. So I think, what I can tell is when we&nbsp;
get new customers who like are excited to use&nbsp;&nbsp;

00:37:40.880 --> 00:37:45.000
a platform that kind of generally tell us&nbsp;
what they're working on? Not the details,&nbsp;&nbsp;

00:37:45.000 --> 00:37:53.000
but like, what they're trying to do. And yeah, I&nbsp;
mean, we see trends, I will say that, you know,&nbsp;&nbsp;

00:37:53.000 --> 00:37:58.200
I come from research and research is leading&nbsp;
enterprise usually. So even people who come in,&nbsp;&nbsp;

00:37:58.200 --> 00:38:01.480
they're already like six months behind. So&nbsp;
they're talking to me about things that were&nbsp;&nbsp;

00:38:01.480 --> 00:38:07.080
out many months ago. And, and it's rare that I&nbsp;
find a new team who's like right on it with like,&nbsp;&nbsp;

00:38:07.080 --> 00:38:10.440
the thing from that week, who’s like thinking&nbsp;
about it. And honestly, as a business,&nbsp;&nbsp;

00:38:10.440 --> 00:38:14.840
you shouldn't be operating at the bleeding&nbsp;
edge. You shouldn't be a little bit behind.&nbsp;&nbsp;

00:38:14.840 --> 00:38:18.240
But researchers are always kind of trying&nbsp;
the new stuff and we have researchers on the&nbsp;&nbsp;

00:38:18.240 --> 00:38:24.400
platform because it's one of the best tools for&nbsp;
R&amp;D and, like, iterative work. And so we see a&nbsp;&nbsp;

00:38:24.400 --> 00:38:29.080
lot of stuff that they do and we collaborate with&nbsp;
them on papers as well. And then those papers get&nbsp;&nbsp;

00:38:29.080 --> 00:38:33.800
published. So we're like at the bleeding edge with&nbsp;
them a lot of times as well. But you know, there's&nbsp;&nbsp;

00:38:33.800 --> 00:38:38.680
no news there. Its a lot of the same stuff,&nbsp;
fine tuning, pre training, deploying, right?&nbsp;&nbsp;

00:38:38.680 --> 00:38:44.400
It's a lot of the same. And then like whether&nbsp;
use RAG or not, it's a detail usually, like all&nbsp;&nbsp;

00:38:44.400 --> 00:38:49.120
these tools that come out, they’re details to&nbsp;
a lot of the ways that these things are done.

00:38:49.120 --> 00:38:58.720
I had a conversation this morning with a guy who&nbsp;
was talking about using multiple models, and then&nbsp;&nbsp;

00:38:58.720 --> 00:39:07.800
having a consensus layer that, sort of, reconciles&nbsp;
contradictions within the outputs from several&nbsp;&nbsp;

00:39:07.800 --> 00:39:17.760
models and comes up with an average or with a—&nbsp;
can that kind of thing be done through Lightning?

00:39:17.760 --> 00:39:22.400
Yeah, so that's, there are few terms for that, but&nbsp;
that's probably mixture of experts (MoE) is he's&nbsp;&nbsp;

00:39:22.400 --> 00:39:26.960
referring to. And yeah, so it's just about&nbsp;
training different models, and then somehow&nbsp;&nbsp;

00:39:26.960 --> 00:39:31.440
aggregating their outputs, you can either average&nbsp;
time or you can have another model do consensus&nbsp;&nbsp;

00:39:31.440 --> 00:39:37.560
for all those models. So that mixtural model, the&nbsp;
mixtural MoE, that's exactly what it does. It has&nbsp;&nbsp;

00:39:37.560 --> 00:39:42.840
eight models and it does that. You know, when&nbsp;
people talk about Chat GPT and they compare with&nbsp;&nbsp;

00:39:42.840 --> 00:39:47.360
open source, it's actually an unfair comparison&nbsp;
because Chat GPT behind the scenes, it's likely&nbsp;&nbsp;

00:39:47.360 --> 00:39:51.480
like 30 models that are all collaborating to do&nbsp;
stuff, right? And then you compare that with,&nbsp;&nbsp;

00:39:51.480 --> 00:39:55.720
like, one model? Well, it's not true, you got to&nbsp;
compare it to a collection of models, right? So&nbsp;&nbsp;

00:39:55.720 --> 00:40:00.800
you can do that. And it is actually probably one&nbsp;
of the only platforms if not the only platform&nbsp;&nbsp;

00:40:00.800 --> 00:40:05.000
that can build systems because every other&nbsp;
platform in the world today can only do like,&nbsp;&nbsp;

00:40:05.000 --> 00:40:11.400
one thing, like a model, right? But they can't&nbsp;
connect things, whereas lightning can keep systems&nbsp;&nbsp;

00:40:11.400 --> 00:40:15.920
kind of going and have many of them working&nbsp;
together, right? So the RAG example that we had,&nbsp;&nbsp;

00:40:15.920 --> 00:40:20.680
it's a good example, where on one studio you&nbsp;
deploy the model and then on a separate studio,&nbsp;&nbsp;

00:40:20.680 --> 00:40:25.320
you have the RAG system completely isolated&nbsp;
and they're talking to each other, right.

00:40:25.320 --> 00:40:33.040
Oh, yeah, that's fascinating. How are you&nbsp;
funded? I mean, was this costly to build?

00:40:33.040 --> 00:40:41.080
Very expensive. So yeah, we've raised about&nbsp;
70 million so far, from Index Venture or Spin&nbsp;&nbsp;

00:40:41.080 --> 00:40:48.440
Capital, Coatue and a bunch of amazing angels.&nbsp;
Yeah, like, really, really great angels and,&nbsp;&nbsp;

00:40:49.000 --> 00:40:57.520
you know, I would say, most enterprises&nbsp;
that we work with have spent, probably even&nbsp;&nbsp;

00:40:57.520 --> 00:41:02.320
100 million easily, to build some version of&nbsp;
this internally. And then their headcount is&nbsp;&nbsp;

00:41:02.320 --> 00:41:05.720
crazy to maintain these things, right. So&nbsp;
if you want to build something like this,&nbsp;&nbsp;

00:41:05.720 --> 00:41:08.320
you probably have to invest about $100&nbsp;
million, and like two or three years&nbsp;&nbsp;

00:41:08.320 --> 00:41:13.080
to try to do it. And most companies have&nbsp;
tried that. And today, if they tried it,&nbsp;&nbsp;

00:41:13.080 --> 00:41:16.400
they hate it, all of them and they're trying&nbsp;
to get rid of it somehow, right. And so they're&nbsp;&nbsp;

00:41:16.400 --> 00:41:21.440
looking to us to replace that. Even the world's&nbsp;
largest banks for example, that we work with,&nbsp;&nbsp;

00:41:21.440 --> 00:41:29.360
they've invested a lot of money, so much. It's&nbsp;
extremely difficult to build. The thing is,&nbsp;&nbsp;

00:41:29.360 --> 00:41:35.000
you look at it, it's pretty easy, right? It looks&nbsp;
looks simple, but the iPhone looks simple. Right?

00:41:35.000 --> 00:41:41.280
Yeah, Wow, and so Studio came out, it&nbsp;
was publicly available in December?&nbsp;&nbsp;

00:41:41.280 --> 00:41:46.080
And your community's growing. What, what's&nbsp;
next? I mean, where does this go? Is it&nbsp;&nbsp;

00:41:46.080 --> 00:41:51.120
just a matter of keeping up with all the&nbsp;
tools that are appearing on the market?

00:41:51.120 --> 00:41:55.720
Yeah, I mean, we want studio to be the way that&nbsp;
you develop and code, that's it. I think we're&nbsp;&nbsp;

00:41:55.720 --> 00:42:02.000
successful, when you’ll get so annoyed at having&nbsp;
to set things up on your laptop, on your local&nbsp;&nbsp;

00:42:02.000 --> 00:42:07.640
machine. You know, you're like, “Oh, I gotta&nbsp;
start a work project”, and you'd rather just&nbsp;&nbsp;

00:42:07.640 --> 00:42:11.840
go to Lightning, turn on a studio, and you know,&nbsp;
you're done, instead of trying to mess around with&nbsp;&nbsp;

00:42:11.840 --> 00:42:16.560
your local machine. We're getting there already&nbsp;
with a lot of people but hopefully by the end&nbsp;&nbsp;

00:42:16.560 --> 00:42:20.960
of the year this is the standard for everyone in&nbsp;
the world, they understand it. Now it will take&nbsp;&nbsp;

00:42:20.960 --> 00:42:27.120
probably more years for that to reach everyone but&nbsp;
like, how long did it take the market to convince&nbsp;&nbsp;

00:42:28.120 --> 00:42:33.880
BlackBerry users that keyboards were not a good&nbsp;
idea, right? It took a while but today we know&nbsp;&nbsp;

00:42:33.880 --> 00:42:37.920
that that opened up a lot of doors, right.&nbsp;
So when there are paradigm shifts that occur,&nbsp;&nbsp;

00:42:38.760 --> 00:42:42.560
it takes a while for the market to catch up.&nbsp;
But in the long term, it is the better thing.

00:42:42.560 --> 00:42:50.840
Yeah, and you have some major enterprises&nbsp;
with a lot of developers using the Studio?

00:42:50.840 --> 00:42:57.120
Yeah, we have quite a few customers all the&nbsp;
way from small startups to huge enterprises.&nbsp;&nbsp;

00:42:57.920 --> 00:43:01.960
Probably one of the largest ones that&nbsp;
we have, it's like a top bank, top two,&nbsp;&nbsp;

00:43:01.960 --> 00:43:08.040
three bank and they have at least four or 5000&nbsp;
data scientists internally that do ML and they&nbsp;&nbsp;

00:43:08.040 --> 00:43:12.920
have 1000s of use cases. And so we're currently&nbsp;
undergoing, like, a full platform deployment&nbsp;&nbsp;

00:43:12.920 --> 00:43:18.220
there as well, which is cool to see because it&nbsp;
is a massive scale, just in that one customer.

00:43:18.220 --> 00:43:25.680
Yeah, and this is a little off topic but I&nbsp;
talked to somebody frequently about unit testing;&nbsp;&nbsp;

00:43:25.680 --> 00:43:29.720
which is kind of something people don't&nbsp;
talk a lot about, it takes a lot of&nbsp;&nbsp;

00:43:29.720 --> 00:43:37.960
time. Does this support unit testing tools,&nbsp;
automated unit testing, or things like that?

00:43:37.960 --> 00:43:43.080
Yeah, so we actually run, so PyTorch Lightning,&nbsp;
all our open source projects that live on GitHub,&nbsp;&nbsp;

00:43:43.080 --> 00:43:46.920
they have rigorous unit tests and they have&nbsp;
CI/CDs because a lot of companies depend on&nbsp;&nbsp;

00:43:46.920 --> 00:43:52.440
them. So we run probably PyTorch Lightning,&nbsp;
on any given day, we run, I don't know,&nbsp;&nbsp;

00:43:52.440 --> 00:43:56.720
5000 tests per pull requests and there are&nbsp;
probably a few dozen pull requests. So we're&nbsp;&nbsp;

00:43:56.720 --> 00:44:01.200
spinning up 1000s of machines a day just&nbsp;
to test open source frameworks. Recently,&nbsp;&nbsp;

00:44:01.200 --> 00:44:04.320
we started switching to using studios for&nbsp;
a lot of those. So we're even getting off&nbsp;&nbsp;

00:44:04.320 --> 00:44:08.256
those platforms, because it's a lot easier&nbsp;
and faster for us to do that, and cheaper.

00:44:08.256 --> 00:44:08.304
Yeah, okay, I'm running out of questions to ask.

00:44:08.304 --> 00:44:10.800
No, good. Well, I'll tell you some other&nbsp;
interesting use cases, because people always&nbsp;&nbsp;

00:44:10.800 --> 00:44:15.360
hack with new tools, right? So coding interviews,&nbsp;
so we've actually started doing our coding&nbsp;&nbsp;

00:44:15.360 --> 00:44:19.360
interviews in Studios, which is cool. So like,&nbsp;
if you interview for us, and you're an engineer,&nbsp;&nbsp;

00:44:19.360 --> 00:44:24.240
you'll get on a studio and you’ll code with me,&nbsp;
right? And it's probably the only tool you can do&nbsp;&nbsp;

00:44:24.240 --> 00:44:28.640
that with for machine learning because like,&nbsp;
what other tool can you just run GPUs on and&nbsp;&nbsp;

00:44:28.640 --> 00:44:32.560
code together? You can't, so if you're testing&nbsp;
a machine learning engineer, who's joining your&nbsp;&nbsp;

00:44:32.560 --> 00:44:37.280
company, I mean, this is kind of the only way&nbsp;
to get them to actually do real world work on&nbsp;&nbsp;

00:44:37.280 --> 00:44:41.960
that interview to see how they work. So you can do&nbsp;
things like, you set up a model and you break it&nbsp;&nbsp;

00:44:41.960 --> 00:44:46.120
and you see how they debug it and understand the&nbsp;
GPU profiling, and all these different things,&nbsp;&nbsp;

00:44:46.120 --> 00:44:51.600
right. So that's something cool that people&nbsp;
started doing, not just us, a few other customers.&nbsp;&nbsp;

00:44:51.600 --> 00:44:56.200
Hackathons is a big one as well. So turns out,&nbsp;
you know, if you want to set up a hackathon,&nbsp;&nbsp;

00:44:56.200 --> 00:45:00.400
you can go set up a bunch of studios for everyone&nbsp;
and then they go off, and you give them credits,&nbsp;&nbsp;

00:45:00.400 --> 00:45:07.040
and it's good. Classes, so right now there's, I&nbsp;
won't say which one but you can probably guess,&nbsp;&nbsp;

00:45:07.680 --> 00:45:13.520
big professor from NYU, teaching a big deep&nbsp;
learning class, using Studio in that class. And,&nbsp;&nbsp;

00:45:13.520 --> 00:45:17.160
you know, it's obviously from our lab. And&nbsp;
so it's cool to see how they're doing it,&nbsp;&nbsp;

00:45:17.160 --> 00:45:20.080
and then they're a bunch of other universities&nbsp;
as well, that are doing it. But imagine,&nbsp;&nbsp;

00:45:20.080 --> 00:45:25.200
as an undergrad, Columbia, when I was there,&nbsp;
they didn’t really have a compute cluster.&nbsp;&nbsp;

00:45:25.200 --> 00:45:29.000
I don't know if they still do, they might,&nbsp;
a little one, and you're learning computer&nbsp;&nbsp;

00:45:29.000 --> 00:45:33.920
science and you have to do everything locally.&nbsp;
It's like, super slow and hard right? Now,&nbsp;&nbsp;

00:45:33.920 --> 00:45:37.760
professors can just be like, here's a studio with&nbsp;
your homework on it, like, go solve it there,&nbsp;&nbsp;

00:45:37.760 --> 00:45:42.425
and they could just immediately get started. So&nbsp;
I think it'll accelerate education a lot as well.

00:45:42.425 --> 00:45:42.620
Yeah, that's fascinating. Okay, is&nbsp;
there anything else I should ask?

00:45:42.620 --> 00:45:44.680
No, I think all these were good questions. I'll&nbsp;
take a minute just to say, about open source,&nbsp;&nbsp;

00:45:44.680 --> 00:45:50.800
like we've been behind open source forever. So&nbsp;
most people today use a lot of libraries out&nbsp;&nbsp;

00:45:50.800 --> 00:45:56.200
there. And they use things like a trainer, or they&nbsp;
use different interfaces that they code with. And,&nbsp;&nbsp;

00:45:56.200 --> 00:46:00.280
you know, a lot of those ideas came from PyTorch&nbsp;
Lightning in 2019. And we introduced this to the&nbsp;&nbsp;

00:46:00.280 --> 00:46:05.960
world. And I think like, what's that's done, is&nbsp;
really standardize the way people do AI. And I&nbsp;&nbsp;

00:46:05.960 --> 00:46:10.600
think it's great because like, you know, it's&nbsp;
not just us, a lot of other companies as well&nbsp;&nbsp;

00:46:10.600 --> 00:46:15.920
have been pushing really hard and getting open&nbsp;
source to be to be big and I really do want to ask&nbsp;&nbsp;

00:46:15.920 --> 00:46:20.560
everyone who's listening to support open source&nbsp;
not just us, but every company who's doing it&nbsp;&nbsp;

00:46:20.560 --> 00:46:24.880
because I think we're at a critical junction where&nbsp;
the last thing you want is to have one or two&nbsp;&nbsp;

00:46:24.880 --> 00:46:31.120
companies like own key IP of models or something&nbsp;
like that. It's like not having an Apple and then&nbsp;&nbsp;

00:46:31.120 --> 00:46:36.640
having IBM be the only one you can get computers&nbsp;
from, like, that would be crazy right? And so I&nbsp;&nbsp;

00:46:36.640 --> 00:46:41.760
think the world has to come together and keep&nbsp;
AI open source and continue to support things.&nbsp;&nbsp;

00:46:41.760 --> 00:46:46.560
And I think Meta and my old lab at Facebook,&nbsp;
they're probably doing the most out of anyone,&nbsp;&nbsp;

00:46:46.560 --> 00:46:50.880
which is great; but I think companies should not&nbsp;
be scared of that and they should understand that&nbsp;&nbsp;

00:46:50.880 --> 00:46:56.960
it's actually better for their business. Go look&nbsp;
at Meta stock today, like, probably 4Xed since&nbsp;&nbsp;

00:46:56.960 --> 00:50:47.960
they started doing AI and working on open source&nbsp;
as well. It's a net benefit for the world,

