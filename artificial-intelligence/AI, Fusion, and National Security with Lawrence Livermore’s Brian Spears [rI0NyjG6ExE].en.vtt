WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:00.840
Brian Spears:
There's a global&nbsp;&nbsp;

00:00:00.840 --> 00:00:05.480
race on taking that compute technology that we've&nbsp;
built here in the US and doing transformational&nbsp;&nbsp;

00:00:05.480 --> 00:00:09.600
things with it. There are adversaries in the&nbsp;
world, especially China, who have declared that&nbsp;&nbsp;

00:00:09.600 --> 00:00:15.400
they will dominate in the AI space by 2030. The&nbsp;
National Security Commission on AI took a hard&nbsp;&nbsp;

00:00:15.400 --> 00:00:23.080
look at this around 2021 to 2022. And they said&nbsp;
in this global scale, there were six structural&nbsp;&nbsp;

00:00:23.080 --> 00:00:27.200
features that they looked at and most players&nbsp;
in the world could not compete with the US,&nbsp;&nbsp;

00:00:27.200 --> 00:00:31.960
save China. China's ahead in half the features;&nbsp;
the US is ahead in half the features. Who wins&nbsp;&nbsp;

00:00:31.960 --> 00:00:36.600
is a toss-up. So the Department of Energy has&nbsp;
stepped up and said [We know how to do computing&nbsp;&nbsp;

00:00:36.600 --> 00:00:41.200
at an enormous scale, we understand what the&nbsp;
national security needs are for the country;&nbsp;&nbsp;

00:00:41.200 --> 00:00:45.400
we're in a unique position to bring together the&nbsp;
compute capability and that awareness of those&nbsp;&nbsp;

00:00:45.400 --> 00:00:49.908
missions, and put it together and do something&nbsp;
productive]. So FAST is the answer to that.

00:00:49.908 --> 00:00:52.600
Craig Smith:
Hi, I wanted to jump in and give a shout-out&nbsp;&nbsp;

00:00:52.600 --> 00:01:00.240
to our sponsor, SysAid. SysAid's vision is to&nbsp;
lead organizations on a transformative journey&nbsp;&nbsp;

00:01:00.240 --> 00:01:08.960
toward AI-driven organizational processes and&nbsp;
services, infusing intelligence and ease in the&nbsp;&nbsp;

00:01:08.960 --> 00:01:16.840
workday with SysAid Copilot. SysAid orchestrates&nbsp;
service management across the organization using&nbsp;&nbsp;

00:01:16.840 --> 00:01:24.040
generative AI that taps into specialized data&nbsp;
accumulated from thousands of customers and&nbsp;&nbsp;

00:01:24.040 --> 00:01:31.280
millions of users. With zero setup required,&nbsp;
SysAid's conversational AI manages employees'&nbsp;&nbsp;

00:01:31.280 --> 00:01:38.400
requests, assists with queries, and accelerates&nbsp;
the resolution of issues. IT pros and service&nbsp;&nbsp;

00:01:38.400 --> 00:01:44.680
management leaders become pioneers, enabling&nbsp;
productivity to thrive. Now, employees can&nbsp;&nbsp;

00:01:44.680 --> 00:01:52.107
do what they're meant to do and organizations are&nbsp;
free to fulfill their purpose. Give SysAid a try.

00:01:52.107 --> 00:01:52.800
Brian Spears:
Hi Craig, thanks for&nbsp;&nbsp;

00:01:52.800 --> 00:01:58.640
having me. My name is Brian Spears. I'm the&nbsp;
Director of the AI Institutional Initiative&nbsp;&nbsp;

00:01:58.640 --> 00:02:03.880
at Lawrence Livermore National Laboratory. Our&nbsp;
institutional initiative drives AI into all of our&nbsp;&nbsp;

00:02:03.880 --> 00:02:08.080
science missions at Lawrence Livermore National&nbsp;
Laboratory. Our central concerns are national&nbsp;&nbsp;

00:02:08.080 --> 00:02:13.640
security science. The principal one is stewarding&nbsp;
the nation's nuclear stockpile. Until recently,&nbsp;&nbsp;

00:02:13.640 --> 00:02:19.160
I was the Deputy Lead for our modeling and&nbsp;
simulation in our ICF (Inertial Confinement&nbsp;&nbsp;

00:02:19.160 --> 00:02:23.907
Fusion) program. That's the program&nbsp;
that we use to achieve fusion ignition.

00:02:23.907 --> 00:02:25.640
Brian Spears:
That is, we got out of a nuclear fuel&nbsp;&nbsp;

00:02:25.640 --> 00:02:30.760
target more energy by fusion than what we actually&nbsp;
put in by our laser driver. We did that at the end&nbsp;&nbsp;

00:02:30.760 --> 00:02:38.160
of 2022. My background gives me the ability&nbsp;
and the privilege to work on that. It comes from&nbsp;&nbsp;

00:02:38.160 --> 00:02:43.080
having gotten a PhD in mechanical engineering&nbsp;
from the University of California at Berkeley.&nbsp;&nbsp;

00:02:43.080 --> 00:02:48.560
Although I was an engineer, my research was in&nbsp;
nonlinear dynamical systems and high-dimensional&nbsp;&nbsp;

00:02:48.560 --> 00:02:54.840
topology for dynamical systems. So a bit of an&nbsp;
applied mathematician, and since I graduated&nbsp;&nbsp;

00:02:54.840 --> 00:03:01.360
with my PhD and started at Livermore, been a&nbsp;
physicist working in the fusion space. So, no one&nbsp;&nbsp;

00:03:01.360 --> 00:03:07.388
knows whether I'm a mathematician, engineer, or&nbsp;
physicist. I sort of like to defy categorization.

00:03:07.388 --> 00:03:09.720
Craig Smith:
Yeah. The AI initiative,&nbsp;&nbsp;

00:03:11.040 --> 00:03:14.227
how does that relate to the fusion ignition?

00:03:14.227 --> 00:03:16.280
Brian Spears:
So, they're pretty&nbsp;&nbsp;

00:03:16.280 --> 00:03:20.240
intimately linked. There are two pieces of&nbsp;
the world. So let me tell you a little bit&nbsp;&nbsp;

00:03:20.240 --> 00:03:24.480
about the fusion and I'll tell you about the&nbsp;
AI and how they're coupled together. To achieve&nbsp;&nbsp;

00:03:24.480 --> 00:03:31.720
fusion ignition for the first time, DOE, Lawrence&nbsp;
Livermore National Laboratory has spent 60 years,&nbsp;&nbsp;

00:03:31.720 --> 00:03:38.280
six decades, going from the invention of the&nbsp;
laser to using lasers to compress fuel targets&nbsp;&nbsp;

00:03:38.280 --> 00:03:43.960
with nuclear fuel in them to just recently, almost&nbsp;
two years ago, a year and a half, igniting that to&nbsp;&nbsp;

00:03:43.960 --> 00:03:49.840
get more energy out than what we put in. To do&nbsp;
that we have two principal pieces of what we do.&nbsp;&nbsp;

00:03:49.840 --> 00:03:55.240
One is enormous scale experiments. So the National&nbsp;
Mission Facility, the laser where we do this, is a&nbsp;&nbsp;

00:03:55.240 --> 00:04:00.880
10-story high football stadium-sized facility that&nbsp;
you could lay three football fields across the top&nbsp;&nbsp;

00:04:00.880 --> 00:04:07.200
of. That generates more precise experimental data&nbsp;
than most humans can imagine. The other piece that&nbsp;&nbsp;

00:04:07.200 --> 00:04:13.960
we use is the world's largest high-performance&nbsp;
computing and simulation capabilities. So we&nbsp;&nbsp;

00:04:13.960 --> 00:04:19.680
have tens of thousands of GPUs that are coupled&nbsp;
together to do physics simulations. So we can&nbsp;&nbsp;

00:04:19.680 --> 00:04:24.240
literally blow up a tiny target with the laser&nbsp;
and we can simulate the details down to the&nbsp;&nbsp;

00:04:24.240 --> 00:04:29.720
micron scale with picosecond or even femtosecond&nbsp;
resolution of exactly what's going to happen.

00:04:29.720 --> 00:04:32.880
Brian Spears:
Now what about the AI? What do we do&nbsp;&nbsp;

00:04:32.880 --> 00:04:39.440
with that? We now introduce AI into the middle of&nbsp;
those two things. So an AI model can be trained on&nbsp;&nbsp;

00:04:39.440 --> 00:04:45.000
hundreds of thousands of simulations, the things&nbsp;
that we think the world should do. We can build&nbsp;&nbsp;

00:04:45.000 --> 00:04:50.320
what we think of as a perfect AI surrogate and&nbsp;
that's fantastic, but it's still wrong. If our&nbsp;&nbsp;

00:04:50.320 --> 00:04:55.040
simulation codes were perfect we wouldn't need&nbsp;
the experimental capability. So now what do we&nbsp;&nbsp;

00:04:55.040 --> 00:05:00.760
do? We look at the experimental data, we take that&nbsp;
AI model trained on simulation, and we partially&nbsp;&nbsp;

00:05:00.760 --> 00:05:06.840
retrain that on the sparse but really high&nbsp;
precision experimental data. Then that AI model is&nbsp;&nbsp;

00:05:06.840 --> 00:05:11.680
now what I call an elevated model. It understands&nbsp;
the theory, the lay of the land, the way we expect&nbsp;&nbsp;

00:05:11.680 --> 00:05:16.200
the world to work from simulation, but it makes&nbsp;
precise and accurate corrections based on the&nbsp;&nbsp;

00:05:16.200 --> 00:05:21.480
experimental data. So now when I use that elevated&nbsp;
AI model, I get a picture of what I actually&nbsp;&nbsp;

00:05:21.480 --> 00:05:26.480
think is going to occur in the experimental&nbsp;
facility based on previous experimental data.

00:05:26.480 --> 00:05:28.480
Brian Spears:
That model we used,&nbsp;&nbsp;

00:05:28.480 --> 00:05:33.680
both the simulation piece and the experimental&nbsp;
piece joined in that AI model, we used to help&nbsp;&nbsp;

00:05:33.680 --> 00:05:38.280
make a prediction about what we expected to&nbsp;
happen before we had ever shot or fielded that&nbsp;&nbsp;

00:05:38.280 --> 00:05:45.360
target that ignited. And that model on the weeks&nbsp;
before, the night before we ran it again, that&nbsp;&nbsp;

00:05:45.360 --> 00:05:49.400
model said the most likely outcome was that for&nbsp;
the first time in human history, we would ignite&nbsp;&nbsp;

00:05:49.400 --> 00:05:53.880
one of these things. We woke up the next morning&nbsp;
at 4:30 in the morning, the way you do when you're&nbsp;&nbsp;

00:05:53.880 --> 00:05:59.640
anxious and you know a shot happens overnight,&nbsp;
and look to see and indeed that is what happened.

00:05:59.640 --> 00:06:01.920
Brian Spears:
Now the AI was critical but we have&nbsp;&nbsp;

00:06:01.920 --> 00:06:06.720
other ways of seeing this too. The simulations&nbsp;
by themselves were starting to say, [hey, this&nbsp;&nbsp;

00:06:06.720 --> 00:06:12.080
is looking promising]. The experimental record&nbsp;
that we had suggested that we were also moving&nbsp;&nbsp;

00:06:12.080 --> 00:06:16.320
in the direction of ignition and then we had this&nbsp;
new third way that was integrating both. It said,&nbsp;&nbsp;

00:06:16.320 --> 00:06:21.520
[indeed, those things are consistent with each&nbsp;
other and you should probably start betting for&nbsp;&nbsp;

00:06:21.520 --> 00:06:26.880
this rather than against it], which, after 18&nbsp;
years of not igniting something, it was pretty&nbsp;&nbsp;

00:06:26.880 --> 00:06:32.120
satisfying to do that. We've now repeated that&nbsp;
five times and our models have suggested that that&nbsp;&nbsp;

00:06:32.120 --> 00:06:38.200
would be the outcome. So we have this increasingly&nbsp;
confident predictive capability that we can detect&nbsp;&nbsp;

00:06:38.200 --> 00:06:43.240
and predict what's going to happen the next time&nbsp;
we do it. Is it perfect? Absolutely not. We are&nbsp;&nbsp;

00:06:43.240 --> 00:06:47.360
still pushing as hard as we can to improve&nbsp;
that process but we're getting real benefit&nbsp;&nbsp;

00:06:47.360 --> 00:06:51.628
out of high-performance computing experiment&nbsp;
with AI as the glue that's holding it together.

00:06:51.628 --> 00:06:53.880
Craig Smith:
Yeah. Does that create kind of a&nbsp;&nbsp;

00:06:53.880 --> 00:07:01.880
loop that every time you do an experiment that&nbsp;
the predictions have shown would be promising&nbsp;&nbsp;

00:07:01.880 --> 00:07:11.707
and there's some delta between the simulation and&nbsp;
the reality, that you can close that gap a little?

00:07:11.707 --> 00:07:14.800
Brian Spears:
That's right. Every time we do another experiment&nbsp;&nbsp;

00:07:14.800 --> 00:07:19.320
we learn a little more. Sometimes that experiment&nbsp;
is what you might call a success and the target&nbsp;&nbsp;

00:07:19.320 --> 00:07:23.760
actually ignites. Then we use that, we can go back&nbsp;
and make the model better. Sometimes the targets&nbsp;&nbsp;

00:07:23.760 --> 00:07:29.680
do not ignite and those are probably, in the long&nbsp;
run, even more valuable because we start to learn&nbsp;&nbsp;

00:07:29.680 --> 00:07:33.560
that there was something that we didn't detect&nbsp;
in the experiment that we need to account for;&nbsp;&nbsp;

00:07:33.560 --> 00:07:37.960
and we can usually go back and find that. Or&nbsp;
there was something in the simulation that we were&nbsp;&nbsp;

00:07:37.960 --> 00:07:43.280
approximating that we're going to have to stop&nbsp;
and get better at, or we just weren't reconciling&nbsp;&nbsp;

00:07:43.280 --> 00:07:49.400
the two of them carefully and those were actually&nbsp;
potentially at odds with one another. Now, sort of&nbsp;&nbsp;

00:07:49.400 --> 00:07:54.120
presaging what happens in the AI world to come&nbsp;
in the future, The National Ignition Facility,&nbsp;&nbsp;

00:07:54.120 --> 00:08:01.640
or NIF, can fire a shot once a week at that very&nbsp;
largest scale where we can ignite, or for smaller,&nbsp;&nbsp;

00:08:01.640 --> 00:08:05.867
slightly less ambitious experiments,&nbsp;
sometimes we can do shots three times a day.

00:08:05.867 --> 00:08:07.520
Brian Spears:
There are facilities now in the world that&nbsp;&nbsp;

00:08:07.520 --> 00:08:12.680
we call high repetition rate laser facilities.&nbsp;
They actually fire at hertz. So you do the same&nbsp;&nbsp;

00:08:12.680 --> 00:08:17.080
thing that I just described: make a prediction,&nbsp;
fire an experiment, look at that delta that you&nbsp;&nbsp;

00:08:17.080 --> 00:08:21.560
talked about of the discrepancy, and then choose&nbsp;
the next place to go. But the next experiment has&nbsp;&nbsp;

00:08:21.560 --> 00:08:26.960
to be planned 100 milliseconds later so you&nbsp;
can't have me make a decision about that. So&nbsp;&nbsp;

00:08:26.960 --> 00:08:32.440
what do we do? We have started to train AI agents&nbsp;
to help us look at that outcome, the delta and&nbsp;&nbsp;

00:08:32.440 --> 00:08:36.600
then choose the next experiment in order to make&nbsp;
the outcome what we want to be better. So we've&nbsp;&nbsp;

00:08:36.600 --> 00:08:41.560
done this running hundreds of experiments over&nbsp;
the course of minutes or a fraction of an hour&nbsp;&nbsp;

00:08:41.560 --> 00:08:45.947
far faster than what we could do at the National&nbsp;
Ignition Facility to prove these concepts out.

00:08:45.947 --> 00:08:46.840
Brian Spears:
Now, the lasers that&nbsp;&nbsp;

00:08:46.840 --> 00:08:52.840
go fast are small. They're very high powers but&nbsp;
they deliver a tiny amount of energy in an even&nbsp;&nbsp;

00:08:52.840 --> 00:08:58.680
tinier amount of time. So it might be a joule&nbsp;
laser or maybe even up to a kilojoule laser,&nbsp;&nbsp;

00:08:59.480 --> 00:09:04.240
which is a thousand joules. The National&nbsp;
Ignition Facility is a two-megajoule laser or&nbsp;&nbsp;

00:09:04.240 --> 00:09:12.200
two million-joule laser and the difference for a&nbsp;
million times in energy is the difference between,&nbsp;&nbsp;

00:09:12.200 --> 00:09:16.720
I can make something really hot versus, at&nbsp;
the National Ignition Facility, I can make&nbsp;&nbsp;

00:09:16.720 --> 00:09:22.480
it hotter and denser than the center of the sun or&nbsp;
of stars. So we are not yet in a place where I can&nbsp;&nbsp;

00:09:22.480 --> 00:09:27.880
take NIF and operate it at 10 times per second.&nbsp;
That's where we want the world to go and in fact,&nbsp;&nbsp;

00:09:27.880 --> 00:09:32.960
if you do that, if you can get fusion ignition&nbsp;
to operate at about 10 times per second,&nbsp;&nbsp;

00:09:32.960 --> 00:09:38.000
or 10 hertz, then what you have is a&nbsp;
commercially viable fusion energy source.

00:09:38.000 --> 00:09:39.880
Brian Spears:
Now, that's a nice outcome&nbsp;&nbsp;

00:09:39.880 --> 00:09:45.960
from the National Ignition Facility; its primary&nbsp;
focus is generating fusion conditions that we know&nbsp;&nbsp;

00:09:45.960 --> 00:09:50.760
to represent key challenges for the nation's&nbsp;
nuclear stockpile and strategic deterrent. We&nbsp;&nbsp;

00:09:50.760 --> 00:09:55.800
are using that today. In fact, on the very first&nbsp;
ignition experiment, we took what we call failure&nbsp;&nbsp;

00:09:55.800 --> 00:10:00.640
mode diagnostics off of that experiment, we&nbsp;
put on a national security package and we&nbsp;&nbsp;

00:10:00.640 --> 00:10:05.400
exposed a material we were interested in to the&nbsp;
conditions that are consistent with environments&nbsp;&nbsp;

00:10:05.400 --> 00:10:10.000
we're interested in for nuclear weapons and&nbsp;
their applications. One, because we had the&nbsp;&nbsp;

00:10:10.000 --> 00:10:15.440
confidence and we thought we could do a secondary&nbsp;
experiment there; and two, because once you do,&nbsp;&nbsp;

00:10:15.440 --> 00:10:19.560
you can directly answer questions for the&nbsp;
stockpile that previously you would have&nbsp;&nbsp;

00:10:19.560 --> 00:10:24.800
either needed codes to predict or simulations&nbsp;
(which are not quite good enough by themselves),&nbsp;&nbsp;

00:10:24.800 --> 00:10:30.548
or you would have needed underground nuclear test&nbsp;
data, and we don't do nuclear testing anymore.

00:10:30.548 --> 00:10:31.520
Craig Smith:
Yeah. And what are you&nbsp;&nbsp;

00:10:31.520 --> 00:10:36.120
trying to predict on the stockpile?&nbsp;
Whether they're still viable?

00:10:36.120 --> 00:10:38.840
Brian Spears:
We have all kinds of questions&nbsp;&nbsp;

00:10:38.840 --> 00:10:45.960
that we answer about stockpile stewardship. We&nbsp;
make sure that the stockpile is safe: that it&nbsp;&nbsp;

00:10:45.960 --> 00:10:51.040
is part of what we call the always never, those&nbsp;
systems should always be used when the nation&nbsp;&nbsp;

00:10:51.040 --> 00:10:56.120
demands them, they should never be available to&nbsp;
be used if we don't want them to be, and what&nbsp;&nbsp;

00:10:56.120 --> 00:11:01.280
we're working on hard is to have a very capable&nbsp;
strategic deterrent so that no one uses those&nbsp;&nbsp;

00:11:01.280 --> 00:11:07.160
weapons across the world. So the questions that&nbsp;
we answer surround the way that materials age,&nbsp;&nbsp;

00:11:07.160 --> 00:11:11.800
the way that they react to environments that are&nbsp;
harsh (that are filled with neutrons and radiation&nbsp;&nbsp;

00:11:11.800 --> 00:11:18.400
sources). And they help us understand how to&nbsp;
design systems that have a longer lifetime, how to&nbsp;&nbsp;

00:11:18.400 --> 00:11:23.160
reuse parts from the stockpile in weapon systems&nbsp;
that make us more effective as an enterprise,&nbsp;&nbsp;

00:11:23.160 --> 00:11:27.800
and how to design systems that are effective&nbsp;
and safe for the strategic deterrent mission.

00:11:27.800 --> 00:11:29.240
Craig Smith:
On the ignition,&nbsp;&nbsp;

00:11:30.560 --> 00:11:39.160
I didn't understand that because there's this&nbsp;
brief spark where you're getting more energy&nbsp;&nbsp;

00:11:39.160 --> 00:11:46.760
out than is going in. I thought the goal was&nbsp;
then to create a sustained fusion reaction&nbsp;&nbsp;

00:11:46.760 --> 00:11:56.600
but what you're saying is you just want these&nbsp;
sparks in close temporal proximity and that's&nbsp;&nbsp;

00:11:56.600 --> 00:12:02.627
enough to get energy out. You don't need a&nbsp;
sustained fusion reaction. Is that right?

00:12:02.627 --> 00:12:04.360
Brian Spears:
That's right. So&nbsp;&nbsp;

00:12:04.360 --> 00:12:08.320
there are two approaches to fusion. One&nbsp;
is magnetic confinement fusion and there,&nbsp;&nbsp;

00:12:08.320 --> 00:12:12.480
the process looks a little bit like what you had&nbsp;
in mind. You want to squeeze the plasma using a&nbsp;&nbsp;

00:12:12.480 --> 00:12:16.480
magnetic bottle, essentially, a confinement;&nbsp;
it's going to run for as long as you can keep&nbsp;&nbsp;

00:12:16.480 --> 00:12:20.400
it confined (so if you don't have instabilities&nbsp;
that break up that confinement). That's going&nbsp;&nbsp;

00:12:20.400 --> 00:12:24.640
to put power into the grid; you should think of&nbsp;
that a little bit like a jet engine. So there's&nbsp;&nbsp;

00:12:24.640 --> 00:12:29.160
a combustion process with fuel coming in and&nbsp;
power going out, and it does what it needs to do.

00:12:29.160 --> 00:12:31.480
Brian Spears:
The inertial confinement fusion,&nbsp;&nbsp;

00:12:31.480 --> 00:12:36.160
or ICF approach, is a lot more like your&nbsp;
car engine. You have a brief explosion,&nbsp;&nbsp;

00:12:36.160 --> 00:12:41.120
then you have another one, then you have&nbsp;
another one, and if it happens often enough&nbsp;&nbsp;

00:12:41.120 --> 00:12:47.880
the average power that you get out is enough&nbsp;
to take that power and put it into, say,&nbsp;&nbsp;

00:12:47.880 --> 00:12:52.040
a blanket of water and run a steam cycle. So&nbsp;
you would run a power plant just like you do&nbsp;&nbsp;

00:12:52.040 --> 00:12:57.680
today except instead of burning a hydrocarbon or&nbsp;
fossil fuel, you're firing these targets quickly.&nbsp;&nbsp;

00:12:57.680 --> 00:13:02.120
And because of the way that the systems scale&nbsp;
physically and what the economics look like,&nbsp;&nbsp;

00:13:02.120 --> 00:13:07.720
you have to be able to do it at about 10 times&nbsp;
per second and you have to get about 20 times&nbsp;&nbsp;

00:13:07.720 --> 00:13:13.640
more energy per implosion out than what we get&nbsp;
right now. So that number can sound like a lot,&nbsp;&nbsp;

00:13:13.640 --> 00:13:18.920
20 times more than what we get right now, but that&nbsp;
is a teeny tiny bit. In fact, we're probably down&nbsp;&nbsp;

00:13:18.920 --> 00:13:23.747
to about 10 times more than what we need right&nbsp;
now, the way that we have increased the yields.

00:13:23.747 --> 00:13:27.800
Brian Spears:
We started in 2012, 2013 at&nbsp;&nbsp;

00:13:29.360 --> 00:13:34.960
more than 100, depending how you count, maybe even&nbsp;
1000 times lower yield (or energy out) than what&nbsp;&nbsp;

00:13:34.960 --> 00:13:40.360
we have right now. So we've come a factor of,&nbsp;
let's say 500, up from where we are. We have&nbsp;&nbsp;

00:13:40.360 --> 00:13:48.160
only a factor of 10 left to go. That's really&nbsp;
not very far. That's for the energy purpose but&nbsp;&nbsp;

00:13:48.160 --> 00:13:53.200
really what we're doing today, the mission that is&nbsp;
fully functional, fully operating, is the one that&nbsp;&nbsp;

00:13:53.200 --> 00:13:57.188
takes care of the stockpile and lets us answer&nbsp;
real questions about the way our systems work.

00:13:57.188 --> 00:13:58.880
Craig Smith:
Right. And on the ignition,&nbsp;&nbsp;

00:13:58.880 --> 00:14:08.000
that last factor of 10, it's not only&nbsp;
closing that gap but being able to do&nbsp;&nbsp;

00:14:08.000 --> 00:14:11.800
it 10 times a second. What is the challenge there?

00:14:11.800 --> 00:14:12.400
Brian Spears:&nbsp;

00:14:12.400 --> 00:14:18.240
The challenges are a few. One you got to be&nbsp;
able to do it with that kind of confidence:&nbsp;&nbsp;

00:14:18.240 --> 00:14:22.800
that you think you can do it every time&nbsp;
that you pull the trigger on the laser. Two,&nbsp;&nbsp;

00:14:22.800 --> 00:14:27.560
you need to have a laser driver that can operate&nbsp;
at that frequency. So I told you we have high rep&nbsp;&nbsp;

00:14:27.560 --> 00:14:33.200
rate lasers that can do that. They can't do it at&nbsp;
the energies that are required to cause diffusion&nbsp;&nbsp;

00:14:33.200 --> 00:14:37.440
ignition so you're going to have to get that&nbsp;
repetition rate laser up to the energy that can&nbsp;&nbsp;

00:14:37.440 --> 00:14:43.400
do fusion or take a fusion energy laser and get it&nbsp;
rep-rated so that it can happen that frequently.

00:14:43.400 --> 00:14:44.560
Brian Spears:&nbsp;

00:14:44.560 --> 00:14:48.640
If you do solve that problem, the next problem&nbsp;
that you have is that you need a target in front&nbsp;&nbsp;

00:14:48.640 --> 00:14:54.400
of that laser at 10 hertz. So that means you&nbsp;
have to have been able to build out a target&nbsp;&nbsp;

00:14:54.400 --> 00:15:01.400
at 10 times per second. Right now our targets are&nbsp;
exquisitely scientifically engineered pieces of&nbsp;&nbsp;

00:15:01.400 --> 00:15:06.800
micromachinery that take us months to build. You&nbsp;
got to get that operation down to effectively,&nbsp;&nbsp;

00:15:06.800 --> 00:15:11.400
you can do it at hertz, and it needs to cost&nbsp;
about 25 cents per target or so and put that&nbsp;&nbsp;

00:15:11.400 --> 00:15:19.840
in front of a laser. So there are hurdles&nbsp;
and DOE, the fusion energy science world,&nbsp;&nbsp;

00:15:19.840 --> 00:15:26.840
is really interested in building out a successful&nbsp;
ecosystem for fusion energy for the United States.&nbsp;&nbsp;

00:15:26.840 --> 00:15:32.240
So there's a really broad and vigorous startup&nbsp;
community. Lawrence Livermore is working with&nbsp;&nbsp;

00:15:32.240 --> 00:15:39.480
those folks to share the lessons that we've&nbsp;
learned to make them more capable and to close&nbsp;&nbsp;

00:15:39.480 --> 00:15:44.080
the gap between what we do on the science side&nbsp;
for the stockpile and what we've learned that&nbsp;&nbsp;

00:15:44.080 --> 00:15:48.668
can then be taken up by private partners to&nbsp;
make that work for inertial fusion energy.

00:15:48.668 --> 00:15:50.240
Craig Smith:
And you're optimistic&nbsp;&nbsp;

00:15:51.320 --> 00:15:59.280
that that'll happen. I mean, is it just an&nbsp;
engineering problem or are there more fundamental&nbsp;&nbsp;

00:15:59.280 --> 00:16:00.400
questions that need to be answered?

00:16:00.400 --> 00:16:02.440
Brian Spears:
Yeah, that's the exciting part of&nbsp;&nbsp;

00:16:02.440 --> 00:16:08.320
ignition. There was a fundamental worry, before we&nbsp;
ignited that for the first time, that there could&nbsp;&nbsp;

00:16:08.320 --> 00:16:14.200
be hidden physics mechanisms or scaling issues in&nbsp;
there that meant that a two-megajoule laser was&nbsp;&nbsp;

00:16:14.200 --> 00:16:19.800
physically incapable of igniting deuterium-tritium&nbsp;
thermonuclear fuel. That is off the table. We can&nbsp;&nbsp;

00:16:19.800 --> 00:16:26.200
absolutely, 100% do it again. Now it's a matter of&nbsp;
quantitative degree. So then in that sense, yeah,&nbsp;&nbsp;

00:16:26.200 --> 00:16:32.840
it's just engineering. Okay, but that engineering&nbsp;
is really hard, it's super challenging. You've got&nbsp;&nbsp;

00:16:32.840 --> 00:16:36.280
to work on laser technologies, you've&nbsp;
got to work on target technologies,&nbsp;&nbsp;

00:16:36.280 --> 00:16:43.160
you've got to put that capability inside a viable&nbsp;
fusion power plant, and we have partners that&nbsp;&nbsp;

00:16:43.160 --> 00:16:47.840
are thinking about all of those things. So you&nbsp;
asked me if I'm optimistic. Yeah, I'm absolutely&nbsp;&nbsp;

00:16:47.840 --> 00:16:52.707
optimistic, but you have to be an optimist&nbsp;
to work in fusion. That's the way it goes.

00:16:52.707 --> 00:16:53.560
Brian Spears:
There's an old joke,&nbsp;&nbsp;

00:16:53.560 --> 00:16:58.120
which anybody in the audience maybe you've&nbsp;
even heard, that fusion power is 30 years&nbsp;&nbsp;

00:16:58.120 --> 00:17:03.720
away and always will be, right. Yeah, so that's&nbsp;
sort of trite and it's a little bit old. People&nbsp;&nbsp;

00:17:03.720 --> 00:17:10.200
used to say fusion ignition is 30 years away&nbsp;
and always will be. But it's not, we did it. So&nbsp;&nbsp;

00:17:10.200 --> 00:17:15.360
that joke is retired. So now you can make it about&nbsp;
fusion power but you can't make it about ignition.

00:17:15.360 --> 00:17:16.080
Brian Spears:
What I will say&nbsp;&nbsp;

00:17:16.080 --> 00:17:19.840
is that I'm pretty confident that in my&nbsp;
children's lifetime, we will see fusion&nbsp;&nbsp;

00:17:19.840 --> 00:17:24.840
power on the grid. If you really pressed&nbsp;
me, I'd be more optimistic than that. But,&nbsp;&nbsp;

00:17:24.840 --> 00:17:31.360
it's not a tomorrow problem. Because it&nbsp;
is “just engineering”, it's a matter of&nbsp;&nbsp;

00:17:31.360 --> 00:17:37.080
will from the federal government. With&nbsp;
sufficient resources, the United States&nbsp;&nbsp;

00:17:37.080 --> 00:17:42.680
can go do this. The current administration&nbsp;
has put out a bold decadal vision in fusion,&nbsp;&nbsp;

00:17:42.680 --> 00:17:47.880
saying that in the next decade, we are going to&nbsp;
greatly advance this. With sufficient funding,&nbsp;&nbsp;

00:17:47.880 --> 00:17:53.148
the United States can go do this. We can do it&nbsp;
first and we're the only country that can do it.

00:17:53.148 --> 00:17:54.840
Craig Smith:
Yeah. On the other,&nbsp;&nbsp;

00:17:56.000 --> 00:18:01.960
the containment fusion, where you&nbsp;
have a plasma that you're containing&nbsp;&nbsp;

00:18:01.960 --> 00:18:10.040
with magnets or whatever; Is&nbsp;
that ahead of the– is it ICF?

00:18:10.040 --> 00:18:11.600
Brian Spears:
Yeah. The convenient&nbsp;&nbsp;

00:18:11.600 --> 00:18:16.400
terms for everybody to think of is, there's the&nbsp;
Magnetic Confinement, or MCF side, and there's&nbsp;&nbsp;

00:18:16.400 --> 00:18:22.360
the Inertial Confinement, or ICF side. We are&nbsp;
complementary to each other. We will say the&nbsp;&nbsp;

00:18:22.360 --> 00:18:28.760
magnetic confinement community is farther ahead in&nbsp;
the engineering. So giant machines like Tokamaks&nbsp;&nbsp;

00:18:29.640 --> 00:18:36.000
are easier to imagine; they're further along,&nbsp;
they exist in the world. They're not yet fully&nbsp;&nbsp;

00:18:36.000 --> 00:18:40.120
functional. They're not capable of confining their&nbsp;
plasmas for long enough to get more energy out&nbsp;&nbsp;

00:18:40.120 --> 00:18:45.880
of them than what they're putting in from their&nbsp;
confinement scheme. We, on the other hand, know&nbsp;&nbsp;

00:18:45.880 --> 00:18:49.920
that we can get more energy out than what we put&nbsp;
in by the laser driver, but then that would have&nbsp;&nbsp;

00:18:49.920 --> 00:18:54.520
to be coupled to a really complicated engineering&nbsp;
machine that fires at 10 hertz and we're a long&nbsp;&nbsp;

00:18:54.520 --> 00:19:03.040
way away from that. If there were four corners&nbsp;
of a 2D matrix, we're in opposite corners. What&nbsp;&nbsp;

00:19:03.040 --> 00:19:09.520
really makes sense for the United States– push&nbsp;
both of these forward. We can lead in both of&nbsp;&nbsp;

00:19:09.520 --> 00:19:15.108
these capabilities and we absolutely should. It's&nbsp;
what makes me optimistic about both approaches.

00:19:15.108 --> 00:19:16.320
Craig Smith:
Are any other&nbsp;&nbsp;

00:19:16.320 --> 00:19:22.547
countries as close or close behind the US?

00:19:22.547 --> 00:19:24.480
Brian Spears:
Yeah. In the magnetic world,&nbsp;&nbsp;

00:19:24.480 --> 00:19:29.280
there's a large international collaboration&nbsp;
on the largest project called ITER,&nbsp;&nbsp;

00:19:29.280 --> 00:19:35.760
which is in Europe. That has participants from&nbsp;
around the world and that is the biggest, most&nbsp;&nbsp;

00:19:35.760 --> 00:19:41.760
ambitious view of what you can do with magnetic&nbsp;
confinement. It's an enormous engineering project&nbsp;&nbsp;

00:19:41.760 --> 00:19:48.560
and it's slow to come to fruition but they're&nbsp;
working very hard to do that. The US is a player&nbsp;&nbsp;

00:19:48.560 --> 00:19:54.600
but we don't dominate that space. Absolutely&nbsp;
critical. My magnetic confinement colleagues&nbsp;&nbsp;

00:19:54.600 --> 00:19:58.640
will probably say that they're at the forefront&nbsp;
leading that and that's probably not wrong.

00:19:58.640 --> 00:20:01.120
Brian Spears:
In inertial confinement fusion, we are the only&nbsp;&nbsp;

00:20:01.120 --> 00:20:06.080
game in the world. There are other laser systems&nbsp;
around the world that are under development. We&nbsp;&nbsp;

00:20:06.080 --> 00:20:11.200
have partners in France that have built out a&nbsp;
laser system called the Laser Megajoule or LMJ&nbsp;&nbsp;

00:20:11.200 --> 00:20:16.320
that is very much a NIF-like system. There are&nbsp;
lasers that scale that have been considered and&nbsp;&nbsp;

00:20:16.320 --> 00:20:21.640
partially built in China and Russia is considering&nbsp;
a similar system. So there's a geopolitical angle&nbsp;&nbsp;

00:20:21.640 --> 00:20:26.520
to the way that these are working out, some of&nbsp;
them US allies, some of them US adversaries but&nbsp;&nbsp;

00:20:26.520 --> 00:20:33.748
we are much farther ahead in the ICF world&nbsp;
than the US is ahead on the magnetic world.

00:20:33.748 --> 00:20:34.360
Craig Smith:
Yeah. Although,&nbsp;&nbsp;

00:20:34.360 --> 00:20:45.667
this isn't a military technology. I mean, this&nbsp;
is for the production of electricity ultimately.

00:20:45.667 --> 00:20:48.480
Brian Spears:
That's right. There's no military interest&nbsp;&nbsp;

00:20:48.480 --> 00:20:54.000
in using our National Ignition Facility to take&nbsp;
that and put energy on some target for military&nbsp;&nbsp;

00:20:54.000 --> 00:20:59.120
purposes. The closest thing to military uses is&nbsp;
the science that we can understand to take care of&nbsp;&nbsp;

00:20:59.120 --> 00:21:03.840
the strategic deterrent, to make sure that we have&nbsp;
functional weapon systems that do what they're&nbsp;&nbsp;

00:21:03.840 --> 00:21:08.600
supposed to do; that “always never” that I talked&nbsp;
about. Again though, the goal is to make sure&nbsp;&nbsp;

00:21:08.600 --> 00:21:13.840
that no one ever uses these systems. They’re to&nbsp;
stay parked and dry where they're supposed to be&nbsp;&nbsp;

00:21:13.840 --> 00:21:18.320
because it's clear that there's no winning outcome&nbsp;
for anyone should they use them. The National&nbsp;&nbsp;

00:21:18.320 --> 00:21:22.720
Initiation Facility is part of that deterrent&nbsp;
mission. In fact, we use that to show the world&nbsp;&nbsp;

00:21:22.720 --> 00:21:29.280
openly, [look how capable our scientific staff is&nbsp;
in this endeavor]. If we are that capable in our&nbsp;&nbsp;

00:21:29.280 --> 00:21:34.760
open capabilities, you should understand what we&nbsp;
do when we're not telling you exactly what's going&nbsp;&nbsp;

00:21:34.760 --> 00:21:39.800
on. So the scientists and the team that I have&nbsp;
the privilege to work with, we are part of the&nbsp;&nbsp;

00:21:39.800 --> 00:21:45.508
strategic deterrent. This is what our nation-state&nbsp;
is capable of; everyone else should understand.

00:21:45.508 --> 00:21:46.880
Craig Smith:
Yeah. One of&nbsp;&nbsp;

00:21:46.880 --> 00:21:50.040
the things that interests me&nbsp;
about that is the simulation,&nbsp;&nbsp;

00:21:51.200 --> 00:22:00.800
the use of the supercomputers or clusters–&nbsp;
I'm not sure how it's configured, yeah,&nbsp;&nbsp;

00:22:00.800 --> 00:22:10.840
to do these simulations. So not only for fusion&nbsp;
research but for biotechnology research or&nbsp;&nbsp;

00:22:10.840 --> 00:22:20.720
anything. Can you talk about the computers behind&nbsp;
those simulations? Are they physical computers&nbsp;&nbsp;

00:22:20.720 --> 00:22:33.947
at the lab? Is it cloud infrastructure that's&nbsp;
being orchestrated? How can you describe that?

00:22:33.947 --> 00:22:34.560
Brian Spears:
Yeah. So I'd like to&nbsp;&nbsp;

00:22:34.560 --> 00:22:38.960
talk about two things. I'll talk about our current&nbsp;
compute capability and then where we're going in&nbsp;&nbsp;

00:22:38.960 --> 00:22:43.880
AI to accelerate and transform the capability&nbsp;
for the country. Currently, the Department of&nbsp;&nbsp;

00:22:43.880 --> 00:22:49.920
Energy maintains the biggest integrated precision&nbsp;
compute systems on the planet. Lawrence Livermore&nbsp;&nbsp;

00:22:49.920 --> 00:22:54.680
has the most capable machine room for scientific&nbsp;
computing on the planet. For a feeling of scale,&nbsp;&nbsp;

00:22:54.680 --> 00:23:01.160
what does that look like? There are more GPUs&nbsp;
and CPUs in Livermore than you can probably&nbsp;&nbsp;

00:23:01.160 --> 00:23:05.520
imagine. Our largest machine, which will turn&nbsp;
on sometime, probably this month, being built&nbsp;&nbsp;

00:23:05.520 --> 00:23:11.507
currently as we speak, will have more than 30,000&nbsp;
graphics processing units, or GPUs, inside it.

00:23:11.507 --> 00:23:13.000
Brian Spears:
That machine room by itself,&nbsp;&nbsp;

00:23:13.000 --> 00:23:20.480
which has more than a half dozen supercomputers in&nbsp;
it, pulls in 85 megawatts of power. 85 megawatts&nbsp;&nbsp;

00:23:20.480 --> 00:23:26.840
is about the size of a power plant that pushes a&nbsp;
Navy sub through the water, roughly, for scale;&nbsp;&nbsp;

00:23:26.840 --> 00:23:31.200
you can move a boat through the ocean at&nbsp;
considerable speed doing that. We use all&nbsp;&nbsp;

00:23:31.200 --> 00:23:36.720
of that power and energy to do math really,&nbsp;
really, really fast. That math provides the&nbsp;&nbsp;

00:23:36.720 --> 00:23:42.640
capability to do simulations at the micron,&nbsp;
sometimes the atomic-level scale, to understand&nbsp;&nbsp;

00:23:42.640 --> 00:23:49.360
what happens in weapon systems, to do biological&nbsp;
missions of the way that proteins fold or small&nbsp;&nbsp;

00:23:49.360 --> 00:23:54.080
molecules interact with biological systems.&nbsp;
And then those same systems that are great for&nbsp;&nbsp;

00:23:54.080 --> 00:23:58.840
the high precision scientific computing, we have&nbsp;
engineered to be also good for the low precision&nbsp;&nbsp;

00:23:58.840 --> 00:24:05.000
AI. So what AI really needs is not the high&nbsp;
precision, what we would call double precision&nbsp;&nbsp;

00:24:05.000 --> 00:24:10.080
scientific computing. It needs lower precision,&nbsp;
but it needs it fast and in a repetitive way,&nbsp;&nbsp;

00:24:10.080 --> 00:24:15.347
doing similar operations over and over again.&nbsp;
That's what graphics processing units are for.

00:24:15.347 --> 00:24:17.520
Brian Spears:
The DOE has been at the forefront of&nbsp;&nbsp;

00:24:17.520 --> 00:24:24.120
designing new architectures to do exactly that. In&nbsp;
fact, the GPUs that our tech industry and AI world&nbsp;&nbsp;

00:24:24.120 --> 00:24:29.040
are working with today, much of that technology&nbsp;
has grown out of co-design between our vendor&nbsp;&nbsp;

00:24:29.040 --> 00:24:34.760
partners like NVIDIA or AMD and the Department of&nbsp;
Energy, where we showed them where we need to go;&nbsp;&nbsp;

00:24:34.760 --> 00:24:39.320
they've helped show us how to get there and we've&nbsp;
designed together GPUs for computation that is&nbsp;&nbsp;

00:24:39.320 --> 00:24:45.120
more than just graphics processing on your laptop.&nbsp;
So it's something we're proud of at DOE and we&nbsp;&nbsp;

00:24:45.120 --> 00:24:53.720
used our Exascale Computing Project, trying to get&nbsp;
to exascale, or 10^18 operations per second. We've&nbsp;&nbsp;

00:24:53.720 --> 00:24:58.320
used that capability jointly, that co-design,&nbsp;
to build out this capability for the world.&nbsp;&nbsp;

00:24:59.040 --> 00:25:04.400
That's great. How do we use AI? How does it drive&nbsp;
the future? So the computers that we have at that&nbsp;&nbsp;

00:25:04.400 --> 00:25:11.080
enormous scale, so tens of thousands of GPUs,&nbsp;
each of those GPUs cost as much as a car. These&nbsp;&nbsp;

00:25:11.080 --> 00:25:15.547
are sort of $30,000 kinds of commodities that&nbsp;
we're putting tens of thousands of them together.

00:25:15.547 --> 00:25:17.680
Brian Spears:
Our next supercomputer is an order&nbsp;&nbsp;

00:25:17.680 --> 00:25:23.320
of magnitude, a half-billion-dollar machine that&nbsp;
we use to do this compute. It does the science&nbsp;&nbsp;

00:25:23.320 --> 00:25:28.440
but it also does the AI which opens up that&nbsp;
mission space that we open with. I can do all the&nbsp;&nbsp;

00:25:28.440 --> 00:25:33.400
scientific computing on the simulation capability.&nbsp;
Then I can train a model on top of that,&nbsp;&nbsp;

00:25:33.400 --> 00:25:38.080
admit that that's not perfect and then retrain it&nbsp;
and pull in the experimental data. But the same&nbsp;&nbsp;

00:25:38.080 --> 00:25:43.040
computer that can run the science can also run&nbsp;
the AI on top of it. We're building out strong&nbsp;&nbsp;

00:25:43.040 --> 00:25:49.400
public-private partnerships with companies that&nbsp;
are vendors, also with companies that are in the&nbsp;&nbsp;

00:25:49.400 --> 00:25:54.240
software world. So we're exploring relationships&nbsp;
with names that you recognize like Google, OpenAI,&nbsp;&nbsp;

00:25:54.240 --> 00:25:58.720
and other folks, all just relationships that&nbsp;
we're starting to build. We also have strong&nbsp;&nbsp;

00:25:58.720 --> 00:26:02.960
partnerships with users of that capability to&nbsp;
help us understand what we also don't know,&nbsp;&nbsp;

00:26:02.960 --> 00:26:08.627
like the GEs, the Boeings, or the Mercedes&nbsp;
of the world. So there's an entire ecosystem.

00:26:08.627 --> 00:26:10.760
Brian Spears:
DOE is highly capable of moving&nbsp;&nbsp;

00:26:10.760 --> 00:26:17.400
this forward but we can't do it alone. What does&nbsp;
make us special is the scale that we operate. So&nbsp;&nbsp;

00:26:17.400 --> 00:26:25.760
here at the SCSP AI Expo, we have rolled out from&nbsp;
DOE an initiative that we call FAST Foundations&nbsp;&nbsp;

00:26:25.760 --> 00:26:32.160
in AI for Science Security and Technology. FAST&nbsp;
is aimed at taking what we understand about the&nbsp;&nbsp;

00:26:32.160 --> 00:26:37.880
AI world and scaling it up to US-nation scale,&nbsp;
being able to do things that are transformational&nbsp;&nbsp;

00:26:37.880 --> 00:26:43.360
for strategic deterrent, for bioresilience, for&nbsp;
decision-making in the intelligence community.&nbsp;&nbsp;

00:26:43.360 --> 00:26:49.640
What we need is the capability to build&nbsp;
frontier AI models on demand and at will&nbsp;&nbsp;

00:26:49.640 --> 00:26:54.587
in the national security missions and we need to&nbsp;
be the first to do it. It's absolutely critical.

00:26:54.587 --> 00:26:56.000
Brian Spears:
There's a global race on&nbsp;&nbsp;

00:26:56.000 --> 00:27:00.760
taking that compute technology that we built here&nbsp;
in the US and doing transformational things with&nbsp;&nbsp;

00:27:00.760 --> 00:27:05.520
it. There are adversaries in the world, especially&nbsp;
China, who have declared that they will dominate&nbsp;&nbsp;

00:27:05.520 --> 00:27:11.800
in the AI space by 2030. The National Security&nbsp;
Commission on AI took a hard look at this around&nbsp;&nbsp;

00:27:11.800 --> 00:27:19.960
2021, 2022 and they said in this global scale–&nbsp;
there were six structural features that they&nbsp;&nbsp;

00:27:19.960 --> 00:27:25.720
looked at and most players in the world cannot&nbsp;
compete with the US, save China. China's ahead&nbsp;&nbsp;

00:27:25.720 --> 00:27:30.067
in half the features. The US is ahead in&nbsp;
half the features. Who wins, is a toss-up.

00:27:30.067 --> 00:27:31.400
Brian Spears:
So the Department of Energy has&nbsp;&nbsp;

00:27:31.400 --> 00:27:36.600
stepped up and said we know how to do computing&nbsp;
at enormous scale. We understand what the national&nbsp;&nbsp;

00:27:36.600 --> 00:27:41.600
security needs are for the country. We're in a&nbsp;
unique position to bring together the compute&nbsp;&nbsp;

00:27:41.600 --> 00:27:45.600
capability and that awareness of those missions&nbsp;
and put it together and do something productive.&nbsp;&nbsp;

00:27:45.600 --> 00:27:51.240
So FAST is the answer to that. It's a way that we&nbsp;
do four things for the country at huge scale. One&nbsp;&nbsp;

00:27:51.240 --> 00:27:56.440
is, take huge amounts of data and do something&nbsp;
transformational, from advanced light sources,&nbsp;&nbsp;

00:27:56.440 --> 00:28:02.440
accelerators, fusion facilities, you name, it&nbsp;
the world's best experiments, combine that with&nbsp;&nbsp;

00:28:02.440 --> 00:28:08.000
simulation data; so data is one. The second is a&nbsp;
simulation and computing capability. We have the&nbsp;&nbsp;

00:28:08.000 --> 00:28:13.160
largest computers in the entire world. Data plus&nbsp;
those computers, it's a really nice environment&nbsp;&nbsp;

00:28:13.160 --> 00:28:17.920
to do a third thing, which is build out&nbsp;
transformational AI models. If you do all of those&nbsp;&nbsp;

00:28:17.920 --> 00:28:24.360
three things: data, compute, and models, you can&nbsp;
make tools for AI that then transform the fourth&nbsp;&nbsp;

00:28:24.360 --> 00:28:28.907
piece, which is critical applications. Those are&nbsp;
the national missionaries that I'm talking about.

00:28:28.907 --> 00:28:30.400
Brian Spears:
So the FAST effort is&nbsp;&nbsp;

00:28:30.400 --> 00:28:35.560
this very ambitious, whole-of-nation effort&nbsp;
led by DOE to go transform what we're doing&nbsp;&nbsp;

00:28:35.560 --> 00:28:39.600
in AI. It will be pointed at things&nbsp;
like we started the conversation with,&nbsp;&nbsp;

00:28:39.600 --> 00:28:44.800
at fusion. If we want to go get that for taking&nbsp;
care of the stockpile, we've got it now. We can&nbsp;&nbsp;

00:28:44.800 --> 00:28:49.000
push up the capabilities to expand in new&nbsp;
ranges. We could think about inertial fusion&nbsp;&nbsp;

00:28:49.000 --> 00:28:55.187
energy. We could think about challenge problems&nbsp;
that were unthinkable even five years ago.

00:28:55.187 --> 00:28:57.480
Brian Spears:
There's a concept that we give&nbsp;&nbsp;

00:28:57.480 --> 00:29:02.720
the name, “the one-month medicine”. How would&nbsp;
you go from seeing an emergent biology threat,&nbsp;&nbsp;

00:29:02.720 --> 00:29:07.320
to the definition of a therapy for it, to the&nbsp;
production of that medication, to knowing it's&nbsp;&nbsp;

00:29:07.320 --> 00:29:12.680
safe in humans on a timescale as short as&nbsp;
one month? We can't do that right now but we&nbsp;&nbsp;

00:29:12.680 --> 00:29:18.760
can see a path. To do that it takes the precision&nbsp;
compute that we have, it takes the AI capability,&nbsp;&nbsp;

00:29:18.760 --> 00:29:23.920
the joining of those two things, and you've got&nbsp;
to go to experimental facilities. If I can imagine&nbsp;&nbsp;

00:29:23.920 --> 00:29:28.320
a molecule that might be helpful, I also have&nbsp;
to take an automated chemistry system and make&nbsp;&nbsp;

00:29:28.320 --> 00:29:33.520
that goop, see whether or not it is just goop or&nbsp;
whether it's a useful therapeutic. If it's not,&nbsp;&nbsp;

00:29:33.520 --> 00:29:36.760
then I got to go back into that loop and&nbsp;
do it kind of like the high repetition&nbsp;&nbsp;

00:29:36.760 --> 00:29:43.760
rate laser. Maybe not at 10 hertz, every 10&nbsp;
seconds but can I make a molecule every hour,&nbsp;&nbsp;

00:29:43.760 --> 00:29:49.320
every couple of hours, and not take a&nbsp;
team of chemists and scientists a much,&nbsp;&nbsp;

00:29:49.320 --> 00:29:55.948
much longer time to make the first go and&nbsp;
then rewind it and have a much longer loop?

00:29:55.948 --> 00:29:57.720
Craig Smith:
Two questions. One on&nbsp;&nbsp;

00:29:57.720 --> 00:30:09.240
the models. Somebody asked Andrew Ross Sorkin,&nbsp;
one of the talk panels here asked, I think the&nbsp;&nbsp;

00:30:09.240 --> 00:30:22.240
CIA director, whether the US is building models.&nbsp;
Whether it has its own proprietary secret model,&nbsp;&nbsp;

00:30:22.240 --> 00:30:29.680
kind of a Manhattan project of AI. And he said no,&nbsp;
because the expertise exists in the private sector&nbsp;&nbsp;

00:30:29.680 --> 00:30:36.920
and that the government funds the private sector,&nbsp;
the private sector develops these powerful models,&nbsp;&nbsp;

00:30:36.920 --> 00:30:42.600
and then the government essentially buys&nbsp;
them back. But what you're talking about&nbsp;&nbsp;

00:30:42.600 --> 00:30:55.587
with this compute technology, for example, at&nbsp;
your lab, are you building models yourselves?

00:30:55.587 --> 00:30:58.120
Brian Spears:
We are. So let me be really&nbsp;&nbsp;

00:30:58.120 --> 00:31:03.040
clear about what that question was precisely.&nbsp;
The question was, [are you building large&nbsp;&nbsp;

00:31:03.040 --> 00:31:08.160
language models that are proprietary to the US&nbsp;
government in secret, that nobody knows about?],&nbsp;&nbsp;

00:31:08.160 --> 00:31:14.840
and the answer was, no. I will say from the&nbsp;
DOE perspective, we are entirely uninterested&nbsp;&nbsp;

00:31:14.840 --> 00:31:20.760
in competing with OpenAI, or Anthropic, or anybody&nbsp;
else making those kinds of large language models.&nbsp;&nbsp;

00:31:20.760 --> 00:31:26.027
We're in fact legally prohibited from doing&nbsp;
so. We don't have any interest in doing that.

00:31:26.027 --> 00:31:28.160
Brian Spears:
We are making US proprietary&nbsp;&nbsp;

00:31:28.160 --> 00:31:34.120
models for all the things that are not language:&nbsp;
for not learning the grammar of English but&nbsp;&nbsp;

00:31:34.120 --> 00:31:39.120
learning the grammar of chemistry, for learning&nbsp;
the grammar of physics, and building out maybe&nbsp;&nbsp;

00:31:39.120 --> 00:31:43.880
even transformer-style architectures, which&nbsp;
are what's behind GPT and other things, but for&nbsp;&nbsp;

00:31:43.880 --> 00:31:49.440
building out molecules for the generation of a new&nbsp;
alloy for advanced manufacturing, or new protein&nbsp;&nbsp;

00:31:49.440 --> 00:31:55.360
for an antibody, or new small molecule for a drug&nbsp;
for cancer, all things that we're actually doing.

00:31:55.360 --> 00:31:58.040
Brian Spears:
Those models are not secret, in the&nbsp;&nbsp;

00:31:58.040 --> 00:32:03.440
sense that the question sort of intimated at&nbsp;
but we're doing it at nation scale and we will,&nbsp;&nbsp;

00:32:03.440 --> 00:32:08.680
and we are doing it with data that only the&nbsp;
US has access to; and it is a transformational&nbsp;&nbsp;

00:32:08.680 --> 00:32:14.640
capability. It's something that no other country&nbsp;
on the planet can do. Inside the Department of&nbsp;&nbsp;

00:32:14.640 --> 00:32:19.480
Energy, we have a workforce of about 60,000&nbsp;
highly trained scientific staff. We have the&nbsp;&nbsp;

00:32:19.480 --> 00:32:24.760
largest physical science database in the world.&nbsp;
We have the most capable scientific machines,&nbsp;&nbsp;

00:32:24.760 --> 00:32:30.720
both experimental and computing for producing more&nbsp;
data, and our FAST effort is designed exactly to&nbsp;&nbsp;

00:32:30.720 --> 00:32:35.960
take all of that data, all of our expertise,&nbsp;
all of our compute, and build out models that&nbsp;&nbsp;

00:32:35.960 --> 00:32:42.200
only the US can have for US advantage. So it's not&nbsp;
quite as spooky as the question, [Is the US doing&nbsp;&nbsp;

00:32:42.200 --> 00:32:47.640
something secret in the background?] We are quite&nbsp;
openly going out to seize global advantage and do&nbsp;&nbsp;

00:32:47.640 --> 00:32:52.428
something transformational for the US, especially&nbsp;
aimed at satisfying our national security needs.

00:32:52.428 --> 00:32:54.640
Craig Smith:
Yeah. And those models then,&nbsp;&nbsp;

00:32:54.640 --> 00:33:00.600
would they be made available to the private&nbsp;
sector or are they for use in national security?

00:33:00.600 --> 00:33:02.560
Brian Spears:
It's quite possible. Some&nbsp;&nbsp;

00:33:02.560 --> 00:33:07.840
of the most exciting work that we've done has&nbsp;
been in public-private partnership with, say,&nbsp;&nbsp;

00:33:07.840 --> 00:33:13.920
private partners like AstraZeneca for developing&nbsp;
antibody therapies. We are interested in sharing&nbsp;&nbsp;

00:33:13.920 --> 00:33:18.240
those models. We are not interested in&nbsp;
sharing them if we think that something&nbsp;&nbsp;

00:33:18.240 --> 00:33:24.000
bad could be done with them. So we will be very&nbsp;
careful and highly responsible about what AI&nbsp;&nbsp;

00:33:24.000 --> 00:33:28.160
safety and security looks like. We're going to&nbsp;
respect everything in the AI executive order&nbsp;&nbsp;

00:33:28.160 --> 00:33:32.240
and we're going to go out and do this super&nbsp;
carefully. So in the biology space, it's very&nbsp;&nbsp;

00:33:32.240 --> 00:33:38.880
easy to imagine a model that interrupts biological&nbsp;
pathways so that you don't propagate disease. So I&nbsp;&nbsp;

00:33:38.880 --> 00:33:44.840
want to stop a COVID-19 infection; great. The same&nbsp;
kind of tool could be used to interrupt biological&nbsp;&nbsp;

00:33:44.840 --> 00:33:50.200
pathways that are critical for staying alive. I'm&nbsp;
going to have to think twice about releasing a&nbsp;&nbsp;

00:33:50.200 --> 00:33:56.320
model that could be used for both purposes. Those&nbsp;
sort of dual-use ideas are at the forefront of&nbsp;&nbsp;

00:33:56.320 --> 00:34:01.387
what we're considering doing and that extends to&nbsp;
all kinds of models. That's not unique to DOE.

00:34:01.387 --> 00:34:02.000
Brian Spears:
When we think about&nbsp;&nbsp;

00:34:02.000 --> 00:34:05.960
building out these AI models, we have to think&nbsp;
about what people with good intent are going&nbsp;&nbsp;

00:34:05.960 --> 00:34:08.960
to do with them. We have to think about what&nbsp;
people with ill intent are going to do with&nbsp;&nbsp;

00:34:08.960 --> 00:34:14.800
them. It's an open research question to decide&nbsp;
how to protect those models from doing things&nbsp;&nbsp;

00:34:14.800 --> 00:34:20.560
that are harmful while enabling them to do things&nbsp;
that are beneficial. The Department of Energy is&nbsp;&nbsp;

00:34:20.560 --> 00:34:27.840
in a unique position to see what is harmful in&nbsp;
scientific technologies, to understand what's&nbsp;&nbsp;

00:34:27.840 --> 00:34:33.800
beneficial, to have expertise and understanding&nbsp;
what AI and high-performance computing can do,&nbsp;&nbsp;

00:34:33.800 --> 00:34:38.200
and to start pushing the frontier of the&nbsp;
ways that we can release the beneficial&nbsp;&nbsp;

00:34:38.200 --> 00:34:44.520
things without unleashing the harmful things.&nbsp;
It's not easy. So in our safety practices,&nbsp;&nbsp;

00:34:44.520 --> 00:34:49.147
we do three things: we assess the risks&nbsp;
to see what we think the options are.

00:34:49.147 --> 00:34:50.520
Brian Spears:
Can we do something safely or is&nbsp;&nbsp;

00:34:50.520 --> 00:34:56.400
there a vulnerability? Second, we put in what are&nbsp;
known to be best practices. So we protect models.&nbsp;&nbsp;

00:34:56.400 --> 00:35:01.640
We share them when it makes sense, we don't share&nbsp;
them. We may share data, we may not. Then the&nbsp;&nbsp;

00:35:01.640 --> 00:35:06.920
third thing that we do is do frontier research&nbsp;
and understanding what is the next best thing we&nbsp;&nbsp;

00:35:06.920 --> 00:35:11.228
can do in the future and we drop those into the&nbsp;
models and then we do that safely in the future.

00:35:11.228 --> 00:35:12.040
Craig Smith:
This is an iterative&nbsp;&nbsp;

00:35:12.040 --> 00:35:16.640
cycle that we just have to run over and&nbsp;
over again. Biology is a place where you&nbsp;&nbsp;

00:35:16.640 --> 00:35:21.240
have to think about it immediately because the&nbsp;
access that people can have for doing good and&nbsp;&nbsp;

00:35:21.240 --> 00:35:25.000
for doing ill with those things. But we have&nbsp;
to think about it for the nuclear stockpile,&nbsp;&nbsp;

00:35:25.000 --> 00:35:28.868
we have to think about it for energy&nbsp;
production, for manufacturing, you name it.

00:35:28.868 --> 00:35:31.760
Craig Smith:
Yeah. You were talking about transformer-based&nbsp;&nbsp;

00:35:31.760 --> 00:35:43.960
models not necessarily language models, I mean&nbsp;
not trained on natural language but DNA is a&nbsp;&nbsp;

00:35:43.960 --> 00:35:57.680
language and there are certainly other languages&nbsp;
in quantum physics in terms of codes that can be&nbsp;&nbsp;

00:35:57.680 --> 00:36:07.947
configured in different ways. So is DNA research&nbsp;
one of the areas that this is being applied?

00:36:07.947 --> 00:36:08.447
Brian Spears:
Yeah

00:36:09.320 --> 00:36:13.320
Craig Smith:
I’m a layman&nbsp;&nbsp;

00:36:13.320 --> 00:36:20.760
and in layman's terms, people get hung up on&nbsp;
parameter size because that's the measure that–

00:36:20.760 --> 00:36:22.588
Brian Spears:
You can count it.

00:36:22.588 --> 00:36:24.720
Craig Smith:
Yeah. Are they&nbsp;&nbsp;

00:36:24.720 --> 00:36:31.740
larger than the existing language models or will&nbsp;
they be larger than existing language models?

00:36:31.740 --> 00:36:33.840
Brian Spears:
They are not yet larger than the&nbsp;&nbsp;

00:36:33.840 --> 00:36:38.520
biggest language models. So the biggest language&nbsp;
models are a trillion parameter class models.&nbsp;&nbsp;

00:36:38.520 --> 00:36:46.200
So think about GPT-4, which is a 1.x- something&nbsp;
parameter model, and the similar largest models&nbsp;&nbsp;

00:36:46.200 --> 00:36:53.000
are coming out at the sort of trillion parameter&nbsp;
scale. The scientific models that are aiming to&nbsp;&nbsp;

00:36:53.000 --> 00:36:58.800
do similar things are far smaller than that right&nbsp;
now. The challenge is to build out architectures&nbsp;&nbsp;

00:36:58.800 --> 00:37:04.000
that are useful; they might be transformer-based.&nbsp;
Before doing that you have to sort of create the&nbsp;&nbsp;

00:37:04.000 --> 00:37:09.720
grammar, the language that goes into them. So&nbsp;
molecules like DNA, DNA is a very long molecule,&nbsp;&nbsp;

00:37:09.720 --> 00:37:14.600
even smaller molecules, they're a really nice test&nbsp;
bed for doing that. They're a little different&nbsp;&nbsp;

00:37:14.600 --> 00:37:19.000
than language; language is super linear. So we&nbsp;
have words that go from left to right in English,&nbsp;&nbsp;

00:37:19.000 --> 00:37:23.200
across the page and we know how to read&nbsp;
them in sequence. A molecule exists in 3D&nbsp;&nbsp;

00:37:23.200 --> 00:37:28.160
space and there are ways to project that into&nbsp;
something that looks like language, a string,&nbsp;&nbsp;

00:37:28.160 --> 00:37:34.040
called SMILES strings but you lose the 3D nature&nbsp;
of the chemistry and that's really important for&nbsp;&nbsp;

00:37:34.040 --> 00:37:38.400
the physics and chemistry of how atoms interact&nbsp;
in molecules. So before you build out these&nbsp;&nbsp;

00:37:38.400 --> 00:37:42.600
enormous models, like you do for language, you&nbsp;
should start with smaller molecules and then&nbsp;&nbsp;

00:37:42.600 --> 00:37:48.400
put a lot of effort on the 3D representations&nbsp;
of that. So we have a project called FLASC,&nbsp;&nbsp;

00:37:48.400 --> 00:37:52.880
which is a semi-tortured acronym that I won't&nbsp;
recall, but the FLASC project at Livermore,&nbsp;&nbsp;

00:37:52.880 --> 00:37:58.920
led by a colleague Brian Van Essen, is building&nbsp;
out frontier-level models for understanding what&nbsp;&nbsp;

00:37:58.920 --> 00:38:03.800
representations of molecules look like. Can&nbsp;
we build out these transformer-style or other&nbsp;&nbsp;

00:38:03.800 --> 00:38:08.787
architecture models that understand the chemistry&nbsp;
grammar, and then can do predictions with them?

00:38:08.787 --> 00:38:10.840
Brian Spears:
But you don't only want to predict will this&nbsp;&nbsp;

00:38:10.840 --> 00:38:15.600
molecule hang together, but you want to predict,&nbsp;
how do I synthesize it? What are the chemical&nbsp;&nbsp;

00:38:15.600 --> 00:38:20.040
precursors that I need? What are the synthesis&nbsp;
pathways that I need to activate? Is this a safe&nbsp;&nbsp;

00:38:20.040 --> 00:38:24.360
molecule to interact with? If it's not, can I&nbsp;
make small tweaks that make it accomplish my&nbsp;&nbsp;

00:38:24.360 --> 00:38:28.840
goal but are also safe so that I don't have to&nbsp;
wear specialized personal protection equipment&nbsp;&nbsp;

00:38:28.840 --> 00:38:34.347
when I handle it? Or if it's a medication, it can&nbsp;
be put into animals or it can be put into people.

00:38:34.347 --> 00:38:36.120
Brian Spears:
So these models need to&nbsp;&nbsp;

00:38:36.120 --> 00:38:40.600
come a long way to get up to the kinds of scales&nbsp;
where you see the sort of large language model,&nbsp;&nbsp;

00:38:40.600 --> 00:38:47.480
GPT kind of behavior. But we understand what the&nbsp;
capabilities are. So we're pushing very hard right&nbsp;&nbsp;

00:38:47.480 --> 00:38:52.400
now at the small scale to get the ingredients&nbsp;
together, just like we did with language models.&nbsp;&nbsp;

00:38:53.240 --> 00:38:58.000
The Attention Is All You Need paper and the&nbsp;
transformer architecture was not built at a&nbsp;&nbsp;

00:38:58.000 --> 00:39:01.720
time where we were doing a trillion parameter&nbsp;
scale stuff. We just understood that that model&nbsp;&nbsp;

00:39:01.720 --> 00:39:06.747
was transformational and when you go to scale, you&nbsp;
get all of these amazing things that come with it.

00:39:06.747 --> 00:39:07.280
Brian Spears:
We would like to&nbsp;&nbsp;

00:39:07.280 --> 00:39:11.440
repeat that. Start with the chemistry case,&nbsp;
do it at small scale, build out the language&nbsp;&nbsp;

00:39:11.440 --> 00:39:17.400
underneath it. We have all that data at DOE;&nbsp;
build those models at small scale and then go&nbsp;&nbsp;

00:39:17.400 --> 00:39:22.240
to large scale. That FAST program that I talked&nbsp;
about, this nation-scale effort is part of the,&nbsp;&nbsp;

00:39:22.240 --> 00:39:26.160
build it at small scale and then scale it&nbsp;
up to the enormous nation scale to give&nbsp;&nbsp;

00:39:26.160 --> 00:39:30.188
the US competitive advantage that you&nbsp;
shouldn't be able to get anywhere else.

00:39:30.188 --> 00:39:34.240
Craig Smith:
Yeah. On understanding&nbsp;&nbsp;

00:39:34.240 --> 00:39:43.120
the 3D structure of molecules, Google&nbsp;
just came out with AlphaFold 3. And we&nbsp;&nbsp;

00:39:43.120 --> 00:39:50.120
were talking yesterday about some of the&nbsp;
work that you guys have done on molecule&nbsp;&nbsp;

00:39:50.120 --> 00:39:59.720
modeling. Are you beyond AlphaFold 3 or do&nbsp;
you use AlphaFold 3 when something like that&nbsp;&nbsp;

00:39:59.720 --> 00:40:08.080
appears? Or is there some complementary&nbsp;
relationship between your research and&nbsp;&nbsp;

00:40:08.080 --> 00:40:19.187
that research? And is your research public in&nbsp;
the way that AlphaFold 3 is somewhat public?

00:40:19.187 --> 00:40:21.840
Brian Spears:
Right. So we do use&nbsp;&nbsp;

00:40:21.840 --> 00:40:26.960
other people's protein folding models. Our&nbsp;
group that works on a project called GUIDE,&nbsp;&nbsp;

00:40:26.960 --> 00:40:35.880
which is a partnership with DOE and DOD, uses&nbsp;
a model from Facebook AI research owned by&nbsp;&nbsp;

00:40:35.880 --> 00:40:41.840
Meta. There's an open model out there that's&nbsp;
really fantastic. We build on top of that,&nbsp;&nbsp;

00:40:41.840 --> 00:40:46.480
or really underneath that, the underlying&nbsp;
scientific data from high-precision physical and&nbsp;&nbsp;

00:40:46.480 --> 00:40:51.000
chemistry simulations from what we call density&nbsp;
functional theory or molecular dynamics theory,&nbsp;&nbsp;

00:40:51.000 --> 00:40:56.560
about the way that molecules stick together to&nbsp;
inform what proteins generated by that model&nbsp;&nbsp;

00:40:56.560 --> 00:41:01.360
look like in terms of their capabilities, their&nbsp;
safety, a variety of other things downstream,&nbsp;&nbsp;

00:41:01.360 --> 00:41:07.360
and we join that into a predictive capability for&nbsp;
models that we want to look at in the future. We&nbsp;&nbsp;

00:41:07.360 --> 00:41:13.000
don't use AlphaFold or AlphaFold 3. The models&nbsp;
that we do have now have some nice features that&nbsp;&nbsp;

00:41:13.000 --> 00:41:19.680
made them very usable. We will look at large&nbsp;
models like that in the future. We also, as&nbsp;&nbsp;

00:41:19.680 --> 00:41:25.040
we just talked about, are growing some of our own&nbsp;
in-house models that we think have options based&nbsp;&nbsp;

00:41:25.040 --> 00:41:31.520
on sort of transformer-style architectures to do&nbsp;
things that are like what AlphaFold and others are&nbsp;&nbsp;

00:41:31.520 --> 00:41:36.600
doing but that are kind of specialized for the&nbsp;
missions that we need to go after. To the open&nbsp;&nbsp;

00:41:36.600 --> 00:41:43.000
question, if we think that there's not a really&nbsp;
negative dual-use opportunity and we're really&nbsp;&nbsp;

00:41:43.000 --> 00:41:50.307
confident that there are good benefits to be&nbsp;
had without ill, then we very often share these.

00:41:50.307 --> 00:41:51.160
Brian Spears:
We will publish our&nbsp;&nbsp;

00:41:51.160 --> 00:41:55.760
information about what we're doing. Sometimes&nbsp;
we will stop short of sharing all of our code&nbsp;&nbsp;

00:41:55.760 --> 00:41:58.920
if we think we just can't be confident&nbsp;
that someone's not going to do something&nbsp;&nbsp;

00:41:58.920 --> 00:42:08.040
really dangerous with it. There is no sense&nbsp;
that we're going to keep this proprietary,&nbsp;&nbsp;

00:42:08.040 --> 00:42:12.600
just to keep it proprietary. The only reason we&nbsp;
will keep it is if we think that there could be&nbsp;&nbsp;

00:42:12.600 --> 00:42:17.960
harm done with it. Our instinct as a federally&nbsp;
funded research and development center is to push&nbsp;&nbsp;

00:42:17.960 --> 00:42:22.520
this out for public good. We share with private&nbsp;
industry as much as we can. We have a very long&nbsp;&nbsp;

00:42:22.520 --> 00:42:30.160
history in DOE of developing technologies&nbsp;
and giving them away to the private sector&nbsp;&nbsp;

00:42:30.160 --> 00:42:34.668
to scale up and build out for US advantage.&nbsp;
So if we can, we will give that to people.

00:42:34.668 --> 00:42:38.040
Craig Smith:
Yeah. I just had a conversation about the National&nbsp;&nbsp;

00:42:38.040 --> 00:42:49.067
AI Resource. Are you guys participating in that?&nbsp;
Is your compute infrastructure part of that?

00:42:49.067 --> 00:42:51.680
Brian Spears:
Yeah, absolutely. So through DOE,&nbsp;&nbsp;

00:42:51.680 --> 00:42:56.120
a good fraction of the computational cycles&nbsp;
that are available in this first round of NAIRR,&nbsp;&nbsp;

00:42:56.120 --> 00:43:03.160
the winners of which were just announced, come&nbsp;
from DOE computational capabilities at Oak Ridge,&nbsp;&nbsp;

00:43:03.160 --> 00:43:08.200
at other places inside the DOE national&nbsp;
laboratories. So we have a collaborative research&nbsp;&nbsp;

00:43:08.200 --> 00:43:14.600
with NSF and with NAIRR. NAIRR is one piece of&nbsp;
the puzzle for building out AI for the nation.&nbsp;&nbsp;

00:43:14.600 --> 00:43:20.920
That gives academic faculty and graduate students&nbsp;
access to slices of compute time where they can&nbsp;&nbsp;

00:43:20.920 --> 00:43:24.960
learn what it looks like to operate at large&nbsp;
scale. They can start to build out science and&nbsp;&nbsp;

00:43:24.960 --> 00:43:30.547
AI workflows and train a workforce and build out&nbsp;
their research in ways they couldn't otherwise.

00:43:30.547 --> 00:43:31.240
Brian Spears:
What it's not&nbsp;&nbsp;

00:43:31.240 --> 00:43:37.600
is what FAST aims to be. FAST is putting out&nbsp;
lighthouse or guide star problems that say, This&nbsp;&nbsp;

00:43:37.600 --> 00:43:43.400
is what huge transformational science looks like.&nbsp;
Interdisciplinary problems at very large scale. If&nbsp;&nbsp;

00:43:43.400 --> 00:43:48.280
you are trained to operate at the smaller scale&nbsp;
of the NSF, NAIRR funding, those skills can be&nbsp;&nbsp;

00:43:48.280 --> 00:43:53.080
brought to bear in interdisciplinary teams to do&nbsp;
larger, more emergent things than you can imagine&nbsp;&nbsp;

00:43:53.080 --> 00:43:58.880
operating at that other scale. They're absolutely&nbsp;
complementary efforts. NAIRR is fantastic and not&nbsp;&nbsp;

00:43:58.880 --> 00:44:03.480
enough. FAST is transformational but needs&nbsp;
the workforce transformation that comes from&nbsp;&nbsp;

00:44:03.480 --> 00:44:08.760
NAIRR and the things that academics can do with&nbsp;
that time. And together we build out students,&nbsp;&nbsp;

00:44:08.760 --> 00:44:14.080
professors, national-level researchers that&nbsp;
can come into the national laboratories&nbsp;&nbsp;

00:44:14.080 --> 00:44:17.628
and we can do transformational things&nbsp;
together. So they're very complementary.

00:44:17.628 --> 00:44:25.720
Craig Smith:
Yeah. Do you have trouble in recruitment? I was at&nbsp;&nbsp;

00:44:25.720 --> 00:44:34.800
NeurIPS in December and people were saying that, I&nbsp;
don't know if it's true, but people who certainly&nbsp;&nbsp;

00:44:34.800 --> 00:44:41.400
know more than I do were saying that OpenAI is&nbsp;
now offering a million dollars starting salary for&nbsp;&nbsp;

00:44:42.000 --> 00:44:49.587
top-level PhDs. I can't imagine the US government&nbsp;
can afford that– or maybe they can, I don't know.

00:44:49.587 --> 00:44:50.680
Brian Spears:
Well, I don't make a million&nbsp;&nbsp;

00:44:50.680 --> 00:45:00.000
dollars. So that'll be my first answer. It's a&nbsp;
tough competition. You can work in the AI space,&nbsp;&nbsp;

00:45:00.000 --> 00:45:05.440
you can go to our private partners in the&nbsp;
world and you can make more money. That's&nbsp;&nbsp;

00:45:05.440 --> 00:45:12.440
not debatable. You will do that. We do have to&nbsp;
compete with them. We do still bring in a pretty&nbsp;&nbsp;

00:45:12.440 --> 00:45:18.227
steady stream of hires. We do that because&nbsp;
of the compelling missions that we have.

00:45:18.227 --> 00:45:18.880
Brian Spears:
Let's say you&nbsp;&nbsp;

00:45:18.880 --> 00:45:23.240
walk into our laboratory. What have I done&nbsp;
for the past two decades of my life? I've&nbsp;&nbsp;

00:45:23.240 --> 00:45:26.960
used the largest computers on the planet&nbsp;
to operate the largest laser in the world,&nbsp;&nbsp;

00:45:27.720 --> 00:45:32.560
using the most sophisticated AI algorithms&nbsp;
together to provide for the first time in human&nbsp;&nbsp;

00:45:32.560 --> 00:45:37.800
history, more energy out of a fusion implosion&nbsp;
than what we put into it with the laser. That&nbsp;&nbsp;

00:45:37.800 --> 00:45:42.720
sounds like science fiction. You can't do that&nbsp;
anywhere else on the planet. You would have a&nbsp;&nbsp;

00:45:42.720 --> 00:45:47.560
hard time paying me enough money to leave that&nbsp;
to go do some of the other things; not begrudging&nbsp;&nbsp;

00:45:47.560 --> 00:45:52.400
our energy partners, all the very cool things that&nbsp;
they do. What we have is the compelling mission to&nbsp;&nbsp;

00:45:52.400 --> 00:45:57.947
work on. We have to use that to our advantage,&nbsp;
but it's not easy. Take my particular case.

00:45:57.947 --> 00:45:59.520
Brian Spears:
Lawrence Livermore National Laboratory&nbsp;&nbsp;

00:45:59.520 --> 00:46:04.680
is located in the Bay Area. We're a 40 minute&nbsp;
drive from the heart of Silicon Valley. Do we lose&nbsp;&nbsp;

00:46:04.680 --> 00:46:11.240
people to our industry partners? Absolutely.&nbsp;
Is it hard to recruit people? Absolutely,&nbsp;&nbsp;

00:46:11.240 --> 00:46:18.400
but we're working on it. Our FAST program is part&nbsp;
of showing the world what we do for good at scale&nbsp;&nbsp;

00:46:18.400 --> 00:46:22.680
for US advantage and making a home for people&nbsp;
who want to do that kind of transformational&nbsp;&nbsp;

00:46:22.680 --> 00:46:27.480
stuff. We cannot pay them what industry pays&nbsp;
them but we can offer a different kind of&nbsp;&nbsp;

00:46:27.480 --> 00:46:32.800
compensation and we just have to be competitive&nbsp;
in that space. We will seek out, through DOE,&nbsp;&nbsp;

00:46:32.800 --> 00:46:37.080
ways to pay competitive salaries. There are&nbsp;
things that we're thinking about to make us look&nbsp;&nbsp;

00:46:37.080 --> 00:46:42.360
more attractive. On a dollar-for-dollar basis,&nbsp;
I don't think we'll ever win. It's got to be&nbsp;&nbsp;

00:46:42.360 --> 00:46:48.320
monetary compensation and something else. I will&nbsp;
say that we've had people leave our laboratory,&nbsp;&nbsp;

00:46:48.320 --> 00:46:55.308
go work at places like Facebook and then come&nbsp;
back. It's a pretty attractive place to work.

00:46:55.308 --> 00:46:55.880
Craig Smith:
Yeah. Well, I&nbsp;&nbsp;

00:46:55.880 --> 00:47:02.880
remember the National Security Commission&nbsp;
on AI was talking about these sort of,&nbsp;&nbsp;

00:47:02.880 --> 00:47:09.720
I can't remember what they were calling them,&nbsp;
but national service programs where people from&nbsp;&nbsp;

00:47:09.720 --> 00:47:20.520
industry could go into a national lab, work&nbsp;
for six months with some agreement with Meta&nbsp;&nbsp;

00:47:20.520 --> 00:47:25.867
or whoever their employer is, and then go&nbsp;
back because they get a lot of knowledge.

00:47:25.867 --> 00:47:26.080
Brian Spears:
Yeah

00:47:26.080 --> 00:47:27.000
Craig Smith:
It kind&nbsp;&nbsp;

00:47:27.000 --> 00:47:31.187
of benefits both sides. Are&nbsp;
those programs active yet?

00:47:31.187 --> 00:47:32.320
Brian Spears:
There are pockets throughout the&nbsp;&nbsp;

00:47:32.320 --> 00:47:36.480
government where they work. They work pretty well&nbsp;
in the cyberspace. They call them reserve forces.

00:47:36.480 --> 00:47:36.547
Craig Smith:
Right

00:47:36.547 --> 00:47:37.160
Brian Spears:
You would think of the&nbsp;&nbsp;

00:47:37.160 --> 00:47:41.160
Army Reserve or the Air Force Reserve for&nbsp;
the military fighting forces. The idea is&nbsp;&nbsp;

00:47:41.160 --> 00:47:46.240
exactly that. Instead of working for your day&nbsp;
job and then spending a weekend working for&nbsp;&nbsp;

00:47:46.240 --> 00:47:53.800
your Army or Air Force Reserve training,&nbsp;
you would work at Facebook or NVIDIA and&nbsp;&nbsp;

00:47:53.800 --> 00:47:57.480
then spend some time working at a national&nbsp;
laboratory, for example. That's one of the&nbsp;&nbsp;

00:47:57.480 --> 00:48:01.600
most forward-leaning things that you can think&nbsp;
of. I thought it was pretty prescient of NSCAI&nbsp;&nbsp;

00:48:01.600 --> 00:48:08.988
to suggest that and I'm a huge fan of the idea.&nbsp;
At scale that doesn't exist yet. I'd like it to.

00:48:08.988 --> 00:48:11.480
Craig Smith:
Yeah. How do you feel&nbsp;&nbsp;

00:48:11.480 --> 00:48:19.440
about the competition? I mean, everyone's obsessed&nbsp;
with China. I spent a lot of my life in China. Are&nbsp;&nbsp;

00:48:19.440 --> 00:48:30.480
they doing similar things? Do they have the same&nbsp;
kind of national compute infrastructure that the&nbsp;&nbsp;

00:48:30.480 --> 00:48:38.200
national labs have in the United States&nbsp;
or the DOE has? Can you talk about that?

00:48:38.200 --> 00:48:41.920
Brian Spears:
Yeah, absolutely. There are lots&nbsp;&nbsp;

00:48:41.920 --> 00:48:46.000
of comparisons we should make between the US and&nbsp;
China, some of which look favorable for the US,&nbsp;&nbsp;

00:48:46.000 --> 00:48:51.160
some of which look favorable for China. In&nbsp;
terms of their ambitions. As I said earlier,&nbsp;&nbsp;

00:48:51.160 --> 00:48:56.080
their ambitions are the same as ours. We will&nbsp;
try to lead. There's a concept that I call escape&nbsp;&nbsp;

00:48:56.080 --> 00:49:02.320
velocity. My firm belief is that the nation&nbsp;
that first establishes a clear advantage in&nbsp;&nbsp;

00:49:02.320 --> 00:49:08.280
AI for designing their science and technology and&nbsp;
national security capability will not be caught.&nbsp;&nbsp;

00:49:08.280 --> 00:49:13.120
They will establish escape velocity. They'll be&nbsp;
out ahead. They'll be able to accelerate harder.&nbsp;&nbsp;

00:49:13.120 --> 00:49:18.760
You cannot catch up to someone who does that. So&nbsp;
in my view the United States needs to be first.&nbsp;&nbsp;

00:49:18.760 --> 00:49:24.440
It's a neck-and-neck race right now; so there's&nbsp;
no clear winner. China has said that by 2030,&nbsp;&nbsp;

00:49:24.440 --> 00:49:28.640
they will be the clear forefront winner. So we&nbsp;
should think about everything that we're doing&nbsp;&nbsp;

00:49:28.640 --> 00:49:34.120
at nation scale against that backdrop. Let's&nbsp;
look at compute capability as a proxy for that&nbsp;&nbsp;

00:49:34.120 --> 00:49:38.160
conversation the things that we can. What&nbsp;
we can say, if you look at high-performance&nbsp;&nbsp;

00:49:38.160 --> 00:49:41.040
computing. What we can say, if you look at high&nbsp;
performance computing, is that China used to be&nbsp;&nbsp;

00:49:41.040 --> 00:49:44.600
a significant laggard in the number of high&nbsp;
performance computing cycles that they could&nbsp;&nbsp;

00:49:44.600 --> 00:49:51.480
put together. Now they have more than half of&nbsp;
the computational cycles that you can rank in&nbsp;&nbsp;

00:49:51.480 --> 00:49:57.760
the top 500 supercomputers in the world. They've&nbsp;
stopped, in fact, participating openly sometimes&nbsp;&nbsp;

00:49:57.760 --> 00:50:02.840
in that conversation but we know that they have&nbsp;
the ambition and the will and maybe have already&nbsp;&nbsp;

00:50:02.840 --> 00:50:07.068
accomplished having more cycles available to them&nbsp;
in high-performance computing than what we have.

00:50:07.068 --> 00:50:07.980
Craig Smith:
What do you mean by cycles?

00:50:07.980 --> 00:50:10.680
Brian Spears:
Cycles. Sorry, that's the ability&nbsp;&nbsp;

00:50:10.680 --> 00:50:17.080
to do numerical operations. So each computer chip&nbsp;
can do some kind of multiplication of numbers,&nbsp;&nbsp;

00:50:17.080 --> 00:50:21.640
some number of those multiplications every&nbsp;
second; every cycle of the clock you can do&nbsp;&nbsp;

00:50:21.640 --> 00:50:29.120
those multiplications. They can do more math&nbsp;
than we can. We will also say, in the US,&nbsp;&nbsp;

00:50:29.120 --> 00:50:33.280
that we do much higher-quality math. So there are&nbsp;
things that we can do at high precision that our&nbsp;&nbsp;

00:50:33.280 --> 00:50:39.440
systems are capable of that in general the Chinese&nbsp;
systems are not capable of. So it's not totally&nbsp;&nbsp;

00:50:39.440 --> 00:50:44.920
fair; they're a little bigger, they're a little&nbsp;
clunkier. Ours are not quite as fast but they're&nbsp;&nbsp;

00:50:44.920 --> 00:50:50.120
much more precise in their capability. Ours&nbsp;
also, because of the DOE investment in computing,&nbsp;&nbsp;

00:50:50.120 --> 00:50:54.307
tend to be far more energy efficient&nbsp;
than the general approach in China.

00:50:54.307 --> 00:50:56.120
Brian Spears:
So right now we're having&nbsp;&nbsp;

00:50:56.120 --> 00:51:00.080
a national conversation about data centers and&nbsp;
the amount of energy that they pull down. We're&nbsp;&nbsp;

00:51:00.080 --> 00:51:05.880
reaching a place where data centers are going to&nbsp;
be starved by their capability to be powered. Some&nbsp;&nbsp;

00:51:05.880 --> 00:51:12.200
of our hyperscaler friends are looking for ways&nbsp;
to co-locate as many computers, as many GPUs as&nbsp;&nbsp;

00:51:12.200 --> 00:51:17.440
they can, without bringing the grid down in the&nbsp;
state that they operate in. Being able to produce&nbsp;&nbsp;

00:51:17.440 --> 00:51:23.600
energy-efficient GPUs, like DOE has helped our&nbsp;
industry partners to generate, is going to be&nbsp;&nbsp;

00:51:23.600 --> 00:51:28.800
an advantage in being able to power those with&nbsp;
an electric grid. So all of this comes together&nbsp;&nbsp;

00:51:28.800 --> 00:51:34.280
in a picture that asks, how much compute can you&nbsp;
have. How much energy does it require? Does your&nbsp;&nbsp;

00:51:34.280 --> 00:51:38.320
grid infrastructure support being able to put&nbsp;
that together? Can you do it in a way that's&nbsp;&nbsp;

00:51:38.320 --> 00:51:43.627
not climate-destroying? Is your energy clean in&nbsp;
the way that you can produce it, or is it not?

00:51:43.627 --> 00:51:44.440
Brian Spears:
This all gets wrapped&nbsp;&nbsp;

00:51:44.440 --> 00:51:50.120
up into a notion of sort of techno-economic&nbsp;
competition between the two countries. It's&nbsp;&nbsp;

00:51:50.120 --> 00:51:54.360
in vogue to talk about China as an adversary&nbsp;
in that sense, but it's very real. They're the&nbsp;&nbsp;

00:51:54.360 --> 00:51:59.160
only competitor out there that operates&nbsp;
at that scale and they've clearly stated&nbsp;&nbsp;

00:51:59.160 --> 00:52:03.240
they have the ambition to win that race&nbsp;
because right now in the compute world,&nbsp;&nbsp;

00:52:03.240 --> 00:52:09.680
if you look at something like OpenAI has&nbsp;
done, they are turning power into GDP,&nbsp;&nbsp;

00:52:09.680 --> 00:52:15.200
into domestic product. What you need to drive&nbsp;
that engine is more power into the grid,&nbsp;&nbsp;

00:52:15.200 --> 00:52:20.400
more efficient computers for turning that power&nbsp;
more effectively into economic product. Don't&nbsp;&nbsp;

00:52:20.400 --> 00:52:26.360
turn that off. Win that race. That's what we're&nbsp;
trying to do in the US. This is not lost on China.

00:52:26.360 --> 00:52:26.960
Craig Smith:&nbsp;

00:52:26.960 --> 00:52:31.000
Yeah. Is there something that you've been&nbsp;
talking about here that I haven't touched on?

00:52:31.000 --> 00:52:33.240
Brian Spears:
No, actually you've guided us&nbsp;&nbsp;

00:52:33.240 --> 00:52:40.040
through pretty much the whole experience of what's&nbsp;
going on, through the really wonderful SCSP expo&nbsp;&nbsp;

00:52:40.040 --> 00:52:45.360
that we're at and the Ash Carter Exchange that&nbsp;
we're co-located next to. It's a good chance to&nbsp;&nbsp;

00:52:45.360 --> 00:52:52.520
recap. One thing that I want people to understand&nbsp;
is that if we had our preference in the world,&nbsp;&nbsp;

00:52:52.520 --> 00:52:56.800
the Department of Energy would be probably&nbsp;
called the Department of Science. We do&nbsp;&nbsp;

00:52:56.800 --> 00:53:02.427
more physical science funding in the US than&nbsp;
any other agency. We operate at huge scale.

00:53:02.427 --> 00:53:06.160
Brian Spears:
We have as our responsibility laser focus,&nbsp;&nbsp;

00:53:06.160 --> 00:53:11.800
no pun intended, on national security missions,&nbsp;
from the nuclear stockpile to bioresilience,&nbsp;&nbsp;

00:53:11.800 --> 00:53:15.080
to making very critical decisions&nbsp;
for the intelligence community. And&nbsp;&nbsp;

00:53:15.080 --> 00:53:20.120
we do it with very sophisticated scientific&nbsp;
underpinning on both compute and experiment,&nbsp;&nbsp;

00:53:20.120 --> 00:53:27.240
and now with a really leading capability in AI and&nbsp;
we're moving further. This fast effort is to take&nbsp;&nbsp;

00:53:27.240 --> 00:53:33.120
that capability and build out a transformational&nbsp;
AI mechanism for the United States to make sure&nbsp;&nbsp;

00:53:33.120 --> 00:53:37.480
that we get out in front, that we have escape&nbsp;
velocity, that we lead for national advantage,&nbsp;&nbsp;

00:53:37.480 --> 00:53:42.000
and that we're not at a disadvantage on that&nbsp;
global scale. So I appreciate the conversation&nbsp;&nbsp;

00:53:42.000 --> 00:53:46.320
that you led me through. We've touched on the&nbsp;
science and we've touched on the compute. What I&nbsp;&nbsp;

00:53:46.320 --> 00:53:52.640
hope people who are listening to this take away is&nbsp;
that the US can do a spectacular, transformative&nbsp;&nbsp;

00:53:52.640 --> 00:53:56.440
thing in this moment. We need only have the&nbsp;
will to do it, and I think we're very close.

00:53:56.440 --> 00:53:58.880
Craig Smith:
Quantum. Is Lawrence&nbsp;&nbsp;

00:53:58.880 --> 00:54:04.000
Livermore working or the National Labs?&nbsp;
What are they doing on quantum? Are you&nbsp;&nbsp;

00:54:04.000 --> 00:54:13.040
a quantum optimist? I would imagine that the&nbsp;
compute power that you've been talking about&nbsp;&nbsp;

00:54:13.040 --> 00:54:19.387
would be important in the simulation&nbsp;
power for solving some of the issues.

00:54:19.387 --> 00:54:21.080
Brian Spears:
Yeah. I'm a quantum&nbsp;&nbsp;

00:54:21.080 --> 00:54:30.080
enthusiast. In my view, quantum computing is&nbsp;
still a physics experiment that's very close&nbsp;&nbsp;

00:54:30.080 --> 00:54:34.480
to becoming a computational capability. We&nbsp;
have researchers who are working on both the&nbsp;&nbsp;

00:54:34.480 --> 00:54:39.560
physical side of building out quantum computing&nbsp;
systems and on the algorithm side of developing&nbsp;&nbsp;

00:54:39.560 --> 00:54:43.160
algorithms for quantum computers to do the kinds&nbsp;
of scientific things we're interested in that&nbsp;&nbsp;

00:54:43.160 --> 00:54:48.960
we've done with traditional computing. Kristi&nbsp;
Beck leads our Center for Quantum Computing,&nbsp;&nbsp;

00:54:48.960 --> 00:54:54.200
which was just launched at Livermore openly, in&nbsp;
fact, last week I think. We've done the research&nbsp;&nbsp;

00:54:54.200 --> 00:54:59.760
for a long time but we've got an investment in&nbsp;
making this a real path forward in computing.&nbsp;&nbsp;

00:54:59.760 --> 00:55:06.267
So you should check her and her team's work&nbsp;
out, but I think it will be transformational.

00:55:06.267 --> 00:55:07.720
Brian Spears:
It's not a today solution,&nbsp;&nbsp;

00:55:07.720 --> 00:55:12.680
though. Today it's about GPUs,&nbsp;
lots of GPUs, how to power them,&nbsp;&nbsp;

00:55:12.680 --> 00:55:17.040
how to take algorithms that they understand&nbsp;
today and make them work. Quantum computing&nbsp;&nbsp;

00:55:17.040 --> 00:55:22.280
offers the ability to potentially transform that&nbsp;
for some types of computing, not for all. So we&nbsp;&nbsp;

00:55:22.280 --> 00:55:26.160
need to learn what that admixture looks like,&nbsp;
the balance between traditional computing,&nbsp;&nbsp;

00:55:26.160 --> 00:55:30.400
von Neumann architectures, things like that&nbsp;
and quantum computing and other ways to move&nbsp;&nbsp;

00:55:30.400 --> 00:55:36.320
data to compute and vice versa. So I'm not a&nbsp;
pessimist about quantum computing. It's just&nbsp;&nbsp;

00:55:36.320 --> 00:55:41.560
a future technology that's really exciting. Not&nbsp;
yet today's solution but we have absolutely got&nbsp;&nbsp;

00:55:41.560 --> 00:55:47.188
to push on that. It is another frontier. Do not&nbsp;
be behind on frontiers, it would be a mistake.

00:55:47.188 --> 00:55:49.920
Craig Smith:
Hi, I wanted to jump in and give a shout-out&nbsp;&nbsp;

00:55:49.920 --> 00:55:57.560
to our sponsor, SysAid. SysAid's vision is to&nbsp;
lead organizations on a transformative journey&nbsp;&nbsp;

00:55:57.560 --> 00:56:06.280
toward AI-driven organizational processes and&nbsp;
services, infusing intelligence and ease in the&nbsp;&nbsp;

00:56:06.280 --> 00:56:14.160
workday with SysAid Copilot. SysAid orchestrates&nbsp;
service management across the organization using&nbsp;&nbsp;

00:56:14.160 --> 00:56:21.320
generative AI that taps into specialized data&nbsp;
accumulated from thousands of customers and&nbsp;&nbsp;

00:56:21.320 --> 00:56:28.600
millions of users. With zero setup required,&nbsp;
SysAid's conversational AI manages employees'&nbsp;&nbsp;

00:56:28.600 --> 00:56:35.720
requests, assists with queries, and accelerates&nbsp;
the resolution of issues. IT pros and service&nbsp;&nbsp;

00:56:35.720 --> 00:56:41.960
management leaders become pioneers, enabling&nbsp;
productivity to thrive. Now, employees can&nbsp;&nbsp;

00:56:41.960 --> 00:56:49.280
do what they're meant to do and organizations are&nbsp;
free to fulfill their purpose. Give SysAid a try.

