change, and thereby also brings forth its own domain of interaction.
(Although living organisms are paradigmatic in this regard, nothing
apparently rules out the possibility of artificial autonomy.) A heteronomy perspective does not provide an adequate framework to investigate and understand this phenomenon; an autonomy perspective is
needed.
The second point is that in any given case or for any candidate
system we need to distinguish between, on the one hand, the operation of the system as such, which is a function of both its organization
(the set of relations that defines it as a system) and physical structure,
and, on the other hand, its performance in relation to whatever wider
context in which it is observed. For example, if we wish to characterize
the organization and operation of the nervous system as a finite neuronal network, then we need to characterize the nervous system as organizationally and operationally closed, such that any change of activity in a neuron (or neural assembly) always leads to a change of
activity in other neurons (either directly through synaptic action or indirectly through intervening physical and chemical elements). Sensory and effector neurons are no exception because any change in the
one leads to changes in the other, such that the network always closes
back upon itself, regardless of intervening elements (Maturana and
Varela 1980, p. 127). Nevertheless, the domain of states available to the
nervous system (as an operationally closed network) is clearly a function of its history of interactions with the rest of the body (and the en-
Autonomy and Emergence 51
vironment). Hence, besides characterizing the nervous system’s operation as a closed network, we need to characterize its performance in its
structural coupling with the rest of the body (and the environment).
Similarly, to characterize the organism as a finite cellular or multicellular entity, we need to characterize it as an organizationally and operationally closed system. At the same time, we need to characterize the
organism’s performance or behavior in its structural coupling with the
environment.
We can also shift perspectives and characterize the nervous system as
a heteronomous system—that is, as a component system with various
functions defined in relation to the organism (such as registering sensory changes or guiding movement). Notice, however—and this is the
third point—that in so shifting perspectives we are ipso facto no longer
talking about the same system. The system with which we are now concerned is no longer the nervous system as a finite neuronal network,
but rather the larger system of the organism (in which the nervous
system is seen as a component). Similarly, we can also shift perspectives
and characterize the organism as a heteronomous system subject to
the control of the environment (for instance, other organisms). Once
again, in thus shifting perspectives we are ipso facto no longer dealing
with the same system. The system now is the larger system of organismplus-environment, not the organism as a finite cellular or multicellular
entity.8
These considerations show us that there is no inconsistency between
characterizing the nervous system and organism as autonomous and
emphasizing their somatic and environmental embeddedness. We do,
however, have to keep our logical and conceptual accounts clear, so
that we know which explanatory heuristic is in play at any given time.
In any case, for the enactive approach it is the autonomy perspective
on natural cognitive agents that remains the reference point for understanding mind and life, not a predefined input-output task strucure.
Information and Meaning
Adopting an autonomy perspective also brings with it a certain way of
thinking about semantic information or meaning. For enactive theorists, information is context-dependent and agent-relative; it belongs
to the coupling of a system and its environment. What counts as infor-
52 The Enactive Approach
mation is determined by the history, structure, and needs of the system
acting in its environment.
According to the received view in cognitive science, in order to explain cognitive abilities we need to appeal to information-bearing
states inside the system. Such states, by virtue of the semantic information they carry about the world, qualify as representations. Cognitivists
conceive of these representations as symbols in a computational “language of thought,” and connectionists as constrained patterns of network activity corresponding to phase space “attractors” (regions of
