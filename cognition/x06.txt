inside the individual’s head. The cognitive properties of computation
do not belong to the individual person but to the sociocultural system
of individual-plus-environment.
The original model of a computational system was a person—a
mathematician or logician manipulating symbols with hands and eyes,
and pen and paper. (The word “computer” originally meant “one who
computes.”) This kind of physical symbol system is a sophisticated and
culturally specific form of human activity. It is embodied, requiring
perception and motor action, and embedded in a sociocultural environment of symbolic cognition and technology. It is not bounded by
the skull or skin but extends into the environment. The environment,
for its part, plays a necessary and active role in the cognitive processes
themselves; it is not a mere contingent, external setting (Clark and
Chalmers 1998; Wilson 1994). Nevertheless, the human mind is able to
idealize and conceptualize computation in the abstract as the mechanical application of formal rules to symbol strings, as Alan Turing did in
arriving at his mathematical notion of a Turing Machine. Turing suc-
8 The Enactive Approach
cessfully abstracted away from both the world in which the mathematician computes and the psychological processes he or she uses to perform a computation. But what do such abstract formal systems reflect
or correspond to in the real world? According to the cognitivist “creation myth,” what Turing succeeded in capturing was the bare essentials of intelligent thought or cognition within the individual (all the
rest being mere implementation details).
The problem with this myth is that real human computation—the
original source domain for conceptualizing computation in the abstract—was never simply an internal psychological process; it was a 
sociocultural activity as well. Computation, in other words, never re-
flected simply the cognitive properties of the individual, but instead
those of the sociocultural system in which the individual is embedded.
Therefore, when one abstracts away from the situated individual what
remains is precisely not the bare essentials of individual cognition, but
rather the bare essentials of the sociocultural system: “The physicalsymbol-system architecture is not a model of individual cognition. It is
a model of the operation of a sociocultural system from which the
human actor has been removed” (Hutchins 1995, p. 363; emphasis
omitted). Whether abstract computation is well suited to model the
structure of thought processes within the individual is therefore questionable. Nevertheless, cognitivism, instead of realizing that its computer programs reproduced (or extended) the abstract properties of
the sociocultural system, projected the physical-symbol-system model
onto the brain. Because cognitivism from its inception abstracted away
from culture, society, and embodiment, it remained resistant to this
kind of critical analysis and was wedded to a reified metaphor of the
mind as a computer in the head.4
The connectionist challenge to cognitivism, however, did not take
the form of this kind of critique. Rather, connectionist criticism focused on the neurological implausibility of the physical-symbol-system
model and various perceived deficiencies of symbol processing compared with neural networks (McLelland, Rummelhart, and the PDP
Research Group 1986; Smolensky 1988).
Connectionism
Connectionism arose in the early 1980s, revising and revitalizing ideas
from the precognitivist era of cybernetics.5 Connectionism is now
Cognitive Science and Human Experience 9
widespread. Its central metaphor of the mind is the neural network.
Connectionist models of cognitive processes take the form of artificial
neural networks, which are virtual systems run on a digital computer.
An artificial neural network is composed of layers of many simple
neuron-like units that are linked together by numerically weighted
connections. The connection strengths change according to various
