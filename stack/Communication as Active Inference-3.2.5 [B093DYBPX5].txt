Welcome to the ActInf podcast, where we will present short, digestible segments clipped from the Active Inference Lab weekly live streams.
If you like what you hear and you want to learn more, check out the entire live stream on the Active Inference Lab YouTube channel.
My name is Blue Knight and I will be guiding you through this podcast, which is clipped from Active Inference Lab live stream number 3.2.
This week's episode is a discussion that is loosely structured around the paper, A World Unto Itself, Human Communication as Active Inference, by Jared Bassel, Paul Badcock, Axel Constant, Carl Friston, and Maxwell Ramstad.
Daniel Friedman, who is based out of Davis, California, is facilitating this live stream discussion, which starts to dive into the Active Inference Framework and the Free Energy Principle.
He will start off talking about the basic Active Inference Loop, and I want to provide you with a little bit of context here.
There are four main components to this cycle, which can be described very basically as the interaction between an agent and its niche.
We could begin at any point in the cycle, and it runs continuously, but I will start arbitrarily with the sensations perceived by the agent.
These sensations impact the internal states of the agent.
The internal states of the agent lead to the agent's actions, where non-action can also be thought of as an action.
The actions of the agent lead to changes in the niche or external states, and changes in the external states then lead to changes in sensations that are perceived by the agent.
For example, the sensation that I perceive is that the music is too loud.
My internal state is uncomfortable because I cannot hear, so I'm going to take action to correct this.
I turn the music down, leading to fewer decibels in my niche environment.
Changes to these external states lead to changes in my sensations.
Now it is not as loud.
And this leads to changes in my internal states.
Now I'm comfortable.
This action-embodied feedback loop, consisting of sensation, internal states, action, and external states, can be applied to any non-equilibrium steady-state system.
So this is, again, about active inference as a process theory.
But I think this is going to be an opportunity for us to kind of go up the chain another dimension, which is to go from this active inference loop, which is very qualitative and like the skeleton of action.
And let's look at a quote from the authors about where does free energy play into this?
So the authors write, the free energy expected under a policy tracks the probability of that particular policy being pursued, i.e. of that specific policy being selected to guide action.
So it's kind of weird when people think, well, wait, what is my brain doing inference on?
It's doing inference on the probability that right now I'm in a chair.
I mean, don't I just know I'm in a chair?
Or don't I just know that it's likely to be me in a chair in 20 minutes if that's where I want to be or not?
But no, actually, what's happening is the brain is doing inference on the probability of a policy being pursued.
Relatively less expected free energy indicates a relatively more probable policy.
And this is seen sometimes, not to go into too many details, but when people take the log or the negative log of a probability, it's just so that you can minimize a number.
And by getting closer to zero, which is like a fixed number, we can know that we're maximizing the probability.
So if we make it so that smaller numbers are more likely, like one over the likelihood type thing, then we can actually do a minimization problem going towards zero as a lower bound because some of these things being bounded by zero and then know that we're making more probable or better policy decisions by minimizing.
Whereas if we were to do a maximization problem and just say, well, let's just maximize the overall likelihood, there's no known upper bound for how optimal it could be.
So you might not know when to stop.
But minimization helps you because it kind of puts a hard stop on zero.
Expected free energy can be decomposed into two terms.
So here we come back.
There's epistemic and there's going to be another one.
The two terms are epistemic value, which is the information gain of an observation, and pragmatic value, which is the expected log evidence of an outcome given a generative model of how outcomes depend on action.
The relative influence of each term quantifies the degree to which a particular policy generates actions that explore the niche, i.e. exploration, or actions that leverage reliable expectations about the niche to secure preferred outcomes, i.e. exploitation.
So any thoughts on this or there's a lot more to say here?
Thanks, Alex.
Hello everyone, I'm Alex, I'm in Moscow, Russia, I'm a researcher in the System Management School.
I just want to point to one thing about what these terms of exploration and exploitation is also could be met in some literature about business strategies.
So it's possible ways to company and to choose direction to act on different stages and different states and you as it rooted in this literature, you should, the company should first to explore some new area and the next step is exploration, exploitation, if there is some value for the company.
Great. And we'll come back to that in just a second. It's so true. It's a lot like explore, exploit in other domains.
And if you go too far onto one end, it ends up being less than useful. If it's purely exploratory, but never exploiting anything, then you never extract the value.
That would be like searching for where the oil is, but never drilling.
And then on the other hand, if you're just like, wait, there's oil right here, I'm going to exploit, you're going to find out that that well is going to run dry and you won't have put in enough research and development into exploration.
And so there's no simple answer as to whether it's better to be exploratory or exploitative at what level.
That's what free energy is about. And I thought this could be a good opportunity to actually connect what is free energy?
Why is it called free energy? If it's just the probability of a particular policy being pursued, why don't we just call it the probability of a policy being pursued?
And to answer this, I'm going to draw on a little bit of chemistry, a little bit of statistical mechanics.
So the term free energy in the usage of Friston has less to do with the Tesla sense of free energy, like electricity for everybody, and has more to do with this sense of Gibbs free energy, which is a thermodynamic characteristic.
And we can look at this equation, the total Gibbs free energy equals U minus TS plus PV, and in chemical terms, these do have physical interpretations, like the absolute temperature in Kelvin or the entropy measured in some other unit.
But the idea that I want to get across with this equation is just that you can partition.
You can have an expected free energy of some chemical reaction, and that, even though it's a total singular number, it can be partitioned into, for example, the internal energy of the system chemically, the temperature-weighted final entropy of the system, and the pressure-weighted final volume.
And so again, it's kind of a metaphor at this point, but there is math that we're just not going into.
We can look at this delta-G partitioning of the system, and again, delta-G doesn't capture everything about the system.
It doesn't mention the activation energy.
It doesn't mention other things about the stoichiometry of the reaction, but it is something that can be partitioned.
And then similarly, we can think about this expected free energy in the Friston sense, and we just heard it discussed as being partitioned into two things, the epistemic and the pragmatic value.
So the knowledge or exploratory value of a policy, and then the pragmatic or the exploitative value of a policy.
And then we can just directly link it to that language around explore and exploit, as well as around divergent and convergent thinking.
So these are still a little bit metaphorical, but I thought it would be interesting just to directly contrast the free energy from thermophysics, basically, and from chemistry,
and then note how this partitioning of expected free energy into multiple terms has a lot of carryover from chemistry and from physics.
Let's actually look at these equations and not to derive them or to implement them, but let's just look at what are these equations because we've talked a lot about how there's internal states and there's external states.
We've talked about how sensations are what enter the Markov blanket and how actions guided by policy are what exit the Markov blanket.
And so this is the minimal loop of embodied inactive cognition.
Okay, so where do we go from the qualitative theory of just saying, hey, ecological cognition means it's always this action embodied feedback loop.
How are we going to add a layer of math and move towards formalization of this?
What action is doing is minimizing the agents bound on surprise, and the two pieces are basically the complexity of the action and the expected accuracy.
You'll also note that there's a ton of things where it's like, wait, you're calculating the expected free energy, not just the free energy itself.
And the reason for that is the actual values are inaccessible to the organism.
And so the computation or the inference that the organism is actually doing is like, not where is my leg?
It's where do I expect my leg to be?
And that's the genesis of things like the ghost limb syndrome, all these phenomena that don't quite make sense in a sensory relay paradigm.
If you make it about a second order expectation, where do I expect to be now?
It's now casting.
And it turns out that where am I now?
How would you even know where you were?
But if you ask, where do I expect to be?
And how confident am I about that expectation?
It turns out that is what gets good enough and does it in a really computationally tractable way.
So action is minimizing the agents bound on surprise by balancing or combining.
We won't go too much into detail there.
The expected complexity of the action versus the accuracy of the action.
And so one way to think about that is complex actions like playing the piano are difficult to perform unless there's a feeling that there's also going to be accuracy.
Whereas very low complexity movements like flailing one's arms maybe are done without worrying too much about the accuracy of the motion.
And then on the perception in the internal state, we have the internal states are reflected by the KL divergence, which is the informational divergence between the priors and the posterior.
So that reflects how the worldview is being updated.
And then it's penalized by the surprise.
And yeah, I just want to put it out there.
Just there is a layer of mathematics and equations that go beyond the structure of active inference.
It frames external states, the niche construction of the external states, as bounding the surprise.
This system is actually symmetric with respect to whether the external states are the human or whether the external states are the world.
Because in the end, it's a bidirectional Markov blanket with sense and action moving both directions.
And so it would be a little bit weird if depending on which system we decided was internal to the Markov blanket, it went one way.
And if we put the system on the other side, it'd be the other way.
So this is the work that's been built out in the variational ecology work of actual constant and others where it's realizing that, hey, the niche, especially when it's just other agents, it's actually like the Markov blanket gives us this symmetry.
And so the internal state equations look a lot like the external state equations.
And then sensations minimize the agents bound on surprise.
And again, this is complexity minus accuracy, which looks a lot like the complexity minus accuracy of action because the senses coming in are the active states of the world.
And so similarly, we have this penalization of the complexity versus the accuracy of sensation.
And that should remind you of earlier when we were talking about the value of communication, if the input is garbled, then the sensations, it's not even that they're surprising or not.
They're just not that useful for us.
And so there's a lot of parallels between the different states in this model across the divide of the Markov blanket, as well as the two types of things that pierce through the Markov blanket.
And so just first coat of paint to close out this discussion with a little bit of the math underlying the formalisms of active inference.
We hope you enjoyed this week's discussion of the free energy principle and active inference, and that you will find it useful in listening to future podcasts discussing similar topics.
