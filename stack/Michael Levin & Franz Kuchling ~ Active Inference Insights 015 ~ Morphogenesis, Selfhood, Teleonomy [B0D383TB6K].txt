Hello, everyone, and welcome back to Active Inference Insights. I'm your host, Darius
Parvizywayen, and today I feel extremely lucky to be able to interview two exceptional researchers.
Dr. Michael Levin is a distinguished professor of biology at Tufts University, serving as
director of the Allen Discovery Centre at Tufts and the Tufts Centre for Regenerative
and Developmental Biology. His lab studies anatomical and behavioural decision-making
at multiple scales of biological, artificial, and hybrid systems. Franz Kuchling is Mike's
postdoc at Tufts with a special interest in the physics of life and how cells adapt to
changes in their physical environment. Guys, welcome to the show. Thank you so much for
joining me. It's an absolute pleasure and an honour. Everyone in Active Inference has a foray
into theoretical biology, but I would say you guys are the first out-and-out biologists that
we've had on the show, so I'm super excited to learn, but you may have to excuse some of
my more layman ideas that come from the British schooling system. Where I want to start is
probably just putting in some groundwork for the audience, who might be unaware of certain
terms that get used in the papers that you guys write. I want to start with morphogenesis.
What is morphogenesis? And in what kind of... You talk about morphospace. What is morphospace,
and how do those two things relate? Yeah. I don't know who wants to take it.
I guess I'll start and then Franz can give his view. So thanks for having us. It's a pleasure to
be here and to talk to you. There's a fundamental fact of biology, which is that complex shape and
functional structure are self-assembled. So let's just think about embryonic development. We all start
life as a single cell. And eventually that single cell has to give rise to a complex organism of
different types. And so this, not only during development, but also during regeneration.
So for example, a salamander loses a limb. Those cells have to not only restore the entire structure,
but then also know to stop when it's done. Okay. And there are other examples of this,
of course, metamorphosis. So when the caterpillar gets to a butterfly or something like that.
So there are numerous examples where the biological hardware is basically constructing itself. And so
this is broadly conceived. This is the notion of morphogenesis. Now, one way to look at this is as a
sort of open loop process, meaning that there are a set of rules that are executed in parallel. So
lots of molecule cells and so on are following these rules. And then there's a process of emergence and
something complex comes out the other end. This is the standard story of cellular automata or
other ways to think about emergent complexity. And that's true. I mean, that does happen. And then
certainly part of the story, but the more interesting part of the story is that morphogenesis,
whether developmental, regenerative, or in the context of cancer suppression or remodeling,
any of those kinds of examples, one of the amazing things that it can do is get to its
get to its target morphology despite various perturbations. So if you want to dig in,
I'll give you, I can give you all kinds of interesting examples where not only the environment
changes, not only injury, but actually the components themselves, the amount of DNA, the type of DNA,
the number of cells, the size of cells, all of these things can change. And certain morphogenetic
systems are amazing at getting where they're going despite all of these things. In fact, they will often
take novel paths to do it, which is William James's definition of intelligence, right? Same goal by
different means. So then the question is, what conceptual tools can we bring to bear to
understand this process? And what we have settled on, or at least what we've been pursuing for the
last some years is this idea of navigation, that what's actually happening here is that you have a
collective intelligence. It's basically a set of processes, hierarchically organized for molecules
to cells, to tissues, and so on. And what they're all doing is navigating the space of all possible
outcomes. So there's a, there's a huge, you know, this space of diverse morphologies that they can
achieve. And what they're doing is like any agent navigating its environment, they are, they are trying
to get to where they're going. And sometimes they have interesting competencies to do it, even when
things go wrong. So now we can bring to bear all of the tools of behavior science, of, of control
theory, all this, you know, cybernetics, all this stuff that's used to design autonomous vehicles,
you know, all of these kinds of things to ask, how does the system know where it is? How does it
remember where it's going and what competencies does it have to get there? So that's, that's,
that's why we use the notion of Morphospace because it allows us to make testable specific
hypotheses about the policies that, that are involved in this process.
Wonderful. That's a, that's a really nice background from which we can kind of explore
these ideas. Yeah. It seems when you put it that way, very consonant with the ideas of active inference,
which is obviously something that you guys have written about before. So friends, maybe I'll come
to you now. You, there's this idea in these, so, so people think of priors and sort of statistical
space or more broadly about the organism as a whole, you know, one of the priors of the organism
to be well-fed, to eat and so on. But we could also talk about a cell's prior or, and a cell's posterior
and Bayesian unfolding, Bayesian processes within the cell. What, in this idea of navigation and
self-organization, what would you say the cell's prior is? Is it purely to reach a kind of target
morphology or is there anything more than that? I would say there's a lot more than that, but that's
the most, the simplest to kind of formulate because Morphospace, like Mike was explaining, is something
that we have much more access to as a developmental biologist, right? So the, the challenge is you can
format all kinds of priors and belief expectations for a cell, but if you have no way to estimating how
that's even being achieved and that's hard to really put in any theory that's, you know,
experimentally accessible. But for one thing kind of to point out that the idea of a Morphospace or
cells navigating spaces is only challenging for, for people that are not involved in this field
because we're so used in spatial dimension as that being the space, right? But you can assign all kinds
of dimensions to a, to a cell and we do this for humans all the time. You know, the idea of characters
and the plot being multidimensional is something that is very much applicable to cells as well.
So to ask, to answer your question more specifically, so what's, what happens in terms of expectations of
a cell that might have, you have to really go into what is it constantly achieving has any relevance
for future states. So that's, why this can be transcriptional states. So what kind of genes are
being expressed at any point in time? And that is being informed, not just by the, by the structure of
the DNA. So by millions of years of evolution, it's also being informed by past events, not just in,
in that individual cell, but in its parent cells and, and going on. So that's what we call the
epigenetic landscape. So which genes are actually even accessible for the transcription machinery,
and which genes are being activated to really transcribe and make certain proteins down the line.
And so that really is something where, where a lot of the prior expectations are going into,
that we are at least now in the lab are really investigating of what kind of transcription
profiles do we see, but then also in terms of its, its transmembrane potential, you know,
in the lab studies, bioelectric potentials a lot. That's something that, of course,
from neuroscience, much more familiar. We talk a lot about action potentials. We don't have those in,
in non-neuronal cells, but every cell has a, has a memory potential, electric potential,
and those are informative and they are causing a lot of downstream events. So we can get more
downstream online, but that's part of where I think is part of the prior belief and expectations
that a cell is constantly having. Excellent. Yeah. I think there's a really important point
there, which is kind of something that I noticed reading your papers, which is a morphogenesis. The,
the very idea of physical space seems to be prioritized. It's self-organization in space.
Is that the only way, just in terms of conceptualization, is that the only way that
we could think of a cell, you know, reaching a posterior that aligns with its prior? Does it
have to be in accordance with some kind of self-organization in space? Or is there another
way that a cell could kind of reach a homeostatic set point? Absolutely. Yeah. Go ahead. It doesn't
have to be just space, right? So, um, even if you have the cell just somewhere in the body already
differentiated, already kind of has its type of morphology achieved, it has to maintain that
morphology, first of all, but then also it has to perform a certain function, right? Your kidney
cells and the liver cells, they have very different functions, even though they're all fixed in space,
in physical space. So prior beliefs are, you know, in this case, for example, for a kidney cell is what
kind of, um, what kind of, um, changes in the blood are being exposed to. Parts in the liver, same thing.
Um, if you have cells in, in the brain, right, it's different. They have expectations about actual
potentials. So, um, it, that space, and again, morpho space isn't just, um, spatial dimension,
right? It's also, it's also traversing because every, every cell in your body is an important
point. Every cell in your body has exact same DNA more or less, right? But what's actually being
expressed, that's the, the difference between all of them. So they are vastly different in the actual
proteins, but also in the genes that are being expressed constantly. So when we say traversing
and navigating the morpho space, we really talk a lot, not just about that physical space, but
how are they changing, which genes are being expressed, which can be turned on and off,
which really makes the cell identity in the end. Excellent. Yeah. Yeah. That's, that's absolutely
really, really useful to integrate function and space there. And I guess those two, they, they feel
to me inextricable, but actually perhaps I'm wrong there, Mike. Is it how, so, so reading kind of the
active inference account of morphogenesis, we talk about the external states of the Markov blanket
for a cell being other cells. And in the case of developmental processes, it turns, they end up
being other specific type of cells that they then join together with in morpho space. Is that how,
how necessary is the presence of specific other cells in the Bayesian unfolding for a particular cell?
Or could you imagine that a cells prior might be confirmed, you know, absent a specific collection
of external cells? Yeah. I mean, this is, this is a great question and it's, it's part of a very
emerging research program because it really isn't super clear yet what precisely cells are paying
attention to and, and what their internal models of the outside world are. What we do know is that in,
for example, let's just take, let's just take early development. So you have a blastoderm and there
are, I don't know, 50,000 cells there. And at some point we, as, as external observers will look at
that and we'll say, well, there's an embryo, there's one embryo, but what is there one of, right? And, and
if you, if you want to think about an embryo, the thing you're really counting when you say one is
you're counting the fact that all of the cells have bought into the same picture of the outside world and
what their goal is. So, so they are all going to cooperate to build a particular thing. What binds
them together into being one larger scale emergent individual is commitment to a particular model of,
of what, where, where they, um, where they belong, where the boundary is between them and, and some
other embryo, right? Because you can, you can make by putting in little, little scratches into that
blastoderm, you can make twins, triplets, you know, there are multiple individuals that can come from
that blastoderm. So every cell has to be part of some, in that scenario has to be part of some
network and that network has to make decisions about where it ends and where the outside world
begins, because that has to do with size control and, and, uh, you know, left, right asymmetry and all
kinds of things. So, uh, it's really critical to understand what exactly, um, the, the cells are
paying attention to what exactly the tissue is paying attention to. So the cell network, because I
actually think that there are, uh, there are agents here at every level. So even actually,
even to take a step back, you know, um, even molecular networks within cells, I don't even
think you have to get to the, to the level of a cell before you can start talking about, um, beliefs
and, and expectations and so on, because as we see, even gene regulatory networks can learn from
experience. They, uh, they can do something like five or six different kinds of learning, including
Pavlovian conditioning. And so you can, you can ask that question about what does the world look like
from the perspective of a gene regulatory network before it's been trained or after it's been
trained and so on. Right. So this is all, of course, very, very active, uh, areas of investigation
still. So we don't know all the answers, but, but I think, I think it's very important to start taking
the perspective of the things that we are modeling and asking what do they see and what, what are they
measuring? What are they paying attention to? How do they remap information into, uh, salient, um,
compressions for them, you know, and, and, and how that affects decision-making and so on.
Um, how does that then, um, integrate with a kind of idea of telos or teleonomy? Um, because,
you know, the way, you know, if we take the perspective of a cell or a collection of cells
that are parametricizing beliefs over external states, it sounds purposive. It sounds like,
as you say, there's agency there. Um, and even the word beliefs people associate with propositional
philosophical beliefs, how far should we take that metaphor literally?
Well, okay. So, so the first thing I would say about that is just this kind of a ground, uh, ground
rules. I, I don't believe in the dichotomy of literally versus metaphorically. Okay. I think
all we have in science is metaphor and, and, and, uh, what, what, you know, when people talk about
molecular pathways, I mean, talk about a metaphor, right? The pathway relative to what's actually
going, I mean, this is completely metaphorical. So all of, all of these things are metaphors.
The real, the real question of course, is what set of tools does that metaphor give you to make
progress? What does it help you discover? What does it facilitate? So, uh, to me, all of this is,
it gets settled empirically to the, to the, uh, to the point that, uh, if, if you have a particular
metaphor, so maybe you talk about cells as having beliefs, or maybe you don't. And the real question
is what does that worldview allow you to do now? I think that's the final judge of it. I don't,
I don't, uh, really put a lot of weight into sort of philosophical pre-commitments about what,
what goals and beliefs have to be. It's a question of port portability of tools. So, um, I now,
now having said that, so, so I think that, uh, these kinds of, um, uh, these kinds of tools are
extremely useful and they're again, not binary because even, even as early as the forties,
already, uh, uh, Wiener Rosenbluth and Bigelow gave us, uh, um, kind of a, a scale of different
types of different goals of different complexity, right? So it's a very simple kinds of, uh, passive
matter and then active matter, and then their homeostatic, various kinds of homeostats and
second order metacognition. And so you can, you can sort of go up and up and, and it's an empirical
question, which of these are the most useful for any of the contexts that you study. But I think
it is, uh, it is absolutely reasonable to see all of these things as having some position on that
scale. And, you know, it's important to say that back, back before, I don't know, let's, let's say
before the, the, the, the thirties and forties, there was a, the, the problem, the problem with
teleology was that, uh, we, we didn't have a way of thinking about machines with goals. We sort of,
most people would assume that, that humans have goals, but other than that, we really had no idea
how to cash that out. But, but it's, it's really critical to, to say that we're past that now. We,
we have a good rigorous science of, uh, what it means for, for mechanisms to have goals.
It's fine. It's not magical anymore. We don't have to be, be, be afraid of it. And, um, and so,
uh, I guess the last thing I want to say is the difference between teleology and teleonomy.
So, um, the def one definition of teleonomy is apparent goal directedness. Okay. Apparent teleology.
And a lot of times people use that as a kind of, um, as a hedge, as a way of softening
the concept is say, well, look, it's not real teleology just looks like teleology, you know,
and, and that's a way. So, so we don't have to really, um, uh, commit to be, to being teleologists.
We're just going to say, it just looks that way. So, so I like the word teleonomy, but for the
opposite reason, I, I am not trying to soften the concept. I'm, I, I, I'm, you know, not in, in, in no
way, uh, um, kind of, uh, hesitant about using teleology. I think it absolutely works. What I think is,
uh, useful about the concept of teleonomy is that by putting the word apparent in there, what it does
is it focuses on an observer's point of view, apparent to whom. And I think that is a really
critical question to ask in almost all of the stuff that, that we talk about here, which is not some,
some sort of objective, uh, uh, universal, uh, truth about these things, but from the perspective
of some particular observer, now that might be a human scientist, that might be a parasite,
that might be a sub-component of the system, that might be some sort of super set of the system,
that might be the system itself, right? We all, you know, systems observe themselves too.
And so, so, so what that says is that there is, there is some perspective from which the system
acts as a goal-directed agent and thus that could, and then can be, can be used with tools that belong
to that. So, um, that's, that's what, you know, that's, that's what I think is the most useful term
of, uh, the sense of teleonomy. Now, Franz, I was wondering what you feel about this,
because, um, I think it's a natural inclination. Maybe it's a romantic fiction that we want to
ascribe some telos to smaller, let's say, or less complex entities like cells or processes within
cells. There's an interesting thing that, uh, Mike said that I wanted to pick up on, which is
that basically everything in science is a metaphor. I guess where I might slightly push back on that is
the science of lived experience, um, and phenomenology, which we can't help.
But we have to take in some ways, literally, because it's the one thing that we're intimately
aware of. And there's a lovely paper by Anthony Jack and Andreas Ropestorff ages ago, 2002,
I think where they argue that basically you can take sort of every psychological construct
and say, well, every, every, the way that we, um, you know, coalesce on what attention means
or memory means really is because of what we, how we experience it. So I was wondering whether
there's a kind of, uh, tie there, I mean, or an association between when we talk about a
cell's beliefs, a cell's attention, a cell's memory, is there any way we can think of that without
bringing in our own phenomenal experience?
It's tough. I mean, um, like, especially initially when I, earlier in my, in my research, when I,
you know, wasn't as deep into a lot of the, the metaphysics behind it and all that, I tried to
really avoid it. And I tried to really focus the, my audience on, on just the mechanical aspects,
the mechanistic aspects, you know, the cellular aspects. But I find that it was almost impossible to
do that because all the words we use are so loaded with everything we have from psychology. Um, but
that being said nowadays, um, I, I think really the important part is to do, to, to do that
transformation, that transversing those two, um, fields in both ways, because the, the, the claim
we're making, I think is not that like a cell is doing the same thing on the same level, on the same
scale that, you know, Mike really mentioned, right. There's a, there's a certain gradient there as a,
as a human being is, but we're trying to understand where the origin of all these phenomena are coming
from and are there, and, and more importantly, are the fundamental principles both shared between
a cell and, uh, and, uh, and, uh, and, uh, and a more classical active, a different agent like a
human being. So things like beliefs, right? So when you say that cell has a belief, people like,
oh, well, you're talking about, you know, um, have religious beliefs and then you get really
fast trapped into, into these loopholes. But I nowadays try to counter this argument by saying, well,
what does it believe in? Like, where does it come from? It can't just, it has to,
in a human being has to come from certain expectations, right? So you really have to
then go down to how, how do you, once you have to define it, you have to then go to some
mathematical frameworks eventually. Otherwise you have to develop it. And so active inference is nice
because there you have very precise definitions of what a belief actually is. Yeah. And so once the
kind of trick you can do is can people also, okay, let's talk about active inference, human being,
you make a certain process, you know, you have a general model, general process, you define the
Markov blanket. So separation between what's outside that you can't see, and then yourself,
so an internal state, and then you have the separation of those two by the active and sensory
inputs you can get, right? You have sensory inputs and then you can act upon the environment
to change what the sensory inputs, your eyes, your ears are perceiving over time. That's actually what
agency really is about. It's about controlling, you can't really control the environment if you can't
perceive it. What you're actually controlling is how you perceive the environment. But of course,
you're doing that by acting on the environment. That's what agency is. Sure. Now, once you put it
in such a form of framework, then I think transferring that to sales becomes much more, much more easier
and much less controversial, I think. Yeah, I sense that that sort of less philosophically
laden, more deflationary account of agency is definitely possible. It's just control in line with
prior expectations or, you know, self-organization, principles of self-organization. I think one thing
that perhaps active inference also hasn't got very clear on, but certainly isn't clear in psychology,
is selfhood. And in some ways, I feel like it's very fundamental to this question of morphogenesis
and self-organization in biological space, because it's morphogenesis for who, right? So, Mike, you
sort of noted that in many ways, well, we're talking about that we have, it's all observer
relative, but also in some ways, it's also internal relative because they are manner, you know, they are
self-organizing for the sake of their own integrity. So, well, again, that might be ascribing a telos
that's unwarranted, but it could be described like that. What is biological selfhood? And I guess for
people who think of the self as one monolithic thing, how can it be distinguished from
more complex forms of selfhood, like metacognitive selfhood or epistemic selfhood and so on?
I think that, you know, the issue of morphogenesis for whom is actually really important because,
you know, a really defective frog embryo might be a very nice zebrafish embryo. And so this whole,
right? And so this whole notion of, you know, mutation and just in general evolutionary change
and what exactly is a birth defect is really important and interesting. Chemistry doesn't make
mistakes. So there's no such thing as, as a mistake in chemistry, but there is potentially a mistake
in carrying out developmental biology, depending on what perspective you're looking at. So it's
something very interesting. It's, you know, the, the ability to make mistakes is a hallmark of a
cognitive system, right? Because, because that suggests that you had certain expectations that
were not met and so on. So just the very nature of a, of a birth defect is, is interesting. So now,
now the notion of a self, I, of course, there are many ways to think about it. I'll, I'll give you
what, how, how I've been thinking about it. Um, what, one of the things that, that I really wanted
to do, uh, for early on is to come up with a framework, uh, to directly think and compare,
think about and compare agents of very diverse structure and provenance. So we're talking about,
you know, conventional beings like, like us and animals. I mean, also, those are also of course,
collective intelligences, right? We're all made of cells and so on, but also, you know, new synthetic
things that are going to be created, um, uh, robots, AI, hybrids, hybrids, cyborgs, you know,
all kinds of mixed, uh, kinds of, uh, things, uh, potential exobiological life and so on.
But what do they all have in common? You know, what, what do all agents have in common, no matter
how they're made and no matter how they got here, you know, what their origin story is.
So what, what I settled on and, and so now you see, you know, I'm super into the whole teleology
thing. So what I settled on is this notion of, um, the size of their goals. In other words,
uh, I, I define this notion of a cognitive light cone, which is, um, it's not the distance that you
can sense or act. It's the size of the goals that you're able to maintain. The biggest goal that you
could possibly maintain is the size of your cognitive light cone. So, you know, so, so every,
every agent has some degree of memory going backwards, maybe large, maybe small, some predictive
of power forward and some spatial area of concern over which its goals play out. And, um, and so,
so now, now the thing about that is that that is the, the determination of a cognitive light cone
by an observer. For example, here, you as a scientist are given a new system. You don't
really know how it works and you want to do some behavioral experiments and you find out that here
are the things that it can possibly care about. That, that is a third person investigation of its
agency. And we say, this is an agent to what, what I think of as a useful definition of the self
is exactly that process in first person. So a self is what, how that process plays out for the
system itself. So the system itself also has to be able to coarse grain the outside world and not
only tell agential stories about, um, things in its environment that do things, right? Because no,
no system can afford to, to track microstates. You know, Laplace's demon isn't gonna, you know,
you'll be eaten and dead long before you calculate anything. So, so every, every agent in the real
world has to, has to coarse grain. And they, they tell these stories about, you know, agents,
other agents doing things, but you also have to tell that story about yourself to some extent.
You, you can't avoid it because if you don't have a compact, uh, self model, you are not going to be
very good at controlling your own parts and making things happen. It's just right. That's part of being
effective in the real world. And so I think what we say when we, um, what we mean when we say self
is the internal first person view of a system about its own, right? So, so, so, so you, so, so there's
kind of a bundle of things you need to have. You need to, you need to have a sense of boundary between
you and the outside world. So which are the things that I think are actually me versus, versus not me.
You need to have some representation of some space that you think you're operating in. You need to have
some sense of your own sensors and effectors. What, what can I actually do? What am I actually
sensing? And so on. We, as third person observer scientists, uh, try to tell those stories about
other things that we work with, but, but agents tell them about themselves and sort of, you know,
parasites and conspecifics and various, you know, potential mates and prey and cheaters and, and all
these things, everybody's hacking everybody else. And in order to hack other, other agents to hack
yourself and your own parts, to have control over your own parts requires that sense of selfhood and
it might be, you know, as, as France said, the point isn't to say that every rock has
human level hopes and dreams. That isn't the point. The point is that, uh, there are, there's a huge
range in how much processing is, how much sort of meta processing is done about all of this.
You know, you can, you can roll all this forward in a, in a very kind of minimal way, or you can have
all kinds of loops where you're actually monitoring your own progress on certain goals and you have the
ability to change your goals and to pick new goals. I mean, there's a, you know, you can layer
stuff on and on, but that's, yeah, that's really great. That's a really lovely explanation. Yeah.
It really deeply aligns with the way that I think about selfhood, which is fundamentally from a sort
of Metzingerian, um, phenomenal self modeling aspect. And that's exactly what Thomas would say,
which is that self modeling is the capacity to recapitulate or re-simulate the actual data
structures of your own body in a kind of coarse grained space. So it's, you know, the, the one
thing that came to mind is talking about the, uh, cognitive light cone is in terms of the, the extent
of your goal. Yes, it's in space, but it's also in time. And that feels like a very relevant thing
here. Um, when I've spoken to Carl and when I've seen the direction of active inference, it's very much
going in time to, uh, in, in, you know, the direction of temporal planning, deep temporal planning,
which arguably relates to the depth of your generative hierarchy, because the deeper your
generative hierarchy, you know, the, the, the highest level is going to be tracking the most
invariant and long-term fluctuations in the external environment. So France, I'm just curious if you're,
I mean, this is just a thought experiment. Is there a way where perhaps if you have a, a cyborg or a
tadpole or, you know, some entity that you're examining and you're trying to get to the,
its cognitive infrastructure is looking, I don't know whether this would be behaviorally or
anatomically is looking at its capacity for planning, which might well just be it's the
depth of its generative hierarchy. Does that give us an insight into its actual,
you know, existential or experiential life?
I think it does. And it relates back to the, your only question about what are its actual beliefs,
you know, what, on what level are, are its beliefs being expressed? And so I just gave you a couple
examples. What I've left out is, you know, that of course, like you just said, what's important is
the hierarchy of that. How are these different, different beliefs organized in a certain hierarchy
of, of spatial and temporal scale. And also to, to, I really like that point Mike made earlier about
chemistry, not making mistakes, right? So what that means is the conclusion of that idea is that any
purely chemical system is not going to change much. It's not going to be entirely predictable.
It's not going to push back on anything in the environment. It's just going to have a certain,
it's going to come to an equilibrium pretty, pretty fast usually. And then that's, that's it.
And so another way to form this question of how does a cell, how can we, um, test agency,
to answer your question, how do we test, um, having a cell, certain, certain ability to form a
hierarchy and inform beliefs, we have to understand of how much pushback can it, can it give you,
can it give to an environment over, over long times. And so the way I would probe this hypothetical
cyborg or, or tadpole in terms of like, what kind of, um, expectations, what kind of planning is it,
is it doing is you have to really see how these different parts of that generative hierarchical model
are interacting. So you will have a, you have a quick first response, which could be, you know,
purely physical, but then very often on it turns very active in the most biological system. That's
the active inference part is really what makes life, life tick. You know, it's, it isn't entirely active
and it's active very quickly, but also over long time scales. And so, um, what we're trying to show in
this one paper about molecular admission with Chris Fields and Mike was that that's a drive that got
selected for a very early on in evolution. And so the way the prophy system is really looking,
having different reporters, um, genetically, but also just having certain diets in the system
that will give you readouts of its, its active states. Like what is it making? What kind of
proteins is it making? Is it changing its potential? And then you try to relate those things. Are they
completely independent? Are they just, you know, in a non non living system, you'd expect those to be
pretty, pretty static with certain very predictable, dynamic, um, reoccurrences of patterns, but now
living systems, they're going to change and they're going to change dependently on the scale. So one
scale is going to affect the other one and it's going to continue to doing that. And that's, I think,
how the planning is achieved by that temporal in, uh, the independent interdependence between those
certain aspects of a cell. If they were independent, there will be no planning, but if they're dependent
on each other and the cells basically be using its longterm processes to redirect and inform its,
its active points at any moment in time. Nice. Yeah. Yeah. And speaks to a kind of
almost predictive coding hierarchy, um, where you have these kind of trickle down predictions.
Mike, did you want to add? Yeah, just, I just want to go back for a second to something you said
before, which I think is quite interesting, um, about the, uh, the, you know, the, the, the non-metaphorical
nature of our phenomenal experience. And I, I, I, I take your point and I think phenomenal
experience is really important, but, but there's the, there's the issue that we change. Right. And
so, and so how you, so, so, so, I mean, for us, so let's say puberty is a, is a, is an example,
right, where, where a lot of valence changes and things that you thought were really important,
suddenly not important at all, but all this other stuff is now important. And, and the, the example that
I really find, uh, kind of, uh, in meaningful for all this is the, uh, caterpillar to butterfly
transition. So what happens there is you've got this, you've got this soft bodied creature that
has a, that lives in a two dimensional world and it crawls around and it has a particular controller
for that kind of soft body act, you know, actuation. So it's got a certain kind of brain
and then it has to be transformed into a completely different creature. That's a hard body,
the kind of vehicle it flies, it lives in a three dimensional world and so on. And so,
so it has a completely different brain. And during that, that process, the brain is basically
mostly broken down. Most of the cells are killed off, um, and then reassembled, you know, it grows,
it grows a new brain. So, so there's a, there's sort of three levels of interesting things here.
The, the, the first level is that, that, that aspect of phenomenal experience, like what's it,
nevermind what's it like to be a butterfly, but what's it like to be a caterpillar becoming a butterfly
and how much of the, and how much of the, um, the metaphors, the, the, how much of the things
that the caterpillar took very seriously, the butterfly thinks were total metaphors at this
point, right? If it could, I mean, I'm not saying that's how it thinks about these things, but,
but right. Things that were quite, um, quite concrete for the, for the, for the caterpillar
are no longer. So for the butterfly, that's the first thing. The second thing is that, um,
we know there's continuity. So, you know, if you, if you like, um, the stability of memories as a
criterion for selfhood, which a lot of philosophers like, uh, we know that the butterfly remembers things
that the caterpillar learned. So there is some continuity here, even though the, the brain,
the cognitive system and the body of all of that stuff is radically changed, but there's some
continuity. And so the next kind of question you think about is, okay, where the heck is this memory
where, when the, but that survives total brain re, you know, refactoring. But the third, the third
thing that I find even, even more important about all of this is, is for it comes from the simple fact
that, um, the way, the way, the way they test these memories is, uh, well, one, one way to do it is you,
um, you, you feed the caterpillar leaves on a particular color disc. And then what you find
is that the, the, the, so it forms the association. And then you find that the butterfly goes back to
that disc to feed. Right. But the, but the key, the key thing here is that butterflies and caterpillars
don't eat the same stuff, right? The caterpillar eats leaves. The butterfly doesn't care about
leaves. The butterfly wants nectar. So, um, so now something very important, you cannot just,
you know, persistence of, uh, of, of the self in terms of memories, what you can't do is just
keep the memories constant because you'll lose the salience. They make no sense to those memories
will make no sense to the butterfly. And in fact, what you have to do something very interesting,
you can't learn leaves on this color. You have to generalize to the, to the, to the higher category
of food. And so, right. And, and, and then you have to remap. So this is the part that I'm super
interested about in terms of, uh, moving memories around and, and, and transplants of memories and,
you know, personal identity and all that. You have to take the, the deep lessons of your past life
and sort of re, uh, reinterpret them for your new life, which is by the way, completely different,
uh, anatomy and all of that. But there are some things you learn that are still pretty useful,
just not exactly in the way, right? It's not the, it's not the details that, that matter now. It's the
kind of the generic concept that matters. So, so remapping, right? Remapping that information onto a
new, onto a new, um, embodiment for, for, for that, for that being. That's, that's why I think the
concept of metaphors is still super strong, even for the phenomenal stuff, because, because you
can't take any of it literally because you're not going to be the same later. I mean, you know,
as certainly for some animals, it's more than more that so than others, but you, you have to
understand the deep metaphor of what you learn, not the, not the specific details of your experience.
Yes. Yes. That's really good. That's really nice. There's a lot there. Um, yeah, again,
it's converging with some of the stuff that I've been thinking about. I'm writing a little bit in draft,
which is I'm kind of, I'm coming to this idea that the self in some ways is a, is a relevance
filter, a salience filter such that, because I think at a very deep phenomenal level, everything
that finds its way into attention or awareness is relevant. It wouldn't really make sense. And so
I, I would say that the one non-metaphorical thing there, although you have the higher order concept of
food is relevance and relevant and meaning making to me. And maybe what I, I, it's interesting that
you say, you know, we were trying to go up in abstraction up the generative hierarchy.
The one thing that the butterfly and the caterpillar share is the imperative for nutrition.
And maybe that's maybe so when we can start linking things in some kind of map of similarity,
maybe the thing that unifies them is preferences. Um, so the caterpillar and that maybe links us with
the caterpillar and the butterfly, right? We have this unified, um, goal that said,
the thing you said about the fact that they returned to the same kind of leaf is very interesting
because there does seem to be a idiosyncratic maintenance of memory, uh, which I can't quite
account for is it made me think of Andy Clark's paper, um, knitting your own Markov blanket,
where he talks about the, um, metamorphosis of Markov blankets and how we can kind of get around
this problem of like, when is one thing, another thing by adopting a process ontology rather than
a substance ontology. But friends, I, oh my God, uh, you know, whoever's got an idea on this in,
is it, is it possible that it's just a false move to say that the butterfly and the caterpillar are the
same thing. Like that's the same organism. Could we not just say that, you know, that actually does
become this division or the separation at, and we, it's philosophically vague as to when it happens,
but there are, you know, there was one thing and then now is another.
Yeah. So, so, so I think the way, uh, the, the way to avoid these kinds of philosophical traps is by
being very practical and asking, uh, what, why do you need to know? So if the, right. So,
so if the reason you need to know is, is because you want to predict how much crawling around there's
going to be, then it's absolutely two different things. Cause there's gonna be zero crawling
around afterwards. But if, but if what you need, but if what you're trying to predict is, um, so
what color substrate will it like to feed on? Then, then, then, then you need to understand that it's
the same thing because you will have less predictive power if you don't understand that it keeps memories.
So it's just, again, I think we're back to, again, the, the, um, the perspective of, of, uh,
uh, well, you know, what, what question are you asking as the observer?
Yeah. Okay, cool. Let's, let's park that there. I think something that you've worked on,
Mike, but also France, you mentioned, and I want to pick up on is the difference between
neural and non-neural structures. Um, there's a, there's a kind of neural bias in psychology,
neuroscience, a cortical bias. Um, France, one, why is that the case? Do you think? And two,
why should it not be the case? If it shouldn't be the case, maybe it should be the case.
Yeah. I mean, one, uh, we're human centric because we are humans, but more, more fundamentally,
the reason that's that, that we are so confined on the idea of, of neural circuits being the only
one that doing any inference is because they just very fast, right? Action potentials are fast. It's
a highly optimal optimized network, but optimized from what, right? Neurons didn't come from nothing.
Uh, actually doesn't come from nothing. Electric potentials were, were being used by cells way
before the, um, innovation of, of neurons. So that is, I think the reason why now we're trying
to look at what about a neural organisms and just cells of, of having these same properties.
Um, and more, and I think other than just that being kind of transition, what's also really
interesting is Mike and I both, uh, it's one of my favorite, um, past daytime activities is asking
neuroscientists, what, what, but your theory is specific to, to neurons. And it's a question that
neither of us has gotten a good answer to yet because a lot of it, of course, so, you know,
there are certain, certain time periods it takes. If you're looking at MRI imaging, you're looking at the
oxygenated blood flow in the brain. So you have to know those, those time constants and how fast
does it take? If you're looking at, if you're actually measuring actual potential of the neuron,
you need to know all these transition times to really make your model tick. But if you change those
time constants and you're, you're compensated for that in your model, it would still work.
So as far as we know, um, so far, we're happy to get proven wrong on here, but so as far as we know,
there's nothing that specific about neurons to that, you need to make any of those models
and clean active inference actually work. They are highly optimized and they have completely
different behaviors, of course, um, because those timings do matter, but they're not necessary for
it because they're not necessary. They're not in active inference framework, right? It's not
necessary to have a brain to have Markov blanket. It's not necessary to have a brain to have generative
model. So once all the actual assumptions that go into a model can be applied to any role systems,
then you're good to go and you should apply it to the system as well.
Yeah. I guess another biased mapping here is between cognition and the brain. Um, and there's,
I feel like there's been a, uh, in, you know, a movement towards, obviously in terms of embodied
cognition and the kind of dynamic, the agent arena dynamic that was happening, but also more recently,
Mark, your paper with Anna, Anna Ciaunica, uh, the brain is not mental. You sort of,
I think you look at the immune system and sort of say how the immune system contributes as well
as the neural system in subserving, um, adaptive control, self-organization, perhaps you could just
speak to that and, and say, you know, well, I mean, it's a, it's a, I guess it's a thought experiment.
What would it look like if we didn't have the immune system? If we were just trying to self-organize
purely in terms of neural dynamics? Yeah. Um, I, I mean, we certainly, there are, uh, there are
knockout mice where the immune system is taken out and all that kind of stuff. So, and, and, and a lot
of self-organization does happen before the immune system kicks in. I think, you know, I, I think the
idea is simply that, uh, there are many, many different kinds of systems that go into this
collective that, uh, that we see when we say it's, it's, it's a human or whatever, or whatever.
And, and all of them, uh, are potentially important contributors to the, to the process.
Um, as, as Fran said, you know, uh, it's, it's, it's a really interesting experience to, uh, to ask
people what a neuron is and, and, and, and watch them list things that are basically every cell in
the body does this. And, and then, and then, you know, so, so I, I have another thought experiment
that we sometimes do is like, like back in the, um, you know, back in the day when, uh, when,
when the idea of neural networks was first being worked out. Right. Um, I wonder if, if, if we had
come along to, uh, to some of the, some of the greats, uh, in that, uh, in that field. Um, and we
said, uh, oh, by the way, just, just FYI, um, the biologist got it wrong. Thinking is in the liver,
not the brain. So, so there's two, there's two ways they could have gone, right? One way is they could
have said, I don't care what you say, we've got models of cognition and they require it to be,
to be neural. So you guys must be wrong. Or they could say, fine, what do we care? Are, are this,
what the, you know, the, the, the basic calculus of, you know, McCulloch-Pitts and all that stuff,
the, the, the basic calculus of it doesn't require, it doesn't care what it is. So fine,
it'll be liver. Right. So, so I, I tend to think it would be, I tend to think it would be the latter.
You know, I don't see really anything in the, in the deep, in the deep lessons of, um, behavioral
neuroscience. That's really about neurons per se. You know, it's about multi-scale control. It's about
active inference. It's about all these kinds of deep things that go far beyond brains and
they're applicable to all sorts of stuff, stuff. But are there certain processes which are reserved
for the brain? I mean, I think someone listening to this, probably a psychologist or a neuroscientist
will say, well, take the brain out. Good luck. Take the liver out. You know, I mean, still good luck,
but you might have a better chance thinking, right? Uh, for, for a short amount of time. I mean,
take the, take the mitochondria out and, uh, and, and you're done for pretty much at the same rate,
uh, as, as the brain. Now, look at the bottom line, like I, the, nobody's arguing that the brain
isn't unique and interesting in certain ways, right? Like we found, you know, as much as we find, uh,
proto-cognitive capacities elsewhere. I've never made the claim that language or long written arm
planning is in there. Like we've not found it could be, you know, I wouldn't be terribly shocked
if it were found, but, but we haven't found it. So we don't make the claim. So clearly brains are
interesting and they do, they do interesting things. But, um, I think it's important to, uh,
make it, make a distinction between, between having found unique features and told a very
specific predictive story that, that of why that is versus just this generic gut feeling that
everybody has that, that I have real, you know, real feelings and plans. And this thing is a slime
mold that, I mean, I don't know how many times people have said to me, well, that's a slime mold.
That's not a real decision. It's just physics. And, and it just, I mean, it drives me up a wall
because what do you, I mean, you don't think we could tell a physics story about you. Like,
of course we could, it wouldn't be a very good story, but, but neither is it about the slime
mold. And the fact that you can tell that story doesn't mean anything. There's always a physics
story to be told about anything. And so I, you're right. I think, I think it's, it's fine to have
specific theories about what it is the brain that's doing differently than other structures. That's great.
Right. But a lot of the resistance to the kind of continuum views that the France and I are talking
about comes from a kind of closet dualism. It's people really, you know, they just really feel
they're different and, and, and they have to accept the fact that the physics are not different.
So, well, now what is it then? Right. It's like this, then there's something else. And I think
not, not even that I'm particularly against that. I just think it should be like, come,
you know, dragged out into the light and let's just say, like, say what you think the difference
is. You know, I think, I think that's really critical. See, I'm not sure the difference.
I'm not sure the dualism really fundamentally is a brain body dualism. I think it's an awareness
body dualism or consciousness. I mean, like a traditional Cartesian dualism, I think is really at play
here. It's just, we're, we've been persuaded that consciousness is rooted in the brain.
And so once you make that association, then you go, well, obviously my brain is special because
it generates consciousness. Consciousness is special. I can, in principle, imagine myself
being conscious without my liver, my leg, my arm, and so on. And so that's the special part.
Is, am I, what am I missing there? No, I think you're right. But, but I think, I think,
I think what people are missing there is when they say conscious of my liver, that isn't,
that isn't the question here. The question, so, so right now your left hemisphere and my left
hemisphere are having a delightful discussion about why language, you know, why consciousness
is in the brain and, and, and how important the brain is for, for consciousness. That's fine.
Then I will say to, and I don't have a new theory of consciousness, by the way, so I'm not like,
I usually don't talk about consciousness at all, but, but since we're here, I'll, I'll just say that.
Um, I, I have said that for the same reasons we think that the brain can support consciousness,
we ought to take seriously that other parts of bodies also support consciousness. Now, at that
point, people say exactly what, what you just said, which is, well, I don't feel like my liver is
conscious, but that's a huge mistake. Of course you don't, but you also don't feel that I'm conscious,
right? That that's, that's, that's exactly right. So, so, so it's nice that the left hemisphere is
eloquent and it has language and it can tell stories to, to other left hemispheres about how,
how, you know, how conscious it is. But that doesn't mean that what you don't have
spread throughout different regions of your body is a non-verbal, non-linguistic, uh, consciousness
that is not for us to access any more than we can access each other's. And that's, that's the, you
know, the fact that you don't feel it is no surprise. There's no surprise there. Um, it, you have to
take its perspective and ask, what do you think that's going on in your brain? And so, so literally,
um, uh, a, a student and I have, have been, uh, we have this, um, we have this table that, that has
rows for the main theories of consciousness. And for each theory, there is something specific,
you know, so, so, so Stu Hameroff will say it's microtubules. Somebody else will say it's, you know,
my electromagnetic field, somebody else will say it's, you know, integrated information,
like whatever it is. And then, and then we just look and say, okay, given that, where does that
occur in the body? And the answer for almost all of them is everywhere. And so none of these theories,
as far as I can tell, just can distinguish, you know, uh, and then, and, and some of them try to
rescue it. So, right. So, so IAT has this postulate that says, okay, but, but, but there's all this,
we're just going to say there's only one, right. That that's, that's, that's a postulate you sort of
add on to things, right. That's not. So, so that's, that's the issue is that it's not about
you feeling your, your liver being conscious. It's the first person perspective, which may or may not
be there. Yeah, there's plenty of that. I actually, yeah, I'm reticent to dive into consciousness
because all my podcasts end up being about consciousness. Um, and I have biologists on,
you know, but yeah, it's, it's, it's interesting. I mean, obviously a lot of this is being,
we have to take as a kind of, um, axiom that at least for this conversation,
that consciousness is, uh, well generated in the brain, whether that's in a property
dualist or whether it's in a reductive way. And I also do just want to give a shout out
to slightly more esoteric forms of idealism, conscious realism, and so on. But it also makes
me think about let's, if we just get away from consciousness in terms of first person perspective,
and just talk about basal intelligence in, in, in terms of morphogenesis, it also makes me think,
well, it's a, it's a, this is a term for consciousness, but people will talk about being,
where the conscious can be is multiply realizable, has multiple realizability. I.e. if I put,
you know, uh, you know, China, you know, if I had a Chinese nation, their blocks idea with exactly
the same functions as my brain, exactly the same synapses. Cause there's the same, you know,
those connections would be the same between the members of the Chinese populace and my brain.
Would I have consciousness? Okay. If we get away from consciousness, I guess my question is,
is morphogenesis itself, can it be, is it multiply realizable in the sense that we're now talking
less about the human body? Is there something sort of, or, uh, and more towards like cyborgs or
robots? What, you know, people have this intuition, I think as well, that there is a life force and they
land vital that leads maybe to this self-organization, right? There's like, there's got to be something
there, like, or else why, why are these things resisting entropy? Why are they self-organizing?
And I think the idea is like, well, if I just stuck some sort of priors in the robot,
why on earth would that end up being self, like, why would that work to use very reductive language?
Franz, I'm just curious, is there like an added ingredient, at least it might be a metaphor,
but an added ingredient that we have to put into a non-carbon based thing in this case to,
to give it the chance to self-organize?
Yeah, probably I would, if I had to name them, it would be evolubility. That would be one,
one part. So if, uh, if the, and it doesn't have to be evolution of, of its actual physical components,
that can be evolution of its, of its programming as well, but that would be an important,
important point to it. Um, the one thing I'd like to point out in for that question is, right. I,
I've talked a lot about in this podcast about one of my, one of my biggest interests is really
understanding of where that drive for, for an agency comes from, but that's not just a kind of, uh,
philosophical, um, interest kind of, it's actually really once you, once you find sufficient evidence
for that being a fundamental drive in evolution, then you have to accept the, the, to combine that
fact with the idea that, well, if any part of your body or any, any robot, um, that you're putting
into this is going to strive to maximize its agency with respect to its environment. That is the real
reason why, if it turns out that the liver is not conscious, um, right now, then the answer would be,
if you accept the fact that, well, the drive is fundamentally an evolution and your, any life
system is going to try to maximize its predictability and its agency over its environment.
And the answer would be, well, its environment isn't very interesting. So the liver probably
didn't have any, any reason to maximize that drive. If you were to put the liver in an end,
or you were to put a robot into an environment that's very active, very much changing, very volatile,
and you give it enough, either enough time to evolve if you come out with the vulnerability,
or you just put in, um, uh, a high degree autonomy over its own beliefs.
And over time with that drive, it should be able to, to, to maximize that. The problem right now is
that the way we program robots is, uh, is very much right. It's a, it's a vague algorithm. We don't
allow any adaptiveness to it. Um, and so that's, that's how you would have to go about it, I think.
And you may not want to do that, FYI, but because the problem is, um, you know, we talk about one of my
favorite, um, uh, examples of why, what differences between machines and, and the brain is that a
calculator is infinitely better than you at calculating, you know, adding numbers together,
multiplying is, I mean, you know, and it's the dumbest thing ever. Like it's so simple. And
we've had these things for, for decades now, but if you, so if you want to have a predictable,
reliable answer, it's always correct. You know, the, the human is not the best way to do this.
That is the reason why we're not, even if we had the theoretical framework to make a really
agenda, um, intelligent system, um, for what we want them to do, which is really make our
lives easier, but making the same thing every day reliably, you wouldn't want to do that.
But if your goal was to create a new, uh, intelligent, um, um, cognitive agent,
then you would have to go about it differently.
Yes. That's an interesting little paradox, isn't it? I mean, like the most robust thing in the
world might be a calculator, but it's quite useless. It's like the more useful you become,
the more, uh, precarious your existence is. Um, Mike, I was wondering if you had any thoughts
on that kind of multiple realizability question. And I guess what I'm going at with that is
it's a very, it's a, it is a philosophical question, but I think it's interesting for
biologists, which is why would ever like, why would evolution prioritize self-organization?
I mean, there's just a fundamental question there in terms of entropy. I mean,
why do we have these pockets of neg entropy entities? Um, is there a biological answer to
that beyond just, well, to be a biological entity, you are neg entropy. Is there anything,
can we get anywhere beyond that? Yeah. Um, a couple of, a couple of things I think are
interesting and I want to be careful here because I, I did, I did a little while ago. I did, um,
I started writing a paper on what exactly is missing from our technology to provide true agency,
because I think we can actually say what some of those things are. And it, it quickly sort of
dawned on me that to whatever extent I was onto something that would actually lead to a massive
creation of, of new beings with that, that matter in the moral sense. And not, I'm not too interested
in, in, you know, um, being responsible for that. So I said, some other people will do it,
I'm sure, but, but, but, but I don't, I don't want to do it. So, so, so, um, but, but I can,
but I can say a few things. Um, I think, I think, uh, when we, I, I, I, when, when we make the
distinction between life and robotics, um, even aside from all the hybrids and cyborgs that, that
show us that it's like a continuum, but even aside from all that, when we make that distinction,
here, here's what I hear. I think life is what we call things that are good at scaling up, uh, goals.
So, so, you know, when you have very, when you have a bunch of subunits that have very
basal competencies, you know, maybe all they can do is follow least action laws or like,
like really simple things. When, when, when you've got a pile of them and the pile has basically
exactly the same cognitive light cone as the, the components we say, well, that's not living,
that's a rock. That's just, you know, but, but, but life is what we, what we call things where
there are, um, special, I, I've also called it a cognitive glue. There are like these special
policies by which the parts relate to each other such that the collective has a bigger cognitive
light cone in new spaces that the parts couldn't have. And that's, and that's what we call life.
Now, now under that, under that way of thinking about it, could you make that out of other things?
I'm sure you could. And I, you know, I tend to think that in the wide universe, I tend to think
that there's probably lots of extremely diverse examples, some, most of which we wouldn't even
recognize of, of, of that happening. And I think, um, specifically, I think, I think what happens is
that, uh, the, the evolutionary process really, I, I, I don't really think it makes specific
solutions to specific problems the way that we do when we do genetic algorithms and things like this.
I think what, what biological evolution does is it makes problem solving machines.
And that's because if you overtrain on your evolutionary priors and you really take seriously,
uh, what expectations that you might have about what genes you have, what the environment is like,
if you take that too seriously, you're done for because, because guaranteed. And this is why I also
think that regeneration is not really about repair of, um, of physical damage, like, like external damage.
I think fundamentally regeneration is about knowing for a fact that your own parts are going to change,
right? Evolution just means the fact that you have a, so some kind of a lineage that's subject
to mutation, whatever, you, you know, your stuff is going to change. If you don't accept that you're,
you're never going to survive long-term. So, so what ends up surviving are architectures that in
particular are these multi-scale architectures where the individual components have agendas and then this,
you know, they, they, they make up systems that have other agendas and, and, and on and on. Our, our
current robotics by and large is very flat, right? So you hope your robot is intelligent, but the,
but the parts it's made of are not, they don't really tend to do anything on, they don't have their
own agendas. And I've given a talk called the why robots don't get cancer. And this is why, right?
It's because you, they, they're made of parts that are not, they, that don't have their own little,
little goals in other spaces and there's no danger of them defecting unlike biology where it happens all the time.
So, um, I think what's, I think what's happening here is that we end up with these architectures
that, uh, are by virtue of cooperation and competition of parts that, that end up being,
uh, being having a, a larger cognitive light cone, you end up with this kind of,
this kind of intelligence ratchet. And we could, you know, I could, I could tell you stories about how
that, that type of thinking explains, you know, planarian, the, the, the amazing facts of planarian
regeneration and so on. This, this, this idea that what evolution I think really selects for
is the plasticity to, and, and, and, and it works out in different types of animals, the two different
degrees, but, but overall the plasticity to deal with novelty. You know, this idea that when you,
when you emerge into the, uh, into the world, you don't know for a fact what you are, what you have,
is your genome the same as it was, are your cells the right shape or size? Do you have,
are you in the same environment? You don't know any of these things. You, you have to, um, do your
best in putting together a model of what that, that that's why life is so interoperable. That's
why we can make anthrobots and xenobots and interface living tissue with crazy nano materials
and make these hybrots that are, you know, just sort of totally cobbled together. It's because by and
large, it's already bought into, you know, the, the life we see today has already bought into the fact
that, um, like, like, you know, everything changes, you know, and you don't, and you can't,
you can't depend on these things. You have to figure them out in real time.
Yeah. Yeah. Great. It, you know, when you mentioned the word cognitive glue, it made me realize that
there's one thing that we haven't even touched upon at all. I haven't even mentioned, which is
electricity and bioelectricity. Um, so I think as you had the paper, Mike, they knew last year,
two years ago, um, about bioelectricity being the glue of the cognitive mind. So from physiology,
all the way up to the mind. And obviously this is very much, you know, uh, a seminal piece of your
work is the processes of bio, bioelectrical processes in cells and outside of cells and in
terms of self-organization. And I think at least to my very layman biological ears, electricity almost
has the, the kind of center of a Elan Vital, a kind of thing that, you know, animates things. And
maybe, you know, I'm thinking about Frankenstein. Um, either one of you, I don't mind whoever wants to
start. What, you know, actually, Franzi, it was something that you mentioned, which is maybe one of
these ways that we can conflate the neural non-neural divide is the fact that both of them have, but for
them are fundamentally electrical. What, what is it about the electrical ontology that animates or
might animate intelligence or morphogenesis?
So when I was writing my, my PhD thesis, I was trying to answer the introduction, the question of
where does, where does the neuron even come from? And the best paper I found that was answering that
question was looking into this very small organism that had just a bunch of little cilia around its
surface. And it was a marine organism that was living on the bottom of the ocean. And it was
trying to send it to the environment and the computer based by small changes in electrical fields
that they're having around it. And that was causing, um, like mini, I don't say action potential,
but it was causing basically mini vibrations and could use that to change, to change this movement.
So the reason I think why that would, you know, why the electricity is, that's so important here.
It's very, it's very simple mechanism to have that is physically a lot more accessible to all
parts of the body. And that's actually the primary reason why I joined Mike's lab and why I'm become
a biologist. I was a physicist before. So I was looking for something in biology that would be
all these, that would not be subject to completely different mechanisms if you switch organisms.
So like the molecular pathways we are typically investigating as developed into biologists, they are
as they were before, they are now still very important and they're directing all these different
functions of the cell and organisms. But they're somewhat, somewhat unsatisfactory for a physicist
because it's just so messy, right? You can't really make heads or tails of it. And there is no clear
field of potential that is just one number essentially, right? You want to reduce it to something very
simple. The beauty of using biologistity is that you can have, you can have one number, one potential,
or you can have like a memory potential or you can describe yourself. It's still made up of all the
individual parts. There's many iron channels involved in this. All the molecular properties
are still making up, they're all feeding into that one, um, one number, that one memory potential.
But what's more interesting is the readout part, right? You sold, if you have to constantly compare
the millions of different molecules in a cell, that's not going to be good, good formulation for,
for achieving consciousness, for even doing any smart behavior, having something that you constantly,
constantly having a surface, almost like a space that you can read it, that you can write onto and read
out to. I think that was makes electric potentials so appealing that the only question then is like,
why wasn't it other physical fields like mechanics? They are of course, uh, very involved as well in
development, biology and regeneration as well, but mechanics don't have this neat feature where it's
not as fast and it's not as localized. So basically the way I see it, the potentials have a, have a beautiful
trade out between being physical, having a broad readability on a, on a cell or even a tissue level,
but are confined enough that they can be modulated enough to actually format the behavior, which you
can't say for, uh, most of the other physical fields that we would, um, think about in this context.
Great. Mike, you want to add?
Yeah. Yeah. A couple, a couple of things. One, one thing to add is that if, if you think about, um,
one of the really powerful things about, um, bioelectricity is that imagine an ion channel is
specifically a voltage sensitive ion channel. So as soon as evolution discovers a voltage sensitive
ion channel, what you have there is an element with historicity. It means that, uh, the current
state is a function of what was going on before. And it means that what you really have is a voltage
gate at current conductance, AKA a transistor. And so, so, so we, you know, we know once you have
that, then, then you can do anything. And so, uh, uh, electricity is, is really good for these kinds
of feedback loops, right? Both positive and negative. It's good for, um, representing information across
time and space. It's good for functionally integrating a system, uh, across, across distance.
Some, some of the, um, really cool early, uh, evolutionary data on this come from bacterial biofilms.
And this is, um, gross. Well, it's amazing work. Uh, what basically he's, he's got a paper
called, um, you know, brain, like signaling and bacterial biofilms. And the idea is that already
in a, in a mat of bacteria. So like a really long time ago, um, evolution already, uh, hit onto this,
uh, to this idea that, um, by using electrical, uh, electrical signaling to integrate activity
among competent subunits, you can get gains at the collective level. So they take turns. It's
used for, for nutrient sharing and, and, and things like this, but, but you get these collective
dynamics. And so I think it's just, it's, it's a very convenient modality for it. That was,
that was found a long time long before neurons, you know, picked that up. Um, it was used for that
kind of thing, but, but no doubt there are other, there are other ways to do it somewhere out in the
universe. There are, there are, there's other, I'm sure, I'm sure there are other kinds of cognitive
blues out there, but, but here electricity works really well. Cool. And so I know we need to wrap
up relatively soon. Um, and I guess, uh, it's a, it's a kind of dark pun, but us wrapping up kind of
soon makes me think about aging and death and decay and whatnot. And there's a, there's a massive fuss
about aging and longevity at the moment. Um, and David Sinclair and this notion of epigenetic
scratches. And it kind of makes me think of the inverse of that, which might be regenerative biology
and the capacity to reestablish self-organization, reestablish, uh, the kind of priors that we've
been discussing in terms of the functional priors, the preference priors, the ones that,
you know, are seeking a certain sort of a external state or seeking a certain probability distribution
so as to be able to fulfill its function, so to speak. Um, what Mike, what is the kind of
lay of the land in your world as to aging? Um, how seriously should we take this kind of epigenetic
approach? I won't ask about the moral aspect of it because it's a completely different question
about whether we should live longer or not, but short, you know, having localized, uh, morphogenesis
and self-organization is really the currency of biological systems. How viable is it that we
can reestablish that in something which is, you know, where self-organization is ailing and, and
rather feeble? Yeah. Um, I think, well, the, the first thing is, uh, I, I do just want to say something
about the moral question because it also gets to the issue of regenerative medicine more broadly,
uh, and, uh, and, and beyond regenerative medicine, human augmentation and all of these
kinds of things. So, so the one, the one, the one thing I want to, uh, point out is, uh,
if it were the case that we were in some way optimized by some intelligence that shared our
values, then one could make the argument, Hey, let's not push too far off of that, right? You're,
you're screwing up the planet. And I get a lot of these emails from people saying, uh, well, well,
things are great. You better, you know, you scientists better not mess it up. And I just
want to be clear that there, there is no basis for, for, for this, for this view. We are, our
lifespan, our health span, our aging, our susceptibility to, to all kinds of dumb diseases
and our lower back pain and our stigmatism and all this, all this stuff is, is not in any way, uh,
optimized for any of the things we care about. That's just where evolution happens to have dropped us
off at this point. That's, that's it. And so there's nothing magical about this lifespan. If,
if, if you do, you know, people who are worried about, um, uh, augmenting this lifespan, well,
what if it had been 20 or 30, you know, then what, then you say, well, you know, that's too short.
Well, why is that too short? It could have been anything. It's, but my point is it's completely
arbitrary. And so, and so let's not, um, base our, uh, decisions about what, um, what ought to be
on where the process of random mutation and selection has, has dumped us. So that's the,
you know, I, I kind of, I think that's important to say, um, be beyond that. I mean, we're certainly
involved in, uh, some, some, uh, some research on aging and the role of bioelectricity in aging and
kind of the, uh, uh, the degradation of bioelectric patterning information with age and all that.
But I think more importantly is the, my, my weather vein for all of this stuff is planaria.
So, so I think, you know, planaria basically, I think hold, hold the answer to all of life's,
uh, big questions. And so, uh, I mean, the, the, the asexual form of, um, planaria that we have,
they do not age. They, they, they, there is no, there's no evidence of an old planarian. They simply,
they, they can go forever. So these ideas that it's some sort of inevitable accumulation of errors
or it's telomeres or it's, uh, you know, uh, clearly there are ways around it. That's the one thing
that's, we, we have an existence proof, uh, that, uh, and then there's a few other animals that do
it, but planaria, I think are the most interesting, uh, there, there is obviously a strategy that gets
around it. And I think it's on us to figure out why that is. And I think it's absolutely not a
coincidence that planaria are also extremely regenerative. In addition to being immortal,
they're extremely regenerative, they're cancer resistant, and they have an incredibly noisy genome
because they don't clean their genome in every generation. Like we do, they, they write somatic
mutations. Just if you, if it doesn't kill the cell, it just basically expands into the next generation.
Planaria can be mixed deployed. Every cell could have a different number of chromosomes. They're
just a complete mess. And, and those are the animals that are, that are highly regenerative,
cancer resistant and immortal. Isn't that amazing? Isn't that right? Yeah. And, and so there's a,
so, so finally after, after years of being like feeling scandalized about this, you know,
the importance of the genome and all that, and why is the animal with the, with the craziest genome
also have all these amazing capacities? Um, I think we actually finally have, have a, a lead on,
on what's going on there, but, um, but I think, I think that's, that's what we need to look at in
terms of aging is, is, is, is I think if regenerative, if the, if the question of regenerative medicine
were solved, aging would be solved as a by-product. Excellent. Yeah. I mean, it makes me think, um,
um, in some ways, I don't know about the, the function of planaria, um, you know, they're
sort of these worms people can search up pictures of planaria. Um, but it makes me think that they,
like the, in many ways, the, let's just take ourselves, for example, what makes a human, a human
is in some ways, the fact that the, the preference price that we have, or our limited functionality,
our functionality is limited, right? Like I am not going to be at 39, 38, 37, and 36 degrees centigrade
with equal probability. But it sounds to me like planaria able to sort of metamorphosize in some
ways, some of their preferences, because as you say, their genome is shaping. Is that, is that kind of
a misconstrual of what's going on? Is it that with, or that with the sort of multi, the, the multiplicity
of the genome, the messy genome comes a multitude of function, or is it that the function is still
constrained? Yeah, I'm, I'm going to, I'm going to give you, uh, and, and, and unfortunately, I have
to, we have to run in a couple of minutes, but I'll just give you a very quick, uh, story of what I
think is going on in planaria. Uh, I think, uh, and, and this is, um, this is Steve, Steve Frank, uh,
told me an interesting, uh, analogy to this. Apparently, uh, you know, when, when RAID arrays became
popular, right? So computer, um, computer discs that are, that makes it big copies of themselves
so that, you know, if something goes wrong, he basically said that when RAID arrays became
popular, the quality of disc media went down because it wasn't as important anymore to have,
to have your hardware be super reliable because you've got this, this, uh, the system on top of it.
I think what, what's happened in planaria in that lineage is that it has, uh, really, uh, come to
grips with the fact that the hardware might be junk and that all the evolutionary effort went into
cranking the algorithm. Basically the idea that we're going to assume from the beginning that
you're full of mutations, you're unreal. It's, it's unreliable hardware, and we're going to assume
it's unreliable. And so what we're going to do is do our best to have a system that is so highly
regenerative that no matter what's going on, we can, we have stand a pretty good chance of making
a good planarian. The, the, the development of planaria that is, is this called a chaotic mode
where it's a total mess and then it sorts itself out into a proper worm. Um, I think, uh, and, and,
and here's why I think it happened. And we have computational models that show, that show how
this works. Imagine that, uh, you, you have a, uh, certain competencies to fix defects. For example,
like in the frog, we know that if, if the mouth is moved off a little bit in development, it'll soon
make its way back to where it needs to be. It sort of fixed, it fixes itself. So, so in evolution,
if you have a system that has a little bit of competency to fix itself, when that individual
comes up for selection and selection sees that, uh, okay, this is a great individual. What selection
doesn't know is, is it great because the genome was amazing or is it great because the genome was
actually so-so, but it fixed itself. You don't know. Once you don't know your, it becomes really
difficult to reward for the best genomes. What you can reward is for the best phenotypic fitness for
the best outcomes. And as soon as you do that, that makes the problem worse because then the competency
goes up, then it becomes even harder to know what your genome was. So, so you, so you start off with this
ratchet with this positive feedback loop. And I think in planaria, it went all the way in another species,
not so far. And it's some like C elegans, maybe not at all, but, but, but that, that idea that,
that the, the more competency of, of, um, uh, kind of, uh, uh, uh, reparative regenerative developmental
process, it, it, it, you can, you can eventually, if you take it to its logical conclusion, you can say,
fine, we're going to assume that the, that the structural genome is going to be all kinds of noise.
And we're going to come up with an algorithm that can keep it clean, keep the morphology clean,
assuming that that's assuming that that's the case. And I think planaria just like crank that
knob all the way and salamanders sort of do it. And, and, you know, and, and maybe nematodes don't
do it much. That is very, very cool. It makes me want to be a biologist because it, the question,
if we have more time, and I know we don't is, well, where on earth is that regenerative mechanism
coming from if it's not encoded in the genome somewhere, but we won't go into it. It just sounds to
me like there are other ways to maximize model evidence to use these active influence words,
to maximize model evidence or to return to an attractor state beyond genomic stability.
And that's really fascinating because I think people think, well, the, the priors,
the so-called phenotypic priors are just what evolution has endowed us in terms of our DNA.
Yeah. And, and, and, and so if we wanted to have another discussion, this is where we would talk
about xenobots and anthrobots and these things that have never been under selection at the organism
level, you know, in the history. Yeah. I mean, I've also been, I'll finish up here,
but I've been reading a little bit of Evan Thompson in mind and life. And he talks about how well
the, the autopoetic coupled system is not going, you can't discover that dynamic in the genome.
Cause there are things that are also selected over time, which, which refer to the external dynamic
and which refer to the world in which we are born and thrown into. And that's really important as
well. And I wonder whether, what that interplay means in terms of regeneration and, and morphogenesis,
but as, as you're all aware and I'm aware, we're limited in time. So we should, I I'd absolutely
love to do this again. I mean, it was absolutely fascinating. Um, guys, thank you. Uh, just,
if you have a minute, it'd be great to know where people can find your details and also like what you
guys have got coming up in the pipeline that people can be aware of.
France, you want to go first? Sure. I mean, you can basically look at our names and on,
you know, scholar and get some of our papers. Um, we have a great website for 11 lab. There has a
bunch of, a bunch of our research come culminated. Um, my, uh, my paper's coming up. We're actually
looking at some of these questions in an annual organism and volvox that's going to be happening
soon. I'm very excited about that. Um, because like all the works published for me right now is
a lot of the chemical simulations and talking about the concepts. I'm excited about most of
my PhD work was trying to apply this to an annual organism and see whether or not there's anything
there. Um, so I felt excited. Fantastic. And Mike?
Yeah. So, so the lab website is at, uh, drmike11.org, one word, drmike11.org. And so that's
where all the peer reviewed stuff, the, the papers, the protocols, um, datasets, software,
everything is, is there. And then kind of, uh, a little bit, uh, more, uh, out there.
Some thoughts are at a blog called thoughtforms.life. And that's just my,
that's just my personal one. I'll make sure everything goes in the, uh, video description
so people can check it out there, but guys, thank you again. Thank you so much. Yeah. Yeah.
Great conversation. Thank you so much. Thank you. It's a pleasure.
