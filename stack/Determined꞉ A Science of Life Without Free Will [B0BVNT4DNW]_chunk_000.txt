This is Audible.
To L and to B and R, who make it all seem worth it, who make it worth it.
1. Turtles All the Way Down
When I was in college, my friends and I had an anecdote that we retold frequently.
It went like this, and our retelling was so ritualistic that I suspect this is close to verbatim 45 years later.
2. So, it seems that William James was giving a lecture about the nature of life in the universe.
Afterward, an old woman came up and said,
Professor James, you have it all wrong.
To which James asked,
How so, madam?
Things aren't at all like you said, she replied.
The world is on the back of a gigantic turtle.
Hmm, said James bemused.
That may be so, but where does that turtle stand?
On the back of another turtle, she answered.
But madam, said James indulgently, where does that turtle stand?
To which the old woman responded triumphantly,
It's no use, Professor James.
It's turtles all the way down.
Oh, how we loved that story.
Always told it with the same intonation.
We thought it made us seem droll and pithy and attractive.
We used the anecdote as mockery,
a pejorative critique of someone clinging unshakably to illogic.
We'd be in the dinner hall and someone had said something nonsensical,
where their response to being challenged had made things worse.
Inevitably, one of us would smugly say,
It's no use, Professor James.
To which the person, who would heard our stupid anecdote repeatedly,
would inevitably respond,
Screw you, just listen.
This actually makes sense.
Here is the point of this book.
While it may seem ridiculous and nonsensical to explain something
by resorting to an infinity of turtles all the way down,
it actually is much more ridiculous and nonsensical
to believe that somewhere down there,
there's a turtle floating in the air.
The science of human behavior shows that turtles can't float.
Instead, it is indeed turtles all the way down.
Someone behaves in a particular way,
Maybe it's wonderful and inspiring.
Maybe it's appalling.
Maybe it's in the eye of the beholder.
Or maybe just trivial.
And we frequently ask the same basic question.
Why did that behavior occur?
If you believe that turtles can float in the air,
the answer is that it just happened.
That there was no cause besides that person having simply
decided to create that behavior.
Science has recently provided a much more accurate answer.
And when I say recently, I mean in the last few centuries.
The answer is that the behavior happened because something that preceded it
caused it to happen.
And why did that prior circumstance occur?
Because something that preceded it caused it to happen.
It's antecedent causes all the way down.
Not a floating turtle or causeless cause to be found.
Or as Maria sings in The Sound of Music,
Nothing comes from nothing.
Nothing ever could.
To reiterate, when you behave in a particular way,
which is to say when your brain has generated a particular behavior,
it is because of the determinism that came just before,
which was caused by the determinism just before that,
and before that, all the way down.
The approach of this book is to show how that determinism works,
to explore how the biology, over which you had no control,
interacting with environment, over which you had no control,
made you you.
And when people claim that there are causeless causes of your behavior
that they call free will,
they have a.
failed to recognize or not learned about
the determinism lurking beneath the surface,
and or b. erroneously concluded
that the rarefied aspects of the universe
that do work indeterministically
can explain your character, morals, and behavior.
Once you work with the notion
that every aspect of behavior has deterministic, prior causes,
you observe a behavior and can answer why it occurred.
As just noted,
because of the action of neurons in this or that part of your brain
in the preceding second.
And in the seconds to minutes before,
those neurons were activated by a thought,
a memory, an emotion, or sensory stimuli.
And in the hours to days before that behavior occurred,
the hormones in your circulation shaped those thoughts,
memories, and emotions,
and altered how sensitive your brain was
to particular environmental stimuli.
And in the preceding months to years,
experience and environment changed how those neurons function,
causing some to sprout new connections
and become more excitable,
and causing the opposite in others.
And from there,
we hurtled back decades in identifying antecedent causes.
Explaining why that behavior occurred
requires recognizing how during your adolescence,
a key brain region was still being constructed,
shaped by socialization and acculturation.
Further back,
there's childhood experience shaping the construction of your brain,
with the same then applying to your fetal environment.
Moving further back,
we have to factor in the genes you inherited
and their effects on behavior.
But, we're not done yet.
That's because everything in your childhood,
starting with how you were mothered within minutes of birth,
was influenced by culture,
which means as well by the centuries of ecological factors
that influenced what kind of culture your ancestors invented,
and by the evolutionary pressures
that molded the species you belonged to.
Why did that behavior occur?
Because of biological and environmental interactions
all the way down.
As a central point of this book,
those are all variables that you had little or no control over.
You cannot decide all the sensory stimuli in your environment,
your hormone levels this morning,
whether something traumatic happened to you in the past,
the socioeconomic status of your parents,
your fetal environment,
your genes,
whether your ancestors were farmers or herders.
Let me state this most broadly,
probably at this point too broadly for most readers,
we are nothing more or less
than the cumulative biological and environmental luck
over which we had no control
that has brought us to any moment.
You're going to be able to recite this sentence
in your irritated sleep by the time we're done.
There are all sorts of aspects about behavior that,
while true,
are not relevant to where we're heading.
For example,
the fact that some criminal behavior
can be due to psychiatric
or neurological problems.
That some kids have learning differences
because of the way their brains work.
That some people have trouble with self-restraint
because they grew up without any decent role models,
or because they're still a teenager
with a teenager's brain.
That someone has said something hurtful
merely because they're tired and stressed,
or even because of a medication they're taking.
All of these are circumstances
where we recognize that sometimes
biology can impinge on our behavior.
This is essentially a nice human agenda
that endorses society's general views
about agency and personal responsibility
but reminds you to make exceptions for edge cases.
Judges should consider mitigating factors
in criminals' upbringing during sentencing.
Juvenile murderers shouldn't be executed.
The teacher handing out gold stars to the kids
who are soaring and learning to read
should do something special too
for that kid with dyslexia.
College admissions officers should consider
more than just SAT cut-offs
for applicants who have overcome unique challenges.
These are good, sensible ideas
that should be instituted
if you decide that
some people have much less self-control
and capacity to freely choose their actions than average,
and that at times
we all have much less than we imagine.
We can all agree on that.
However, we're heading into very different terrain,
one that I suspect most readers will not agree with,
which is deciding that we have
no free will at all.
Here would be some of the logical implications
of that being the case.
That there can be no such thing as blame,
and that punishment as retribution is indefensible.
Sure, keep dangerous people from damaging others,
but do so as straightforwardly and non-judgmentally
as keeping a car with faulty brakes off the road.
That it can be okay to praise someone
or express gratitude toward them
as an instrumental intervention
to make it likely that they will repeat
that behavior in the future,
or as an inspiration to others,
but never because they deserve it.
And that this applies to you
when you've been smart or self-disciplined or kind.
Oh, as long as we're at it.
That you recognize that the experience of love
is made of the same building blocks
that constitute wildebeests or asteroids.
That no one has earned or is entitled to
being treated better or worse than anyone else.
And that it makes as little sense to hate someone
as to hate a tornado
because it supposedly decided to level your house
or to love a lilac
because it supposedly decided to make a wonderful fragrance.
That's what it means to conclude
that there is no free will.
This is what I've concluded
for a long, long time.
And even I think that taking that seriously
sounds absolutely nutty.
Moreover, most people agree that it sounds that way.
People's beliefs and values,
their behavior,
their answers to survey questions,
their actions as study subjects
in the nascent field of experimental philosophy
show that people believe in free will
when it matters.
Philosophers, about 90%,
lawyers, judges, jurors, educators,
parents, and candlestick makers.
As well as scientists,
even biologists,
even many neurobiologists,
when push comes to shove.
Work by psychologists
Alison Gopnik at UC Berkeley
and Tamar Kushnier at Cornell
shows that preschool kids
already have a robust belief
in a recognizable version of free will.
And such a belief is widespread,
but not universal,
among a wide variety of cultures.
We are not machines in most people's view.
As a clear demonstration,
when a driver or an automated car
makes the same mistake,
the former is blamed more.
And we're not alone in our faith in free will.
Research that we'll look at
in a later chapter
suggests that other primates
even believe that there is free will.
This book has two goals.
The first is to convince you
that there is no free will,
or at least that there is much less free will
than generally assumed
when it really matters.
To accomplish the first goal,
we'll look at the way smart,
nuanced thinkers argue for free will,
from the perspectives of philosophy,
legal thought, psychology, and neuroscience.
I'll be trying to present their views
to the best of my ability,
and then to explain
why I think they are all mistaken.
Some of these mistakes
arise from the myopia
used in a descriptive
rather than judgmental sense,
of focusing solely on just one sliver
of the biology of behavior.
Sometimes this is because of faulty logic,
such as concluding that
if it's not possible
to ever tell what caused X,
maybe nothing caused it.
Sometimes the mistakes reflect
unawareness or
misinterpretation of the science
underlying behavior.
Most interestingly,
I sense that mistakes arise
for emotional reasons
that reflect that there being
no free will
is pretty damn unsettling.
We'll consider this
at the end of the book.
So, one of my two goals
is to explain
why I think
all these folks are wrong
and how life would improve
if people stopped
thinking like them.
Right around here,
one might ask of me,
where do you get off?
As will be seen,
free will debates
often revolve
around narrow issues.
Does a particular hormone
actually cause a behavior
or just make it more likely?
Or is there a difference
between wanting to do something
and wanting to want something
that are usually debated
by specialized authorities?
My intellectual makeup
happens to be that
of a generalist.
I'm a neurobiologist
with a lab
that does things like
manipulate genes
in a rat's brain
to change behavior.
At the same time,
I spent part of each year
for more than three decades
studying the social behavior
and physiology
of wild baboons
in a national park in Kenya.
Some of my research
turned out to be relevant
to understanding
how adult brains
are influenced
by the stress
of childhood poverty.
And as a result,
I've wound up spending time
around the likes
of sociologists.
Another facet of my work
has been relevant
to mood disorders,
leading me to hang
with psychiatrists.
And for the last decade,
I've had a hobby
of working with
public defender offices
on murder trials,
teaching juries
about the brain.
As a result,
I've been carpetbagging
in a number
of different fields
related to behavior,
which I think
has made me
particularly prone
toward deciding
that free will
doesn't exist.
Why?
Crucially,
if you focus
on any single field
like these,
neuroscience,
endocrinology,
behavioral economics,
genetics,
criminology,
ecology,
child development,
or evolutionary biology,
you are left
with plenty of wiggle room
for deciding
that biology
and free will
can coexist.
In the words
of UC San Diego
philosopher
Manuel Vargas,
claiming that
some scientific result
shows the falsity
of free will
is either bad scholarship
or academic
hucksterism.
He is right,
if in your face.
As we will see
in the next chapter,
most experimental
neurobiology research
about free will
is narrowly anchored
by the result
of one study
that examined
events that happen
in the brain
a few seconds
before a behavior
occurs.
And Vargas would
correctly conclude
that this
scientific result,
plus the spinoffs
it has generated
in the subsequent
40 years,
doesn't prove
there's no free will.
Similarly,
you can't disprove
free will
with a scientific result
from genetics.
Genes in general
are not about
inevitability,
but rather about
vulnerability
and potential,
and no single gene,
gene variant
or gene mutation,
has ever been identified
that falsifies
free will.
You can't even do it
when considering
all our genes
at once.
And you can't
disprove free will
from a developmental
sociological perspective
by emphasizing
the scientific result
that a childhood
filled with abuse,
deprivation,
neglect,
and trauma
astronomically
increases the odds
of producing
a deeply damaged
and damaging adult.
Because there
are exceptions.
Yeah,
no single result
or scientific discipline
can do that.
But,
and this is the
incredibly important point,
put all the scientific
results together
from all the relevant
scientific disciplines,
and there's no room
for free will.
Why is that?
something deeper
than the idea
that if you examine
enough different disciplines,
one ology after another,
you're bound to
eventually find one
that provides a slam dunk,
falsifying free will
all by itself.
It is also deeper
than the idea
that even though
each discipline
has a hole
that precludes it
from falsifying free will,
at least one of the
other disciplines
compensates for it.
Crucially,
all these disciplines
collectively negate
free will
because they are
all interlinked,
constituting the same
ultimate body of knowledge.
If you talk about
the effects of
neurotransmitters
on behavior,
you are also
implicitly talking
about the genes
that specify
the construction
of those chemical
messengers
and the evolution
of those genes.
The fields of
neurochemistry,
genetics,
and evolutionary biology
can't be separated.
If you examine
how events
in fetal life
influence adult behavior,
you are also
automatically
considering things
like lifelong changes
in patterns
of hormone secretion
or in gene regulation.
If you discuss
the effects
of mothering style
on a kid's
eventual adult behavior,
by definition,
you are also
automatically discussing
the nature
of the culture
that the mother
passes on
through her actions.
There's not
a single crack
of daylight
to shoehorn
in free will.
As such,
the first half
of the book's
point is to rely
on this biological
framework in
rejecting free will,
which brings us
to the second half
of the book.
As noted,
I haven't believed
in free will
since adolescence,
and it's been
a moral imperative
for me to view
humans without
judgment or the
belief that anyone
deserves anything
special,
to live without
a capacity for
hatred or
entitlement,
and I just
can't do it.
Sure,
sometimes I can
sort of get
there,
but it is rare
that my immediate
response to events
aligns with what
I think is the
only acceptable
way to understand
human behavior.
Instead,
I usually fail
dismally.
As I said,
even I think it's
crazy to take
seriously all the
implications of
there being no
free will.
And despite that,
the goal of the
second half of the
book is to do
precisely that,
both individually
and societally.
Some chapters
consider scientific
insights about how
we might go about
dispensing with
free will belief.
Others examine how
some of the
implications of
rejecting free will
are not disastrous,
despite initially
seeming that way.
Some review
historical circumstances
that demonstrate
something crucial
about the radical
changes we'd need
to make in our
thinking and feeling.
We've done it
before.
The book's
intentionally
ambiguous title
reflects these
two halves.
It is both about
the science of
why there is no
free will,
and the science of
how we might best
live once we
accept that.
Styles of Views
Whom I Will Be
Disagreeing With
I'm going to be
discussing some of
the common
attitudes held by
people writing
about free will.
These come in
four basic
flavors.
The world is
deterministic and
there's no free
will.
In this view,
if the former is
the case, the
latter has to be
as well.
Determinism and
free will are not
compatible.
I am coming from
this perspective of
hard incompatibilism.
The world is
deterministic and
there is free will.
These folks are
emphatic that the
world is made of
stuff like atoms.
and life, in the
elegant words of
psychologist Roy
Baumeister, currently
at the University of
Queensland in
Australia, is
based on the
immutability and
relentlessness of the
laws of nature.
No magic or fairy dust
involved, no
substance dualism, the
view where brain and
mind are separate
entities.
Instead, this
deterministic world is
viewed as compatible
with free will.
This is roughly 90% of
philosophers and legal
scholars, and the
book will most often
be taking on these
compatibilists.
The world is not
deterministic.
There is no free
will.
This is an oddball
view that everything
important in the
world runs on
randomness, a
supposed basis of
free will.
We'll get to this in
chapters 9 and 10.
The world is not
deterministic.
There is free will.
These are folks who
believe, like I do,
that a deterministic
world is not
compatible with
free will.
However, no
problem, the world
isn't deterministic in
their view, opening a
door for free will
belief.
These libertarian
incompatibilists are a
rarity, and I'll only
occasionally touch on
their views.
There's a related
quartet of views
concerning the
relationship between
free will and
moral responsibility.
The last word
obviously carries a
lot of baggage with
it.
And the sense in
which it is used by
people debating
free will typically
calls forth the
concept of basic
desert, where
someone can deserve
to be treated in a
particular way, where
the world is a morally
acceptable place in its
recognition that one
person can deserve a
particular reward,
another a particular
punishment.
As such, these views
are, there's no free
will, and thus holding
people morally
responsible for their
actions is wrong, where
I sit.
And as will be covered
in chapter 14, this is
completely separate from
forward-looking issues of
punishment for deterrent
value.
There's no free will, but
it is okay to hold people
morally responsible for
their actions.
This is another type of
compatibilism.
An absence of free will
and moral responsibility
coexist without invoking
the supernatural.
There's free will, and
people should be held
morally responsible.
This is probably the most
common stance out there.
There's free will, but
moral responsibility isn't
justified.
This is a minority view.
Typically, when you look
closely, the supposed free
will exists in a very
narrow sense and is
certainly not worth
executing people about.
Obviously, imposing these
classifications on
determinism, free will, and
moral responsibility is
wildly simplified.
A key simplification is
pretending that most
people have clean, yes-or-no
answers as to whether
these states exist.
The absence of clear
dichotomies leads to
frothy philosophical
concepts like partial
free will, situational
free will, free will in
only a subset of us, free
will only when it matters
or only when it doesn't.
This raises the question
of whether the edifice of
free will belief is
crumbled by one flagrant,
highly consequential
exception, and conversely,
whether free will skepticism
collapses when the
opposite occurs.
Focusing on gradations
between yes and no is
important, since interesting
things in the biology of
behavior are often on
continua.
As such, my fairly
absolutist stance on these
issues puts me way out in
left field.
Again, my goal isn't to
convince you that there's
no free will.
It will suffice if you
merely conclude that
there's so much less free
will than you thought that
you have to change your
thinking about some truly
important things.
Despite starting by
separating determinism
slash free will and
free will slash moral
responsibility, I follow the
frequent convention of
merging them into one.
Thus, my stance is that
because the world is
deterministic, there can't
be free will, and thus
holding people morally
responsible for their
actions is not okay.
A conclusion described as
deplorable by one leading
philosopher, who's
thinking we're going to
dissect big time.
This incompatibilism will
be most frequently
contrasted with the
compatibilist view that
while the world is
deterministic, there is
still free will, and thus
holding people morally
responsible for their
actions is just.
This version of
compatibilism has produced
numerous papers by
philosophers and legal
scholars concerning the
relevance of neuroscience
to free will.
After reading lots of
them, I've concluded that
they usually boil down to
three sentences.
A. Wow, there have been
all these cool advances in
neuroscience, all reinforcing
the conclusion that ours is
a deterministic world.
B. Some of those
neuroscience findings challenge
our notions of agency,
moral responsibility, and
deservedness so deeply that
one must conclude that there is
no free will.
C. Nah, it still exists.
Naturally, a lot of time will
be spent examining the nah part.
In doing so, I'll consider only a
subset of such compatibilists.
Here's a thought experiment for
identifying them.
In 1848, at a construction
site in Vermont, an accident
with dynamite hurled a metal
rod at high speed into the
brain of a worker, Phineas Gage,
and out the other side.
This destroyed much of Gage's
frontal cortex, an area central
to executive function, long-term
planning, and impulse control.
In the aftermath, Gage was no
longer Gage, as stated by one
friend.
Formerly sober, reliable, and
the foreman of his work crew,
Gage was now fitful, irreverent,
indulging at times in the grossest
profanity, which was not
previously his custom, obstinate,
yet capricious and vacillating, as
described by his doctor.
Phineas Gage is the textbook case
that we are the end products of our
material brains.
Now, 170 years later, we
understand how the unique function
of your frontal cortex is the
result of your genes, prenatal
environment, childhood, and so on.
Wait for chapter 4.
Now the thought experiment.
Raise a compatibilist philosopher
from birth in a sealed room where
they never learn anything about the
brain.
Then, tell them about Phineas Gage
and summarize our current knowledge
about their frontal cortex.
If their immediate response is,
whatever, they're still free will.
I'm not interested in their views.
The compatibilist I have in mind is
one who then wonders,
OMG, what if I'm completely wrong
about free will?
Ponders hard for hours or decades
and concludes that there's still
free will, here's why, and it's
okay for society to hold people
morally responsible for their
actions.
If a compatibilist has not wrestled
through being challenged by
knowledge of the biology of who we
are, it's not worth the time trying
to counter their free will belief.
Ground Rules and Definitions
What is free will?
Grown, we have to start with that.
So here comes something totally
predictable along the lines of
different things to different types
of thinkers, which gets confusing.
Totally uninviting.
Nevertheless, we have to start there,
followed by, what is determinism?
I'll do my best to mitigate the drag
of this.
What do I mean by free will?
People define free will
differently.
Many focus on agency, whether a
person can control their actions,
act with intent.
Other definitions concern whether,
when a behavior occurs, the person
knows that there are alternatives
available.
Others are less concerned with what
you do than with vetoing what you
don't want to do.
Here's my take.
Suppose that a man pulls the
trigger of a gun.
Mechanistically, the muscles in his
index finger contracted because they
were stimulated by a neuron having an
action potential.
That is, being in a particularly
excited state.
That neuron, in turn, had its action
potential because it was stimulated by
the neuron just upstream, which had its
own action potential because of the next
neuron upstream.
And so on.
Here's the challenge to a free willer.
Find me the neuron that started this
process in this man's brain, the neuron
that had an action potential for no
reason, where no neuron spoke to it just
before.
Then, show me that this neuron's actions
were not influenced by whether the man was
tired, hungry, stressed, or in pain at the
time.
That nothing about this neuron's function was
altered by the sights, sounds, smells, and so
on, experienced by the man in the previous
minutes, nor by the levels of any hormones
marinating his brain in the previous hours
to days, nor whether he had experienced a
life-changing event in recent months or years.
And, show me that this neuron's supposedly
freely-willed functioning wasn't affected by
the man's genes, or by the lifelong changes in
regulation of those genes caused by experiences
during his childhood, nor by levels of hormones
he was exposed to as a fetus when that brain
was being constructed, nor by the centuries of
history and ecology that shaped the invention
of the culture in which he was raised.
Show me a neuron being a causeless cause in this
total sense.
The prominent compatibilist philosopher Alfred
Mele of Florida State University emphatically feels that
requiring something like that of free will is
setting the bar absurdly high.
But this bar is neither absurd nor too high.
Show me a neuron or brain whose generation of a
behavior is independent of the sum of its
biological past, and for the purposes of this
book, you've demonstrated free will.
The point of the first half of this book is to
establish that this can't be shown.
What do I mean by determinism?
It's virtually required to start this topic with the
dead, white male Pierre-Simon Laplace, the 18th-19th
century French polymath.
It's also required that you call him a polymath, as he
contributed to mathematics, physics, engineering, astronomy,
and philosophy.
Laplace provided the canonical claim for all of
determinism.
If you had a superhuman who knew the location of every particle in
the universe at this moment, they'd be able to accurately
predict every moment in the future.
Moreover, if this superhuman, eventually termed Laplace's
demon, could recreate the exact location of every particle at
any point in the past, it would lead to a present identical to
our current one.
The past and future of the universe are already determined.
Science, since Laplace's time, shows that he wasn't completely right,
proving that Laplace was not a Laplacian demon, but the spirit of his
demon lives on.
Contemporary views of determinism have to incorporate the fact that
certain types of predictability turn out to be impossible, the subjects of
chapters 5 and 6, and certain aspects of the universe are actually
non-deterministic, chapters 9 and 10.
Moreover, contemporary models of determinism must also accommodate the
role played by meta-level consciousness.
What do I mean by this?
Consider a classic psychology demonstration of people having less freedom in
their choices than they assumed.
Ask someone to name their favorite detergent, and if you have unconsciously
cued them earlier with the word
ocean, they become more likely to answer
tide.
As an important measure of where meta-level consciousness comes in,
suppose the person realizes what the researcher is up to, and wanting to show
that they can't be manipulated, decides that they won't say tide, even if it is
their favorite.
Their freedom has been just as constrained, appointed many of the coming
chapters.
Similarly, wind up as an adult exactly like your parents, or the exact opposite of
them, and you are equally unfree.
In the latter case, the pull toward adopting their behavior, the ability to
consciously recognize that tendency to do that, the mindset to recoil from that with
horror and thus do the opposite, are all manifestations of the ways that you became
you outside your control.
Finally, any contemporary view of determinism must accommodate a profoundly important point,
one that dominates the second half of the book.
Despite the world being deterministic, things can change.
Brains change.
Behaviors change.
We change.
And that doesn't counter this being a deterministic world without free will.
In fact, the science of change strengthens the conclusion.
This will come in Chapter 12.
With those issues in mind, time to see the version of determinism that this book builds
on.
Imagine a university graduation ceremony.
Almost always moving, despite the platitudes, the boilerplate, the kitsch.
The happiness, the pride, the families whose sacrifices now all seem worth it, the graduates
who were the first in their family to finish high school, the ones whose immigrant parents
sit there glowing, their saris, dashikis, barongs, broadcasting that their pride in the
present isn't at the cost of pride in their past.
And then, you notice someone.
Amid the family clusters post-ceremony, the new graduates posing for pictures with grandma
in her wheelchair, the bursts of hugs and laughter, you see the person way in the back,
the person who is part of the grounds crew, collecting the garbage from the cans on the
perimeter of the event.
Randomly pick any of the graduates.
Do some magic so that this garbage collector started life with the graduates' genes.
Likewise, forgetting the womb in which nine months were spent and the lifelong epigenetic
consequences of that.
Get the graduates' childhood as well.
One filled with, say, piano lessons and family game nights.
Instead of, say, threats of going to bed hungry, becoming homeless, or being deported for lack
of papers, let's go all the way so that, in addition to the garbage collector having gotten
all that of the graduates' past, the graduate would have gotten the garbage collectors' past.
Trade every factor over which they had no control and you will switch who would be in the graduation
robe and who would be hauling garbage cans.
This is what I mean by determinism.
And why does this matter?
Because we all know that the graduate and the garbage collector would switch places.
And because, nevertheless, we rarely reflect on that sort of fact, we congratulate the graduate
on all she's accomplished and move out of the way of the garbage guy without glancing at him.
Two men stand by a hangar in a small airfield at night.
One is in a police officer's uniform, the other dressed as a civilian.
They talk tensely, while in the background, a small plane is taxiing to the runway.
Suddenly, a vehicle pulls up and a man in a military uniform gets out.
He and the police officer talk tensely.
The military man begins to make a phone call.
The civilian shoots him, killing him.
A vehicle full of police pulls up abruptly, the police emerging rapidly.
The police officer speaks to them as they retrieve the body.
They depart as abruptly, with the body but not the shooter.
The police officer and the civilian watch the plane take off and then walk off together.
What's going on?
A criminal act obviously occurred.
From the care with which the civilian aimed, he clearly intended to shoot the man.
A terrible act, compounded further by the man's remorseless air.
This was cold-blooded murder.
Depraved indifference.
It is puzzling, though, that the police officer made no attempt to apprehend him.
Possibilities come to mind.
None good.
Perhaps the officer has been blackmailed by the civilian to look the other way.
Maybe all the police who appeared on the scene are corrupt, in the pocket of some drug cartel.
Or perhaps the police officer is actually an imposter.
One can't be certain.
But it's clear that this was a scene of intent-filled corruption and lawless violence.
The police officer and the civilian exemplars of humans at their worst.
That's for sure.
Intent features heavily in issues about moral responsibility.
Did the person intend to act as she did?
When exactly was the intent formed?
Did she know that she could have done otherwise?
Did she feel a sense of ownership of her intent?
These are pivotal issues to philosophers, legal scholars, psychologists, and neurobiologists.
In fact, a huge percentage of the research done concerning the free will debate revolves around intent,
often microscopically examining the role of intent in the seconds before a behavior happens.
Entire conferences, edited volumes, careers, have been spent on those few seconds.
And, in many ways, this focus is at the heart of arguments supporting compatibilism.
This is because all the careful, nuanced, clever experiments done on the subject collectively fail to falsify free will.
After reviewing these findings, the purpose of this chapter is to show how, nevertheless,
all this is ultimately irrelevant to deciding that there's no free will.
This is because this approach misses 99% of the story by not asking the key question.
And where did that intent come from in the first place?
This is so important because, as we will see,
while it sure may seem at times that we are free to do as we intend,
we are never free to intend what we intend.
Maintaining belief in free will by failing to ask that question
can be heartless and immoral
and is as myopic as believing that all you need to know to assess a movie
is to watch its final three minutes.
Without that larger perspective,
understanding the features and consequences of intent
doesn't amount to a hill of beans.
300 milliseconds
Let's start off with William Henry Harrison,
ninth president of the United States.
Remembered only for idiotically insisting on giving a record-long two-hour inauguration speech
in the freezing cold in January 1841,
without coat or hat.
He caught pneumonia and died a month later,
the first president to die in office and the shortest presidential term.
With that in place, think about William Henry Harrison.
But first, we're going to stick electrodes all over your scalp
for an electrocephalogram, EEG,
to observe the waves of neuronal excitation
generated by your cortex when you're thinking of Bill.
Now, don't think of Harrison.
Think about anything else,
as we continue recording your EEG.
Good. Well done.
Now, don't think about Harrison,
but plan to think about him whenever you want a little while later,
and push this button the instant you do.
Oh, also, keep an eye on the second hand of this clock
and note when you chose to think about Harrison.
We're also going to wire up your hand with recording electrodes
to detect precisely when you start the pushing.
Meanwhile, the EEG will detect
when neurons that command those muscles to push the button
start to activate.
And this is what we find out.
Those neurons had already activated
before you thought you were first freely choosing
to start pushing the button.
But the experimental design of the study isn't perfect
because of its nonspecificity.
We may have just learned what's happening in your brain
when it is generically doing something
as opposed to doing this particular something.
Let's switch instead to your choosing
between doing A and doing B.
William Henry Harrison sits down
to some typhoid-riddled burgers and fries,
and he asks for ketchup.
If you decide he would have pronounced it ketchup,
immediately push this button with your left hand.
If it was catsup,
push this other button with your right.
Don't think about his pronunciation of ketchup right now.
Just look at the clock
and tell us the instant you chose which button to push.
And you get the same answer.
The neurons responsible for whichever hand pushes the button
activate before you consciously formed your choice.
Let's do something fancier now
than looking at brain waves,
since EEG reflects the activity
of hundreds of millions of neurons at a time,
making it hard to know what's happening
in particular brain regions.
Thanks to a grant from the WHH Foundation,
we've bought a neuroimaging system
and will do functional magnetic resonance imaging,
fMRI of your brain,
while you do the task.
This will tell us about activity
in each individual brain region
at the same time.
The results show clearly,
once again,
that particular regions have decided
which button to push
before you believe you consciously
and freely chose,
up to 10 seconds before,
in fact.
Eh,
forget about fMRI
and the images it produces,
where a single pixel signal
reflects the activity
of about half a million neurons.
Instead,
we're going to drill holes in your head
and then stick electrodes into your brain
to monitor the activity
of individual neurons.
Using this approach,
once again,
we can tell if you'll go for
ketchup or catsup
from the activity of neurons
before you believe
you decided.
These are the basic approaches
and findings
in a monumental series of studies
that have produced
a monumental shitstorm
as to whether they demonstrate
that free will is a myth.
These are the core findings
in virtually every debate
about what neuroscience
can tell us on the subject.
And I think that
at the end of the day,
these studies are irrelevant.
It began with
Benjamin Libet,
a neuroscientist
at the University of California
at San Francisco,
in a 1983 study
so provocative
that at least one philosopher
refers to it as
infamous.
There are conferences
held about it,
and scientists
are described
as doing
Libet-style studies.
We know
the experimental setup.
Here's a button,
push it whenever you want,
don't think about it beforehand,
look at this fancy clock
that makes it easy
to detect fractions
of a second
and tell us
when you decided
to push the button.
That moment
of conscious awareness
when you freely
made your decision.
Meanwhile,
we'll be collecting
EEG data from you
and monitoring
exactly when
your finger starts moving.
Out of this
came the basic findings.
People reported
that they decided
to push the button
about 200 milliseconds,
two-tenths of a second,
before their fingers
started moving.
There was also
a distinctive
EEG pattern
called a readiness potential
when people
prepared to move.
This emanated
from a part of the brain
called
the SMA,
supplementary motor area,
which sends projections
down the spine,
stimulating muscle movement.
But here's the crazy thing.
The readiness potential,
the evidence
that the brain
had committed
to pushing the button,
occurred about
300 milliseconds
before people
believed
they had decided
to push the button.
That sense of
freely choosing
is just a
post-hoc illusion,
a false sense
of agency.
This is the observation
that started it all.
Read technical papers
on biology
and free will,
and in 99.9%
of them,
Libet will appear,
usually by the
second paragraph.
Ditto for articles
in the lay press.
Scientist proves
there is no free will.
Your brain decides
before you think
you did.
The article
inspired scads
of follow-up research
and theorizing.
People are still
doing studies
directly inspired
by Libet
nearly 40 years
after his 1983 publication.
For example,
there's a 2020 paper
entitled
Libet's Intention Reports
Are Invalid.
Having your work
be important enough
that decades later,
people are still
trash-talking it
is immortality
for a scientist.
The basic Libet
finding that you're
kidding yourself
if you think
you made a decision
when it feels like
you did
has been replicated.
Neuroscientist
Patrick Haggard
of University College London
had subjects
choose between
two buttons,
choosing to do
A versus B,
rather than
choosing to do
something versus not.
This suggested
the same conclusion
that the brain
has seemingly decided
before you think
you did.
These findings
ushered in
Libet 2.0,
the work of
John Dylan Haynes
and colleagues
at Humboldt University
in Germany.
It was 25 years later
with fMRIs available.
Everything else
was the same.
Once again,
people's sense
of conscious choice
came about
200 milliseconds
before the muscles
started moving.
Most important,
the study replicated
the conclusion
from Libet,
flushing it out further.
With fMRI,
Haynes was able
to spot
the witch-button decision
even farther up
in the brain's
chain of command,
in the prefrontal cortex,
PFC.
This made sense,
as the PFC
is where executive
decisions are made.
When the PFC,
along with the rest
of the frontal cortex,
is destroyed,
a la gauge,
one makes terrible,
disinhibited decisions.
To simplify a bit,
once having decided,
the PFC passes
the decision on
to the rest
of the frontal cortex,
which passes it
to the premotor cortex,
then to the SMA,
and a few steps later,
on to your muscles.
Supporting the view
of Haynes
having spotted
decision-making
farther upstream,
the PFC was making
its decision
up to 10 seconds
before subjects felt
they were consciously
deciding.
Then,
Libet 3.0
explored free will
as an illusion,
down to monitoring
the activity
of individual neurons.
Neuroscientist
Isaac Fried
of UCLA
worked with patients
with intractable epilepsy,
unresponsive
to anti-seizure medications.
As a last-ditch effort,
neurosurgeons remove
the part of the brain
where these seizures
initiate.
With Fried's patients,
it was the frontal cortex.
One obviously
wants to minimize
the amount of tissue
removed,
and in preparation
for that,
electrodes are implanted
in the targeted area
prior to the surgery,
allowing for monitoring
activity there.
This provides
a fine-grained map
of function,
telling you what
subparts you should
avoid removing,
if there's any leeway.
So Fried would have
the subjects
do a Libet-style task,
while electrodes
in their frontal cortex
detected when particular
neurons there
activated.
Same punchline.
Some neurons activated
in preparation
for a particular
movement decision,
seconds before subjects
claimed they had
consciously decided.
In fascinating
related studies,
he has shown that
neurons in the hippocampus
that code for a
specific episodic memory
activate one to two
seconds before the
person becomes aware
of freely recalling
that memory.
Thus,
three different
techniques,
monitoring the activity
of hundreds of millions
of neurons down
to single neurons,
all show that at the
moment when we believe
that we are consciously
and freely choosing
to do something,
the neurobiological
die has already
been cast.
That sense of
conscious intent
is an irrelevant
afterthought.
This conclusion is
reinforced by studies
showing how malleable
the sense of intent
and agency is.
Back to the basic
Libet paradigm.
This time,
pushing a button
caused a bell to ring
and the researchers
would vary how long
of a fraction of a
second time delay
there'd be between
the pushing and the
ringing.
When the bell ringing
was delayed,
subjects reported
their intent to push
the button coming a bit
later than usual,
without the readiness
potential or actual
movement changing.
Another study showed
that if you feel happy,
you perceive that
conscious sense of
choice sooner than
if you're unhappy,
showing how our
conscious sense of
choosing can be
fickle and subjective.
Other studies of
people undergoing
neurosurgery for
intractable epilepsy,
meanwhile,
showed that the
sense of intentional
movement and actual
movement can be
separated.
Stimulate an
additional brain
region relevant to
decision making,
and people would
claim they had just
moved voluntarily,
without so much as
having tensed a
muscle.
Stimulate the
pre-SMA instead,
and people would
move their finger
while claiming that
they hadn't.
One neurological
disorder reinforces
these findings.
Stroke damage to
part of the SMA
produces anarchic
hand syndrome,
where the hand
controlled by that
side of the SMA
acts against the
person's will.
For example,
grabbing food from
someone else's plate.
Sufferers even
restrain their
anarchic hand with
their other one.
This suggests that
the SMA keeps
volition on task,
binding intention
to action, all
before the person
believes they've
formed that
intention.
Psychology studies
also show how the
sense of agency
can be illusory.
In one study,
pushing a button
would be followed
immediately by a
light going on,
some of the time.
The percentage of
time the light
would go on was
varied.
Subjects were then
asked how much
control they felt
they had over the
light.
People consistently
overestimate how
reliably the light
occurs, feeling that
they control it.
In another study,
subjects believed
they were voluntarily
choosing which hand
to use in pushing
a button.
Unbeknownst to them,
hand choice was
being controlled by
transcranial magnetic
stimulation of their
motor cortex.
Nonetheless,
subjects perceived
themselves as
controlling their
decisions.
Meanwhile, other
studies used
manipulations straight
out of the playbook
of magicians and
mentalists, with
subjects claiming
agency over events
that were actually
foregone and out of
their control.
If you do X, and
this is followed by
Y, what increases
the odds of your
feeling like you
caused Y?
Psychologist Daniel
Wegner of Harvard,
a key contributor in
this area, identified
three logical
variables.
One is priority, the
shorter the delay
between X and Y, the
more readily we have
an illusory sense of
will.
There are also
consistency and
exclusivity, how
consistently Y happens
after you've done
X, and how often Y
happens in the
absence of X.
The more of the
former and the less
of the latter, the
stronger the illusion.
Collectively, what
does this Libetian
literature, starting
with Libet, show?
That we can have an
illusory sense of
agency, where our
sense of freely,
consciously choosing
to act can be
disconnected from
reality.
We can be
manipulated as to
when we first feel a
sense of conscious
control.
Most of all, this
sense of agency comes
after the brain has
already committed to
an action.
Free will is a
myth.
Surprise, people
have been screaming
at each other about
these conclusions ever
since.
Incompatibilists
perpetually citing
Libet and his
descendants, and
compatibilists being
scornful shade-throwers
about the entire
literature.
It didn't take long
to start.
Two years after his
landmark paper, Libet
published a review in
a peer-commentary
journal, where
someone presents a
theoretical paper on
a controversial topic,
followed by short
commentaries by the
scientist's friends
and enemies.
Commentators beating
on Libet accused
him of egregious
errors, overlooking
fundamental measurement
concepts, conceptual
unsophistication.
Pardon, your dualism
is showing, accused
one critic, and having
an unscientific faith in
the accuracy of his
timing measurements,
sarcastically proclaiming
Libet as practicing
chronotheology.
The criticisms of the
work of Libet, Haynes,
Fried, Wegner,
and friends, continue
unabated.
Some focus on
minutiae, like the
limitations of using
EEGs, fMRI, and
single neuron recordings,
or the pitfalls
inherent in subjects
self-reporting most
anything.
But most criticisms are
more conceptual and
collectively show that
rumors of Libetianism
killing free will are
exaggerated.
These are worth
detailing.
You guys proclaim the
death of free will
based on spontaneous
finger movements?
The Libetian literature
is built around people
spontaneously deciding
to do something.
In the view of
Manuel Vargas, free
will revolves around
being future-oriented,
enduring an immediate
cost for a long-term
goal.
And thus, Libet's
experiment insisted on a
purely immediate,
impulsive action,
which is precisely not
what free will is for.
Moreover, what was
being spontaneously
decided was to push a
button, and this bears
little resemblance to
whether we have free
will concerning our
beliefs and values or
our most consequential
actions.
In the words of
psychologist Uri Maus
of Chapman University,
this is a contrast
between picking and
choosing.
Libet is about picking
which box of Cheerios
to take off the
supermarket shelf, not
about choosing
something major.
Dartmouth philosopher
Adina Roskies, for
example, views Libet
world-picking as a
caricature of real
choice, dwarfed even
by the complexity of
deciding between tea
and coffee.
Does the Libet finding
apply to something more
interesting than
button-pushing?
Freed replicated the
Libet effect when
subjects in a driving
simulator chose between
turning left and
turning right.
Another study merged
neuroscience with
getting out of the
lab on a sunny day,
checking for the Libet
phenomenon in subjects
just before they
bungee jumped.
Did the neuroscientists
clutching their
equipment jump too?
No.
A wireless EEG device
was strapped to the
jumpers' heads,
making them look like
Martians persuaded to
bungee jump by frat
bros after some
beer pong.
Results?
Replication of Libet,
where a readiness
potential preceded the
subjects believing they
had decided to jump.
To which the
compatibilists replied,
this is still totally
artificial.
Choosing when to leap
into an abyss or whether
to turn left or right in a
driving simulator tells us
nothing about our free
will in choosing between,
say, becoming a nudist
versus a Buddhist,
or becoming an
algologist versus an
allergologist.
This criticism was backed
by a particularly elegant
study.
In the first situation,
subjects would be presented
with two buttons and told
that each represented a
particular charity.
Press one of the buttons
and that charity will be
sent a thousand dollars.
Second version.
Two buttons,
two charities,
push whichever button you
feel like.
Each charity is getting
five hundred dollars.
The brain was commanding the
same movement in both
scenarios,
but the choice in the first
one was highly consequential,
while that in the second
was as arbitrary as the one
in the Libet study.
The boring arbitrary
situation evoked the usual
readiness potential before
there was a sense of
conscious decision.
The consequential one
didn't.
In other words,
Libet doesn't tell us
anything about free will
worth wanting.
In the wonderfully sarcastic
words of one leading
compatibilist,
the take-home message of
this entire literature
is,
don't play rock-paper-scissors
for money,
with one of these
free will skeptic
researchers,
if your head is in
an fMRI machine.
But then,
the revenge of the
free will skeptics.
Haynes' group
brain-imaged subjects
participating in a
non-motoric task,
choosing whether to add
or subtract one number
from another.
They found a neural
signature of decision
coming before
conscious awareness,
but coming from
a different brain region
than the SMA,
called the posterior
cingulate,
precuneus cortex.
So maybe the
pick-your-charity
scientists were just
looking in the wrong
part of the brain.
Simple brain regions
decide things before
you think you've
consciously made a
simple decision.
More complicated regions
before you think
you've made a
complicated choice.
The jury is still out,
because the
Libetian literature
remains almost entirely
about spontaneous
decisions regarding
some fairly simple
things.
On to the next
broad criticism.
60%?
Really?
What does it mean
to become aware
of a conscious decision?
What do deciding
and intending
really mean?
Again,
with semantics
that aren't just
semantic.
The philosophers
run wild here
in subtle ways
that leave many
neuroscientists,
for example me,
gasping in
defanged awe.
How long does it
take to focus on
focusing on the
second hand on a
clock?
In her writing,
Roskies emphasizes
the difference
between conscious
intention and
consciousness of
intention.
Alfred Mealy
speculates that
the readiness
potential is the
time when,
in fact,
you have
legitimately
freely chosen,
and it then
takes a bit of
time for you to
be consciously
aware of your
freely willed
choice.
Arguing against
this,
one study showed
that at the time
of the onset of
the readiness
potential,
rather than
thinking about
when they were
going to move,
many subjects
were thinking
about things
like dinner.
Can you
decide to
decide?
Are intending
and having an
intent the
same thing?
Libet instructed
subjects to note
the time when
they first became
aware of the
subjective experience
of wanting or
intending to
act, but are
wanting and
intending the
same?
Is it
possible to
be spontaneous
when you've
been told to
be spontaneous?
As long as
we're at it,
what actually
is a readiness
potential?
Remarkably,
nearly 40
years after
Libet, a
paper can
still be
entitled,
What is the
readiness
potential?
Could it
be deciding
to do
actual
intention,
while the
conscious sense
of decision
is deciding
to do now
an
implementation
of intention?
Maybe the
readiness potential
doesn't mean
anything.
Some models
suggest that it
is just the
point where
random activity
in the SMA
passes a
detectable
threshold.
Mealy forcefully
suggests that
the readiness
potential is not
a decision,
but an urge,
and physicist
Susan Pocket
and psychologist
Suzanne Purdy,
both of the
University of
Auckland,
have shown that
the readiness
potential is less
consistent and
shorter when
subjects are
planning to
identify when
they made a
decision versus
when they felt
an urge.
For others,
the readiness
potential is the
process leading
to deciding,
not the
decision itself.
One clever
experiment supports
this interpretation.
In it,
subjects were
presented four
random letters
and then instructed
to choose one
in their minds.
Sometimes they
were then signaled
to press a button
corresponding to
that letter,
sometimes not.
Thus,
the same
decision-making
process occurred
in both
scenarios,
but only one
actually produced
movement.
Crucially,
a similar
readiness potential
occurred in
both cases,
suggesting,
in the words of
compatibilist
neuroscientist
Michael Gazoniga,
that rather than
the SMA deciding
to enact a
movement,
it's warming up
for its
participation in
the dynamic
events.
So are
readiness
potentials and
their precursors
decisions or
urges?
A decision is
a decision,
but an urge
is just an
increased likelihood
of a decision.
Does a
preconscious
be a
readiness potential
ever occur?
And despite
that,
the movement
doesn't then
happen?
Does a movement
ever occur
without a
preconscious
signal preceding
it?
Combining these
two questions,
how accurately
do these
preconscious
signals predict
actual behavior?
Something close
to 100%
accuracy would
be a major
blow to
free will
belief.
In contrast,
the closer
accuracy is to
chance,
that is,
50%,
the less
likely it is
that the
brain decides
anything before
we feel a
sense of
choosing.
As it turns
out,
predictability
isn't all
that great.
The original
Libet study was
done in such a
way that it
wasn't possible
to generate a
number for
this.
However,
in the Haines
studies,
fMRI images
predicted which
behavior occurred
with only about
60% accuracy,
almost at the
chance level.
For Mealy,
a 60% accuracy
rate in predicting
which button a
participant will
press next
doesn't seem to
be much of a
threat to free
will.
In Roski's
words,
all it suggests
is that there
are some
physical factors
that influence
decision-making.
The Freed
studies recording
from individual
neurons pushed
accuracy up into
the 80% range.
While certainly
better than
chance,
this sure doesn't
constitute a nail
in free will's
coffin.
Now,
for the next
criticisms.
What is
consciousness?
Giving this
section this
ridiculous heading
reflects how
unenthused I am
about having to
write this next
stretch.
I don't understand
what consciousness
is, can't
define it.
I can't
understand
philosophers
writing about
it, or
neuroscientists,
for that matter,
unless it's
consciousness in
the boring
neurological sense,
like not
experiencing
consciousness
because you're
in a coma.
Nevertheless,
consciousness is
central to
limit debates,
sometimes in a
fairly heavy-handed
way.
For example,
take Mealy,
in a book whose
title trumpets that
he's not pulling
any punches.
Free.
Why science
hasn't disproved
free will.
In his first
paragraph, he
writes,
There are two
main scientific
arguments today
against the
existence of
free will.
One arises from
social psychologists
showing that
behavior can be
manipulated by
factors that
we're not aware
of.
We've seen
examples of
these.
The other is
neuroscientists
whose basic
claim is that
all our
decisions are
made unconsciously
and therefore
not freely.
My emphasis.
In other
words, that
consciousness is
just an
epiphenomenon,
an illusory,
reconstructive sense
of control
irrelevant to
our actual
behavior.
This strikes me
as an overly
dogmatic way of
representing just
one of many
styles of
neuroscientific
thought on
the subject.
The, oh,
you neuroscientists
not only eat
your dead,
but also
believe all
our decisions
are unconscious
matters because
we shouldn't be
held morally
responsible for
our unconscious
behaviors,
although
neuroscientist
Michael Shadlin
of Columbia
University,
whose excellent
research has
informed free
will debates,
makes a spirited
argument along
with Roski's
that we should
be held morally
responsible for
even our
unconscious
acts.
Compatibilists
trying to fend
off the
Libetians
often make a
last stand
with consciousness.
Okay, okay,
suppose that
Libet,
Haynes,
Freed,
and so on
really have
shown that the
brain decides
something before
we have a sense
of having
consciously and
freely done so.
Let's grant
the incompatibilists
that, but does
turning that
preconscious
decision into
actual behavior
require that
conscious sense
of agency?
Because if it
does, rather
than bypassing
consciousness as
an irrelevancy,
free will can't
be ruled out.
As we saw,
knowing what a
brain's
preconscious
decision was
moderately
predicts whether
the behavior
will actually
occur.
But what about
the relationship
between the
preconscious
brain's decision
and the sense
of conscious
agency?
Is there ever
a readiness
potential followed
by a behavior
without a conscious
sense of agency
coming in between?
One cool study
done by Dartmouth
neuroscientist
Thalia Wheatley
and collaborators
shows precisely
this.
Subjects were
hypnotized and
implanted with a
post-hypnotic
suggestibility that
they make a
spontaneous
libbit-like
movement.
In this case,
when triggered
by the cued
suggestion,
there'd be a
readiness potential
and the
subsequent movement
without conscious
awareness in
between.
Consciousness is
an irrelevant
hiccup.
Sure, retort
compatibilists,
this doesn't mean
that intentional
behavior always
bypasses
consciousness.
Rejecting free
will based on
what happens in
the post-hypnotic
brain is
kind of flimsy.
And there is a
higher order level
to this issue,
something emphasized
by incompatibilist
philosopher Greg
Caruso of the
State University
of New York.
You're playing
soccer, you have
the ball, and
you consciously
decide that you
are going to try
to get past this
defender, rather
than pass the
ball off.
In the process of
then trying to do
this, you make a
variety of procedural
movements that
you're not
consciously choosing.
What does it
mean that you
have made the
explicit choice
to let a
particular implicit
process take
over?
The debate
continues, not
just over whether
the pre-conscious
requires consciousness
as a mediating
factor, but also
over whether both
can simultaneously
cause a
behavior.
Amid these
arcana, it's
hugely important if
the pre-conscious
decision requires
consciousness as a
mediator.
Why?
Because during that
moment of conscious
meditation, we should
then be expected to
be able to veto a
decision, prevent it
from happening, and
you can hang moral
responsibility on
that.
Free won't.
The power to veto.
Even if we don't
have free will, do we
have free won't?
The ability to slam
our foot on the
brake between the
moment of that
conscious sense of
freely choosing to
do something and the
behavior itself?
This is what Libet
concluded from his
studies.
Clearly, we have
that veto power.
Writ small, you're
about to reach for
more M&Ms, but
stop an instant
before.
Writ larger, you're
about to say something
hugely inappropriate
and disinhibited, but
thank God, you stop
yourself as your
larynx warms up to
doom you.
The basic Libetian
findings gave rise to
a variety of studies
looking at where
vetoing actions fits
in.
Do it or not.
Once that conscious
sense of intent
occurs, subjects have
the option to stop.
Do it now or in a
bit.
Once that conscious
sense of intent
occurs, immediately
push the button or
first count to ten.
Impose an external
veto.
In a brain-computer
interface study,
researchers used a
machine-learning
algorithm that
monitored a subject's
readiness potential,
predicting in real
time when the person
was about to move.
Some of the time, the
computer would signal
the subject to stop
the movement in time.
Of course, people could
generally stop themselves
up until a point of no
return, which roughly
corresponded to when the
neurons that send a
command directly to
muscles were about to
fire.
As such, a readiness
potential doesn't
constitute an unstoppable
decision, and one would
generally look the same
whether the subject was
definitely going to push
a button or there was
the possibility of a
veto.
How does the vetoing
work, neurobiologically?
Slamming a foot on the
brake involved activating
neurons just upstream of
the SMA.
Libet may have spotted this
in a follow-up study
examining free won't.
Once subjects had that
conscious sense of intent,
they were supposed to veto
the action.
At that point, the tail
end of the readiness
potential would lose
steam, flatten out.
Meanwhile, other studies
explored interesting
spin-offs of free
won'tness.
What's the neurobiology of
a gambler on a losing
streak who manages to
stop gambling versus one
who doesn't?
What happens to free
won't when there's
alcohol on board?
How about kids versus
adults?
It turns out that kids
need to activate more of
their frontal cortex than
do adults to get the same
effectiveness at inhibiting
an action.
So, what do all these
versions of vetoing a
behavior in a fraction of
a second say about free
will?
Depends on whom you talk
to, naturally.
Findings like these have
supported a two-stage
model about how we are
supposedly the captains of
our fate, one espoused by
the likes of everyone from
William James to many
contemporary compatibilists.
Stage 1.
The free part.
Your brain spontaneously
chooses, amid alternative
possibilities, to generate
the proclivity towards some
action.
Stage 2.
The will part is where you
consciously consider this
proclivity and either
greenlight it or free won't
it.
As one proponent writes,
freedom arises from the
creative and indeterministic
generation of alternative
possibilities, which present
themselves to the will for
evaluation and selection.
Or in Millie's words, even
if urges to press are
determined by unconscious
brain activity, it may be up
to the participants whether
they act on those urges or
not.
Thus, our brains generate a
suggestion, and we then
judge it.
This dualism sets our thinking
back centuries.
The alternative conclusion is
that free won't is just as
suspect as free will, and for
the same reasons.
Inhibiting a behavior doesn't
have fancier neurobiological
properties than activating a
behavior, and brain circuitry
even uses their components
interchangeably.
For example, sometimes brains do
something by activating neuron X,
sometimes by inhibiting the neuron
that is inhibiting neuron X.
Calling the former free will, and
calling the latter free won't, are
equally untenable.
This recalls Chapter 1's
challenge to find a neuron that
initiated some act without being
influenced by any other neuron or
by any prior biological event.
Now the challenge is to find a
neuron that was equally autonomous in
preventing an act.
Neither free will nor free won't
neurons exist.
Having now reviewed these debates,
what can we conclude?
For Libetians, these studies show
that our brains decide to carry out
a behavior before we think that we
freely and consciously done so.
But given the criticisms that have
been raised, I think all that can be
concluded is that in some fairly
artificial circumstances, certain
measures of brain function are
moderately predictive of a
subsequent behavior.
Free will, I believe, survives
Libetianism.
And yet, I think that is irrelevant.
Just in case you thought this was
all academic.
The debates over Libet and his
descendants can be boiled down to a
question of intent.
When we consciously decide that we
intend to do something, has the
nervous system already started to act
upon that intent?
And what does it mean if it has?
A related question is screamingly
important in one of the areas where
this free will hubbub is profoundly
consequential.
In the courtroom.
When someone acts in a criminal
manner, did they intend to?
By this, I'm not suggesting bewigged
judges arguing about some low life's
readiness potentials.
Instead, the questions that define
intent are whether a defendant could
foresee, without substantial doubt,
what was going to happen as a result
of their action or inaction, and
whether they were okay with that
outcome.
From that perspective, unless there was
intent in that sense, a person
shouldn't be convicted of a crime.
Naturally, this generates complex
questions.
For example, should intending to shoot
someone but missing count as a lesser
crime than shooting successfully?
Should driving with a blood alcohol
level in the range that impairs control
of a car count as less of a
transgression if you lucked out and
happen not to kill a pedestrian than
if you did?
An issue that Oxford philosopher Neil
Levy has explored with the concept of
moral luck.
As another wrinkle, the legal field
distinguishes between general and
specific intent.
The former is about intending to commit a
crime, whereas the latter is intending to
commit a crime, as well as intending a
specific consequence.
The charge of the latter is definitely
more serious than the former.
Another issue that can come up is
deciding whether someone acted
intentionally out of fear or anger, with
fear, especially when reasonable, seen as
more mitigating.
Trust me, if the jury consisted of
neuroscientists, they deliberate for
eternity trying to decide which emotion was
going on.
How about if someone intended to do
something criminal, but instead
unintentionally did something else
criminal?
An issue that we all recognize is how
long before a behavior the intent was
formed.
This is the world of premeditation, the
difference between, say, a crime of
passion with a few milliseconds of intent
versus an action long planned.
It is pretty unclear legally exactly how
long one needs to meditate upon an
intended act for it to count as
premeditated.
As an example of this lack of clarity, I
once was a teaching witness in a trial
where a pivotal issue was whether eight
seconds, as recorded by a CCTV camera, is
enough time for someone in a life-threatening
circumstance to premeditate a murder.
My two cents was that, under the
circumstances involved, eight seconds not
only wasn't enough time for a brain to
do premeditated thinking, it wasn't
enough time for it to do any thinking, and
free won'tness was an irrelevant concept.
The jury heartily disagreed.
Then there are questions that can be at
the core of war crime trials.
What kind of threat is needed for someone's
criminality to count as coerced?
What about agreeing to do something with
criminal intent, while knowing that if
you refused, someone else would do it
immediately and more brutally?
Taking things even further, what should
be done with someone who intentionally
chose to commit a crime, not knowing that
they would have been forced to commit that
act, if they had tried to do otherwise?
At this juncture, we appear to have two
wildly different realms of thinking about
agency and responsibility.
People arguing about the supplementary
motor area in neurophilosophy conferences, and
prosecutors and public defenders jousting in
courtrooms.
Yet they share something that potentially
strikes a blow against free will skepticism.
Suppose it turns out that our sense of
conscious decision-making doesn't actually
come after things like readiness
potentials.
That activity in the SMA, the prefrontal
cortex, the parietal cortex, wherever, is
never better than only moderately predicting
behavior, and only for the likes of pushing
buttons.
You sure can't say free will is dead based on
that.
Likewise, suppose a defendant says,
I did it.
I knew there were other things I could do,
but I intended to do it, planned it in
advance.
I not only knew that X could have been the
outcome, I wanted that to happen.
Good luck convincing someone that the
defendant lacked free will.
But the point of this chapter is that even
if either or both of these are the case, I
still think that free will doesn't exist.
To appreciate why, time for a Libet-style
thought experiment.
The Death of Free Will in the Shadow of
Intent
You have a friend doing research for her
doctorate in neurophilosophy, and she asks you
to be a test subject.
Sure.
She's upbeat because she's figured out how to
both get another data point for her study, and
simultaneously accomplish something else that
she's keen on.
Win-win.
It involves ambulatory EEG out of the lab, like
in the bungee jumping study.
You're out there now, wired up with the
leads, electromyography being done on your
hand, a clock in view.
As with the classic Libet, the motoric action
involved is to move your index finger.
Hey, aren't we decades past that sort of really
artificial scenario?
Fortunately, the study is more sophisticated
than that, thanks to your friend's careful
experimental design.
You'll be making a simple movement, but with a
non-simple consequence, don't plan ahead to make
this movement, you're told.
Do it spontaneously, and note on the clock what
time it is when you first consciously intend to.
All set?
Now, when you feel like it, pull the trigger and
kill this person.
Maybe the person is an enemy of the fatherland, a
terrorist blowing up bridges in one of the
gloriously occupied colonies.
Maybe it's the person behind the cash register in the
liquor store you're robbing.
Maybe they're a terminally ill loved one in
unspeakable pain, begging you to do this.
Maybe it's someone who is about to harm a child.
Maybe it is the infant Hitler, cooing in his crib.
You are free to choose not to shoot.
You're disillusioned with the regime's brutality
and refuse.
You think killing the clerk ups the ante too much
if you're caught.
Despite your loved one begging, you just can't do it.
Or maybe you're Humphrey Bogart, your friend is Claude
Rains.
You're confusing reality with storyline and figure that
if you let Major Strasser escape, the story doesn't end and
you'll get to star in a sequel to Casablanca.
But suppose you have to pull the trigger or else there'll be
no readiness potential to detect and your friend's research
will be slowed down.
Nonetheless, you still have options.
You can shoot the person.
You can shoot but intentionally miss.
You can shoot yourself rather than comply.
As a major plot twist, you can shoot your friend.
It makes intuitive sense that if you want to understand
what you wind up doing with your index finger
on that trigger, then you should explore
Libetian concerns, studying particular neurons
and particular milliseconds in order to understand
the instant you feel you have chosen to do something,
the instant your brain is committed to that action,
and whether those two things are the same.
But here's why these Libetian debates,
as well as a criminal justice system that cares only about
whether someone's actions are intentional,
are irrelevant to thinking about free will.
As first aired at the beginning of this chapter,
that is because neither asks a question central
to every page of this book.
Where did that intent come from in the first place?
If you don't ask that question,
you've restricted yourself to a domain of a few seconds,
which is fine by many people.
Frankfurt writes,
The questions of how the actions and his identifications
with their springs are caused
are irrelevant to the questions of whether he performs
the actions freely
or is morally responsible for performing them.
Or in the words of Shadlin and Roskies,
Libetian-ish neuroscience
can provide a basis for accountability and responsibility
that focuses on the agent
rather than on prior causes.
My emphasis.
Where does intent come from?
Yes, from biology interacting with environment
one second before your SMA warmed up,
but also from one minute before,
one hour,
one millennium,
this book's main song and dance.
Debating free will can't start and end
with readiness potentials
or with what someone was thinking
when they committed a crime.
Why have I spent page after page
going over the minutiae of the debates
about what Libet means
before blithely dismissing all of it with
and yet I think that is irrelevant.
Because Libet is viewed as
the most important study ever done
exploring the neurobiology
of whether we have free will.
Because virtually every scientific paper on free will
trots out Libet early on.
Because maybe you were born
at the precise moment
that Libet published his first study
and now,
all these years later,
you're old enough
that your music is called
classic rock
and you have started to make
little middle-aged grunting sounds
when you get up from a chair.
And they're
still debating Libet.
And as noted before,
this is like trying to understand a movie
solely by watching its final three minutes.
This charge of myopia
is not meant to sound pejorative.
Myopia is central to how we scientists
go about finding out new things.
By learning more and more
about less and less.
I once spent nine years
on a single experiment.
This can become the center
of a very small universe.
And I'm not accusing
the criminal justice system
of myopically focusing solely
on whether there was intent.
After all,
where intent came from
someone's history
and potential mitigating factors
are considered
when it comes to sentencing.
Where I am definitely
trying to sound pejorative
and worse
is when this
ahistorical view
of judging people's behavior
is moralistic.
Why would you ignore
what came before the present
in analyzing someone's behavior?
Because you don't care
why someone else
turned out to be different
from you.
As one of the few times
in this book
where I will knowingly
be personal,
this brings me to the thinking
of Daniel Dennett
of Tufts University.
Dennett is one of the best-known
and most influential
philosophers out there,
a leading compatibilist
who has made his case
both in technical work
within his field
and in witty,
engaging popular books.
He implicitly takes
this ahistorical stance
and justifies it
with a metaphor
that comes up frequently
in his writing
and debates.
For example,
in Elbow Room,
the varieties of free will
worth wanting,
he asks us
to imagine a foot race
where one person
starts off
way behind the rest
at the starting line.
Would this be unfair?
Yes,
if the race
is a hundred-yard dash.
But it is fair
if this is a marathon
because
in a marathon,
such a relatively small
initial advantage
would count for nothing
since one can reliably expect
other fortuitous breaks
to have even greater effects.
As a succinct summary
of this view,
he writes,
After all,
luck averages out
in the long run.
No,
it doesn't.
Suppose you're born
a crack baby.
In order to counterbalance
this bad luck,
does society rush in
to ensure
that you'll be raised
in relative affluence
and with various therapies
to overcome
your neurodevelopmental problems?
No.
You are overwhelmingly
likely to be born
into poverty
and stay there.
Well then,
says society,
at least let's make sure
your mother is loving,
is stable,
has lots of free time
to nurture you
with books
and museum visits.
Yeah, right.
As we know,
your mother
is likely to be drowning
in the pathological consequences
of her own
miserable luck in life
with a good chance
of leaving you
neglected,
abused,
shuttled through foster homes.
Well,
does society
at least mobilize then
to counterbalance
that additional bad luck,
ensuring that you live
in a safe neighborhood
with excellent schools?
Nope.
Your neighborhood
is likely to be
gang-riddled
and your school
underfunded.
You start out
a marathon
a few steps back
from the rest of the pack
in this world of ours.
And counter to what
Dennett says,
a quarter mile in,
because you're still
lagging conspicuously
at the back of the pack,
it's your ankles
that some rogue hyena nips.
At the five-mile mark,
the rehydration tent
is almost out of water
and you can get only
a few sips of the dregs.
By ten miles,
you've got stomach cramps
from the bad water.
By twenty miles,
your way is blocked
by the people
who assume the race is done
and are sweeping the street.
And all the while,
you watch the receding
backsides of the rest
of the runners,
each thinking that
they've earned,
they're entitled to,
a decent shot at winning.
Luck does not
average out over time.
And in the words of Levy,
we cannot undo
the effects of luck
with more luck.
Instead,
our world virtually guarantees
that bad and good luck
are each amplified further.
In the same paragraph,
Dennett writes that,
a good runner
who starts at the back
of the pack,
if he is really good enough
to deserve winning,
will probably have plenty
of opportunity
to overcome
the initial disadvantage.
My emphasis.
This is one step above
believing that God
invented poverty
to punish sinners.
Dennett has one more thing
to say that summarizes
this moral stance.
Switching sports metaphors
to baseball
and the possibility
that you think
there's something unfair
about how home runs work,
he writes,
if you don't like
the home run rule,
don't play baseball.
Play some other game.
Yeah,
I want another game,
says our now adult
crack baby
from a few paragraphs ago.
This time,
I want to be born
into a well-off,
educated family
of tech sector
overachievers
in Silicon Valley,
who,
once I decide that,
say,
ice skating seems fun,
will get me lessons
and cheer me on
from my first wobbly
efforts on the ice.
Fuck this life
I got dumped into.
I want to change games
to that one.
Thinking that it is sufficient
to merely know about
intent in the present
is far worse
than just
intellectual blindness.
Far worse
than believing
that it is the very first
turtle on the way down
that is floating in the air.
In a world such as we have,
it is deeply
ethically flawed as well.
Time to see
where intent
comes from
and how the biology
of luck
doesn't remotely
average out
in the long run.
3.
Where does intent
come from?
Because of our fondness
for all things
Libetian,
we sit you in front
of two buttons.
You must push
one of them.
You're given only
hazy information
about the consequences
of pushing each button
beyond being told
that if you pick
the wrong button,
thousands of people
will die.
Now,
pick.
No free will skeptic
insists that sometimes
you form your intent,
lean way over
to push the appropriate
button,
and suddenly,
the molecules
comprising your body
deterministically
fling you the other way
and make you
push the other button.
Instead,
the last chapter
showed how
the Libetian debate
concerns when
exactly you formed
that intent,
when you became
conscious of
having formed it,
whether neurons
commanding your muscles
had already activated
by then,
when it was that
you could still
veto that intention.
Plus,
questions about
your SMA,
frontal cortex,
amygdala,
basal ganglia,
what they knew
and when they knew it.
Meanwhile,
in parallel
in the courtroom
next door,
lawyers argue
over the nature
of your intent.
The last chapter
concluded by claiming
that all these
minutiae of milliseconds
are completely irrelevant
to why there is
no free will,
which is why
we didn't bother
sticking electrodes
into your brain
just before seeding you.
They wouldn't reveal
anything useful.
This is because
the Libetian wars
don't ask the most
fundamental question,
why did you form
the intent
that you did?
This chapter shows
how you don't
ultimately control
the intent you form.
You wish to do something,
intend to do it,
and then successfully
do so.
But no matter
how fervent,
even desperate you are,
you can't successfully
wish to wish
for a different intent.
And you can't
meta your way out.
You can't
successfully wish
for the tools,
say,
more self-discipline,
that will make you
better at successfully
wishing what you
wish for.
None of us can.
Which is why
it would tell us
nothing to stick
electrodes in your head
to monitor what
neurons are doing
in the milliseconds
when you form
your intent.
To understand
where your intent
came from,
all that needs
to be known
is what happened
to you in the
seconds to minutes
before you formed
the intention
to push whichever
button you choose.
As well as what
happened to you
in the hours
to days before,
and years
to decades before,
and during
your adolescence,
childhood,
and fetal life.
And what happened
when the sperm
and egg destined
to become you
merged,
forming your genome?
And what happened
to your ancestors
centuries ago
when they were
forming the culture
you were raised in,
and to your species
millions of years ago?
Yeah,
all that.
Understanding this
turtleism
shows how the intent
you form,
the person you are,
is the result
of all the interactions
between biology
and environment
that came before.
All things
out of your control.
Each prior influence
flows without a break
from the effects
of the influences
before.
As such,
there's no point
in the sequence
where you can insert
a freedom of will
that will be
in that biological world
but not of it.
Thus,
we'll now see
how who we are
is the outcome
of the prior seconds,
minutes,
decades,
geological periods
before,
over which we had
no control,
and how bad
and good luck
sure as hell
don't balance out
in the end.
Seconds to minutes
before.
We ask our first
version of the question
of where that intent
came from.
What sensory information
flowing into your brain,
including some
you're not even
conscious of,
in the preceding seconds
to minutes,
helped form that intent.
This can be obvious.
I formed the intent
to push that button
because I heard
the harsh demand
that I do so
and saw the gun
pointed in my face.
But things can be
subtler.
You view a picture
of someone holding
an object
for a fraction
of a second.
You must decide
whether it was
a cell phone
or a handgun,
and your decision
in that second
can be influenced
by the pictured
person's gender,
race,
age,
and facial expression.
We all know
real-life versions
of this experiment
resulting in police
mistakenly shooting
an unarmed person
and about the implicit
bias that contributed
to that mistake.
Some examples
of intent
being influenced
by seemingly
irrelevant stimuli
have been
particularly well-studied.
One domain
concerns how
sensory disgust
shapes behavior
and attitudes.
In one highly
cited study,
subjects rated
their opinions
about various
sociopolitical topics.
For example,
on a scale
of 1 to 10,
how much do you
agree with this statement?
And if subjects
were sitting in a room
with a disgusting smell
versus a neutral one,
the average level
of warmth
both conservatives
and liberals
reported for gay men
decreased.
Sure,
you'd think
you'd feel less warmth
for anyone
if you're gagging,
However,
the effect
was specific
to gay men
with no change
in warmth
toward lesbians,
the elderly,
or African Americans.
Another study
showed that
disgusting smells
make subjects
less accepting
of gay marriage
as well as about
other politicized
aspects of sexual behavior.
Moreover,
just thinking
about something
disgusting,
eating maggots,
makes conservatives
less willing
to come into contact
with gay men.
Then there's
a fun study
where subjects
were either
made uncomfortable
by placing
their hand
in ice water
or disgusted
by placing
their thinly
gloved hand
in imitation vomit.
Subjects then
recommended
punishment
for norm violations
that were
purity-related.
For example,
John rubbed
someone's toothbrush
on the floor
of a public restroom,
or the supremely
distinctive,
John pushed
someone into
a dumpster
which was
swarming
with cockroaches,
or violations
unrelated to purity.
For example,
John scratched
someone's car
with a key.
Being disgusted
by fake puke,
but not being
icily uncomfortable,
made subjects
more selectively
punitive about
purity violations.
How can
a disgusting smell
or tactile sensation
change unrelated
moral assessments?
The phenomenon
involves a brain region
called the insula,
a.k.a.
the insular cortex.
In mammals,
it is activated
by the smell
or taste
of rancid food,
automatically triggering
spitting out the food
and the species's
version of barfing.
Thus,
the insula
mediates olfactory
and gustatory disgust
and protects
from food poisoning,
an evolutionarily
useful thing.
But the versatile
human insula
also responds
to stimuli
we deem
morally disgusting.
The insula's
this-food's-gone-bad
function in mammals
is probably
a hundred million
years old.
Then,
a few tens
of thousands
of years ago,
humans invented
constructs like
morality
and disgust
at moral norm
violations.
That's way too
little time
to have evolved
a new brain region
to do
moral disgust.
Instead,
moral disgust
was added
to the insula's
portfolio.
As it said,
rather than inventing,
it was added
to the insula's portfolio.
Rather than inventing,
it was added
to the insula's portfolio.
As it said,
rather than inventing,
