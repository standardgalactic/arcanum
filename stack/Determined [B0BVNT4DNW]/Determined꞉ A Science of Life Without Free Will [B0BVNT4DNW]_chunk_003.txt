chaos theory, and should know better. On a philosophical level, it struck me that
chaoticism was an operational way to define free will in a way that allowed you to reconcile free
will with determinism. The system is deterministic, but you can't say what it's going to do next.
As a final example, philosopher David Steenberg explicitly links the supposed free will of chaos
with morality. Chaos theory provides for the reintegration of fact and value by opening
each to the other in new ways. And to underline this linkage, Steenberg's paper wasn't published
in some science or philosophy journal. It was in the Harvard Theological Review. So, a bunch of
thinkers find free will in the structure of chaoticism. Compatibilists and incompatibilists
debate whether free will is possible in a deterministic world. But now you can skip
the whole brouhaha, because, according to them, chaoticism shows that the world isn't deterministic.
As Eilenberger summarizes,
But since we now know that the slightest, immeasurably small differences in the initial
state can lead to completely different final states, that is, decisions, physics cannot
empirically prove the impossibility of free will. In this view, the indeterminism of chaos
means that, although it doesn't help you prove that there is free will, it lets you
prove that you can't prove that there isn't. But now to the critical mistake running through
all of this. Determinism and predictability are very different things. Even if chaoticism is
unpredictable, it is still deterministic. The difference can be framed a lot of ways.
One is that determinism allows you to explain why something happened, whereas predictability
allows you to say what happens next. Another way is the woolly-haired contrast between ontology
and epistemology. The former is about what is going on, an issue of determinism, while the
latter is about what is knowable, an issue of predictability. Another is the difference between
determined and determinable. Giving rise to the heavy-duty title of one heavy-duty paper,
Determinism is ontic. Determinability is epistemic.
By philosopher Harold Atmansbacher. Experts tear their hair out over how fans of
chaoticism equals free will fail to make these distinctions. There is a persistent confusion
about determinism and predictability. Write physicists Sergio Caprara and Angelo Volpiani.
The first nameless philosopher, GMK Hunt, of the University of Warwick, writes,
In a world where perfectly accurate measurement is impossible, classical physical determinism
does not entail epistemic determinism. The same thought comes from philosopher Mark Stone.
Chaotic systems, even though they are deterministic, are not predictable. They are not epistemically
deterministic. To say that chaotic systems are unpredictable is not to say that science cannot
explain them. Philosophers Vadim Batitsky and Zoltan Demeter, in their wonderfully titled paper,
When Good Theories Make Bad Predictions, describe chaotic systems as deterministically unpredictable.
Here's a way to think about this extremely important point. I just went back to that fantastic pattern in
the last chapter on page 138 and estimated that it is around 250 rows long and 400 columns wide.
This means that the figure consists of about 100,000 boxes, each now either open or filled.
Get a hefty piece of graph paper, copy the row 1 starting state from the figure, and then spend the next
year sleeplessly applying rule 22 to each successive row, filling in the 100,000 boxes with your number
2 pencil. And you will have generated the same exact pattern as in the figure. Take a deep breath and do it
a second time? Same outcome. Have a trained dolphin with an extraordinary capacity for repetition go at it?
Same result. Row 113 would not be what it is because at row 112, you or the dolphin just happen to choose
to let the open or filled split in the road depend on the spirit moving you, or on what you think Greta Thunberg
would do. That pattern was the outcome of a completely deterministic system consisting of the eight
instructions comprising rule 22. At none of the 100,000 junctures could a different outcome have resulted
unless a random mistake occurred, as we'll see in chapter 10. Constructing an edifice of free will on random
hiccups is quite iffy. Just as the search for an uncaused neuron will prove fruitless, likewise for an uncaused box.
Let's frame this in the context of human behavior. It's 1922 and you're presented with a hundred young adults
destined to live conventional lives. You're told that in about 40 years, one of the hundred is going to
diverge from that picture, becoming impulsive and socially inappropriate to a criminal extent.
Here are blood samples from each of those people. Check them out. And there's no way to predict which
person is above chance levels. It's 2022. Same cohort with, again, one person destined to go off
the rails 40 years hence. Again, here are their blood samples. This time, this century, you use them to
sequence everyone's genome. You discover that one individual has a mutation in a gene called MAPT, which
codes for something in the brain called the TAW protein. And as a result, you can accurately predict
that it will be that person, because by age 60, he will be showing the symptoms of behavioral variant
frontotemporal dementia. Back to the 1922 cohort, the person in question has started shoplifting,
threatening strangers, urinating in public. Why did he behave that way? Because he chose to do so.
Year 2022's cohort, same unacceptable acts. Why will he have behaved that way? Because of a
deterministic mutation in one gene. According to the logic of the thinkers just quoted,
the 1922 person's behavior resulted from free will. Not resulted from behavior we would erroneously
attribute to free will. It was free will. And in 2022, it is not free will. In this view,
free will is what we call the biology that we don't understand on a predictive level yet.
And when we do understand it, it stops being free will. Not that it stops being mistaken for free will.
It literally stops being. There is something wrong if an instance of free will exists only until there
is a decrease in our ignorance. As the crucial point, our intuitions about free will certainly
work that way. But free will itself can't. We do something, carry out a behavior, and we feel like
we've chosen that there is a me inside, separate from all those neurons. That agency and volition dwell
there. Our intuitions scream this, because we don't know about, can't imagine, the subterranean
forces of our biological history that brought it about. It is a huge challenge to overcome those
intuitions, when you still have to wait for science to be able to predict that behavior precisely.
But the temptation to equate chaoticism with free will shows just how much harder it is to overcome
those intuitions when science will never be able to predict precisely the outcomes of a deterministic
system. Wrong conclusion number two, a causeless fire. Most of the fascination with chaoticism comes from
the fact that you can start with some simple deterministic rules for a system and produce
something ornate and wildly unpredictable. We've now seen how mistaking this for indeterminism leads
to a tragic downward spiral into a cauldron of free will belief. Time now for the other problem.
With its demonstration with Rule 22, that two different starting states can turn into the identical
pattern. And thus, it is not possible to know which of those two was the actual source.
This is the phenomenon of convergence. It's a term frequently used in evolutionary biology.
In this instance, it's not so much that you can't tell which of two different possible
ancestors a particular species arose from. For example, was the ancestor of elephants three-legged
or five-legged? Who can tell? It's more when two very different sorts of species have converged
on the same solution to the same sort of selective challenge. Among analytical philosophers,
the phenomenon is termed over-determination, when two different pathways could each separately determine
the progression to the same outcome. Implicit in this convergence is a loss of information,
which possible pathway led to the present state. This issue of convergence has a surprising parallel
in legal history. Thanks to negligence, a fire starts in Building A. Nearby, completely unrelated,
separated, separate negligence gives rise to a fire in Building B. The two fires spread toward
each other and converge, burning down Building C, in the center. The owner of Building C sues the other
two owners. But which negligent person was responsible for the fire? Not me, each would argue in court.
If my fire hadn't happened, Building C would still have burned down. And it worked, in that neither
owner would be held responsible. This was the state of things until 1927, when the courts ruled in
Kingston v. Chicago and Northwestern Railroad that it is possible to be partially responsible for what
happened, for there to be fractions of guilt. Similarly, consider a group of soldiers lining up in a firing squad to
kill someone. No matter how much one is pulling a trigger in glorious obedience to God and country,
there's often some ambivalence, perhaps some guilt about mowing down someone, or worry that fortunes will
shift, and you'll wind up in front of a firing squad. And for centuries, this gave rise to a cognitive
manipulation. One soldier at random was given a blank, rather than a real bullet. No one knew who had it,
and thus, every shooter knew that they might have gotten the blank, and thus weren't actually,
a killer. When lethal injection machines were invented, some states stipulated that there'd be
two separate delivery routes, each with a syringe full of poison. Two people would press each of two
buttons, and a randomizer in the machine would infuse the poison from one syringe into the person and dump
the contents of the other into a bucket, and not keep a record of which did which. Each person thus
knew that they might not have been the executor. Those are nice psychological tricks for diffusing a
sense of responsibility. Chaoticism pulls from a related type of psychological trick.
The feature of chaoticism where knowing a starting state doesn't allow you to predict what will
happen is a crushing blow to classic reductionism. But the inability to ever know what happened in the
past demolishes what's called radical eliminative reductionism. The ability to rule out every conceivable
cause of something until you've gotten down to the cause. So you can't do radical eliminative reductionism
and decide what single thing caused the fire, which button presser delivered the poison, or what prior
state gave rise to a particular chaotic pattern. But that doesn't mean that the fire wasn't actually
caused by anything. That no one shot the bullet-riddled prisoner, or that the chaotic state just popped up
out of nowhere. Ruling out radical eliminative reductionism doesn't prove indeterminism.
Obviously. But this is subtly what some free will supporters conclude. If we can't tell what caused X, then you
can't rule out an indeterminism that makes room for free will. As one prominent compatibilist writes,
it is unlikely that reductionism will rule out the possibilities of free will, because the chain
of cause and effect contains breaks of the type that undermine radical reductionism and determinism,
at least in the form required to undermine freedom. God help me that I've gotten to the point of
examining the split hair of and, but chaotic convergence does not undermine radical reductionism
and determinism. Just the former. And in the view of that writer, this supposed undermining of
determinism is relevant to policies upon which we hinge responsibility. Just because you can't tell
which of two towers of turtles propping you up goes all the way down, doesn't mean that you're floating in the air.
Conclusion. Where have we gotten at this point? The crushing of knee-jerk reductionism,
the demonstration that chaoticism shows just the opposite of chaos, the fact that there's less
randomness than often assumed, and instead, unexpected structure and determinism. All of this is wonderful.
Ditto for butterfly wings, the generation of patterns on seashells, and will darling. But to get from
there to free will requires that you mistake a failure of reductionism that makes it impossible to
precisely describe the past or predict the future as proof of indeterminism. In the face of complicated
things, our intuitions beg us to fill up what we don't understand, even can never understand,
with mistaken attributions. On to our next related topic.
7. A Primer on Emergent Complexity
The previous two chapters can basically be distilled to the following.
Break it down to its component parts, reductionism, doesn't work for understanding some vastly interesting
things about us. Instead, in such chaotic systems, minuscule differences in starting states amplify
enormously in their consequences. This non-linearity makes for fundamental unpredictability,
suggesting to many that there is an essentialism that defies reductive determinism, meaning that the
there can't be free will because the world is deterministic stance goes down the drain.
Nope. Unpredictable is not the same thing as undetermined. Reductive determinism is not the
only kind of determinism. Chaotic systems are purely deterministic, shutting down that particular angle
of proclaiming the existence of free will. This chapter focuses on a related domain of amazingness
that seems to defy determinism. Let's start with some bricks. Granting ourselves some artistic license,
they can crawl around on tiny, invisible legs. Place one brick in a field. It crawls around aimlessly.
Two bricks. Ditto. A bunch, and some start bumping into each other. When that happens, they interact in
boringly simple ways. They can settle down next to each other and stay that way, or one can crawl up on
top of another. That's all. Now, scatter a hundred zillion of these identical bricks in this field, and they
slowly crawl around. Zillions sitting next to each other. Zillions crawling on top of others. And they
slowly construct the Palace of Versailles. The amazingness is not that, wow, something as complicated
as Versailles can be built out of simple bricks. It's that once you made a big enough pile of bricks,
all those witless little building blocks, operating with a few simple rules, without a human in sight,
assembled themselves into Versailles. This is not Chaos's sensitive dependence on initial conditions,
where these identical building blocks actually all differed when viewed at a high magnification,
and you then butter flew to Versailles. Instead, put enough of the same simple elements together,
and they spontaneously self-assemble into something flabbergastingly complex, ornate, adaptive,
functional, and cool. With enough quantity, extraordinary quality just... emerges. Often
even unpredictably. As it turns out, such emergent complexity occurs in realms very pertinent to our
interests. The vast difference between the pile of gormless, identical building blocks, and the Versailles
they turn themselves into seems to defy conventional cause and effect. Our sensible sides think, incorrectly,
of words like indeterministic. Our less rational sides think of words like magic. In either case,
the self part of self-assembly seems so agentive, so rife with, be the Palace of Bricks that you wish to be,
that dreams of free will beckon. An idea that this and the next chapter will try to dispel.
Why we're not talking about Michael Jackson moonwalking
Let's start with what wouldn't count as emergent complexity. Put a beefy guy in a faux military
uniform carrying a sousaphone in the middle of a field. His behavior is simple. He can walk forward,
to the left, or to the right, and does so randomly. Scatter a bunch of other instrumentalists there,
and the same thing happens. All randomly moving, collectively making no sense. But toss 300 of them
onto the field, and out of that emerges a giant Michael Jackson moonwalking past the 50-yard line
during the halftime performance. There are all these interchangeable, fungible marching band marchers,
with the same minuscule repertoire of movements. Why doesn't this count as emergence? Because there's
a master plan. Not inside the sousaphoneist, but in the visionary who fasted in the desert,
hallucinating pillars of salt moonwalking, then returned to the marching band with the good news.
This is not emergence. Here's real emergent complexity. Start with one ant. It wanders aimlessly on the field,
as do ten of them. A hundred interact with vague hints of patterns. But put thousands of them together,
and they form a society with job specialization. Construct bridges, or rafts out of their bodies,
that float for weeks, build flood-proof underground nests with passageways paved with leaves.
Leading to specialized chambers with their own microclimates. Some suited for farming fungi,
and others for brood rearing. A society that even alters its functions in response to changing
environmental demands. No blueprint, no blueprint maker. What makes for emergent complexity?
There is a huge number of ant-like elements, all identical, or coming in just a few different
types. The ant has a very small repertoire of things it can do. There are a few simple rules
based on chance interactions with immediate neighbors. For example, walk with this pebble in
your little ant mandibles until you bump into another ant holding a pebble. In which case, drop yours.
No ant knows more than these few rules, and each acts as an autonomous agent. Out of the hugely
complicated phenomena this can produce, emerge irreducible properties that exist only on the collective
level. For example, a single molecule of water cannot be wet. Wetness emerges only from the collectivity
of water molecules. And studying single water molecules can't predict much about wetness. And that
are self-contained at their level of complexity. That is, you can make accurate predictions about the
behavior of the collective level without knowing much about the component parts. As summarized by Nobel
laureate physicist Philip Anderson, more is different. These emergent properties are robust and resilient.
A waterfall, for example, maintains consistent emergent features over time, despite the fact
that no water molecule participates in waterfallness more than once. A detailed picture of the maturely
emergent system can be unpredictable, which should have echoes of the previous two chapters. Knowing
the starting state and reproduction rules, a la cellular automata, gives you the means to develop the
complexity, but not the means to describe it. Or, to use a word offered by a leading developmental
neurobiologist of the past century, Paul Weiss, the starting state can never contain an itinerary.
Part of this unpredictability is due to the fact that in emergent systems, the road you are traveling
on is being constructed at the same time and, in fact, your being on it is influencing the construction
process by constituting feedback on the road-making process. Moreover, the goal you are traveling toward may
not even exist yet. You are destined to interact with a target spot that may not exist yet, but, with any
luck, will be constructed in time. In addition, unlike last chapter's cellular automata, emergent systems are
also subject to randomness. Jargon, stochastic events, where the sequence of random events makes a difference.
Often, the emergent properties can be breathtakingly adaptive, and, despite that, there's no blueprint
or blueprint maker. Here's a simple version of the adaptiveness. Two bees leave their hive, each flying
randomly until finding a food source. They both do, with one source being better. Each returns to the hive,
neither bee knowing anything about both food sources. Nonetheless, all the bees fly straight to the better
site. Here's a more complex example. An ant forages for food, checking eight different places. Little ant
legs get tired, and, ideally, the ant visits each site only once, and in the shortest possible path of the
five thousand forty possible ones. That is, seven factorial. This is a version of the famed
traveling salesman problem, which has kept mathematicians busy for centuries, fruitlessly searching for a general
solution. One strategy for solving the problem is with brute force. Examine every possible route, compare them all,
and pick the best one. This takes a ton of work and computational power. By the time you're up to ten
places to visit, there are more than 360,000 possible ways to do it. More than 80 billion with 15 places to
visit. Impossible. But take the roughly ten thousand ants in a typical colony, set them loose on the eight
feeding site version, and they'll come up with something close to the optimal solution out of the
five thousand forty possibilities, in a fraction of the time it would take you to brute force it,
with no ant knowing anything more than the path that it took, plus two rules, which we'll get to.
This works so well that computer scientists can solve problems like this with virtual ants, making use of
what is now known as swarm intelligence. There is the same adaptiveness in the nervous system. Take a
microscopic worm that neurobiologists love. The wiring of its neurons shows close to traveling salesman
optimization, in terms of the cost of wiring them all up. Same in the nervous system of flies, and in
primate brains as well. Examine the primate cortex. Identify eleven different regions that wire up with
each other. And of several million possible ways of doing it, the developing brain finds the optimal
solution. As we'll see, in all these cases, this is accomplished with rules that are conceptually
similar to what the traveling salesman ants do. Other types of adaptiveness also abound. A neuron
wants to spread its array of thousands of dendritic branches as efficiently as possible for receiving
inputs from other neurons, even competing with neighboring cells. Your circulatory system wants
to spread its thousands of branching arteries as efficiently as possible in delivering blood to
every cell in the body. A tree wants to branch skyward most efficiently to maximize the sunlight its
leaves are exposed to. And as we'll see, all three solve the challenge with similar emergent rules.
How can this be? Time to look at examples of how emergence actually emerges, using simple rules
that work in similar ways in solving optimization challenges. For, among other things, ants, slime molds,
neurons, neurons, humans, and societies. This process will easily dispose of the first temptation.
To decide that emergence demonstrates indeterminacy. Same answer as in the last chapter.
Unpredictable is not the same thing as undetermined. Disposing of the second temptation is going to be
more challenging. Informative scouts followed by random encounters.
Many examples of emergence involve a motif that requires two simple phases.
In the first, scouts in a population explore an environment. When they find some resource,
they broadcast the news. The broadcast must include information about the quality of the resource,
such as better resources producing louder or longer signals. In the second phase, other individuals
wander randomly in their environment with a simple rule regarding their response to the broadcast.
Back to honeybees as an example. Two bee scouts check out the neighborhood for possible food sources.
They each find one, come back to the hive to report. They broadcast their news by way of the famed
bee-waggle dance, where the features of the dance communicate the direction and distance of the food.
Crucially, the better the food source a scout found, the longer it carries out one part of the dance.
This is how quality is being broadcast. As the second phase, other bees wander about randomly in the hive.
And if they bump into a dancing scout, they fly away to check out the food source the scout is broadcasting
about, and then return to dance the news as well. And because a better potential site equals longer
dancing, it's more likely that one of those random bees bumps into the great news bee than the good news
one, which increases the odds that soon there will be two great news dancers, then four, then eight,
until the entire colony converges on going to the optimal site. And the original good news scout
will have long since stopped dancing, bumped into a great news dancer, and been recruited to the optimal
solution. Note, there is no decision-making bee that gets information about both sites, compares the
two options, picks the better one, and leads everyone to it. Instead, longer dancing recruits bees that will
dance longer, and the comparison and optimal choice emerge implicitly. This is the essence of swarm intelligence.
Similarly, suppose the two scout bees discover two potential sites that are equally good, but one is half
as far from the hive as the other one. It will take the local news bee half the time to get to and back
from its food source, then it takes the distant news bee, meaning that the two, four, eight doubling
starts sooner, exponentially swamping the signal of distant news bee. Everyone soon heads to the closer
source. Ants find the optimal site for a new colony this way. Scouts go out, and each finds a possible
site. The better the site, the longer they stay there. Then, the random wanderers spread out with the rule
that if you bump into an ant standing at a possible site, maybe check the site out. Once again, better
quality translates into a stronger recruitment signal, which becomes self-reinforcing. Work by my
pioneering colleague, Deborah Gordon, shows an additional layer of adaptiveness. A system like
this has various parameters. How far do ants wander? How much longer do you stay at a good site versus a
mediocre one? And so on. She shows that these parameters vary in different ecosystems as a
function of how abundant food sources are, how patchily they are distributed, and how costly
foraging is. For example, foraging is more expensive, in terms of water loss, for desert ants than for
forest ants. The better a colony has evolved to get these parameters just right for its particular
environment, the more likely it is to survive and leave descendants. The two steps of scout
broadcasters, followed by recruitment of random wanderers, explains virtual ant traveling salesman
optimization. Place a bunch of ants at each of the virtual foraging sites. Each ant then picks a route
at random that involves visiting each site once, and leaves a pheromone trail in the process.
How does better quality translate into a stronger broadcast? The shorter the route, the thicker the
pheromone trail that is laid down by a scout. Pheromones evaporate, and thus, shorter, thicker pheromone
trails last longer. A second generation of ants shows up. They wander randomly, with the rule that if they
encounter a pheromone trail, they join it, adding their own pheromones. As a result, the thicker and
therefore longer lasting the trail, the more likely another ant is to join it and amplify its recruiting
message. And soon, the less efficient routes for connecting the sites evaporate away, leaving the
optimized solution. No need to gather data about the length of every possible route, and have a centralized
authority compare them and then direct everyone to the best solution. Instead, something that comes
close to the optimal solution emerges on its own. Something worth pointing out. As we'll see, these
rich-get-richer recruitment algorithms explain optimized behavior in us as well, along with other species.
But optimal is not meant in the value-laden sense of good. Just consider rich-get-richer scenarios where,
thanks to the recruitment signaling of economic inequality, it's literally the rich who get
richer. Next, we turn to how emergence helps slime molds solve problems. Slime molds are these slimy,
moldy, fungal, amoeboid, single-cell protists, just to make a bunch of taxonomic errors, that grow and
spread like a carpet over surfaces, looking for microorganisms to eat. In a slime mold, zillions of
single-cell amoebas have joined forces by merging into a giant, cooperative single-cell that oozes over
surfaces in search of food. Apparently an efficient food-hunting strategy. And as a hint of the
emergence pending, a single independent slime mold cell can no more ooze than a molecule of water can
be wet. What used to be the individual cells are connected by tubules that can stretch or contract,
depending on the direction of oozing. See figures 7.1 and 7.2 in your PDF file.
Out of these collectivities emerge problem-solving capabilities. Spritz a dollop of slime mold into
a little plastic well that leads to two corridors, one with an oat flake at the end, the other with
two oat flakes, beloved by slime molds. Rather than sending out scouts, the entire slime mold expands to
fill both corridors, reaching both food sources. And within a few hours, the slime mold retracts from
the one oat flake corridor and accumulates around the two oats, have two pathways of differing lengths
leading to the same food source. The slime mold initially fills both paths, but eventually takes
only the shortest route. Same with a maze with multiple routes and dead ends. As the tour de force of slime
mold intelligence, Atsushi Tero at Hokkaido University plopped a slime mold down into a strangely shaped
walled-off area with oat flakes at very specific locations. Initially, the mold expanded, forming
tubules connecting all the food sources to each other in multiple ways. Eventually, most tubules retracted,
leaving something close to the shortest total path length of tubules connecting food sources.
The traveling slime mold. Here's the thing that makes the audience shout for more. The wall outlines the
coastline around Tokyo. The slime was plopped onto where Tokyo would be, and the oat flakes corresponded to
the suburban train stations situated around Tokyo. And out of the slime mold emerged a pattern of tubule
linkages that was statistically similar to the actual train lines linking those stations. A slime mold
without a neuron to its name versus teams of urban planners. How do slime molds pull this off? A lot like
ants and bees. Take the two corridors leading to either one or two oat flakes. The slime mold initially
oozes into both corridors, and when food is found, tubules contract in the direction of the food,
pulling the rest of the slime mold toward it. Crucially, the better the food source, the greater the
contractile force generated on the tubules. Then the tubules a bit farther away dissipate the force
by contracting in the same orientation, increasing the force of contraction, spreading outward until
the whole slime mold has been pulled into the optimal pathway. No part of the slime mold compares the
two options and makes a decision. Instead, the slime mold extensions into the two corridors act as scouts,
with the better route broadcast in a way that causes rich-get-richer recruiting via mechanical forces.
Now, let's consider a growing neuron. It extends a projection that has branched into two scout arms,
growth cones, heading toward two neurons. Simplifying brain development to a single mechanism,
each target neuron is attracting the growth cone by secreting a gradient of attractant molecules. One target
is better, thus secreting more of the attractant, resulting in a growth cone reaching it first,
which causes a tubule inside that growing neuron's projection to bend in that direction, to be attracted
to that direction, which makes the parallel tubule adjacent to it more likely to do the same, which
increases the mechanical forces recruiting more and more of these tubules. The other scout arm is
retracted, and our growing neuron has connected up with the better target. Let's look at our ant-bee slime
mold motif as applied to the developing brain forming the cortex, the fanciest most recently evolved part of
the brain. The cortex is a six-layer thick blanket over the surface of the brain, and cut into a cross-section,
each layer consists of different types of neurons. The multi-layered architecture has lots to do with
cortical function. In the picture, think of that slab of cortex as being divided into six vertical columns,
best seen as the six dense clusters of neurons at the level of the arrow. The neurons within any of
these many columns send lots of vertical projections, that is, axons to each other, collectively working as a
unit. For example, in the visual cortex, one mini-column might decode the meaning of light
falling on one spot of the retina, with the mini-column next to it decoding light on an adjacent
spot. It's ants' redux in building a cortex. The first step in cortical development is when a layer
of cells at the bottom of each cross-section of cortex sends long, straight projections to the surface,
surface, serving as vertical scaffolding. These are our ant scouts, called radial glia. Ignore the letters
in the diagram on figure 7.5. There is initially an excess of them, and the ones that have blazed the less
optimal, less direct paths are eliminated, through a controlled type of cell death. As such, we have our first
generation of explorers, with the ones with the more optimal solution to cortex building,
persisting longer. You know what's coming next. Newly-born neurons wander randomly at the base
of the cortex, until they bump into a radial glia. They then migrate upward along the glial guide rail,
leaving behind chemo-attractant signals that recruit more newbies to join the soon-to-be mini-column.
Scouts, quality-dependent broadcasting, and rich-get-richer recruiting, from insects and
slime molds to your brain. All without a master plan, or constituent parts knowing anything beyond
their immediate neighborhood, or any component comparing options and choosing the best one.
With remarkable prescience about these ideas in 1874, the biologist Thomas Huxley wrote about the
mechanistic nature of organisms, such that they only simulate intelligence as a bee simulates a
mathematician. Time for another motif in emergent systems.
Fitting infinitely large things into infinitely small spaces
Consider the figure 7.6 in the PDF that accompanies this audiobook. The top row consists of a single
straight line. Remove its middle third, producing the two lines that constitute the second row.
The length of those two together is two-thirds the length of the original line. Remove the middle
third from each of those, producing four lines that, collectively, are four-ninths the total length of
the original line. Do this forever, and you generate something that seems impossible. An infinitely large number
of specks that have an infinitely short cumulative length. Let's do the same thing in two dimensions.
See figure 7.7 in the PDF that accompanies this audiobook. Take an equilateral triangle, number one.
Generate another equilateral triangle on each face, using the middle third as the base for the new triangle,
resulting in a six-pointed star, number 2. Do the same to each of those points, producing an 18-pointed star,
number 3. Then a 54-pointed star, number 4, over and over. Do this forever, and you'll generate a two-dimensional
version of the same impossibility. Namely, a shape whose increase in area from one iteration to the next
is infinitely small, while its perimeter is infinitely long. Now, three dimensions. Take a cube. Each of its
faces can be thought of as being a three-by-three grid of nine boxes. Take out the middlemost of those
nine boxes, leaving eight. Now, think of each of those remaining eight as a three-by-three grid, and take
out the middlemost box. Repeat that process forever on all six faces of the cube. And the impossibility
achieved when you reach infinity is a cube with infinitely small volume, but infinitely large surface
area. These are, respectively, called a canter set, a coke snowflake, and a menger sponge. These are
mainstays of fractal geometry, where you iterate the same operation over and over, eventually producing
something impossible in traditional geometry. Which helps explain something about your circulatory
system. Each cell in your body is at most only a few cells away from a capillary, and the circulatory
system accomplishes this by growing around 48,000 miles of capillaries in an adult. Yet that ridiculously
large number of miles takes up only about three percent of the volume of your body. From the
perspective of real bodies in the real world, this begins to approach the circulatory system being
everywhere, infinitely present, while taking up an infinitely small amount of space. See drawings of
capillary bed and neurons in figures 7.10 and 7.11. A neuron has a similar challenge in that it wants to
send out a tangle of dendritic branches that can accommodate inputs at 10,000 to 50,000 synapses,
all with a dendritic tree taking up as little space as possible and costing as little as possible to
construct. And, of course, there are trees forming real branches to generate the maximal amount of surface
area for foliage to absorb sunlight, while minimizing the costs of growing it all.
The similarities in underlying mechanisms would be obvious to Cantor, Koch, or Menger. Namely,
iterative bifurcation. Something grows a distance and splits in two. Those two branches grow some distance,
and each splits in two. Those four branches, over and over, going from the aorta down to 48,000 miles of
capillaries, from the first dendritic branch in a neuron to 200,000 dendritic spines, from a tree trunk
to something like 50,000 leafy branch tips. How are bifurcating structures like these, generated in
biological systems, on scales ranging from a single cell to a massive tree? Well, I'll tell you one way
it doesn't happen, which is to have specific instructions for each bifurcation. In order to
generate a bifurcating tree with 16 branch tips, you have to generate 15 separate branching events.
For 64 tips, 63 branchings. For 10,000 dendritic spines in a neuron, 9,999 branchings.
You can't have one gene dedicated to overseeing each of those branching events,
because you'll run out of genes. We only have about 20,000. Moreover, as pointed out by Hiesinger,
building a structure this way requires a blueprint as complicated as the structure itself.
Raising the turtle's question, how is the blueprint generated? And how is the blueprint that generated
that blueprint generated? And it's these sorts of problems writ large and larger for the circulatory
system and for actual trees. Instead, you need instructions that work the same way at every
scale of magnification. Scale-free instructions like this.
Step 1. Start with the tube of diameter Z. A tube because geometrically, a blood vessel branch,
a dendritic branch, and a tree branch can all be thought of that way.
Step 2. Extend that tube until it is, to pull a number out of a hat, four times longer than its
diameter. That is, four Z. Step 3. At that point, the tube bifurcates, splits in two. Repeat.
This produces two tubes, each with a diameter of one-half Z. And when those two tubes are four
times longer than that diameter, that is, two Z, they split in two, producing four branches,
each one-quarter Z diameter, which will split in two when each is one Z. See figure 7.12 in the PDF
that accompanies this audiobook. While a mature tree sure seems immensely complex,
the idealized coding for it can be compressed into three instructions, requiring only a handful
of genes to pull this off, rather than half your genome. You can even have the effects of those
genes interact with the environment. Say you're a fetus inside someone living at high altitude,
with low levels of oxygen in the air, and thus in your fetal circulation. This triggers an epigenetic
change, back to chapter 3, so that tubes in your circulation grow only 3.9 times the width,
instead of 4.0, before splitting. This will produce a bushier spread of capillaries. I'm not sure if that
would solve the high altitude problem. I'm making this up. So, you can do this with just a handful of
genes that can even interact with the environment. But let's turn this into the reality of real biological
tubes and what genes actually do. How can your genes code for something abstract, like
grow four times the diameter and then split, regardless of scale? Various models have been
proposed. Here's a totally beautiful one. Let's consider a fetal neuron that is about to generate
a bifurcating tree of dendrites. Although this could be any of the other bifurcating systems we've been
covered. We start with a stretch of the neuron's surface membrane that is destined to be where
the tree starts growing. Note that in this very artificial version, the membrane is made of two
layers, and in between the layers is some growth stuff, hatched, coded for by a gene. The growth stuff
triggers the area of the neuron to start constructing a trunk. See figure 7.13 and 7.14 in the pdf that
accompanies this audiobook. How much growth stuff was there at the beginning? 4z's worth, which will
make the trunk grow 4z in length before stopping. Why does it stop? Critically, the inner layer of the
growing front of the neuron grows a little faster than the outer layer, such that right around a
length of 4z, the inner layer touches the outer layer, splitting the pool of growth stuff in half.
No more growth stuff in the tip. Things stop at 4z. But crucially, there's now 2z's worth of growth
stuff pooled on each side of the tip of the trunk, which triggers the area underneath to start growing.
Because these two branches are narrower, the inner layers touch the outer layers after a length of
only 2z, which splits the growth stuff into 4 pools, each with 1z's worth. And so on.
The key to this diffusion-based geometry model is the speed of growth of the two layers differing.
Conceptually, the outer layer is about growing, the inner about stopping growing. Numerous other
models produce bifurcations just as emergently, with similar themes. Wonderfully, two genes coding
from molecules with growth and stopping growth properties, respectively, have been identified that
are central to bifurcation in the developing lung. And the intensely cool thing is that these very
different physiological systems – neurons, blood vessels, the pulmonary system, and lymph nodes – use
some of the same genes, coding for the same proteins in the construction process. A menagerie of proteins such
as VEGF, efrins, netrins, and semaphorins. These are not genes used for, say, generating the circulatory
system. These are genes for generating bifurcating systems, applicable to one single neuron, and to
vascular and pulmonary systems using billions of cells. Aficionados will recognize that these bifurcating
systems all form fractals, where the relative degree of complexity is constant, no matter at what scale
of magnification you are considering the system. With the recognition that, unlike the fractals of
mathematics, fractals in the body don't bifurcate forever. Physical reality asserts itself at some
point. We're now in very strange terrain, having to consider the molecules of the sort mentioned in
the previous paragraph, being coded for by fractal genes. Which means that there must be fractal
mutations, disrupting normal branching in everything from single neurons to entire organ systems.
There are some hints of these out there. These principles apply to non-biological complexity as
well. For example, by rivers emptying into the sea bifurcate into river deltas, and it even applies to
cultures. Let's consider one last emergent bifurcating tree, one that shows either the
deeply abstract ubiquity of the phenomenon, or how I'm running too far with a metaphor.
Look at the intensely bifurcated diagram in figure 7.18 in the PDF that accompanies this audiobook.
Don't worry about what the branch tips are. Just note the branching's all over the place.
What is this tree? The perimeter represents the present. Each ring represents 100 years back into
the past, reaching the year 0 AD at the center, with a trunk going back millennia from there.
And the branching pattern? The history of the emergence of Earth's religions. A mass of bifurcations,
trifurcations, dead-end side branches, and so on. A partial magnification.
What constitutes the diameter of each tube in this emergent history of religions?
Maybe measures of the intensity of religious belief, the number of adherents, their cultural
homogeneity, their collective wealth or power. The wider the diameter, the longer the tube is likely to
persist before destabilizing, but in a scale-free way. Would this be adaptive in the same sense as
analyzing, say, bifurcating blood vessels? I think that right around now I should recognize that I'm on
thin speculative ice and call it a day. What has this section provided us? The same themes as in the
prior section about pathfinding ants, slime molds, and neurons. Simple rules about how components of
a system interact locally, repeated a huge number of times with huge numbers of those components, and
out emerges optimized complexity. All without centralized authorities comparing the options and making freely
chosen decisions. Let's design a town. You're on the planning board for a new town, and after endless
meetings, you've collectively decided where it will be built, how big it will be. You've laid out a grid
of the streets, decided on locations for the schools, hospitals, and bowling alleys. Time now to figure out
where the stores will go. The stores committee first proposes that stores be randomly scattered
throughout town. Uh, that's not ideal. People want stores conveniently clustered. Right, says the committee,
and then proposes that all the stores be in a single cluster in the middle of town. Uh, not quite right
either. With this single cluster, there won't be convenient parking, and the stores in the center of this
mega mall will be so inaccessible that they'll go out of business. They'll die from some commercial
equivalent of insufficient oxygen. Next plan. Have six malls of the same size set equal distances
from each other. That's good, but someone notices that all dozen coffee shops are in the same mall.
These shops will drive each other out of business, while five malls will have no coffee shops.
Back to planning. Paying attention now not just to store-ness, but to the type of store. In each
mall, one pharmacy, one market, two coffee shops. Consider interactions between different types of
stores. Separate the candy shop and the dentist. The optometrist goes next to the bookstore. Get the
correct ratio of places for sinning. A gelato shop. A bar. To those for repenting. A fitness center.
A church. And whatever you do, don't put the store selling God Bless America sweatshirts next to the
store selling God Less America ones. Once that is implemented, there's one last step, which is building
major thoroughfares that connect the malls to each other. At last, the commercial districts in your
town are planned. After all, these urban planning meetings, filled with individuals with differing
expertise, careerism, personal agendas, cooperation taking a hit because one person resents another for
taking the last donut. Take a beaker full of neurons. They're newly born, so no axons or dendrites yet.
Just rounded up little cells destined for glory. Pour the contents into a petri dish filled with a
soup of nutrients that keep neurons happy. The cells are now randomly scattered everywhere. Go away for a
few days. Come back. Look at those neurons under a microscope. And what you will see is in figure 7.19
in the PDF that accompanies this audiobook. A bunch of neurons in a mall. I mean, clumped together. To the
far right is the start of another cluster of cell bodies with major thoroughfares of projections linking
the two, as well as to distant clusters outside the picture. No committee, no planning, no experts,
no choices freely taken. Just the same pattern is for the planned town, emerging from some simple rules.
Each neuron that has been thrown randomly into the soup secretes a chemoattractant signal. They're all
trying to get the others to migrate to them. Two neurons happen to be closer than average to each
other by chance, and they wind up being the first pair to be clumped together in their neighborhood.
This doubles the power of the attractant signal emanating from there, making it more likely that
they'll attract a third neuron, then a fourth. Thus, through a rich-get-richer scenario, this forms
a nidus, the starting point of a local cluster growing outward. Growing aggregates like these are
scattered throughout the neighborhood. Each clump of neurons reaches a certain size,
at which point the chemoattractant stops working. How would that work? Here's one mechanism. As a ball
of clumping neurons gets bigger, the ones in the center are getting less oxygen, triggering them to
start secreting a molecule that inactivates chemoattractant molecules. All along, neurons have
been secreting a second type of attractant signal in minuscule amounts. It's only when enough neurons
have migrated into an optimally sized cluster that there is collectively enough of the stuff to prompt
the neurons in the cluster to start forming dendrites, axons, and synapses with each other.
Once this local network is wired up, detectable by, say, a certain density of synapses,
a chemo-repellant is secreted, which now causes neurons to stop making connections to their
neighbors and to instead start sending long projections to other clusters, following a
chemoattractant gradient to get there, forming the thoroughfares between clusters. This is a motif of
how complex adaptive systems, like neuronal shopping malls, can emerge thanks to control over space and
time of attractant and repellent signals. This is the fundamental yin-yang polarity of chemistry and
biology. Magnets attracting or repelling each other, positively charged or negatively charged ions,
amino acids attracted to or repelled by water. Long strings of amino acids form proteins, each with a
distinctive shape, and therefore function, that represents the most stable formation for balancing the
various attraction and repulsion forces. As just shown, constructing neuronal shopping malls in the
developing brain entailed two different types of attractant signals and one repellent one. And things get
fancier. Have a variety of attractant and repellent signals that work individually or in combinations. Have
emergent rules for which part of a neuron a growing neuron forms a connection with. Have growth cones with
receptors that respond to only a subset of attractant or repellent signals. Have an attractant signal pulling
a growth cone toward it. However, when it gets close, the attractant starts working as a repellent. As a result,
the growth cone swoops past. It's how neurons make long-distance projections, doing fly-bys of one
signpost after another. Most neurobiologists spend their time figuring out minutiae, like, say, the
structure of a particular receptor for a particular attractant signal. And then there are those marching
superbly to their own drummer, like Robin Heesinger, quoted earlier, who studies how brains develop with
simple emergent informational rules like we've been looking at. Heesinger, whose review papers have
puckish section titles like The Simple Rules That Can, has shown things like the three simple rules needed for
neurons in the eye of a fly to wire up correctly. Simple rules about the duality of attraction and repulsion,
and no blueprints. Time now for one last style of emergent patterning.
Talk locally, but don't forget to also talk globally now and then.
Suppose you live in a thoroughly odd community. There is a total of 101 people in it,
each in their own house. The houses are arranged in a straight line, say, along a river. You live in the
first house of this 101 house long line. How often do you interact with each of your 100 neighbors?
See figure 7.20, A through F. There are all sorts of potential ways. Maybe you talk only to your next
door neighbor. Maybe, as a contrarian, you interact only with the neighbor the farthest from you,
figure B. Maybe the same amount with each person, figure C. Maybe randomly, figure D.
Maybe you interact the most with your immediate neighbor, x percent less with the neighbor after
that, and x percent of that less with the neighbor after that, decreasing at a constant rate, figure E.
Then there's a particularly interesting distribution where around 80 percent of your interactions occur
with the 20 closest neighbors and the remainder spread out across everyone else, with interactions
a little less likely with each step farther out. Figure F. This is the 80-20 rule. Approximately 80
percent of interactions occur among approximately 20 percent of the population. In the commercial world,
it's sardonically stated as 80 percent of complaints come from 20 percent of the customers.
80 percent of crime is caused by 20 percent of the criminals. 80 percent of the company's work is due to
the efforts of 20 percent of the employees. In the early days of the pandemic, a large majority of
COVID-19 infections were caused by the small subset of infected super-spreaders. The 80-20 descriptor
captures the spirit of what is known as a Pareto distribution, of a type mathematicians call
a power law. While it is formally defined by features of the curve, it's easiest to understand
in plain English. A power law distribution is when the substantial majority of interactions are very
local, with a steep drop-off after that, and as you go out further, interactions become rarer.
All sorts of weird things turn out to have power law distributions, as demonstrated by work pioneered
by network scientist Albert Laszlo Barabasi of Northeastern University. Of the 100 most common
Anglo-Saxon last names in the U.S., roughly 80 percent of people with those names possess the 20 most
common. 20 percent of people's texting relationships account for about 80 percent of the texting. 20
percent of websites account for 80 percent of searches. About 80 percent of earthquakes are of
the lowest 20 percent of magnitude. Of 54,000 violent attacks throughout eight different insurgent wars,
80 percent of the fatalities arose from 20 percent of the attacks. Another study analyzed the lives of
150,000 notable intellectuals over the last two millennia, determining how far each individual died from their
birthplace. 80 percent of the individuals fell within 20 percent of the maximal distance. 20 percent of words in a
language account for 80 percent of the usage. 80 percent of craters on the moon are in the smallest
20th percentile of size. Actors get a bacon number, where if you were in a movie with the prolific
Kevin Bacon, 1,600 people, your bacon number is 1. If you were in a movie with someone who was in a movie with him,
yours is 2. In a movie with someone who was in a movie with someone who was in a movie with bacon?
3. The most common bacon number, held by approximately 350,000 actors, and so on. And starting with that
modal number and increasing the bacon number from there, there is a power law distribution to the smaller
and smaller number of actors. I'd be hard-pressed to see something adaptive about power law distributions
in bacon numbers or the size of lunar craters. However, power law distributions in the biological
world display can be highly adaptive. For example, when there's lots of food in an ecosystem, various
species forage randomly. But when food is spare, roughly 80 percent of foraging forays, that is,
moving in one direction looking for food before trying a different direction, are within 20 percent of
the maximum distance ever searched. This turns out to optimize the energy spent searching relative to
the likelihood of finding food. Cells of the immune system show the same when searching for a rare
pathogen. Dolphins show an 80-20 distribution of within-family and between-family social interactions.
The 80-ness means that family groups remain stable even after an individual dies,
while the 20-ness allows for the flow of foraging information between families. Most proteins in
our bodies are specialists, interacting with only a handful of other types of proteins, forming small,
functional units. Meanwhile, a small percentage are generalists, interacting with scores of other
proteins. Generalists are switch points between protein networks. For example, if one source of energy is rare,
a generalist protein switches to using a different energy source.
Then there are adaptive power-law relationships in the brain. What counts as adaptive or useful in how
neuronal networks are wired? It depends on what kind of brain you want. Maybe one where every neuron
synapses onto the maximal possible number of other neurons while minimizing the miles of axons needed.
Maybe one that optimizes solving familiar, easy problems quickly, or being creative in solving rare,
difficult ones. Or maybe one that loses the minimal amount of function when the brain is damaged.
You can't optimize more than one of those attributes. For example, if your brain cares only about solving
familiar problems quickly, thanks to neurons being wired up in small, highly interconnected modules of
similar neurons, you're screwed the first time something unpredictable demands some creativity.
While you can't optimize more than one attribute, you can optimize how differing demands are balanced.
What trade-offs are made? To come up with a network that is ideal for the balance between predictability
and novelty in a particular environment. And this often turns out to have a power-law distribution
where, say, the vast majority of neurons in cortical mini-columns interact only with immediate
neighbors, with an increasingly rare subset wandering out increasingly longer distances.
Writ large, this explains brainness, a place where the vast majority of neurons form a tight,
local network, the brain, with a small percentage projecting all the way out to places like your toes.
Thus, on scales ranging from single neurons to far-flung networks, brains have evolved patterns
that balance local networks solving familiar problems with far-flung ones being creative, all the while
keeping down the costs of construction and the space needed. And, as usual, without a central planning committee.
Emergence Deluxe
We've now seen a number of motifs that come into play in emergent systems.
Rich-get-richer phenomena, where higher-quality solutions give off stronger recruiting signals.
Iterative bifurcation that inserts near infinity into finite places.
Spatio-temporal control of attraction and repulsion rules.
Mathematical optimizing of the balance between different wiring needs.
And there are many more.
Here are two last examples of emergence that incorporate a number of these motifs.
One is startling in its implications. One is so charming that I can't omit it.
Charm first.
See figure 7.21 in the PDF that accompanies this audiobook.
Consider a toe nail that is a perfect platonic rectangle X units in height,
after ignoring the curvature of a nail.
Diagram A. Savage the perfection with some scissors cutting off a triangle of toenail.
Diagram B. If the toenail universe did not involve emergent complexity,
the toenail would now regrow as in diagram C. Instead, you get diagram D, with the angle of the cut
returning to the original angle, with the end of the nail squared off as before.
How?
The top of a toe nail thickens from bearing the brunt of contacting the outside world.
That is, the inside of your sock, a boulder, that damn coffee table.
Why didn't we get rid of it?
All we do is pile up junk on it. And once it thickens, it stops growing.
After the cutting, only point A, at the original length, next diagram, retains the thickening.
And as point B's regrowth brings it to the same height as point A,
it now bears the brunt of the outside worlds and thickens.
Its further growth is probably also constrained by the thickness of point A adjacent to it.
The same process occurs when point C arrives. There's no comparative information involved.
Point C doesn't have to choose between emulating point B or emulating point D.
Instead, the optimal solution emerges from the nature of toenail regrowth.
What inspired me to include this example? A man named Bhupendra Madhawala,
then age 82, living in Mumbai, India, did that experiment with the toenail of his,
repeatedly photographed the regrowth process, and then emailed pictures to me from out of the blue.
Which made me immensely happy.
Now the awesome final example.
As a tautology, studying the functions of neurons in the brain tells you about the function of neurons in the brain.
But sometimes more detailed information can be found by growing neurons in petri dishes.
These are typically two-dimensional, monolayer cultures,
where a slurry of individual neurons is plated down randomly, then begin to connect with each other as a carpet.
However, some fancy techniques make it possible to grow three-dimensional cultures,
where the slurry of a few thousand neurons is suspended in a solution.
And these neurons, each floating on its own, find and connect up with each other, forming clumps of brain organoids.
And after months, these organoids, barely large enough to be visible without a microscope,
self-organize into brain structures.
A slurry of human cortical neurons starts making radiating scaffolding,
constructing a primitive cortex with the beginnings of separate layers,
even the beginnings of cerebrospinal fluid.
And these organoids eventually produce synchronized brain waves that mature similarly to the way they do in fetal and neonatal brains.
A random bunch of neurons, perfect strangers floating in a beaker,
spontaneously build themselves into the starts of our brains.
Self-organized Versailles is child's play in comparison.
What has this tour shown us?
A. From molecules to populations of organisms,
biological systems generate complexity and optimization that match what computer scientists,
mathematicians, and urban planners achieve.
And where roboticists explicitly borrow swarm intelligence strategies of insects.
B. These adaptive systems emerge from simple constituent parts, having simple local interactions.
All without
centralized authority, overt comparisons followed by decision making,
a blueprint, or a blueprint maker.
C. These systems have characteristics that exist only at the emergent level.
A single neuron cannot have traits related to circuitry,
and whose behavior can be predicted without having to resort to reductive knowledge about the component parts.
D. Not only does this explain emergent complexity in our brains,
but our nervous systems use some of the same tricks used by the likes of individual proteins,
ant colonies, and slime molds, all without magic.
Well, that's nice. Where does free will come into this?
8. Does your free will just emerge?
First, what all of us can agree on.
So, emergence is about reductive piles of bricks producing spectacular emergent states,
ones that can be thoroughly unpredictable, or that can be predicted based on properties that exist
only at the emergent level.
Reassuringly, no one thinks that free will lurks in the neuronal equivalent of individual bricks.
Well, almost no one. Wait for the next chapter.
This is nicely summarized by philosopher Christian List of Ludwig Maximilian University in Munich.
If we look at the world solely through the lens of fundamental physics,
or even that of neuroscience, we may not find agency, choice, and mental causation.
And people rejecting free will make the mistake of looking for free will at the wrong level,
namely, the physical or neurobiological one, a level at which it cannot be found.
Robert Cain states the same. We think we have to become
originators at the micro level to explain free will. And we realize, of course, that we cannot do that.
But we do not have to. It is the wrong place to look. We do not have to micromanage our individual neurons
one by one. So, these free will believers accept that an individual neuron cannot defy the physical
universe and have free will. But a bunch of them can. To quote List, free will and its prerequisites are
emergent, higher-level phenomena. Thus, a lot of people have linked emergence and free will.
I will not consider most of them because, to be frank, I can't understand what they're suggesting.
And, to be franker, I don't think the lack of comprehension is entirely my fault.
As for those who have more accessibly explored the idea that free will is emergent,
I think there are broadly three different ways in which they go wrong.
Problem 1. Chaotic Missteps Redux
We know the drill. Compatibilists and free will skeptic incompatibilists agree that the world is
deterministic, but disagree about whether free will can coexist with that. But if the world is
indeterministic, you've cut the legs out from under free will skeptics. The chaos chapter showed how
you get there by confusing the unpredictability of chaotic systems with indeterminism. You can see
how folks drive off a cliff with the same mistake about the unpredictability of many instances of
emergent complexity. A great example of this is found in the work of List, a philosophy heavyweight
who made a big splash with his 2019 book, Why Free Will is Real. As noted, List readily recognizes that
individual neurons work in a deterministic way, while holding out for higher level, emergent free will.
In this view, the world may be deterministic at some levels, and indeterministic at others.
List emphasizes unique evolution, a defining feature of deterministic systems,
where any given starting state can produce only one given outcome. Same starting state, run it over
and over, and not only should you get one mature outcome each time, but it better be the same one.
List then ostensibly proves the existence of emergent indeterminism with a model that appears in
various forms in a number of his publications. The top panel represents a reductive,
fine-grained scenario where, progressing from left to right, five similar starting states each produce
five distinct outcomes. We then turn to the bottom panel, which is a state that List says displays
emergent indeterminism. How does it get there? The bottom panel shows the same system at a higher level
of description, obtained by coarse-graining the state space, making use of the usual rounding convention.
And when you do that, those five differing starting states become the same, and that singular starting
state can produce five completely different paths, proving that it is indeterministic and unpredictable.
Eh, maybe not. Sure, a system that is deterministic at the micro level can be indeterministic at the
macro in this way, but only if you're allowed to decide that five different, though similar,
starting states are all actually the same, merging them into a single higher-order simulation.
This is the last chapter all over again. When you're Edward Lawrence, come back from lunch and
coarse-grain your computer program, decide that the morning's parameters can be rounded off with
the usual rounding convention, and you're bit in the rear by a butterfly. Two things that are similar
are not identical, and you can't decide that they are, simply because that represents the conventions of
thinking. Reflecting my biological roots, here's a demonstration of the same point. See figure 8.2.
Here are six different molecules, all with similar structures. Now let's coarse-grain them, decide that
they are similar enough that we can consider them to be the same, by the usual scale of rounding
convention, and therefore they can be used interchangeably when we inject one of them
into someone's body and see what happens. And if there isn't always the same exact effect? Yeah,
you've supposedly just demonstrated emergent indeterminism. But they're not all the same.
Consider the middle and bottom structures in the first column. Majorly similar. Just try remembering
their structural differences for a final exam. But if you coarse-grain them into being the same,
rather than just very similar, things are going to get really messy. Because the top molecule of the
two is a type of estrogen. And the bottom is testosterone. Ignore sensitive dependence on
initial conditions. Decide the two molecules are the same, by whatever you've deemed the usual
conventional rounding. And sometimes you get someone with a vagina, sometimes a penis, sometimes sort of
both. Supposedly proving emergent indeterminism. It's the last chapter redux. Unpredictable is not the
same thing as indeterministic. Disperse armies of ants at 10 feeding spots. And you can't
predict just how close, and by what route, they are going to get to THE solution to the traveling
salesman problem out of the 360,000-plus possibilities. Instead, you'll have to simulate
what happens to their cellular automaton step-by-step. Do it all again, same ants at the same starting
points, but with one of those 10 feeding spots in a slightly different location. And you might get a
different, but still remarkably close, approximation of the traveling salesman solution. Do it repeatedly,
each time with one of the feeding stations moved slightly, and you're likely to get an array of great
solutions. Small differences in starting states can generate very different outcomes.
So much for the idea that in emergent systems, the same starting state can give rise to multiple
outcomes. The next mistake is a broader one. The idea that emergence means the reductive bricks that you
start with can give rise to emergent states that can then do whatever the hell they want.
This has been stated in a variety of ways, where terms like brain, cause and effect,
or materialism stand in for the reductive level, while terms like mental states, a person, or I,
imply the big, emergent end product. According to philosopher Walter Glannon,
although the brain generates and sustains our mental states, it does not determine them,
and this leaves enough room for individuals to will themselves to be through their choices and
actions. Persons, he concludes, are constituted by, but not identical to, their brains.
Neuroscientist Michael Shadlin writes of emergent states having a special status as a
consequence of their emergence as entities orphaned from the chain of cause and effect that led to
their implementation in neural machinery. Emphasis mine. Adina Roskies relatedly writes,
Macro-level explanations are independent of the truth of determinism. These same arguments suffice to
explain why an agent still makes a choice in a deterministic world, and why he or she is responsible for it.
This raises an important dichotomy. Philosophers with this interest discuss weak emergence,
which is where no matter how cool, ornate, unexpected, and adaptive an emergent state is,
it is still constrained by what its reductive bricks can and can't do. This is contrasted with strong
emergence, where the emergent state that emerges from the micro can no longer be deduced from it.
Even in chaoticism's sense of a stepwise manner. The well-respected philosopher Marc Badeau of Reed College
considers the strong emergence that can do as it pleases, with happy-go-lucky free will,
to be close to theoretically impossible. Strong emergence claims heighten the traditional worry that
emergence entails illegitimately getting something from nothing, which is uncomfortably like magic.
The influential philosopher David Chalmers of New York University weighs in as well, considering that
the only thing that comes close to qualifying as a case of strong emergence is consciousness.
Likewise, with another major contributor to this field, Johns Hopkins physicist Sean Carroll,
who thinks that while consciousness is the only real reason to be interested in strong emergence,
it's sure not a case of it.
With a limited role, if any, for strong emergence, and thus for its being the root of free will,
we are left with weak emergence, which, in Badeau's words, is no universal solvent.
You can be out of your mind, but not out of your brain. No matter how emergently cool,
ant colonies are still made of ants that are constrained by whatever individual ants can or can't do,
and brains are still made of brain cells that function like brain cells.
Unless you resort to one last trick to pull free will from emergence.
Problem 3. Defying Gravity
The place where a final mistake creeps in is the idea that an emergent state can reach down
and change the fundamental nature of the bricks comprising it.
We all know that an alteration at the brick level can change the emergent end product.
If you're injected with many copies of a molecule that activates six of the 14 subtypes of serotonin
receptors, your macro level is likely to include perceiving vivid images that other people don't,
plus maybe even some religious transcendence. Dramatically drop the number of glucose molecules
in someone's bloodstream and their resulting macro level will have trouble remembering whether Grover
Cleveland was president before or after Benjamin Harrison. Even if consciousness qualifies as the
closest thing to true strong emergence, induce unconsciousness by infusing a molecule like
phenobarbital, and you'll have shown that it isn't remotely free from its building blocks.
Good. We all agree that altering the little can change the emergent big. And the reverse certainly
holds true. Sit here and press button A or B, and which motor neurons tell your arm muscles to shift
this way or that, will be manipulated by the emergent macro phenomenon called aesthetics. If you're asked which
painting you prefer, the one of a Renaissance woman with the half smile, or the one of Campbell's soup cans.
Or press the button indicating which of two people you deem more likely to be destined for hell. Or whether
1946's Call Me Mister or 1950's Call Me Madam is the more obscure musical. A 2005 study concerning social
conformity shows a particularly stark, fascinating version of the emergent level manipulating the reductive
business of individual neurons. Sit a subject down and show them three parallel lines, one clearly
shorter than the other two. Which is shorter? Obviously that one. But put them in a group where everyone
else, secretly working on the experiment, says the longest line is actually the shortest. Depending on the
context, a shocking percentage of people will eventually say, yeah, that long line is the shortest one.
This conformity comes in two types. In the first, go along to get along public conformity. You know which
line is shortest, but join in with everyone else to be agreeable. In this circumstance, there is
activation of the amygdala, reflecting the anxiety driving you to go along with what you know is the wrong
answer. The second type is private conformity, where you drink the kool-aid and truly believe that somehow,
weirdly, you got it all wrong with those lines and everyone else really was correct. And in this case,
there is also activation of the hippocampus, with its central role in learning and memory,
conformity trying to rewrite the history of what you saw. But even more interesting, there's activation of
the visual cortex. Hey, you neurons over there. The line you foolishly thought was longer at first
is actually shorter. Can't you just see the truth now? Think about this. When is a neuron in the visual
cortex supposed to activate? Just to wallow in minutiae that can be ignored. When a photon of light is
absorbed by rhodopsin in disc membranes within a retinal photoreceptive cell, causing the shape of the
protein to change, changing transmembrane ion currents, thus decreasing the release of the
neurotransmitter glutamate, which gets the next neuron in line involved, starting a sequence culminating in that
visual cortical neuron having an action potential. One big micro-level blowout of reductionism.
And what's happening instead during private conformity? That same Mr. Machine little neuron
in the visual cortex activates, because of the macro-level immersion state that we'd call
an urge toward fitting in, a state built out of the neurobiological manifestations of the likes of
cultural values, a desire to seem likable, adolescent acne having left scars of low self-esteem, and so on.
So, some emergent states have downward causality, which is to say that they can alter reductive
function and convince a neuron that long is short and war is peace. The mistake is the belief that once
an ant joins a thousand others in figuring out an optimal foraging path, downward causality causes it
to suddenly gain the ability to speak French. Or that when an amoeba joins a slime mold colony that is
solving a maze, it becomes a zoroastrian. And that a single neuron, normally being subject to gravity,
stops being so once it holds hands with all the other neurons producing some emergent phenomenon.
That the building blocks work differently once they're part of something emergent.
It's like believing that when you put lots of water molecules together,
the resulting wetness causes each molecule to switch from being made of two hydrogens and one oxygen
to two oxygens and one hydrogen.
But the whole point of emergence, the basis of its amazingness,
is that those idiotically simple little building blocks that only know a few rules about interacting with their
immediate neighbors remain precisely as idiotically simple when their building block collective
as outperforming urban planners with business cards.
Downward causation doesn't cause individual building blocks to acquire complicated skills.
Instead, it determines the context in which the blocks are doing their idiotically simple things.
individual neurons don't become causeless causes that defy gravity and help generate free will just
because they're interacting with lots of other neurons.
And the core belief among the style of emergent free willers is that emergent states can in fact
change how neurons work and that free will depends on it. It is the assumption that emergent systems have
base elements that behave in novel ways when they operate as part of the higher order system.
But no matter how unpredicted an emergent property in the brain might be,
neurons are not freed of their histories once they join the complexity.
This is another version of our earlier dichotomy. There's weak downward causality where something
emergent like conformity can make a neuron fire the same way as it would in response to photons of light.
The workings of this component part have not changed. And there's strong downward causality where it can.
The consensus among most philosophers and neurobiologists thinking about this is that strong downward causality,
should it exist, is irrelevant to this book's focus. In a critique of this approach to discovering free will,
psychologists Michael Mascolo of Merrimack College and Eva Calio of the University of Yavascula write,
while emergent systems are irreducible, they are not autonomous in the sense of having causal powers
that override those of their constituents. A point emphasized as well by Spanish philosopher Jesus
Zamora Bonilla in his essay, Why Emergent Levels Will Not Save Free Will. Or stated in biological terms by
Mascolo and Calio, while the capacities for experience and meaning are emergent properties of biophysical systems,
the capacity for behavioral regulation is not. The capacity for self-regulation is an already existing capacity
of living systems. There's still gravity.
At last, some conclusions. Thus, in my view, emergent complexity, while being immeasurably cool,
is nonetheless not where free will exists, for three reasons. A. Because of the lessons of chaoticism.
You can't just follow convention and say that two things are the same, when they are different,
and in a way that matters, regardless of how seemingly minuscule that difference.
Unpredictable doesn't mean undetermined. B. Even if a system is emergent, that doesn't mean it can
choose to do whatever it wants. It is still made up of, and constrained by, its constituent parts,
with all their mortal limits and foibles. C. Emergent systems can't make the bricks that built them
stop being brickish. These properties are all intrinsic to a deterministic world, whether chaotic,
emergent, predictable, or unpredictable. But what if the world isn't really deterministic after all?
On to the next two chapters.
9. A Primer on Quantum Indeterminacy
I really do not want to write this chapter, or the next one. I've been dreading it, in fact.
When friends ask me how the book writing is going, I grimace and say, well, okay, but I'm still
postponing doing the chapters on indeterminacy. Why the dread? To start, A. The chapter's subject
rests on profoundly bizarre and counterintuitive science. B. That I barely understand. And C.
That even the people who you'd think understand it admit that they don't, but with the profound
non-comprehension, compared with my piddly cluelessness. And D. The topic exerts a gravitational pull
upon crackpot ideas as surely as does a statue upon defecating pigeons. A pull that constitutes
a what-are-they-talking-about strange attractor. Nonetheless, here goes.
This chapter examines some foundational domains of the universe in which extremely tiny stuff
operates in ways that are not deterministic. Where unpredictability does not reflect the
limitations of humans tackling math, or the wait for an even more powerful magnifying glass,
but instead reflects ways in which the physical state of the universe does not determine it.
And the next chapter is about reining in the free-willers in this playground of indeterminacy.
Were I to chicken out and end this pair of chapters right here,
the conclusions would be that, yes, Laplacian determinism really does appear to fall apart,
down at the subatomic level. However, such eensy-weensy indeterminism is vastly unlikely to
influence anything about behavior. Even if it did, it's even more unlikely that it would produce
something resembling free-will. Scholarly attempts to find free-will in this realm frequently strain credulity.
Undetermined randomness. What exactly do we mean by randomness? Suppose we have a particle that moves
randomly. To qualify, it would show these properties. If at time 0 a particle is in spot x, the most likely
planned nunca waiting for it to be a move capacity, the most likely paralyze the world of a wave in the
dimension of the universe. Most likely play at the board or on the equation of a miejsce.
So state to prove that the anthology раза it were carve out a力ás.
Not only if we were, we'll also notice it as a tiny dark height.
