Hello everyone and welcome back to Active Inference Insights. I am your host, Darius
Parvizzi-Wayne, and today I am absolutely thrilled to be speaking with Professor Chris
Friff. Chris is a neuropsychologist and a pioneer in the application of brain imaging
to the study of mental processes. He has contributed more than 500 papers to peer-reviewed
scientific journals and is known especially for his work on agency, schizophrenia and
social cognition. Within this latter field, he has worked extensively with his wife,
Professor Uta Friff. Together, they have published seminal papers on theory of mind and social
signalling, and last year they published the book, What Makes Us Social? Again, it is no
overstatement to say that Chris possesses a legendary status in the spheres of psychology and neuroscience,
and so it is a real honour on my part to be chatting to him today. Chris, thank you so much for joining
me and welcome to the show. Well, thanks for those nice words. You're welcome. Are you in London
currently? It's a beautiful day. Yes. Albeit a bit frosty. Yeah. Excellent. So, as I mentioned in my
introduction, you root many or you ground many of our social capacities in mentalising, which requires
theory of mind. Now, some of our audience might not, our audience is diverse. You know, Active Inference
brings in people from maths, physics, all sorts. They might not have a psychology background, so they
might not be aware of what mentalising or theory of mind actually is. So, it might be worth just
setting the stage and giving a brief exposition of what those terms mean, if possible. Right. Yes,
theory of mind is a rather misleading phrase because it's not a theory of how the mind works,
and it's probably not even a theory. So, mentalising is a slightly better term, I think. But the idea is
that one way into this is to say we're trying to predict. It's useful to be able to predict what people
are going to do and to understand why they're doing it. And theory of mind originally said people do things
because of their hidden mental state such as beliefs and intentions. So, if somebody takes an umbrella
with them, this doesn't mean that it's raining. It means that they believe it is raining or is going
to rain. And the key to the experiments on people's ability to understand these hidden mental states is the
impact of false beliefs. Because if somebody, if you know it's not raining and this person goes out with
an umbrella, then you can say he has a false belief that it's going to rain, and his belief is different
from mine, and I have to take this into account when I predict what he is going to do. So, that's basically
what mentalising is about. It's the process of predicting what other people's mental states are.
And mental states meaning things like intentions, beliefs, and desires. And we think that this is
probably different from understanding people's emotions.
Yes, I can imagine a lot of people make that conflation. I guess a further thing to unpack there is
when people hear about sort of mentalising, they might think of autism and the associated
difficulties in mentalising that seem to be associated with autism. But over time, many autistic
people use heuristics or tricks or social cues to mentalise. Is there a difference? Because
behaviourally, they might manifest similarly, and permit kind of harmonious social interaction.
Is theory of mind or mentalising committed to saying that those who are mentalising actually have a
mental representation, a kind of recursive mental representation of what the other person is
thinking?
Well, that's what I think. I don't think everybody agrees with that. There is, I mean, more recently,
there is evidence that there are two, I mean, depends on how you decide to talk about it,
two levels of mentalising, which some people say the lower one is not really mentalising. But that is to
say sometimes called behaviour reading, that you can solve many, you can make many of these predictions
without needing to know about other people's mental states. And this is also, in some sense, automatic. So it
happens, you don't have to think about it, you just know this is the right way to behave next in this
interaction. And in relation to autism, there's some suggestion that it's this lower level part that
they find difficult. And that the heuristics, as you call them, are in fact something that we all use. So
there's this, there's this thing called folk psychology, which is supposed to be inferior, but I think is
actually very important, which is that we know, this is the idea that people do indeed behave because of their
beliefs and desires. And that's how we can predict, and their behaviour. And this is a cultural
phenomena. So in different cultures, you may have different ideas about how folk psychology works. And in
particular, there's some anthropological work on the people who come from the Pacific Rim, which includes
some mias in Mexico, and Fiji, and these various other places where they, there's a cultural attitude
that it's impossible to know what other people's mental states are. And that you shouldn't bother to
try. And in fact, children are brought up, not, you know, you shouldn't be doing this sort of thing,
you just look at their behaviour. And it even extends to sort of interesting, semi-legal situations
where in the West, we're very concerned that, you know, it's the intention that counts, not, it's more
important, the intention is more important than the outcome. Whereas in these other cultures, the outcome
is all that matters. And even if it's an accident, you'll be punished. Interesting.
So there's an interesting level of, I think, cultural effects on some of these mentalising
stories.
Yes, philosophically, I certainly have issues with that. But we won't, we won't go into that too much.
Yes, that's interesting, I guess, because it also maps onto our scientific institutions and our way of
actually viewing what's going on mentally. I can't help but notice that we are presupposing mental
representations, even when I asked that question. And I've been sort of delving into the world of
radical in activist cognition. And they would say, well, there are no representations, there are,
there is no content. All we have are these dynamic relationships between, or these dynamic
couplings between agent and arena. Does that, does theory of mind collapse? If we just permit that
these are, I guess they talk about sort of perceiving correlations in the environment,
that's something that they're very excited about. But actually, this isn't a, you know,
this isn't necessarily a representation or intentional stance. Does it, does it, is it compatible
with these sort of ramped up versions of an activist cognition?
Hello, everyone. And I do apologise for interrupting the flow of the conversation with Chris.
I wanted to add this a little bit, because I realised, upon watching the conversation that I had
with Chris, that at this juncture I did misspeak and misconstrue and overgeneralise the claims of
REC, at least explicated by Hato and Mayan. So I made it out as if they say that all cognition
is contentless. This is not actually what they say. They say that basic mind or basic cognition is
contentless, whereby basic cognition means all cognitive activities except those involving public language
and cultural symbol systems. So again, they do not say that all cognition is contentless,
because there are also these higher order forms of cognition, which might be content involving.
And again, those require public symbols, social practices of symbolic communication. So they're
therefore governed by semantic norms and these correctness conditions. So where the theory of
mind is that, that higher order form or lower order form, I guess, is for you to decide.
But you'll see later on, I speak about these kind of scaffolded developmental capacities,
which might involve content as if it wasn't part of the theory of Hato and Mayan, but it is.
And so I really wanted to clarify that before this goes, before this podcast goes live. Again,
just more broadly, I do want to take responsibility as your podcast host for saying things are accurate
and truthful and owning up when I make mistakes. This was one of those places I would have edited out,
but it really would have messed up the flow of the conversation. So I thought it was easier for me
to just come on here and clarify that I made a mistake and hopefully clear up any confusion.
Again, I don't mind too much if I mess up describing what I think, because they're my thoughts. But I know
that authors far more senior than me have put a lot of time, a lot of effort into their accounts. And so I'd be
doing a disservice to them, disservice to you, if I misconstrue or misspeak when describing their thoughts and
their writings. So when I do this again, because, you know, in the heat of the moment, in the moment, I will make
mistakes as I did here. And again, it's just because these are live conversations, I'm having to think on my feed.
But when I do it again, because unfortunately I'm fallible, please do tell me. I will always look out for it.
I'm happy that I spotted this one. But again, I feel a very strong responsibility to be as accurate as possible.
So that relies on you as well. So please do inform me when I make a mistake.
And I will not keep you any longer, because this is a cracking conversation with Chris, and I hope you enjoy the rest of it.
Yeah, I'm not very keen on these ramped up versions.
It's conceivable that this might be a useful way of looking at the sort of automatic mentalizing.
But I think the sort of cultural and folk psychology story very much depends on representations.
I mean, we almost, we're talking about them, as it, I mean, yeah.
I can't, there's a philosopher called Davidson, and I can't remember precisely what he said,
but it's all about applying, you know, rational arguments to what we believe are these mental states.
So you're saying, if he believes that the chocolate is in the cupboard, he will go and look in the cupboard.
It's the sort of philosophical approach to this.
Yeah, I mean...
And that has content, I think, yeah.
No, as you say, I mean, these are sort of an activist cognition on steroids.
There are, of course, people, and I don't think you would disagree with them,
that recognize that if there are representational schema, those are built off scaffolds that occur from social cognition,
developmental psychology, being with others.
And I don't think you would disagree with that.
And that is something that I want to touch upon in terms of self-modeling and self-perception.
But yeah, I'll backtrack.
I don't think they would say that cognition is non-intentional,
just that it's non-contentful or non-representational.
But there are obviously quite severe critiques of that.
And there probably are a representation as well, as they make clear in their works.
So now expanding that out to, away from didactic, or not didactic, dyadic interactions,
into broader social contexts, why, going beyond just the coupled duo,
why is theory of mind or mentalizing so important just for social institutions more broadly?
Well, I would claim that we don't think that necessarily.
Okay.
So we think that some people seem to equate social cognition with theory of mind.
Right.
And we do not.
Sure. Okay. Let's clarify that.
Yeah.
So we think there are all sorts of social cognitive processes that are not to do with representing mental states or whatever.
And many of those might be more relevant to larger group interactions.
And we talked about, I mean, what's, and the original paper that we read in 1999, I think,
which is sort of starting in social cognition, we had mentalizing on one side,
and we had mirror neurons on the other side, because they had only recently been confirmed.
And mirror neurons are all about how we can imitate others, and how we get, what's the word, contagion from others.
So, for example, emotions are contagious.
We tend to feel the emotions that other people are expressing.
We tend to do what other people do.
We imitate their actions.
And one very important aspect of human sociality is over-imitation.
Do you know about that?
Yes.
I've seen some of it in sort of linguistic innovation, where a language learner learning another's language will over-imitate.
And so they'll be sort of, they'll all speak in RP, for example, even though no one's spoken in RP since 1910.
Yes, but I'm, yes, I've not thought about it so much in that respect, but it's more to do with simple actions,
like shaking hands, and you have to do it in the right way.
And the early experiments where they had these puzzle boxes, which you have to solve by going through a series of manoeuvres,
and the trainer puts in a couple of manoeuvres that are not actually necessary to open the box.
But the children all imitate these as part of the, that's the over-imitation bit, so that they do them even though they're not necessary.
Ah, I see.
I see.
And the interesting thing is that chimpanzees don't.
Very interesting.
And the idea is that this is, we're imitating not to get to the reward, we're imitating to show that we are doing it properly.
We are part of the group.
We are the people who behave like this, and they're all.
Yes.
Yeah, so it's kind of, in a sense, direct to the, in active inference terms, kind of a higher, a higher order prior.
Yes.
Yes.
That's very interesting.
Yeah, I mean, I guess to return to my initial question, yes, I recognize it might be an overextension of theory of mind.
I didn't mean it in terms of everything is theory of mind.
That's clearly not the case, because then it would be sort of serious cognitive overload if I was just mentalizing everyone and everything.
And it sounds borderline schizophrenic to be thinking that, you know, my chair has intentions.
But it seems to me that even in making or acting to confirm that higher order prior, that I am like you, and so you're going to like me, and we're going to be able to establish this recursive relationship.
I need to have, at the very fundament of that, a notion that you are an intentional, conscious agent, which kind of seems to me to be a very low-level form of theory of mind.
It might be implicit in our interactions, but that still seems to be present.
Yes, that's a very interesting idea.
One of the things that we've written about is sort of addressing this question, how do we know when we're wanting to, in competitive situations, and which usually means you're playing an economic game, like hide and seek.
Yeah.
You need to know what sort of agent you're competing against.
Sure.
And if it's a very, you know, it could be a completely random agent that just is biased, so it's very easy to beat one of those.
Or it could be a simple learning agent that depends on what's, you know, the pattern of reward in the past.
And it's fairly easy to beat one of those.
And the most difficult ones to beat are the ones that are intentional and are trying to predict what you're going to do, as well as at the same time as you're trying to predict what they're going to do.
Like rock, paper, scissors or something like that.
Yes.
And then that's where you get into this infinite recursion where you say, does he have a representation of what I think he's going to do now?
Yeah, yeah, yeah, yeah, yeah, yeah.
And what is interesting, at least the bits of information I have, it's very difficult to work out that you're competing against an intentional agent from their behavior.
And therefore, we tend to depend on our prior.
If we think it's a intentional agent, we'll behave in such and such a way.
If we think it's not, we won't.
And there's this nice experiment from John Donizot's group in Paris, where he has people, he has artificial agents that can do recursive tom.
Yeah.
And he has people playing against them, you know, at various levels.
You can have zero tom, one tom, two tom, and so on, in terms of recursion.
And if you tell them they're playing against a one-armed bandit, they assume that it's not intentional, and they lose when the agent is functioning at two levels of recursion, even though they have several hundred trials.
If they think it's a person, they all adopt the high-level strategy.
And, of course, this is reasonable, because this high-level mentalizing is extremely cognitively demanding.
Yes.
So you're going to avoid going to that level if you can.
Yes.
And there's this nice stuff.
And do you know about the beauty contest game, which is a nice example of this?
I don't.
Ah, this is invented by John Maynard Keynes.
Anyway, the task is, you're part of a group, everybody has to produce a number between one and a hundred, and the person who produces half the mean production will win.
Okay.
And Keynes call it a beauty contest game, because when you have to say who is the most beautiful person, it's not who is the most beautiful person, but who people think is the most beautiful person.
Anyway, the argument is, you know, if you think about what are the other, you have to think about what are the other people going to do, and you think if they're completely stupid, then it'll be a 50, would be the average number, and therefore you'll win with 25.
If they're not completely stupid, they think it's going to be 25, therefore you'll win with 12 and a half.
If you've read about Nash Equilibrium, you think everybody's super rational, and you'll say one, so you always lose.
And the average, I mean, there have been huge experiments on this in newspapers where they get thousands of people to take part, and the average level of recursion is two and a half.
Interesting.
Yes, there has to be a cutoff.
There has to be a cutoff.
This is what they call, I think Carl would call it bounded rationality or something.
Yes.
Yeah.
Yeah, well, yes, I guess it's also, I guess in some sense, to do with the depth of your temporal hierarchy.
Yeah.
Because each recursive step seems to me at least to be kind of an end plus one in your kind of information space.
And so you're just going to the next one, and there has to be an end at some point.
We can't plan forever.
That's fascinating.
Okay, that's fascinating.
Yeah, no, that's...
The other game I'm interested in is the stag hunt game.
Do you know that game?
Yeah, I know the fact.
Yeah, yeah, yeah.
And that, again, seems to be recursive, because if I'm going to hunt stags, I have to believe that you're going to hunt stags,
and I have to believe that you think that I'm going to hunt stags.
And it seems to me the heuristic there that solves all this to say, we are cooperative people.
And I don't have to worry about this.
Yeah, a couple of things come to mind there.
I mean, Dennett, as I'm sure you know, has this notion of an intentional stance.
Yeah.
Do you think that maps ontologically onto our sort of priors in some sense that we start off with the notion that things are intentional, animate, conscious, however you want to term it,
and then we start pruning?
Or is it the other way around?
I think it's the other way around.
We want to start with the idea that it's all very easy.
Yes.
Yeah.
Yes.
But we do have, I mean, I think we have a prior that people are intentional.
And would that be, and would we get that evidence from the phenotype of people, so to speak?
So if you have a similar body to me, you move in a similar way to me, you speak in a similar way to me, that is evidence to confirm that prior.
But I guess it has to be an evolutionary prior at quite a non-conceptual level because evolution doesn't work like that.
It's not going to say if you've got, if you're six foot, you're an agent, right?
It needs to be a little bit more subtle than that.
Yeah.
But certainly there's this somewhat discouraging work on in-groups and out-groups, where out-groups are considered to be less intentional.
Gosh.
Yeah.
So that's quite terrifying.
Yeah.
Yeah.
But that said, I mean, we do have, it makes me think of the fusiform facial area and the fact that that certainly constitutes some kind of perceptual prior, at least.
Excellent.
That's very good.
I mean, I was listening to an interview that you and Uta did with, I think it was the Dissenter.
It would have been about a month ago.
And I think, I just was listening to the beginning and Uta, I think it was Uta mentioned that we could consider cognition all, like entirely social cognition.
So all cognition is social cognition.
It makes me think, my master's thesis was exploring what's called social baseline theory.
And I wonder what you thought about it.
I'm not sure you're aware of social baseline theory.
No, I'm not.
So this is a kind of, the experimental work for it started in 2006, 2007, and then the theory was fleshed out sort of early last decade.
So this is people like James Cohen, I think it's Cohen, it might be Cohen, Elizabeth Gross.
These are people that the audience can search up.
But the notion is, is that the primary ecological niche we find ourselves in is social.
Yes.
And so what that means is that the human brain, for adaptive reasons, expects social resources.
Because it, and in doing so, it, that acts to mitigate risk and also preserve energy expenditure.
Yes.
So what they then say in white school social baseline theory is that being with others constitutes a cognitive baseline.
So that when we actually put people in an fMRI scanner and we get them to do a task alone, which is the standard in cognitive psychology, we're actually viewing them as a deficit.
Because they have to engage in all of this self-regulatory processes that they don't, they would be doing to a lesser degree if they were trusted others.
How does that sound to you as a theory?
Oh, I, I, I, I, I, I love that.
I'm very sad that I didn't know about it.
It's really, it's, it's, it's, there's this really, really beautiful experimental studies.
I think the most famous one is that people will perceive a hill to be less steep if they're with someone else.
Oh, yeah.
Because they, I think the perception in some ways, I guess it feeds into a broader question about to what degree is perception influenced by top-down factors?
Is it modular?
I mean, I come from active inference, I'm saying, no, like it's definitely influenced, but I think notion is that perceptual, yeah, a percept is influenced by your notion of how much effort is going to be in some sense, the affordance, how much effort is going to be to exploit that affordance.
So being with others reduces that effort.
No, I think that I would entirely agree with that.
And there's other experiments that we did talk about in the book, which I didn't know how they relate to this.
And I'm not sure whether the baseline people know about this is about affordance.
This is this business, if you have a table with mugs on it, you can show that you will get, when the mug appears, as it were, if it's within your reach, you will get activity in motor cortex.
And there's a social version of this.
If there's a second person sitting at the table, even a mug that's out of your reach, but in his reach, you will activate the motor system so that you're treating, this is sort of group affordance.
It's within, I call it the we mode, it's within our reach.
And that seems to happen automatically.
So that's entirely consistent with this.
That is wonderful.
I guess in some sense, from an active influence perspective, it's worth predicting others' actions as if they were our own, because their actions are so influential on personal outcomes.
But I was thinking more, it's like the monkey in the rake.
We can use this person as a tool to get what we...
Ah, yes.
Ah, okay.
So mine was a bit more generous, I guess.
It was a little bit more altruistic.
Ah, okay.
Okay.
Cool.
Yeah, that's an interesting stance on it.
I guess...
I mean, the answer, you know, a test of that would be if the other person sitting at the table is your enemy, would you then not get the affordance from the things that they...
Has someone done that experiment?
I don't think so.
It would be worthwhile.
An interesting thought experiment that I think you've used and Carl has used is, let's say we're on some exoplanet and it's just me.
Yeah, yeah.
Um, I don't...
I want to leave the questions about agency and sense of self for a bit, because I do want to get there.
That's kind of more my speciality, the work that I focus on is more to do with self-modelling.
But we say, okay, all cognition is social cognition.
It's built into us.
It's our baseline.
We have social priors.
Therefore, what happens when we start denying evidence for those priors if I'm in a planet which was just N of one?
And I guess, are there differences there for if that was always the case versus I've just been plumped there and I've...
Now I have a memory, in some sense, of being a social creature, which is now being denied to me.
I think, yes, there would be a huge difference.
Um, I would say, if you've just dropped there, I mean, it's a bit like being put into, um, solitary confinement.
I'm sure you will start thinking about the past or making up stories or about social interactions and so on.
And I was thinking also your nice point about being in an MRI scanner all by yourself.
I suspect what most people do when they're in an MRI scanner all by myself are thinking about what on earth is the experiment
of doing this for?
Sure.
I think that when I get x-rays, actually, I'm like, why are they doing this with the blocks of lead and stuff?
Yes.
If you've never had social interactions, I would, I would think you would be, well, in the extreme...
I had a strange interaction long ago with Christophe Koch talking about...
I was trying to talk about, you know, what's the function of consciousness?
And I was putting the argument, it's all social.
So my argument would be, if you were never had interactions with other people, you would
not be conscious.
I think Karl has a similar stance.
Yes.
And what was Christophe's response to that?
You know, consciousness is in these special neurons.
Yeah.
I don't think that one's got very far.
Sorry, Christophe.
You're far more senior than me, but I don't think that one's got very far.
And he lost that bet to David Chalmers.
I think he had to give him that case of wine.
Yeah.
So I think he lost.
Well, that's a really interesting point.
Let's go there then, because as I said, this is really where I want to go, is this self-modelling.
Yeah.
And I'm thinking, and again, this is something that I've spoken to Karl about, and I've heard
Karl mention, which is that we need, in some sense, to be able to infer the agency of others
or their self-model to be able to apply to ourselves a self-model.
There's a wonderful paper.
I like shouting out papers here so that people can go read, and also just to give credit
where it's due, by Jakob Howey.
And I think his last name is Michael.
I'm not sure what his first name is.
And it's called, Why Does Anybody Have a Self?
It's any body.
There are two words.
And they talk about sort of cultural imitation as really being foundational to the development
of a sense of agency, in the sense that I'm going to shape my self-model on what I
see as kind of optimal, agentic behavior on the part of others.
So I guess the question here is, how necessary is this capacity for inference of the agentic
state of another or the mental states of another for our own formation of agency and selfhood?
I certainly think that selfhood depends on interacting with others, though I think you
would get quite a long way without doing mentalizing.
It could be based on behavior to a certain extent.
But one of the things that we talk about quite a lot in our book is reputation, which is very
important economically.
I mean, the economist, I mean, Adam Smith, who invented economics, talked about, he didn't
call it reputation, he called, I can't quite remember, the esteem with which other people
hold you in, was more important than wealth.
And what the main driving factor in human behavior is to get the esteem of others, to have a good
reputation, in other words.
Though sometimes money can be a sort of proxy for this.
And there are all sorts of interesting experiments on this, because if you have a good reputation,
then people will trust you, they will choose to work with you, and they will invest money
in you, and all that sort of thing.
And then you have a very interesting arms race with the free riders, because you want to have
a good reputation, but you want to cheat people at the same time.
And then you have to, that's why being anonymous is jolly useful for this sort of competitive
situation, because no one, you don't have a reputation that carries with you.
And it seems to me the reputation is an important aspect of the self.
And of course, the reputation is not in you, it's in the minds of others.
Yes, exactly.
But in some sense, it then gets transferred onto you.
I mean, I think it's quite a classic literary trope in some sense.
I've mentioned Luigi Pirandello before, I don't know why, but he's come up again here.
He's got a very peculiar book called Uno Nes Uno Cento Mila.
One, no one, a hundred thousand.
Notion is, is that these are different ways of modeling oneself.
And what he goes around doing in this book as protagonist is he, he goes around trying
to spot himself in mirrors so that he can perceive himself, um, not, so he's trying to
catch himself looking at himself, not as others would perceive him, but sort of in this raw
moment of self perception and he eventually dissolves or goes a bit mental.
Yeah.
It's that's one thing that came up into mind.
This is a far more folk or popular culture thing.
There's a very interesting show on BB on the BBC right now, um, called the traitors,
uh, which I highly recommend, which is, it's about sort of 20 people in a castle and three
of them are traitors and 17 of them are so-called faithfuls.
And they have to kind of guess who's who.
And if the traitors stay in, they win all the money.
If the faithful stay in, they win all the money.
So there's some trash reality element to it.
But it's a very interesting psychological recursive thing where there's lots of triple quadruple
bluffings going on.
Um, so that's really that in, in action and reputation.
Yes.
Plays a very big role in, in trustworthiness.
Uh, and you're watching that as the objective sort of God-like figure and saying, well, how
could you not see that this person is so malign?
Um, but you're not there in some sense.
Okay.
That's, that's interesting.
I guess a further question I had, and this is actually something I would love to explore
personally.
Um, cause I don't think anyone has done that much work on this.
Um, so I've, I put this down as a sort of thing that I might want to explore in a PhD,
which is that we seemingly have homogeneity in self-modeling.
Um, so there are certain things that just come out of the literature here.
I'm thinking about people like Danza Harvey and Sean Gallagher and, um, Jacob, that it's
in some way, narrational, in some ways it's, uh, epistemic, it's somewhat coherent.
Um, again, this goes all the way back to like people like Derek Parfit.
Um, but it's, and, and that is homogenous across us.
I was wondering, do you think that that is a quite a thought that I had is that that's
rooted in the fact that we all engage in similar processes to arrive at that self-modeling,
to arrive at that self-conception, namely inference about others.
Does that seem reasonable?
Yes, I'm not sure.
I mean, I would have thought that there's a, I mean, I'm not sure.
Are you saying that because of our inherent individual cognitive processes being similar
to others, we arrive at the same end result?
In some sense, but it's a little bit more specific in the sense that, uh, let's say I'm
a, I'm a child and, uh, I watch my parents enact presumably agentic behavior.
Yeah.
My model of agentic behavior therefore starts to align with theirs.
Yeah.
And what I do is I, in, according to active inference, I act in order to provide evidence
for that prior.
And so you see this kind of, um, convergence over time on a self-model of course, there's
going to be variety, but these core features are present.
I would think that that certainly has a role, but I think there's also a role of a sort of
top-down cultural effects.
So you're told this is what agents, how agents behave.
Right.
As I was saying, you're told, I mean, even the very simple level, you're told that people,
you know, when people are, if people are eating a lot, it means they're hungry.
I mean, even at this simple level, our behavior is determined by our desires.
It's something that to some extent is top-down imposed, but I was thinking, you were mentioning
all these various people.
There's an interesting, Galen Strawson objects to this narrative story.
Yes, he does.
And I'm inclined to, I mean, I think there are different individual differences in this.
I have no idea.
I don't have a plan.
I never had a plan for my life as it were.
Me neither.
Yeah.
And I might be a quite different person next week.
Yeah.
So, yeah, Galen's critique is very apt here.
And here, I guess he's kind of actually criticizing Dennett, because Dennett is quite keen on talking
about the linguistic form of this narrational sense of self.
Jakob Howie's got a similar point there, which is that maybe we can replace the word
narrational with, it's not as catchy, but something like a predictive coherence or hierarchical
constraints or something like that, in the sense that the higher levels of your generative
hierarchy are tracking lower levels.
And so your preferences, right, like I like ice cream, is going to dictate my behavior
in the moment that I'm more likely to go get ice cream.
And that feeds back and forward, right?
Yeah.
I think that maybe we could just, I don't know what that term would be.
But no, I think it's a reasonable critique.
Cool.
That's interesting.
Yeah.
Let's go to consciousness then, because it was something that you brought up.
Um, so there were two quotes that I'll read back to you, if I may, that you've said, and
I'm curious about what you think.
These are from papers.
I haven't just...
I was a completely different person then.
Yes, yes, yes.
That was very, yeah, very Derek Parfitt.
There are lots of you.
Um, in 1995, this is a while ago, in a very, I like the title of this paper, consciousness is
for other people, you wrote, the primary function of consciousness is to permit high level interactions
with other conscious beings.
And then this is, so that's about function.
Yeah.
And then in another paper, you wrote, phenomenological consciousness is necessary for taking an intentional
stance towards other agents.
To do this, we have to be able to treat ourselves as agents also.
I think we can just bracket off that second sentence, because we kind of touched upon that.
But there's one point where it's function is interactions.
And the second one is almost nature, the necessity for, uh, intent, the, the necessity for consciousness
to take an intentional stance.
I don't know which order you want to take that in, but it would be really interesting to
unpick both of those.
Well, I think we've taken that a bit further.
Actually, start with the first one.
Sure.
So this is a study on metacognition.
With various people, particularly Nick Shea and Cecilia Hayes.
Mm-hmm.
And the idea is, and it, but it comes from originally from our, the work with Bahadur, which is about
people working together.
You know this study, I'm sure.
So people are working together to detect a weak visual signal.
And we show that two people working together and coming up with a consensus answer are more
accurate than the more accurate person working on their own in the right context, at least.
And the reason that this happens is that they're able to tell each other how confident they are in
their, um, in their belief.
And on a trial by trial basis, you choose the answer of the more confident person.
Hmm.
So in other words, it depends on them telling each other about their phenomenal state, if
you like.
Why?
Because I, I've come across as David Chalmers' parrot on many times in this, in this podcast,
and I'm going to do it again.
So why, why is that necessarily the case?
So why could it not just, why could it not just be an offline computation whereby we have
two probability distributions that are just done completely like offline, non-phenomenal,
they're just numbers.
Um, and you know, you have a higher order agent or, or one of them, you know, there's
just a, there's just a algorithm if choose the higher one.
And none of this is done online.
And why do the lights need to be on, um, for that, um, for that successful interaction?
The information has to get from one mind to the other.
Yes.
Yes.
If, if we presuppose that, uh, well, what for adaptive behavior in this example, yeah.
Yes.
But that could not be achieved also with offline minds, I guess is my point.
Could that, why do we need to invoke like intentionality, qualia, subjectivity, all the
fundamental tenets of consciousness?
I don't really quite understand.
So Chalmers in 1995 speaks about how you can give me a function of consciousness.
So whether it's, uh, like a global workspace or whether it's binding or whether it's this
and, but you can never tell me about how that function maps onto its phenomenal nature and
why that function couldn't happen.
I think what's wrong with that is he's talking about the individual brain and I'm talking about
interactions between two people.
And the key thing of the interaction is that they have to communicate with each other.
In this case, confidence.
Yes.
But could we not have something like an artificial agent, which has precision, which could be
a proxy for confidence?
And they're not conscious.
They just have done some mathematical computations, the inverse entropy.
And this is my confidence, right?
Based on like, you could have that with a large language model, for example.
So you would have to have, so your argument would be if you had two artificial agents, they
could also get better than one working on their own.
Precisely.
In this situation.
Yeah.
There you go.
That would be my contention.
Not that, again, that doesn't discount the putative role of consciousness.
It just discounts or calls into question the necessity for consciousness, I guess.
Right.
But I mean, on the basis of that sort of experiment, we went a bit further and started talking about
do we actually learn from each other how to interpret these in the states that we have.
And again, it becomes very intentional.
And I'm not sure if this is relevant or not, but when we talk to each other about how confident
we are, we can actually, then you get in competitive situations, we can express more confidence than
is actually justified in order to, in this experiment, to become an advisor.
So people would want to take your advice because you seem to be more confident about it.
And that seems so.
Yes.
My only concern, I guess, is that there are these interesting works coming out about sort
of extended trust in mind-robot interactions or mind-artificial agent interactions.
And if I have a belief that even a robot is extremely predictable and reliable and productive,
I can offload a lot of my capacities to that robot.
And actually, if we were in this kind of task, I could very happily take its interpretation
of the events or its position as my own.
And I might receive great outcomes, but I don't need to invoke in that any representational
space within that robot.
Does that, in some ways, not call into question even something like confidence, metacognition,
whatever it is, again, I'm not calling into question the fact that it might be this.
It's more the necessity of it.
Right.
Anyway, it's an interesting little rabbit hole.
Consciousness does this.
We've got into, you know, everyone I've had on and we talk about consciousness, it leads
into these rabbit holes.
We had an interesting discussion on Tuesday at the Institute of Philosophy, because they're
all obsessed with large language models.
Yes.
And they were talking about, does it mean, when, you know, does it understand what it's saying?
And it was interesting that the presenter was finishing up by saying, there is meaning, but
it doesn't mean what it says.
So basically, they decided that together, you had to have intentionality.
Right.
Which large language models don't currently have.
How much of this is sort of rooted in John Searle's work, Chinese Room and things like that?
That sort of thing, yeah.
Excellent.
Yeah, yeah, yeah.
It's good.
I like to see that 80s philosophy still has its role.
This is what I was sort of brought up on.
Excellent.
Let's now, it's not a jump, because I think the wonderful thing about your work is that
although it seems diverse, they all sort of trickle down into these fundamental questions
of agency and selfhood.
I want to talk about schizophrenia.
Yes.
And maybe we can start with a very interesting symptom, which is delusions of control.
Yes.
So you spoke, you wrote very extensively on delusions of control.
So, again, people who are not schizophrenic or don't have a psychological or psychiatric
background might not know what I mean by delusions of control.
So it might be worthwhile starting there, just outlining what that phrase means.
So this is where the patient says, it is not me doing, causing these actions.
There's some external agent making me do these things.
And they could be quite trivial things like combing my hair, or they could be more dangerous
things like attacking people or something.
But the idea is, and this is interesting because there's a delusion, typically is considered to
be a belief.
So you can say that they believe that external agents are causing their actions.
But it seems more likely, and the early psychiatrists had more or less stated this, is it's not so
much that I believe that external agents are causing my actions, it's I feel as if external
agents are causing my actions.
It's not just a belief in the sort of philosophical senses, something stronger than that.
Well, that's interesting.
So it goes beyond the propositional in some sense.
And there is part of a whole slew of symptoms called passivity phenomena, whereby you can say
it's not my emotion, it's being implanted in me.
And the most perplexing one of all, they're not my thoughts.
Yes, I wanted to get to that.
That is very weird.
It might be worth distinguishing the delusions of control from something like an alien.
Hand syndrome, just so people might be aware of this notion of a wandering hand.
So the alien hand syndrome is typically caused by a brain lesion.
And that's where the hand starts moving by itself.
And the patient says, I'm not controlling it.
Oh, I don't have control over it.
It's doing these things that I don't want to do.
But typically, the patient doesn't really say there's some alien force making it do these
things.
And they try to stop it.
I mean, the classic is Dr. Strangelove in the film.
I actually haven't seen it.
I know.
I know.
I'm going to get shouted at that in the comments.
So Peter Stirlers is playing, amongst many other characters, this Dr. Strangelove, who's
an ex-Nazi scientific advisor in a wheelchair.
And he keeps making these stories.
Well, it seems to have some strange overlap, perhaps, with Tourette's.
I'm working on, again, don't come at me.
I'm not saying they're the same.
But it seems like that.
I've come up with this term called oppositional self-modelling, which is that at one level
of some prior, at one sort of lower level of generative hierarchy, you kind of, you
have a habitual action policy.
So you'll just do it, right?
So there's got to be some part of your motor loop where you will move your hand or you
will do a tick.
But then you have a higher conceptual level where you really don't want to do it because
you want the type of agent that does ticks or does move your hand randomly.
So that's what I mean by sort of the overlap there with Tourette's.
There's also utilization behavior after frontal lesions where people make these habitual
responses in situations where they shouldn't.
They can no longer inhibit them.
Okay.
Interesting.
Yes.
So in terms of delusions of control, perhaps you could explain to people where the model
that you proposed for where this might come from, at least some of the versions of it
in terms of the inverse modeling and forward modeling.
Yes.
Well, I guess it goes back to Helmholtz who noted that when we move our eyes, obviously
the image on the retina jumps about, but we don't perceive it jumping about.
And the idea is that we use what's so-called corollary discharge so that when you send the message
to move your eye, you also send the message to the visual system saying there's going to
be movement now, but it's not caused by something happening in the outside world.
It's due to my own eye movement.
And that applies to all sorts of movements.
And more recently, particularly associated with Daniel Wolpert, you have this idea of inverse
and forward models.
So it says, when I move my arm, I actually have a forward model that tells me where my arm is going to be
when the movement is finished and what sort of sensations are going to be accompanying the movement.
And because I can predict them, I can discount them.
Yes.
So sensory attenuation.
Yeah.
And this is the difference between a passive movement and an active movement.
So in a passive movement, when somebody else moves my arm, I feel all these sensations because there's no discounting
and that's why you can't tickle yourself.
Yes.
And the idea was that in schizophrenia, perhaps something went wrong with this system of control.
So it literally was the case that when they moved their arm, it felt as if somebody else was moving it.
Yes.
And we showed, or Sarah Jane Blatomore showed that they could tickle themselves.
Oh, really?
I didn't actually see that.
I'm aware of her work.
I know you three all did wonderful work in this domain.
Maybe it's worth unpicking exactly what that looks like technically.
It's a shame that I can't get up all of the nice diagrams because there are some really nice diagrams.
But it might be worth talking about.
So people might think, okay, I want to move my hand to grip this mug.
Yeah.
This I love Dante mug, oddly enough, because I'm a bit of a Dante acolyte.
That's beside the point.
And I can just, I just know what motor action to employ and I just do it.
Yes.
I think you term that, I think that might be termed the inverse problem.
Why is that sort of folk psychology notion not possible for cognitive creatures like us?
As far as I understand it, the inverse problem is that whenever you have a goal of your action,
which is to reach that mug in the appropriate way, but there are an infinite number of different
ways in which the movement could proceed.
And the question is, how do you decide which one to use?
And there are various arguments like, do you minimize the energy requirement or the distance?
Or I think Daniel Wolpert, and I don't know whether he still thinks this,
thinks what you minimize is the end point error.
So that's the sort of argument about, and also there are always different muscles you can use,
and it's all very complicated.
And luckily we don't have to think about it, we just do it.
But underlying, there is something underlying all that, and certain kinds of lesions you can,
becomes extremely difficult to grasp things.
Interesting.
So there are potentially infinite ways of choosing a suite of sensory,
sorry, motor movements to achieve a goal.
So it's kind of computationally intractable to find a unique sequence, or a singular sequence.
However, we can predict the outcome of odd sequences.
Now that's a different point.
Yes, that is the critical idea with the inverse model is intractable to work out what's the best thing to do.
With the forward model, once you have given a set of instructions,
you can predict precisely where you're going to finish up.
Okay, excellent.
And so let's, so that's, so we've got the inverse problem, the forward model now.
And if we then fold in, what's going to be another kind of inverse type,
which is the efference copy?
Yeah.
So what's the efference, what's the role of the efference copy here?
As far as I understand it, the efference copy is just a way of saying we can predict what sensations
are going to arise from this movement.
And that's the thing that enables you to stop the image apparently moving about,
because you're, you know what the movement is going to be.
And if the outcome is, the real outcome matches the predicted outcome,
then everything is fine.
Yes.
But if it, in the case of schizophrenia, the prediction is wrong,
so it doesn't match the outcome.
So we have to explain this prediction error.
And one way of explaining the prediction error is saying, somebody move my arm.
I see.
And does this require us, in some ways, to go to thought insertion, to say that thought is an action, in some ways?
Well, many people believe that thought is, thinking is an activity.
This goes right back to Luria, I think, in Russian psychology.
But it philosophically becomes very complicated, because you can say, you have to say, I intended to have a thought.
Yes, and that's definitely, the Buddhists might have a problem with that.
If you're thinking about a problem, you would have some idea of what sort of outcome you want to have as you work your way through this problem.
And so there is room there for, you know, metacognitive approach to thinking.
So you could certainly say this, I have not succeeded in my thinking task.
You can actually say, I think I have a good, even when you begin, you can say, I have a good chance of achieving this thinking task.
And I guess one might relate that to tip of the tongue phenomena, where you say, I can't remember at this moment, but I'm pretty sure if I try a bit harder, I shall get there.
So these would be examples of putting thinking into a sort of active framework.
Yes, there are some very nice metacognitive models, actually, or meta-awareness models with an active inference.
So there's one by Lars Sandberg-Smith, 2021, which is very beautiful.
These really rich Bayes graphs with these hierarchical layers.
So I believe there's good evidence that people with schizophrenia do not have major problems in motor control.
How is this accounted for?
Oh, yes.
Well, that's exactly right.
There's always a proper schizophrenic, whenever you come up with a theory of schizophrenia, they should be much worse than they actually are.
Yes.
Yes.
But they do have eye movement abnormalities, and sort of smooth pursuits and things like that, which would be consistent with failing to predict properly the consequences of eye movements.
There's some nice experiments from Germany.
You can do strain, how does this work?
You can do experiments where you have to track a moving target, and this means that your expression is that the target stays in the middle of your field of view, and the background moves.
Even though it's the target that's moving, and the background is stationary.
So you obviously have to correct for the moving background, as it were, and you can measure how successfully people make these corrections, and schizophrenia patients are less good at doing that.
So there are some subtle effects that you can see.
Yes.
Interesting.
Actually, I've got one more question before we go to delusions and hallucinations, because I sense those are slightly different.
I mean, this is, in some sense, a delusional belief.
So there's some interesting stuff.
There's some very adjacent or actually overlapping work in active inference about agency, and it's very much an offshoot of the comparator models
and what we've been talking about.
So, and a lot of this is actually now being focused on depersonization.
Yes.
So an idea I really like comes from George Dean.
He's got this idea of an allostatic control model.
And what that means is that if I can predict the sensory outcomes of my actions, very similar to what you were saying,
and I get a sort of non-prediction error, right, I get the results that I expect, I can start to develop the inference that there is an agent in my generative model that does these things.
And what happens is, let's say now that's an inference, and I need to keep providing evidence for that inference to keep it high precision, let's say.
Now, let's say I'm in a torture chamber.
This is an example.
Torture is a very reliable producer of symptoms of depersonization.
Let's say I'm now getting tortured.
I have a prior that I am the type of agent that should be able to do things to confirm evidence for my own model of the world.
But in the torture situation, I might have a desired action, but I'm not able to actually do it and therefore provide sensory evidence for it.
And so what you start seeing here is the disentangling of that very inference that there is some agent at the heart of my generative model.
How does that sound to you?
Does it sound very much aligned with the way you would think about agency?
Yes, I know.
I think that's very interesting.
I mean, I've been very interested in the feeling of being in control.
And there are experiments on that.
And I guess the torture situation is where you're totally not in control, which we luckily don't normally experience.
Yes.
I'm just trying to think.
I guess a lot of this.
Go on, please.
I mean, it's a very Bayesian story that the feeling in control of being in control depends not only on the intention to do something, but also on the outcome.
Yes, exactly.
Exactly.
Yeah.
Yeah.
I've been writing with Carl and others on so-called flow states.
Yeah.
Flow states of surfing, rock climbing, playing a musical instrument.
And there, although you don't have this rich sense of self, this epistemic agent model, this propositional agent, you do feel in control.
Yes, exactly.
And that is exactly as you say, because you have this alignment between the predicted consequences of your action and the actual sensory outcomes in this very tight motor loops.
And I think it's worth folding in this notion of interoceptive inference as well.
So this is people like Anil Sef and Lisa Feldman Barrett, this notion that at the very core, what Thomas Metzingo would call your minimal phenomenal self.
They've argued that this is rooted in successful interoceptive inference, either through autonomic reflex or eating, some actual volitional action.
And I guess something else there is that torture would also deny the possibility for successful interoceptive inference.
If I'm not getting fed, I am weakening, I am unable, that prior that I need to have a certain level of glucose is not going anywhere.
So I think what happens there is that the agentic model itself dissolves rather than the homeostatic requirements.
So there's some really beautiful work being done here.
Excellent.
Before we go on to delusions and hallucinations, I wanted to ask, so my sort of forays into psychiatry are limited.
I'm more adept at cognitive science.
But I did read over the summer, R.D. Lange's The Divided Self.
I was curious, he's famous for sort of instituting a more, I would say, empathetic and understanding approach to psychiatry.
That these people are not just crazy, right?
But they are what we would now say are actually Bayes Optimal, just confirming priors that don't really correspond to what we would see as adaptive behavior.
I was just curious about what your opinions are of whether you have any of R.D. Lange and what he puts forward in The Divided Self.
No, I don't have a very high opinion of R.D. Lange, but then this is mostly due to interacting with other psychiatrists.
And I don't think I might have read The Divided Self, but I don't think I did.
But the idea, I mean, putting it into that Bayesian story is quite interesting because that seems a very good idea.
That is to say they have the wrong priors, but they're behaving.
I mean, certainly all the stuff on delusions.
Yes.
It suggests that the original idea was that they're irrational.
Yes.
Whatever that means.
Whatever that means.
And that, in other words, they are not arguing, you know, they're not appropriately arguing from the evidence.
And all the experiments that have ever been done show that they're extremely rational.
They're probably more irrational than other people.
And as you say, it's just that they start with the wrong priors.
Yes, there's something in Bayesian modeling called the complete class theorem, which is that any action perception can be cast as Bayes optimal, just given a certain set of priors.
It's slightly worrying, you know.
Slightly worrying.
But it accounts for things, it accounts for all, I mean, well, basically all phenomena.
Because if you speak to Carl, well, actually, you wouldn't go that far.
But you could cast it all as this kind of variational Bayesian inference.
So it's all Bayes optimal.
Everything is Bayes optimal.
But I guess the flip side of that, the positive side of that, is that maybe it does license a more humanistic approach to psychiatric patients.
Insofar as, there's this interesting argument.
I don't know if it's an argument.
There's an interesting point, which is that maybe something like, it's going slightly away from schizophrenia, but it's relevant.
Something like PTSD or OCD or general anxiety disorder actually could be quite adaptive in a certain ecological niche.
If I'm in a war zone, having hyper salience and being really, you know, having very high precision over the likelihood of some sensory input and downweighting priors, like, you know, arguably in PTSD, is actually really useful.
But it's just not adaptive in modern, you know, calm London, leafy Regents Park.
So how do you think, in your experience in psychiatry, this work has altered the way that we view psychiatric patients?
Yes, I mean, in psychiatry, in reality, of course, it's very difficult because there aren't enough of them and there's no money and they can't find any junks at work.
But I mean, that's how that really operates.
But going back to the slightly earlier question, people like, gosh, I can't remember his name, there is the idea that the symptoms of schizophrenia are not understandable, which is another, you know, they have nothing to do with reality or our lives.
And I guess one of my aims in the sort of story of delusionless control is to say they are understandable.
It literally does feel as if somebody was moving my arm.
And how much would you say this has come from your, would you say?
Schneider, that was the person you heard, yeah.
Do you sense that this empathy that you have, in the very literal sense of empathy, that you can, that it's understandable, comes from direct work, you know, directly working with these people?
Oh, to some extent, yes.
I mean, when I was with the Medical Research Council, my lab, so called, was in the middle of the acute psychiatric ward.
So I was interacting with them every day.
And it was quite good, because they were actually very bored.
So they would come and knock on the door and say, have you got another experiment for me to do?
Yes, I think that's where Carl started, was in psychiatric rotations.
Yeah, yeah.
How did you guys first meet, if I may ask?
Was it at UCL?
No, no, we met at the cyclotron unit at the Helmersworth Hospital.
Oh, wow.
Where we had, there was a project, I think, run by Peter Little, to basically start scanning patients with schizophrenia to test various theories.
And if I remember rightly, Carl was appointed, because he had this psychiatric background, to work on this project.
And that was in the very early days, before we knew how to analyse brain imaging data.
Yes.
So he was given the task of analysing the brain imaging data.
And the rest is history, as they say.
Quite, quite.
What was it like?
Your most cited paper on ever is the statistical parametric mapping work that you did.
Again, we're going a little bit off piece, but this is the beauty of this podcast.
Like, you know, we can go wherever we want.
What was it like?
Again, I don't know how SPM works.
I don't know how, I'm not a brain scanner, so maybe one day, or voxel-based morphometry, or any of these things.
But I'm just curious about what it was like.
No, it was very exciting.
Yeah, I'm sure it was.
It was very exciting.
And I think what was wonderful about Carl is that, I mean, there were lots of other people doing imaging for the first time,
and they were tending to invent new ways of analysing the data.
Yes.
Whereas Carl, very sensibly, said, but there are all these statistical paradigms already there.
Yeah.
These are what we should be using.
And that's...
Yes.
I've always kind of wondered how Carl knew about them in the first place.
But I sense that your work on forward modelling, I was reading, I had the joy of going, not obviously through the entire catalogue of your works,
because that would take me until next year, but going through a couple of them again, and some of them are sort of canonicals.
I've read them before.
And what struck me, almost like reading Thomas Metzinger, I've said this before about Thomas Metzinger, how incredibly...
In retrospect, it just seems like you're speaking the same language as what we're saying now in active inference landscapes.
Not quite, but nearly.
Not quite, but well, there's a lot of overlap, and it's incredibly influential.
And I would say that for you and Sarah Jane and someone like Thomas Metzinger, it's really remarkable.
How, you know, how much was...
How in conversation were you with Carl when he was beginning to develop the free energy principle?
Oh, yeah, I know it all the time.
We share an office.
Oh, nice.
So I have lots of passive smoking experience.
Oh, yeah, he does like a cigarette.
Fair enough.
I think he's warranted one.
And have you given much thought?
I guess we are on the Active Inference podcast, so I ought to ask something more specific.
I know we spoke before an email, and you said, you know, this is not directly your line of work.
But you were around for when the 2010 paper was released, the 2009 paper was released.
I think a free energy, you know, 2005 might be the sort of beginnings.
What were your kind of experiences around then, and how did you contribute?
Well, I'm not quite sure.
Yes, Carl has this habit of putting my name on papers from time to time.
And I guess I contribute to some extent by saying we need more independent references or something like that.
So I sometimes change the wording a bit.
And what I was particularly interested in is I was very keen, and it really goes right back to Richard Gregory and people like that,
the approach to perception and the idea that we, you know, if there's a prediction error, we have to update our model of the world.
And I thought that was very exciting and wrote about that in my previous book.
And so I was particularly excited with active inference, because that gave you the other side of the picture.
And when we get a prediction error, we don't have to update our model of the world.
We can change the world instead.
Isn't that amazing?
I thought that was wonderful.
I know, it is wonderful.
Well, your thought, so this is kind of what, if anyone's familiar, this is what we would call the low road to active inference.
Yeah, this is predictive coding, Helmholtzian perception, and the like, and action as inference, I guess you could say.
Have you given any thought to the so-called high road?
And by that, I mean dynamical stochastic systems and no.
No, no, that's too difficult for me.
I'm trying to learn the maths.
Yeah, you're not wrong.
You're not wrong.
It is rather tricky.
Excellent.
Okay, so I said we will talk about hallucinations and delusions.
I think delusions, we've somewhat touched upon, which is kind of this fixity of priors that is not allowing for updating.
But I read, you know, I read Kapoor's work on sort of the dope aberrant salience model.
I never thought that any of this stuff really accounted for hallucinations.
Where, to the best of your knowledge, do you think hallucinations might come from?
Well, with Paul Fetcher, we wrote a paper which we're basically saying there's no fundamental difference between hallucinations and delusions.
Okay.
If you take a Bayesian approach.
Yes, yes.
Because the hallucinations are, it's just about perception rather than beliefs, but in both cases it's all about whether you update and where the evidence comes from.
But the thing you have to remember about schizophrenia is that these hallucinations are predominantly auditory, and they're predominantly hearing voices.
And one symptom is so-called thought broadcast, or no, yes, you can, I hear my thoughts as if they're being spoken aloud.
And you can even have a sort of very similar story with the forward model, and there's work on this, so that when you speak, you hear your own voice, but you suppress it.
And there's some evidence that when patients speak, that, again, the suppression system seems to go wrong in relation to speaking as well.
And you have inner speech and all these sorts of things.
So one idea is that they're perceiving their own inner speech as if it was from an external source, which is not that far away from a delusion of control.
Yes, I sometimes think, how true is that?
When one meditates, for example, if one is doing Vipassana, it does seem like those thoughts are coming from, not from you.
So this might be looping back into our sort of humanistic approach to psychiatric disorders.
So don't tell that to your psychiatrist.
Yes, yeah, yeah, yeah, yeah.
I won't.
But it's true.
At least, and the, you know, there's this very odd overlaps between Buddhism and psychiatry and ego death and all of these kind of things.
Do you think that this notion that self-talk, let's say, I'll stick with that because it's very interesting, is self-talk?
From a Buddhist, from a very raw Buddhist perspective, that doesn't get off the ground because there is no self.
These thoughts are just popping into awareness and it's all process.
It's process ontology.
It's not, there's no substance there.
It's coming and going.
It's just the field of awareness.
So is it just an adaptive tool for us to presume or have this illusion that it's self-generated?
I guess that depends what you mean by self-generated.
I mean, so.
Well, not self-generated, but.
It's in-talk.
Well, what does self-talk mean then?
That maybe that's, because it's, yes, I mean, clearly it's not, I'm not intentionally saying these things per se, but I'm perceiving them as belonging to me.
Yes.
So.
They're not coming from outside.
Yeah.
Sure.
But what's, in this, in this way, we have to kind of ask, well, what is inside and outside?
Yeah.
So, so.
Well, that's, I mean, that's a common one.
I mean, one quite dominant theory of schizophrenia is they've lost the boundary between inside and outside.
That's really interesting.
Yeah.
They've lost their Markov blanket.
Yes.
Yeah.
Yes.
But I guess, I guess the reality is you never lose a Markov blanket.
I mean, this, to be honest, it points to quite, it points to theoretical difficulties in active inference, which is something that's been brought up in this podcast before and in other works,
which is where do you even cast the Markov blanket?
And what is it to say that you have internal states and external states?
Really what those actually mean, and I give credit to Maxwell Ramsteed for pointing this out to me,
is that internal you can just say are tracking and external are tracked.
But that said, you have someone like Andy Clark who might say, well, in my tracking mechanism, I might have my telephone or my notepad.
And then you have Jakob Howey who says, no, no, no, the evidential boundary is the mind and even the body is being predicted.
Yeah.
Does any of those dichotomies or debates inform something like what we've been talking about, self-talk and delusions of control?
Well, self-talk, inner speech, people used to call it.
Yes.
And that is, and again, the Russian psychologist, I mean, Vygotsky, I think, and there's some evidence for this,
that, you know, young children, particularly doing difficult tasks, what one might call frontal tasks,
you actually talk aloud, I must now do this, and I must now do this, and this becomes internalized,
so you're doing that internally.
And I think for some difficult tasks and things like mental arithmetic, there is indeed inner speech,
which is being used to control what you're doing.
Interesting.
And some schizophrenic hallucinations where they hear a voice commenting on their actions,
so now he's going to do this, and then you do this, why is he doing that?
And it's all very weird, what they, but you can see a sort of thread coming through this.
So, I mean, that's what I would call self-talk, and the self is not important.
Well, I wonder whether there is some space for a predictive model here,
insofar as if we're going to talk about what we meant by self-generated and agency,
we were talking about deploying some prediction and having, in association with that prediction,
not just, I don't just deploy an action policy, I also have precise predictions about the sensory outcomes
I'm expecting to receive.
And perhaps we can talk about self-talk in a similar way, which is that at the inception of my self-talk,
let's say I'm predicting the sensory, in speech marks, consequences of an action policy of saying this at T plus one,
and then I receive that back, and that seems self-generated.
Yeah, yeah.
And I guess if that mechanism itself is disrupted through synaptic problems, precision weighting problems,
then that is not only just going to be motor action, but also mental action.
Yeah.
Is that appropriate?
Absolutely, yeah.
Oh, maybe I should be a psychiatrist.
Mental action is a good term, yeah.
Yeah, mental action is a very good term.
Well, I mean, all of this, it's kind of become very clear to me that all, such a plethora of behavior in active inference is mental action.
I mean, the very deployment of precision over what now, you know, we're using these Bayesian graphs,
these so-called POMDP schemes.
So you have your sensory expectations, your C matrix, your state transitions, your B matrix.
These are, deploying precision over those are all mental actions.
Yeah.
So, okay, excellent.
Okay, that's, that's, okay.
Interesting.
Okay, that's very, that's very cool.
I was wondering, so there's a, I believe he was a philosopher called Louis Sasse, or maybe he was a psychologist,
and he wrote a book called Madness and Modernity.
He, yes, was he more sort of modernism?
It might be, it might be.
It's been a while since I read it.
Yeah.
Please, please educate me, because I'm, yeah.
I mean, I read it too, but it was a very long time ago.
So, I mean, it's a removal of sort of structures and base,
standard procedures and, you know, stream of business stuff.
And how does that feed into schizophrenia?
Schizophrenia is sort of the etiology of schizophrenia somewhat linked to having an unstable lifestyle.
Yes.
I mean, there's an interest, this is very unlikely to be true,
but there's interesting stuff on volatility.
So, when the environment is volatile, you should have a faster learning rate.
Yes.
And I think that somehow interacts with the dopamine system.
Okay.
So, you could, and there is some evidence that children brought up in very volatile environments are more at risk.
And one wonders whether, and then you've got this dopamine aspect coming in as well,
or if you've got too much dopamine, so you get the, there's that sort of story.
And the modernism, in a sense, is increasing the volatility because you no longer rely on cultural givens.
You know, currently an interesting idea in relation to schizophrenia, which is bringing the cultural thing,
is that most of our beliefs at this high level are constrained by interactions with other people and culture more generally.
And you could argue that what's odd about what the reason that schizophrenic beliefs don't update is because they're no longer constrained by this high level cultural and what other people say.
So, these are, yes, your work is all coalescing.
Exactly.
That's cool.
That's nice.
Yeah, that's very, yes.
It's interesting, isn't it?
Because we think of ourselves as these, we live in a rather individualistic society where we think of ourselves as these atomistic beings.
And we're not.
And we're not.
That's terrifying.
Um, good.
Excellent.
So, so the book came out last year.
Yes.
What's on the, what's on the horizon for Chris Friff, Uta Friff, the Friffs?
Well, um, we're in our 80s now.
Um, you wouldn't be able to tell.
Um, we haven't got a major project.
In line.
Um, we have a quite exciting interaction with our friends in Aarhus in Denmark.
Yes.
Where they have uploaded all our papers and are trying to construct a large language model.
Interesting.
To discover who we really are.
Yeah.
Interesting.
Uh, is this Andreas?
Oh, no, it's in his, you know, his lab.
Yeah.
Yeah.
Yeah.
Cause you have a, you have a partnership with him or is that still ongoing?
We visit every year.
Yes.
Yes.
Excellent.
He's got, I think he might be coming on.
Uh, yes, we should certainly talk to him.
Yeah.
No, I'm extremely interested in his work.
Chris, this was, um, this was a delight.
Um, it's been a delight on my part to go back and read, uh, your texts.
I mean, um, I did finish my master's just background about myself in case you did.
And I finished my master's at UCL in experimental psychology last year.
Um, and I would say sort of your presence and Carl's presence sort of lingers in a positive
way, not in a sort of ghoulish way through the corridors.
Um, so thank you.
Yep.
My pleasure.
It's been an absolute pleasure.
All right.
Excellent.
Excellent.
