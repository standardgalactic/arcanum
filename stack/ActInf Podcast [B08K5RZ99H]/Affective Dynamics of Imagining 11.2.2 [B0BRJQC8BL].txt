This is the ActInf podcast, where we provide short clips from the Active Inference Institute
weekly live streams. If you want to hear more of this material, check out the entire live stream
at the Active Inference Institute YouTube channel. The link to the live stream is provided in the
episode description. I am the host and curator of this episode. My name is Blue Knight, and this
episode is going to be clipped from live stream number 11.2. Our discussion is based on the 2020
paper entitled Sophisticated Active Inference, Simulating Anticipatory Affective Dynamics of
Imagining Future Events by Casper Hesp, Alex Shantz, Baron Milledge, Maxwell Ramstad, Carl Friston,
and Ryan Smith. This discussion is going to be facilitated by Daniel Friedman, who's going to
start us off. This is the affective inference question, where the affective the agent is
relating into how it simulates rolling out all these future time points. And at each time point
in this model, the agent is going to be running out some possibilities for what could happen in
the future. So Stephen, and then we'll think about the examples.
Hi, I'm Stephen Silly. I'm in Toronto. And one thing that's come up, and I've been doing some work
with this Metaphors of Movement, and Andrew Austin, who does that work, he talks a lot about how anxiety,
he finds anxiety is often related to people having, trying to have elevated status, like they're trying
to have an elevated status. And it makes a lot of sense for this, because it could also be like,
you feel like you put yourself in an elevated status, and you're always going to be slightly
uncertain, unless maybe you're a king or someone, about that status being maintained. So being put
on a pedestal can be, so there could be something about Western society and status, which is partly why
we have this overarching anxiety. And it would make sense in a way, because there's always a sense
of never being completely clear about whether your status is going to be maintained. So I thought that's
kind of interesting. And this would support that kind of observation.
Yep. So status, or various other sort of social approval metrics we can think of, it's like the
water we swim in as social organisms. So just like a company might be wanting to stay above water
financially, at least that department, a person has to be staying above water reputationally. We can
think of it in that way. And so again, let's go to the examples and think about these different
systems and what they might be performing inference on. Scott?
Hi, I'm Scott David. I'm at the University of Washington Applied Physics Lab, and I've been a
lawyer for 27 years. I'm trying to use physics principles to help structure social relationships.
I'm just going to comment on the status issue that it feels like. Then you can adjust. So you're
making serial adjustments, right? You're trying to minimize the free energy, minimize the difference
between your expectation and the reality you're experiencing, as I understand it. So with that
overall effective status, you can do what feels like compensating controls. So you could, if you
feel like you're at risk, vis-a-vis the one presentation you're making of self, you can rake in other
presentations of self to complement or supplement or mitigate the impression of one of them, because
because you have myriad affective projections that you're making simultaneously. So it feels like
if you have an awareness of this, it can help you with that presentation of self question by
understanding that you, okay, this effective status that I'm presenting is not getting me where I want
to be inside. So let me leverage another one, which is contiguous or a neighboring affectation. I'll call it
an affectation here, but I mean in a presentation of a Markov binding site. So it feels like it gives a
strategy for hybridizing and synthesizing your presentation of your Markov blankets. Anyway,
keep going. It's just, it's impressionable. Yes. Okay. So let's go to the examples and think about how
these three potentially even overlapping systems are going to be carrying this out. And an individual
at each time point, maybe let's just say this is every second or each minute, a team might be
interested in organizing on the multi-day and the organization is going to be more explicitly
thinking, okay, quarter to quarter, that's going to be our next time that we're going to do all this
simulation. So it's not surprising that as things get bigger, they also get slower. So that's a common
theme we're going to see. The individual's affect is really where this emotional inspiration comes from.
So there there's the closest mapping between affect and emotion, but let's think about that team and
the large company example. Well, affect again, and valence specifically is like that plus to minus
axis. So is this team going well? Is this company going well? And if someone says, yeah, we're burning
money at an incredible rate, it's unsustainable, but it's going well because I have a believed trajectory
that we're going to go on where we actually pull out of the nosedive and do XYZ. So they can still
think it's going perfectly well, even if the instantaneous rate of loss is high. And then on
the flip side, you can imagine a team or a large company where instantaneously their state looks
like it's good. It looks like they have a lot of cash or it looks like they have a lot of people
involved in the team, but they still feel negative about it. So that disjoint between the affect about
a situation and the state of the situation is one thing to take into account. Now let's connect the
affect at all these levels to precision estimates at different levels. Especially in the active
inference framework, which frames what organisms or any system is doing as precision seeking,
high anxiety is going to be coming from having low precision. Now it's not that we want zero
uncertainty. We want to have this controlled novelty sort of U curve, but it can be clearly
situations where your precision is too low. And then you're surprised by what is being emitted to
you in the niche, whether it's your team operating environment or the company's operating environment.
And then if your precision, it can't get too high because if you're overly precise and you're
incorrect, then you're going to die. Like if you have a super, super accurate understanding, but you're
just delusional, then you're going to fall off the cliff. So in a way, what shapes
this precision is actually the real world, which prunes beliefs that are not functionally
associated with success in the real world. Stephen, and then we'll come back to it.
Yeah, I really like this idea of thinking about how we understand ourselves within all of this.
So for instance, yeah, if you could move between a different regime of attention or sense of self,
which could be like what happens when we do sense making, maybe even change the operating metaphors
of the person, you know, who am I at the moment? You know, what's the context? What's my situational
attunement? What's my team's purpose? What's the operating metaphor for this team? Are we like
all driving together in a car? Are we building ourselves a fortress? You know, and that would,
that almost could give a way to jump in and out of these kind of affective engines, if that makes
sense. So as you're seeing over time, how's it going? What's the policy? And what's the affective
states that are sort of thought about in a certain future? And they could almost then say, okay,
what if I shifted? Maybe that's where you'd need the body, like the metaphor I'm working with.
And then what does that do? And maybe at times that's when you need to work with a group to be
able to do that, because maybe an individual can't just keep flipping backwards and forwards. You need
to work as a group to do that kind of sense making across different times.
Cool. Scott?
I had a question for Sasha. You were mentioning pruning, but you weren't talking about dendritic
pruning. But I wonder if dendritic pruning is describable by what the type of pruning you were
just talking about. Because my understanding of dendritic pruning, very minimal, is that, you know,
during the day you have the growth of dendrites and then this prune back selectively. And that
is influenced by your externality each day. The growth is influenced by your externality. And then
there's this pruning process that feels like it's iterating itself at that level. Is that
describable by this here? Is that another scale? Or is it something else that's going on there?
Yeah, I think that's a really interesting analogy that that's kind of what's happening there. I don't
know if I would kind of draw all the same parallels. Yeah, just from a mechanistic standpoint, but it's
true that kind of in the generalities that as connections are formed during the day, then
they're pruned or lost as they're not used. And yet we think that happens at night.
But yet, I think that's an interesting analogy to draw that it's beliefs about the world that
aren't, I don't know, useful or supported are the ones that then get pruned.
Yes.
And I was also going to say, the other aspect is, I think we know, from our lived experience
is that it's really, it's really interesting when people can be holding certain beliefs
and not, not know that. And then when they finally kind of confront the belief, it kind of,
yeah, there's a bit of a breakdown. And to me, that that moment is very interesting. When
people have to confront certain beliefs that maybe they didn't even recognize that they
held.
So there's a phase change, and a recontextualization piece in the last part you said, Sasha, and
the pruning is using a network analogy. So it's like pruning connections between different
aspects of the system. And so let's think about the individual,
in the office having a conversation with somebody, the query, the prompt to them, let's just say is,
how are you feeling? And that is a query that's presented to the interface, which is their ears,
and also their vision and other aspects. The query is presented to the interface about what's inside
of the interface. And now what's happening inside of the interface is a generative model of that query
presenting system. So inside of the person, there's a generative model of, for example, the person who's
talking to them asking that question. And we know it's a generative model, because if they covered
up their eyes, or if they only heard part of it, they might be able to still recover what was being
asked. But in either case, there's a generative model inside of the interface, and a prompt is
being presented as an observation stimuli to the interface that's querying how the system will respond.
So speech is action. And that's not even a legal claim. It's that it's a motor claim. Speech is
generated by a motor behavior. It's not your hand, but it is a motor behavior. And for some people,
it is with their hand. So various body parts can be used to communicate. Let's think about that
interface in the process of the team and the company. So potentially for these organizational
entities, the interface could be like a consultant who interfaces with specific questions. But instead of
a counselor who asks, how are you feeling to an individual, there might be questions that could
be asked to the team. And there can be questions that could be asked such that only the team could
respond. And someone might say, well, how could you ask a question that only a team could respond to?
Aren't teams composed of people? There's two things I'd say there. The first is that that's the
reductionist argument. The reductionist slide is like, what do you mean get a response from a person?
Aren't you just going to get a response from skin cells and neurons? It's like, right,
that's what I'm trying to get that response. So even if the response can be reductionistically
understood as being composed of smaller pieces, that's not a surprise that should be taken for
default. So questions can be asked to teams that of course humans are going to be responding
to as well. But also we can think about kind of like colony phenotypes. We can think about team
phenotypes. So for example, let's just say I ask a question to a team, like what did you have for
lunch or what do you think the most exciting project is for next year? And then I looked at
the distribution of how long it took people to respond to that message. That's like a colony level
trait. It's a collective trait. That distribution is composed of people acting, but no individual can
dictate what that distributional parameter is. So it's like a measurement of, let's just say,
some blood cells. You flow a million blood cells through, and then you can get a distribution
across all of those blood cells. So it's like you're querying in the aggregate, even though each
individual sub piece could have been following that distribution or somewhat of an outlier.
So those are the kinds of things that you could ask presenting to a team or an organization.
And the team or the organization is going to have a generative model of its niche. So if it's involved
in a certain type of consultancy where it paid a lot of money and it really respects what the person is
going to be doing, then maybe when you ask them the question, what's the most exciting project and
why, they give one response. Or what's the most challenging project of this year and why was it
challenging? Whereas if you were in a different context, you'd give a different response. Because the
generative model of the system across that interface is very different, so the response that it gives
will be different. And it's going to be querying different things and externalizing different
aspects of itself. Could be accurate, could be inaccurate. Scott?
So one of the things that raises is, I've been in some of the work that I've done in cybersecurity, I've been
parsing principles versus ethics versus norms. And so it's kind of interesting in querying a group, you're going to
get an average, right, you'll get a Gaussian distribution or whatever of opinion, and you'll then it'll be
informative. And so norms, I assert, for these purposes, that they're behaviors, behavioral expectations
that are set through the past what was normal. And one of the assertions I make is principles, and again,
they're assertions, there's different overlap here. The principles are institutional assertions of
aspiration. And ethics also are aspirational, but they're human assertions about human behaviors.
That's the distinction I make, whatever words you want to use. And so it's interesting in the context
where you're talking about, about querying a group, because there's different evidentiary
group, chunks that you'll look at, right? Normative, you'll be looking, according to those definitions,
on, hey, what'd we do before? And what'd we do against a set of standards that set?
The principles may be more aspirational, and it may be, you know, how are we doing towards that
thing, but it's not necessarily based on what was done before. You can, you know, you can say our
principles are more aspirational than what we did before. So it's interesting, just that interface of
what's used in the discussion of the group dynamics, and how that relates to what you were just describing,
which is the querying of the group and individuals. The framing of the nature of that output you're
getting from the group is kind of interesting based on that question asked, right? What do you do before
is one question. What do you wish to do in the future is a different question.
Yes. So that query could be, what do you regularly do? So again, it could be the person in the office,
and someone says, what is your morning routine? That's something we talked about in a previous week.
Or it could be a query to a team. What is your onboarding routine? Or how do you welcome new
members? And then this question of the aspirational and the norms. So it's funny because norms can mean
what's normal. It means what's expected. That's what has happened in the past, because what's not
normal, you know, if not, if not the past, what's normal. But at the same time, normative means
what should be. So a normative claim should be like, I think people should be treated this way.
And that may or may not reflect what has been the norm. So people, all of belief systems make
normative claims that sometimes are consistent with norms and sometimes are almost radically
divergent from norms. Someone says the norm is A, but I think the norm should be B. So I'm making a
normative claim about the norms and it should be different. And so these are all interesting
things to, uh, yeah, Scott.
So one big gap that's out there in the world right now is the gap between law and what, and the
interactions that technology allows. And I'm talking about practically up and down the chain,
reproductive interactions, biomedical, population-wide, all these different things.
The law is really lagging. Okay. So one of the things that's interesting about this is there a
possibility that this kind of analysis can help us to discover norms that would guide, um, uh, groups
and those norms, if they're sufficiently interesting to the groups can be made enforceable into laws.
And so that to me, this is a very interesting way of a possibility of discovery of new laws and
self-constraints that groups can put on themselves in order to function as larger systems in the globe,
uh, kind of context. But I'll put that aside for now. But I just wanted to raise that. Is this a
discovery, is this a mechanism for discovery of new working models of larger scale norms?
Yes. Stephen?
Yeah, I think that this is a good point because, and discovering that with this model here where
you've got this task specific, and then you've got this effective, actually as a, as a larger
sort of scale, time scale, sort of checking, I think it's also relevant in terms of how we can
get mechanized in our, like, if we just keep doing the same task and we get the reward and the cue,
and it starts to create a high sense of, this full sense of certainty in our world, which is so much
about just constructing more of our social niche and, and alienating or externalizing the environmental.
So we, we can start to get caught up in this kind of task specific ways of working and silos.
And so there may be this, this, this could speak to why we need to do some sort of sense breaking
to sort of take us out of some of these mechanizations and look at a longer time scale
and use affect to do that integration and not just rely on metrics.
Cool. Let's, let's take Scott's point about this being not just an enforcement understanding,
but a discovery process and connect that to some topics we've been considering like bottom
up versus top down function of systems. So the bottom up is learning. That's where the little
ants are going out and they're finding different things, or each of the cells in the retina is
receiving a different photon, or each person is receiving a different newsfeed. And then as it goes
quote up or in the system, it's being aggregated. And that is updating progressively more and more
summary like variables, like of teams or of organizations. And then norms can feed back
down to lower levels of the system, whether in the brain, like the Bayesian brain or the predictive
processing hypothesis, or whether it's team communication norms. And those can be informal
or formal. When we are talking about human organizations, we gain this level of syntactic
framing of top down priors. So instead of just saying, this is how things are like the red blood
cells are flowing at this speed. So that's the speed they're flowing at. We're going to say there's
a speed limit. And if you don't follow the speed limit, then we're going to have this type of
enforcement mechanism. And so it could be the case that in the legal context, that if you just apply
a law, a top down law, it's kind of like trying to teach someone a motor pattern. Let's just say a speech
law of some type of controlling speech. It's like controlling someone's motor behavior again,
because it is a motor behavior. And so what would you do? Would you put them in the exoskeleton
and say, okay, here's a perfect golf swing. Now you're a golfer, right? Well, no, you actually need
to practice and you need to have feedback. And so if the law is overly punitive and it says, oh,
that one time that you got put in the exoskeleton, you didn't understand how to golf and other sports
that golfers know, how could you not have made the connection there? Not one time that I punished
you for messing up. That is not an extremely helpful framework for certain issues. So how could
we have this bi-directional conversation where there's experimentation and implementation at the
edges? And then people's experience percolates upwards in the system and then the system informally,
eventually formally ends up entrenching healthy or productive or agreed upon patterns. So it's an
interesting thought about how these types of systems are not just about learning. They're not
just about exploitation. As we've been thinking about, they're sort of in both domains and they
can trade off. And when they need to exploit, they can dip into exploitative type behavior,
but also they can be in an exploratory mode. We hope you enjoyed this week's episode.
Stay tuned for next time when we're going to have more discussions of the same paper.
