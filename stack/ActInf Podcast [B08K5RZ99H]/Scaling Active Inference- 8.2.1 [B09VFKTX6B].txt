welcome to the active podcast where we will present short digestible segments clipped from
the active inference lab weekly live streams if you like what you hear and you want to learn more
check out the entire live stream at the active inference lab youtube channel the link to the
live stream is provided in the episode description my name is blue knight and i will be guiding you
through this podcast episode which is clipped from active lab live stream number 8.2 this discussion
will be loosely structured around the paper scaling active inference by alex shans manuel baltieri
anil seth and christopher buckley alex shans the first author is going to start us off talking about
his motivation for undertaking this study i'm very interested in reinforcement learning machine learning
and also very interested in the inference the two communities don't really speak to each other as
much as they should and so much of the work that's happening in reinforcement learning um especially
model-based reinforcement learning has direct analogies to the work that's being developed in the
active inference community um so stuff like the use of variational methods variational auto encoders the use of
dynamics models the use of trajectory based planning uh or just planning in general these algorithms have
a lot of similarities between the two um the use of intrinsic objectives these information game terms is
widespread in both the use of belief based planning so all the things that you sort of touched on on the
paper so in my mind when i started out the aim was really just to construct an agent using the machinery
that would be common and um relatable to the machine learning crowd but that was consistent with the
active inference homework um and i guess the secondary goal was also to put together an initial attempt to
look at whether what needs to be put in to get some of these ideas to scale um uh with a particular focus
on you know this wasn't a biologically plausible suggestion but looking at some of the objective
functions the expected free energy at scale um i think is of interest uh rather than you know where
it's commonly looked at in these uh small discrete discrete uh teammates starting by
Daniel Friedman is going to take over facilitating this discussion about what it means to scale active
inference cool really helpful in a lot of terms that we've heard but to link together the ideas of
the variational inference with the belief and the trajectory based planning those are all really cool
things i just have a question about the at scale part so one aspect was that you introduced the
continuous state space as opposed to the discrete but is there anything else that's meant by at scale or what
what does it mean to scale in this context well i mean so i guess the scale just means is almost defined
in relation to what is currently uh common in the active inference literature which is where your entire
world is often designed by four or five states um and there's transitions for so this paper um presents a
framework that can be applied to you know observations of um you know 10 000 100 000 uh and so your state
space or your observation space is much larger um so that's what i meant by by scale is is putting
forward a framework that could be applied to uh high dimensional tasks and the ones that we aren't
concerned there's also a second thing which is not really captured in the word scale but also the
complexity of the complexity of the dynamics um so some of these tasks actually have quite a small
state space you know four or five but the complexity of their dynamics requires um large models of a
number of parameters to learn um so there's kind of a scaling aspect and there's scaling in the space of
complexity of your balance cool very interesting stuff and i also found it interesting there's
the scaling dimensionality then there's the introduction of continuous state spaces not just
discrete and then often as machine learning people might use the word scaling to mean it's about the
number of observations the size of the data set um and that relates to like the compute scaling
relationship as you add uh when you double the data set input is it the same amount of training
time is it twice as long is it four times as long is it four thousand times as long and um so really
interesting because there's also the scaling in terms of the understanding in the world and
people talk about scaling and innovation and entrepreneurship and how do you scale a solution
so there's a lot of parallel meanings and a fun and concise title because uh you know that the
finding isn't going to be in the title there isn't just a simple way that says oh this protein does
this in this species we're talking about developments in a modeling framework but we also want to be
specific about what those advances are and how they relate to systems even first and then anyone who wants
thank you hi i'm steven i'm based in toronto i i do a lot of work with participatory theater and
community development and i'm researching how social topographies can be used across scales i'm just
curious because i know that the scaling question has been maybe looked at more from a philosophical
perspective in the kind of active inference so what this paper really helped me do it or helped me was
it like broke that fear of questioning the kind of these models because the big like people like yourself and
um annual and that are saying look there's a challenge here in the scaling like this stuff is
being kind of used at these low dimensional spaces and basically it showed like a gap in the literature
in terms of how to action that which kind of helped me because it sort of gave me a bit of permission to
say okay it's okay there's a gap there and it's not that i just don't understand everything it's just not
easy to scale and i think this paper was the first one to explicitly say that because all the other
papers tend to talk about yes we know how to scale but in a philosophical way but this is like okay well
this is the problem from a practice perspective cool just one note on that if anyone else wants to raise
their hand i really love this idea where there's the gap in the literature and there's there's a billion
gaps on literature um it's about which ones are salient and fundable and relevant so there's many
gaps in literature and then when we find that gap which is often very niche like in a phd and i thought
wow this data set has been collected from this ant species but not this other ant species there's a gap
in the literature we don't have this data set on this ant species and then seeing that as a opportunity
and something that's okay even if it's not your traditional field of study it's okay because
you're at the edge like at the gap with us talking to the author and talking through the equations but
this is what it looks like to look across the gap and try to connect because somebody else has identified
it as a research question or maybe you have alec yeah i just wanted to comment on that as well and
entirely agree with what you're saying um to come to maybe the defense of uh the existing literature on
active inference i think it's viewed a little bit or this maybe it's just me interpreting what they're
saying but um but maybe that the problems that they're um testing their agents in uh for instance
something like the teammates are actually viewed uh as quite complex in a different dimension so
a lot of these reinforcement learning tasks stuff like atari uh most of atari most of you know the stuff
where you're already pushing to get state-of-the-art results with a huge amount of compute and deep
mind uh computing links there they're often you can often get by with just this model free
reinforcement learning that doesn't require any notion of beliefs or any notion of proper epistemics
you can get away with under its expression so what i think uh the active influence community
has tried to do is look at simple tasks such as the teammates that actually well you can solve them
without beliefs but are far far more amenable to being solved with a belief-based scheme and with
this directed uh expiration and uncertainty reduction um to show the kind of complexity that the framework
can come up but then you could also respond by saying that this is also thought about a lot in
reinforcement learning and uh there is the question obviously of whether the kind of uh process theories
they put forward will apply when you've got uh when you've really got the scale that the important
learning comes to do yeah let me add on to that because it's a really great point so a lot of times
what's perceived as cutting edge or modern or advanced research in machine learning i mean go check
go check the lay media and it's going to be about this many graphical processors or this size of data
set or this accuracy or this level of skill using massive data and it's very much on the performance
end and on the eking out a little bit more performance from increasingly large data sets with increasingly
large types of models but it's actually in some sense of local exploration it's locally exploring
certain frameworks and ways of doing machine learning which is just computer statistics and so what this
is like with this paper is a return to simplicity and it's a return to a slightly different way of
conceptualizing some of the parameters and how they're related and the big data just train it
bigger train it uh better is kind of like thinking that we can do x without a belief we can train on go
just by watching go and we can train the laws of physics just by watching physics we can learn language
by just watching regularities and human language these approaches um there's merit to them this isn't just
about one way being better it's just that what is being done in this paper is to take the free energy
principle and active inference which previously had made these kinds of philosophically at the very
least tantalizing claims like the relevance of a belief guided trajectory based optimization and search
taking these very fascinating ideas a little bit out of the sandbox into the next level of the playground
where now we can actually start to compete or at least compare and contrast directly with the kinds
of benchmarking algorithms that are used so maybe one day you know active inference go or active
inference chess but today we have the simple control theory parameters which is one level closer to
these kinds of use cases that are happening today one level closer than the teammates or the the three
state uh decision is it a mouse or a hawk or a cat that type of stuff we hope you enjoyed this week's
episode stay tuned for next time where we'll be moving on to discuss a new paper
