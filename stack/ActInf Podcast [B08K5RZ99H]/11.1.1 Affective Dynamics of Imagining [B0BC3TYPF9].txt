This is the Active Podcast, where we provide short clips from the Active Inference Institute
weekly live streams. If you're interested in hearing more of this material, check out
the entire live stream at the Active Inference Institute YouTube channel. The link to the
live stream is provided in the episode description. I am Blue Knight, the host and curator of this
episode, which is clipped from live stream number 11.1. This discussion will be facilitated
by Daniel Friedman and is based on the 2020 paper entitled, Sophisticated Active Inference,
Simulating Anticipatory Effective Dynamics of Imagining Future Events by Casper Hesp, Alex
Shantz, Baron Milledge, Maxwell Ramstad, Carl Friston, and Ryan Smith. Enjoy!
What would be something you would say to somebody who had never heard of Active Inference and
just what is something that it captures that other models haven't captured or something
that you'd be excited to see it head in the direction towards? Stephen, thanks.
Hi, I'm Stephen Silly. I'm in Toronto. I think the counter-intuitive nature and the ability for
things to be unexpectedly stable and unexpectedly transition is something that I don't know of
any way that traditional models of the world would show you. Because you could be like, oh,
people would normally either just take one of those moments and then that gets extrapolated for
everything. But actually, you need to follow it over time because it matters a lot.
It does. And it needs to be kind of through time in two ways. The actual agent needs to be progressing
through time. But at each time point, the agent needs to be simulating time points of the past,
present, and future. And so that's this double timeline that's happening with the model's topology
here. But it's like, right now it's 10 a.m. and I'm looking ahead to 10, 11, 12, and then it's 11,
and then I'm thinking ahead again, but I'm also looking back. And all of that is being spun out
of a generative model of a trajectory. Stephen?
Yeah, that's, and I thought it was interesting. I haven't seen
a positive valence and a negative valence. I haven't seen sort of two dynamics
mapped alongside each other simultaneously. Normally, there's just the one. So I thought
that's something that's kind of the good and bad as to, you know, it's not just about good.
It's about the blending of good and bad. I thought that's good. I mean, theoretically,
you could have loads of variants of that. You know, you could have good, the bad, the ugly.
Yep. Yep. Valence, just like an electron or a proton, you know, valence of plus or minus,
that's plus to minus, positive and negative valence. But affect is a multi-dimensional landscape.
And so that is something that could be explored in a higher dimensional way. But again, let's think
about that trading example. There's so many ways. Oh, it's an elegant trade. It's an ugly trade. It was
a clumsy one. It was a one with very much foresight, or it was a retributive trade, all these adjectives.
But then what does it boil down to? Given my preferences and my affordances, was it a good trade?
And that if your preferences are, hey, I have too much money. I'm trying to sponsor a couple people
who have less crypto than me, then a quote, good trade given that preference
preference vector might not look like a preference or a policy selected by somebody with a different
preference. So that is where agent specific preferences come into play, is you're never
going to get away from that. The agent is not doing this neutral calculation followed by a secondary step
of policy selection. The preferences for policy and for outcomes are entrenched within the kernel of this
model at every single time step. Stephen? And that gives a plausible Bayesian route to your gut feeling.
I mean, some of those emotions, like you're saying, an elegant trade might be kind of a cognitive process
and some other type of part of it might be kicking your deep, you know, there's certain times when you're
thinking about stuff and then suddenly you get a sinking feeling in your stomach, you know, and it's like,
well, that, that, that, who knows where that's coming from. But this gives a, you only get one overall
sort of gut feeling, you only get one overall sort of route to actively infer how to take action in the
world. And all these different things, they only become available to you when you maybe reflect on it
later and you have to describe what, why you had that gut feeling. Like you just mentioned,
there could be hundreds of different things all being Bayesianly integrated.
Exactly. And that's this go, no go. Hey, I'm just not feeling good about this,
this whole vacation, or I'm just feeling really great. I don't know what's behind the door number
four, but I'm feeling great about it. That valence aspect of prediction for the future is like the
highest level control summary statistic. It's like, are we going to accept this person into the college
or not? There's so many other dimensions, but it gets distilled into the choke point through
the Markov blanket of action. It gets distilled into go or no go on that specific person or that
specific policy or that specific outcome. And so that's actually the justification for the use of
valence as a simple positive to negative, even though there's so many other dimensions to affect
overall. It does get distilled into this gut feeling, which you can go into and, and, uh,
you can cognize, you can add adjectives on top, but it's sort of interesting. It's like,
is the gut feeling just positive versus negative? And when you introspect, do you get higher and
higher levels of abstracted polysyllabic emotions, or do you get deeper and deeper into your body
and into increasingly summary statistics like go, no go, um, freeze fight? These are things like go
and no go. Oh, Sasha, go ahead. Hi, my name is Sasha. I'm also in California. That's kind of what I was
thinking is, uh, with this model of valence, would, uh, a human participant, let's say, um, be able to
self-report in the similar way about, um, their valence during an experience, or is this kind of
like the, you know, hidden by the Markov blanket and, um, we can have these models to help explain
what was happening at the time, but those states might be unaccessible to, uh, people actually
experiencing this, you know, decision-making process. And, um, yeah, it just reminds me of,
I guess how people spend money and thinking about economic, um, economic decisions that, uh,
people make that are, you know, either logical or not logical and that it really, um, has little to
do with the money that we have and then the mindset that we have about the money and like how we ought to
be spending it and, um, you know, who we want to be supporting or not with our, uh, investment
decision. And yeah, it just really, uh, I know it's at such a higher level than, um, just thinking about
someone's salary. It's how they interact with the economic system and, um, what role they might play
in it. And it just, especially in the holidays, like all I can think is we're so deeply influenced by,
um, times and like season and tradition with how we choose to, uh, how and where we choose to spend
money. Right. You send money, you literally give money away to people on their birthday,
on their bio-rhythm or, you know, in the holiday season. And then also what you just said, Sasha,
it reminded me of like course graining estimates and why it's so important. If your economic estimate
that you're making is, will we have enough or not? You might be very confident that you'll have
enough. Say, I don't know the details, but I'm confident that we'll have enough or even I'm
confident we're not going to have enough and we're going to have to do XYZ policy. Okay. We can work
with that. But if you're trying to do a estimate down to the cent, you might have a very noisy estimate.
And then apparently people can get quite anxious about relatively small amounts of money that are
way up there in the big salary range. Is it going to be this number or a slightly higher or a slightly
smaller number? So there's this jockeying and uncertainty up there at the high level because
they're doing a nine figure precision estimate with a large variance. Whereas there's something to
be said for course graining and simplifying and functionalizing it and actually not just reducing
the cognitive load, but increasing the precision of our estimate, even if the state estimate is
inferior. So there's so much there to continue exploring. We hope you enjoyed this week's
episode. Stay tuned for next time when we're going to have more discussions of the same paper.
