Welcome to the ACT-INF podcast, where we will present short, digestible segments clipped
from the Active Inference Lab weekly livestreams.
If you like what you hear and you want to learn more, check out the entire livestream
at the Active Inference Lab YouTube channel.
The link to the livestream is provided in the episode description.
My name is Blue Knight and I will be guiding you through this podcast episode, which is
clipped from ACT-INF Lab livestream number 5.2.
This discussion will be loosely structured around the paper Multiscale Integration Beyond
Internalism and Externalism by Maxwell Ramstead, Michael Kirchhoff, Axel Constant, and Carl
Friston.
Daniel Friedman will be facilitating this discussion about the generative model and how it relates
to consciousness.
Here's a quote.
The generative model is a statistical construct, aka that means by people, that transcribes
the expected sensory-causal regularities in the process generating sensory states.
The generative model is used to model the set of viable phenotypic statistical relations,
such as preferences and action policies, that must be brought forth by the organism in active
inference.
In short, a model of a viable state of being for the organism.
Through active inference, internal states are tuned and this tuning changes its posterior belief,
hence the organism's best guess about what caused its sensation, that usually include its own
actions.
In other words, a generative model can be used to understand how organisms are able to track
or infer their own behavior.
And one key part there is that the best guess doesn't mean the one that's closest to reality
per se.
It means it's the most action-oriented or evolutionarily relevant guess.
So the best guess for a loud noise isn't just doing inference on the location of the noise
or on the exact type of object that caused it.
The best guess when you're doing inference on policy is actually about how the body should
change its dynamics.
And then the question that I raised here is just, how does a multiscale generative model
work in the brain or in a social group?
And can there be a generative model without action or behavior or external states being
influenced so heavily?
Maybe these are things that we can return to later if no one has any comments now.
So yeah, Steven?
Steven?
Okay.
Hi, I'm Steven.
I'm in Toronto.
And I do community development projects using theatre and immersive participatory approaches.
And one thing I'd be interested in is if you're looking at someone's generative model, like what's
the best place to look at it?
Like in a way, if I was to look at someone's physical states and how that's compatible with
their existence in the environment, is that a good read on their generative model as much
as looking in the brain?
You know, like if the states that I'm in constitute my generative model's best guess of how I should
be in the world, in a way, that is a window into what my organism-level cognition is.
I don't know whether thinking is the right term.
I'm Maxwell Ramstad.
I'm a postdoctoral fellow at McGill University.
Yeah, I mean, for the most part, it's a behavioral modeling framework.
So what you're trying to do when you're tuning your generative model is to get your behavioral
profile to align with some data that you're generating, right?
So, uh, you know, behavior on some kind of task of some sort, uh, yeah.
And it, it's the, the, the connection to the, the neuro stuff is a bit more elaborate.
We, we rely on like sort of auxiliary hypotheses and other work that kind of suggest that, oh,
these precisions are being estimated here.
These prediction errors are being generated here and so on.
So like, if you want to, you can use a fitted generative model to make predictions about
the kind of neural substrates that you would expect to be engaged in this or that task.
And that can help guide, uh, you know, fMRI and EEG experimental design to kind of probe
into like specific brain regions that you think might be involved.
And so you get into this kind of circular experimental design thing, if you want to do the, the brain
aspect, but actually these techniques are more easily used for behavioral modeling, because
you don't have to make all these assumptions about brain structure.
Yeah.
Just one comment on there.
And this was clarified by reading the SPM statistical parametric mapping textbook.
The generative models were used extensively to, uh, rather than just do descriptive statistics
on the very complicated data structure of neuroimaging, what was being, uh, done in the SPM approach
was a generative model of brain states was being used as a generative model for the data.
And so, again, that's that instrumentalism of the scientific kind that just from the purely
statistical, like, how am I going to write this paper perspective, having a generative model
or having the brain regions connected in a generative model that generates data given certain hypotheses
about how brain regions are connected, that turns out to be a lot more tractable to study.
And it allows you to do model comparisons in a very, very direct way.
And then maybe the activity of what those brain regions are doing is itself making a generative
model, a Cartesian theater or something like that.
It'd be wild and amazing if true, and also wild and amazing if the bold, the brain oxygen level
dependent signal captured that. But at the very least, and again, this is sort of retreating to the,
the, the scientific instrumentalism, at the very least, it's a way that we can investigate
the changes in the dynamics of those systems. And so.
Yeah, absolutely. Uh, I mean, and this is the duality of techniques that we use, right?
On the one hand, there's dynamical causal modeling, which as you're pointing out, Dan, doesn't assume that
the process that you're modeling is itself an active inference process, although it could.
Uh, so, you know, this is the technique that we use in fMRI data analysis, uh, for example.
And it's also the technique that, uh, has been used recently by, uh, Carl Fristen's group to model
the spread of coronavirus, uh, which, you know, you could think that, uh, you know, maybe, uh, corona itself
is an active inference type thing, but you don't need to make that assumption to use this modeling
strategy and try to extract, you know, using the, what the fMRI, what the corona, um, studies do
essentially is take a bunch of raw data, like, uh, you know, raw number of, uh, of infected, a raw
number of deaths from corona and use that as data that you're essentially trying to, uh, then write a
generative model of, right. And fit the generative model to the data, the time series effectively,
uh, to kind of extract, uh, the causal structure of the disease process in this case, that's, uh,
leading to the data that we're, uh, that we're observing. Yeah. Active inference modeling can be
combined with this, but makes the assumption that the agents that we're modeling are all performing a
kind of active inference, uh, variational inference thing.
Just to give one last comment on this generative versus a descriptive model, um, what reality
hands us, what the CSV that it hands the scientist or the images that it hands us from our sensory
observations, we could go just from the data and just identify, keep on going upstream until we have
a model of the world. And that's sort of correlation all the way down. You can say, well, it was big and
red, and you can keep on carrying that correlation between bigness and redness, but it's always just
going to be correlational. And then the other approach would be to go this back and forth between
the observations and then an actual generative model where let's just say big and red cause each other,
or there's a hidden cause that causes big and red to exist. And then through expectation, maximization,
the algorithm is a good starting point for people who want to learn more about this in the scientific
instrumentalist perspective. Um, yep. Alejandra.
Hello. Hello. Hello everybody. My name is Alejandra and I'm here, um, in Mexico. I was, I was thinking,
um, maybe it's great to say a boundary between this, um, autopoietic process in thinking in a cell,
for example. Um, when we can talk about a generative model and all of stasis processes,
um, and on the other sides, like only homostatic processes. So when you can, um, like observe a cell
and, okay, this, this, this autopoiesis, um, processes, um, are, are driven by a generative model
or they are just like a more reactive and, um, homeostatic. I was, um, thinking if, if, if there's
like a boundary or any distinction or, um, just to make, um, an inference about metabolic changes, uh, in
order to maintain this, um, like desire states or just react and, and compensate them. Um,
I don't know, but I'm, I'm quite confused. Um, um, when taking this autopoietic, uh, theory about, uh,
living things and, and then thinking about, um, generative models inside this, uh, theory. So
I, I don't know if I'm, I'm clear in, in. I thought that was pretty clear. I mean, um, so I should
like, you know, provide the, the, the caveat that, uh, most inactivists, I think,
vehemently disagree with me about this. Uh, but, uh, you know, my hot take on this is that, uh,
the free energy principle completely, uh, kind of subsumes, uh, autopoietic and activism,
meaning that everything that an autopoietic and activist can do within their framework,
we can do better. Uh, and the reason for that is that, uh, well, so autopoiesis, right. Is self
production. And my understanding at least of this for having, I consider myself a kind of reformed
and activist. This was like my main thing for a while until I, I stumbled upon the free energy
principle. Uh, so inactivists kind of start from the idea of autopoiesis, autonomy, and then kind of
work out, uh, like how it works and, uh, what you can say on the basis of, uh, you know, autopoiesis.
Um, so the free energy stuff is cool. I think because it, it explains to you how the autopoiesis
gets established to begin with. Um, I mean, I haven't written about this, but I kind of feel like,
um, like what active inference is doing is putting the adaptive loop first, right. Rather than just
saying, Hey, look, there's this Markov boundary, uh, you know, like an inactivist would, Hey,
look, there's this autopoietic boundary that's kind of producing itself. Uh, like the active
inference framework is asking, so what are, what, what is the set of processes that have to be in play
such that a boundary can be maintained over time. And then the generative model is, is really just kind
of a, it's a probability density over all of the states that are kind of, uh,
it's secluded behind the Markov blanket. And that, that basically tells you, okay, well,
so what are the values of these, uh, states behind the blanket that are allowable? So look at a very
simple, uh, example of this is, uh, so let's consider my, the boundary of my skin, you know,
as the kind of organismic boundary for a second. Well, uh, one of my internal states is core body
temperature and my generative model has a kind of normative density over this state, which says 36.5
degrees Celsius with a very small variance. And, uh, you know, when I'm detecting a discrepancy
from that kind of preferred data point, uh, I initiate action to bring myself back to that preferred data
point. So, you know, uh, it's getting cold now. So like, you know, I might put on a parka if I'm, uh,
if I'm trending in the, the kind of negative direction. Um, I mean, the point about allostasis
and homeostasis is interesting. I think it's, it's, it's, it's increasingly been worked out by
people like Andrew Corcoran and, uh, Jakob Howey. Uh, but I mean like, you know, homeostasis is all
about what I just said, right? So you have a preferred data vector and you're trying to, uh, get yourself as
close as possible to that data vector, uh, where, where that data vector is, is often going to be something
like, okay, well, my body temperature or whatever. Uh, allostasis is about the control of that data
vector. Yeah. Uh, especially in response to stress and, uh, environments that are basically frustrating
your, your, your desire for certain kinds of data. And, uh, I actually have a paper that we've been
preparing for like a year and something now with, uh, uh, Irina Arnaldo and, uh, Casper Hesp and,
and Andrew, uh, precisely on, uh, on this issue. Uh, the, the paper is about a depression as an
allostatic, uh, disorder. Uh, so the idea that, you know, if you need to continuously, uh, be involved
in an allostatic process where you're, you're, you're always away from your kind of default, uh, data,
uh, uh, uh, distribution that you would prefer, uh, then it leads to a, basically a kind of
inflammatory condition where you're kind of accumulating a chronic, uh, chronic inflammation
effectively from having to stay far away from your, uh, preferred kind of homeostatic set point.
Yeah. Um, is there still any space, uh, to reactive process, processes without, um, inference?
Uh, the one second response to this is like, well, uh, inference here just means tuning statistical
structure. So it's nothing like, uh, uh, you know, that paper, a tale of two densities tries
to make this point. I think like the, the free energy formulation doesn't really, it's
a bit counterintuitive, but it doesn't necessarily require you to explicitly compute and represent
a prediction error in the way that predictive coding might, for example, uh, if you look at
the math of it, the free energy only ever exists in the dynamics. And by that, I mean the updates,
right? Like, so you really just need a target data structure and some sensory data. And that's
enough to engage in active inference. If you're able to compute the difference between the
two, uh, yeah. And then, then it's just gradient descent. Like if you have a mechanism that's
in place that can track and keep a, like a lid on that discrepancy, then you're engaging
in active inference. Uh, like it doesn't need to be like this explicit kind of computation.
So, uh, you know, from that point of view, the, I, I, I, I, I've always kind of shocked
at the response of an activist, uh, this kind of framework, because I think it's everything
that an activist would, would want, right? Like it's, it doesn't involve explicit computation,
uh, whatever information, theoretic quantities are involved only exists in the dynamics. I mean,
you know, nice. Um, and, and just that last closing point on the metabolism and also to tie
it to semiotics. So a sugar molecule touching the tongue it's through a receptor, which transmits
through neural signaling that sweetness, and that might elicit in a reactive way, the secretion
of insulin, but also insulin gets secreted in advance of a meal, as well as in a circadian
rhythmic pattern that is adaptive over evolutionary time. And so there's this meaning making of
the sensory inputs of the, the, the sweetness of sugar. Is it necessarily related to a impending
spike? In fact, artificial sweeteners are example that the sweet taste or the activation
of that receptor doesn't necessarily entail a subsequent increase, although in our evolved
history, it did. And so there's space in that whole, uh, mechanism with the tongue and with the
blood sugar and the pancreas, there's space for reactive integration of stimuli through semiotics,
as well as for the predictive secretion of insulin in advance of a meal. So we're coming along pretty
nicely. So here, I just found some funny, you know, memes about changing your mind and mind over
matter and stuff. And the questions I put on here was first with a quote, and then two questions.
The quote was, under the free energy principle, the system's posterior belief is refined or tuned
under the generative model through a process of variational approximate Bayesian inference,
and it becomes a tight bound on the true posterior belief it aspires to. And so this sort of aspirational
way of phrasing what systems are trying to do. It's not just that it wants to change its body
temperature to be healthy, it aspires to it. I wondered, okay, well, if the body is some, you know,
if my arm is aspiring to be this length or aspiring to have, you know, this ratio of muscle to fat or
something like that, where do our conscious beliefs fit into that? And are those upstream of
our phenotype? Are they downstream? Are they themselves a phenotype? How do mental states
influence our physical states and action? I think it depends what you mean by conscious.
What do you mean by conscious? Well, so look, if by conscious, you mean a form of like reflexive access,
then what you need there is a kind of temporally or parametrically deep architecture. So by that,
I mean by temporally deep, I mean that you don't want just a generative model that anticipates the
next kind of data point that you'll be sensing, but you want the generative model that's capable
of entertaining like temporally deep counterfactual like observations contingent on courses of action.
So you might think that if a system is able to entertain, you know, possible counterfactual futures
contingent on courses of action, then it would be more conscious, right, than something that couldn't do
that. So our preferred approach recently is parametric depth. We've been exploring this since
a paper that actually was just accepted in neural computation called deeply felt affect.
And so in that paper, what we do is effectively induce a hierarchical model
that is able to make inferences about its own inferences. So by that, I mean, this model takes
at a second layer of the generative model, it takes as its data for inference, like its observable states,
the posterior state and precision estimations at the lower level.
So from that point of view, what these systems are able to do is have a rudimentary form of self-access,
right, where they are able not just to make inferences about what's causing their data patterns,
but inferences about their own inferences and how much they trust them. And so like from that point
of view, that might also get you slowly closer and closer to something like consciousness in the
access consciousness sense of like, you know, having a kind of nested or reflexive access to states of
your own being. If you're talking about phenomenal consciousness, I think all bets are off. I have no
idea.
I was wondering what people thought about how might these Bayesian posterior beliefs be related to
consciously held beliefs or thoughts. And then where might variously things like affirmations,
meditation, education, or propaganda fit into this? So all of these involve sensory as well as thought
processes. How do we figure that these Bayesian beliefs, which may or may not be consciously held,
how does that relate? Why can't we just change our mind to understanding the free energy principle or
change our mind to be different? And these memes sort of suggest that it is possible. And there's
entire industries built around telling people, if you can change your mind, you can change your life.
But what actually enables someone to change their mind so that they can change their life? And how should we
think about that in this multi-scale cognitive framework? Alejandra?
Yeah, I was reading this image that if you can change your mind, you can change your life.
Maybe I can read this sentence the way around. If you can change your life, you can change your mind in
terms in this active engagement with the world. So if you want to think differently, behave differently,
it's not just a desire, you have to do it. So then considering that cognition is relational. So all these
Markov blankets and Markov blankets of Markov blankets, so going up to your consciousness. So by bodily interactions,
I think is the only way you can change your mind and be conscious about it. So yeah.
Sure. Sasha?
Hi, thank you. My name is Sasha. I'm a neuroscience graduate student at Davis.
Yeah, I like that restatement of that fun phrase, if you can change your life, then you can change your mind.
Because that just reminds me, I mean, the reason we have all these sayings is because it is really
hard to enact behavioral change. And it shouldn't be easy to change your mind, because then you wouldn't
have learning and memory, and you wouldn't have these patterns that your life depended on.
And so thinking about what it means to change your mind or update your priors about something. Like if I want to
have a different lifestyle or exercise more or something like that, it's not just as simple as deciding that,
then you actually have to follow through. And so how to make that loop easier to complete, going from changing
your actions to then updating your beliefs. It's kind of like taking, it's like starting to take the first step
before you know which direction you're moving in.
Shannon?
I'm Shannon Brooks. I'm in South Dakota currently, but I'm usually based at the University of California.
I think this also brings in, so like Vygotsky or Piaget's work where you have your cognition scaffolded by
an external teacher role. And like once you're developed, you're not a child anymore. The scaffolding
role comes through propaganda or education or affirmations that are put forth by whatever our
sociocultural group is or whatever our social media algorithms are throwing at us. And so it's in as much
as changing your behavior or changing your life can change your mind. Also changing the way that you
interact with the particular regime of attention, like a particular social group that you engage with
or that you are nudged to engage with through interactions on social media or even just regular
news media. All sort of like nudge in less volitional ways, your like Bayesian posterior beliefs
in terms of like conscious higher level beliefs about the world.
Agreed. Well said. It's not enough just to say I'm the kind of person who runs every morning,
because if you're not running, then you're going to be not having your sensory input aligned with your
even stated beliefs. So it takes actually the action to make that connection. Steven?
Yeah, I think this is also like, I know if anyone, you know, when you walk into a cathedral,
it's like if you want someone to feel a sense of awe and start to take their consciousness up to the
heavens, you know, walk into a 400 foot high cathedral and it will do a lot to you, you know? And so
it's the way that, and it's not necessarily anyone there saying you should believe in God or not straight
away anyway. We hope you enjoyed what you heard this week. Stay tuned for our next podcast episode,
where we will get into a more technical discussion about free energy minimization.
