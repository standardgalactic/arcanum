Welcome to the ACTIMF podcast, where we will present short, digestible segments clipped
from the Active Inference Lab weekly live streams.
If you like what you hear and you want to learn more, check out the entire live stream
at the Active Inference Lab YouTube channel.
The link to the live stream is provided in the episode description.
My name is Blue Knight, and I will be guiding you through this podcast episode, which is
clipped from ACTIMF Lab live stream number 9.1.
This discussion will be based on the paper, The Projective Consciousness Model and Phenomenal
Selfhood, by Kenneth Wilford, Daniel Bennekin, Carl Friston, and David Redroff.
In today's episode, Daniel Friedman is going to take us through the benefits of the Projective
Consciousness Model.
Basically, this is just a summary of what they believe the PCM's strengths are and how
they summarize it, which is that the structure, geometrically, of multimodal lived conscious
experience closely approximates a projective three-space.
So that's like a three-dimensional space with kind of this geometer's lingo, on which
a projective transformation, I believe PGL4 is saying it's a four-dimensional projection,
projected down.
But we could hear from a geometer with a little bit more information here, or what would the
physics community notate this as?
Our model fits intuitive data, but it also helps account for other phenomena that might
seem at first unconnected, including working perspectival imagination, inferences about
the points of view and aims of others, like the intentional stance, modulo active inference,
and many peculiar phenomena associated with consciousness.
So OBE, out-of-body experience, kiatoscopy, derealization, oceanic, and mystical experiences.
It also sheds light on some visual phenomena, which we'll definitely get to, and it sounds
like there's a bunch of papes and they're probably writing more.
So if any of the authors want to share what they're thinking or doing now, that's cool.
Here is an example we talked about a little earlier, which is that when we consider, like
think about the Empire State Building, we think about it in perspective, like looking up at
the Empire State Building or just floating away, far away, so that it basically looks Euclidean
because it's far away.
But it's going to be both conceptualized independently of any particular point of view, like you could
zoom in in your little brain AutoCAD simulator and imagine yourself on the 40th floor looking
at a 90-degree angle in an I-beam, and you wouldn't have any deception that it's actually
Euclidean 90 degrees.
But then at the same time, we can naturally co-experience almost this, like looking up at
it and understanding that, no, it's still not going to look 90 degrees.
So that's what optimally allows, with this projection, the perspectival accessing of Euclidean
models of the world in memory for appraisal and updating of such models through active
sampling.
So we get to benefit from the sort of statistical reality, realism, let's say, at least not reality,
of having a model that's actually rectilinear, for example, but then also have this total
fluid projection that allows us to act and perspectively understand ourself in that space.
So there's the relative perception, and then there's that perspective, independent, objective
knowledge base, which doesn't mean it's correct.
It just means that it's about an object.
It's of an object.
It's not truth objectivity.
It's objective, like it's about this box on my desk.
And predictive geometry helps functionally connect subjectivity.
So being about the subject, that's relational, and then epistemic objectivity.
Again, not truth, just knowledge about objects, allowing us to see consciousness as a kind
of mediator between the situated organism and the objective world it inhabits.
Very cool stuff.
They also write, so active vision thus becomes like a palpation of a 3D spatial user surface
to feel the epistemic affordances that are quantified by expected free energy.
This anticipatory palpation with temporal depth requires a generative model that encompasses
the consequences of actions and their effective values.
So in some other work by Friston and colleagues where they've looked at, for example, reading
and informational foraging with the ocular motor, with the eye muscles.
And so the way that the eye scans around the page, it's not based upon maximal reward.
It's based upon the maximally informative observation that could be made.
And what is that observation maximally informative in the framework of?
Well, top-down priors about semantics.
So when somebody is coming towards you, there's like subconscious eye saccade movements that
first assess, for example, the broad category of person that it belongs to.
And then it will zoom in on different components of the face and culturally informed areas of
the face that might signal different types of things like whether there's going to be a
good relationship in the future or not.
And so it is so interesting what the authors did, which is to tie this information foraging,
optimal foraging, info foraging, info thermodynamics perspective, take it from the cybernetics where
it already had been very well entrenched and now say like, that's our experience of vision.
That's why even when your eyes are circading at the level that you're actually perceiving,
it's actually a lot smoother because our experience is sort of smoothed out over those underlying
saccades. That being said, those saccades are driven in a top-down way as a compromise with
top-down forces, let's say, by culturally informed priors. Your eyes won't know how to
scan if you don't know how to read the language. You won't know which parts of the letter are
informative, which parts of the word. But when you're fluent in the language, then we know that
like all the letters in the middle can be mixed up because you're really just doing a generative
model of the text. And that turns out that includes information about font and includes
sentence structure, all these other things. You can't understand the sentence with the words mixed
up in a different order. If the letters are in the right order, but the words are mixed,
the semantics don't allow the top-down to inform the bottom-up. So your visual foraging is bunk
because you're going to be looking at the difference between a B and a D, but you're not going to
understand what the sentence's meaning is because that's the level we're actually at.
This framing of expected free energy through projective transformation in imagination
provides a method for envisioning. How things would look, feel, or be from another, hopefully
better location and thus guide action. It's like, where would I be looking at if I were figuring out
what this word were under my generative assumptions about language? It is important to emphasize that
according to the projective consciousness model, free energy minimization is always operating as the
fundamental algorithm governing the field of consciousness and thus there's never an end to
the process as there is never in practice a solution that reduces free energy to zero, which because
it's defined as this informational distance against the non-stationary realism world, it means that
basically it's always going to be bounded by zero. And this I thought was very funny. Hegel might be
happy to know that on the projective consciousness model, consciousness is thus always somehow unhappy
even when it reaches the best possible states available to it. So this is the well-known Hegelian
dialectic of thesis, antithesis, synthesis, often shown as a loop as if it were just this runaround
rock, paper, scissor. Here, it's actually like a virtuous or a vicious spiral. And it just showing how
this semantic ordering of events with thesis, antithesis, and synthesis, it's like it never ends.
Free energy minimization, optimization, cybernetic control processes, multi-scale evolutionary adaptive
systems. They don't end. They can't take a break. There can be relaxing times, but they can't rest
in the actual like stasis. There can be stasis with respect to a certain dimension, but that's
reflected by this seething activity that actually structures the strange attractor so that the system
returns to these homeostatic preferred, expected, and optimal states. And if you prefer over evolutionary
time, something that isn't optimal or isn't functional, you're not going to exist. That model
will not exist of the statistical regularities in their niche because their preferences, the
observations they seek out will include things like toxins or jumping off of cliffs. These are not
adaptive observations, interoceptively or from a visual perspective. And so you end up not seeing
models that prefer those things. And so it's like this endless preference hunt, policy adaptive selection
stuff happening. Pretty cool stuff by the authors.
We hope you enjoyed this week's episode. Stay tuned for next time where we will be discussing a new
paper dealing with script theory.
