welcome to the active podcast where we will present short digestible segments clipped from
the active inference lab weekly live streams if you like what you hear and you want to learn more
check out the entire live stream at the active inference lab youtube channel the link to the
live stream is provided in the episode description my name is blue knight and i will be guiding you
through this podcast episode which is clipped from active lab live stream number 7.2 this discussion
will be loosely structured around the paper variational ecology and the physics of sentient
systems by maxwell ramstead axel constant paul badcock and carl friston daniel friedman is
facilitating this discussion and we will start off questioning the role of counterfactuals
in morphogenesis i just wrote down a few questions one was um i believe alejandra's question from
several weeks ago about what are some differences between simulating systems like those that can at
least apparently engage in deep counterfactuals and morphological systems and so the question rose like
okay but is the cell really doing a counterfactual analysis of alternate cell shapes it could be
in a way that the brain may be doing some type of modeling of what behavioral states could be
and then so that's the previous question that we're definitely going to return to
hear new perspectives on from anyone who wants to raise their hand and then the second set of
questions is cool where does evolution fit into all of this and so a little bit more broadly how does
this bayesian perspective play into evolution ecology development and learning because this is a
morphogenesis problem it's a devo problem and we know that eco and evo are going to come into play
with devo so how do we think about all these levels and how does figure four make its appearance in this
paper what is it relevant what does it show so any thoughts before is just about how morphogenesis and
in general higher order pattern formation happens under the variational framework so i mean we've
discussed this in previous episodes but the idea is always essentially the same it's that so what is
it to share a generative model well in the context of active inference to share a generative model means
that you share the same beliefs about the kinds of sensory consequences that follow you know the effects of
states in the world and in particular the effects of my own actions in the world so the idea is that
if we share a generative model we expect to perceive the world in the same way as a consequence of the same
kinds of things so uh pursuit pursuing on that idea if we have the same generative model then if i just do
my thing and you just do your thing we're eventually going to end up zeroing in on the same overall
pattern because we share the same expectations about the kinds of things that we should expect conditions
on the same kinds of states so if if you have a system that's equipped with like state or yeah state
dependent uh observation profiles so for example if i'm a heart cell i should expect to sense other heart
cells and to you know register blood flow and whatever whereas if i'm a brain cell then i really
shouldn't be registering blood or other heart cells at all uh so if you have these kinds of state dependent
observation uh distributions uh then you can start to see how sharing a generative model would allow
for a bunch of components to zero in on uh well first of all on a target configuration and second of all
kind of settle into a mutually coherent pattern of inference about what is my role in these higher
order uh patterns that i'm part of um yeah and so the the idea there i guess is the so this is the
the vertical stack idea that we discussed last last week uh this the the variational ecology is a
horizontal and a vertical story a vertical and a horizontal story it's a vertical story and
i understand that you have nested systems of systems of systems of systems which is what i
tend to emphasize in a lot of of my work but at every basically in between every two scales
there's a niche construction story where uh you know the the the the body at large is a niche for
the organs the organs at large are a niche for the cells and and so on thanks i'm gonna address the
evolution side and then return to this idea that maxwell was just talking about about shared generative
models because that was also very helpful so how does evolution play into this well let's imagine
this morphogenesis creature that we're watching okay it turns out that there's a lot of parameters
in this model that are detailed in the paper but it's not like all parameter combinations lead to
this solution on the bottom right only specific priors and specific mapping relationships between sensory
and action states will result in this exact kind of um light bulb shaped creature okay you can imagine
there's some arrangement that might result in a circle there's some arrangement it might the state
space is large and it might not fix upon a stable point or it might do it very rapidly what cuts through
all of these models what does model selection evolution it turns out that the wind is blowing from the
north to the south in this image and that this shape it has worked in the past and it left more
uh you know offspring that believed that that shape was the morphogenesis um position to approach
you'll just see that around it doesn't mean it's the only solution it just means it is what has
existed so this is sort of an ab initio or a computational simulation of an artificial situation obviously but
in the realized world where creatures are evolving then you find that only the organisms that have the
phenotypes that adequately reflect regularities their niche are going to be left carrying forward
and so it's kind of like wow how do the ants know to drag back this fly from 30 meters in the desert
it's like it's all they do it's all they've been doing if they couldn't do it they'd be doing
something else or they wouldn't exist it's not like you'd see an ant just struggling and failing to do
it that would be a very short-lived strategy so there's wacky stuff that happens again when the
niche is transiently misaligned with evolutionary priors or when an evolutionary prior tends towards just
like accept everything into the nest you know pull in threads or something like that but i think that's
really important to keep in mind that evolution often does model selection for us to actually find
the solutions that work bottom right and the expectation action relationships top left that
relate in morphogenesis top right through the extracellular target signal being the coordinating
mechanism in this morphogenesis example on the bottom that's development mediated what appears to be by this
basically monotonic decrease in free energy representing the utility of modeling this system
in converging to or converging towards a developmental attractor using a free energy framework well notice
that it spikes initially which is interesting so all the agents are kind of trying to figure out
what their position is and then they settle into like a mutually consistent uh group inference
um and you know this work has been recapitulated across several scales uh uh enser palacios and
colleagues have a cool paper where they do this this across three scales so they they have like a micro
a mezzo and a macro scale all premised on the same free energy functional and you get these nice layers of
like organelles within organs within an organism um cool and let me also go back to one thing you said about the
shared generative models you talked about like the neurons sort of being in their niche you know
wrapped in a specific type of glia or receiving certain types of communication at different
developmental time periods from different inputs um there's almost this um not a complete replacement
that you can do of having a shared generative model as you mentioned between the cells but it's like
they're part of a shared generative model at a higher level like through the neurons own
expectations and its own niche it subsumes and it becomes a functional part of a larger
generative model brains know things that neurons don't and so that is very naturally accommodated in
a multi-scale framework because at the level of analyzing just the two cells you'd find that they
act as if they had a shared generative model and so it would make sense oh at the level of the social
interaction it's like two people are having shared generative models like they both know how the movie
is going to play out or they both know whose turn it is to speak but then at a higher level and that's
all happening at the same time it's also like being part of a shared generative model that is the higher
level whether that's thought of as collective computation or collective cognition or distributed
intelligence whatever framework it ends up playing out as the brain knows things that the neuron doesn't
and so the social group is having dynamics that constrain and facilitate the individual level
in a way that specifically will evade the computation or the understanding of the individual so i think
that's kind of an interesting consequence of this and yeah good yeah to address uh a question that uh
was asked initially about shared intentionality um i mean so we have this paper now out in entropy uh
where we we basically argue that the free energy principle provides a formal semantics and by that we
mean that so what it is really to act on a generative model is to have an intentional relation with uh some
features of an environment that you're inferring constantly uh i mean that that's effectively what
having a generative model allows you to do it allows you to go from your sensory data and from
your architecture of priors and likelihoods to an estimation of what most likely caused uh your sensory
data um and you know intentionality kind of seems to come pre-packaged with that as in like you know
if intentionality means being uh appropriately receptive uh or to you know features of an
environment that stimulate you well then having a generative model just means being intentional in
that sense and sharing a generative model it means that you you're participating in a form of shared
intentionality so a shared way of systematically you know relating uh your observations and embodied priors to
um like patterns of behavior and so on cool one other thought and this was something that our friend
blue was talking about at our event a couple weeks ago was this multi-scale agency concept the individual
agency concept a relational edge agency then the small group and then the community and so we can't
necessarily directly experience but what can you tell somebody to participate in at the local level
that does engender this higher order adaptive process to play out and so i think it's this space
between having a shared generative model and being a shared generative model like we're going to have
shared norms so that we're going to take cognitive diversity and help that map our search space for
the critical problems that influence us all so we'll have the best search and we'll figure out the
outcomes that are going to be reflecting this kind of a distribution that we want to converge toward
that's the kind of well specified harnessing of differences within the niche because you you said
maxwell agents that see the world in the same way so i i know that you didn't mean that from the
overlapping because literally no one's you know generative visual model is going to be the exact same
but there's this question of how much seeing the same way versus basically the variation within the
niche in the exact same way of course not but it's it's a goldilocks situation because if everyone had
exactly the same predictive model then we would never see literally differences in opinions or ideas
and so when thinking about the heterodox or the novel or the informative the adaptive that space is
really about the mapping of the individual you know uh action perception loops in a sense onto this
collective level and there's uh individual states that can be healthy in one context and and unhealthy
or considered unhealthy in another context and so it's just i think it's just the beginning of thinking
about multi-scale systems from this way but then as we know people's concept about themselves and their
social world changes their behavior and in ways that are really subtle kind of what is water so just
very interesting stuff we hope you enjoyed this week's episode stay tuned for next time where we'll
be moving on to a new paper
