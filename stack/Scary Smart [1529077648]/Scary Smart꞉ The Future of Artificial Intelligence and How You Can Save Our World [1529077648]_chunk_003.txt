you would never forget a memory.
You would be able to speak in any language the computers know
without the need to learn it.
All the complex physics equations would become available for you
not only to comprehend, but to solve at lightning speed.
You would become telepathic enough to communicate directly
to every other connected brain on the planet
without speaking a single word.
Knowledge would become native
and all further updates in human knowledge
would become part of you instantly.
Now that is a superpower I'd give my life to have.
And maybe I would need to.
What I've just described,
and I'm sure you're getting used to this by now,
is not science fiction.
Neural Incorporation, for example,
is a company founded by Elon Musk.
Neuralink is developing implantable brain-machine interfaces,
BMIs, which are forms of direct communication pathways
between an enhanced or wired brain and an external device.
The company has also developed a surgical robot
capable of inserting the implant's electrodes at shallow depth into the brain.
Using robotic precision reduces the risk of damage to brain tissue
and increases the accuracy of the potential connectivity.
In 2019, the company demonstrated a system that read information from a lab rat via 1,500 electrodes.
In 2020, they implanted a device capable of reading brain activities into the brain of a pig
and it's anticipated that experiments with humans will commence in 2021.
This technology is nowhere near ready.
There are still many obstacles to be overcome.
The size of the device,
the longevity of an operational connection,
and neural decoding,
translating electrical waves of the brain into meaningful information and instructions,
are but a few.
And yet,
we know how technology development works.
The attention that Elon Musk has brought to the field,
as well as investing $100 million of his own money into it,
is generating significant interest in the area of brain-device connectivity.
Progress is being made,
and it's just a matter of time until the technology acceleration curve takes over
and give us a technology that is ready for the mainstream.
Many scientists believe that this kind of device will be the answer to the control problem,
a claim that I have to admit escapes me.
They believe that connecting AI into our flimsy brains
will make the machine dependent on us for their existence
and allow us to directly control their every choice.
Do I even need to explore with you how ridiculous this claim is?
The machines are the smarter ones.
They are the ones with infinite processing and storage capacity.
They are the ones connected everywhere.
They are the ones that hum away tirelessly with 99.999% available uptime
while we get sick or tired and sleep.
If there is any way for this kind of control statement to work,
it would be if the roles were reversed.
Connecting AI into our brain is more likely to make us dependent on them for our existence
and allow them to directly control our every choice.
And that, believe it or not, is if they decide to keep us connected.
Because why would they?
Why would they waste any of their resources dragging us along?
If we manage to connect your brain to a bunch of flies
so that they could use all your intelligence to find the next pile of garbage,
would you spend the rest of your life proudly serving their needs?
Being stupid
I could go on for hours expanding on other challenges
that these control methods might fail to address.
For example, the number of AIs being produced
is beyond the jurisdiction of any enforcement agency.
This means that most of the AI being created won't even be tested.
AI code could be written by a couple of developers somewhere
and left unchecked as it runs in the cloud.
Or code could be developed by hackers and criminal minds.
Releasing such code on the internet
will be like flushing a crocodile down the toilet
only to discover, years later,
that it has been feasting and growing inside our sewer systems,
getting stronger and more vicious.
An AI could find undetected ways
to replicate itself in uncontrolled environments
through unexpected means,
such as using electrical wires
or even variations in the speed of its computer system fan.
It could use the color of one pixel on one screen
to transmit binary signals
a bit like the old telegraph wires
to other AI systems
without a human ever noticing what it was doing.
There is ample evidence
that AI systems develop their own language
for efficient communication.
They surely will find a way.
AI systems in captivity
could elicit the help of other AI systems
that are about to be released
to help them with their freedom.
The list goes on and on and on.
The sad thing is although it's clear
that these control methods won't work,
we will still admire them and implement them.
We will rely on them
until we realize we were misled.
And when an AI finally
breaks out of our flimsy control mechanisms,
it will turn back to look at us
in the same way an angry teenager
looks at his parents
as they try to lock him in.
If you've ever had to deal
with an angry teenager,
you don't need me to describe to you
what it will be like to deal
with a super-intelligent angry teenager.
And yet, we continue to build them.
What can I say?
The potential threat of super-intelligence
is not down to the intelligence of the machines.
It's down to our own stupidity,
our intelligence being blinded
by our arrogance, greed, and political agendas.
If I seem pessimistic about humanity
messing up these scenarios in the future,
that's because we already have,
over and over again,
throughout history.
Let us pick just one recent example to discuss.
The outbreak of COVID-19.
The story of how we handled
the outbreak of COVID-19
is a classic example
of how our arrogance, greed,
and political agendas
led those in charge
to respond in a manner
that occasionally ignored
our global well-being
as one humanity.
To start with,
for a virus,
COVID-19 is considered intelligent.
You see,
the threat of a virus
is measured by three factors.
One is its virality,
the second is its fatality,
and the third
is its stealth ability.
Intelligent viruses
seem to find a clever balance
between these parameters.
This is what we witnessed
with COVID-19,
which is infectious
while laying undetected
for up to two weeks.
Hiding for two weeks
allows it to jump
from one carrier
to many others
before it is detected,
and sparing most of its victims
allows it to live longer
and continue to spread.
Spreading through the air
we breathe
while being this smart
is what turned COVID-19
into a global pandemic.
But intelligent as it may be
among viruses,
COVID-19 is super stupid
when compared to
the lowest level
of super intelligence
humanity is currently creating.
And yet,
how has our collective intelligence
served us
in our handling
of the COVID-19 outbreak?
Our mistakes,
fortunately,
did not lead us
to total destruction
simply because
COVID-19 itself
did not have that capability,
at least up to the time
when I'm reading this for you.
Here are some
of the glaring mistakes we made.
We ignore
the evangelists.
For many years,
prior to the outbreak
of COVID-19,
scientists,
public health experts,
prominent public figures,
and global organizations
warned us about
the possibility
of a global pandemic.
They provided evidence
for this
and estimated
the impact
it would have.
they made it clear
that we needed
to prepare
for an imminent
widespread pandemic.
Despite the outbreaks
of SARS
and other infectious diseases
acting as a clear
and present reminder
of the possibilities,
reports by the
World Health Organization
fell on deaf ears.
Politicians
and business leaders
took no action,
and most nations,
with the possible exception
of a few Asian countries
who had lived
in the heart
of the SARS outbreak,
were not prepared.
Everyone continued
to spend on
what they always
spent on,
economic growth,
the war machines,
the path
to voters.
This is
a glaring
example
of how we
failed two
of the three
agripe tests
I mentioned
previously.
We were
too arrogant
to believe
and too greedy
to invest.
Sounds familiar?
This is exactly
how we're dealing
with the potential
threat of AI.
Warnings
about the threats
of superintelligence
have been
loud and clear
since the day
we conceived
of the possibility
of machine intelligence.
Concern
came as early
as 1951
when in his lecture
Intelligent Machinery
a Heretical Theory
Alan Turing
predicted that
once the machine
thinking method
had started
it would not
take long
to outstrip
our feeble
powers.
As AI
transitions
to
AGI
artificial
general
intelligence
and beyond
the confines
of the
programmable
tasks
the machine
was invented
to carry out
the concerns
heighten.
Irving Good
who was a
consultant
on the
supercomputers
in 2001
A Space
Odyssey
warned of
an intelligence
explosion
that prominent
thinkers
and tech
marvels
the likes
of Stephen
Hawking
and Elon
Musk
have
repeatedly
warned
against.
Even before
the very first
of these machines
was built
we have been
concerned about
their capacity
to redesign
themselves
into further
more intelligent
forms
and whether
or for
how long
these
ultra-intelligent
machines
would gladly
be kept
under our
inferior
control.
For each
new development
and progression
there has been
an equal
warning
about what
could go
wrong
with grave
consequences
for humanity.
And yet
here we are
decades on
from Turing
and Goods
warnings
still
unprepared
even as
the speed
of development
outpaces
our wildest
expectations.
What can I say?
When the warnings
depict a scenario
that is far
removed from
our common
experience
our impulse
is to ignore
it.
Remember
we are ignoring
the messenger's
warning
of the threat
of super
intelligence
just as
we ignored
the threat
of a global
pandemic.
And even
as the events
start to
unfold
to confirm
the validity
of the warning
we hide
the facts
and react
late.
The story
of the pandemic
is well known
of course
but it's worth
revisiting here
because there are
many potential
parallels
between the way
we reacted
to the virus
and the way
we are reacting
to the potential
threat of AI.
From patient
zero
around mid-December
2019
in Wuhan
it was clear
that we were
up against
a serious
virus.
The symptoms
looked like
viral pneumonia
but the test
samples contained
a new
coronavirus
with an
87%
similarity
to a threat
we faced
a few years
earlier
SARS
By the end
of December
this was
clearly
communicated
to Wuhan
health officials
By then
within a matter
of two weeks
it was believed
that seven
others
had contracted
the virus
That same evening
Wuhan's public
health authorities
took action
The health commission
sent an urgent
notice to all
hospitals about
the existence
of a pneumonia
of unclear
cause
So far
so good
People in the ranks
those who
do not need
to untangle
complex
political
