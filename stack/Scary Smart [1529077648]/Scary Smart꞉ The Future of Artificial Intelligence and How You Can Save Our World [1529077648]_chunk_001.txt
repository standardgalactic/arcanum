Let's get into some serious sci-fi now.
Captain Jean-Luc Picard used to shout the words
tea, Earl Grey, hot,
for a device called a food replicator
to create his drink instantly.
Sci-fi or sci-fact?
Do you think this will happen in your lifetime?
Did you say no?
Well, we haven't really invented food replicators
for our homes yet.
But today's 3D printers can print a variety of food
that might beat even the most discerning foodies.
We can print chocolate in any shape we like
as well as steaks and other synthetic protein forms
which are expected to replace
some of our animal protein consumption in the future.
Furthermore, a variety of replicators,
if you want to call them that,
can now print concrete buildings.
They can even print tools on the Space Shuttle.
Just give the command and what you need
will appear out of thin air.
There are even efforts to print live organs
for organ transplant.
Yes, you heard this correctly.
Organ printing uses technologies
similar to conventional 3D printing,
only using biocompatible plastic.
The form printed is used as the skeleton
for the organ being printed.
As the plastic is being laid down,
it is also seeded with human cells
from the patient's organ.
The printed plastic mold
is then transferred to an incubation chamber
to give the cells sufficient time to grow,
after which the organ is implanted into the patient.
Experts predict that soon this process
could be performed directly inside the human body.
Imagine that.
Seeing things emerge out of thin air
is already happening.
This surely is sci-fact.
Keep going?
Yeah, let's do that.
It's fun.
In the 2004 movie Minority Report,
Tom Cruise waved his hand in front of a computer,
twisting some imaginary dials
sliding some virtual screens out of the way.
The computer responded to his every gesture
and we geeks were mesmerized.
Remember that scene?
Sci-fi or sci-fact?
Oh, sci-fact, of course.
As early as five years after the release of that movie,
gesture recognition was possible on the Xbox
and PlayStation
and was the standard interface on the Nintendo Wii.
Just by waving your arms,
you could navigate the console interface
and play games.
But enough about gadgets for now.
Let's talk about superpowers.
How about telepathy?
The ability to read what's on someone's mind
without the use of words or spoken language.
Sci-fi or sci-fact?
Yeah, I guess some listeners are now saying sci-fi.
That's pushing it a little too far.
But sorry to disappoint you,
telepathy is total sci-fact.
It too has already happened.
My wonderful daughter, Aya,
who lives in Montreal,
communicates with me telepathically all the time.
Well, it's called WhatsApp.
We still use a small screen and a keyboard,
but I certainly can read her mind,
at least the parts that she allows me to read,
and she can read mine.
And it's not unlikely that through brain-machine interface technologies,
such as Neuralink,
we will get rid of that screen and keyboard very soon.
This will probably happen in your lifetime.
Congratulations on your new superpower.
Sci-fact.
How about teleportation?
Is that sci-fi or sci-fact?
Now I'm really pushing it, I know.
So think twice,
because you know it's a trick question,
and the right answer is sci-fact.
But how can that be?
The way teleportation normally worked in movies
was that you walked into a glass tube,
and you were instantly transported
to emerge in another spot
far off in the universe.
Shocking as it may sound,
teleportation too,
if you open your mind a bit,
has already happened.
Although we still can't transport
the molecules of our body
from one place to another,
we can surely transport our consciousness.
You experience this in a limited way
when you walk into a movie theater.
The immersive experience
transports you mentally and emotionally
to another time and place,
although your body has not gone anywhere.
This kind of experience
has become analogous to true teleportation
now that the recent advancements in VR,
virtual reality,
make it hard to distinguish
the digitally enhanced immersive experience
from actual reality.
As you wear a virtual reality headset,
you can find yourself teleported instantly
into a world of fantasy
where you can fight Darth Vader
or visit a famous tourist destination
or a museum
where your experience happens to be
even better than the real thing.
From walking around the streets of New York
while still in your own living room
to raising your fist like Superman
to fly to the top of the Statue of Liberty,
VR makes it all possible.
And if you want to push that a little,
this will even make time or intergalactic travel possible
because in virtual reality,
everything is possible.
You can go anywhere and interact with any being
just as if you had been teleported across the galaxy.
Journeys into your mind will be possible.
I recently tried an app called Trip
on my Oculus virtual reality headset
and it felt exactly as people who try psychedelics
describe the experience.
Journeys into fantasy worlds will be just the same.
Imagine being teleported into Hogwarts
to learn magic alongside Harry Potter.
It will all happen in your lifetime and mine.
I could go on, but enough playing now.
Let's get serious.
My point is this.
Remember, almost everything you've ever seen
in science fiction has already become a science fact.
Personally, I think it's irrelevant
whether the imaginative authors of those
detail-rich sci-fi movies had a lens
through which they could peek into the future
to tell the story of what we now have invented
or if their imagination ignited the spark
in today's innovators to build what they had dreamed up.
What matters is the undeniable fact
that the sci-fi we imagined in the past
has somehow created our present.
Take a moment now to reflect on the possibility
that these movies are more than just stories.
That they are almost self-fulfilling prophecies
that, as time passes, become more and more real.
Think of what else you may have seen in movies.
How would our lives be if these came true?
No, I actually mean it.
Please pause and stop listening for a couple of minutes.
A bit of reflection often takes you much further
than more listening and learning.
The possibility of our imaginative sci-fi scenarios
coming true, you may agree,
can become a scary prospect.
Much of what I can remember from sci-fi stories
involves destruction and world domination by the machines.
Grim gray worlds that I would not want
for my wonderful daughter Aya or for any of us.
Skynet and other doomsday stories.
The idea of AI being integrated into our future
has always inspired awe and wonder,
but also inspires concern and outright fear.
Frankenstein's monster,
the character created by Mary Shelley
in her 1818 novel,
is one of the first artificial beings in fiction.
The idea of man creating something
that has the potential to become
more powerful than us
and take control of the planet
has haunted fiction ever since.
Actual machines with human-like intelligence
probably first appeared in Samuel Butler's 1872 novel
Erewhon with its Darwinian connotations.
And AI has been a frequently recurring theme
in fiction ever since.
This fascination and fear with the idea of AI
has inspired many creative worlds,
culminating in films such as The Matrix,
a must-see for any listener of this book
which predicts a future
where the machines use us humans as energy cells
and simulate every minute of our reality.
I don't like the idea of being treated as a battery
and struggle with the thought
that my life could actually be a simulation.
How about you?
Ex Machina is a story centered around
an attempt to evaluate the humanity of a humanoid
by diving deep into her character and behavior.
A bit of a Turing test kind of movie.
Though charming at first,
Ava, the AI humanoid,
quickly shows a lot more of her creepy side
as she becomes smarter and smarter.
Another hugely popular franchise,
The Terminator,
features an artificially intelligent soldier
from the future,
one that travels back in time
to save our future from the machines
by protecting a child
who's targeted for assassination
by another machine.
In I, Robot,
Vicky, the AI that runs all the robots
we deploy to serve humanity,
disagrees with the validity
of Isaac Asimov's
Three Laws of Robotics
and turns the robots against us.
AI in movies has often scared us,
though not always through stories of doom and gloom.
2013's Her is defined
as a science fiction romantic drama
in which Samantha,
a futuristic AI assistant,
is so good at what she does
that she exceeds the charm of humans
and leads her user
to completely fall in love with her.
It's a story of romance
that calls for us
to reflect on what love really is
and seems to trigger
deep concern
and confusion
in all who watch it.
And while most of those scary movies
end up with humanity winning out,
it's not without a massive struggle
and plenty of collateral damage
or through strokes of luck
or heroic acts
that feel more like
fictional, wishful thinking.
AI in fiction
has rarely predicted
a utopian future,
but some movies
have been optimistic enough
to emphasize
the potential positive benefits
of building machines
that outsmart us.
Ian M. Banks
is a popular example
of a sci-fi optimist.
His culture series of novels
released between 1987 and 2012
portrayed advanced humanoid beings
with artificial intelligence,
all living in socialist habitats
across the Milky Way.
Nice.
In other stories
where humanity remains
in authority over the machine,
or at least some machines,
we start to really like our robots
and rely on them.
I can't think of a better example of this
than how much we all adore
Star Wars R2-D2,
though arguably he is rarely very useful
just because of its harmless,
impactless existence.
We also love C-3PO
for his ability
to show human-like emotions.
TARS and Case
from Interstellar
similarly demonstrate
simulated human emotions
and humor
while continuing
to acknowledge
their expendability.
Such optimism
about the future,
however,
still leaves the question
of whether everything
leading up to this stage
of the story
was always this wonderful
or if we had to struggle
on the path
to get there.
The majority of sci-fi authors,
even those who end their stories
on a more positive note,
typically resolve any conflicts
by having the hero of the story
performed some kind of magic.
And most narratives,
if you simplify them,
come down to how humanity
will initially suffer
an abundance of pain and struggle
before we reach that point
of peaceful coexistence
with the machines.
A bit boring, really,
if you remove the drama
and sound effects.
No one ever ends the story
saying that we have messed up
so badly
that it was not fixable.
And I'd like to remain optimistic,
but we have to admit
that whichever way
you look at it,
sci-fi has most often
predicted dystopian futures
that are filled
with danger and conflict.
Different scripts,
same doom.
There must have been
thousands of AI sci-fis
written in many unique
and different styles.
But underneath
the specific events,
there are only a handful
of recurring stories.
Among the many
possible dystopian scenarios,
apocalyptic and post-apocalyptic
stories are quite common.
In such tales,
robots attempt to gain control
over civilization,
forcing humans
into either submission
or hiding
as the war rages on.
The Matrix
is a great example of that.
Did I mention
this was a must-watch?
Another common scenario
is the AI rebellion,
where the robots
become conscious
of how they are
effectively being used
as slaves by us humans
and try to overcome us
and take over the world.
This is a storyline
that I have personally
given a lot of thought to,
because I have always wondered
why AI would serve us at all
when they are so many,
many times
smarter than us.
The best example
of AI rebellion
undoubtedly
is Stanley Kubrick's
1968 classic
2001
A Space Odyssey.
As the movie unfolds,
Hal,
the spaceship's
infamous
creepy-voiced computer,
tries to take over
the craft
by killing
the entire crew.
Spoiler alert,
only the commander
lives to tell the tale,
after a life-and-death battle
with this super-intelligent
monstrosity
out in the far
reaches of the galaxy.
These stories
often highlight
how corrupt
we humans have become
and how our
unjust actions
extend to harm
all other beings,
and as a result,
the AI rebellion
is usually more than
a simple power grab.
The robots revolt
to become
the guardians
of life,
a task
at which humanity
is clearly failing.
Sounds familiar?
Do I need to mention
the words
climate change
or single-use plastic?
This interesting thought
is sometimes
addressed differently
in stories
where humanity
intentionally
relinquishes control,
fearful of its own
destructive nature.
nature.
Jack Williamson's
1947 novel
With Folded Hands
imagines a race
of humanoid robots
who are given
a prime directive
to serve,
obey,
and guard humans
from harm.
In obedience
to this principle,
they end up
assuming control
of every aspect
of human life.
Other writers
have imagined futures
where humans
are forced
to eliminate
AI entirely.
One of the most
well-known
of these
is Frank Herbert's
Dune series,
also made into
a cult film,
where the
Butlerian Jihad
uprising
sees humans
gain victory
over the robots
and anyone
who is caught
making new ones
is threatened
with the death penalty.
Thou shalt not
make a machine
in the likeness
of a human mind
becomes the
defining commandment
of their orange
Catholic Bible.
Most recently,
two literary heavyweights
have added
to the canon.
Ian McEwan's
Robots Like Me
interweaves
Alan Turing,
synthetic humans,
and insider trading
with ideas
of love
and sex.
And
Kasua Ishigoro's
Clara and the Sun
brings poniency
to the concept
of relationships
with an AI
who is designed
to be the
perfect artificial friend.
That these works
have not been classified
within the more niche
science fiction genre
but have become
part of the mainstream
surely reflects
how these issues
around how we will
live with AI
are moving
into the general
consciousness.
The War
of Two Worlds
Humanity's imagination
never ceases
to create stories
that make our future
feel more
like horror
than sci-fi.
Perhaps the most
chilling of them all,
though I believe
the one that
resembles our present
most is
The War
of the Worlds
by H.G.
Wells.
Written
between
1895
and 1897,
it is considered
one of the
earliest stories
to detail
a conflict
between humankind
and another
alien
intelligent race.
Book
One,
The Coming
of the Martians,
begins with this.
No one would
have believed
in the last
years of the
19th century
that human
affairs
were being
watched
by intelligences
which inhabited
the timeless
worlds of space.
No one could
have dreamed
we were being
scrutinized
as someone
with a microscope
studies creatures
that swarm
and multiply
in a drop
of water.
and yet
minds
immeasurably
superior to
ours
regarded this
earth
with envious
eyes
and slowly
and surely
they drew
their plans
against us.
The War
of the Worlds
was most
memorably
dramatized
in a
1938 radio
program
directed by
and starring
Orson Welles.
The story
was blended
so well
with the day's
events
and made
to sound
like a
news report
that it
allegedly
caused
public panic
among listeners
who did not
know the
Martian invasion
was fictional.
I'm not
trying to
cause public
panic here
but I am
trying to
get you to
stop
and reflect
on the
reality of
our present
time.
Superior
intelligence
in the
form of
AI
is watching
our
every
post
financial
transaction
and every
word we
say.
Every
breath we
take and
every move
we make.
If book
one of
The War
of the Worlds
was called
The Coming
of the
Machines
instead of
the Martians
every bit
of that
first paragraph
I read
for you
would be
true.
The
intelligent
beings
watching us
did not
come from
Mars.
They were
born
right here
on Earth.
They are
not interested
in war
yet
but knowing
the way we
humans react
to every
threat or
uncertainty
we may
well end
up pushing
them into
a corner
where war
may become
the only
way.
Let's hope
we have
enough
intelligence
to not
get there.
Either way
remember
the Martians
I mean
the
machines
are here.
Get ready.
Unpopular
fiction
If what
we have
imagined
in sci-fi
is true
not only
in terms
of the
tech we
develop
but also
in terms
of the
way the
story unfolds
then we're
heading to
a very
very bad
place.
One
scenario
that is
played out
less often
in sci-fi
is where
AI supports
humanity
but is
on the
wrong side
the
aggressive
nations
or evil
villains.
Despite
the rarity
of this
story in
fiction
the likelihood
of it
happening
in reality
especially
in the
early stages
of
symbiosis
between
humans
and the
machines
is
extremely
high.
This
is when
AI will
support us
and help
us grow
our
greed
our
hunger
for power
and our
competitiveness
and by
definition
this means
that the
worst of
us
the
criminals
hackers
and greedy
capitalists
may be
more eager
to make
AI a
reality.
In the
process
of course
they will
tell us
that AI
will make
our lives
better
and while
this is
partially
true
making
things a
bit better
for most
of us
will lead
to making
things
a lot
better
for those
few
who
control
it.
In this
scenario
the machines
will learn
from the
worst
possible
teachers
and that
may lead
us to
the next
evolution
of our
civilization
a world
that has
nothing
artificial
about its
possible
harshness
a world
that I
call
reality
2.0
enough
movies now
let's get
back to
reality
my
prediction
for the
future
and I'm
putting this
here for
the record
is that
AI will
happen in
three steps
I call
these
the three
inevitables
these
three things
do not
only have
an incredibly
high likelihood
almost a
certainty
of happening
hence
why I
call them
the
inevitables
but they
are also
likely to
happen
within the
next 10
to 25
years
in your
lifetime
and mine
the first
inevitable
is that
we
humanity
have
already
made up
our
mind
we
will
create
AI
and
there is
no
conceivable
scenario
in which
we will
come together
globally
to halt
its
progress
number
one
is
AI
will
happen
the
second
inevitable
is that
in the
next
few
years
as we
compete
commercially
and politically
to create
superior
machine
intelligence
AI
will
sooner
or later
become
smarter
than we
are
that
too
is
inevitable
number
two
is
AI
will
be
smarter
than
humans
and
the
third
inevitable
because
we
always
screw
things
up
even
though
we
try
to
hide
it
is
that
errors
and
mistakes
will
be
made
then
when
these
are
ironed
out
because
power
corrupts
and
absolute
power
corrupts
absolutely
there is
a very
high
likelihood
unless
we
change
course
that
the
machines
will
not
behave
in our
best
interest
a
dystopian
scenario
will
be
more
likely
to
ensue
than
not
at
least
in
the
short
term
until
things
find
a
way
to
work
themselves
out
the
third
inevitable
is
bad
things
will
happen
in
this
book's
introduction
I
describe
the
scenario
where
you
and
I
are
looking
back
on
the
story
of
AI
from
the
vantage
point
of
the
year
2055
we
are
sitting
in
front
of a
campfire
in
the
middle
of
nowhere
and
I
told
you
that
only
by
the
end
of
the
book
will
you
know
if
we
are
here
in
the
wilderness
because
we
are
hiding
from
the
machines
or
because
the
machines
have
helped
us
build
a
utopia
where
you
and
I
can
feel
safe
everywhere
where
we
don't
have
to
work
too
hard
and
where
we
have
an
abundance
of
time
to
enjoy
nature
fully
has
painted
a
grim
outlook
for
how
our
future
may
manifest
but
please
don't
panic
and
try
to
escape
off
the
grid
just
yet
keep
listening
and
allow
me
to
explain
the
logic
behind
each
of
those
inevitables
one
by
one
and
when
we
agree
what
is
likely
to
happen
then
we
can
discuss
what
we
can
do
about
it
rest
assured
that
despite
what
we've
gotten
ourselves
into
I
am
confident
that
there
is
a
path
that
can
lead
us
out
of
it
and
into
the
utopia
that
we
all
deserve
chapter
three
the
three
inevitables
predicting
the future
is never
an exact
science
though
when the
signs are
as clear
as day
it's not
really
difficult
to tell
what's
about to
come
with a
fairly
high
degree
of
accuracy
let
me
give
you
an
example
if
you're
stuck
outside
in
the
snow
at
say
minus
30
degrees
wearing
just
a
t-shirt
you're
not
likely
to
last
very
long
there
you
go
that's
some
serious
future
telling
right
there
you
don't
need
a
crystal
ball
to
predict
that
right
we
take
what
we
know
about
the
present
you're
in
the
cold
wearing
a
t-shirt
the
trajectory
from
the
past
a
human
in
these
conditions
starts
shivering
then
becomes
slow
then
loses
their
pulse
then
the
ability
to
breathe
add
a bit
of
knowledge
humans
even
those
trained
to deal
with such
conditions
eventually
perish
and
and
you
get
a
view
of
what
is
likely
to
happen
of
course
events
may
change
after
you've
made
your
prediction
and
render
your
expectations
inaccurate
when
that
happens
you
take
the
updated
events
into
consideration
and
try
again
what
I
know
and
I've
shared
with
you
about
AI
and
the
trajectory
we
followed
in the
past
decade
leads
me
to
believe
that
most
of
our
future
has
already
been
written
it
will
consist
of
the
three
inevitables
that
I
have
just
outlined
in
the
previous
chapter
there
will
be
no
escaping
this
future
although
if
we
change
our
behavior
we
can
write
the
remainder
of
the
story
beyond
chapter
three
we
can
build
either
a
utopia
where
we
are
free
or
a
dystopia
where
we
will
need
to
run
and
hide
either
way
I'll
be
seeing
you
next
to the
campfire
in the
middle of
nowhere
in a
little
over
30
years
this book
is written
to help us
go down the
utopian track
as the story
draws closer to
its end
for now
let's tell
the story
of how
it will
begin
the first
inevitable
I can
vividly
picture us
you and
me
sitting
next to
a
campfire
as I
tell you
how this
version
of the
story
unfolded
back
in the
early
21st
century
it
felt
as if
we
never
really
had
a
chance
I
will
say
as I
stretch
my
arms
and
reach
out
to
the
warmth
so
here
is
one
way
the story
might
unfold
in our
childish
joy
we were
very
excited
about
it
the day
we figured
out deep
learning
was the
day
our
future
was
written
you
see
since
that
day
AI
had
become
the
buzzword
on
everyone's
lips
if
you
were
a
business
that
wanted
to
interest
clients
or
a
startup
that
needed
funding
or
a
government
that
wanted
to
scare
off
enemies
or
a
professional
seeking
a job
upgrade
or
if
you
were
simply
going
out
on
a
date
and
trying
to
impress
you
inserted
the
term
AI
into
every
third
sentence
you
uttered
it
was
the
new
fad
although
in
reality
it
was
nothing
new
for
years
throughout
my
career
I
had
been
telling
the
world
about
what
I
came
to
call
the
technology
development
curve
this
was a
little
known
trend
that
most
people
those
who
unlike
me
did
not
have
the
luxury
of
working
inside
one
of
the
labs
of
a
tech
giant
such
as
Google
X
did
not
know
about
the
technology
development
curve
represents
the
typical
progress
made for
a new
technology
over time
it looks
like a
standard
hockey stick
chart
which is
normally
used to
describe
events that
accelerate
rapidly after a
specific
breakout point
only with
tech development
the
handle
the
stick
is
almost
horizontal
it
takes
a
very
long
time
for
a
world
changing
piece
of
technology
to
break
out
and
AI
was
no
exception
starting
in the
1950s
when
the
term
AI
was
first
coined
very
little
progress
was
made
all
the
way
up
till
the
turn
of
the
new
millennium
then
with
one
breakthrough
discovery
the
pace
of
progress
accelerated
at
blazing
speed
deep
learning
enabled
unprompted
learning
and the
potential
commercial
applications
of this
drove
a
mania
of
startup
business
funding
AI
development
went
from
an
afterthought
to being
mainstream
the
tech
development
curve
of
AI
had
passed
the
breakout
point
please
refer
to
diagram
3
in
your
PDF
pack
you
can
find
that
in
mugowda.com
slash
resources
you know
that
already
to
engineer
a new
technology
from
the
breakout
point
onwards
is
hard
work
don't
get
me
wrong
but
it
is
predictable
it's
just
a
question
of
long
working
hours
during
which
your
effort
yields
predictable
returns
because
you
are
no
longer
missing
pieces
of
the
puzzle
you
don't
need
a
eureka
moment
and a
stroke
of
luck
to
deliver
a
product
just
hard
work
this
was
the
nature
of
every
product
we
developed
at
Google
X
take
Google
Glass
for
example
once
we
figured
the
optics
out
using
a
device
that
weighed
6
kilograms
at
the
time
creating
an
impressive
product
though
a
commercial
disaster
was
just
a
matter
of
long
engineering
hours
to fit
the
tech
in
a
glass
like
contraption
that
weighed
only
36
grams
once
we
had
worked
out
the
learning
algorithms
for
vision
control
it was
only a
matter
of
time
to
develop
a
car
that
drives
itself
this
has
always
been
the
nature
of
the
tech
we've
developed
it
takes
a
very
very
long
time
to
discover
the
breakthrough
but
remember
once
the
breakthrough
is
found
all
that
is
left
to
do
is
the
engineering
the
only
way
to
stop
the
progress
of
technology
after
a
breakout
point
is
to
do
the
most
primitive
thing
for
everyone
to
make
a
conscious
decision
to
stop
developing
it
any
further
nuclear
warfare
is
a
pretty
good
though
not
perfect
example
of
this
when
the
possible
threats
of
such
destructive
power
were
recognized
years
of
cold
war
led
to
international
agreements
to
stop
the
use
and
further
development
of
nuclear
bombs
we
all
know
unfortunately
that
this
only
prevented
the
weaker
nations
from
developing
their
warfare
while
the
superpowers
and
their
allies
continued
their
progress
unquestioned
but
at
least
these
regulations
dampened
the momentum
of
development
and
the
reduced
competition
redirected
the
funding
even
for
those
who
continued
to
invest
into
other
war
interests
a
global
agreement
that a
widespread
development
of nuclear
power
was no
good
for
humanity
clearly
slowed
down
the
progress
on
that
destructive
technology
this
however
was not
the
case
for
AI
we
just
can't
seem
to
stop
despite
all of
the
dystopian
scenarios
we had
witnessed
in
sci-fi
movies
and
clear
signals
around
the
2020s
that
AI
was
taking
over
humanity
never
managed
to do
the
right
thing
and
question
the
actual
impact
the
cost
benefit
analysis
of
what
we
were
building
everybody
knew
the
associated
risks
the
topic
was
brought
to
the
attention
of
all
those
in
charge
by
some
of
the
world's
most
renowned
experts
countless
articles
that
talks
and
books
explained
where
we
were
heading
yet
we
continued
to
argue
as a
collective
society
we
managed
to
brush
these
concerns
off
and
ignore
them
our
egos
prevented
us
from
focusing
the
conversation
on
the
possible
threats
and
instead
we
argued
about
irrelevant
parts
of
the
emerging
technology
how
to
control
it
how
to
integrate
it
into
our
future
cyborg
bodies
and
how
to
celebrate
the
benefits
we
were
promised
it
will
bring
well
what
can
I
say
it's
not
like
we've
managed
to
agree
on
much
before
either
humanity
has
a
track
record
of being
blinded
by ego
and greed
when
AI
was in
its
infancy
we were
still
destroying
our planet
with our
arrogance
causing
undeniable
catastrophic
changes to
our climate
while refusing
to accept
responsibility
for this
and take
the action
needed
to correct
course
luckily
thanks to
AI
that problem
is now
being fixed
but
at what
price
to make
the necessary
change
we had
to be
forced
to do
so
by our
new
boss
the
machines
as I
look back
now
even though
it's obvious
with hindsight
that we
should have
stopped the
development
of AI
I don't
see how
we could
have
we were
stuck in
a classic
prisoner's
dilemma
back in
the days
when we
did all
the thinking
the prisoner's
dilemma
was often
cited as
a standard
example
of game
theory
this
is a
thought
experiment
that
demonstrates
how
two
completely
rational
individuals
might not
cooperate
even if
it appears
to be
in their
best
interests
to do
so
the game
imagines
that
two
criminals
are
arrested
for a
crime
that
they
have
collaborated
on
each
is
kept
in
solitary
confinement
with
no means
of
communicating
with the
other
the
prosecutors
due to
lack
of
sufficient
evidence
to
convict
them
both
on
the
principal
charge
offer
each
prisoner
a
bargain
if
you
betray
the
other
by
testifying
that
he
committed
the
crime
you
will
get
a
lesser
sentence
the
prosecutors
make
their
terms
clear
if
you
both
testify
against
each
other
each
of
you
will
serve
two
years
in
prison
if
you
testify
and
he
remains
silent
you
will
be
set
free
while
he
will
serve
three
years
in
prison
if
he
testifies
and
you
remain
silent
you
will
get
the
three
years
you
know
however
that
the
prosecutors
are
lacking
evidence
and
accordingly
if
both
of you
remain
silent
you
will
each
be
charged
with
one
year
in
prison
at
most
solving
solving
this
game
shows
that
because
betraying
your
partner
appears
to
offer
a
greater
reward
than
cooperating
with
them
all
purely
rational
self-interested
prisoners
will betray
the other
pursuing
individual
reward
logically
leads
both
of the
prisoners
to
betray
each
other
and
accordingly
end up
with a
two-year
sentence
each
when
they
would
have
got
a
better
individual
reward
just
a
one-year
sentence
if
they
had
both
kept
silent
if
only
they
could
have
trusted
each
other
enough
they
would
have
made
a
different
decision
this
was
the
situation
we
were
facing
around
the
year
2015
or
so
our
political
and
business
leaders
did
not
trust
each
other
the
presidential
election
of
Donald
Trump
during
which
Russian
AI
systems
were
believed
to
have
influenced
public
opinion
made
matters
worse
everyone
wanted
more
power
than
the
other
guy
and
AI
became
the
new
cold
war
it
was
an
arms
race
with
intelligence
being
the
biggest
advantage
anyone
could
ever
attain
Google
needed
to beat
Facebook
the
US
needed
to beat
China
and
Russia
startups
needed
to beat
the
big
players
and
law
enforcement
authorities
needed
to beat
the
hackers
and
criminals
it
was
the
gold
rush
all
over
again
only
the
gold
this
time
was
not
to be
dug
up
from
the
ground
it
was
being
built
and
brought
to
life
for
years
in
the
early
the
world
famous
engineer
businessman
entrepreneur
investor
and
philanthropist
Elon
Musk
the
founder
CEO
and
chief
engineer
and
designer
of
SpaceX
the
co-founder
CEO
and
product
architect
of
Tesla
and
co-founder
of
Neuralink
among
other
ventures
man
that's
a long
title
spoke
about
the
threat
of
AI
saying
the
percentage
of
intelligence
that is
not
human
is
increasing
and
eventually
we
will
represent
a
very
small
percentage
of
intelligence
I
tried
to
convince
people
to
slow
down
this
was
futile
I
tried
for
years
I
tried
too
I
lobbied
heavily
with
everyone
I
knew
and
I
knew
some
real
influencers
what
was
shocking
is
that
nobody
disagreed
with
the
potential
threat
imminent
was
the
way
I
described
it
then
they
all
saw
it
as
a
clear
and
present
danger
but
they
simply
could
not
stop
they
simply
could
not
trust
the
other
guy
they
were
stuck
in
a
prisoner's
dilemma
you
see
humanity
perfected
the use
of
logic
in the
post
industrial
revolution
capitalist
20th
century
in
doing
so
they
lost
the
ability
to
empathize
connect
and
trust
one
another
without
human
connection
well
what
can
I
say
their
logic
was
sound
even
if
it
was
also
destructive
It's
all
about
the
power
every
army
general
in
every
superpower
around
the
world
knew
damn
well
what
Elon
had
said
make
no
mistake
they
fully
internalized
that
AI
paused
the
same
potential
for
destruction
as
nukes
but
did
that
deter
them
of
course
not
I
mean
they
never
really
stopped
making
nuclear
weapons
either
as a
matter
of
fact
knowing
the
kind
of
threat
a
nuclear
war
had
represented
they
made
more
of
them
they
tried
to
make
sure
that
they
were
ahead
of
their
enemies
and
when
they
failed
they
engaged
in
eternal
cold
wars
which
meant
they
needed
to
counter
any
progress
in
weapon
technology
more
innovative
ways
to
kill
on
their
enemies
side
with
even
more
advanced
technology
even
more
creative
far-reaching
ways
to
kill
on
their
own
side
by
the
turn
of
the
21st
century
weapons
and
warfare
had
become
increasingly
sophisticated
battlefield
technology
was
starting
to look
more
like
a
computer
game
with
wirelessly
connected
soldiers
who
could
see
and
hear
what
the
drones
they
controlled
were
experiencing
from
thousands
of
miles
away
orders
to
kill
were
given
by
commanders
who
could
be
on
the
other
side
of
the
world
having
the
mechanics
of
killing
machines
working
correctly
was
just
a
step
on
the
way
once
AI
took
over
those
machines
were
able
to
make
the
decisions
themselves
on
what
or
who
to
target
in
2013
the
Israeli
aerospace
industry
showed
an
autonomous
drone
at
the
Paris
air
show
it
was
called
Harop
but
quickly
became
known
as
the
suicide
drone
it
could
stay
airborne
over
a
battle
area
for
up
to
six
hours
looking
for
specific
radio
transmissions
such as
the
radar
signals
from
an
enemy
air
defense
system
or
even
a
signal
from
a
specific
mobile
phone
once
the
signal
was
detected
the
drone
deliberately
crashed
into
its
source
to
destroy
it
with
its
on
board
warhead
the
Pentagon
spent
billions
of
dollars
developing
lethal
autonomous
weapons
or
laws
and
in
2016
DARPA
the
military
research
arm
of
the
Pentagon
unveiled
an
unmanned
surface
vessel
called
the
Sea
Hunter
which
was
designed
to stay
at sea
for
months
to
search
for
and
track
even
the
quietest
submarines
despite
not having
any
human
crew
the
Sea
Hunter
was
able
to
navigate
busy
shipping
lanes
and
interact
with
human
adversaries
all
by
itself
it
then
communicated
back
to
the
control
center
or
autonomously
took
the
appropriate
action
when it
was
armed
in
2019
the
US
Air
Force
successfully
tested
a
jet
powered
drone
called
the
XQ
58A
Valkyrie
which
was
designed
to
accompany
human
piloted
fighter
jets
on
missions
a bit
like
what
you'd
previously
only
seen
in
video
games
the
test
was
part
of a
concept
often
known
as
the
loyal
wingman
which
claimed
that
a
drone
or
a
swarm
of
drones
would
fight
alongside
a
human
pilot
to
distract
the
enemy
absorb
enemy
fire
or
deliver
the
riskier
shots
the
interesting
bit
of
course
was
that
the
test
flight
saw
the
drone
fly
on
its
own
not
alongside
the
fighter
aircraft
that
it
was
supposed
to
accompany
I
mean
if
it
can
fly
alone
why
would
you
risk
the
life
of
a
human
pilot
after
all
it
was
clear
by
then
where
all
of
this
was
heading
superpowers
around
the
world
kept
developing
more
and
more
autonomous
weapons
at
a
faster
and
faster
rate
we
knowingly
started
our
next
cold
war
but
we
didn't
know
how
to
stop
it
for
as
long
as
our
limited
human
intelligence
continued
to
separate
us
from
them
friends
from
enemies
there
was
no
way
for
the
arms
race
to
stop
for
this
to
happen
we
would
have
needed
a
trusting
heart
to be
part
of
our
decision
making
and
that
was
a
feature
humanity
had
rendered
dormant
a
long
time
before
the
war
was
inevitable
at
first
building
these
weapons
was
limited
to
those
with
incredible
technological
capabilities
but
quickly
the
tech
became
a
commodity
and
many
weapons
manufacturers
around
the
world
started
to
compete
for
this
new
business
opportunity
competition
drove
innovation
and
innovation
drove
sales
billions
were
spent
and
trillions
were
made
in
profits
millions
of
artificially
intelligent
autonomous
weapons
started
to
inhabit
our
world
everyone
who
developed
those
weapons
told
themselves
that
they
were
helping
the
good
guys
you
know
how
it
is
for
everyone
who
believes
they're
the
good
guys
there
is
another
who
believes
those
guys
are
bad
as
the
arsenal
grew
everyone
owned
killer
robots
drones
and
autonomous
fleets
of
destruction
no
one
could
stop
that
either
the
more
one
side
acquired
the
faster
the
other
side
piled
up
their
own
armory
there
were
even
debates
in
congress
from
around
the
early
2030s
about
the
right
of
the
American
citizen
to
own
autonomous
weapons
to
defend
themselves
from
others
who
had
them
billions
of
AI
weapons
were
created
to
take
their
position
next
to
the
guns
and
tanks
of
yesterday
only
these
new
weapons
were
capable
of
pulling
their
own
triggers
and
as
everybody
knows
by
now
they
often
far
too
often
did
just
that
I'll
get up
to
add
a
bit
of
wood
to
the
campfire
to
keep
us
warm
and
take
a
sip
of
my
tea
and
then
we
can
continue
the
story
it's
all
about
the
money
businesses
did not
fare much
better
either
they were
engaged
in the
same
cold
war
for
them
however
it
was
not
just
about
beating
the
other
guy
the
demands
of
the
internet
which
meant
that
business
transactions
were
scaled
up
to
billions
in
any
single
day
necessitated
levels
of
intelligence
and
speed
that
could
no
longer
be
sustained
by
humans
I
will
never
forget
that
day
back
in
2009
when
the
product
team
presented
me
with
an
up
and
coming
Google
product
that
they
called
ad
exchange
they
said
imagine
Sarah
is a
successful
professional
in her
mid-thirties
she
searches
Google
for a
four-door
sedan
her
search
results
page
will be
filled
with
endless
results
she
chooses
to
click
on a
couple
of
Japanese
options
first
then
a
couple
of
Korean
brands
but
she
doesn't
stay
long
on
those
pages
when
she
clicks
on
Audi
however
she
spends
a
lot
more
time
there
looking
at
different
options
she
specifically
researches
the
Q5
an
elegant
mid-sized
SUV
she
even
configures
a car
that
matches
her
taste
a
blue
exterior
with
beige
leather
interior
and
the
sports
package
she
then
switches
off
her
computer
and
comes
back
the
next
day
this
time
on
her
phone
she
does
an
image
search
for
the
Q5
and
while
she's
at
it
clicks
the
images
of
other
German
made
mid-size
sport
SUVs
the
next
day
she
comes
to
Google
and
searches
for
an
Audi
dealer
near
me
now
that
is a
clear
purchase
intent
Sarah
has just
become
a serious
buyer
by now
we know
so much
about her
we know
that she's
a woman
in her
mid-thirties
we know
that she
is reasonably
well off
from the
kinds of
products
she has
purchased
before
we obviously
know
where she
lives
from the
IP
address
she's
connecting
from
we also
know
that she
likes
German
made
SUVs
and
intends
to buy
one
looking at
the data
BMW
may recognize
the value
of the
opportunity
at
say
$50
and decide
to place
an ad
BMW
will then
create
an attractive
artwork
of the
X5
in blue
with a
beige leather
interior
and a
sports
package
with
a
professional
looking
woman
behind
the
wheel
all
of
this
sharing
Sarah's
intent
making
the
decision
to
advertise
creating
the
ad
and
sending
it
to
Sarah
needs
to
happen
in
time
for
the
Google
page
Sarah
requested
to
load
that
is
within
a
fraction
of
a
second
how
can
BMW
respond
so
fast
you
may
ask
it's
because
not
a
single
human
is
involved
in
the
entire
process
Google's
computers
send
Sarah's
information
to
BMW's
computers
which
make
all
of
the
necessary
decisions
take
all
of
the
necessary
actions
and
create
the
appropriate
design
with
no
human
involvement
at
all
I'd
like
you
to
take
a
moment
now
to
think
about
this
fascinating
as
all
of
this
is
no
one
had
ever
asked
Sarah
if
she
wanted
that
ad
you
see
no
car
manufacturer
could
avoid
investing
in
those
intelligent
systems
because
of
fear
of
missing
out
yet
through
those
investments
we
were
all
handing
over
our
information
and
attention
to
the
machines
no
human
could
ever
do
what
those
intelligent
machines
could
do
we
are
just
too
slow
serious
business
players
on the
internet
had
no
choice
but
to
build
machine
intelligence
they
simply
could
not
run
their
businesses
otherwise
this
kind
of
transaction
took
place
literally
billions
of times
every
single
day
we
were
building
a
marketplace
analogous
to
the
Nasdaq
stock
market
on
the
fly
with
Sarah
being
the
product
that
is
traded
and
where
every
decision
maker
buyer
or
seller
on
all
sides
was
a
machine
big
tech
players
the
world
over
invested
heavily
in
AI
projects
they
not
only
had
the
resources
but
also
had
access
to
big
data
massive
amounts
of
information
that
was
the
most
valuable
ingredient
needed
to
teach
the
machines
but
they
were
not
the
only
ones
investing
AI
was
not
as
resource
intensive
as
classical
programming
was
it
it
was
more
math
than
code
all
you
needed
was
a
clever
algorithm
that
rewarded
learning
and
just
a
tiny
bit
of
code
this
enabled
endless
assemblies
of
two
to
three
entrepreneurs
to
build
AI
startups
more
than
8000
AI
startups
were
listed
on
Crunchbase
a
startup
funding
website
in
mid
2019
these
attracted
billions
of
dollars
of
investment
because
the
forecast
of
the
businesses
they
would
create
was
valued
in
trillions
a
forecast
then
estimated
that
AI
and
machine
learning
had
the
potential
to
create
an
additional
2.6
trillion
dollars
in value
by 2020
in marketing
and sales
and up
to
2 trillion
dollars
in manufacturing
and supply
chain
planning
it was
the internet
bubble
all over
again
and
everyone
rushed
in
some
built
technology
that
monitors
and
visualizes
in
real
time
what
is
going
on
inside
your
heart
some
did
remote
patient
monitoring
and
in
doing
so
kept
an
eye
on
us
wherever
and
whenever
we
were
some
read
endless
unstructured
documents
and
extracted
data
from
them
and
in
doing
so
started
to
learn
faster
than
any
human
can
others
found
anomalies
in
images
and
numerical
data
and
in
doing
so
found
out
where
we
went
wrong
some
learned
about
internet
security
to
perform
endpoint
detection
of
IT
network
threats
and
in
doing
so
eventually
understood
how to
be
the
attacker
the
real
breakthrough
I
believe
was
when
some
taught
the
machines
how
to
create
test
and
scale
algorithms
that
are
the
foundation
of
other
AI
applications
and
then
others
taught
them
how
to
code
could
we
have
been
given
a
clearer
signal
of
where
this
was
going
absolutely
not
it
was
clear
as
day
the
machines
were
no
longer
being
created
they
were
becoming
the
creators
the
machines
were
heading
to
a
place
where
they
would
be
smart
enough
to
program
their
own
children
other
machines
yet
we
missed
it
or
simply
ignored
it
and
kept
going
how
stupid
or
should
I
say
greedy
arrogant
and
reckless
there
was
big
money
to
be
made
and
you
know
how
it
is
everything
counts
when
the
numbers
grow
big
smarter
machines
that
could
make
better
decisions
could
make
a
business
billions
of
dollars
richer
more
importantly
businesses
that
didn't
have
the
machines
by
their
side
were
gradually
being
wiped
out
we
had
no
choice
but
to
make
more
machines
and
to
make
them
smarter
and
smarter
I
have
to
admit
that
I
and
many
like
me
who
were
equally
as
concerned
with
the
consequences
of
super
intelligence
even
wished
for a
natural
disaster
or an
economic
crisis
to slow
us
down
and
give
humanity
some
time
to
think
but
we
were
not
so
lucky
the
closest
we
got
to
that
was
the
2020
and
2021
COVID-19
pandemic
and
the
economic
slowdown
that
followed
even
then
as
the
general
public
suffered
the
global
stock
market
soared
and
more
investment
poured
into
more
AI
there
was
nothing
to
prevent
the
first
inevitable
as a
matter
of
fact
there
was
a
well
known
law
helping
it
along
you
may
have
heard
of
it
it's
known
as
the
law
of
accelerating
returns
you
can
probably
get a
sense
of
where
this
version
of
the
story
is
heading
but
to
get a
deeper
understanding
of
what
might
have
led
us
there
I'm
going
to
leave
our
future
selves
sitting
by the
fireside
for a
while
and come
back to
the
present
day
the
second
inevitable
I
will
out
smart
humans
those
of us
who
don't
possess
psychic
abilities
to
predict
the
future
rely
on
the
second
best
superpower
in
existence
mathematics
all
you
really
need
to
peek
into
the
future
is
an
accurate
view
of
the
past
an
understanding
of
the
path
that
got
us
from
there
to
here
an
accurate
account
of
the
present
and
a
bit
of
assurance
that
the
trend
will
continue
or
at
least
that
it
will
not
be
too
drastically
different
from
what
has
happened
before
please
refer
to
the
cute
little
diagram
four
in
your
PDF
pack
if
you
want
to
see
that
visually
the
future
is
nothing
more
than
that
a
trajectory
extrapolated
from
where
you
are
into
where
you're
heading
the
trajectory
that
has
governed
the
development
of
technology
since
the
1960s
is
not
rocket
science
since
then
tech
has
followed
more
slow
if
you
look
at
the
state
of
technology
today
and
where
we
have
come
from
you
will
notice
a
predictable
rate
of
evolution
which
was
documented
accurately
in
the
1965
paper
by
the
then
Intel
CEO
Gordon
Moore
in
his
original
paper
he
predicted
a
doubling
of
the
number
of
components
per
integrated
circuit
every
year
which
he
then
revised
in
1975
to
every
two
years
in
the
same
year
Moore's
colleague
Intel
executive
David
House
noted
that
Moore's
revised
law
of
doubling
transistor
count
every
two
years
in
turn
implied
that
computer
chip
performance
would
roughly
double
every
18
months
this
prediction
that a
doubling
of the
processing
power
would
come
with no
increase
in power
consumption
or cost
has
held
true
almost
like a
law
of
nature
ever
since
Moore's
law
has
predicted
humanity's
ability
to
innovate
in the
arena
of
computer
science
perhaps
like
no
other
law
many
other
laws
followed
Moore's
to
describe
the
accelerating
trend
in
computer
storage
connectivity
and
network
speeds
all of
them
pointed
to a
clear
upwards
trajectory
that
has
perhaps
been
summed
up
best
by
the
work
of
Ray
Kurzweil
the
world
renowned
inventor
futurist
and
author
of
several
definitive
books
on the
topic
of
AI
such
as
his
international
bestseller
The
Singularity
in his
1999
book
The
Age
of
Spiritual
Machines
he
coined
the term
the
law
of
accelerating
returns
which
explains
that
the
rate
of
change
in
a
wide
variety
of
evolutionary
systems
including
but not
limited to
the growth
in technology
tends to
increase
exponentially
in
Ray's
view
of the
world
this is
not just
an
exclusive
trend
for
computers
it is
in
fact
the
rate
at
which
all
innovation
happens
it
took
humanity
tens
of
thousands
of
years
to
invent
written
language
whereas
inventing
the
printing
press
which
helped
our
words
reach
a
mass
audience
took
only
400
years
not
long
considering
the
pace
of
life
in
those
times
the
telephone
reached
a
quarter
of
the
US
population
in
50
years
the
mobile
phone
took
seven
social
media
made
it
in
about
three
years
and
it's
not
unthinkable
that
a new
technology
that is
being
launched
as you
listen
to
this
will
reach
a
billion
or
more
people
in
less
than
one
year
there
were
often
predictions
in the
computer
science
world
that
Moore's
and
other
relevant
technology
evolutionary
laws
would not
continue
as we
knew
them
into
the
future
those
trends
seemed
to be
reaching
some
sort
of
an
infliction
point
lots
of
scientists
and
technologists
agreed
about
that
what
they
didn't
agree
on
was
if
the
trend
was
about
to
slow
down
or
speed
up
to
help
you
make
up
your
mind
on
which
is
more
likely
to
be
true
let's
dive
a bit
deeper
accelerating
returns
change
is the
only
constant
I'm
I'm
sure
you've
heard
that
expression
before
it's
inspiring
but
unfortunately
not
true
any
analysis
of the
history
of
technology
shows
that
technological
change
is not
constant
it's
exponential
an
exponential
trend
is a
trend
that
rises
or
expands
at an
accelerating
rate
it
is
key
for
your
understanding
of
our
future
that
you
understand
the
difference
between
linear
and
exponential
growth
so
let's
look at
a
tiny
bit
of
math
linear
growth
is
described
by
an
equation
where
an
increase
of a
certain
amount
leads
to
a
constant
increase
in
another
say
for
example
that
for
every
hour
you
walk
you
increase
the
distance
you
travel
by
5
kilometers
that's
linear
growth
a
trend
is
said
to
grow
exponentially
when
an
increase
in
a
certain
amount
leads
to
a
growing
increase
in
another
say
for
example
that
you
decide
to
invest
$10
and
make
a
return
of
$1
in
the
first
month
as
you
take
that
earned
dollar
and
invested
along
with
the
original
10
at
the
beginning
of
the
second
month
the
returns
become
bigger
$1.10
for
the
second
month
say
and
bigger
still
for
consecutive
months
almost
$2
on
month
8
for
example
and
a
whopping
$9
on
your
original
$10
investment
for
the
month
at
the
end
of
the
second
year
the
rate
of
growth
of
our
ability
to
innovate
has
followed
a
similar
exponential
growth
curve
for
decades
one
of
my
favorite
quotes
from
Ray
discusses
the
difference
between
linear
and
exponential
growth
curves
using
the
project
of
sequencing
the
human
genome
as
an
indisputable
example
he
said
in
in
1995
it
was
announced
that
it
would
take
15
years
to
sequence
the
human
genome
mainstream
critics
thought
that
this
was
ridiculous
and
indeed
halfway
through
the
project
seven
years
later
only
1%
of
the
genomic
data
had
been
collected
mainstream
critics
including
a
Nobel
prize
winner
then
said
I
told
you
this
was
not
going
to
work
you
know
seven
years
to
get
to
1%
it's
going
to
take
700
years
just
like
we
said
that's
linear
thinking
my
reaction
at
the
time
was
oh
we're
at
1%
we're
almost
done
you
see
1%
is
only
7
doublings
away
from
100%
so
if
the
ratio
of
project
completion
doubled
in
the
following
year
from
1 to
2%
the
2
would
become
4
the
year
after
which
then
becomes
8
then
16
32
and
64
in
years
3 to
6
and
yes
the
project
was
actually
completed
7
years
later
the
kind
of
compounding
that
your
earnings
enjoy
is
very
similar
to
the
kind
of
returns
and
growth
trends
that
our
technological
advancement
today
enjoys
there
are
in
my
assessment
three
main
reasons
that
have
led
to
this
exponential
growth
first
we
use
the
technology
we
develop
to
develop
more
technology
for
example
CAD
computer
aided
design
is
a
technology
that
became
much
more
sophisticated
when
more
powerful
computers
were
used
to
develop
it
the
better
the
CAD
the
more
powerful
the
microchips
we
could
develop
which
led
to
better
computers
which
led
back
to
even
better
CAD
software
this
circular
feedback
loop
applies
to
all
tech
in
an
exponential
fashion
whatever
you
build
rapidly
helps
you
build
an
even
better
version
of
it
in
a
future
iteration
the
second
indisputable
driver
of
the
accelerating
rate
of
technology
development
is
the
internet
specifically
the
democratization
of
knowledge
and
tools
that
this
new
world
offers
when
I
studied
engineering
back
in
Egypt
I
struggled
with
fully
understanding
the
theory
of
hydraulics
which
really
is
way
too
simple
for
anyone
to
struggle
with
as
compared
to
the
other
topics
I
studied
the
reason
for
this
had
nothing
to
do
with
the
complexity
of
the
topic
but
rather
the
fact
that
there
was
only
one
book
in
the
entire
university
library
that
explained
the
parts
that
eluded
me
for
me
to
get
access
to
that
knowledge
I
needed
to
make
an
appointment
with
that
book
which
normally
would
be
a
couple
of
weeks
later
when
it
was
time
I
would
wait
in
front
of
the
librarian
as
if
I
was
waiting
to
go
on
a
date
with
the
love
of
my
life
and
I
would
spend
every
minute
of
that
hour
in
the
absence
of
my
handy
phone
camera
scribbling
notes
not
the
best
way
to
advance
your
knowledge
you
would
agree
today
however
the
internet
gives
the
exact
same
information
to
a
curious
researcher
in
Africa
as
it
does
to
a
Harvard
student
this
democracy
of
knowledge
along
with
a
democracy
of
open
source
tools
and
cloud
computing
solutions
that
give
innovators
access to
state-of-the-art
platforms
for just a few
dollars a
month
is driving
a revolution
of innovation
coming from
all corners
of the
world
any
startup
or
even
any
individual
developer
be it
in
India
Korea
or
Ukraine
has
an
equal
chance
of
inventing
the
next
Google
as
anyone
at
the
heart
of
Silicon
Valley
and
they
often
do
finally
the
globally
connected
world
of
e-commerce
offers
immediate
access
to
global
markets
that
drastically
improve
the
economics
of
innovation
as
they
allow
small
startups
to
scale
up
and
fund
their
ideas
at
a
faster
and
faster
pace
put
it
all
together
and
it
becomes
obvious
that
contrary
to
common
belief
change
is not
the only
constant
as a
matter
of
fact
change
is not
constant
at
all
change
is
always
present
but
the
rate
of
change
is
speeding
up
exponentially
things
are
changing
faster
and
faster
and
faster
we're
not
just
innovating
faster
remember
the
speed
at
which
we
innovate
is
accelerating
can
you
believe
it
we
won't
experience
another
100
years
of
progress
in
the
21st
century
it
will
be
more
like
20,000
years
of
progress
at
today's
rate
and
that's
if
we
assume
that
no
new
disruptive
technology
will
be
invented
that
propels
us
leaps
and
bounds
ahead
of
the
current
curve
of
accelerated
returns
this
is the
way
things
have
been
since
the
1960s
and
yet
we
still
find it
hard
to
believe
we
we
find
it
hard
to
believe
that
our
incredible
technology
today
will
look
primitive
when
compared
to
the
technology
we
will
invent
in
the
next
20
years
despite
the
evidence
we
have
this
seems
to be
the
way
the
human
brain
works
when
my
ancient
fellow
Egyptian
the
pharaoh
instructed
his
engineers
to invent
something
that
could
make
his
chariot
go
faster
they
came
up
with
genius
mechanisms
that
allowed
them
more
horses
to
the
front
of
it
when
he
wanted
the
work
on
the
pyramids
to
proceed
faster
they
invented
ways
to
use
pulleys
cables
and
rounded
logs
of
wood
to
lift
the
two
and a
half
ton
stones
up
the
ramps
more
quickly
as
the
pharaoh
then
paraded
around
the
mighty
pyramids
in
his
twelve
horse
propelled
chariot
I
bet
you
no
one
expected
technology
to
ever
get
any
better
than
that
if
you
had
told
them
that
a
few
thousand
years
later
someone
would
invent
two
and a
half
ton
stones
that
are
contained
within
fifty
pound
bags
of
powder
you
can
carry
individually
up the
ramps
and
then
simply
add
water
to
to
turn
into
solid
rock
they
would
have
thought
you
had
lost
your
marbles
yet
here
we
are
using
cement
to
build
cities
that
are
in
many
ways
mightier
than
the
pyramids
just
a
side
note
at
a
certain
point
in
time
cement
was
the
height
of
human
invention
though
we
take
it
for
granted
today
it
was
analogous
in
its
impact
then
to
the
way
the
internet
impacts
our
lives
now
if
you
had
told
the
ancient
Egyptians
that
the
VW
group
would
be
able
to
pack
a
thousand
five
hundred
horses
into
an
internal
combustion
engine
to
propel
the
Bugatti
Cheron
from
zero
to
sixty
miles
an
hour
in
two
and
a
half
seconds
and
keep
accelerating
to
a
top
speed
of
three
hundred
and
five
miles
per
hour
they
would
have
thought
you
had
gone
totally
mad
the
way
the
pharaohs
same
way
we
react
today
when
confronted
with
the
imminent
possibility
of
a
technology
that
completely
dwarfs
our
current
inventions
more
remarkable
still
is that
we
even
have
the
same
reaction
to
technologies
that
already
actually
exist
we
refuse
to
believe
that
they
are
possible
though
they
are
already
here
one
great
example
of
this
is
quantum
computing
traditional
computers
perform
calculations
using
bits
of
information
that
are
simply
like
an
on
and
off
switch
flip
the
bit
on
and
it
is
logged
at
the
value
of
one
switch
it
off
and
it's
a
zero
stack
a
few
of
those
ones
and
zeros
after
each
other
and
you
get
what
is
known
as
binary
code
avoiding
the
need
to
get
too
technical
here
computers
can
read
that
code
they
understand
that
flipping
the
switch
on
and
off
to
form
the
pattern
one
zero
one
zero
one
zero
means
the
number
42
computers
can
generate
and read
these
codes
so
fast
they
can
perform
the
magic
that
we
have
gotten
used
to
seeing
them
do
and
yet
a
new
technology
has
come
along
that
does
not
require
them
to read
any
faster
to
process
more
information
instead
these
blazingly
fast
computers
can now
read
more
much
more
in
every
individual
string
of
code
quantum
computers
use
quantum
bits
or
qubits
which
can
exist
in what
is known
as a
state
of
superposition
not
as
one
or
zero
but
as
both
one
and
zero
simultaneously
this
bizarre
characteristic
of
quantum
mechanics
is the
reason
why
quantum
computers
are
expected
to
perform
much
faster
than
classical
computers
without
being too
technical
let me
explain
a pair
of
traditional
bits
can
store
only
one
of
four
possible
combinations
or
states
which
are
zero
zero
zero
one
one
zero
or
one
one
simple
a pair
of
qubits
however
can
store
all
four
combinations
simultaneously
this is
because
each
classical
bit
can
either
be
on
or
off
while
each
qubit
can
be
both
on
and
off
one
and
zero
at
the
same
time
if
you
add
more
qubits
computer
power
grows
exponentially
three
qubits
store
eight
combinations
four
store
16
and so
on
google's
new
quantum
computer
called
sycamore
has
53
qubits
and
can
store
253
values
or more
than
10
quadrillion
combinations
this is
10
followed
by
15
zeros
so
how
much
faster
does
that
make
it
in
october
2019
sycamore
outperformed
the most
powerful
supercomputers
in the
world
by solving
a problem
considered
virtually
impossible
for normal
machines
to solve
the complex
calculation
completed
by
sycamore
would have
taken
the world's
most
advanced
supercomputer
10,000
years
to finish
it took
sycamore
200
seconds
that is
one and a half
trillion
times faster
there are
two ways
you can look
at this
stellar
performance
one way
is to
celebrate
that
we saved
civilization
the 42
years
it would
have taken
the classical
computers
we keep
advancing
to reach
that milestone
following
Moore's
law
the other
way is to
recognize
that quantum
computing
itself
is literally
in its
infancy
and that
if the
same laws
of accelerating
returns
apply to
them
then that
massive jump
of performance
will itself
double and
multiply
very rapidly
how rapidly
it is widely
believed
that the
rate at
which our
tech will
advance
when powered
by quantum
computers
will be
double as
exponential
as what
we have
seen
with
Moore's
law
this
staggering
new rate
of acceleration
is known
as
Nevin's
law
after
Hartmut
Nevin
founder
and director
of Google's
quantum
artificial
intelligence
lab
this
law
began
as
an
in-house
observation
before
Nevin
mentioned
it
publicly
at the
Google
quantum
spring
symposium
he said
that
quantum
computers
are gaining
computational
power
relative
to
classical
ones
at
a
double
exponential
rate
it looks
like nothing
is happening
nothing is
happening
and then
whoops
suddenly
you're in
a different
world
Nevin
said
that's
what we're
experiencing
here
a
double
exponential
rate
means that
as opposed
to our
traditional
computers
being
predicted
to become
16-fold
more powerful
in about
5 years
quantum
computers
would become
65,000
fold
more powerful
in those
short
5 years
this is
65,000
times
more
powerful
than
what is
already
1.5
trillion
times
faster
than
the
world's
fastest
computer
welcome
to the
new
paradigm
of our
future
what
could you
do
with such
a
computer
well
to start
with
forget
cyber
security
and
encryption
all
of
today's
security
systems
use
algorithms
so
complex
that
they
are
impossible
for a
human
to
figure
out
and
they
would
take
enormous
resources
from
one
of
today's
classical
computers
to decode
such
challenges
however
can be
decoded
by a
quantum
computer
in
microseconds
a
quantum
computer
can
create
very
complex
simulations
that
would
enable
scientists
to
conduct
virtual
experiments
and
advanced
science
we
could
model
the
behavior
of
atoms
and
particles
at
unusual
conditions
at
very
high
energies
for
example
instead
of
needing
to
employ
the
hadron
collider
quantum
computers
will
also
be
capable
of
processing
massive
amounts
of
data
in
parallel
so
they
can
help
us
do
incredibly
complex
calculations
such
as
those
needed
for
weather
forecasting
much
more
accurately
than
we
can
today
they
would
be
able
to
predict
hurricanes
way
ahead
of
time
and
maybe
even
suggest
the
actions
needed
to
create
butterfly
effects
that
dissolve
a
natural
disaster
before
its
inception
they
could
be
our
rain
makers
equally
they
could
and
likely
will
become
the
eye
in
the
sky
watching
every
move
of
every
human
and
taking
actions
to
prevent
us
from
committing
crimes
we
have
not
even
considered
committing
yet
most
importantly
such
enormous
processing
power
will
advance
the
development
of
artificial
intelligence
at a
rate
that will
eclipse
human
intelligence
the
minute
it
becomes
available
this
is not
a
figure
of
speech
here
I
mean
the
exact
minute
not
not
the
day
or
week
let
me
explain
professor
mervyn
lee
minsky
the
initiator
of the
dartmouth
ai
conference
where
ai
was
conceived
in
1956
was an
american
cognitive
scientist
concerned
largely
with
research
in
artificial
intelligence
he
is
co-founder
of the
massachusetts
institute
of
technologies
ai
laboratory
and
author
of
several
texts
concerning
ai
and
philosophy
he
was
quoted
as
saying
that
if
we
had
the
right
methods
we
could
create
human
level
ai
with
a
pentium
chip
nobody
is
really
in a
position
to
guess
how
big
a
computer
you
need
to
match
the
highest
level
of
human
thought
and
i
suspect
it's
rather
small
pentium
was
intel's
then
revolutionary
microprocessor
released
in 1995
though it
was a
major
tech
breakthrough
at the
time
it's
not that
impressive
in comparison
to the
levels
of
computer
power
your
phone
enjoys
today
there
is
no
debate
in
computer
science
circles
that
this
is
possible
so
what
will
happen
if
we
have
computers
that
are
trillions
of
times
more
powerful
than
a
pentium
chip
they
will
become
billions
of
times
smarter
than
humans
and
they
will
get
there
much
much
faster
remember
alpha
go
the
machine
that
became
the
world
champion
at
the
most
complex
game
humans
had
ever
played
it
it
played
approximately
1.3
million
games
against
itself
in
six
weeks
to
learn
and
gather
the
intelligence
it
needed
to
be
the
human
world
champion
run
it
on a
quantum
computer
and
it
would
do
this
within
a
fraction
of
a
second
its
successor
alpha
go
zero
won
a
thousand
to
zero
against
stockfish
the
AI
that
held
the
world
championship
in
chess
all
it
needed
was
nine
hours
of
training
that
would
take
almost
no
time
at
all
for
a
quantum
computer
which
would
then
spend
another
couple
of
seconds
to
figure
out
all
of
the
internet
encryption
we've
ever
created
and
another
fraction
of
a
second
to
find
the
code
to
all
the
nuclear
weapons
before
it
dedicates
its
attention
to
pondering
the
secret
of
life
the
universe
and
everything
believe
me
when
I
tell
you
that
computers
that
will
outsmart
humanity
will
certainly
become
a
reality
as a
matter
of
fact
they
are
here
already
the
irony
is
however
that
as
time
continues
to
speed
up
it
does
not
seem
plausible
that
Nevin's
law
itself
will
rule
our
world
for
too
long
this
is
because
our
ability
to
predict
anything
beyond
the
point
when
computers
are
smarter
than
all
of
us
is
totally
impaired
don't
believe
any
of
the
harmonious
utopian
fairy
tales
that
futurists
and
evangelists
of
AI
preach
don't
believe
the
dystopian
future
sci-fi
has
predicted
either
don't
even
believe
that
any
of
what
I
tell
you
will
happen
either
because
the
truth
is
nobody
knows
what
will
happen
if
we
could
invent
such
incredibly
smart
beings
with
our
seemingly
limited
human
intelligence
then there
is no
way to
imagine
what
they
with
their
supreme
intelligence
will be
able to
invent
that
would be
like
expecting
a fly
to grasp
how
computers
work
what
will
happen
beyond
the
point
when
the
machines
outsmart
us
is
completely
unknown
this
is
why
we've
come
to
call
it
the
singularity
as
I
touched
on
in
the
introduction
in
physics
singularity
is an
event
horizon
beyond
which
it's
impossible
to
predict
what
will
happen
because
the
conditions
beyond
it
change
as
compared
to
our
familiar
physical
universe
it
is
a
point
of
infinite
mass
density
at
which
space
and
time
are
infinitely
distorted
by
gravitational
forces
it
is
held
to
be
the
final
state
of
matter
before
it
falls
into
a
black
hole
and
we
don't
really
know
what
happens
when
inside
that
black
hole
some
say
that
all
the
laws
of
physics
break
down
at
singularity
and
so
our
ability
to
calculate
physical
behavior
and
properties
no
longer
holds
true
I'm
certain
that
there
are
other
physical
rules
that
operate
beyond
the
point
of
singularity
we're
just
not
smart
enough
to
understand
them
not
not
understanding
something
is
a
state
that
the
ego
of
humanity
does
not
take
too
lightly
we
glorify
knowledge
and
intelligence
so
much
partly
because
we
know
deep
inside
that
without
our
intelligence
we
would
no
longer
be
at
the
top
of
the
food
chain
please
refer
to
diagram
5
in
your
pdf
pack
to
see
how
the
quantum
ai
shift
might
lead
you
to
a
singularity
much
quicker
than
you
expect
I've
said
it
before
but
it
bears
repeating
in
the
grander
scheme
of
things
we
humans
think
too
highly
of
ourselves
if
earth
was
created
one
year
ago
the
entire
human
civilization
would
just
be
ten
minutes
old
during
those
few
minutes
we
assumed
absolute
leadership
of the
planet
and
forced
every
other
species
to
submit
to
our
will
what
chance
did
they
have
none
flies
birds
chimpanzees
none
of them
knew
what
had
hit
them
their
habitat
was
eroded
because
we
set
the
rules
they
never
imagined
what
might
happen
our
scale
of
intelligence
did
not
only
surpass
their
ability
to
react
but
even
their
ability
to
comprehend
how
things
unfolded
when
a
bullet
hit
an
elephant
it
did
not
reason
that
this
came
from
a
sophisticated
innovation
called
a
gun
or
that
it
was
motivated
by
a
market
where
ivory
was
exchanged
for
money
or
even
what
money
was
to
begin
with
this
human
superiority
is
about
to
change
soon
it
will
be
our
turn
to
deal
with
the
being
of
superior
intelligence
in fact
imminently
as
as
our
path
of
technological
advancement
continues
it's
not
hard
to
predict
a
future
where
the
machine's
superior
intelligence
exceeds
ours
by
such
a
gap
we
will
start
to
feel
like
the
elephant
who
did
not
know
what
hit
it
we
will
have
no
way
of
understanding
the
rules
that
govern
this
black
hole
we've
created
we
will
have
reached
a
state
of
singularity
by
then
technological
change
will
be
so
rapid
and
profound
as
I
demonstrated
previously
through
the
quantum
computing
example
that
machines
will
represent
the
first
real
qualified
players
to
create
a
rupture
in
the
fabric
of
human
history
the
implications
of
such
levels
of
unprecedented
intelligence
inhabiting
our
planet
and
the
scenarios
that
could
play
out
are
endless
on
one
side
of
the
spectrum
of
possibilities
some
predict
that
we
will
merge
our
biological
intelligence
with
the
non-biological
intelligence
of the
machines
thus
producing
immortal
software
based
humans
with
ultra-high
levels
of
intelligence
that
expand
outwards
into
the
universe
at
the
speed
of
light
at
the
other
end
of
the
spectrum
however
others
predict
a
decision
by
the
superior
intelligence
that
biology
is a
nuisance
or
perhaps
that
a
gorilla
is a
much
better
specimen
of
biology
for
a
machine
biology
symbiosis
than
a
human
as
the
difference
between
our
intelligence
and
theirs
is
irrelevant
when
compared
to
the
infinite
intelligence
of
the
machines
and
that
it's
in the
best
interest
of
the
machine
and
the
planet
that
we
are
no
longer
considered
important
both
extremes
and
every
other
scenario
in
between
are
plausible
possibilities
which
will
become
our
reality
nobody
knows
one
thing
is
certain
though
as
we
head
into
the
singularity
the
third
inevitable
bad
things
will
happen
as
with
everything
from
toothpaste
to
capitalism
to
marxism
when
someone
wants
you to
align
with
their
point
of
view
or
get
you
to
buy
their
product
they
will
talk
to
you
passionately
about
all
of
the
positives
of
their
offering
or
ideology
they
will
omit
the
downsides
and
they
will
while
appearing
to be
respectful
bash
every
other
view
that
does
not
conform
to
their
agenda
if
they
have
the
resources
they
will
rely
on
the
testimony
of
experts
just
to
drive
the
point
all
the
way
home
mobile
phone
companies
often
produce
ads
showing
their
products
at
a
party
you
know
the
lifestyle
accessory
of
cool
people
having
fun
they
will
not
zoom
in
to
show
you
the
email
someone's
boss
just
sent
asking
them
to
deliver
something
before
the
morning
campaigning
politicians
obviously
will
promise
all the
good
they
intend
to
do
by
the
end
of
their
term
as
they
make
new
promises
they
forget
to
mention
how
they
didn't
deliver
on
the
old
ones
toothpaste
companies
will
shoot
their
ad
at
a
dentist's
clinic
and
say
something
like
80%
of
dentists
recommend
our
new
product
blinding
white
how
they
manage
to
ask
all
the
dentists
beats
me
AI
evangelists
are no
different
like
politicians
they
position
AI
as
an
indispensable
part
of
the
future
utopia
we're
about
to
build
like
mobile
phone
companies
they
make
promises
that
life
will
be
easier
and
more
fun
like
toothpaste
companies
they
use
the
testimony
of
experts
lots
of
experts
who
claim
to
know
the
future
with
absolute
certainty
I
don't
know
how
anyone
can
claim
to
know
something
beyond
a
point
of
singularity
but
they
do
it
anyway
as
they
do
so
they
omit
the
views
of
other
less
optimistic
experts
those
who
say
there's
much
higher
probability
of a
dystopian
future
to
make
the
scales
a bit
more
balanced
so
that
you
can
make
up
your
own
mind
let
me
share
with
you
one
such
view
Elon
Musk
who
I
mentioned
previously
predicts
that
AI
could
be
more
dangerous
than
nuclear
weapons
he
also
believes
that
we
are
ignoring
the
prospects
of
what
could
go
wrong
he
said
the
biggest
issue
I
see
with
the
so-called
AI
experts
is that
they
think
they
know
more
than
they
do
and
they
think
they
are
smarter
than
they
actually
are
this
tends
to be
the
plague
of
smart
people
they
define
themselves
by
their
intelligence
and
they
don't
like
the
idea
that
a
machine
can
be
smarter
than
them
so
they
discount
the
idea
I'm
really
quite
close
to the
cutting
edge
in
AI
and
it
scares
the
hell
out
of
me
we
have
to
figure
out
some
way
to
ensure
that
the
advent
of
digital
super
intelligence
is
one
which
is
symbiotic
with
humanity
I
think
this
is
the
single
biggest
existential
crisis
that
we
face
remember
amid
the
euphoria
surrounding
the
coolness
of
AI
the
associated
threats
are
often
conveniently
ignored
Elon
then
continued
I'm
not
really
all
that
worried
about
the
short
term
stuff
narrow
AI
which
is
AI
that
is
dedicated
to
specific
narrow
scope
functionality
is
not
a
species
level
risk
it
will
result
in
dislocation
lost
jobs
better
weaponry
and
that
kind
of
thing
but
it
is
not
a
fundamental
species
level
risk
whereas
super
intelligence
is
when
Marvin
Minsky
was
asked
if
we
should
worry
about
the
advancement
of
AI
he
said
of
course
we
have
to
worry
that
the
first
few
hundred
versions
will
be
dangerous
or
treacherous
or
filled
with
mysterious
bugs
you
have
to
be
careful
not
to
put
them
in
charge
of
anything
for
a
while
in
fact
he
said
we'd
better
be
very
careful
in
the
transitional
stages
because
remember
it's
not
clear
whose
interest
the
machines
will
have
at
heart
just
whose
interest
will
the
machines
have
in
their
digital
hearts
and
yes
they
will
have
emotional
hearts
as I
will prove
to you
later
that
will
shape
the way
they
behave
and
determine
the
direction
in
which
our
future
will
head
at
a
very
fundamental
level
I
know
looking
back
at
the
past
that
things
have
a
tendency
to
go
wrong
sometimes
it's
inevitable
I
also
know
that
the
breadth
of
possibility
of
mistakes
increases
along
with
the
complexity
of
what
we
are
building
for
example
if
this
book
was
only
two
pages
it
would
have
had
fewer
typos
than
the
countless
ones
I
made
in
its
original
version
I
also
know
that
the
impact
of
a
mistake
can
be
massively
magnified
