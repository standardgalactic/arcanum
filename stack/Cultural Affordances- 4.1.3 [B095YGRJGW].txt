Welcome to the ACTIV podcast, where we will present short, digestible segments clipped
from the Active Inference Lab weekly live streams.
If you like what you hear and you want to learn more, check out the entire live stream
on the Active Inference Lab YouTube channel.
My name is Blue Knight, and I will be guiding you through this podcast, which is clipped
from Active Inference Lab live stream number 4.1.
This week's episode is a discussion that is loosely structured around the paper, Cultural
Affordances, Scaffolding Local Worlds Through Shared Intentionality and Regimes of Attention
by Maxwell Ramstead, Samuel Vessier, and Lawrence Kiermaier.
Maxwell Ramstead, the first author, will be starting off this episode discussing human
thinking.
Daniel Friedman will be jumping in to facilitate the live stream discussion.
The point that we're making here, I mean, it's really developed in our BBS paper, Thinking
Through Other Minds, but it's that human thinking really is not just thinking about
other humans, but thinking through their own perspective, and that much of our social
interactions actually are structured by the beliefs that we have about other people's
beliefs about our own behavior and beliefs.
So you get this kind of nicely recursive intentionality structure.
Yeah, so that's like the simple kind of, you know, the basic cognitive formula that we're
calling it.
But we think that this really applies to almost all human thinking.
We're really always kind of trying to understand a situation from the perspective of, you know,
shared beliefs about what's appropriate in that situation, which implies the ability to
kind of perspective take, and to think through the minds of others.
Yep.
When someone's talking to hear themselves talk, as we say, it's off the rails, because it's
not in feedback with other minds.
But when somebody is attuned to the narrative and the culture of the local world, the local
actual interaction, not just the hypothetical, then there's the opportunity for communication
to be targeted and direct and actually move towards shared goals and under shared values
as well, instead of just individuals biophysically running their mouth, which is an affordance
that we also have.
So how do we move our communication patterns towards this higher level, instead of just using
the opportunities that we know that we can also have?
I'm Stephen, I'm based in Toronto.
One thing I was going to say as well is that we talk a lot about perspectivism and, you know,
we go up to higher and higher levels.
But I think you see a point at which you can only take a perspective on what you think to
a certain level.
It gets too complex, too multi-sensory, too many inputs.
And it is that kind of phenomenological embodied feel for what you need to do, which is not
something you even have a perspective on, you know, that idea of the flow.
So there's this inferential kind of approach as well as a perspectival approach, which just
comes from just feeling what you should do.
And I think this kind of shows that because I think you can only go up so far and take perspectives
on things when how you act in the moment.
And sometimes you just have to be there and feel it.
Yeah.
And we can't perfectly emulate what somebody else wants.
And it's just not that simple.
We're in the bodies that we have with the affordances that we see.
And so to try to over-engineer what the other person wants or should want or should want to
want, it's a good thought experiment.
And it helps in a lot of situations, but it is not the end game of relating.
Well, it might also explain some of the difficulties that we're having currently in our political
landscape.
So, I mean, as a Canadian, I'm very sold on the idea of multiculturalism and diversity
and pluralism.
But I think these are not intuitive modes of sociality precisely because they oblige us
to multiply the different perspectives through which we're trying to, you know, relate to
a shared social world.
And, you know, like things like Dunbar's number, I'm sure you're all familiar with Dunbar's
number, right?
And if you basically plot the size of primate brains against the size of their social groups,
there's almost a linear relation.
And if you extrapolate that to humans, we would, you know, live in groups of about 100,
150-ish.
And, you know, that probably has a lot to do with, you know, the kind of sweet spot where
it's easy to kind of share, you know, a bunch of beliefs and norms and patterns of behavior
with the group.
And things get more and more complicated as the group expands and diversity is included,
which is not to say that diversity is a bad thing.
By all means, I think, you know, we should move in that direction.
But I think it speaks to some difficulties that we're seeing politically, that it's not
an intuitive mode of sociality.
Here, Maxwell is going to transition from talking about social structure and diversity within
social structure to human thinking in relation to cultural affordances.
So the point here is to kind of say, well, it's not merely just about, you know, inferring
what others think I should do.
It's really more about the situational coping, right?
So it's about, like, learning different contexts and learning about what's allowable in all
of these different contexts and then being able to juggle that and to reactivate the right
constellation of, you know, semantic knowledge, for example, or rules and norms that pertain
to each context and also then, you know, moving from one context to the next and seeing what
kind of flexibility that allows for, ultimately, because, you know, human reality is improvisational.
Like, it's about kind of, you know, coping with a situation given the constraints of that situation
in real time.
Yeah.
Yeah, it's a controlled novelty question, like a lot of improvisation.
It's on the edge, the bleeding edge and the trade-off between explore and exploit where
successful systems are at.
And so the teenage rebellion, if the teenagers just mindlessly fell into the line of whatever
was happening before, maybe in some niche that was unchanging, that would be a successful
evolutionary strategy.
But the niches are always changing, not for the least of which is ecology, but also improvisation
has this always moving dynamic.
And so the teenage rebelliousness is there's the element of the individual coming to precision
about who am I and who am I in this broader sense.
And then at the higher level, there's this explore-exploit where some element of contrarianism,
it comes across like a negative word, but if you'd ever had contrarian models, then you
couldn't know if you were just in a very, very local optima or whether there are other realms
to explore.
So there's so much there and the details are all in actually formulating these specific
situations and understanding what are the affordances, what is precision doing here.
So figure three is a hierarchical prediction error minimization framework.
And Maxwell, maybe could you give a shot on what was being summarized here?
Sure.
I mean, we're just describing Bayesian predictive coding here.
And the way these schemes work is, I think, consonant with the phenomenology.
So essentially, if the brain doesn't have to process something, then it doesn't.
The brain is a lazy organ.
So the thing I often say to drive this home is, what was the color of the last door handle
you opened?
There's a large, there's a high probability that you didn't register that at all.
Well, because there's no reason to, right?
Like you just smoothly coped with the door.
What you needed to do is open the door to get to the other side of it.
And, you know, there was no reason to even register the color of the door handle.
So what this kind of framework says is, the signal that the brain is processing at any
time is the discrepancy between the data that it was expecting to register and the data that
it actually does.
And this difference is called a prediction error.
This relates to Bayes in the sense that descending messages carry prior probabilities.
So essentially, you can think of this as the base rate for a given phenomenon, independent
of the data that I'm collecting.
And then the prediction error kind of combines that knowledge with data.
So it's something like the likelihood.
If the prior is just the probability of an event that I'm considering, the likelihood is
the probability of that event given some data that I've actually registered effectively.
So this is why these frameworks are often called Bayesian.
The ascending messages carry prediction errors, which are likelihoods, and the descending messages
carry prior probabilities, which are the predictions that the predictive brain and so on are all about.
Perfect.
And then from here, we move on to a specific hypothesis, the predictive coding.
I'm not sure 100% the degree to which we're still committed to this functional distinction.
But the idea is that, at least in the brain, there are going to be two kinds of neural populations.
The ones which encode effectively these generative model units, which are the ones that are encoding
the kind of base rates about the phenomena that you're interested in.
And then another functionally distinct subpopulation of neurons that's responsible for computing the difference
between the data you expected given these predictions and the data that you're actually receiving.
And again, the unexplained signal, that the part of the signal that wasn't predicted by the descending messages
is passed upstream in the hopes that it will be explained away at some point.
And also one note that can help understand this is this caption.
In the empirical Bayes framework, the system can then use the posterior obtained from one iteration
as the prior in the next iteration.
And so the empirical Bayes framework is in a way what it cuts the Gordian knot.
It prevents us from just saying, well, it's just simply priors all the way up.
And we start somewhere by starting our prior for one level with just empirically what we're
getting from the posterior at the lower level at that time point as a starting point.
And so this can be instantiated in physical, not infinite systems, because there's a possibility
that empirical Bayes, just as it's used in data analysis in a variety of fields, you can use
the data to inform a prior and then have a generative model that starts working from there.
Yeah, precisely.
And what Bayes does in this context is just provide a way to optimally combine what you
knew before sampling any data with what you've learned from that data.
So as you're saying, what you're essentially doing is multiplying your posterior.
So you calculate your posterior by multiplying your prior by your likelihood and then normalizing,
which can get a bit hairy at times, but that's effectively what you're doing here.
We hope that you enjoyed this week's episode on human thinking and some ways that it is modeled.
